Recently, the black-box nonlinear system identification approaches have become effective methods to model complex systems. By the idea of combining the merits of reservoir computing (RC) of the Echo state network (ESN) and fuzzy inference system, a TSK fuzzy ESN for the black-box identification is proposed in this paper. The proposed network is constructed on the basis of the framework of ESN containing multiple sub-reservoirs in which each sub-reservoir is contributed with a TSK fuzzy rule. Through this hybrid structure, first, a modified structure of ESN with less complexity is provided to give an effective black-box identification method for uncertain nonlinear systems. Second, the fuzzy clustering of the training data of an application is used to define the number of sub-reservoirs; then, the singular value decomposition (SVD) is applied to randomly initialize the weight matrix of each sub-reservoir. Third, according to the characteristic of ESN, only the output weights of the sub-reservoirs are learned by the recursive least squares (RLS) algorithm without adjusting the other parameters of the network including the centers and widths of the fuzzy basis function of the TSK fuzzy inference system. Moreover, the convergence of the parameter learning based on RLS is investigated. To demonstrate the performance of the proposed TSK fuzzy ESN in the identification of nonlinear systems, three numerical simulations are given. The simulation results also involve a comparison with other structures of ESN and fuzzy neural networks to confirm the effectiveness of the proposed TSK fuzzy ESN.

Introduction
Nowadays, the complex structure of industrial processes such as chemical industry, electricity, metallurgy, electronics, and machinery manufacturing makes it difficult to obtain the physical models for these processes. Consequently, the black-box nonlinear system modeling field has been introduced to address this issue [50]. This modeling scheme creates a data-driven mathematical approximation of nonlinear systems with little or no information about their dynamics.

During the last decades, neural networks (NNs) have been found wide applications in the black-box identification [4, 29, 53,54,55]. By combining the fuzzy rule-based systems with the learning ability of NNs, fuzzy neural networks (FNNs) have become one of the powerful and flexible universal approximations in the black-box identification [13, 45, 68]. To define the optimum structure of FNNs, self-organized FNN approaches have been conducted in the literature [16,17,18, 27, 44].

FNNs based on Takagi–Sugeno–Kang (TSK) inference system are the most useful structure in nonlinear system modeling; they are multi-model structures that can combine linear sub-models to effectively approximate complex nonlinear dynamic systems [26, 27, 35]. By using TSK fuzzy model, many adaptive control strategies have been developed for nonlinear systems. In the control problems of stochastic nonlinear systems, fuzzy adaptive control schemes have received considerable attention. For example, the authors in [39] proposed an adaptive fuzzy control scheme for a class of stochastic nonlinear systems with a risk-sensitive performance index. Using fuzzy modeling concept, event-triggered adaptive tracking control for a class of pure-feedback stochastic nonlinear systems was introduced [56]. For networked control systems (NCSs), various kinds of control strategies via fuzzy modeling technique were proposed [15, 57].

Constructing more effective TSK FNN for uncertain systems became an interesting point of research. In this aspect, many hybrid structures based on TSK fuzzy inference system and other approximation functions were introduced. For example, fuzzy wavelet neural networks (FWNNs) in which the consequent part of the TSK fuzzy inference system was replaced by wavelet function [1, 28, 64]. A hybrid FNN based on wavelet support vector regression was proposed in [30]. A computational intelligent approach combining kernel methods with wavelet multi-resolution analysis (MRA) was introduced to improve the performance of FWNN with nonlinear system modeling [37]. The wavelet function was used as the consequent part of the TSK-type fuzzy cerebellar neural network to construct a hybrid algorithm for uncertain nonlinear systems [67].

Generally, NNs are classified into feed-forward neural networks (FFNNs) and recurrent neural networks (RNNs) [14]. RNNs are more convenient to nonlinear system modeling than FFNNs because they can cope with time-varying input or output through their natural temporal operation. Moreover, less number of neurons for RNN can approximate the dynamic mapping to obtain the desired performance [5]. However, the traditional RNNs suffer from the problems related to the gradient descent learning algorithms. These algorithms cause slow convergence, local minima problem, sensitivity to bifurcations, and may instability [3].

In recent years, a class of RNNs, echo state network (ESN), has been introduced to alleviate the training complexity of traditional RNNs [22, 23]. ESN is a recurrent neural network with a large number of randomly connected nodes named reservoir and read-out layer. The synaptic connection weights of the reservoir are not changed after initialization, and only readout output weights are trained. ESN was used for predicting time series [19, 48, 58, 59], for modeling nonlinear systems [47, 62, 63, 65] as well as adaptive controlling of nonlinear systems [8, 10, 25, 41, 42].

The learning process of ESN is a regression task method that greatly simplifies the training of the network and eliminates the issues of the traditional RNNs training process [51]. Among the existing training methods of ESN, the pseudo-inverse method and the gradient-based methods have been used [2, 7, 24, 40, 52]. However, the pseudo-inverse method is sensitive to the initial values of the input and the internal weights of ESN. Also, the gradient-based methods suffer from the local minima problem and slow convergence. To avoid the aforementioned linear regression problems, different learning algorithms have been used in the literature. For example, a matrix trace-based online learning algorithm was introduced to train the output weights of the proposed sinusoidal ESN [62]. An online learning algorithm based on the historical reservoir state and training error has been applied to training the weights of adaptive ESN [63]. The evolutionary algorithm-based methods such as particle swarm optimization (PSO) and covariance matrix methods have been used [11, 36].

In general, the ESN performance improves with a high reservoir size (model complexity) [31]. However, a poor generalization performance can result in an increased model complexity [46]. Given time series problems, many improved structures based on the reservoir size design have been proposed. The growing echo state network (GESN) with a multiple-reservoir structure was proposed to determine the reservoir size and topology automatically [46]. A broad echo state network with multiple reservoirs in parallel structure for the prediction of a class of time series was conducted by Yao and Wang [60]. A multiple reservoir computing in series–parallel configuration based on intelligent interconnected ESN was proposed for time series classification and predication [61]. A hybrid method based on PSO and singular value decomposition (SVD) was introduced to design a growing ESN with multiple-reservoir structure [33]. Li et al. [32] proposed a multi-reservoir ESN (MR-ESN) based on the simple training mechanism of ESN and the strong feature extraction capability of deep learning.

On the other hand, Han and Lee [20] proposed a hybrid structure combining the concepts of ESN, fuzzy logic system, and wavelet function to improve the performance of the surface sliding mode control approach. Latter, the authors developed a fuzzy ESN network for the prescribed tracking performance of a strict feedback multi-input-multi-output (MIMO) nonlinear system [49]. In this work, the fuzzy ESN exploits the FNN structure in terms of the input layer, fuzzification layer, and rule firing layer, whereas the defuzzification layer and the output layer are represented by a leaky integrator ESN [24]. Hence, the approximation performance of an unknown nonlinear function can be improved by integrating the advantages of the fuzzy inference system and ESN.

This paper aims to introduce a TSK fuzzy ESN that is a hybrid structure to give further improvement for the data-driven modeling process. In this structure, the consequent part for each TSK fuzzy rule is represented by a reservoir. Consequently, the proposed structure incorporates the features of the fuzzy inference system and the ESN with multiple reservoirs in a unified model. Therefore, the fuzzy inference system improves the approximation efficiency of the proposed hybrid structure. On the other side, the ESN with multiple reservoirs provides nonlinear dynamics for the proposed model. Since only the readout output weights of the proposed network are updated using the recursive least squares (RLS) method without training the fuzzy inference parameters (i.e., centers and width of the fuzzy basis function), the proposed network has a fast training procedure. Moreover, the stability of the RLS algorithm for the proposed network is analyzed. It is noteworthy that the proposed structure can be considered a general recurrent neural network for black-box nonlinear systems identification. If each sub-reservoir is reduced to a single neuron, the proposed hybrid structure can be defined as a recurrent fuzzy neural network [18, 35]. Furthermore, if the fuzzy inference system is taken away from the structure, the proposed network can be abbreviated to an ESN with multiple reservoirs [33, 46, 60]. In summary, the main contributions of the proposed structure are as follows:

1.
Presenting an ESN with multiple sub-reservoirs such that the contribution of each sub-reservoir is weighted by a TSK fuzzy rule. Hence, the effective performance of the proposed network in the modeling and prediction of nonlinear systems with a small size of the reservoir can be obtained.

2.
The fuzzy c-mean algorithm [6] is used to define the structure of the TSK fuzzy ESN that is the number of fuzzy rules (i.e., the number of sub-reservoirs). Then, the random initialization of each sub-reservoir weight matrix is performed by SVD to guarantee the stability and the echo state property of the proposed structure.

3.
The merits of the proposed TSK fuzzy ESN are demonstrated using three simulation examples which are a nonlinear function approximation, prediction of a chaotic system, and modeling of a nonlinear dynamic system. The comparison between the proposed network, the ordinary ESN [23] and the fuzzy ESN [49] as well as other hybrid FNN structures over the three modeling simulations are performed.

The outline of the rest of this paper is organized as follows. Section 2 describes the essential background of ESN. In Sect. 3, the detailed description of the proposed TSK fuzzy ESN including the network structure, learning, and stability analysis is presented. In Sect. 4, three modeling simulations are introduced to demonstrate the capability of the suggested structure. Finally, the conclusion and future work are discussed in Sect. 5.

Echo state network
The structure of ESN without output feedback is illustrated in Fig. 1. It is composed of an input layer with m neurons, a hidden layer (i.e., dynamical reservoir) with R connected units, and an output layer. Define 𝑥(𝑘)=[𝑥1(𝑘),...,𝑥𝑚(𝑘)]𝑇∈ℜ𝑚, and 𝜁(𝑘)=[𝜁1(𝑘),...,𝜁𝑅(𝑘)]𝑇∈ℜ𝑅, where x(k) and 𝜁(𝑘) specify to the input vector and the state of the reservoir at time step k, respectively. The dynamic of ESN is done by updating its reservoir states and outputs as

𝜁(𝑘)=𝑓(𝜃𝜁(𝑘−1)+𝜃𝑖𝑥(𝑘))
(1)
𝑦(𝑘)=𝜃𝑇o𝜁(𝑘)
(2)
where y is the network output, 𝑓(⋅)=(𝑓1(⋅),...,𝑓𝑅(⋅)) are the activation functions of the hidden units (typically tanch or sigmoid function), 𝜃∈ℜ𝑅×𝑅 denotes to the reservoir weight matrix , 𝜃𝑖∈ℜ𝑅×𝑚 is the input weight matrix, and 𝜃o∈ℜ𝑅 is the weight vector for output node. Based on the RC of ESN, only 𝜃o is learned, whereas 𝜃 and 𝜃𝑖 are randomly generated in the initialization stage and fixed in the training procedure. Therefore, ESN presents faster learning than traditional recurrent neural networks. Let Σ=[𝜁(1),...,𝜁(𝑁)] is the reservoir state matrix, and 𝑍=[𝑧(1),...,𝑧(𝑁)] is the corresponding target output vector for N data pattern. The optimal output weights can be given by solving the following minimization problem:

min𝜃o‖𝜃oΣ−𝑍‖
(3)
By obtaining the pseudo-inverse Σ+=(ΣΣ𝑇)−1Σ of Σ, the output weights 𝜃o can be given as [23]

𝜃o=Σ+𝑍=(ΣΣ𝑇)−1Σ𝑍
(4)
Unfortunately, the pseudo-inverse method suffers from the high sensitivity to initialize values of the network weights. Also, for a large reservoir size of the network, the inverse calculation is quite complex. To alleviate these problems, the RLS can be an effective alternative training method for the network. The existence of the echo state property is critical to ensure adequate operation of the dynamic reservoir of ESN. Practically, ESN can possess this property by performing the following steps [23]:

1.
Randomly choosing the internal weights 𝜃, which is typically drawn from a uniform distribution over the symmetric interval.

2.
Normalizing 𝜃 by dividing it with its largest eigenvalue.

To construct the reservoir weight matrix without scaling and guarantee the stability of ESN, SVD-based design algorithms have been used [33, 58]. In the following, we will propose TSK fuzzy ESN with a simple training method based on RLS and a small complexity modal (i.e., reservoir size) by combining the ESN structure and fuzzy reasoning system. Besides, the echo state property condition is considered.

Fig. 1
figure 1
ESN structure

Full size image
TSK fuzzy echo state network
The proposed TSK fuzzy ESN network involves a set of sub-reservoirs, and each reservoir is used as the consequent part of a TSK fuzzy IF-THEN rule. A typical TSK fuzzy rule of the proposed network is described as

Rule𝑛:IF𝑥1(𝑘)is𝐴𝑛,𝑥2(𝑘)is𝐴𝑛,...,and𝑥𝑚(𝑘)𝑖𝑠𝐴𝑛Then:𝜁𝑛(𝑘)=𝑓𝑛(𝜃𝑛𝜁𝑛(𝑘−1)+𝜃in𝑥(𝑘))𝑦𝑛(𝑘)=𝜃on𝜁(𝑘),for𝑛=1,...,𝑞
(5)
Here, 𝜁𝑛, 𝑓𝑛, 𝜃𝑛∈ℜ𝑅×𝑅, and 𝜃in∈ℜ𝑅×𝑚 stand to the states, the activation function, the reservoir weight matrix, and the input weight matrix of the nth sub-reservoir, respectively. 𝑦𝑛 is the 𝑛𝑡ℎ sub-reservoir output, and 𝜃on∈ℜ𝑅 is its weight vector.

Remark 1
In the proposed TSK fuzzy ESN network, all sub-reservoirs are assumed to have the same reservoir size (i.e., R) [33]. Moreover, the number of the TSK fuzzy rules of the proposed structure is assumed to be equal to the number of the fuzzy sets of the input variables of the network (i.e., q) [18, 38].

The neural network topology of the TSK fuzzy ESN can be described in the following subsection.

TSK fuzzy ESN structure
The structure of the TSK fuzzy ESN is shown in Fig. 2. It consists of five layers that can be described in the following.

1.
Layer one: This layer is the input layer that accepts the input variables of the network, the number of units of this layer is the dimension of the input space, and they are given as 𝑥(𝑘)=[𝑥1(𝑘),...,𝑥𝑚(𝑘)]𝑇∈ℜ𝑚.

2.
Layer two: This layer represents the fuzzy rule layer, and each node of this layer is the firing of a fuzzy rule represented by a radial basis function (RBF) as

𝜓𝑛=∏𝑖=1𝑚exp(−(𝑥𝑖−𝑐in𝑤in)2),𝑛=1,2,...𝑞
(6)
where 𝑐in and 𝑤in are the centers and the width of the nth RBF for the ith input, respectively.

3.
Layer three: This layer is the normalization stage in which each rule firing strength given in the last layer is normalized by

𝜑𝑛=𝜓𝑛∑𝑞𝑛=1𝜓𝑛
(7)
4.
Layer four: This layer is a group sub-reservoirs, and the states and the output of each sub-reservoir are calculated as

𝜁𝑛(𝑘)𝑦𝑛(𝑘)=𝑓𝑛(𝜃𝑛𝜁𝑛(𝑘−1)+𝜃in𝑥(𝑘))=𝜃𝑇on𝜁𝑛(𝑘)
(8)
5.
Layer five: This is the output layer, which is the sum of the outputs of the sub-reservoirs weighted with their associated normalized rule firing strength giving from (7). Hence, the output is obtained as:

𝑦(𝑘)=∑𝑛=1𝑞𝜑𝑛𝑦𝑛(𝑘)
(9)
Fig. 2
figure 2
TSK fuzzy ESN structure

Full size image
Structure identification of TSK Fuzzy ESN
To identify the structure of the proposed model, the following parameters need to define: (1) the number of sub-reservoir q; (2) the size of each sub-reservoir R; (3) initialization of the suitable random values of the weight matrix of each sub-reservoir that satisfying the echo state property of the proposed TSK fuzzy ESN.

The fuzzy c-mean clustering algorithm (FCM) is employed here to generate the convenient number of sub-reservoir (i.e., the number of fuzzy rules) of the network, and consequently, the optimum centers of each RBF associated with each sub-reservoir [6]. The size of each sub-reservoir is selected such that a trade-off between the network complexity and its satisfactory performance in the modeling of nonlinear systems should be taken into consideration.

Once the reservoir size is selected, the random selection of the weights matrix of each sub-reservoir (i.e., 𝜃𝑛) should be done to the convenient values that satisfying the echo state property of the proposed TSK fuzzy ESN. Here, the SVD-based design method is provided to construct the weights of the sub-reservoirs. By defining U and V as two orthogonal matrices ∈ℜ𝑅×𝑅 and a diagonal matrix 𝑆=𝑑𝑖𝑎𝑔(𝜎1,𝜎2,...,𝜎𝑅), the nth reservoir weight matrix 𝜃𝑛∈ℜ𝑅×𝑅 can be given based on SVD as

𝜃𝑛=USV
(10)
Hence, 𝜃𝑇𝑛𝜃𝑛=(USV)𝑇USV=𝑉𝑇(𝑆𝑇𝑆)𝑉, 𝑈𝑇𝑈=𝐼, I is identity matrix; it means that both 𝜃𝑛 and S have the same singular values which are (𝜎1,𝜎2,...,𝜎𝑅). The FCM and SVD-based identification stage for the proposed network is summarized in Algorithm 1.

The computation burden of Algorithm 1 can be obtained by the summation of the complexity of the FCM and SVD methods. In general, the complexity of the FCM is O(Nq), where O refers to the overall computational cost of an algorithm, N is the number of data points, and q is the number of clusters [66]. Besides, applying SVD on a matrix of R variables requires 𝑂(𝑅3) [12]. Hence the computational complexity of SVD for the proposed network is 𝑞∗𝑂(𝑅3), where R is the reservoir size for each sub-reservoir and q is the number of sub-reservoirs (i.e., number of fuzzy rules).

figure a
Parameter learning of TSK Fuzzy ESN
The statement of the parameter learning of TSK fuzzy ESN can be formulated as in the following. Substituting from Eq. (8) into Eq. (9), yields

𝑦(𝑘)=𝜃𝑇𝑜1𝜑1𝜁1(𝑘)+...+𝜃𝑇𝑜𝑞𝜑𝑞𝜁𝑞(𝑘)
(11)
Define Θo=[𝜃𝑜1,...,𝜃𝑜𝑞]𝑇∈ℜ𝑅𝑡 and 𝜁𝑡=[𝜑1𝜁1,...,𝜑𝑞𝜁𝑞]𝑇∈ℜ𝑅𝑡, where 𝑅𝑡=𝑅×𝑞 is the total reservoir size of the network. Thus, the output of TSK fuzzy ESN can be represented by following linear form

𝑦=Θ𝑇o𝜁𝑡
(12)
Accordingly, any continuous function 𝑔(𝑥):ℜ𝑚→ℜ on a large enough compact set Ω⊂ℜ can be approximated by the TSK fuzzy ESN in form (12) such that the following inequalities hold

sup𝑥∈Ω|𝑔(𝑥)−𝑦𝑡(𝑥)|≤𝜂𝑚
(13)
where 𝜂𝑚>0, then g(x) can be approximated by

𝑔(𝑥)=(Θ∗o)𝑇𝜁𝑡(𝑥)+𝜂,∀𝑥∈Ω
(14)
where 𝜂 bounded by |𝜂|≤𝜂𝑚 is the approximation error of the TSK fuzzy ESN and Θ∗o is the ideal output weights satisfying

Θ∗o=argminΘo∈ℜ𝑅𝑡{sup|𝑥∈Ω∣∣𝑔(𝑥)−Θ𝑇o𝜁𝑡(𝑥)∣∣}
(15)
Practically, Θ∗o is unknown and its estimation value is used and updated by designing a learning algorithm to minimize the approximation error asymptotically. Given N arbitrary data samples {𝑥(𝑘),𝑍(𝑘)}𝑁𝑘=1 for the network. The matrix pseudo-inverse method defined in Eq. (4) can be adapted to estimate the TSK fuzzy ESN parameters as:

Θo=Σ+𝑍=(ΣΣ𝑇)−1Σ𝑍
(16)
Here, Σ=[𝜁𝑡(1),...,𝜁𝑡(𝑁)] is matrix including the state vectors of all sub-reservoirs and 𝑍=[𝑧(1),...,𝑧(𝑁)] is the corresponding target output vector. To avoid the linear regression problem of the pseudo-inverse method, the RLS is used for the training of the proposed model as follows.

Let 𝐻(𝑘)=(Σ(𝑘)Σ𝑇(𝑘))−1, then Θo given in (16) at time step k is given by:

Θo(𝑘)=𝐻(𝑘)Σ(𝑘)𝑍(𝑘)=𝐻(𝑘)(∑𝑗=1𝑘−1𝜁𝑡(𝑗)𝑧(𝑗)+𝜁𝑡(𝑘)𝑧(𝑘))
(17)
Also at time step 𝑘−1, we have

Θo(𝑘−1)=𝐻(𝑘−1)Σ(𝑘−1)𝑍(𝑘−1)=𝐻(𝑘−1)(∑𝑗=1𝑘−1𝜁𝑡(𝑗)𝑧(𝑗))
(18)
and

𝐻(𝑘)𝐻(𝑘−1)=(Σ(𝑘)Σ𝑇(𝑘))−1=(∑𝑗=1𝑘𝜁𝑡(𝑗)𝜁𝑇𝑡(𝑗))−1=(Σ(𝑘−1)Σ𝑇(𝑘−1))−1=(∑𝑗=1𝑘−1𝜁𝑡(𝑗)𝜁𝑇𝑡(𝑗))−1
(19)
Then

𝐻−1(𝑘)=𝐻−1(𝑘−1)+𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘)
(20)
Multiplying the two sides of (18) by 𝐻(𝑘−1)−1, yields

𝐻−1(𝑘−1)Θo(𝑘−1)=(∑𝑗=1𝑘−1𝜁𝑡(𝑗)𝑧(𝑗))
(21)
Substituting from Eq. (21) into Eq. (17), yields

Θo(𝑘)=𝐻(𝑘)(𝐻−1(𝑘−1)Θo(𝑘−1)+𝜁𝑡(𝑘)𝑧(𝑘))
(22)
Substituting from Eq. (20) into Eq. (22), yields

Θo(𝑘)=𝐻(𝑘)((𝐻−1(𝑘)−𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘))Θo(𝑘−1)+𝜁𝑡(𝑘)𝑧(𝑘))
(23)
Then, we have

Θo(𝑘)=Θo(𝑘−1)+𝐻(𝑘)𝜁𝑡(𝑘)(𝑧(𝑘)−𝜁𝑇𝑡(𝑘)Θo(𝑘−1))=Θo(𝑘−1)+𝐻(𝑘)𝜁𝑡(𝑘)𝑒𝑠(𝑘)
(24)
where

𝑒𝑠(𝑘)=𝑧(𝑘)−𝜁𝑇𝑡(𝑘)Θo(𝑘−1)
(25)
Define the approximation error at time step k as

𝑒(𝑘)=𝑧(𝑘)−𝜁𝑇𝑡(𝑘)Θo(𝑘)
(26)
Using Eq. (24) and the approximation error defined above, the variable 𝑒𝑠(𝑘) can be calculated by

𝑒𝑠(𝑘)=𝑒(𝑘)1−𝜁𝑇𝑡(𝑘)𝐻(𝑘)𝜁𝑡
(27)
By substituting from Eq. (27) into Eq. (24), the updating rule of Θo at time step k is given by

Θo(𝑘)=Θo(𝑘−1)+𝐻(𝑘)𝜁𝑡(𝑘)𝑒(𝑘)1−𝜁𝑇𝑡(𝑘)𝐻(𝑘)𝜁𝑡
(28)
Applying the inversion matrix lemma:

(𝐴+𝐵𝐶𝐷)−1=𝐴−1−𝐴−1𝐵(𝐷𝐴−1𝐵+𝐶−1)−1𝐷𝐴−1
with 𝐴−1=𝐻(𝑘−1),𝐵=𝜁𝑡(𝑘),𝐶=𝐼,𝐷=𝜁𝑇𝑡(𝑘) in Eq. (20), the recursive relation for calculating H(k) can be defined by:

𝐻(𝑘)=𝐻(𝑘−1)−𝐻(𝑘−1)𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘)𝐻(𝑘−1)1+𝜁𝑇𝑡(𝑘)𝐻(𝑘−1)𝜁𝑡(𝑘)
(29)
Using the RLS-based training method for the proposed network provides two advantages. First, the updating rule of the proposed network weights only requires the reservoir state vector utilized by the network. Hence, the regression matrix problem related to the pseudo-inverse method is avoided. Second, the RLS uses a time-varying matrix gain (i.e., 𝐻(𝑘)1−𝜁𝑇𝑡(𝑘)𝐻(𝑘)𝜁𝑡 term in Eq. (28) that speeds up the learning process, whereas the gradient-based methods such as back-propagation algorithm use a constant scalar gain (i.e., learning rate) [21]. Therefore, the RLS based-training method needs a small computation burden to update the weights of the proposed network.

Convergence analysis
This subsection investigates the convergence of the learning algorithm for the proposed structure. At time step k, define:

𝑦(𝑘)=𝜁𝑇𝑡(𝑘)Θo(𝑘)
(30)
𝑧(𝑘)=𝜁𝑇𝑡(𝑘)Θ∗o
(31)
where Θ∗o and Θo are the ideal network weight and its estimated value, respectively. The estimation error for the network weights is

Θ˜o(𝑘)=Θ∗o−Θo(𝑘)
(32)
Substituting from (30) and (31) into (25), yields

𝑒𝑠(𝑘)=𝜁𝑇𝑡(𝑘)Θ˜o(𝑘−1)
(33)
Hence, according to Eqs. (32) and (33), Eq. (24) can be reformulated as:

Θ∗o−Θ˜o(𝑘)=Θ∗o−Θ˜o(𝑘−1)+𝐻(𝑘)𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘)Θ˜o(𝑘−1)
(34)
This yields

Θ˜o(𝑘)=(𝐼−𝐻(𝑘)𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘))Θ˜o(𝑘−1)
(35)
From Eqs. (20), (35) can be reconstructed as

Θ˜o(𝑘)=𝐻(𝑘)𝐻−1(𝑘−1)Θ˜o(𝑘−1)
(36)
Let:

𝑃(𝑘)=𝐻(𝑘)𝐻−1(𝑘−1)
(37)
Then

Θ˜o(𝑘)=𝑃(𝑘)Θ˜o(𝑘−1)
(38)
Using Eq. (20), the matrix P(k) can be set as:

𝑃(𝑘)=(𝐻−1(𝑘−1)+𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘))−1𝐻−1(𝑘−1)
(39)
𝜁𝑡(𝑘)𝜁𝑇𝑡(𝑘) is a symmetrical and positive matrix because of using the sigmoid function or the tanch function as an activation function for each sub-reservoir in the proposed network. Consequently, 𝐻−1(𝑘−1)=𝜁𝑡(𝑘−1)𝜁𝑇𝑡(𝑘−1) is also a symmetrical and positive matrix. As a result, the norm of the matrix ‖𝑃(𝑘)‖<1. Then we can say that

Θ˜o(𝑘)<𝑃(𝑘)Θ˜o(𝑘−1)
(40)
Therefore,

lim𝑘→∞Θ˜o(𝑘)=0
(41)
According to (32) and (41)

lim𝑘→∞Θo(𝑘)=Θ∗o
(42)
We conclude that the learning algorithm expressed in Eqs. (28) and (29) for the proposed network is globally convergent.

Simulation results
This section presents the results obtained by the application of the proposed structure for the black-box identification of nonlinear systems. Three modeling examples are used to validate the proposed TSK fuzzy ESN: (1) approximation of a nonlinear function; (2) predication of Henon chaotic system; (3) identification of a nonlinear dynamic system. For all tested models, the following items are considered.

The sigmoid function 𝑓(𝑥)=(1−exp(−𝑥))/(1+exp(−𝑥)) is used as the reservoir activation functions for each sub-reservoir.

The input weight matrices for all sub-reservoirs 𝜃in, 𝑛=1,2,...𝑞 are randomly generated within the range [−0.5,0.5].

The maximum singular value for designing the reservoir weight matrix for each sub-reservoir based on SVD is selected as 𝜎𝑚𝑎𝑥=0.5.

The training samples are classified into 3 clusters (i.e., meaning that the network has 3 sub-reservoirs) and the sub-reservoir size was set to 10. Consequently, the total reservoir size of the network is 30.

All simulations are performed by MATLAB 7.9 and implemented using an Intel i7, 2.4 GHz CPU, with 8 GB RAM running on Windows 10 (64 bit) operating system.

Because the proposed structure is a hybrid scheme between the ESN and TSK fuzzy system, two points of view for the comparisons are conducted (i.e., from viewpoints of the echo state network structures and the FNN fuzzy structures). In the first one, the proposed structure was compared with the traditional ESN [23] and the hybrid fuzzy ESN [49] for the tested models. From the second point of view, the proposed structure is compared with other existing hybrid fuzzy neural networks that have been reported in the literature on the given modeling examples. The performance metrics including the root-mean-squared error (RMSE) and the computation time are used for evaluating the performance of the proposed network as well as for the comparison procedure. The RMSE is defined as:

RMSE=1𝑁∑𝑘=1𝑁(𝑧(𝑘)−𝑦(𝑘))2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷
(43)
where N is the number of training data, z is the target, and y is the network output at an instant time k.

Approximation of a Nonlinear function
In this example, the proposed network is evaluated via the approximation of the following nonlinear function [38, 67].

𝑦=64−81(𝑥1−0.6)2+(𝑥2−0.5)2‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√/9−0.5
(44)
In this example, the inputs of the network are 𝑥1 and 𝑥2, which are randomly generated in the interval [0, 1]. In total, 1100 sampling data are collected from the function. The first 1000 samples are used for the training of the proposed TSK fuzzy ESN, and then, the last 100 samples are chosen for the testing phase. For training the proposed network to approximate the nonlinear function, 10 independent runs are carried out for 100 epochs. Figure 3 shows the output response of the network. It can be observed that the proposed network can approximate the nonlinear function where the testing error provided by the proposed TSK fuzzy ESN is very small and within the range [−0.0021,0.0036].

Fig. 3
figure 3
Outputs of nonlinear function and the proposed TSK fuzzy ESN during testing phase

Full size image
To verify the performance of the proposed structure, the ESN [23] and the fuzzy ESN [49] are used to compare the approximation accuracy. Using the data pattern collected from the nonlinear function, the two comparative networks are trained for different reservoir sizes (i.e., 30, 45, 60, 75, and 90) using the same learning algorithm of the proposed TSK fuzzy ESN. For the fuzzy ESN [49], three fuzzy rules are used as in the proposed network. Based on 10 independent runs, the average performance metrics including RMSE and computation time in the training and the testing phases for the three networks are given in Table 1. From this simulation results, we can see that for all cases of ESN [23] and fuzzy ESN [49], the approximation accuracy of the proposed TSK fuzzy ESN is the best. The RMSE values of the proposed network with reservoir size 30 (i.e., the smallest size) are 0.0011 and 0.0012 in the training and testing stages, respectively, while the best RMSE values of ESN are 0.0031 and 0.0035 with reservoir size 75 and the fuzzy ESN are 0.0119 and 0.0126 with reservoir size 90. As a result, the training time of the proposed TSK fuzzy ESN is the smallest as shown in this table.

Table 1 Performance comparison of ESN, fuzzy ESN, and the proposed TSK fuzzy ESN (nonlinear function example)
Full size table
The comparison with other existing hybrid FNNs such as wavelet fuzzy neural network (WFNN) [38], TSK-type fuzzy cerebellar neural network models (TSK-FCMNN) [34], fuzzy cerebellar neural network model (FCMNN) [9], and wavelet TSK-type fuzzy cerebellar neural network structure (WTFCMNN) [67] that reported on the same example is depicted in Table 2. As shown in the table, the proposed structure can provide better RMSE performance compared to other FNNs and the smallest computation time.

Table 2 Performance comparison of the proposed structure with different FNNs in the approximation of a nonlinear function
Full size table
Prediction of Henon chaotic system
In this example, the proposed network is used to predict the Henon chaotic system which is one of the classical benchmark tasks used for chaotic time series prediction problems [18, 67]. This system is described by

𝑥(𝑡+1)=−𝐻𝑥2(𝑡)+𝑄𝑥(𝑡−1)+1.0
(45)
where 𝐻=1.4 , 𝑄=0.3 , and 𝑥(0)=𝑥(1)=0.1. In total, 400 data samples are collected from the system over the interval [−1.5,1.5], the first 200 samples for the training, and the last 200 samples for the testing. The proposed TSK fuzzy ESN is provided to predict 𝑥(𝑡+1) using the series–parallel predication method shown in Fig. 4, where the inputs of the TSK fuzzy ESN are 𝑥(𝑡−1) and x(t), 𝑥(𝑡+1) is the target output, and 𝑥ˆ(𝑡+1) is the prediction output for the chaotic system using the TSK fuzzy ESN model. Like the previous example, the network is trained for 10 independent runs for 100 epochs. The prediction output using the proposed network and the output of the chaotic system during the training phase are shown in Fig. 5. The testing outputs of the proposed network and the Henon system are also shown in Fig. 6. It can be seen that the proposed structure provides effective performance in the prediction of the Henon chaotic system. To show the prediction performance, Fig. 7 describes the phase plane diagram of the network, and the figure refers to the high prediction accuracy of the proposed network.

Fig. 4
figure 4
Series–parallel prediction method for Henon chaotic system using the proposed TSK fuzzy ESN, where 𝑞−1 is the back sift operator

Full size image
Fig. 5
figure 5
Outputs of the Henon chaotic system and the proposed TSK fuzzy ESN during the training phase

Full size image
Fig. 6
figure 6
Outputs of the Henon chaotic system and the proposed TSK fuzzy ESN during testing phase

Full size image
Fig. 7
figure 7
The phase plane diagram of the Henon chaotic system and the predicted output using the proposed TSK fuzzy ESN

Full size image
The RMSE and computation time for the proposed TSK fuzzy ESN, the ESN [23], and the fuzzy ESN [49] are given in Table 3. It is clear that the best values of the training and the testing RMSE for the ESN [23] are 0.0031 and 0.0059, respectively. These values are obtained in the case of a reservoir size 75, and the computation time is 0.0666 s. For the fuzzy ESN [49], the best RMSE values are 0.0062 and 0.0077, respectively, for a reservoir size 90 and the computation time is 0.1232 s, while the training and the testing RMSE values of the proposed network are 0.0024 and 0.0026, respectively, with the smallest reservoir size 30 and the computation time 0.0202 s. Finally, we can conclude that the proposed structure has a superior performance with a small reservoir size and less computation cost compared to the ESN [23] and the fuzzy ESN [49].

Table 3 Performance comparison of ESN, fuzzy ESN, and the proposed TSK fuzzy ESN (Henon chaotic system)
Full size table
The performance of the TSK fuzzy ESN is also compared with other FNN structures reported in the prediction of Henon chaotic system such as a hybrid FNN based on wavelet support vector regression (WSVR-FNN) [30], recurrent FNN with local feedback (RFNN-LF) [27], interactively self-evolving FNN (IRSFNN) [35], and self-organized FNN with adaptive gradient algorithm (SOFNN-AGA)) [18]. To make the proposed network has the same training samples used for the other FNNs, 2000 data samples are collected from the system over the interval [−1.5,1.5] to train the proposed network; the first 1000 samples are used for the training phase and the last 1000 are used for the test phase. The comparison is measured by the number of fuzzy rules, the testing RMSE, the CPU time, and the testing average percentage error (APE) which is calculated by

APE=1𝑁∑𝑘=1𝑁∣∣∣𝑧(𝑘)−𝑦𝑁(𝑘)𝑧(𝑘)∣∣∣×100
(46)
The comparative results are given in Table 4. From the table, it can be observed that the testing RMSE and APE of the proposed network are less than the other FNNs models as well as the CPU time. The higher performance of the proposed network in the sense of RMSE and APE concerning other FNNs is due to adding the ESN approach in the fuzzy system. Further, the small CPU time of the proposed network is due to updating only the readout weights of the ESNs, while other parameters are fixed.

Table 4 Performance comparison of the proposed structure with different FNNs in the prediction of Henon system
Full size table
Identification of a nonlinear dynamic system
In this example, the proposed structure is used to identify the following nonlinear system [18]:

𝑦(𝑡+1)=0.72𝑦(𝑡)+0.025𝑦(𝑡−1)𝑢(𝑡−1)+0.01𝑢2(𝑡−1)+0.2𝑢(𝑡−3)
(47)
where y(t) and u(t) are the output and the input of the system, respectively. The initial values are set to zero (i.e., 𝑦(0)=𝑢(0)=0). Using the series–parallel identification method shown in Fig. 8, the proposed TSK fuzzy ESN is provided to identify the given nonlinear system. Here, the input vector of the proposed TSK fuzzy ESN is 𝑥=[𝑦(𝑡),𝑦(𝑡−1),𝑢(𝑡−1),𝑢(𝑡−2)]𝑇, 𝑦(𝑡+1) is the target output, and 𝑦ˆ(𝑡+1) is the identifier output. Given the same structure of the TSK fuzzy ESN used in the previous two modeling examples, two identification cases were conducted to validate the proposed structure in modeling the nonlinear dynamic system.

Free noise case
In this case, 1000 samples are generated to train the TSK fuzzy ESN using the input signal 𝑢(𝑡)=1.05sin(𝜋𝑡/45), and other 1000 samples are collected for the testing phase using the following input signal:

𝑢(𝑡)=⎧⎩⎨⎪⎪⎪⎪sin(𝜋𝑡/25)1−10.6sin(𝜋𝑡/10)+0.1sin(𝜋𝑡/32)+0.3sin(𝜋𝑡/25)𝑡<250,250≤𝑡<500,500≤𝑡<750,𝑡≥750,
(48)
For this case, the system output and the response of the network during the testing process are illustrated in Fig. 9. These results prove that the output of the proposed network is very close to the nonlinear system output.

Fig. 8
figure 8
Series–parallel identification method for the nonlinear system using the proposed TSK fuzzy ESN

Full size image
Fig. 9
figure 9
Outputs of the nonlinear system and the proposed TSK fuzzy ESN during testing phase (free noise case)

Full size image
Noise case
In order to test the robustness of the TSK fuzzy ESN, a white Gaussian sequence with zero mean and variance 0.3 is added to the training data used in the previous task as well as the testing. In this case, the system and the network outputs during the training phase and the training errors are shown in Figs. 10, 11. Moreover, the outputs during the test phase are shown in Fig. 12. It is clear that the proposed TSK fuzzy ESN can effectively fit the nonlinear system even that the system is noisy.

Fig. 10
figure 10
Outputs of the nonlinear system and the proposed TSK fuzzy ESN during training phase (noise case)

Full size image
Fig. 11
figure 11
Training error (noise case)

Full size image
Fig. 12
figure 12
Outputs of the nonlinear system and the proposed TSK fuzzy ESN during testing phase(noise case)

Full size image
The two networks ESN [23] and the fuzzy ESN [49] are trained using the same training samples to model the given nonlinear dynamic system with noise and free-noise cases. The comparative results during the training and testing processes for the two cases are shown in Table 5. The performances of the three structures indicate that the proposed network gives the best performance in comparison with all cases of ESN and fuzzy ESN despite the simplicity of its structure (since the reservoir size of the proposed TSK fuzzy ESN is only 30) especially in the case of noisy data. This assures the robustness and the simplicity of the proposed model inspired by the concept of sub-reservoirs based on fuzzy partitioning.

Table 5 Performance comparison of ESN, fuzzy ESN, and the proposed TSK fuzzy ESN in the identification of a nonlinear system
Full size table
Finally, the comparison of the TSK fuzzy ESN with other FNN models such as FWNN [1], WSVR-FNN [30], RSEFNN-LF [27], and SOFNN-AGA [18] reported on the modeling of the given nonlinear dynamic system is performed. Using the same data patterns, Table 6 depicts the comparison in terms of the number of fuzzy rules, testing RMSE, testing APE, and CPU time. The table demonstrates that the proposed TSK fuzzy ESN has the smallest testing performance indices RMSE and APE (i.e., 0.0059 and 0.0013). Moreover, the CPU time of the proposed network is less than all comparative FNN models.

Table 6 Performance comparison of the proposed structure with different FNNs in the identification of a nonlinear system
Full size table
Performance evaluation
In this subsection, the influence of the sub-reservoir size “R” and the number of sub-reservoir ‘‘𝑞″ on TSK fuzzy ESN performance is studied. Without loss of generality, the prediction of the Henon chaotic system is used to perform this evaluation.

First, using 3 sub-reservoirs of the network, different sub-reservoir sizes (i.e., 𝑅=10,15,20,25,30,40, and 50) were successively used to train the network to predict the Henon chaotic system. The performance measurements in terms of the RMSE and the computation time in the training and testing stages are drawn in Fig. 13. It is clear that in the sensing of RMSE, the network performance improves as the sub-reservoir size increases and its best performance is in the case of the sub-reservoir size 30. But after that, there is no clear improvement in both the training and testing phases. At the same time, with increasing size, an increase in the computation time is shown. Thus, the sub-reservoir size should be selected such that a trade-off between the performance of the network and its complexity is taken into consideration.

Fig. 13
figure 13
Performance evaluation of the proposed TSK fuzzy ESN versus sub-reservoir size

Full size image
Second, to study the influence of the number of sub-reservoirs (i.e., number of fuzzy rules) in the network performance, it was trained with different numbers of sub-reservoirs (i.e., 𝑞=2, 𝑞=3, 𝑞=5, and 𝑞=10) to predict the chaotic system. In this study, the total reservoir size of the network was kept fixed at 30. This means that the sub-reservoir size R must be selected such that 𝑅𝑡=𝑞∗𝑅=30. For example, when training data were partitioned into 2 fuzzy clusters (i.e., 2 sub-reservoirs), the size of each sub-reservoir has been selected to be 15 and when the number of sub-reservoirs was selected to 5, the sub-reservoir size has been set to 6, etc. The performance metrics including the RMSE and the computation time in the training and testing phases of those cases are shown in Fig. 14. It is noted that the RMSE performance of the network improves when the number of sub-reservoirs increases from 2 to 3, whether in the training or testing phase. Also, the network performance at the number of sub-reservoirs being 3 and 5 is almost equal. After increasing the number of sub-reservoir from 5 to 10, the performance is drastically decreased in the training and testing phases. On the other hand, by increasing the number of sub-reservoirs the computation complexity drastically increases. Through this study, determining the optimum number of sub-reservoir can be considered as a step-wise modeling procedure. It can be selected by successive training of the proposed structure with an increase of q; then, the appropriate value associated with the smallest RMSE is determined by taking into consideration the network complexity.

Fig. 14
figure 14
Performance evaluation of the proposed TSK fuzzy ESN versus number of sub-reservoirs

Full size image
Conclusion
In this work, a new identification method based on TSK fuzzy ESN is proposed for the black-box modeling of nonlinear systems. The proposed TSK fuzzy ESN is an improved structure of ESN with multiple sub-reservoirs designed based on TSK fuzzy inference realization. To identify the structure of the network based on the features of the training data, the fuzzy clustering algorithm is first applied. Also to ensure that the TSK fuzzy ESN has the echo state property, an SVD-based design method is given to initialize the weights of the sub-reservoirs. The RLS-based parameter learning algorithm is used as a simple and fast training method for the proposed network. From some theoretical analysis, the stability and convergence of the learning method are proved.

Based on the advantages of both ESN and the TSK fuzzy reasoning system, the proposed structure provides an improvement of the performance in the modeling and prediction of nonlinear systems. The simulation results refer to that the black-box identification method based on TSK fuzzy ESN can give a clear improvement of the identification accuracy for nonlinear systems with a small size of the reservoir and a less computation complexity compared to ESN and fuzzy ESN. Also, by comparing with other FNN structures, the proposed TSK fuzzy ESN is an effective hybrid FNN structure for nonlinear system modeling.

Based on the proposed TSK fuzzy ESN, two issues could be addressed in future research: (1) the selection of a suitable optimization method to optimize the network structure in terms of the size and number of sub-reservoirs of the network; (2) the investigation of the proposed network in nonlinear control approaches such as direct and indirect adaptive control schemes, an event-triggered adaptive tracking control scheme, and networked control systems.

Keywords
Echo state network
TSK fuzzy neural networks
Recurrent neural networks
Black-box identification
Modeling and prediction