The different reconstruction parameters of CT imaging lead to domain shifts, which limits the generalization of deep learning models and their applications in computer-aided diagnosis systems. In this paper, we investigate the multi-source domain generalization (DG) problem in the context of lung nodule detection from CT images. We first identify the reconstructed convolution kernel as the key parameter leading to domain shifts. Accordingly, we reorganize the public LUNA16 dataset into a domain generalization benchmark, i.e.,, LUNA-DG. Then, we propose a novel DG method by adversarial frequency alignment (AFA). Specifically, we devise an adaptive transition module (ATM) to learn a frequency attention map that can align different domain images in a common frequency domain. For this purpose, a fidelity discriminator and a multi-domain discriminator are used to train the ATM alternately and adversarially. In addition, to mitigate the issue of ineffective gradient back-propagation in naive multi-domain adversarial learning, we propose a novel random domain adversarial learning (RDAL) strategy that can back-propagate effective gradient signals and gradually reduce the gap between multiple domains. The ATM can be combined with nodule detection models through differentiable Fast Fourier Transform (FFT) and inverse FFT, allowing end-to-end training. Experimental results on both LUNA-DG and our in-house datasets validate the superiority of AFA over representative DG methods.

Introduction
Lung cancer is the deadliest cancer worldwide [1], while the early diagnosis of lung cancer and prompt treatment can reduce the mortality. As the early sign of lung cancer, detecting pulmonary nodules is of great significance and becomes a popular screening technique with low-dose Computed Tomography (CT). Recently, deep pulmonary nodule detection models can be used in computer-aided diagnosis systems (CAD) to help radiologists improve their working efficiency [2,3,4]. However, they still face a lot of challenges to meet the expectation of high sensitivity and low false-positive rate. On the one hand, different CT manufacturers have their private and unique reconstructing algorithms. Consequently, using different reconstructing parameters may result in different image styles, which are also known as different domains [5]. On the other hand, it is required to collect sufficient CT images from all the domains to train a robust deep model, which, however, is almost impossible in practice.

The most common case is that we only have images from some source domains and expect the model could generalize well in other target domains. However, the distribution shift between source and target domains, a.k.a. domain shift (DS), limits the model’s generalization ability. Recently, a lot of efforts have been made to address the DS issue in some vision tasks [6,7,8,9,10]. Image-to-image translation methods aim to transfer the style of source images to the target ones [7], while domain adaptation methods try to learn a domain invariant feature representation, therefore facilitating to train models with good generalization ability on down-stream tasks [8,9,10]. However, for one thing, we may have never seen the target domain images in the training stage, i.e.,, the domain generalization problem. For another, there may be multiple source domains in the training data and the distribution is unbalanced. Consequently, we face the more challenging multi-source domain generalization (DG) problem [11,12,13].

Both image-to-image translation and domain adaptation methods rely on the adversarial learning strategy. In the context of medical images, adversarial learning is often adopted to synthesize images. Nie used the adversarial learning strategy to produce more realistic target images from source images [14], and Sun proposed ANT-GAN to generate normal-looking medical images based on their abnormal counterparts [15]. In addition, adversarial learning can be used to enhance the features’ representation capability. Yu proposed a novel tensorizing GAN model with high-order pooling to improve the classification performance of Alzheimer’s disease [16]. Wang proposed a multi-channel generative adversarial network (MGAN) to learn the distribution of DR features and identify the inconspicuous lesions [17]. Due to the benefits of adversarial learning, we also adopt it to solve the challenging DG problem.

In the field of lung nodule detection, few works focus on the DG problem. One of the key reasons is the absence of a public benchmark. In this paper, we make an attempt to fill this gap. We identify that “convolution kernel”, which is one of the reconstructing parameters, is the main factor that causes domain shift. So we reorganize the famous LUNA16 [18] benchmark as a domain generalization benchmark based on the convolution kernel parameter, named LUNA-DGFootnote1. Based on this dataset, we propose a novel adversarial frequency alignment (AFA) method to address the DG problem in the context of lung nodule detection from CT images. Specifically, an adaptive transition module (ATM) is devised to learn a frequency attention map that can align different domain images in a common frequency domain. To this end, a fidelity discriminator and a multi-domain discriminator are utilized to alternately and adversarially train ATM. In addition, to mitigate the ineffective gradient back-propagation issue in naive multi-domain adversarial learning, we propose a novel random domain adversarial learning (RDAL) strategy, which can back-propagate effective gradient signals to progressively narrow the gaps among multiple domains. ATM can be bridged with the nodule detection model via the differentiable Fast Fourier Transform (FFT) and inverse FFT, making them end-to-end trainable. Experimental results on LUNA-DG and our in-house dataset validate that AFA outperforms representative DG methods.

Related work
Domain adaptation and generalization
Various domain adaptation and generalization methods have been proposed in the literature. Typical domain generalization methods can be divided into three groups, data manipulation, learning strategy, and representation learning [19]. Data manipulation methods use data augmentation and generation to enlarge the training data to help generalization [20]. The second group utilizes the general learning strategy to promote the generalization capability, such as meta-learning [12, 13, 21] and ensemble learning [22]. Representation learning methods intend to learn a domain invariant feature representation [11, 23, 24]. For example, adversarial learning employs a domain discriminator after the generator to distinguish the generated samples and real samples and the reversed gradients from the discriminator will force the generator to eliminate domain-specific information [10, 25, 26]. However, if there are multiple source domains, the discriminator becomes a multi-class classifier and the reversed gradients will drive the generated image close to the domain with the highest gradient magnitude. Consequently, the model is prone to collapsing to several domain cluster centers. To address this issue, MDAN [27] adopted multiple binary discriminators, which is costly when the domain number is large. Some works adopted a uniform posterior probability distribution to confuse the discriminator and update the generator [28]. However, the predefined uniform distribution may not be suitable to account for the complicated multiple domains. In this paper, we propose a novel random domain adversarial learning strategy that could adaptively push all the domains to an implicit common domain.

Benchmark datasets for DG
Many datasets have been proposed for various DG tasks, such as PACS [29] for object recognition, CityScape [30] for semantic segmentation. In the field of medical image analysis, clinical images are hard to collect, leading to the scarcity of public datasets, especially for domain generalization tasks that require images from different domains. Current research papers of medical images usually build the domain generalization dataset by incorporating multiple public datasets [31, 32]. LUNA16 [18] is a famous lung nodule dataset that consists of CT images from multiple institutions. To reuse it for domain generalization tasks, we reorganize it as a new benchmark LUNA-DG in this work according to the reconstructing convolutional kernel, which is found as the main factor that causes domain shift.

Deep learning in the frequency domain
Recently, deep learning in the frequency domain for computer vision tasks has attracted a lot of attention and some methods are proposed [33, 34]. Stuchi et al. proposed FreqNet [35] that exploits some trainable frequency filters to boost discriminative components in the spectrum. Chen et al. [36] jointed the spatial and frequency domain by the attention mechanism in face detection tasks. Yang et al. [20] proposed a data augmentation method in the frequency domain by swapping the low-frequency spectrum of different domains to improve the generalization capacity, where frequency domain was not injected explicitly into the learning process. To the best of our knowledge, we are the first to explicitly align CT images from different sources in the frequency domain for lung nodule detection.

Pulmonary nodule detection
Due to the large number of negative samples, a two-stage framework is frequently used in pulmonary nodule detection, which includes candidate nodules generation and false positive reduction [37, 38]. In traditional methods, morphological operations and shape index are widely used to detect lung nodules [39, 40]. In the deep learning era, this field has been dominated by CNN-based methods [41, 42]. Some 2.5D [43] and 3D [44] networks are introduced to automatically learn effective nodule features. Our work follows the two-stage framework and employs a 3D CNN in both stages to learn strong and discriminative features. To mitigate the domain shift issue, we propose AFA and RDAL to effectively learn domain-invariant feature representation of nodules that benefit the down-stream detection task.

Motivation
CT manufacturers hold their private reconstructing algorithms, and different reconstructing algorithms will lead to different image styles, also known as different domains [5]. When deploying a pre-trained deep model to a new domain, where the data distribution is different from the one during training, a significant performance drop is often observed, which will limit the generalization of deep learning models and their applications in computer-aided diagnosis systems. Thereby, domain adaptation and generalization are urgently needed to be addressed.

Table 1 (a) Confusion matrix of a domain classifier trained on three domains (D1∼D3) with different convolution kernel parameters. (b) Generalization performance (CPM [45]) of the nodule detection model trained on each domain, i.e.,, each row denotes the results of a model
Full size table
To address the domain generalization problem, we first conduct plenty of experiments on the reconstructing parameters of CT images and figure out that “convolution kernel” parameter is the main factor that causes domain shift. The convolution kernel represents the ramp filter in the reconstructing process, and different convolution kernels will result in different noise patterns, which causes domain shift. The experimental results are shown in Table 1b. We divided the CT images into different domains (D1∼D3) according to their reconstructing convolution kernels. A significant performance drop is observed when the nodule detection model trained on one domain is applied to other domains. We also trained a domain classification model on the candidate nodules from the three domains, and the results are shown in Table 1a. It can be seen that the classifier almost perfectly recognizes the domain label of each image, which further demonstrates that a big appearance gap exists among different domains. Based on this finding, we trace back the CT scans in the famous LUNA16 [18] benchmark to LIDC-IDRI [46] and reorganize it as a domain generalization benchmark named LUNA-DG. In addition, we also collect a large-scale in-house dataset for benchmarking of different DG methods.

A 3D CT scan is reconstructed from a series of 2D projection images, which are first transformed to the Fourier frequency domain, and then multiplied by the ramp filter [47]. Different convolution kernels refer to different ramp filters. Since the convolution kernel is the main factor that causes domain shift, it is more direct to align different domains in the frequency domain. So we propose a novel adversarial frequency alignment (AFA) method to address the domain generalization problem of CT images.

Method
Fig. 1
figure 1
Framework of the two-stage nodule detection

Full size image
We adopt a two-stage nodule detection framework including candidates generation and false positives reduction by following the same idea in [37, 38]. The pipeline is illustrated in Fig. 1. We first generate candidate nodules by a segmentation model, and the nodule location is determined as the center of the nodule segmentation mask. Then we crop the 3D patches surrounding the candidate nodules from CT images, and perform a binary classification model to identify the true nodules. Since the first stage maintains a high recall rate on different domains, the proposed multi-source domain generalization method is only applied to the false positives reduction stage. Figure 2 illustrates the proposed AFA method. We devise an adaptive transition module (ATM) and attach it in front of the classification model. ATM is trained in the frequency domain by two discriminators, while the classification model is trained in the original spatial domain. We will introduce the candidates generation process briefly in Sect. 4.1 and detail AFA in the remaining parts.

Fig. 2
figure 2
Pipeline of the proposed AFA method. We attach an adaptive transition module G in front of the binary nodule classification model G. Two discriminators, i.e.,the fidelity discriminator and the multi-domain discriminator, are employed in the training phase to assist the learning of G

Full size image
Candidates generation
The candidates generation stage aims to filter out most normal regions while maintaining a high sensitivity of nodules. We employ a U-net [48] style segmentation model to generate the candidate nodules. It is trained on 3D patches surrounding the nodules with the Dice loss [49]. After training, we can easily apply it to the whole CT scan and output a complete probability map due to its fully convolutional nature. Then, we obtain the candidate nodule centers by binarization and connected component analysis. Although the candidates generation stage recalls almost all the true nodules, it brings in some false positives inevitably. Hence, we should further reduce the false positives, e.g., via a binary classification model.

It is noteworthy that the domain shift issue may also affect the segmentation model, but fortunately, what we need is not the precise segmentation masks of nodules, but their positions, i.e.,the center of the segmentation mask. According to what we observed, domain shift only affected the segmentation mask on the boundries, which has little impact on the result of the nodule position. The coarse segmentation mask is sufficient to maintain a high recall rate of nodules, as shown in the experiment section. Therefore, we only perform AFA on the classification model in the second stage.

Adaptive transition in the frequency domain
The standard imaging process of CT scans is based on the filtered back-projection algorithm [47], in which a 3D CT scan is reconstructed from a series of 2D projection images in the frequency domain. Besides, as mentioned in the introduction section, the reconstructing convolution kernel is the main factor that causes domain shift. These observations inspire us to eliminate the domain shift in the frequency domain. Concretely, we propose an adaptive transition module (ATM) to align different domains, as illustrated in Fig. 3. The whole transition process can be formulated as follows:

Fig. 3
figure 3
Diagram of the adaptive transition module

Full size image
(𝑥𝐴,𝑥𝑃)=𝐹𝐹𝑇(𝑥),
(1)
𝑥̂ 𝐴=𝐸𝐷(𝑥𝐴)⊗𝑥𝐴,
(2)
𝑥̂ ≜𝐺(𝑥)=𝑖𝐹𝐹𝑇(𝑥̂ 𝐴,𝑥𝑃).
(3)
The 3D CT image x is first converted to the frequency domain by FFT, obtaining the amplitude spectrum 𝑥𝐴 and the phase spectrum 𝑥𝑃. From our observation, the style information is preserved in the amplitude spectrum, while the content information is preserved in the phase spectrum [20]. Thereby, the phase spectrum remains unchanged in the transition process. The logarithmic rescaled amplitude spectrum is sent to an encoder-decoder network ED to learn an attention map 𝐸𝐷(𝑥𝐴), which is element-wise multiplied with the original amplitude spectrum to reconstruct a new one 𝑥̂ 𝐴. The attention map can be regarded as a gate to filter out the domain-specific frequency information. Finally, the frequency-aligned image 𝑥̂  is obtained by iFFT of the reconstructed amplitude spectrum and the original phase spectrum. The whole transition process is denoted as G(x). The encoder-decoder ED follows the U-net style, which includes 3 downsampling stages and 3 upsampling stages, followed by a sigmoid function to obtain the attention map. ATM is trained via adversarial learning using a fidelity discriminator. The loss function is defined as:

𝐿𝐹(𝐺,𝐷𝑓)=𝐸𝑥∼𝑝data[log𝐷𝑓(𝑥)]+𝐸𝑥∼𝑝data[log(1−𝐷𝑓(𝐺(𝑥)))].
(4)
Here, 𝐷𝑓 is the fidelity discriminator aiming to distinguish real images and the reconstructed images, while ATM tries to reconstruct images that confuse the fidelity discriminator. Adversarial training between them will push the distribution of the generated samples to the real data distribution and guarantee that the generated image is still a realistic image. Since iFFT is nonparametric, the entire transition process is accomplished in the frequency domain. The pretraining step can facilitate the convergence of the subsequent training processes. After pretraining, ATM will be fine-tuned together with a multi-domain discriminator to progressively align different domains.

Random domain adversarial learning
The input images of ATM come from multiple source domains that have significant domain shifts, which our AFA method tries to eliminate in the frequency domain. Adversarial learning has proved its effectiveness in aligning two domains [50] using a binary domain discriminator. In our multi-domain case, we first introduce a multi-domain discriminator, which tries to classify images into different domains. The loss function can be defined as follows:

𝐿𝐷(𝐺,𝐷𝑑)=−∑𝑖=1𝑁𝐸𝑥𝑖∼𝑝data(𝑋𝑖)[log𝐷𝑖𝑑(𝐺(𝑥𝑖))],
(5)
where N is the number of domains, 𝑋𝑖 is the ith domain and its domain label is i, 𝐷𝑑 is the multi-domain discriminator and 𝐷𝑖𝑑(𝐺(𝑥𝑖)) represents the ith output. To train ATM, a naive implementation is to maximize 𝐿𝐷, known as a min-max game. The reversed gradients from the discriminator will drive the generated image away from the distribution of its original domain and close to the domain that has the highest gradient magnitude. Since the closer domain tends to have a higher gradient magnitude, this naive min-max training will cause the generated images to collapse to several domain cluster centers, which is against our expectation to align all the domains. To mitigate this issue, we propose a novel random domain adversarial learning (RDAL) strategy to gradually narrow the gaps among all the domains.

When adversarially updating the encoder-decoder by the gradients from the multi-domain discriminator, RDAL randomly samples a fake label for each image from the whole labels except for the real one. We utilize uniform sampling to balance among different domains. The loss function is defined as follows:

𝐿𝐺(𝐺,𝐷𝑑)=−∑𝑖=1𝑁𝐸𝑥𝑖∼𝑝data(𝑋𝑖),𝑗∼𝑝𝑖[log𝐷𝑗𝑑(𝐺(𝑥𝑖))],
(6)
𝑝𝑖(𝑗)={1/(𝑁−1)0𝑗≠𝑖𝑗=𝑖,
(7)
where j is the sampled fake label. Note that 𝑝𝑖 is not related to the number of images in different domains. In addition, the sampling process is performed on-the-fly, i.e.,, the fake label for each image is not fixed. Figure 4 illustrates the convergence process. If the distance between 𝑋𝑖 and 𝑋𝑗 is close, 𝐷𝑗𝑑(𝐺(𝑥𝑖)) tends to be high, then the loss and gradient magnitude will be low, which is opposite to the naive min-max training. Therefore, the accumulated gradient direction is toward the barycenter of all the domains’ distributions. Consequently, the distances among different distributions will be gradually reduced until convergence. Leveraging the RDAL strategy, adversarial learning can be well suited in the multi-domain case. It is capable of driving ATM to discover a common distribution, which is unbiased in terms of source domains. In this way, ATM is expected to be generalized well on unseen target images by transforming them into the common domain.

Fig. 4
figure 4
The convergence process of the proposed random domain adversarial learning strategy. A, B, C, D, E, and F represent the distributions of six different domains. The blue dotted lines with arrows represent the gradients of different fake labels of A, and the yellow dotted lines represent the accumulated gradients

Full size image
Overall training procedure
In our framework, iFFT is used to bridge the ATM module with the nodule classification network. Since adaptive transition and nodule classification are performed in the frequency and spatial domain, respectively, domain alignment and nodule-relevant feature extraction are decoupled. Therefore, the mutual interference between them can be avoided. The overall training consists of three components:

Domain alignment in the frequency domain. ATM is first pretrained using the fidelity discriminator and then alternately fine-tuned using the multi-domain discriminator and the fidelity discriminator. Guided by the two discriminators, ATM can discover a common frequency domain.

Feature extraction in the spatial domain. The features of nodules are more visually apparent in the spatial domain than the frequency domain. Besides, the spatial domain is more suitable for convolutional networks. So we extract the nodule features in the spatial domain. The loss function of the classification network is a simple binary cross-entropy.

End-to-end training. Since iFFT is differentiable, the gradients from the nodule classifier can be back-propagated to ATM, making the whole model end-to-end trainable. There are two benefits. Firstly, since ATM aligns CT images from different domains, it eases the feature extraction of downstream tasks. Secondly, gradients from the downstream task also help ATM to distinguish between domain-specific information and nodule-relevant information. Therefore, domain alignment and feature extraction can be mutually improved. The overall training process is detailed in Algorithm 1.

figure a
Experiments
Implementation details
The CT images were first clipped to [−1200, 600] Hounsfield Units (HU) to filter noises, and normalized by the mean and variance of the whole dataset. Then, all the CT images were interpolated into 0.78125 mm spacing for the axial, coronal, and sagittal direction. In the candidates generation stage, we adopted a 6-layer U-Net style network to segment candidate nodules. The resolution of the training patches is 40 × 40 × 40. In the false reduction stage, we cropped the 26 × 40 × 40 patches surrounding the segmented candidate nodules as the training data. Since the false nodules are much more than the true nodules, we used balanced sampling for each batch during training. Random shift and multi-scale were used for data augmentation.

The proposed domain generalization framework consists of four networks: an encoder-decoder in the ATM module, a fidelity discriminator, a multi-domain discriminator, and a classification network. The encoder-decoder is a shallow U-net including 6 stages, with two residual blocks [51] in each stage. Every convolution layer is followed by a batch normalization layer and a ReLU activation function. The fidelity discriminator, domain discriminator, and classification model are all based on Resnext [52] and detailed in Table 2. The fidelity discriminator and the classification model have the same architecture. Particularly, the last fully connected layer of the multi-domain discriminator is replaced by a convolution layer with a kernel size of 1× 1 × 1, making the network fully convolutional [53]. Thereby, the multi-domain discriminator will output a score map, whose element is corresponding to a patch in the image. Adversarial loss is applied to every element of the output map. We used Xavier initialization [54] and Adam optimization [55] for all the networks.

Table 2 Detailed architecture of the discriminators 𝐷𝑓, 𝐷𝑑 and the nodule classification model C
Full size table
During the pretraining of ATM, the initial learning rates of the fidelity discriminator and encoder-decoder are 0.001 and 0.01, respectively. Both networks were trained for 50 epochs with a batch-size of 64 and the learning rate was divided by 10 every 20 epochs. In the finetuning stage, we reset the learning rate of the fidelity discriminator and encoder-decoder as 0.0001 and 0.001, respectively. The initial learning rates of the multi-domain discriminator and classification network are both 0.01. The multi-domain discriminator and fidelity discriminator were trained alternately every epoch. The finetuning stage lasted 120 epochs, and all the learning rates were divided by 10 every 30 epochs. Our implementation was based on PyTorch.

Competition Performance Metric (CPM) [45] is the most popular metric used in pulmonary nodule detection tasks, which is defined as the average sensitivity at seven operating points of the Free Response Receiver Operating Characteristic (FROC) curve, i.e.,, 1/8, 1/4, 1/2, 1, 2, 4, and 8 False Positives per scan (FPs/scan). In this paper, we adopted CPM to evaluate all models.

Datasets
The experiments were conducted on the reorganized LUNA-DA dataset and our in-house dataset.

LUNA-DG dataset. LUNA16 [18] includes 888 CT scans from the LIDC-IDRI [46] database. Each CT scan was annotated by four experienced radiologists in a two-phase reading process. If a nodule was annotated by at least three radiologists, it was considered as a valid annotation. The nodules with a smaller diameter than 3 mm were also filtered out in LUNA16, as they are not relevant for lung cancer screening protocols [56]. After cleaning, there are 1,186 nodules in total in LUNA16. We traced back the CT scans in LUNA16 to LIDC-IDRI and figured out the meta information. We filtered out one scan that has no meta information. Then, we divided the CT scans into different domains according to their reconstructing convolution kernels. We selected the domains with fewer CT scans as target domains and the other domains were regarded as source domains. Both the source domains and target domains cover a wide range of slice thickness, from 0.625 to 2.5 mm, and other scanning parameters, so this division is univariate. The statistics of different data sets are summarized in Table 3. We also randomly selected some CT scans from the source domain as the separate source test set to evaluate the models’ performance on the source domain.

In-house dataset. We collected a larger in-house dataset from which several common domains were selected as source domains because they are more clinically accessible. Detailed information of the data sets is listed in Table 3. The target domain data are difficult to obtain, so the amount of scanning per target domain is much smaller than that of the source domain. The CT scans were annotated by three radiologists with more than 10 years of experience. And the nodules annotated by at least two radiologists were considered valid.

Table 3 Statistics of LUNA-DG and our in-house dataset
Full size table
Results of candidates generation
The results of the candidates generation stage are presented in Table 4. Our AFA method achieves high recall rates on all the test sets, which indicates that the domain shift issue has little impact on the first stage, as explained in Sect. 4.1. The mean recall rate of AFA on LUNA-DG is comparable to the result in the false positive reduction challenge track of LUNA16 [18], which achieves 0.979. Note that our method produced much fewer false positives. Besides, since the scans in LUNA16 are manually selected by radiologists, it is easier than our in-house dataset. So the number of false positives in our in-house dataset is more than LUNA-DG.

Table 4 Results of the candidates generation stage
Full size table
Comparison with other methods
We first conducted an experiment on the original LUNA16 dataset to evaluate the performance of the classification network. It achieved 0.923 CPM value with one model, and 0.941 CPM value after an ensemble of three models. The highest CPM value on the leaderboard is 0.951, so the network used in this work is competitive on the nodule detection task. Then we performed the domain generalization methods on LUNA-DG. Table 5 summarizes the results of different methods on LUNA-DG. The results for each target domain are not shown because the number of scans per target domain is too small to be convincing. We first trained a classification model by simply mixing all CT scans of the source domain as a strong baseline. We found that the CPM values of the source domains and target domains were similar. We suspect this is because the target domain data are easier than the randomly selected test data in the source domain. Then we implemented some representative methods [10,11,12, 20] to compare with our method.

Domain Adversarial Neural Networks (DANN) [10] aligns the feature distributions of two domains by a gradient reversal layer. MDAN [27] further modified it to a multiple source domain version. However, domain alignment and downstream task feature extraction in the same feature space might confuse the learning process, and it is difficult for the model to strike a balance between the two goals, e.g., the source domains’ result of MDAN gets a slight improvement, while the target domains’ result gets much lower than the baseline. Meta-Learning Domain Generalization (MLDG) [12] applies meta-learning to the domain generalization task. Since the meta-training phase requires a large number of tasks to train a robust model, the number of source domains will affect the performance of the model. There are only 8 source domains in the training dataset. Consequently, the results of MLDG on the source domains and target domains are both lower than the baseline. MMD-based adversarial autoencoder (MMD-AAE) [11] extends adversarial auto-encoders by imposing the Maximum Mean Discrepancy (MMD) measure to align different domains to a prior distribution. The prior distribution might not be suitable for the learning of downstream tasks, which will misguide the model, so the results of MMD-AAE also drop a lot. FDA [20] propose a data augmentation method in the frequency domain by swapping the low-frequency spectrum of the source domain and target domain. Here we adapt it to the DG setting by randomly swapping the low-frequency spectrum of arbitrary two source domains. Its results are lower than the baseline, implying that the frequency characteristics of CT images are more complicated than those of natural images and such simple augmentation can not bridge the domain gap.

Table 5 Results of different methods on LUNA-DG
Full size table
Computer-aided diagnosis systems should work well on all the domains, so we present the average results of the source domains and target domains. It is noteworthy that all the representative DG methods fail to surpass the baseline. Our AFA method, which is inspired by the CT imaging process, outperforms all the other methods including the baseline, on both the source domains and unseen target domains. The improvements on the target domains confirm that the proposed ATM and RDAL strategy are able to eliminate the domain shift in the frequency domain and make AFA generalize well in the unseen domains. After eliminating the domain shift, the downstream model can make full use of the data from different domains in the common frequency domain, so the performance of AFA on the source domains is also improved.

Table 6 Results of different methods on our in-house dataset
Full size table
We also compared different methods on our in-house dataset. The results are presented in Table 6. This dataset was collected from clinical scenarios and is more complex than LUAN16. For example, pneumonia and other lesions usually appear in this dataset. Therefore, the performance on this dataset is lower than that on LUNA16. Our in-house dataset includes 14 domains in the training set, which is more than LUNA16. Benefit from the more training domains, MLDG can sample more tasks in the meta-training stage, leading to a more robust model. Besides, as the number of domains increases, the distributions of the training domains become more and more dense, so mode collapse described in Sect. 4.3 is less likely to happen in the adversarial learning of MDAN. So MDAN and MLDG both achieve a higher CPM value than the baseline. Nevertheless, our method outperforms them on both the source domains and unseen target domains. Note that our method is the only one that outperforms the baseline on every target domain. Moreover, the performance gap between the source and target domains is reduced, indicating that the learned model has a strong generalization capacity. The results further demonstrate the effectiveness of the proposed method in dealing with the multi-source domain generalization problem.

The detailed recall rates at different operating points on the fROC curves of different methods are shown in Fig. 5. It can be found that the proposed AFA method has a higher recall rate than other methods at low false positive numbers, which indicates that, with the help of ATM, the classification model learns a better feature representation to discriminate between true nodules and false positives. This result benefits from the end-to-end training of our method, which encourages ATM to automatically discover a suitable common domain for the nodule classification task.

Since the proposed method introduces an ATM module before the classification model, we further evaluated the computation time on a single Tesla V100 GPU. The classification model took 8.6 ms, and the ATM module took 4.1 ms for each candidate nodule. Considering the first stage’s time cost, 532 ms, the proposed method took 25% more computation time. However, running in real-time is not required in clinical scenes, where radiologists usually read the CT scans a few hours after it is reconstructed. Thereby, computation time was not fully considered in this work. If the network structure was carefully devised, the time cost of the ATM could be reduced dramatically.

Fig. 5
figure 5
fROC curves of different methods on the target domains

Full size image
Ablation study
We investigated the effect of each component in our method on LUNA-DG, and the results are shown in Table 7. Similarly, the model trained by mixing the CT scans from multiple source domains is used as the baseline. At first, we added an encoder-decoder before the original backbone to study the impact of deepening the classification network. The results showed that the network depth does not affect the performance. Then, we added the fidelity discriminator and multi-domain discriminator for adversarial training. The encoder-decoder was trained in the spatial domain using the reversed gradients from the two discriminators. We found this network was difficult to converge. So we employed an extra perceptual loss [57] to guide the training process. The perceptual loss was calculated from the intermediate layer of a pre-trained MobileNet-V3 [58]. Although the network can converge, its performance is worse than the baseline. The result shows that aligning multiple domains in the spatial domain is difficult and will affect the learning of downstream tasks. Then, we aligned different domains in the frequency domain by using the proposed ATM. By learning an attention map for enhancing the amplitude spectrum and retaining the phase spectrum, the model could converge quickly and obtains significant performance gains in the source domains. However, the performance of the target domains improves only a little, indicating that domain gaps still exist after the naive min–max adversarial training. We replaced the naive implementation with the proposed RDAL strategy and consequently our AFA model obtains similar good performance on both the source and target domains.

Table 7 The ablation study results on LUNA16
Full size table
Visualization
To further analyze the impact of the proposed method on the nodule detection task, we visualize the attention maps and the transformed images in Fig. 6. Obviously, the original images from different domains have different noise patterns [5]. It can be seen from the learned attention map that the high-frequency components are weakened. Since noise belongs to high frequency components, therefore, the transition attention map has a denoising ability. The transformed images in Fig. 6 have a similar style, where the edges of nodules are sharpened, and the borders with the background become clearer. Besides, the transformed backgrounds in different images tend to have similar intensity values. Therefore, the transition process reduces the difference in appearance between different domains and enhances the distinction between the positive and negative samples. There is no doubt that learning in the transformed images facilitates the nodule classification task.

Fig. 6
figure 6
Images generated by the proposed method. Each row represents a different domain. The first column is the original image, the second column is the learned attention map and the last column is the transformed image. The nodules are surrounded by red rectangles

Full size image
Conclusion
In this paper, we propose a novel idea of aligning CT images in the frequency domain by adversarial learning. The proposed adversarial frequency alignment method can mitigate the domain shift issue in multi-source CT domains for domain generalized lung nodule detection. The adaptive transition module effectively aligns different images in the frequency domain by learning an adaptive attention map to filter domain-specific frequency information. The random domain adversarial learning strategy mitigates the mode collapse issue caused by the ineffective back-propagated gradient signals in the naive implementation, making adversarial learning more effective in the multi-domain setting. By bridging ATM and the down-stream module classification model together through a differentiable iFFT, the whole model can be trained end-to-end, where they are mutually improved. We also construct a new dataset named LUNA-DG by reorganizing LUNA16 for benchmarking domain generalization models. Experimental results on LUNA-DG and our in-house dataset show that our method can effectively eliminate domain shift and perform well on both source and unseen target domains. In the future, we plan to investigate more domain knowledge in CT imaging and clinical diagnosis to help devise more effective models and improve their generalization capabilities for various medical diagnosis tasks.

Keywords
Domain generalization
Lung nodule detection
Domain adaptation
Generative adversarial network