Water pollution is a widespread problem, with lakes, rivers, and oceans contaminated by an increasing amount of microplastics and other pollutants. Microplastic counting from microscope images is a laborious, time-consuming, and error-prone task. The ability of researchers to automate the detection and counting of microplastics would accelerate research and monitoring activities. This paper applies machine learning techniques to automatically segment and count microplastics in a given image, in challenging cluttered conditions. A U-Net neural network was trained to segment microplastics and image post-processing techniques were then applied to count the number of microplastics as well as highlight their position in an image. Different forms of skip connections from the U-Net encoder layers to decoder layers were tested to assess the impact of skip connections on the performance of the U-Net architecture. Our work shows that U-Net can achieve human-level performance in enumerating microplastics in cluttered images and that the standard skip-connection architecture is not necessarily optimal.

Introduction
Plastic pollution is a major global problem, with as much as 12.7 million tons of plastic waste entering the world’s oceans annually [1]. Recent attention has turned to microplastic pollution, due to increasing concern over its effects on organisms and human health [2]. Assessment of microplastic contamination levels in aquatic systems requires laboratory processing of samples. This processing involves manual counts of microplastic fragments using a microscope. This is time-consuming, laborious, and error-prone. Automating the process would negate these issues and facilitate the processing of greater numbers of samples, which is important for proper assessment of contamination levels. Thus, there is a pressing need to automate the process of counting microplastics.

A possible solution is to use machine learning techniques to detect and count the number of microplastics in a given microscope image, which could potentially be faster and more accurate than manual counting. However, the process of counting in such a cluttered environment could prove difficult even for the best neural network architectures, since, apart from complexity, clutter also leads to the issues of camouflage and occlusion, and is often associated with a greater diversity of backgrounds. According to [3], clutter is the “typically negative percept resulting from the disordered organization of an excessive number of objects”, where these objects, in our case, are particles present in microplastic samples such as sediments and organic material. In contrast, most counting problems in the literature have little to no clutter (e.g. red blood cell counting), and rarely have to also deal with camouflage, occlusion and diverse backgrounds, or the counting is done on the clutter itself (e.g. crowd density estimation). Our problem involves filtering out clutter and detecting microplastics in spite of camouflage, occlusion, and diverse backgrounds.

Our proposed solution was split into two parts. In the first part, a neural network performed semantic segmentation on raw microscope images (refer to Fig. 1a) to obtain segmentation masks (refer to Fig. 1b) indicating the location of microplastics. In the second part, image processing techniques were used to clean up the output masks generated by the neural network. This was then followed by counting and microplastic annotation in the microscope images. Several variants of the U-Net neural network architecture were subject to experimentation, focusing on the structure of skip connections, in order to assess whether the standard symmetrical design is optimal for the current application.

Fig. 1
figure 1
Example data: a raw microscope image, with b corresponding segmentation masks

Full size image
Although U-Net has been successfully applied to many segmentation and counting tasks, our application and associated dataset present specific problems which are still partially unresolved. In particular, the images in our dataset exhibit a significant proportion of sediments and organic matter acting as distractions while also camouflaging, and sometimes occluding, target microplastics. To the best of our knowledge, the current techniques in the literature have not yet been fully tested on microplastic counting problems with the extent of clutter, camouflage, occlusion, and background variation, typical in microplastic samples.

Our task involves counting sparse, camouflaged, and often occluded, objects in a cluttered and diverse background. The main contributions of our work are: (1) we present a new microplastics segmentation and counting dataset which is particularly challenging due to the presence of extreme clutter, (2) we demonstrate for the first time (to the best of our knowledge) that a standard U-Net architecture can learn to effectively segment microplastics in extremely cluttered environments (up to now microplastic segmentation and counting solutions have avoided conditions of extreme clutter), (3) we demonstrate that the above segmentation output combined with simple post-processing techniques can lead to human-level counting accuracy, (4) we experiment with several different U-Net designs, and propose a novel and effective reverse U-Net architecture, demonstrating that the standard U-Net skip-connection architecture is not necessarily a unique optimum in this domain, providing a rationale for future work on skip-connection optimization. The paper takes an empirical approach to model development, demonstrating a solution that can be directly applied to the real-world problem of microplastic counting, while demonstrating new avenues for research in U-Net skip-connection architectures.

The following section will provide an overview of several works closely related to ours, followed by a description of the methods and experimental design adopted; in turn, this is followed by a description and discussion of the results and a final conclusion.

Related works
Microplastic counting
Although the literature contains several examples of artificial intelligence solutions to the problem of counting microplastics, these examples tend to avoid the issues of extreme clutter and image diversity that typically characterizes samples collected from rivers and lakes. For instance, in [4], a system was developed for automating the characterization of beach microplastics through the application of image analysis. However, the images that were used had microplastics clearly separated from one another and did not exhibit any clutter. Although the techniques adopted were effective, they are likely to be restricted to controlled clutter-free conditions.

In a similar vein, the authors of [5] proposed a fibre instance detection pipeline, which applies problem decomposition to fibre detection and segmentation. The authors were able to detect well-separated instances through image processing techniques and succeeded in separating tangled fibres via deep pixel embeddings. However, their techniques used feature engineering and would not generalize well to our problem domain where clutter is significant.

The authors in [6] developed a solution that involves a distinctive preparatory step, where microplastics are extracted from a sample of water and are subsequently cleaned. As a result, microplastics are completely segregated. Again, this is different from our problem, since we have not implemented a separate cleaning stage, and therefore, we are trying to locate and count microplastics with severely cluttered backgrounds, whereas in [6], the authors are trying to classify microplastics by their types on an image where the microplastics are on a clean background.

Arguably, the work in [7] is more closely related to ours, since the authors also split the counting process into two tasks. The first task involves image segmentation with the U-Net architecture [8], followed by a second stage using a VGG16 [9] neural network that classifies the shapes of microplastics. While the paper obtained 98.11% accuracy on their dataset, there are several key differences between their dataset and ours, which make a direct comparison of our approaches impossible. Firstly, their images were taken using digital and smartphone cameras, while ours were taken using a microscope. Secondly, their sample images had significantly fewer sediments and clutter, with each piece of microplastic well-separated from other pieces. The dataset used in our research has much more clutter such as fragments of organic and inorganic material, with some microplastics overlapping each other, which forced us to take a more aggressive approach in terms of data augmentation and an exploration of alternative skip-connection architectures. Our use of only microscope images potentially makes the problem more consistent, but the clutter and presence of other material makes it more challenging.

Neural network architectures
U-Net [8] is a convolutional neural network architecture first developed for biomedical image segmentation. It uses an encoder–decoder architecture to perform semantic segmentation. Skip connections are used to concatenate the feature maps from encoder layers to corresponding decoder layers (as shown in Fig. 4). The skip-connection architecture provides spatial information to each decoder so that it can effectively recover fine-grained details when producing output masks. There is a lot of ongoing research on the U-Net architecture [10], and it is generally considered a strong solution for semantic segmentation. U-Net++ [11] is a nested version of U-Net [8] with re-designed skip connections and deep supervision. The encoder and decoder sub-networks are connected through a dense convolution block. It outperforms the original version of U-Net but is computationally more expensive due to the extra convolution operations.

MDUnet [12] is a multi-scale densely connected U-net applied to biomedical image segmentation. Three different architectural variants have been proposed. For any layer, neighbouring feature maps from both higher and lower layers of different scales are fused, in order to improve information flow.

Mask RCNN [13] is a deep neural network used for instance segmentation. Either a video or image can be provided as input. Mask RCNN performs instance segmentation in two stages. It first generates proposal regions where there might be an object based on the input image. The approach then predicts object class, fine-tunes bounding boxes and generates segmentation masks.

Feature Pyramid Networks for object detection were proposed in [14]. The approach takes an image as input, and outputs proportionally sized feature maps at multiple levels, in a fully convolutional fashion. It is a generic solution for building feature pyramids inside deep convolutional networks.

In [15], the authors discuss the possibility of using a new augmentation technique to synthesize more training data for counts that do not exist in the dataset. Their data augmentation technique combines two images with different cell counts by taking the maximum value of every pixel between the two images. While effective for cell counting, this technique will not work for images in our dataset as they have three colour channels instead of one, and have substantially more clutter, which frequently produces occlusion and camouflage.

In [16] the authors describe object counting on a much larger scale; they tackle a similar issue to ours, which is to perform counting when there is much clutter in the dataset. The paper proposes a model with four stages. The first stage is a truncated VGG16 [9] which serves as a feature extractor, followed by an attention module to highlight important features and filter background regions. The next stage is a scale pyramid module, which is followed by a deformable convolution layer. The overall architecture composed of these four stages is referred to as ASPD-Net. The paper attempts to tackle the problem of scale variation, background clutter and dataset scarcity, which are problems faced by this project.

A multi-branch convolution block called selective kernel convolution was proposed in [17], which consists of three operations: split, fuse, and select. These convolution blocks can be combined to form the full SKnet. The split operator splits the input into multiple paths with various kernel sizes, which correspond to different neuronal receptive field sizes. The fuse operator combines the information from multiple paths, which is then passed to the select operator which adaptively aggregates the feature maps of different sized kernels, resulting in a solution with dynamic receptive field sizes.

Match Feature U-Net [18] was built on the original U-Net [8] and SKNet [17]. The approach proposes a match operator which matches features in different branches of each selective kernel convolution block to allow for a more accurate selection of features. The paper also proposes the utilization of this new block to create a new U-Net architecture with a dynamic receptive field size.

A two-step approach for segmentation and counting for microscopy data was proposed in [19], where cell segments are first produced using a feature pyramid network, followed by a VGG16 style neural network for counting of cells in a given image. In a discussion of their failed cases, the authors mentioned the problem of high cell overlap and irregular cell shapes, which are both problems that are faced by this project.

It is evident that numerous techniques for microplastic segmentation and/or counting exist. We decided to focus on U-Net for segmentation since: (1) it has shown good performance in several diverse areas and it would be useful to test it on a microplastic domain characterized by extreme clutter and camouflage, (2) the architecture is simple and effective, even at moderate sizes, which means that the approach is accessible to a broader range of users, and (3) it still holds several open research questions, including the optimality and problem specificity of its skip-connection design; thus, there remains scope for further development.

Methodology
Data collection and preparation
For each sample, 2L of water were collected from the Langat River, Malaysia, and filtered through a 53 𝜇𝑚 mesh sieve. The contents of the sieve were then washed into glass sample bottles to be transported to the laboratory. Organic materials in the samples were digested with 0.02L each of 30% hydrogen peroxide and 0.05M iron (II) solution (catalyst). The samples were then vacuum-filtered through glass microfibre filter papers (1.2𝜇𝑚; Whatman GF/C) and oven-dried before observation.

Images of 16 parts of each dried filter paper were taken using a stereomicroscope at 35X magnification (Leica EZ4D) and the Leica Acquire software version 3.4.4. The microplastics in each image were then identified and enumerated through visual inspection by 2 trained professionals. Microplastics were distinguished by their colour and shape. Finally, all suspected microplastics were touched with a hot needle. Those that curled or melted when touched were confirmed as microplastic [20]. The microplastic count in each image was noted down in a spreadsheet, and an extra copy of each image was created for image segmentation.

Each identified microplastic was manually labelled on the extra copy of the image. Labelled pieces were highlighted on the image using the pencil tool in the GIMP editor for image segmentation. Different highlight colours were used to classify microplastics into film, fragments or fibre. The highlights were selected using the fuzzy select tool. Next, the background of the image was removed using the invert selection tool, leaving only the highlighted features on the image. Lastly, the processed images were exported in the Tag Image File Format (TIFF) for further processing. It is worth noting that the process above is a one-shot process implemented by the model building team and that, once deployed in the real world, the model can be used directly to segment and count images without any additional related work.

Synthetic data generator
Of the 4751 original (real) images selected for segmentation labelling, only 1141 contained microplastics. Moreover, most original images that contained microplastics only had one fragment, which meant that the neural network models had limited information to learn the features of microplastics. In preliminary experiments, this caused the networks to have a tendency to generate images without masks as default output. Data augmentation via artificial (or semi-artificial) training images can help counteract this problem, which is why we developed our own semi-synthetic data generator.

The synthetic data generator works by extracting microplastics from a set of original raw images, based on corresponding masks provided by human labellers, and then inserts these microplastics into other original raw images (that may contain other microplastics), at random locations and orientations. In parallel to creating a semi-synthetic image (input), the generator will also create a corresponding blank image with masks (i.e. output target). In this manner, synthetic images can be created with virtually any number of microplastics and in any spatial configuration. For example, in order to create a synthetic image with 10 microplastics, the generator might insert 6 different microplastics extracted from 3 other original images (e.g. 2 from each one), into another original image that already contains 4 microplastics. Figure 2 shows an example of a semi-synthetic image (left) with a corresponding target image with masks (right).

Fig. 2
figure 2
Example semi-synthetic data generation: a microscope image with artificially inserted microplastics, b corresponding image with segmentation masks

Full size image
U-Net
A PyTorch implementation of U-Net is available on GitHub [21]. This was adapted to fit the needs of this project. Hyperparameters such as the learning rate and learning rate scheduler were changed as the default values caused the network to overfit and did not generalize well, resulting in poor validation and test performance. Moreover, in the original implementation, ReLU was used as the activation function between convolution layers and was here changed to LeakyReLU to prevent the training from prematurely converging due to vanishing gradients.

The original U-Net implementation did not use any image transformations for data augmentation. Transformations are very powerful tools that can be used to increase the generalization performance of models. Simple horizontal and vertical flipping transformations were applied on the fly to every instance (probability of 0.5 for each transformation). The dataset was also normalized to its mean and standard deviation.

Originally, the convolution layers that were combined with batch normalization [22] did not disable the use of a bias term. This bias term on convolution layers is redundant since batch normalization already contains a bias term so it was removed to reduce the memory footprint of the network while reducing the number of parameters to be trained.

Transfer learning
The synthetic data generator is able to generate training data. However, the model is likely to fail on real data if trained only on synthetic data, as the latter may contain colour artefacts, may not represent the full diversity of microplastics, and may exhibit unnatural spatial distributions of fragments. To counter this problem, transfer learning was used. Transfer learning [23,24,25] is the process of improving the learning performance of a neural network by transferring knowledge from one network/domain to another. The task of counting microplastics generated by the synthetic data generator could be considered a very closely related domain to counting microplastics in real images.

Synthetic training data were first used to train a neural network, which allowed the neural network to learn the important features of microplastics and learn to filter out background clutter. After the network was pre-trained on synthetic data, the network weights were transferred to another network in order to be further trained on the real dataset.

Data engineering
The data used to train the images were in the form of image and mask pairs; the images were the microscope images, while the masks contained the ground truth location of the microplastics, as shown in Fig. 1. Since the resolution of training images was high, when used in conjunction with U-Net, this posed a memory issue, causing the training process to crash. Instead of downscaling, which would lead to crucial information loss, we sliced training images and masks into four and trained these separately. Since microplastic segmentation does not rely on the context of the whole image, this strategy worked effectively.

To maximize experimental throughput, the research was conducted on a subset of 272 images, which exhibited a good diversity of backgrounds and sufficient microplastics. From the 272 training images, 30 images were separated to be used as the test set. The remaining 242 images were split into four sections, for a total of 968 training images. A synthetic dataset was also generated from the above training images, leading to a total of 300 synthetic training images, where each was again split into four parts. Consequently, there was a total of 1200 synthetic training images. Thirty extra synthetic images were generated and used for testing. Figure 3 shows a summary of the datasets used.

Fig. 3
figure 3
Summary of datasets used, including real, synthetic, split, and flipped images

Full size image
Neural architectures
Architectural changes to the standard U-Net architecture were experimented on. In the original U-Net [8], the skip connections are symmetrical (see Fig. 4), where the decoder layer receives skip connections from the corresponding encoder layer. The symmetrical structure is sensible from the perspective of information recovery, but the design is not necessarily optimal for all applications, as our experiments show (refer to Sect. 4.6). To the best of our knowledge, so far, there is no significant research into the question of when this symmetrical structure is optimal.

Fig. 4
figure 4
Simplified representation of a standard U-Net architecture with symmetric skip connections

Full size image
In this work, two U-Net variants were proposed, neither using symmetrical skip connections. In one variant, shown in Fig. 5a, every decoder layer receives skip connections from all encoder layers. Unfortunately, this model was not feasible given the compute resources available, since the memory footprint of the network was too high. Therefore, a pruned variant of it was used, where instead of having every decoder layer receive skip connections from every encoder layer, the deeper decoder layers receive more skip connections than the shallower ones, as shown in Fig. 5b. The rationale is that over time information is lost from one layer to another. However, the information losses at the higher decoder layers would be more substantial than those at lower layers, so the former may benefit from additional skip connections.

Fig. 5
figure 5
U-Net architectural variations: a dense skip connections, b semi-dense skip connections, and c reverse skip connections

Full size image
The proposed architecture in Fig. 5b has a smaller memory footprint, although it still uses a relatively large number of skip connections. Ideally, we are trying to minimize the number of parameters in the network while trying to counter the problem of information loss at higher decoder layers. Therefore, an architecture, where the skip connections are reversed from the original U-Net was used, is shown in Fig. 5c. In this architecture, decoder 1 would receive skip connections from encoder 1, decoder 2 from encoder 2, and so on. The total number of layers that the skip connection has “skipped” from encoder 1 to decoder 1 would be 5, and this is true for every skip connection. The rationale behind this architecture is that information is lost as the input passes through many layers of convolutions. Since some of the skip connections are so long in the standard U-Net, for example, the skip connection from encoder 1 to decoder 5, arguably the information recovery from encoder 1 may not be as useful anymore when it reaches decoder 5. Having skip connections of the same length is an attempt to make information from every encoder layer equally useful when producing the output mask.

Image post-processing
Since during training each image is split into four, during inference, the same splitting process is applied. However, the output masks are subsequently stitched back together before proceeding with post-processing and counting.

Simple thresholding and morphological operations were used to clean up the output masks. An erosion operation was first applied to remove small noise artefacts. Then, a dilation operation with a bigger kernel size was applied to reverse the erosion that was applied as well as to connect any disconnected strands of microplastics together. To ease the work of environmental researchers, the resulting masks were then used to annotate the original image. Bright red segmentation masks and bounding boxes were added to the locations where microplastics were detected (refer to Fig. 8b for an example). In order to generate counts, simple blob counting was used with respect to segmentation masks (i.e. each segment was considered a blob, and a basic blob counting method was applied), which is equivalent to the number of bounding boxes added to the image.

Metrics
Three metrics were used to evaluate segmentation performance: Dice coefficient, precision, and recall. Recall has particular relevance in the context of microplastic identification, as a higher recall would indicate that the neural network is able to identify more microplastics, even if there are potentially more false positives. For many microplastic counting applications, the goal is to obtain a recall of 100% while minimizing false positives. For a human researcher checking the results of a counting system that places bounding boxes over detected microplastics, it is much easier/faster to reject a false positive than it is to correct a false negative. Unfortunately, precision and recall tend to go hand in hand. When a network scores a higher precision, it will tend to have a lower recall score and vice versa. Therefore, the dice coefficient is still the most useful performance metric as it takes into account both precision and recall.

Results
Baseline parameters
To obtain a baseline, the standard U-Net model was trained on the synthetic dataset. However, it was not able to effectively learn the dataset. After some experimentation with learning rates and the learning rate scheduler, the performance improved significantly (Table 1). For the baseline settings, a learning rate of 1e-4 was used, with PyTorch’s ReduceLROnPlateau scheduler using parameters: mode=max and patience=2. For the tuned settings, a learning rate of 1e-6 was used, with PyTorch’s StepLR scheduler, with parameters: step_size=4, and gamma=0.8. In addition, for all experiments, the weight decay and momentum were set to 1e-8 and 0.9, respectively.

Table 1 Model performance based on different learning rates and learning rate schedules
Full size table
Sample images were generated to observe the differences between the outputs generated from different hyperparameter settings. In Fig. 6, which can be classified as moderately cluttered and challenging, the baseline before tuning fails to identify all microplastics, whereas the tuned version was capable of detecting all microplastics. Many strands of microplastics in the former case (Fig. 6a) are disconnected, while in the latter case (Fig. 6b), most microplastic bounding boxes are fully intact.

Fig. 6
figure 6
Synthetically generated test image with bounding boxes around detected microplastics, based on the baseline model: a before tuning, and b after tuning

Full size image
Transformations performance
Data augmentation via spatial transformations is a well-known approach for improving the generalization performance of neural networks, which is particularly relevant when the number of training images is limited. After applying transformations and normalization to the dataset, an appreciable performance improvement was observed (Table 2). Although the precision is similar, it can be seen that the dice coefficient and recall are a step higher, which can tentatively be explained by the fact that the application of simple horizontal and vertical flips increases the number of configurations experienced by the network by a factor of 4, which decreases the probability of false negatives; in turn, this has a direct positive effect on recall.

Table 2 Transformation performance statistics
Full size table
Image scaling
Scaling down the training images is an easy way to increase the speed of model training. However, the performance of the network trained on half-scale images is slightly worse (see Table 3) when compared to networks trained on full-scale images. In addition, and assuming on-the-fly scaling, training at half-scale could actually impact training speed on platforms with limited CPU resources.

Table 3 Impact of image scale on performance
Full size table
Table 3 indicates that the half-scale condition leads to a noticeable drop in performance on the synthetic dataset, where the dice coefficient score and recall are lower. This is due to the fact that scaling results in the loss of information, so there might be some information missing when trying to reconstruct the full output mask.

Overall, this experiment suggests that for the purposes of segmenting microplastics, scaling is still important and final experimentation should be done on full-scale images to maximize performance. However, during prototyping, half-scale images may be used to decrease training time at a cost of a slight performance drop.

Transfer learning
The tests described above are related to the synthetic dataset. This section concerns two experiments focused on the real dataset. In the first, the neural network was trained from scratch on the real dataset. In the second, the neural network received pre-trained weights from a model trained on the synthetic dataset. Figure 7 and Table 4 summarize the performance of both models.

Fig. 7
figure 7
Results of training the model without pre-trained weights (green curve) versus with pre-trained weights (orange curve) after 30 epochs: a Dice Coefficient, b Precision, c Recall. Both models were trained on a learning rate of 1e-6. The model that did not receive pre-trained weights performed worse than the model that did receive pre-trained weights

Full size image
Table 4 Impact of pretraining on performance
Full size table
Precision is slightly better, whereas recall and the dice coefficient are significantly better, in the pre-trained condition (Table 4). The output generated by the neural network trained from scratch in Fig. 8a contains noise and many spurious detections, whereas in Fig. 8b, only the single target microplastic was detected. Both networks were able to identify the target microplastic, although in Fig. 8a the microplastic strand was divided into pieces, while in Fig. 8b, it was detected whole.

Fig. 8
figure 8
Test image extracted from the real dataset, where a is the output of the network trained from scratch (note the presence of false positives), and b is the output of the network which received pre-trained weights (note the absence of false positives)

Full size image
Impact of learning rate on performance
As given in Table 5, the learning rate used to train the neural network has a large impact on the ability of the network to learn. On the synthetic dataset, the performance when trained on a learning rate of 1e-5 exceeded the performance of 1e-6 by a clear margin, with the dice score, precision, and recall each around 0.9. On the real dataset, however, after transfer learning (Table 6), both networks perform similarly. Despite this similarity, training with a higher learning rate was beneficial since the model converged much faster than that with a lower learning rate.

Table 5 Effect of learning rate on the synthetic dataset
Full size table
Table 6 Effect of learning rate on the real dataset when using transfer learning
Full size table
Modified U-Net architectures
This section summarizes the evaluation of the semi-dense U-Net (Fig. 5b) and reverse U-Net (Fig. 5c) architectures described in Sect. 3.3.

The evaluation was first applied to the synthetic dataset. The performance across models was somewhat similar, with the reverse U-Net trailing behind slightly (Table 7). No clear inferences can be drawn about the performance of the models using only the synthetic dataset.

Table 7 Model performance on the synthetic dataset
Full size table
Regarding the real dataset, however the standard U-Net architecture was a significant improvement compared to semi-dense U-Net, with a higher dice coefficient score and recall (Table 8). Precision was similar between the two models. Conversely, the reverse U-Net had a higher dice coefficient score than the standard U-Net architecture. Although not depicted here, the reverse U-Net also exhibited increased training stability, with fewer sporadic score drops during training.

Table 8 Model performance on the real dataset
Full size table
Based on these experiments, the reverse U-Net appears to perform slightly better than the other two models, although these results are still restricted to segmentation performance. Further experiments were conducted to understand the actual counting performance of the models, as discussed in the following section.

Counting performance
The standard U-Net, semi-dense U-Net and reverse U-Net models were evaluated based on their counting performance on 30 randomly selected test images. The standard U-Net architecture produced the largest number of correctly counted images (i.e. 22 images), with the semi-dense U-Net and reverse U-Net trailing behind by a small margin (i.e. 20 images correctly counted), followed by human counters with an average of 18.5 correct counts (Table 9). For a more complete understanding of relative performances, we have also included the mean absolute error (MAE) and mean squared error (MSE) metrics, since these are sensitive to the degree of error in each count, particularly MSE. Table 9 highlights the best results in boldface, and the second best via an asterisk. From the table, it is clear that U-Net is the best performer across all metrics, reverse and semi-dense U-Net architectures are the second best in terms of number or proportion of correct counts; Human 2 is second best for both MAE and MSE. Overall, these results make it clear that U-Net architectures are perfectly capable of achieving (even slightly surpassing) human-level performance in counting microplastics in cluttered domains.

Table 9 Count performance metrics for different conditions: U—standard U-Net; SD—semi-dense U-Net; R—reverse U-Net; H1—human 1; H2—human 2; H-av—human average
Full size table
To illustrate how models can miscount, Fig. 9 gives an example test image with associated segmentation masks and bounding boxes. The semi-dense U-Net (Fig. 9c) correctly counted three microplastics, whereas the U-Net (Fig. 9b) and reverse U-Net (Fig. 9d) counted four microplastics. For the last two cases, the images need to be inspected carefully since the counts partly resulted from several very small bounding boxes, corresponding to noise or fragmented detections. Both the U-Net and reverse U-Net had trouble detecting the microplastic at the top of this test image. In spite of this, we can see small bounding boxes placed where the microplastic should be, so the models were able to find the microplastic. However, the models were uncertain about the detection, with segmentation values for parts of the microplastic below the blob detection threshold of 0.5.

Fig. 9
figure 9
Segmentation masks, bounding boxes and counts for an example test image based on different models: a Ground truth (three microplastics), b U-Net (four bounding boxes), c Semi-dense U-Net (three bounding boxes), and d Reverse U-Net (four bounding boxes)

Full size image
Different test images presented the models with different challenges (i.e. clutter, camouflage, occlusion) and novel microplastic characteristics (i.e. not present in the training set). Overall the reverse U-Net seems to be the architecture that can best handle difficult microplastics characterized by camouflage and occlusion. Some false positives were generated by all three models, incorrectly highlighting plant fragments that looked very similar to microplastics.

Discussion
With a few simple changes and hyperparameter tuning, the standard U-Net architecture proved a good solution for the segmentation of microplastics in difficult cluttered conditions. In spite of the complexity of the background clutter and its relative similarity with target microplastics, sufficient discriminatory information still exists to allow the model to recognize clutter as a category distinct from target microplastics, thus allowing clutter to be ignored. However, the model is still not able to fully solve the segmentation and counting problem, and this limitation is likely to require more than just additional training data, since our experiments have shown that the symmetrical skip-connection architecture of a standard U-Net may not necessarily be uniquely optimal for this particular application. The experiments showed that all three designs (i.e. standard, semi-dense, and reverse) were able to filter through most of the clutter, did not produce many background artefacts, and succeeded in detecting most microplastics.

From an inspection of the test image outputs, it is evident that a number of plant fragments were falsely classified as microplastics (Fig. 10). Given that plant fragments were a major source of false positives, future work could look into the explicit classification of both categories. This would help the models to properly learn the features distinguishing plant fragments and microplastics, instead of treating plant fragments as general background clutter. In a system incorporating this type of model, bounding boxes could be placed over microplastics and plant fragments, with a percentage indicating the model’s confidence with respect to the different classes. This would still save a lot of time for environmental researchers since they would only need to focus on bounding boxes to make final count decisions.

Fig. 10
figure 10
A plant fragment in a cluttered scene with microplastics

Full size image
When comparing the test output masks generated by all three models, it is evident that reverse U-Net was more aggressive in the detection of microplastics. This has its benefits for hard-to-detect (e.g. camouflaged) microplastics but leads to more false positives compared to U-Net and semi-dense U-Net. Further work should be done on other datasets to better understand whether, and if so why, this is an inherent property of reverse U-Net. Overall, all three models still performed well and were able to find the more obvious microplastics in the test images.

The post-processing techniques used for counting (after segmentation), corresponded to traditional low-level image processing, so the counting system does not have the ability to deal fully with complex detection cases (e.g. fragmented microplastics or artefacts). Another problem is that of overlapping microplastics. Although rarely, sometimes microplastics may overlap, causing the system to count two microplastics as one. One potential solution is to use another neural network such as VGG16 to perform counting over the segmentation outputs. A neural network may be able to learn the different shapes of microplastics and differentiate when a segmentation blob is background noise, or if two microplastics are overlapping, whereas traditional methods are not able to do this without heavy feature engineering. This has already been addressed by Hernández et al. [19] used a VGG16 network for counting [9]. Further work could be done to implement this technique for microplastic counting.

Three methodological issues remain. Firstly, it is difficult for the models to determine if a strand is a plant fragment or a microplastic, especially if the microplastic is brown in colour. This leads not only to a large number of false positives but also impacts the ability of the models to fully mask the locations of microplastics. Secondly, the neural network still has trouble finding microplastics with unique characteristics that are not part of the training data. This however may improve with more training data. Thirdly, the difficulties posed by clutter appear to originate not so much from the background complexity of images, but rather from the fact the clutter contributes significantly to camouflage and occlusion.

Our experiments have shown that it is possible to use a machine learning approach to automate the enumeration of microplastics in environmental samples. They indicate that it is possible to achieve counting accuracy equivalent to manual counting. This is significant from the perspective of monitoring contaminated water bodies, since confidence in assessment loads and health risks requires large enough sample sizes so that short-term variability, related for example to flow conditions, is factored into estimates of concentrations. For example, Chen et al. [26, 27] found that microplastic concentrations in the Sememyih river, Malaysia, varied significantly over a range of timescales, from hourly to daily to monthly; accordingly, one-off sampling is insufficient to arrive at robust estimates of loads. Automated processes, therefore, are of great utility, allowing both researchers and monitoring agencies to collect the numbers of samples required to yield representative data on concentrations and loads. As a side note, it is also worth mentioning that our current implementation, which has not been optimized in terms of speed, has an overall decision time that is slightly faster than the average human decision time we recorded, which was 13.3 seconds per image. Future versions can potentially improve accuracy beyond human-level performance, and decrease decision times even further.

This work would benefit from the following strands of investigation: (1) improving the synthetic data generator to output more naturalistic images, (2) increasing the amount and diversity of training data, (3) automatically learning the optimal skip-connection architecture via different neural architecture search techniques, (4) adding attention and/or dropout to skip connections, (5) training another neural network to perform the counting process over segmentation outputs, and (6) developing a web application to wrap the segmentation and counting modules in a user-friendly system.

Conclusion
Counting microplastics is a laborious, time-consuming, and error-prone task. To address this, a system was designed to automate the counting of microplastics, with the incorporation of automated segmentation (via machine learning) and image processing. Two variants of the standard U-Net architecture were proposed, incorporating new skip-connection ideas to allow better representation learning. Through experiments, it was shown that the standard symmetrical skip-connection structure of U-Net may not be the best design for all applications. A novel skip-connection design, termed reverse U-Net, was proposed with good performance characteristics and several advantages over the standard design. In general, the research showed that solutions based on the U-Net architecture are effective candidates for the segmentation of microplastics in cluttered backgrounds with camouflage and occlusion. These solutions, when combined with simple post-processing, result in automated microplastic counting at human performance levels, both in terms of accuracy and speed.

Keywords
Deep learning
U-Net
Microplastics
Segmentation
Counting