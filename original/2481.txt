This paper presents a novel convolutional layer, called perturbed convolution (PConv), which performs not only a convolution operation but also a dropout one. The PConv focuses on achieving two goals simultaneously: improving the generative adversarial network (GAN) performance and alleviating the memorization problem in which the discriminator memorizes all images from a given dataset as training progresses. In PConv, perturbed features are generated by randomly disturbing an input tensor before performing the convolution operation. This approach is simple but surprisingly effective. First, to produce a similar output even with the perturbed tensor, each layer in the discriminator should learn robust features having a small local Lipschitz value. Second, since the input tensor is randomly perturbed during the training procedure like the dropout in neural networks, the memorization problem could be alleviated. To show the generalization ability of the proposed method, we conducted extensive experiments with various loss functions and datasets including CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-ImageNet. The quantitative evaluations demonstrate that PConv effectively boosts the performance of GAN and conditional GAN in terms of Frechet inception distance (FID).

Introduction
Generative adversarial network (GAN) [7], which is based on convolutional neural networks (CNNs), have achieved rapid advancements in various applications such as image inpainting [30, 32, 43], image-to-image translation [3, 12, 52], and text-to-image translation [11, 28]. However, this great success still suffers from one major problem: instability in the training procedure [31]. Since a goal of GAN training is to find the Nash equilibrium of a non-convex game in a continuous and high-dimensional parameter space, GAN is substantially more complicated and difficult to train, compared to neural networks that are based on supervised learning [48]. To alleviate this problem, some researchers [2, 13, 46, 47] propose novel network architectures for discriminator and generator. Although these methods successfully generate high-resolution images on challenging datasets such as ImageNet [17], they still have the fundamental problem of the instability of GAN training.

Instead of modifying the network architecture, various studies [8, 16, 23, 25, 29, 48, 51] proposed normalization and regularization techniques that penalize the discriminator for alleviating the instability of GAN training. The most widely used normalization technique is spectral normalization [25], which imposes the Lipschitz constraint by dividing weight matrices of the discriminator with an approximation of their largest singular value. As a regularization, Gulrajani et al. [8] introduced the gradient regularization, called gradient penalty, which penalizes the gradient norm of straight lines between real and generated samples. Kodali et al. [16] proposed another form of gradient regularization which constrains the magnitude of the gradient as one around the real samples. Roth et al. [29] presented a stabilizing regularization technique that directly regularizes the squared gradient norm, where the gradient is calculated with respect to the real and generated samples. These normalization and regularization techniques are effective to improve the performance of GAN. However, some researchers [19, 48] pointed out that when both normalization and gradient-based regularization are used, the performance is either slightly improved or it fails to improve.

Recent studies [2, 49] argued that the memorization problem is another reason for the instability of the GAN training. As mentioned in [49], when the discriminator memorizes all images from a given dataset as training progresses, i.e. the memorization problem occurs, it disrupts the training dynamics and degrades a generated image quality. Brock et al. [2] observed that this severe problem has not only happened on small datasets; the memorization problem often occurs on large-scale datasets including ImageNet. To alleviate this problem, some researchers [14, 38, 49, 50] applied data augmentation techniques such as translation, zoom-in/out, and Cutout [5]. These approaches effectively prevent the memorization problem and improve GAN performance.

Despite the extensive ongoing efforts to develop the normalization, regularization, and data augmentation techniques, there are still some fundamental challenges. To the best of our knowledge, there are no previous works that attempt to develop a convolutional layer for alleviating these problems. In this paper, we propose the new form of the convolutional layer specialized for discriminator, called perturbed convolution (PConv). PConv contains a dropout layer with a special form, which effectively leads the discriminator to achieve two goals simultaneously: boosting the generative adversarial network (GAN) performance and moderating the memorization problem where the discriminator memorizes all images from a given dataset as the training progresses. The proposed method produces perturbed features by randomly disturbing an input tensor prior to performing the convolution operation. PConv is simple but surprisingly effective. First, to make similar output even with the perturbed tensor, each layer in the discriminator should learn robust features having a small local Lipschitz value. Second, when the input tensor is randomly perturbed during the training procedure like the dropout in neural networks, the memorization problem can be alleviated. By replacing the standard convolutional layer with the perturbed-convolutional layer, the proposed method can be easily applied to existing network architectures without imposing training overheads or additional computational cost. To demonstrate the generalization ability of the proposed method, we conducted series of experiments with various datasets including CIFAR-10, CelebA, CelebA-HQ, LSUN, and tiny-Image Net. The quantitative evaluations show that the proposed method significantly improves the performance of GAN and conditional GAN in terms of Frechet inception distance (FID).

In summary, our contributions of the study are summarized as follows. First, we propose a novel convolutional layer, i.e. PConv, which performs not only a convolution operation but also a dropout one. Second, the proposed method can be easily applied to the existing GAN without modifying the network architectures. Third, the proposed method significantly boosts the performance of GAN without training overhead or additional computational cost. Finally, we conducted extensive ablation studies to demonstrate the generalization ability of the proposed method. In various datasets and experimental settings, GAN with the proposed method shows a superior performance than GAN with the standard convolutional layer.

Fig. 1
figure 1
Overall framework of the proposed method. Contrary to the standard convolutional layer, the proposed method disturbs the input tensor before conducting the convolutional operation to produce the perturbed features

Full size image
Background
Generative adversarial network
In general, GAN [7] consists of generator G and discriminator D. In the original setting, both networks are trained simultaneously; nonetheless, their goals are different. G is optimized to produce visually appealing samples, whereas D is trained to distinguish the generated samples from real ones. This procedure can be summarized as the following objective functions:

ğ¿ğ·=âˆ’ğ¸ğ‘¥âˆ¼ğ‘ƒdata(ğ‘¥)[logğ·(ğ‘¥)]âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§(ğ‘§)[log(1âˆ’ğ·(ğº(ğ‘§)))],
(1)
ğ¿ğº=âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§(ğ‘§)[log(ğ·(ğº(ğ‘§)))],
(2)
where ğ¿ğ· and ğ¿ğº are the objective function for the discriminator and generator, respectively. In addition, z and x indicate a random noise vector and a real sample from the random normal distribution ğ‘ƒğ‘§(ğ‘§) and the data distribution ğ‘ƒdata(ğ‘¥), respectively. To improve the stability of the training process, several studies on the modification of the Eqs. (1) and (2) have been conducted. For instance, Mao et al. [22] applied the least square errors to the objective function (LSGAN), whereas Arjovsky et al. [1] computed the loss value by measuring the Wasserstein distance between the real and generated distributions (WGAN). Another commonly adopted GAN formulation is the hinge-version of adversarial loss [20], which is written as

ğ¿ğ·=ğ¸ğ‘¥âˆ¼ğ‘ƒğ‘‘ğ‘ğ‘¡ğ‘(ğ‘¥)[max(0,1âˆ’ğ·(ğ‘¥))]+ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§(ğ‘§)[max(0,1+ğ·(ğº(ğ‘§)))],
(3)
ğ¿ğº=âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§(ğ‘§)[ğ·(ğº(ğ‘§))].
(4)
The current widely used practice is to employ the hinge-version of adversarial loss while enforcing spectral normalization [25] either only on the discriminator or on both the discriminator and generator.

On the other hand, conditional GAN which focuses on producing the class conditional images has been actively researched [24, 25, 27, 45]. The conditional GAN usually employs conditional information c, e.g. class labels or text condition, to both generator and discriminator in order to control the data generation process. This procedure can be formulated as follows:

ğ¿ğ·=âˆ’ğ¸(ğ‘¥,ğ‘)âˆ¼ğ‘ƒdata(ğ‘¥)[logğ·(ğ‘¥,ğ‘)]âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§(ğ‘§),ğ‘âˆ¼ğ‘ƒdata(ğ‘¥)[log(1âˆ’ğ·(ğº(ğ‘§,ğ‘)))],
(5)
ğ¿ğº=âˆ’ğ¸ğ‘§âˆ¼ğ‘ƒğ‘§(ğ‘§),ğ‘âˆ¼ğ‘ƒdata(ğ‘¥)[log(ğ·(ğº(ğ‘§,ğ‘)))],
(6)
By training the networks based on Eqs. (5) and (6), the generator can select an image category to be generated, which is not possible when employing the GAN framework.

Memorization problem in the discriminator
To avoid the overfitting problem, deep learning models in various fields usually adopt label-preserving data augmentation techniques such as region masking [5], flipping, rotation, cropping [18, 39], data mixing [44], and local and affine distortions [33]. Inspired by these approaches, to moderate the memorization problem in the discriminator, some researchers [14, 38, 48,49,50] apply data augmentation techniques for training GAN. Particularly, Zhao et el. [49] conducted extensive experiments with various cases and demonstrated that data augmentation techniques are effective to avoid the memorization problem in the discriminator.

On the other hand, instead of using the data augmentation methods, Brock et al. [2] applied the dropout technique [34] to the last layer in the discriminator for alleviating the memorization problem. However, they argued that the traditional dropout strategy could alleviate the memorization problem; however, it degrades the performance of the GAN. In this paper, we also attempted to apply the conventional dropout-based approach for moderating the memorization problem, but we observed that the performance was drastically degraded when the dropout ratio was increased. These observations indicate that the conventional dropout techniques are not suitable to train the GAN.

Fig. 2
figure 2
Illustration of the GAN training results on eight 2D Gaussian mixture models. We have trained the networks two times to reveal the trend of the perturbed-convolutional layer module

Full size image
Proposed method
In this paper, we propose a novel convolutional layer, which not only moderates the memorization problem similar to dropout techniques but also effectively improves the performance of GAN. Figure 1 shows the overall framework of the proposed method. As depicted in Fig. 1, before conducting the convolutional operation, the proposed method randomly disturbs the input tensor by multiplying a random scaling mask M in which randomly selected channels have a random constant value ğ‘˜âˆˆ[0,1], others have one. In particular, M is built as follows: a tensor consisting of the constant value 1 is first produced. Then, such as the channel-selecting procedure in the dropout technique, some channels to be perturbed are randomly selected by a certain ratio ğœ†R. After that the selected channels are scaled down by multiplying the common k. By performing these simple procedures, we could build M that has k in the randomly selected channels, others have the value 1. Therefore, PConv with the input feature x can be defined as follows:

ğ‘¦ğ‘–=ğ‘“ğ‘–(ğ‘¥)=(ğ‘¥âŠ—ğ‘€)âˆ—ğ‘¤ğ‘–,
(7)
where ğ‘“ğ‘–(â‹…) and ğ‘¤ğ‘– indicate the i-th output value and convolutional kernel, respectively. Tensor broadcasting is included in Eq. (7) and different random scaling masks are employed to each intermediate layers. This masking operation is simple and meaningful for the discriminator. To classify real and generated images even if the input tensor is randomly perturbed, PConv should learn the robust features that do not have much effect on the subsequent convolutional layer. In other words, to minimize the adversarial loss successfully, |ğ‘“ğ‘–(ğ‘¥)âˆ’ğ‘“ğ‘–(ğ‘¥Ì‚ )| should become a small value, where ğ‘¥Ì‚  indicates the perturbed feature, i.e. ğ‘¥âŠ—ğ‘€. This indicates that ğ‘“ğ‘–(â‹…) should have a small local Lipschitz constant; if the Lipschitz constant of ğ‘“ğ‘–(â‹…) is large, the output of the discriminator will change a lot with small perturbations. Therefore, by simply replacing the standard convolutional layer with PConv, it is possible to lead the discriminator to learn robust features having a small local Lipschitz constant. Note that, PConv is not designed to constraint the global Lipschitz constant of the discriminator; it is designed to learn robust features in each layer.

To validate the effectiveness of the proposed method, we trained a GAN with a simple network architecture consisting of multiple fully-connected layers on eight two-dimensional (2D) Gaussian mixture models (GMMs). For a fair comparison, in the discriminator, we only replaced the fully-connected layers with the perturbed-fully-connected layers. Figure 2 illustrates the experimental results. As the training process continues, the GAN consisting of standard fully-connected layers suffers from the mode collapse problem, whereas the GAN with the perturbed-fully-connected layers learns all the GMMs successfully. These results indicate that the proposed method is superior to the standard convolutional layer in GAN training. More extensive experiments will be presented in the next section. The detailed implementation code for PConv based on Tensorflow is described in Fig. 3. We only need to build the random scaling mask before performing the convolutional layer. This means since PConv only contains a trivial multiplication operation that can be computed quickly, the proposed method does not incur training overhead; the multiplication operation is slightly compared to the convolution operation, thus we could argue that PConv does not impose the training overhead. In addition, since PConv is used for the discriminator, it does not affect the test phase that generates images from the generator.

Fig. 3
figure 3
Python code of perturbed-convolutional layer based on TensorFlow

Full size image
Indeed, one may anticipate that the PConv is similar to the conventional spatial-dropout (SDrop) method [36], which drops out the randomly selected channels of the input feature. However, there is a major difference between the proposed method and the conventional one: the existence of the random scaling value k. More specifically, SDrop sets the randomly selected channels to zero, whereas the proposed method scales down the features in those channels by multiplying k. This small difference has a large effect on GAN training. To prove the theoretical validity of this assumption, we will show an example. Let us consider x as an n-dimensional vector, i.e. ğ±={ğ‘¥1,â€¦,ğ‘¥ğ‘›}T where ğ‘¥1â‰¥â‹¯â‰¥ğ‘¥ğ‘›, and the output of the convolutional layer, i.e. y, is a single scalar value. This indicates that the convolutional layer contains a single kernel vector ğ°={ğ‘¤1,ğ‘¤2,â€¦,ğ‘¤ğ‘›}T. When the SDrop method is applied to this convolutional layer, the variation range of y, ğ›¥ğ‘¦ can be defined as follows:

ğTminğ°â‰¤ğ›¥ğ‘¦â‰¤ğTmaxğ°,
(8)
where ğmin and ğmax are the perturbed vectors which produce the minimum and maximum changes when they are projected onto w, respectively. For instance, when n is 10 and ğœ†R is set to 0.1, ğmin={ğ‘¥1,â€¦,ğ‘¥9,0} and ğmax={0,ğ‘¥2,â€¦,ğ‘¥10}. In contrast, when applying PConv, the range of ğ›¥ğ‘¦ becomes

0â‰¤ğ›¥ğ‘¦â‰¤ğTmaxğ°,
(9)
because ğmin is zero when the random scaling value is one. As described in Eqs. (8) and (9), the PConv can produce the output without variations, but SDrop is not. In other words, since there is at least ğTminğ° variant in the features, the discriminator using SDrop is difficult to produce the decision boundaries that guide the generator well. In addition, when the dropout ratio becomes large, the minimum boundary of ğ›¥ğ‘¦ is increased in the case of SDrop, but PConv does not change. Therefore, the proposed method is less sensitive to the dropout ratio, compared to SDrop.

Fig. 4
figure 4
Probability maps that represent the feature spaces when applying SDrop [36] and PConv. a SDrop [36] b PConv

Full size image
To reveal the effectiveness of the random scaling operation in PConv, we conducted toy examples that compare the output vectors of PConv and those of SDrop. In our experiments, we set the input feature ğ¯âˆˆâ„2 as {1,1} and scaled down the randomly selected channels. More specifically, we multiplied zero or the random constant value ğ‘˜âˆˆ[0,1] when producing the output vectors of SDrop or PConv, respectively. Figure 4 shows the probability maps representing the feature spaces that SDrop and PConv can cover. As depicted in Fig. 4, SDrop generates discrete vectors, i.e. {0,0},{0,1},{1,0}, which are confined to the corners of the plane, whereas PConv produces continuous vectors that handle the entire plane. Although ğTmaxğ° values of SDrop and PConv are the same, the covered feature space is different. Since the output vectors of PConv are perturbed smoothly, it is more effective to guide the generator than the SDrop.

Table 1 Network architecture of the generator for each image resolution
Full size table
Table 2 Network architecture of the discriminator for each image resolution
Full size table
Experiments
Implementation details
To show the generalization ability of PConv, we conducted extensive experiments using various datasets including CIFAR-10 [37], LSUN [42], CelebA [21], CelebA-HQ [13, 21], and tiny-ImageNet  [4, 40] (a subset of ImageNet [4]), consisting of the 200 selected classes. Among a large number of images in LSUN, we randomly selected 30,000 images per each class for training. This indicates that in this study, we built the LSUN dataset using 300,000 images. The images in the CelebA and LSUN datasets are resized to 64Ã—64 pixels, whereas the images in the tiny-ImageNet are resized to 128Ã—128 pixels. To evaluate the generation performance of high-resolution images, we utilized CelebA-HQ by resizing the images to 256Ã—256 and 512Ã—512 pixels. We employed the hinge-version loss in Eqs. (3) and (4) as the adversarial objective function.

Fig. 5
figure 5
Network architectures of ResBlock utilized in our experiments. In our experiments, we replaced the Conv in the discriminator with PConv: a ResBlock for the discriminator and b ResBlock for the generator

Full size image
Table 3 Comparison of the proposed method and SDrop on CIFAR-10 in terms of FID. The best results are marked in bold
Full size table
Since all the parameters in the generator and discriminator including (PConv) can be differentiated, we performed an optimization using the Adam optimizer [15], which is a stochastic optimization method with adaptive estimation of moments. We set the parameters of the Adam optimizer, i.e. ğ›½1 and ğ›½2, to 0 and 0.9, respectively, and we set the learning rate to 0.0002. During the last 50,000 iterations of the training, we decrease the learning rate linearly. Similar to the conventional methods [1, 8, 25, 26], each time we update the generator, the discriminator was updated five times using different mini-batches. For the CIFAR-10, CelebA, and LSUN datasets, we set the batch size to 64 and trained the generator for 50k, 100k, and 100k iterations, respectively. In addition, for the CelebA-HQ and tiny-ImageNet, we trained the network 100k and 450k iterations with 16 and 32 batch sizes, respectively. It is worth noting that we trained the generator with a batch size twice as large as that of the discriminator. For instance, on the CIFAR-10 dataset, we trained the discriminator with a batch size of 64, whereas the generator was trained with a batch size of 128. The proposed method contains a single hyper-parameter ğœ†R which determines how many channels are scaled randomly during the training procedure. How we determined ğœ†R value will be described in Sect. 4.3. Note that, we perturbed the discriminator features when training the not only discriminator but also generator. More specifically, the generator is trained to synthesize images having features that are used to classify the real and generated images in the discriminator. Thus, if the features used to classify the images are different from the features used for training the generator, the adversarial learning becomes unstable. In other words, the features used to train the discriminator and generator should be the same.

In this paper, we employed the generator and discriminator architectures consisting of multiple residual blocks [9] as our baseline models [25, 26, 41]. The detailed network architectures for the generator and discriminator are presented in Tables 1 and  2, where ResBlock architectures are described in Fig. 5. In the discriminator, we utilized the spectral normalization [25] for each layers. The discriminator down-samples the feature maps using the average pooling after the second convolutional layer by using the average pooling, whereas up-sampling (a nearest-neighbor interpolation) is performed before the first convolutional layer in the generator.

Performance evaluation metric
To evaluate how well the generator produces the image, we employed the most popular assessments called Frechet inception distance (FID) [10]. This metric measures the visual appearance and diversity of the generated images using the Wasserstein distance between the distributions of the real and generated images in the feature space obtained by the Inception model [35]. The FID can be expressed as follows:

FID(ğ‘,ğ‘)=â€–ğœ‡ğ‘âˆ’ğœ‡ğ‘â€–22+trace(ğ¶ğ‘+ğ¶ğ‘âˆ’2(ğ¶ğ‘ğ¶ğ‘)1/2),
(10)
where {ğœ‡ğ‘,ğ¶ğ‘} and {ğœ‡ğ‘,ğ¶ğ‘} are the mean and covariance of the samples with the distributions of the real and generated images, respectively. Lower FID scores mean better quality of the generated images. To measure the performance using the FID, in this paper, we generated 50,000 images for CIFAR-10, LSUN, CelebA, and tiny-ImageNet and 30,000 images for Celeb-HQ.

Table 4 Comparison of the standard convolution, SDrop, and PConv on CIFAR-10 in terms of classification accuracy
Full size table
Table 5 Comparison of the FID scores in different sizes of the datasets on CIFAR-10. The best results are marked in bold
Full size table
Quantitative comparison
Before evaluating the performance of PConv on the various datasets, we first present the ablation studies on the CIFAR-10 dataset. We trained the network three times from the scratch to show that the performance gain was not due to the lucky weight initialization. First, we discuss the difference between the proposed method and SDrop [36]. As shown in Table 3, SDrop shows poor performance compared to the proposed method. In particular, the proposed method shows a stable performance, even with an increasing value of ğœ†R. In contrast, the performance of SDrop is drastically degraded when ğœ†R value becomes large. To make our results more reliable, we conducted additional experiments that randomly changed the ğœ†R of SDrop during the training procedure. This indicates that we verified whether SDrop shows fine performance when ğmin in Eq. (8) is zero. In order to statistically match the dropout ratio with other experiments, we randomly changed ğœ†R in the range [ğœ†Râˆ’0.1, ğœ†R+0.1]. For instance, when ğœ†R is set to 0.1, the statistical dropout ratio is 0.1, whereas ğmin becomes zero. As described in Table 3, SDrop with random dropout ratio (we denoted it as SDrop*) shows a similar trend with SDrop. Although ğmin becomes zero, SDrop* still converts the randomly selected channels as zero, which disturbs the adversarial learning.

Table 6 Comparison of FID scores in different loss settings on CIFAR-10. The best results are marked in bold
Full size table
Indeed, as depicted in Fig. 5, SDrop produces discrete vectors since it turned on or off the all values in the selected dropping channels, i.e. Bernoulli dropout. However, this problem could be mitigated by using the Gaussian dropout which perturbs the features by multiplying the scaling values sampled from ğ‘âˆ¼(1,ğ‘(1âˆ’ğ‘)) distribution. This indicates that the SDrop with Gaussian dropout could cover the entire feature space like PConv. Thus, we measured the GAN performance when using SDrop with Gaussian dropout (we denoted it as SDropâ€ ). As described in Table 3, SDropâ€  is more stable than SDrop even though ğœ†R becomes large. These results reveal that in order to train GAN stably, it is necessary to cover the entire feature space continuously. Although SDropâ€  shows fine performance, the proposed method still outperforms the SDrop-based approaches. Based on these results, we concluded that PConv is more effective to boost the GAN performance compared to SDrop-based approaches. Since the performance of PConv is not significantly different when ğœ†R=0.1 and ğœ†R=0.2, in the rest of this paper, we conducted other experiments by setting ğœ†R as 0.1.

Table 7 Comparison of the proposed method with the standard convolutional layer on CIFAR-10, CelebA, LSUN, and tiny-ImageNet in terms of FID. The best results are marked in bold
Full size table
Furthermore, we investigated whether PConv would alleviate the discriminator memorization problem. To verify whether the overfitting problem has occurred, the conventional image classification techniques generally measure the classification accuracy gap between the training and test sets. Therefore, a large gap in the classification accuracy is considered a more serious overfitting problem. Based on these approaches, we divided the CIFAR-10 dataset into the training and test sets, which contain 40,000 and 10,000 images, respectively. Thereafter, we trained a GAN using the training set as real samples. After completing the adversarial learning, we counted the number of images for which the discriminator outputs a value greater than zero because the discriminator was trained using the hinge-version of the adversarial loss [20]. As shown in Table 4, the proposed method exhibits a lower accuracy gap between the training and test sets, compared with the standard convolutional layer. These observations indicate that PConv effectively alleviates the memorization problem in the discriminator. Although the SDrop moderates the memorization problem better than the proposed method, it is not effective for the adversarial learning as shown in Table 3. Thus, as mentioned in [2], the conventional dropout techniques can effectively moderate the memorization problem; however, they often degrade the performance of GAN. Since the main goal is not only to alleviate the memorization problem but also boost the GAN performance, PConv is more suitable.

To further show the effectiveness of the proposed method, we trained the network using only the half or quarter number of images on the CIFAR-10 dataset. As shown in Table 5, the performance of the network using the standard convolutional layer is degraded when the number of training images becomes smaller. In contrast, the network trained with the proposed method achieves a better performance since PConv can moderate the memorization problem. Here, one may anticipate that the data augmentation (DA) techniques could alleviate the memorization problem. To clarify the superiority of PConv, we compared the performance of PConv against that of the standard convolution trained with DA. In our experiments, following the previous paper [49], we built the augmented data using Translation (with in [âˆ’1/8, 1/8] of the image size, padded with zero) and Cutout [5] (making with a random square of half image size) techniques. As described in 5, the DA techniques improve the GAN performance, especially for training the GAN with a small number of real images, but they show weak performance compared with PConv. This means that the proposed method is suitable to train GAN using a small number of real images.

In addition, to demonstrate the generalization ability of the proposed method, we trained the networks using various adversarial loss functions. In this paper, we conducted additional experiments using two different loss functions: the loss function based on the cross-entropy (CE) theorem [Eqs. (1) and (2)] and the loss function proposed in the least square GAN (LSGAN) paper [22]. As shown in Table 6, even with the various loss functions, the proposed method still has a superior performance, compared to the standard convolutional layer. These results reveal that the proposed method can be easily applied to the GAN without considering the experimental settings such as the adversarial loss function.

Fig. 6
figure 6
Generated images with 512Ã—512 and 256Ã—256 resolutions on the Celeb-HQ dataset

Full size image
Extensive experimental results on various datasets are summarized in Table 7. First, in the GAN scheme, the proposed method shows a superior performance than the standard convolutional layer. In particular, on the LSUN and tiny-ImageNet datasets containing complex images that are difficult to generate, the proposed method significantly improves the generator performance. These results indicate that even with spectral normalization, the discriminator using the standard convolution layer is struggle to learn robust features which are effective to guide the generator. By simply replacing the standard convolutional layer with the proposed method, we achieved a higher performance in the various datasets. The proposed method shows a slightly better performance than the standard convolutional layer on the CelebA dataset. Because low-resolution face images are easy to generate using the conventional techniques, it is difficult to further enhance the performance. However, when generating the high-resolution face images, the proposed method exhibits significantly superior performance than the conventional one. We will present the experimental results related to the high-resolution images later.

We conducted more experiments to validate the effectiveness of the proposed method in the conditional GAN scheme. Therefore, following the most representative conditional GAN scheme, we replaced the BN in the generator with the conditional BN layer [6] and added the conditional projection layer in the discriminator. Note that, network architectures are the same as the models used for the experiments of GAN. As described in Table 7, similar to the trend of experimental results of GAN, the proposed method exhibits a superior performance, compared to the conventional method [26]. These results indicate that the proposed method can be applied to the conditional GAN scheme to boost the performance.

To show the effectiveness of the proposed method for generating high-resolution images, we conducted additional experiments using the CelebA-HQ dataset. In our experiments, the networks were trained to produce 256Ã—256 and 512Ã—512 images. The experimental results are presented in Table 8 and Fig. 6. The proposed method shows significantly low FID scores, compared to the standard convolutional layer, and it produces visually pleasing images. These results demonstrate that the proposed method is also effective in generating high-resolution images. Indeed, this study does not intend to produce the design of an optimal generator and discriminator architectures for PConv. There can be another network architecture that improves the performance and generates more visually pleasing images. This paper focuses on verifying whether it is possible to achieve better performance by simply replacing the standard convolutions with PConv.

Table 8 Comparison of the proposed method and the standard convolutional layer on CelebA-HQ in terms of FID. The best results are marked in bold
Full size table
Conclusion and future work
This paper has introduced a straightforward technique for boosting the performance of GAN. By simply replacing the standard convolutional layer with PConv, the discriminator is able to effectively guide the generator, which results in performance improvement of the generator. The main advantage of the proposed method is that it can be easily applied to the existing discriminator networks without imposing the training overhead, while significantly improving the performance. Furthermore, this paper shows the generalization ability of PConv in various aspects through high-resolution image generation and several ablation studies. Therefore, we expect that PConv can be applicable to various GAN-based applications.

Indeed, our manuscript focuses on introducing a novel approach specialized to the generative adversarial network (GAN). We agree that the perturbation procedure in PConv might work well for the discriminator, but might cause some issues in other networks used for different applications. Although our manuscript only covers the GAN, we have shown that the proposed method could improve the GAN performance significantly with various aspects. Thus, we expected that PConv could be effectively used for GAN-based diverse applications such as image-to-image translation. As our future work, we plan to further investigate a novel perturbation skill that covers various applications.

Keywords
Generative adversarial network
Perturbed convolutional layer
Adversarial learning
Dropout