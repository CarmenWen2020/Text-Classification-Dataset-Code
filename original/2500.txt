Recently, the reciprocal recommendation, especially for online dating applications, has attracted increasing research attention. Different from the conventional recommendation problems, the reciprocal recommendation aims to simultaneously best match usersâ€™ mutual interests to make the recommendations. However, the most existing RRS algorithms seldom model usersâ€™ interest and attractiveness simultaneously under the high-dimensional feature space. Furthermore, the sparsity of reciprocal relations seriously deteriorates the recommendation performance. Thus, we propose a novel Deep Contrast Reciprocal Recommender System (DCRS) to address the aforementioned research issues. Particularly, we resolve the sparsity issue by introducing the reciprocal neighbors to increase the number of possible reciprocal relations. Then, a novel deep contrast neural network is then proposed to model the mutual interest by contrasting between the reciprocal and non-reciprocal relations. As a result, it was able to better identify the reciprocal relations for the latter recommendation. Extensive experiments have been evaluated on two real-world datasets, and the promising results demonstrate that the proposed DCRS is superior to both baseline and the state-of-the-art approaches.

Introduction
Different from the conventional recommender system targeting at recommending items (e.g., movies and products) to users, reciprocal recommender system (RRS) tries to make reciprocal recommendations between users. Among these reciprocal applications, online dating is one of the most popular ones with the purpose of best matching users who are mutually interested in each other. Apparently, this task is more challenging than the conventional recommendation task. For the conventional recommender system, it focuses on recommending items that are of the most interest to the user. However, for the RRS problem, a successful recommendation should well consider the bi-directional interests but not merely the interest of the service user. This means that the service user (or the receiver) is more likely to proactively send messages to the target users (or recommended users) recommended by the platform. Meanwhile, the target user is highly possible to reply the messages sent by the service user [15].

By considering the bi-directional interests, the reciprocal recommender system differentiates itself from the conventional recommender systems [12, 17, 19] from the following perspectives. First, the bi-directinal interests could not be simply decomposed as a two-stage conventional recommendation problem. Although there exist some related approaches resolving this issue from this perspective, it is believed that such decomposition might result in the information loss caused by decoupling the correlations between the reciprocal users. While a RRS model that models such correlations under a unified framework is desired to achieve better reciprocal recommendation results. Second, different kinds of user behaviors, e.g., â€œsend messageâ€ or â€œreply messageâ€ in RRS, contain different levels of implicit preferences of a user, and thus they should be used to discover the interests or attractiveness for recommendation. Third but not the least, the sparsity issue in the RRS problem is a serious issue due to following reasons. In a typical RRS application, users might send or receive a good number of messages, but they only reply few messages, which makes the reciprocal relations (edges) very sparse. Moreover, they might leave these online dating applications after a successful matching, thus the corresponding graph data become extremely sparse.

Recently, a few RRS algorithms have been proposed in the literature by considering the mutual interests between the service and target users [15, 28, 29, 42]. For instance, [28] models the mutual interests using the similarity calculated in a pair-wised manner between the target usersâ€™ attributes and the service userâ€™s interest. Alternative to usersâ€™ attributes, [42] proposes a collaborative filtering approach which models users interest or attractiveness using their interactive behaviors (e.g, send and reply behavior). [15] proposes a deep learning-based method which converts this RRS problem to the task of predicting the probability that the target user might reply the messages. However, the aforementioned research challenges are not fully addressed by these prior research attempts.

To address these research challenges, in this paper, we propose a novel Deep Contrast Reciprocal Recommender System (DCRS) for online dating. Specifically, we model the online dating data as a bipartite graph and define four kinds of relations based on our previous observations to well reflect the interest and attractiveness of users. To solve the sparsity problem of reciprocal relations, we first propose a reciprocal user embedding component that embeds each user into a hidden space. Then, by measuring the similarity in hidden space, we introduce the reciprocal neighbors to increase the number of possible reciprocal relations to facilitate model optimization. Finally, inspired by the popular contrast learning [18, 39], we propose a novel deep contrast neural network that contrasts the reciprocal relations with the non-reciprocal ones. This can help the model better identify the reciprocal relations for recommendation via integrating both the user attributes and behaviors information. The proposed DCRS approach recommends the top N users to a service user, i.e., the top N pairs of users, and with them a reciprocal relation is more likely to be generated. Extensive experiments have been evaluated on two real-world datasets extracted from the most popular online dating platforms, respectively. The experimental results demonstrate the superiority of the proposed approach. To summarize, our major contributions are as follows:

We propose a novel reciprocal user embedding technique that represents the usersâ€™ interest and attractiveness in an hidden space. Besides, the reciprocal neighbor is introduced to alleviate the sparsity issue of reciprocal relations widely occurred in RRS.

We propose a Deep Contrast Reciprocal Recommender System (DCRS) which simultaneously considers the usersâ€™ attributes and behaviors. Meanwhile, the reciprocal relations are captured for recommendation by contrasting with the non-reciprocal ones.

Extensive experiments have been evaluated on two real-world datasets. The promising experimental results demonstrate that our proposed approach is superior to both the baseline models as well as the state-of-the-art approaches w.r.t. number of evaluation criteria.

The rest of this paper is organized as follows. Section 2 reviews the related work, and the proposed approach is detailed in Sect. 3. We evaluate the proposed approach as well as other baseline models and report the experimental results in Sects. 4, and  5 concludes the paper.

Table 1 Representative RRS methods in online dating
Full size table
Related work
The recommender system has long been investigated in the literature. With the surge of web-scale social applications such as online dating, the reciprocal recommender system has attracted more and more research attentions. In this section, we first review the most related RRS techniques. As shown in Table 1, it can be roughly categorized into two categories, i.e., content-based and collaborative filtering-based approaches. Then, we briefly introduce the latest research attempts by employing graph representation learning and contrast learning techniques for recommendation.

Content-based RRS
The content-based recommender system has long been investigated for various recommendation tasks [44, 46, 47, 49]. Recently, researchers have proposed several content-based RRS approaches. RECON, proposed in [28], is the first one to consider the reciprocal recommendation for online dating problems. It carefully measures the mutual interests between service users and target users. Particularly, the authors design an attribute-based method which calculates the reciprocal scores for all possible matching pairs of users. However, this approach only considers usersâ€™ attributes but not their behaviors. Similar to RECON, [36] also emploied the social media profiles of reciprocal users to generate explainable recommendations for online dating users. [1] proposed a Markov model-based approach to analyze usersâ€™ historical behavior data to predict whether a reciprocal edge exists or not. Similarly, [38] adopted a LDA model to learn usersâ€™ preferences from their behaviors as well as their profile data. [21] proposed a novel random CNN component to extract the connection between usersâ€™ attributes. This could be used to infer the likeness and disgust between users for online dating. In addition, [1] utilized the graph embedding technique to embed each user for the reciprocal recommendation.

Collaborative filtering-based RRS
The collaborative filtering-based approach [48, 50] generally considers the similarity between users to make recommendations. [5,6,7] predicted the existence of the reciprocal edges by measuring the interest and attractiveness similarity between reciprocal users. The proposed approach by [42] computed the reciprocal scores by using not only the similarities between usersâ€™ attributes but also the similarities of mutual interest and attractiveness between the users and their neighbors. In their work, the interest and attractiveness similarity of a pair of users is calculated as the number of common neighbors who have been proactively approached by service and target users. [15] proposed a hybrid model which employs a deep neural network model to predict the probability that the target user is interested in the service user. They first sum the similarity scores between the service user and all other users who are interested in the target user. Then, the features of both service user and target user are concatenated as the input for the proposed deep learning model. The output of the DNN model is to predict the probability that the target users will reply the messages of the service user. [25, 37] emploied the latent factor model to capture userâ€™s preferences to make reciprocal recommendations. More related works on RRS task could be found in [26].

Graph representation learning for recommendation
With the advance of graph representation learning techniques [11, 27], there exists another line of research efforts which directly explore social relations from the graph to make recommendations [33, 35]. One common assumption of these approaches is that usersâ€™ preferences are susceptible to their cliques (nearest neighbors) which is theoretically supported by social correlation theory [22, 23]. Particularly, Graph Neural Network (GNN) has demonstrated its superior ability to represent graph structural data [4, 9, 40, 43]. Consequently, research attempts have been made toward customizing various GNNs to solve this recommendation problem. In [45], the authors proposed a random walk-based approach to sample neighboring nodes, which are then embedded with feature of the service node. Then, the learned embedding is used to make recommendation. [10] proposed to learn the representations of users and items based on their social relations that are implicitly contained in the extracted social graphs. [20] proposed a motif-guided graph neural network to capture the preference representation of user from graph. Then, it utilized the user representation learned by the proposed MotifGNN to perform reciprocal recommendation for online dating.

Contrast learning
The contrast learning techniques [2, 8, 13] are originally proposed in the domain of computer vision to minimize the distance between positive pairs and maximize the distance between negative pairs simultaneously. Then, contrast learning techniques have been adapted to recommendation task to better preserve userâ€™s preferences. For example, [16] contrasted the image-user distance between positive pairs and negative pairs to learn the usersâ€™ preference. The merit of contrast learning lies in that it needs less labeled data than other techniques and thus optimizes the model in a self-learning manner. Apparently, the contrast learning well suits for resolving the sparsity issue in the RRS problem. Inspiring by this, we propose this novel deep contrast reciprocal recommender system approach for online dating recommendations.

The proposed approach
We detail the proposed approach in this section. First, we define four kinds of relations based on our previous investigations. Then, we introduce how the users are embedded using the defined four kinds of relations. Last, we propose the Deep Contrast Reciprocal Recommender System (DCRS) to integrate the graph structural information as well as user feature embedding to make the reciprocal recommendation.

User interactive relation
For a reciprocal recommendation system, it is desired to pay more attention to capture the bi-directional interest between service and target user. Such interest could be modeled via the â€œSENDâ€ and â€œREPLYâ€ relations. The â€œSENDâ€ relation in online dating applications often denotes behaviors such as send messages and click event. The â€œREPLYâ€ relation could be represented by reply messages or become a couple.

Such â€œSENDâ€ or â€œREPLYâ€ action could be represented by a directional edge in a corresponding graph ğº=(ğ‘‰,ğ¸). In this graph, we assume that each user ğ‘¢âˆˆğ‘‰ is either male or female. Users as well as their interaction relations ğ‘’âˆˆğ¸ form a large and sparse bipartite graph. In this graph, the combination of these directional edges represent rich relationships among users. Thus, we define four kinds of relations between service and target users as plotted in Fig. 1.

1.
Mutual Interest Relation: R. The mutual interest relation, denoted as R, refers to the situation that the service user has sent messages to and replied by the target user. It represents the mutual interest between the service and target user.

2.
Neighbor Mutual Interest Relation: ğ‘…â€². The neighbor mutual interest relation, denoted as ğ‘…â€², refers to the situation that there exists a mutual interest relation for the reciprocal neighbors of a service user.

3.
Proactive Relation: U. The proactive relation, denoted as U, means that a service user proactively send messages to target users, but the target user does not reply the message. It hints that the target user is not interested in the service user, and thus the algorithm should not recommend this target user to the service user.

4.
Passive Relation: ğ‘ˆâ€². The passive relation, denoted as ğ‘ˆâ€², refers to the situation that target user sends message to service users without response. This implies that the target user should not be recommended to the service user.

Fig. 1
figure 1
Four relations defined for online dating data

Full size image
For brevity reason, we use the following notations to represent each kind of relation in the following paragraphs. The relation R models the mutual interest between the service and the target user and is the basic relationship to make reciprocal recommendations. It is desired to recommend such target users in R to the service user. However, R-type data are very sparse in real-world applications. Thus, it poses a great challenge to RRS to identify the mutual interest relation for recommendation. To cope with this issue, ğ‘…â€²-type data (neighbor mutual interest relation) are introduced to augment the possible reciprocal relations. The assumption, inspired by the basic idea of collaborative filtering [31], is that if two users are similar to each other, the target users in ğ‘…â€² relation might also form a reciprocal relationship with the service user. Thus, we denote these similar users as reciprocal neighbors in our settings, and we will introduce the way of finding possible reciprocal neighbors in Sect. 3.3.2. Among the four proposed relations, R and ğ‘…â€² could be considered as reciprocal relations. On the contrary, U and ğ‘ˆâ€² are non-reciprocal relations, indicating that there is only one-way interest between service users and target users.

Embedding reciprocal users
The previously defined relations could be directly used to compute the similarity between users for the reciprocal recommendation [42]. However, as discussed in Sect. 1, the reciprocal relations in online dating applications are very sparse. Thus, how to carefully discover the implicit similarities between users has become a key component. Inspired by the graph representation learning technique [11, 27, 34, 51], we model the user in a high dimensional feature space, where each user is represented by a continuous user vectors. In this way, the similarities between users could be easily measured in the embedded feature space, and all potential similarities can be computed by the proposed reciprocal user embedding.

Interest similarity and attractiveness similarity
To better learn the embeddings of reciprocal users, we first consider both the interest similarity and attractiveness similarity between users. We propose two similarity measurements to calculate these similarities. First, we define two sets of users based on their â€œSENDâ€ or â€œREPLYâ€ behaviors, given as

ğ‘†ğ‘’(ğ‘¢ğ‘–)={ğ‘¢ğ‘—:ğ‘¢ğ‘– â„ğ‘ğ‘  ğ‘ ğ‘’ğ‘›ğ‘¡ ğ‘ ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ğ‘  ğ‘¡ğ‘œ ğ‘¢ğ‘—},
(1)
ğ‘…ğ‘’(ğ‘¢ğ‘–)={ğ‘¢ğ‘—:ğ‘¢ğ‘– â„ğ‘ğ‘  ğ‘Ÿğ‘’ğ‘ğ‘’ğ‘–ğ‘£ğ‘’ğ‘‘ ğ‘ ğ‘šğ‘’ğ‘ ğ‘ ğ‘ğ‘”ğ‘’ ğ‘“ğ‘Ÿğ‘œğ‘š ğ‘¢ğ‘—},
(2)
where ğ‘†ğ‘’(ğ‘¢ğ‘–) is defined as a set of users that user ğ‘¢ğ‘– has proactively approached to, ğ‘…ğ‘’(ğ‘¢ğ‘–) is defined as a set of users who have sent messages to ğ‘¢ğ‘–. Apparently, ğ‘†ğ‘’(ğ‘¢ğ‘–) indicates the interest of user ğ‘¢ğ‘–, whereas ğ‘…ğ‘’(ğ‘¢ğ‘–) indicates the attractiveness of user ğ‘¢ğ‘–. With these two sets of users, the interest similarity and the attractiveness similarity are defined as follows.

Interest similarity: If two users ğ‘¢ğ‘– and ğ‘¢ğ‘— send message to the same user, they are considered to have similar interest and thus are more likely to contact similar users. Therefore, the ratio of the intersect set of ğ‘†ğ‘’(ğ‘¢ğ‘–) and ğ‘†ğ‘’(ğ‘¢ğ‘—) to the union set of ğ‘†ğ‘’(ğ‘¢ğ‘–) and ğ‘†ğ‘’(ğ‘¢ğ‘—) is adopted to quantify such interest similarity. The intersect set of ğ‘†ğ‘’(ğ‘¢ğ‘–) and ğ‘†ğ‘’(ğ‘¢ğ‘—) represents the common set of users (interested user set) that user ğ‘¢ğ‘– and ğ‘¢ğ‘— have sent messages. The union set of ğ‘†ğ‘’(ğ‘¢ğ‘–) and ğ‘†ğ‘’(ğ‘¢ğ‘—) is the complete set of users that either user ğ‘¢ğ‘– or ğ‘¢ğ‘— has sent messages to.

ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘’ğ‘ ğ‘¡_ğ‘†ğ‘–ğ‘š(ğ‘¢ğ‘–,ğ‘¢ğ‘—)=|ğ‘†ğ‘’(ğ‘¢ğ‘–)âˆ©ğ‘†ğ‘’(ğ‘¢ğ‘—)||ğ‘†ğ‘’(ğ‘¢ğ‘–)âˆªğ‘†ğ‘’(ğ‘¢ğ‘—)|.
(3)
Attractiveness Similarity: If two users ğ‘¢ğ‘– and ğ‘¢ğ‘— have received messages from the same user, it indicates that they might attract the same set of users. Consequently, the ratio of the intersect set of ğ‘…ğ‘’(ğ‘¢ğ‘–) and ğ‘…ğ‘’(ğ‘¢ğ‘—) to the union set of ğ‘…ğ‘’(ğ‘¢ğ‘–) and ğ‘…ğ‘’(ğ‘¢ğ‘—) is adopted to quantify such attractiveness similarity. The intersect set of ğ‘…ğ‘’(ğ‘¢ğ‘–) and ğ‘…ğ‘’(ğ‘¢ğ‘—) represent the common set of users (attracted user set) that user ğ‘¢ğ‘– and ğ‘¢ğ‘— have received messages from. The union set of ğ‘…ğ‘’(ğ‘¢ğ‘–) and ğ‘…ğ‘’(ğ‘¢ğ‘—) is the complete set of users that either user ğ‘¢ğ‘– or ğ‘¢ğ‘— has received messages from.

ğ´ğ‘¡ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘›ğ‘’ğ‘ ğ‘ _ğ‘†ğ‘–ğ‘š(ğ‘¢ğ‘–,ğ‘¢ğ‘—)=|ğ‘…ğ‘’(ğ‘¢ğ‘–)âˆ©ğ‘…ğ‘’(ğ‘¢ğ‘—)||ğ‘…ğ‘’(ğ‘¢ğ‘–)âˆªğ‘…ğ‘’(ğ‘¢ğ‘—)|.
(4)
With equation 3 and 4, the usersâ€™ similarity could be defined as

ğ‘ˆğ‘ ğ‘’ğ‘Ÿ_ğ‘†ğ‘–ğ‘š(ğ‘¢ğ‘–,ğ‘¢ğ‘—)=ğ›¼âˆ—ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘’ğ‘ ğ‘¡_ğ‘†ğ‘–ğ‘š(ğ‘¢ğ‘–,ğ‘¢ğ‘—)+ğ›½âˆ—ğ´ğ‘¡ğ‘¡ğ‘Ÿğ‘ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ğ‘›ğ‘’ğ‘ ğ‘ _ğ‘†ğ‘–ğ‘š(ğ‘¢ğ‘–,ğ‘¢ğ‘—),
(5)
where ğ›¼ and ğ›½ are, respectively, the weight of interest similarity and attractiveness similarity satisfying ğ›¼+ğ›½=1. In this paper, this equation is used to compute the similarity between users to train the embedddings of the reciprocal users.

Optimizing reciprocal user embedding
Although we initialize the node embddings using usersâ€™ attributes, the embeddings of reciprocal users should also consider the interest and attractiveness similarity between users. As a result, given the interest and attractiveness similarity, we revise the loss function of the Skip-gram model [24] to train the reciprocal user embedding.

Let ğº=(ğ‘‰,ğ¸) denote the extracted graph, ğ‘“:ğ‘‰â†’â„ğ‘‘ is a mapping function to embed users. Let d denote the number of embedding dimension, f is a matrix with size |ğ‘‰|Ã—ğ‘‘. For a service user ğ‘¢âˆˆğ‘‰, ğ‘ğ‘ (ğ‘¢) denotes a set of the most similar users generated using equation 5, and ğ‘ğ‘›(ğ‘¢) denotes a set of randomly selected dissimilar users. As the original Skip-gram model cannot be directly applied to our case, a revised version is proposed in this paper, and the corresponding loss is given as

ğ‘šğ‘ğ‘¥ğ‘ƒğ‘ ğ‘šğ‘–ğ‘›ğ‘ƒğ‘›âˆ‘ğ‘¢âˆˆğ‘‰ğ‘™ğ‘œğ‘”ğ‘ƒğ‘ (ğ‘ğ‘ (ğ‘¢)|ğ‘“(ğ‘¢))+ğ‘™ğ‘œğ‘”(1âˆ’ğ‘ƒğ‘›(ğ‘ğ‘›(ğ‘¢)|ğ‘“(ğ‘¢))),
(6)
where ğ‘ƒğ‘  is probability that the similar users co-occur with the neighboring users, ğ‘ƒğ‘› is the probability that dissimilar users appear as the neighboring nodes. Equation 6 is to minimize ğ‘ƒğ‘› and maximize ğ‘ƒğ‘ . In this way, we maximizes the existence of the similar users and minimize the existence of dissimilar users in neighborhoods for a user u. As a result, the similarity between users can be represented by user embeddings.

To resolve equation 6, [11] has proposed following two assumptions.

Conditional independence: The likelihood of observing a neighborhood node is independent of observing any other neighborhood node given the feature representation of the source node, written as

ğ‘ƒğ‘Ÿ(ğ‘ğ‘ (ğ‘¢)|ğ‘“(ğ‘¢))=âˆğ‘¢ğ‘–âˆˆğ‘ğ‘ (ğ‘¢)ğ‘ƒ(ğ‘¢ğ‘–|ğ‘“(ğ‘¢)).
(7)
Symmetry effect. A source node and neighboring nodes have a symmetrical effect on each other at the feature representation level. With the symmetrical effect, the conditional likelihood of any pair of service user and his/her neighbor users could be calculated using a softmax function and we take the product of their embedding features ğ‘“(âˆ—) as input, written as

ğ‘ƒ(ğ‘¢ğ‘–|ğ‘“(ğ‘¢))=ğ‘’ğ‘¥ğ‘(ğ‘“(ğ‘¢ğ‘–)âŠ¤ğ‘“(ğ‘¢))âˆ‘ğ‘¢ğ‘—âˆˆğ‘‰ğ‘’ğ‘¥ğ‘(ğ‘“(ğ‘¢ğ‘—)âŠ¤ğ‘“(ğ‘¢)).
(8)
With the aforementioned assumptions, the objective function can now be defined as

ğ‘šğ‘–ğ‘›ğ‘“âˆ‘ğ‘¢,ğ‘¢ğ‘–âˆˆğ‘‰ğ‘†(ğ‘¢,ğ‘¢ğ‘–)ğ‘™ğ‘œğ‘”ğ‘ƒ+(1âˆ’ğ‘†(ğ‘¢,ğ‘¢ğ‘–))ğ‘™ğ‘œğ‘”(1âˆ’ğ‘ƒ).
(9)
where P is calculated using equation 8, and ğ‘†(ğ‘¢,ğ‘¢ğ‘–) is the similarity between u and ğ‘¢ğ‘– calculated using equation 5.

Equation 9 is then optimized using Stochastic Gradient Ascent algorithm [30]. The algorithm of the revised Skip-gram model is depicted in Algorithm 1. The learned Reciprocal User Embedding f will be further used in DCRS to discover reciprocal neighbors.

figure a
Deep contrast reciprocal recommender system
For reciprocal recommendation, an idea recommender system should consider the mutual interest between the service user and target user. Such interest can be captured by the reciprocal relations introduced in Sect. 3.1. However, suffering from sparsity, it is hard to directly use these relations to optimize a powerful reciprocal recommender system. In this paper, we propose a Deep Contrast Reciprocal Recommender System that contrasts between reciprocal relations and non-reciprocal relations to better capture the mutual interest. Furthermore, the reciprocal neighbor is adopted to augment the possible reciprocal relations. The framework of DCRS is illustrated in Fig. 2.

Fig. 2
figure 2
The overall framework of the proposed Deep Contrast Reciprocal Recommender System. a Incorporate the user attributes and relations in an unified representation. b Find reciprocal neighbors and contrast with reciprocal relations. c Contrast with non-reciprocal relations

Full size image
User feature representation
In RRS, both the user attributes and relations should be considered simultaneously to best capture the mutual interest. Therefore, we integrate the learned reciprocal user embeddings with user attributes to represent each user. As plotted in Fig. 2a, for each user ğ‘¢ğ‘–, given its user attributes ğ‘¥ğ‘–, we first project its attributes into a latent space. Then, by combining with the learned reciprocal user embedding ğ‘“(ğ‘¢ğ‘–), the final user representation ğ‘’ğ‘– can be acquired as

â„ğ‘–=ğœ(ğ‘Š1â‹…ğ‘¥ğ‘–+ğµ1)
(10)
ğ‘’ğ‘–=ğœ(ğ‘Š2â‹…(â„ğ‘–||ğ‘“(ğ‘¢ğ‘–)+ğµ2),
(11)
where ğœ(â‹…) denotes the nonlinear function, || denotes the concatenation operation, and ğ‘Šâˆ—, ğµâˆ— are the model parameters. As a result, both the user attributes and user relations are considered in an unified representation.

Discovering reciprocal neighbors
As we mentioned in Sect. 3.1, we introduce the concept of reciprocal neighbors to augment the number of reciprocal relations. Due to the sparsity issue, it is challenging to directly find possible reciprocal neighbors using defined relations. However, with the learned reciprocal user embeddings, the similarity between users can be measured in a hidden space. Thus, we utilize the similarity between the embeddings of reciprocal users to discover possible reciprocal neighbors.

We first adopt the learned reciprocal user embedding to build a KD-Tree [3] îˆ·. As shown in the middle of Fig. 2, given a service user ğ‘¢ğ‘– and a distance L, the reciprocal neighbors ğ‘â€²(ğ‘¢ğ‘–) of ğ‘¢ğ‘– could be found by using îˆ·, written as

ğ‘â€²(ğ‘¢ğ‘–)={ğ‘¢ğ‘—|ğ‘¢ğ‘—âˆˆîˆ·(ğ‘¢ğ‘–,ğ¿)},
(12)
where îˆ·(ğ‘¢ğ‘–,ğ¿) denotes a set of users whose similarities are smaller than L. In this way, the reciprocal neighbors could be found with its complexity to be O(NlogN) where N denotes the total number of users. Meanwhile, the neighbor mutual interest relation ğ‘…â€² can be calculated as

ğ‘…â€²(ğ‘¢ğ‘–)={ğ‘¢ğ‘˜|ğ‘¢ğ‘˜âˆˆğ‘…(ğ‘¢ğ‘—)âˆ§ğ‘¢ğ‘—âˆˆğ‘â€²(ğ‘¢ğ‘–)},
(13)
where ğ‘…(ğ‘¢ğ‘—) denotes a set of users forming the relation R with each reciprocal neighbor user ğ‘¢ğ‘—. As a result, the number of reciprocal relations can be augmented by ğ‘…â€².

Deep contrast learning for reciprocal recommendation
By contrasting the reciprocal relations with the non-reciprocal relations, the DCRS incorporates the proposed four kinds of relations for reciprocal recommendation. To distinguish the reciprocal relations from non-reciprocal relations, we require the distance between users who belong to the relations R and ğ‘…â€² to be as close as possible. On the contrary, the distance between users who belong to relations U and ğ‘ˆâ€² are as far as possible. Thus, DCRS should be trained under these constraints.

To avoid confusion, we reformulate the problem as follows. Let ğ‘¢ğ‘– denote the service user, ğ‘¢ğ‘— denote the target user to be recommended to ğ‘¢ğ‘–, and ğ‘¢â€²ğ‘– denote the reciprocal neighbor users of ğ‘¢ğ‘–. For contrast learning, the positive and negative samples should be defined in DCRS. To enable DCRS to capture the mutual interest, as shown in Fig. 2b, we denote the users belonging to the reciprocal relation as the positive user, given as

ğ‘ˆ+(ğ‘¢ğ‘–)={ğ‘¢ğ‘—|ğ‘¢ğ‘—âˆˆğ‘…(ğ‘¢ğ‘–)âˆªğ‘…â€²(ğ‘¢ğ‘–)},
(14)
where ğ‘…(ğ‘¢ğ‘–) denotes a set of users who form the relation R with a service user ğ‘¢ğ‘–. Similarly, as shown in Fig. 2c, the negative sample is denoted as

ğ‘ˆâˆ’(ğ‘¢ğ‘–)={ğ‘¢ğ‘—|ğ‘¢ğ‘—âˆˆğ‘ˆ(ğ‘¢ğ‘–)âˆªğ‘ˆâ€²(ğ‘¢ğ‘–)},
(15)
where ğ‘ˆ(ğ‘¢ğ‘–) and ğ‘ˆâ€²(ğ‘¢ğ‘–) denotes the set of users who form the non-reciprocal relation U and ğ‘ˆâ€² with ğ‘¢ğ‘–, respectively. With positive samples ğ‘ˆ+ and negative samples ğ‘ˆâˆ’, given a service user ğ‘¢ğ‘–, we want to minimize its distance with the user in ğ‘ˆ+ and maximize its distance with ğ‘ˆâˆ’. In this way, the DCRS can learn the reciprocal relation by contrasting the positive and negative samples.

To measure the distance between positive samples and negative samples, four mapping functions are designed to map the user representations to a hidden space representing each relation, written as

ğœ‹(ğ‘’ğ‘–)=ğ‘€ğ¿ğ‘ƒ1(ğ‘’ğ‘–)
(16)
ğ›¾(ğ‘’â€²ğ‘–)=ğ‘€ğ¿ğ‘ƒ2(ğ‘’â€²ğ‘–),ğ‘¢â€²ğ‘–âˆˆğ‘â€²(ğ‘¢ğ‘–)
(17)
ğœ™(ğ‘’ğ‘—)=ğ‘€ğ¿ğ‘ƒ3(ğ‘’ğ‘—),ğ‘¢ğ‘—âˆˆğ‘ˆ+(ğ‘¢ğ‘–)
(18)
ğœ“(ğ‘’â€²ğ‘—)=ğ‘€ğ¿ğ‘ƒ4(ğ‘’ğ‘—),ğ‘¢â€²ğ‘—âˆˆğ‘ˆâˆ’(ğ‘¢ğ‘–),
(19)
where each ğ‘€ğ¿ğ‘ƒâˆ— denotes a multi-layer perceptron with independent parameters.

With the mapping functions, the distance between user representations could be contrasted, which is shown in the right of Fig. 2. For reciprocal relation R, we want the distance between R is smaller than the non-reciprocal relation ğ‘ˆâˆ’. Thus we formulate this situation as

ğ·+(ğœ‹(ğ‘’ğ‘–),ğœ™(ğ‘’ğ‘—))<ğ·âˆ’(ğœ‹(ğ‘’ğ‘–),ğœ“(ğ‘’â€²ğ‘—)),
(20)
where ğ·(â‹…) denotes the L2 distance between two representations.

For neighbor mutual interest relation ğ‘…â€², its contrast learning could be formulated as

ğ·â€²(ğœ‹(ğ‘’ğ‘–),ğ›¾(ğ‘’â€²ğ‘–))+ğ·+(ğœ‹(ğ‘’â€²ğ‘–),ğœ™(ğ‘’ğ‘—))<ğ·âˆ’(ğœ‹(ğ‘’ğ‘–),ğœ“(ğ‘’â€²ğ‘—)),
(21)
where the distance between service user ğ‘¢ğ‘– and reciprocal neighbors ğ‘¢â€²ğ‘– is considered for the contrast learning. Intuitively, if the distance between ğ‘¢ğ‘– and ğ‘¢â€²ğ‘– is close, it is highly possible that the mutual-interest user ğ‘¢ğ‘— for ğ‘¢â€²ğ‘– could form a mutual interest relation R with ğ‘¢ğ‘–. The sum of their distances should be smaller than the distance between ğ‘¢ğ‘– and ğ‘¢â€²ğ‘—.

Therefore, with the equation 20 and 21, the objective function for contrast learning can be formulated as

minâˆ‘ğ‘¢ğ‘–âˆˆğ‘‰âˆ‘ğ‘¢â€²ğ‘–âˆˆğ‘â€²(ğ‘¢ğ‘–)âˆ‘ğ‘¢ğ‘—âˆˆğ‘ˆ+(ğ‘¢ğ‘–)âˆ‘ğ‘¢â€²ğ‘—âˆˆğ‘ˆâˆ’(ğ‘¢ğ‘–)ğ·+(ğ‘¢ğ‘–,ğ‘¢ğ‘—)+ğ·â€²(ğ‘¢ğ‘–,ğ‘¢â€²ğ‘–)âˆ’ğ·âˆ’(ğ‘¢ğ‘–,ğ‘¢â€²ğ‘—).
(22)
When ğ‘¢ğ‘—âˆˆğ‘…(ğ‘¢ğ‘–), ğ‘¢â€²ğ‘–=ğ‘¢ğ‘–, and ğ·â€²(ğ‘¢ğ‘–,ğ‘¢â€²ğ‘–)=0, thus the objective function becomes equation 20. When ğ‘¢ğ‘—âˆˆğ‘…â€²(ğ‘¢ğ‘–), ğ‘¢ğ‘– in ğ·+(ğ‘¢ğ‘–,ğ‘¢ğ‘—) is equal to ğ‘¢â€²ğ‘–, thus the objective function becomes equation 21. As a result, the equation 22 represents the contrast between the mutual interest relation and the neighbor mutual interest relation.

In the recommendation stage, given a service user ğ‘¢ğ‘– and a target user ğ‘¢ğ‘—, the DCRS randomly select a negative user ğ‘¢â€²ğ‘— from ğ‘ˆâˆ’(ğ‘¢ğ‘–). Then the probability that ğ‘¢ğ‘– and ğ‘¢ğ‘— are mutually interested in each other is computed as

ğ‘ƒ(ğ‘¢ğ‘–,ğ‘¢ğ‘—)=ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘(ğ·+(ğ‘¢ğ‘–,ğ‘¢ğ‘—)âˆ’ğ·âˆ’(ğ‘¢ğ‘–,ğ‘¢â€²ğ‘—)).
(23)
Notably, DCRS does not directly compute the probability whether a reciprocal relation exists or not. On the contrary, it contrasts the target user with the known negative users. In this way, it is easier for DCRS to discover the reciprocal relation and conduct successful recommendation.

Experiments
To evaluate the model performance, we first collect the experimental dataset from two real-world applications. Then, the proposed approach as well as several benchmark approaches and state-of-the-art approaches are implemented on these datasets.

Experimental dataset
In the experiment, we collect the experimental datasets from two real-world applications. The first dataset, denoted as â€œDataset 1â€ is collected by ourselves from one of the most popular online dating applications. This application has over 100 million registered users and over 40 million monthly active users. After collecting data from this application, we choose users who have sent or received over 40 messages to guarantee sufficient training data for each user. After doing so, the experimental dataset contains 228,470 different users and 25,168,824 messages. Each registered user has 28 different attributes such as age, sex, marriage status, height, weight, body, constellation, Chinese Zodiac, education, occupation and salary. â€˜Dataset 2â€ is a public online dating dataset provided by a competitionFootnote1. It contains 34 user attributes and their interaction histories, i.e., â€œmessageâ€ and â€œclickâ€. We treat these actions equally between users to generate both reciprocal relations and non-reciprocal relations. The statistics of the experimental datasets are illustrated in Table 2. The reciprocal rate in Dataset 2 (0.0402) is much lower than Dataset 1 (0.1449) indicating its sparsity issue.

Table 2 Statistics of the experimental datasets
Full size table
Evaluation metric
We adopt three evaluation metrics in the experiments, i.e., success rate, recall and failure rate, which are widely used to evaluate the performance of RRS [26, 28, 29]. In the experiment, we recommend the top-N user list â„• for each service user. The success rate considers both the successful and failed recommendations in â„•. It is defined as the ratio of the number of successful recommendations and all the recommendations (both successful and failed) in the list, given as

ğ‘†ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ @â„•=#ğ‘ ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ ğ‘“ğ‘¢ğ‘™#ğ‘ ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ ğ‘“ğ‘¢ğ‘™+#ğ‘“ğ‘ğ‘–ğ‘™ğ‘’ğ‘‘
(24)
The recall rate implies how close a recommendation list â„• is to the known reciprocal relations. It is defined as the ratio of the number of successful recommendations in â„• and all known successful reciprocal relations of the service user in the dataset, given as

ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™@â„•=#ğ‘ ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ ğ‘“ğ‘¢ğ‘™#ğ‘˜ğ‘›ğ‘œğ‘¤ğ‘›_ğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ğ‘Ÿğ‘œğ‘ğ‘ğ‘™_ğ‘Ÿğ‘’ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ 
(25)
The failure rate of a list â„• indicates whether the RRS helps to minimize non-reciprocal relations in the recommendation list or not, given as

ğ¹ğ‘ğ‘–ğ‘™ğ‘¢ğ‘Ÿğ‘’@â„•=#ğ‘“ğ‘ğ‘–ğ‘™ğ‘’ğ‘‘#ğ‘ ğ‘¢ğ‘ğ‘ğ‘’ğ‘ ğ‘ ğ‘“ğ‘¢ğ‘™+#ğ‘“ğ‘ğ‘–ğ‘™ğ‘’ğ‘‘
(26)
Note that a higher success rate and recall value and a lower failure rate value indicate a better model performance.

Baseline method
To evaluate the performance of DCRS, the following state-of-the-art reciprocal recommendation methods as well as graph representation learning approaches have been implemented for performance comparison.

RECON: This method is proposed in [28]. The RECON measures how much a service user matches the preferences of a target user using preferred attributes and all attributes of a target user. After calculating user preferences, the algorithm computes a list of recommended users for a service user. Every target user approached by a service user will be assigned with a score reflecting how much the service user likes the target users, and similarly, scores are calculated for the service user by each target user. This score is called the reciprocal score. The final score between them is the harmonic mean of the compatibility scores of these users. Then, the final scores are ranked from which top-N users are recommended and presented.

RCF-A/RCF-I: These two methods are proposed based on RCF [42]. RCF introduces a nearest-neighbor based strategy combined with similarity measuring, to estimate the mutual interest between service users and target users. The author introduced two views of similarity, i.e., attractiveness similarity and interest similarity. Either view can be used to calculate the similarity scores between service (target) usersâ€™ neighbors and target (service) users. Finally these scores are added together to represent the mutual interest. The RCF-A and RCF-I denote RCF using attractiveness similarity and interest similarity, respectively.

LFRR: This method is proposed by [25]. LFRR learns latent attributes from a preference matrix using matrix factorization. To address the reciprocal recommendation challenges, LFRR adopts two latent factor models to capture the preferences of service users and target users respectively. In this way, the likelihood of mutual interest can be calculated by the dot product between two latent factors.

TCF: This method is proposed by [37]. TCF proposes a Mutual-Attraction Indicator to model the mutual preferences of both parties. By such indicators, TCF designs a transfer-learning based CF model for the reciprocal recommendation.

Node2Vec: This method is inspired by [11]. However, the original node2vec cannot be directly applied to the reciprocal recommendation problem. The reason is that the random walk in original node2vec cannot be directly applied to the graph with a reciprocal edge. To implement this approach, we simply build user-pair using relation R. Then, we train the Skip-gram model using the extracted user-pairs. By doing so, we can use the embedding feature matrix to find the top-N users as the recommendation list.

PinSage: This method is proposed by [45]. The proposed PinSage is a Graph Convolutional Network (GCN)-based algorithm. It combines random walk and graph convolution operation to generate node embeddings. The generated feature embeddings incorporate both graph structural information and node attribute information. However, the original method is proposed for user-item recommendation problem but not for the reciprocal issue. In this paper, we adapt this algorithm to our problem. We first convolute the service user as well as his/her neighbor users (including user attributes) together. Then, we perform the dot product between the convoluted features and the target user (including user attributes) to be predicted. The output is binarized to 0 or 1 indicating whether the target user should be recommended or not.

Implementation detail
Among the baselines, the RECON, RCF-A and RCF-I are parameter-free methods, which means these algorithms can be directly applied to the reciprocal recommendation problem. The dimension of user embeddings for LFRR, TCF, Node2vec and PinSage is set to 128. We adopt the a fully connected layer to aggregate the neighbor users in PinSage.

For the proposed DCRS, the dimension of reciprocal user embedding is also set to 128. The dimension of each relation mapping function is set to 256. The dropout rate during the training is set to 0.5. We implement the proposed model using PyTorchFootnote2. The Adam algorithm [14] is adopted to optimize the model, and the learning rate is set to 0.001. We also select three reciprocal neighbors for each service user during the training. The effect of neighbor number is investigated in Sect. 4.6.

Model performance evaluation
To evaluate model performance, we compare our model with both the state-of-the-art reciprocal recommendation methods and graph representation methods on two real-world datasets. In each dataset, we randomly select 100 users as service users. For each method, a top-N recommended user list is returned for each service user, and N is set to 5, 10 and 20, respectively. The corresponding results of success rate, recall and failure rate on the two datasets are reported in Tables 3, 4 and 5, respectively. We emphasize the best results in experiments with bold.

Table 3 Model performance comparison results with respect to the success rate
Full size table
From the results in Tables 3, 4 and 5, we can observe that the proposed DCRS outperforms all baseline models with respect to three metrics. This demonstrates the superiority of the proposed DCRS for this task.

For traditional RRS methods (i.e., RECON, RCF-A and RCF-I), RECON performs better than RCF-A and RCF-I. The possible reason is that RCF-A and RCF-I only consider attractiveness and interest at a time. This indicates that, in RRS, both the attractiveness and interest should be taken into account to accurately capture the reciprocal relations. In addition, RECON adopts the user attributes to make reciprocal recommendations, which is neglected by RCF-A and RCF-I. In contrast, DCRS utilizes user attributes, attractiveness, as well as interest to generate comprehensive user representations to improve model performance.

For learning-based methods, the performances of LFRR and TCF are slightly better than traditional methods in Dataset 1 but worse in Dataset 2. The LFRR and TCF can capture user preferences for recommendation. However, their performances are vulnerable to the sparsity issue, and therefore the performances of these methods decrease on Dataset 2 which contains very sparse reciprocal relations (reciprocal rate: 0.0402). Whereas for the proposed DCRS, the number of reciprocal relations are augmented, and thus a robust DCRS could be learned.

For graph representation-based methods, Node2vec takes advantage of the graph structural information and user embeddings, which is able to model the mutual interest of users in a hidden space. But its performance is still worse than PinSage that incorporates graph structure and user attributes at the same time. With the graph convolutional operation, PinSage achieves the second best performance among all the baselines, but it is still sensitive to the sparsity of reciprocal relations. This leads PinSage unable to successfully identify reciprocal relations. However, DCRS adopts the contrast learning scheme to address this dilemma. By contrasting the reciprocal relations with the non-reciprocal relations, DCRS is trained to possess the ability to well discover the reciprocal relations, which might explain why the proposed approach could achieve the SOTA model performance.

Table 4 Model performance comparison results with respect to the recall
Full size table
Table 5 Model performance comparison results with respect to the failure rate
Full size table
Fig. 3
figure 3
The effect of the number of reciprocal neighbors

Full size image
Effect of reciprocal neighbor
To evaluate the effect of reciprocal neighbors, we perform this experiment to investigate how the number of neighboring users could affect the modelâ€™s performance. We, respectively, set the number of neighbors to 3, 5, 10 and plot the corresponding success rate and recall of DCRS in Fig. 3. From this figure, it is obvious that when the number of neighbors is 3, the proposed model could achieve the best success rate as well recall results. Although a bigger number of reciprocal neighbors could augment the possible reciprocal relations, it might contain certain level of noises which consequently result in the decrease of model performance.

Reciprocal user embedding result
To evaluate the quality of reciprocal user embeddings, we apply PCA [41] on the embedding results to demonstrate the embedding quality. As plotted in Fig. 4, the blue dot represents male user while the red dot represents female users. Obviously, the male user and the female users are well separated, and this partially verifies that the effectiveness of the learned reciprocal user embeddings. Moreover, this work is a joint research work with the online dating website targeting at resolving aforementioned research issues, and our model performance on these real-world datasets already indicates its practical applicability on this real-world task.

Fig. 4
figure 4
The result by applying PCA on reciprocal user embedding

Full size image
Conclusion
With the emergence of online dating applications, reciprocal recommendation has become a hot research issue. In this paper, we propose a Deep Contrast Reciprocal Recommender System called DCRS to capture the mutual interest between users. First, we define four kinds of relationships that reflect the interest and attractiveness. Then, the reciprocal user embedding is learned to measure the similarity between users in a hidden space while finding reciprocal neighbors. The extracted reciprocal neighbors could augment the set of possible reciprocal relations. Last, a contrast learning-based model is proposed to contrast the reciprocal relations with the non-reciprocal relations, and the reciprocal recommendations are made based on it. Extensive experiments are evaluated on two real-world datasets, and the promising results demonstrate that the proposed DCRS is superior to the compared methods with respect to the adopted evaluation metrics. In future, our purpose is to further adopt user profile information such as self-introduction and userâ€™s photo to further enhance the model performance. Accordingly, a multi-modal model should be carefully designed for this purpose.

Keywords
Recommender system
Graph embedding
Online dating
Reciprocal recommendation