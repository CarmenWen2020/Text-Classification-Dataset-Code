In this work, a new multi-objective optimization algorithm called multi-objective learner performance-based behavior algorithm is proposed. The proposed algorithm is based on the process of moving graduated students from high school to college. The proposed technique produces a set of non-dominated solutions. To test the ability and efficacy of the proposed multi-objective algorithm, it is applied to a group of benchmarks and five real-world engineering optimization problems. Several widely used metrics are employed in the quantitative statistical comparisons. The proposed algorithm is compared with three multi-objective algorithms: Multi-Objective Water Cycle Algorithm (MOWCA), Non-dominated Sorting Genetic Algorithm (NSGA-II), and Multi-Objective Dragonfly Algorithm (MODA). The produced results for the benchmarks and engineering problems show that in general the accuracy and diversity of the proposed algorithm are better compared to the MOWCA and MODA. However, the NSGA-II outperformed the proposed work in some of the cases and showed better accuracy and diversity. Nevertheless, in problems, such as coil compression spring design problem, the quality of solutions produced by the proposed algorithm outperformed all the participated algorithms. Moreover, in regard to the processing time, the proposed work provided better results compared with all the participated algorithms.

Introduction
During the last few decades, a number of techniques have been proposed to solve engineering optimization problems. The majority of the techniques were based on nonlinear and linear programming methods. They can find the global optimum for simple to medium problems. An immense number of real-world optimization problems have more than one objective function to maximize and/or minimize. These objectives are often conflicting. Biological disciplines, economic, engineering, and automotive problems are examples of such real-world problems. Thus, since the 1970s, researchers have been interested in examining multi-objective optimization algorithms; see [1,2,3,4,5,6]. It has been proved that these algorithms are affective in solving all types of optimization problems, such as numerical optimization problems, complex optimization problems, and mixed-integer optimization problems. For example, in [7, 8] multi-objective evolutionary algorithms were used to optimize mixed-integer problems and very satisfactory results were produced. However, no single approach exists to tackle all optimization problems with a large number of conflicting objectives as per the No Free Lunch theorem [9].

When using the multi-objective optimization algorithms, it is difficult to find one utopian solution which satisfies all the conflicting objectives. This is because that utopian solution may satisfy one objective, or a subset of the objectives while provides poor regarding another objective, or a subset of objectives. Hence, the multi-objective optimization algorithms provide a set of tradeoff solutions instead of one utopian solution. The produced set is known as the non-dominated solution set or Pareto optimal solution set. The non-dominated solution set provides solutions with a tradeoff that satisfy all the conflicting objectives without violating any of the existing constraints. The individual solutions in the non-dominated set are called Pareto optimum. All Pareto optimal solutions are optimal, and compared to the optimum solutions no better solutions exist in the search space when considering all objectives. None of the Pareto optimum solutions is better than another Pareto optimal solution. It should be noted that decision makers will eventually decide which of the Pareto optimum solutions is better for a particular application. Hence, finding as many Pareto optimum solutions as possible is necessary. Thus, multi-objective optimization algorithms may produce an infinite number of optimal solutions. Plotting the Pareto optimum solutions produces a Pareto front. The foremost goal of multi-objective optimization algorithms is to produce a Pareto front for the provided multi-objective optimization problem [10, 11].

Optimization algorithms, in general, are utilized to optimize various problems in various fields. For example, in [12], a genetic algorithm (GA) was combined with interior point techniques to optimize a new approach that solves the initial value of the equation of a Painlev´e II, and its variants, utilizing the feed-forward artificial network. The GA was utilized as a global search technique to optimize the weights of the artificial neural network, and the interior point techniques were utilized as a local search technique. The proposed model was validated using relative investigation with plain Runge–Kutta numerical process on nonlinear Painlev´e II through utilizing various magnitudes of forcing factors. The reason for proposing the combined technique was that with enlarging the iterations, the GA’s ability to optimize the solutions was reduced, and the improvements in the solutions for a big number of iterations were not reasonable. Hence, the researchers utilized an effective local search technique to reduce the drawbacks of the global search technique for the proposed work. The hybrid method utilized in the work was efficient, yet it was more prone to different runs. Similarly, Sabir et al. [13] designed a neuro-heuristic schema for the nonlinear second order Thomas–Fermi system. To optimize the schema, the GA and sequential quadratic programming were utilized, and it was observed that the examined schema was feasible, precise, and effective. In [14], a salp swarm algorithm (SSA) with Jaya optimizer was used to optimize the parameters of temperature effect in dam health monitoring utilizing support vector machines. Jaya and SSA were utilized as search engines to select the parameters of least square support vector machines and support vector machines (SVM). In the proposed work, a hybrid technique was examined to predict the behaviors of concrete dams. The work discussed the influence of incorporating measured temperatures into the model rather than utilizing a model with indirect temperature. The results proved that the proposed model has a small value of prediction errors and residuals.

Evolutionary algorithms are stochastic and considered as global search methods. They symbolize the concept of natural selection and the endurance of the fittest. It has been proved that evolutionary algorithms are powerful and robust search techniques [15, 16]. They excel at finding many tradeoff solutions in the sole run. Additionally, due to their ability to explore the large promising region and solve problems with many conflicting objectives, the evolutionary algorithms are well suited to solve multi-objective optimization problems. Hence, one of the effective approaches to solve multi-objective optimization problems is evolutionary multi-objective optimization algorithms. However, in case of a large design search space, evolutionary algorithms need a huge number of design evaluations. To decrease this deficiency of evolutionary algorithms and get benefit of the high-quality solutions produced by them, in [8], the S metric selection-evolutionary multi-objective optimization algorithm (SMS-EMOA) was hybridized with simulations of co-evolutionary design process. The hybridized technique was used to investigate the outline search space of a building spatial design in its very early step. The proposed technique in [8] combined the good speed of simulations of co-evolutionary design process and the ability of evolutionary algorithms in producing high quality solutions. Moreover, researchers have kept working on improving the ability of these algorithms. Hypervolume indicator was advocated by [17], which is a metric to examine the quality and performance of the solutions in the produced Pareto front. Moreover, it sometimes participates in the selection procedure in evolutionary multi-objective optimization algorithms. It uses a reference point to calculate the size of the subspace which is dominated from above. The reference point is specified by a user, and during the optimization procedure it ought to please the condition that all the solutions in the non-dominated set dominate it. Besides, the expected hypervolume improvement gradient lets a number of points to walk toward the Pareto front [18]. The good exploration of expected hypervolume improvement encouraged researcher to utilize it with multi-objective Bayesian global optimization (MOBGO). This was due to the low performance of the MOBGO compared to the evolutionary algorithms. The main reason of the low performance of the MOBGO was that the expected hypervolume improvement called repeatedly during the searching procedure for the optimal solution. Hence, a formula for the expected hypervolume improvement gradient utilized to improve the searching procedure of the MOBGO through using the gradient ascent or using the formula as a stopping indicator in the evolutionary algorithms. The MOBGO is developed on Kriging theory. MOBGO supposed that a number of objective functions are cooperatively free in an objective space. The objective functions are approximated using the Kriging technique or Gaussian procedure, and the Kriging model was utilized to evaluate the unsureness of the prediction. It was proved that using the expected hypervolume improvement gradient as a stopping indicator improved the quality of the produced Pareto front even more and decreased the execution time [19]. Additionally, in [7] it is proved that using the hypervolume improvement gradient technique as a local search with the evolutionary multi-objective optimization algorithms provided better Pareto front approximations. In general, evolutionary multi-objective optimization algorithms usually need a large number of objective function evaluations to converge and find the Pareto front [11, 16].

In this work, we introduce some multi-objective optimization algorithms and propose a novel evolutionary multi-objective optimization algorithm, namely the multi-objective learner performance-based behavior (MOLPB) algorithm. The basic ideas of this algorithm are based on the procedure of moving graduated students from high school to colleges. Besides, the learning behaviors may affect the performance of the learners in colleges, and the elements that may encourage the learners to overcome their high-school study behaviors that are not effective anymore with new and effective behaviors [20]. The proposed multi-objective algorithm uses the dominance concept to compare the participated objective functions in a specific problem.

The contributions of the algorithm:

A new evolutionary algorithm is proposed for solving multi-objective optimization problems.

The main population is divided into sub-populations depending on the fitness of the individuals.

Non-dominated approach and crowding distance techniques are used to recognize the better (fitter) solutions.

The subpopulations direct the algorithm toward a promising area. Because the subpopulation that contains the best individuals has priority to be used for selecting the parents.

An archive is employed to store the non-dominated solutions to create the Pareto front set.

Whenever the number of the non-dominated solution in the archive reaches a number bigger than the archive size, then we will apply the crowding distance to the archive to delete the solutions that have a low crowding distance value.

The results are confirmed by utilizing several benchmarks, including ZDT, and five real-world multi-objective optimization problems.

The proposed algorithm is compared against NSGA-II, MODA, and MOWCA for optimizing multi-objective optimization problem.

The rest of the paper is organized as follows. Related works are provided in Sect. 2. Section 3 gives the details of the proposed method. The metrics of comparison are covered in Sect. 4. Results and conclusions are discussed in Sects. 5 and 6.

Related works
In this section, we introduce four multi-objective algorithms. The main reason for choosing these algorithms is that except the strength Pareto evolutionary algorithm, similar to the proposed one, the rest of the algorithms utilize crowding based distance to provide reasonable diversity among the non-dominated solutions in the external archive. Furthermore, the strength Pareto evolutionary algorithm similar to the other algorithms discussed here uses an external archive. However, it utilizes deterministic clustering method to provide good diversity between non-dominated solutions inside the external archive. Three of the discussed algorithms in this section are later tested on the benchmarks and five real-world multi-objective engineering problems. The results of the algorithms are then compared with the proposed algorithm.

Multi-objective cellular genetic algorithm
In [21], a cellular genetic algorithm (cGA) was proposed. The proposed algorithm is called the multi-objective cellular (MOCell) genetic algorithm, which works like a multi-objective version for cGA. cGAs utilize a small neighborhood concept that provides exploration. The individuals here collaborate only with the individuals in the close neighbors. This means that the chosen parents are from close neighbors. Mutation and recombination operators are applied to the chosen individuals to produce offsprings. MOCell utilizes an external archive for storing the observed non-dominated solution in the course of running the algorithm. To provide reasonable diversity in the external archive, the crowding distance examined in NSGA-II was utilized. The crowding distance was also utilized to manage the number of solutions in the external archive. After each iteration, the auxiliary population replaces the old population, and then, a feedback technique is executed. During the feedback procedure, some solutions from the external archive are departed to the population, and the same number of randomly chosen solutions from the population will replace them.

Non-dominated sorting genetic algorithm
In [22], an improved version of the non-dominated sorting genetic algorithm (NSGA-II) was proposed. NSGA-II assigned a rank to individual solutions that are equal to the level of non-domination (level 1 is the best; level 2 is the next best, and so on). At first, a random population 𝑃0 with size 𝑁 is produced. Then, the genetic operations are used to produce an offspring population 𝑄0 with size 𝑁. At each generation (𝑡), the two populations 𝑃𝑡 and 𝑄𝑡 are combined to produce a merged population 𝑅𝑡 with size 2𝑁. This step makes elitism secure because all the members from the current and previous steps are included in the produced population. The solutions in the new population 𝑅𝑡 are then sorted based on the non-dominated solutions. The solutions in the non-dominated set are the best in the combined population. If the size of the non-dominated set is smaller than the population size, all the solutions from the non-dominated set are copied to the new population (𝑃𝑡+1). The rest of the members of the 𝑃𝑡+1 population come from the next best-non-dominated fronts according to the ranks. This procedure of copying members from the fronts is continued until all the available fronts are finished. The number of members from all the available fronts may be larger than 𝑁. Hence, the members come from the last front are sorted in descending order, and crowding based comparison is used to choose the best members to fill the newly produced population (𝑃𝑡+1). The genetic operation (selection, crossover, and mutation) is then utilized in the population (𝑃𝑡+1) to produce a new offspring population (𝑄𝑡+1).

The crowding distance technique shows the diversity of non-dominated solutions on every side of a specific non-dominated one. The smaller the value produced by the crowding distance shows a better distribution among solutions in a particular region. It directs the process of selection at different stages of the multi-objective algorithm against a well distributes Pareto optimal front. The crowding distance technique can be utilized in the objective space and the parameter space as well. The ≺𝑛 the operator was used as a crowded comparison operator. For instance, suppose each individual 𝑖 has two characteristics:

𝑖𝑟𝑎𝑛𝑘 indicates the rank of nondomination.

𝑖𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒 indicates crowding distance.

Hence, 𝑖 ≺𝑛 𝑗 if 𝑖𝑟𝑎𝑛𝑘 is smaller than 𝑗𝑟𝑎𝑛𝑘 or if the 𝑟𝑎𝑛𝑘 of both 𝑖 and 𝑗 is equal, but the 𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒 of 𝑖 is greater than the 𝑑𝑖𝑠𝑡𝑎𝑛𝑐𝑒 of 𝑗. This means that between two solutions the one that has a lower rank is better. However, if the ranks are equal the one that locates in a low crowding region is preferred.

Compared to the original NSGA, NSGA-II has several advantages: 1) the computational complexity of the NSGA-II is smaller than the original NSGA. The reason for this is the non-dominated sorting procedure utilized by the NSGA-II. 2) The NSGA-II utilizes the elitism procedure, which according to [23] has a great impact on improving the performance of a genetic algorithm. Moreover, using elitism prevents losing the best-found solution. 3) To protect the diversity of the non-dominated solution set, a crowding-based procedure was utilized which does not need any defined parameters by the user to keep the diversity rate.

Strength pareto evolutionary algorithm
In [24], a new elitist non-dominated multi-objective evolutionary algorithm called Strength Pareto Evolutionary Algorithm (SPEA) was proposed. SPEA has an external population that contains all the non-dominated solutions found so far. The algorithm maintains the external population during all the generations and makes sure that the external population has been involved in all the operations. At the beginning of each generation, a merged population is produced which consists of the current, and the external population. Depending on the number of solutions dominated by the non-dominated solutions, fitness is given to each non-dominated solution in the merged population, and fitness worse than the worst fitness of the non-dominated solutions is assigned to the dominated solutions. The procedure of assigning fitness directs the search toward a promising area. Moreover, SPEA uses a deterministic clustering method to provide a good rate of diversity among non-dominated solutions.

Multi-objective water cycle algorithm
A multi-objective water cycle algorithm (MOWCA) is proposed in [25]. The water cycle algorithm (WCA) was first introduced in [26]. WCA imitates the observation of the water cycle and the process of flowing the streams and rivers against the sea. A random population that consists of the raindrops is built as a first step. The best raindrop (individual) represents the sea. The next best raindrops are considered as a river, and the remaining raindrops are chosen as streams. The water on the rivers comes from streams. Additionally, the water of the rivers flows to the sea. The amount of water that flows to a river or sea differs from one stream to another.

Similar to nature, here, streams consist of raindrops, and the streams merge to form new rivers. Some of the streams directly flow to the sea. The final point for all streams and rivers is the sea which is considered as the best individual. The procedure of flowing streams in various directions represents the exploitation phase of the algorithm. If the produced solution by a stream is better than the produced solution by a river, the positions of stream and river are swapped. The same procedure of swapping can happen between the sea and river. The condition of evaporation was utilized to avoid trapping into local optima. The sea evaporates whenever a river or a stream flows into it. Hence, the evaporation procedure happens whenever a stream or a river is close enough to the sea. Whenever the evaporation procedure ends, the raining procedure will apply and new streams will generate in various locations. The raining process is the same as the mutation in the genetic algorithm. The exploration phase is secured by the evaporation procedure.

Similar to most of the multi-objective optimization algorithms, MOWCA uses the crowding distance technique to choose the best solutions as rivers and the sea. Moreover, it utilizes an external archive to store the non-dominated solutions. Additionally, crowding distance is utilized to control which solution should enter or remain in the external archive when it becomes full. MOWCA has mixed exploratory and exploitative behaviors. For further clarification, the exploitation phase in the MOWCA comes first, flowing streams against the rivers and rivers against the sea (exploitation phase). In the middle of this moving procedure, evaporation occurs (exploration phase). This technique is significant to explore a wider area of design space while focusing on close optimum non-dominated solutions. For handling constraints, the MOWCA defines a technique. At each generation, when the solution set is defined, the algorithm checks all the constraints, and it separates the feasible solutions. Then, the non-dominated solutions are chosen from the separated feasible solutions. Afterward, these non-dominated solutions are moved to the Pareto archive. Finally, this Pareto archive is used to choose the rivers and sea.

Learner performance-based behavior algorithm
In this section, first, the single version of the learner performance-based behavior algorithm is presented, and then, the multi-objective version of the algorithm is discussed.

Single-objective learner performance-based behavior algorithm
Learner performance-based behavior (LPB) algorithm is inspired by the process of accepting graduate students from high school in colleges. The procedure of transferring high school students to colleges starts with a group of graduate students from high school. Depending on their GPA, some of the applications of these students are accepted in different departments and some of them are rejected. Departments specify the minimum GPA that the students should have. This is like dividing the students into groups depending on their GPA. The students that have a GPA greater than or equal to the minimum required GPA for a specific department are accepted in that department. However, the students with higher GPA have priority to be accepted first. The LPB algorithm utilizes the division probability (dp) operator to separate a percentage of individuals (students) randomly [20]. Equation (1) can be used to separate a percentage of individuals from the main population.

𝑆=𝑛𝑃𝑜𝑝×𝑑𝑝
(1)
where.

S indicates the number of separated individuals from the main population, nPop indicates the number of the main population, dp is a value in the range [0.1, 0.9].

After calculating the fitness of individuals in the separated group, the individuals will be divided into two subpopulations (good and bad). A good population contains individuals with better fitness (GPA), and a bad population contains individuals that have lower fitness. After this, the fitness of all individuals in the main population is calculated. In the main population, the individuals that have a fitness smaller than or equal to the best fitness in the bad population go to the bad population, as shown in Eq. (2). The remaining individuals in the main population are divided into two subpopulations. The individuals that have fitness higher the best fitness in the good population are moved to the perfect population, as shown in Eq. (3), and those who have fitness smaller than or equal to the best fitness in the good population go to the good population, as shown in Eq. (4). The individuals in the perfect population have priority to go through the optimization process first, then the individuals in the good population, and the individuals in the bad population.

𝑥∈𝑏𝑎𝑑𝑃𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛𝑖𝑓𝑓𝑥≤max(𝑏𝑎𝑑𝑃𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛)
(2)
𝑥∈𝑝𝑒𝑟𝑓𝑒𝑐𝑡𝑃𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛𝑖𝑓𝑓>max(𝑔𝑜𝑜𝑑𝑃𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛)
(3)
𝑥∈𝑔𝑜𝑜𝑑𝑃𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛𝑖𝑓𝑓𝑥≤max(𝑔𝑜𝑜𝑑𝑃𝑜𝑝𝑢𝑙𝑎𝑡𝑖𝑜𝑛)
(4)
where.

In Eqs. (7–9), the problem is maximization and 𝑥 is the fitness of an individual in the main population.

Moreover, fresh students should adopt new studying behaviors to be good college students. Additionally, when students go to colleges, their studying behaviors are affected by the studying behaviors of other students. To show this in the algorithm, a crossover operator was utilized. A crossover operator is utilized to exchange information between two individuals (parents), and it produces two offsprings as a result that have different characteristics.

Moreover, the level of metacognition has a big impact on students. The students that have a good level of metacognition are better compared with those who do not have an adequate level of metacognition. Moreover, when the level of metacognition is affected, all the studying behaviors will be affected as well, so that stochastically exchanging positions of behaviors or updating the values of behaviors according to a specific rate can do that. This was shown in the algorithm by utilizing the mutation operator from the genetic algorithm.

Multi-objective learner performance-based behavior algorithm
To change the learner performance-based behavior (LPB) algorithm to an efficacious multi-objective optimization algorithm, we need to redefine the main features of the method (i.e., the learner that owns the best skills). When a single-objective function requires to be minimized, the best solutions found so far are chosen as the best learner. However, multi-objective optimization problems have more than one objective to be evaluated (minimized or maximized). Hence, the algorithm should utilize another criterion for selecting the learners (individuals) from the subgroups. Here, crowding distance from [22] is utilized to choose the best non-dominated solutions. As shown in previous sections, the crowding distance procedure shows the diversity of non-dominated solutions on every side of a specific non-dominated one. The smaller the value produced by the crowding distance shows a better distribution among solutions in a particular region. The crowding distance can be used in both objective and parameter spaces or only in the objective space. To utilize it in the objective space, we sort all the non-dominated solutions according to the result of one of the objectives.

Dividing the main population through utilizing the dp operator into various subpopulations and focusing on the subpopulation that has the best individuals so far directs the search toward a promising area. Selecting the individuals from the best subpopulation and then the next best is the best guide for selecting solutions in the next coming iterations. This procedure is counted as an important pace in the multi-objective learner performance-based behavior (MOLPB) algorithm. To provide a good convergence rate and protect a good diversity, the crowding distance technique is applied to all non-dominated solutions. Afterward, the subpopulations are rebuilt utilizing the non-dominated solutions that are nominated based on the crowding distance. Therefore, the new subpopulations have individuals with a smaller value of crowding distance. The crowding distance mechanism from NSGA-II is used to maintain a good diversity rate.

Besides, it is crucial to have an archive to store the non-dominated solutions to create the Pareto front set. At each generation, we update the archive and delete the dominated solutions. We assign the archive and the population to the same size. Whenever the number of the non-dominated solution in the archive reaches a number bigger than the archive size, we will apply the crowding distance to the archive to delete the solutions that have a low crowding distance value.

Steps of the MOLPB algorithm
1.
Initialize the operators (population size, Crossover, Mutation, dp).

2.
Randomly generate the initial population.

3.
Randomly choose several individuals (learners) by using the dp operator.

4.
Run the selected individuals in the previous step through the fitness function.

5.
Use the non-dominated approach and crowding distance to choose half of the population in step 3, and call this group goodPopulation. Rename the other half as badPopulation.

6.
Do crossover and mutation between half of the elements in the goodPopulation, and for the other half, we bring partners from the main population. However, before choosing the partners from the main population we do the following:

7.
We find the best element (the non-dominated one comparing to the other elements) in the badPopulation.

8.
Remove the elements from the main population that are dominated by the best element founded in A.

9.
In the main population, the individuals that have fitness smaller than or equal to the best fitness in the badPopulation go to the badPopulation.

10.
The remaining individuals in the main population are divided into two sub populations:

a.
perfectPopulation contains the individuals that have fitness higher the best fitness in the goodPopulation.

b.
goodPopulation contains individuals that have fitness smaller than or equal to the best fitness in the goodPopulation.

11.
After filtering the data, do crossover and mutation between the rest of the individuals in the goodPopulation and the elements in the perfectPopulation. If the individuals from the perfectPopulation were not enough, bring individuals from the badPopulation.

12.
Store the non-dominated solutions in the external archive.

13.
Find the crowding distance for the non-dominated solutions in the external archive.

14.
Whenever the external archive becomes full, use the crowding distance technique to remove the dominated solutions (those who have low crowding distance value) in the archive and store the non-dominated solutions.

15.
If the stopping condition is met, the algorithm will quit; otherwise, go to step 3.

Metrics
To evaluate the proposed algorithm quantitatively and compare the results with other multi-objective algorithms, four performance metrics are used. The utilized metrics are among the most widely used metrics for evaluating the multi-objective algorithms [27]. These metrics are described in detail in the following subsections.

Generational distance metric
Generational Distance (GD) metric was proposed by [28]. According to [27], GD is the second most used metrics by the researchers to examine multi-objective evolutionary algorithms. It takes the obtained Pareto front (approximation set) and examines how far the set is from the optimal Pareto front. It examines the average distance of Euclidean between the members of the obtained Pareto set and the closest individuals in the optimal Pareto front. This metric is used to count the accuracy of the algorithm to find the Pareto optimal solutions.

Reverse generational distance metric
The Reverse Generational Distance (RGD) is a reverse form of GD; however, the RGD shows remarkable differences compared with the GD. Instead of the average distance of Euclidean, it examines the smallest Euclidean distance among the obtained and optimal Pareto front solutions. Moreover, it utilizes the optimal Pareto front solutions as a reference instead of the solutions in the obtained Pareto set. Additionally, it is utilized to measure the accuracy (convergence) and the diversity of the algorithm [29]. Similar to the GD, RGD is counted as one of the most widely used metrics [27].

Metric of spacing
The spacing metric (S) is used to measure the distribution of the obtained solutions in the Pareto optimal front. When the spacing value is zero, it means that the space between individuals is similar [30].

Metric of maximum spread
The metric of Maximum Spread (MS) is used for examining the diversity of the solutions in the obtained Pareto front. It uses the width sum of every participated objective to show the spread of the solutions [31].

It should be note that these four metrics allow us to quantify the performance of the multi-objective algorithms in this work in terms of convergence and coverage of Pareto optimal solutions obtained.

Results and discussions
In this section, we tested the proposed multi-objective algorithm using a group of standard benchmarks, and five real-world multi-objective engineering problems. Additionally, to statistically evaluate the ability of the algorithm, the average (Ave.) and standard deviation (Std.) of the results for all the participated algorithms (MOLPB, MOWCA, NSGA-II, and MODA) were calculated by the authors. The results are then compared with three multi-objective algorithms in the literature (MOWCA, NSGA-II, and MODA). The overall parameters for the MOLPB and other participated algorithms are shown in Table 1. The parameters and MATLAB code of MOWCA, NSGA-II, and MODA are from [32, 33], and [34], respectively. However, some of their main parameters are presented in Table 1.

Table 1 Parameter settings for algorithms
Full size table
MATLAB programming software was used to code the MOLPB algorithm. For optimizing each benchmark, 30 independent runs were utilized. The algorithm executed over 30 independent runs and 350 iterations each. To store the non-dominated solutions, we utilized an external archive with the size of 100. A standard laptop with a processor Intel Core i7, 16 GHz was used. Similarly, the same conditions and computing platform are utilized to run all other participated algorithms (MOWCA, NSGA-II, and MODA) in this paper by the authors of the work.

The description of quality in multi-objective optimization problems is significantly more complex compared to that in the optimization of single-objective problems. Hence, reasonable convergence and diversity are used as metrics to recognize better multi-objective optimization algorithms [27, 35, 36]. In multi-objective optimization algorithms, to decide the quality of the algorithm in solving multi-objective optimization problems, researchers focus on the following [30]:

Minimizing the distance between the non-dominated solutions set in the Pareto optimal front.

Providing well and uniformly distributed solutions.

The results of the utilized benchmarks and the real-world engineering problems in this paper proved the perfect distance between the non-dominated solutions produced by the MOLPB algorithm. Additionally, the algorithm can provide a set of the well and uniformly distributed solutions.

Computational complexity is described as a method of size (cardinality) of the input set of data. In general, when debating computational complexity if it is not stated, the time complexity is presumed. For measuring the computational complexity of an algorithm, big-O notation (𝑂) is the most popular complexity measure. It is complicated to measure the time complexity of multi-objective evolutionary algorithms [32]. Because they are stochastic algorithms, the operators they use, the implementation of the operators, the representation of the individuals, the number of objectives, the size of the population affect their complexity. For calculating the computational complexity of multi-objective evolutionary algorithms, it is important to examine both, the complexity of each generation and the complexity of all generations [37, 38]. Concerning the MOLPB algorithm, the computational complexity for a single generation is 𝑂(𝑛𝑜𝑏𝑛𝑝𝑜𝑝2), where 𝑛𝑜𝑏 is the number of objectives, and 𝑛𝑝𝑜𝑝 is the population size. However, for all the generations, the complexity is 𝑂(𝑛𝑜𝑏𝑛𝑝𝑜𝑝𝑛𝑔2), where 𝑛𝑔 represents the number of generations.

ZDT benchmarks
The ZDT benchmarks were first proposed in [36]. The family of the ZDT, which consists of six benchmarks, is very popular to assess the performance of the multi-objective optimization problems. Each ZDT benchmark contains a characteristic, which shows a real-world optimization problem that could make it difficult to converge to the Pareto front. All the test functions in the ZDT test suit consist of two objectives. Optimization problems with two objectives are counted as the most popular utilization of multi-objective optimization, mainly within applications in the engineering area [39]. The ZDT5 was not used in this study for benchmarking the algorithm because it is for binary problems. The ZDT functions and their parameters are presented in Table 13@@ in Appendix A. More information about the ZDT family test suit can be found in [36]. The average and standard deviation for each of the ZDT benchmarks are counted for all the utilized metrics (GD, MS, RGD, and S), and they are shown as (Ave.GD, Ave.MS, Ave.RGD, Ave.S) and (Std.GD, Std.MS, Std.RGD, Std.S), respectively.

The statistical results for the ZDT1 prove that for all the performance metrics the produced results by the MOLPB algorithm are better than the MODA. However, the average values of both GD and RGD of MOWCA and NSGA-II were better than those of the MOLPB algorithm. The values of GD and RGD were evidence that the proposed algorithm is more accurate than MODA and less accurate in producing results than MOWCA and NSGA-II. On the other hand, the average values of MS and S of the MOLPB algorithm were better than all the participated algorithms. The results of MS and S metrics proved the superior distribution of the solutions produced by the algorithm. The results of the standard deviation proved that the stability of the algorithm compared with the MODA was much better. However, compared to the values of standard deviation, the other two algorithms were more stable. The numerical results of the ZDT1 are shown in Table 2. The non-dominated solutions for all the participated algorithms are shown in Fig. 1. As shown in Fig. 1, the provided Pareto front by the MOLPB algorithm is very close to the optimal one. Regarding the processing time (PT), the MOLPB algorithm is the faster optimizer to optimize this function compared to the other algorithms. The reason for this is that size of the sub-populations is smaller compared with the main population. Hence, the searching procedure in these smaller sub-populations is speeder, which minimizes the optimization time. In Table 2, the results that outperformed other results are shown in bold.

Table 2 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the ZDT1
Full size table
Fig. 1
figure 1
Non-dominated solutions produced by MOLPB, MOWCA, NSGA-II, and MODA, respectively, for ZDT1

Full size image
The results of the ZDT2 benchmark are presented in Table 3. In Table 3, the results that outperformed other results are shown in bold. The average values of the GD and RGD of the NSGA-II were better than the MOLPB algorithm, and the MOLPB was superior compared to the MODA and MOWCA. This proved the accuracy of the MOLPB algorithm compared with MODA and MOWCA. The average values of the GD and RGD proved the accuracy of the algorithm compared to the MODA and MOWCA. The average results of the MS and S of MODA were superior to the other algorithms. The average results of S of the MOLPB algorithm were comparable to the MOWCA, which proved the good diversity of the proposed technique to solve this problem. Additionally, the results of the Std. proved the superior stability of the algorithm. For all the metrics, the Std. of the MOLPB algorithm was the second-lowest among other algorithms. Regarding the PT, the MOLPB algorithm performed much better compared to the other participated algorithms. The produced Pareto front for all the participated algorithms is shown in Fig. 2. The formulated Pareto front in Fig. 2 shows that the ability of the proposed algorithm is great to optimize the problem, and the provided Pareto front is very similar to the optimal one.

Table 3 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the ZDT2
Full size table
Fig. 2
figure 2
Non-dominated solutions produced by MOLPB, MOWCA, NSGA-II, and MODA, respectively, for ZDT2

Full size image
The results of the performance metrics for ZDT3 are presented in Table 4. In Table 4, the results that outperformed other results are shown in bold. The average values of the GD, RGD, and MS for the MOLPB algorithm were much better compared to the MODA, and this proves the accuracy and good divergence of the proposed work compared with the MODA. Additionally, the stability of the algorithm for providing distributed non-dominated solutions was better than the rest of the participated algorithms. This was evaluated by using the standard deviation of the S metric. Moreover, the standard deviation of the MS metric for the MOLPB algorithm was the second lowest value, and this proves the stability of the algorithm in providing accurate non-dominated solutions. However, the values of the metrics show that the proposed algorithm did not perform well on this benchmark compared to the MOWCA and NSGA-II. The reason for this is that for this problem, the distribution of the Pareto optimal solutions produced by those algorithms is better than the distribution of the Pareto optimal solutions produced by the MOLPB algorithm. Similar to the ZDT1 and ZDT2, the processing time of the MOLPB algorithm for solving ZDT3 is smaller than the other participated algorithms. The produced Pareto front for the algorithms is presented in Fig. 3. The produced Pareto front is an evident that the algorithm can produce a set of non-dominated solutions which are very close to the optimal solutions.

Table 4 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the ZDT3
Full size table
Fig. 3
figure 3
Non-dominated solutions produced by MOLPB, MOWCA, NSGA-II, and MODA, respectively, for ZDT3

Full size image
The statistical results of the ZDT4 are shown in Table 5. In Table 5, the results that outperformed other results are shown in bold. In general, the results of the performance metrics prove that the proposed work was the second-best algorithm among the other multi-objective algorithms in the literature. The results are evidences of the accuracy and stability of the algorithm in producing non-dominated solutions. The results of the NSGA-II were better than the produced results by the MOLPB algorithm. On the contrary, the produced results of the MOLPB algorithm were much better compared with the MOWCA and MODA. Hence, the algorithm could prove its ability in optimizing the problem and providing well-distributed solutions with great accuracy. Figure 4 shows the convergence curve of the MOLPB algorithm, MOWCA, NSGA-II, and MODA, for optimizing the ZDT4 test function. Figure 4 proves the truth that the MOLPB algorithm is the second best algorithm to optimize this problem. The produced Pareto front by the MOLPB algorithm was very close to the optimal Pareto front, which is evidence that the multi-objective version of the proposed algorithm can optimize this problem accurately, produce solutions that are well distributed, and own a considerable diversity. Moreover, the examined algorithm converged earlier compared with the MOWCA and NSGA-II. However, the PT for the MODA is smaller compared with the MOLPB.

Table 5 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the ZDT4
Full size table
Fig. 4
figure 4
Non-dominated solutions produced by MOLPB, MOWCA, NSGA-II, and MODA, respectively, for ZDT4

Full size image
Similar to ZDT4, the MOLPB algorithm has a great ability to optimize the ZDT6 test function. The results of this problem prove the superiority of the algorithm to provide a set of Pareto fronts which is very similar to the optimal Pareto front. The accuracy of the algorithm in providing optimal solutions is proved by the value of the GD metric. Moreover, the considerable diversity of the algorithm is shown through the result of the MS metric. The results of the RGD and S metrics of the NSGA-II were better than the results of the MOLPB algorithm. On the contrary, the proposed work produced better results compared with the MOWCA and MODA in all the metrics, and in the MS metric compared with the NSGA-II. The statistical results of the ZDT6 are provided in Table 6. In Table 6, the results that outperformed other results are shown in bold. Figure 5 shows the Pareto front for ZDT6 by the MOLPB algorithm, MOWCA, NSGA-II, and MODA, respectively. Figure 5 provides evidence of that presented in Table 6. The PT in Table 6 shows that the proposed algorithm is the fastest compared with the other algorithms.

Table 6 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the ZDT6
Full size table
Fig. 5
figure 5
Non-dominated solutions produced by MOLPB, MOWCA, NSGA-II, and MODA, respectively, for ZDT6

Full size image
Dividing the main population into a number of sub-populations affected the diversity of the algorithm, because the algorithm focuses on the sub-population that contains better individuals, and usually the individuals in sub-populations have similar fitness which affects the diversity of the algorithm. In addition, it showed a great diversity in most of the cases. Moreover, having few parameters to adjust is one of the best properties of this algorithm. Besides, it showed a good ability to produce a set of well and uniformly distributed non-dominated solutions, which is one of the characteristics of good multi-objective algorithms. Concerning the processing time, the algorithm selects individuals from the sub-population which are smaller compared to the main population; hence, the procedure becomes quicker.

Real-world engineering problems
In this section, the proposed algorithm was tested on five multi-objective real-world engineering problems. All the problems were tested on several other algorithms in [40], and the optimal Pareto front for all the problems is presented. The optimal Pareto front in [40] was utilized to calculate the metrics (GD and RGD) and visualize the obtained Pareto front with the optimal one whenever needed. The problems are described in the following subsections. The average and standard deviation for each of all the problems are counted for the utilized metrics (GD, and RGD), and they are shown as (Ave.GD, and Ave.RGD) and (Std.GD, and Std.RGD), respectively.

The 4-bar truss design problem
The 4-bar truss design problem is one of the most popular problems for evaluating and validating various techniques [25]. This problem is also utilized in [41, 42]. The mathematical form of the problem is as follows:

Minimize

𝑓1(𝑥)=𝐿(2𝑥1+2‾√𝑥2+𝑥3‾‾‾√+𝑥4)
(5)
𝑓2(𝑥)=𝐹𝐿𝐸(2𝑥1+22‾√𝑥2−22‾√𝑥3+2𝑥4)
(6)
where

(𝐹𝜎)≤𝑥1,𝑥4≤3×(𝐹𝜎)
2‾√×(𝐹𝜎)≤𝑥2,𝑥3≤3×(𝐹𝜎)
The parameters are as follows:

F = 10 kN, E = (2)105 kN/cm2, L = 200 cm, 𝜎 = 10 kN/cm3.

Shifting the joint and the magnitude of the four-bar truss should be optimized at the same time. The results of various techniques for this problem are shown in Table 7.

Table 7 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the four bar truss design problem
Full size table
Depending on the average of the GD values presented in Table 7, the NSGA-II owned the best performance to solve this problem, and the MOLPB algorithm has the second-best performance for finding the non-dominated solution among the participated algorithms. This proves that the produced non-dominated solutions by the MOLPB algorithm have the smallest distance to the optimal Pareto front after the NSGA-II. However, the average value of the RGD of the MOLPB algorithm was smaller than the RGD value of the NSGA-II. Based on the results of the RGD method, the MOLPB has the second-best diversity among its non-dominated solutions compared to the other algorithms and the MODA has the best diversity. Besides, the value of the Std. for the MOLPB algorithm for both methods (GD and RGD) is the second-best, which proves its stability regarding the non-dominated solutions that have the lowest distance from the optimal Pareto front, and the solutions that have a good diversity in the non-dominated set. The produced Pareto front by the participated algorithms for this problem is shown in Fig. 6. The formulated Pareto front proved the provided data in Table 7, and that the algorithm has a great ability to optimize the problem. In Table 7, the results that outperformed other results are shown in bold.

Fig. 6
figure 6
Non-dominated solutions produced by the MOLPB, MOWCA, NSGA-II, and MODA for the 4-bar truss design problem

Full size image
The pressure vessel design problem
Both ends of the cylindrical pressure vessel are covered with half-round heads as shown in Fig. 7. For this problem, the costs of forming, material, and welding should be minimized, and this is the first objective of the problem. The decision variables are the width of the shell, the width of the head, the radius, and the cylindrical length. 𝑥1,𝑥2,𝑥3, and 𝑥4 are utilized to represent the decision variables, respectively [40, 43].

Fig. 7
figure 7
Pressure vessel design

Full size image
The mathematical form of this problem is as follows.

Minimize

𝑓1(𝑥)=0.6224𝑥1𝑥3𝑥4+1.7781𝑥2𝑥23+3.1661𝑥21𝑥4+19.84𝑥21𝑥3
(7)
Subject to

𝑔1(𝑥)=𝑥1−0.0193𝑥3≥0
(8)
𝑔2(𝑥)=𝑥2−0.00954𝑥3≥0
(9)
𝑔3(𝑥)=𝜋𝑥23𝑥4+43𝜋𝑥33−1296000≥0
(10)
where

𝑥1,𝑥2∈{1,…..,100}, 𝑥3∈[10,200], 𝑥4∈[10,240].

The second objective for the mentioned problems is the summation of the constraints. The following is the mathematical formulation of this objective:

𝑓2(𝑥)=∑𝑖=13𝑚𝑎𝑥{𝑔𝑖(𝑥),0}
(11)
As shown in Table 8, for this problem, the MOLPB algorithm produced the lowest average value of GD compared with the other algorithms. This proves the superior performance of the MOLPB algorithm to find the non-dominated solutions with the minimum distance from the optimal Pareto front. Additionally, the average value of the RGD again proved the superior diversity of the MOLPB algorithm in comparison with the other participated algorithms. However, based on the values of the Std., the MOLPB algorithm is the second-best concerning the stability of finding the non-dominated solutions with the minimum distance from the optimal Pareto front and the non-dominated solutions that own a good diversity. As the result of GD proved, the NSGA-II owns the best stability in finding the non-dominated solutions with the minimum distance from the optimal Pareto front. According to the results of RGD, the MODA owns the best stable diversity among the non-dominated solutions. Figure 8 presents a comparison between the MOLPB algorithm, NSGA-II, MOWCA, and MODA. The results from Table 8 are verified in Fig. 8.  In Table 8, the results that outperformed other results are shown in bold.

Fig. 8
figure 8
Non-dominated solutions produced by the MOLPB, MOWCA, NSGA-II, and MODA for the pressure vessel design problem

Full size image
Table 8 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the pressure vessel design problem
Full size table
The coil compression spring design problem
This problem is a real-world mechanical engineering optimization problem. The spring is a spiral squeezing spring as shown in Fig. 9. A strictly lengthwise and a sustained load are put in the spring. Minimizing the volume of steel wire was utilized to create the spring. The decision variables include the number of spirals of the spring (x1), the exterior diameter of the spring (x2), and the diameter of the spring wire (x3). This problem contains integer (x1), continuous (x2), and discrete (x3) variables. The allowable discrete values of x3 are shown in Table 9. This problem contains two objectives to minimize and six constraints. Minimizing the volume of steel wire utilized to create the spring is the first objective. The other objective is the total of the constraint violations [40, 44].

Fig. 9
figure 9
Spiral spring

Full size image
Table 9 Allowable diameters for the spring wire
Full size table
This problem is mathematically formulated as follows:

𝑓1(𝑥)=𝜋2𝑥2𝑥23(𝑥1+2)4
(12)
Subject to

𝑔1(𝑥)=−8𝐶𝑓𝐹𝑚𝑎𝑥𝑥2𝜋𝑥33+𝑆≥0
(13)
𝑔2(𝑥)=−𝑙𝑓+𝑙𝑚𝑎𝑥≥0
(14)
𝑔3(𝑥)=−3+𝑥2𝑥3≥0
(15)
𝑔4(𝑥)=−𝜎𝑝+𝜎𝑝𝑚≥0
(16)
𝑔5(𝑥)=−𝜎𝑝−𝐹𝑚𝑎𝑥−𝐹𝑝𝐾−1.05(𝑥1+2)𝑥3+𝑙𝑓≥0
(17)
𝑔6(𝑥)=−𝜎𝑤+𝐹𝑚𝑎𝑥−𝐹𝑝𝐾≥0
(18)
𝐶𝑓= 4(𝑥2/𝑥3)−14(𝑥2/𝑥3)−4+0.615𝑥3𝑥2
(19)
𝐾=𝐺𝑥438𝑥1𝑥32
(20)
𝜎𝑝=𝐹𝑝𝐾
(21)
𝑙𝐹=𝐹𝑚𝑎𝑥𝐾+1.05(𝑥1+2)𝑥3
(22)
where

𝑥1∈{1,……,70}
𝑥2∈[0.60,30]
𝑥3 is the diameter of the wire and it is shown in Table 9.

And the parameters are as follows:

𝐹𝑚𝑎𝑥=1000𝑙𝑏, it is the highest working load.

𝑆=189,000𝑝𝑠𝑖, it is the accepted highest sheer stress.

𝑙𝑚𝑎𝑥=14𝑖𝑛𝑐ℎ, it is the highest free length.

𝑑𝑚𝑖𝑛=0.2𝑖𝑛𝑐ℎ, it is the lowest diameter of the wire.

𝐷𝑚𝑎𝑥=3𝑖𝑛𝑐ℎ, it is the highest exterior diameter of the spring.

𝐹𝑝=300𝑙𝑏, it is the preload compression force.

𝜎𝑝𝑚=6𝑖𝑛𝑐ℎ, it is the accepted highest diversion under preload.

𝜎𝑤=1.25𝑖𝑛𝑐ℎ, it is the diversion from preload location to highest load location.

𝐺=11.5×106, it is the material’s shear modulus.

𝑓2(𝑥)=∑𝑖=16𝑚𝑎𝑥{𝑔𝑖(𝑥),0}
(23)
The produced results in Table 10 show that the MOLPB algorithm outperforms other participated algorithms to solve the coil compression spring design problem. The proposed algorithm produced the minimum average result for both the GD and RGD methods. These produced results for the GD technique are evidence for the superior performance of the MOLPB algorithm to find the non-dominated solutions with the smallest distance from the optimal Pareto front. Moreover, the lowest average result for the RGD proved the superior diversity of the proposed algorithm. Additionally, the minimum result of the Std. for the MOLPB algorithm compared with the other algorithms showed the stability of the algorithm. Figure 10 proves the results shown in Table 10. The results in bold are the best produced results by the participated algorithms.

Table 10 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the coil compression spring design problem
Full size table
Fig. 10
figure 10
Non-dominated solutions produced by the MOLPB, MOWCA, NSGA-II, and MODA for the coil compression spring design problem

Full size image
The speed reducer design problem
This problem was first designed as a single objective optimization problem. It was then converted to many-objective optimization. It is the design of a gearbox that can be utilized in some airplanes. It contains three objectives, eleven constraints, and seven decision variables. The first two objectives of the problem are to reduce the volume and the stress in either of the gear shafts, respectively. The third objective is the total of the constraints. This problem is also utilized to test other algorithms in [40, 42, 45]. The mathematical formulation of the problem is as follows:

𝑓1(𝑥)=0.7854𝑥1𝑥22(10𝑥233+14.933𝑥3−43.0934)−1.508𝑥1(𝑥26+𝑥27)+7.477(𝑥36+𝑥37)+0.7854(𝑥4𝑥26+𝑥5𝑥27)
(24)
𝑓2(𝑥)= (745𝑥4/𝑥2𝑥3)2+1.69×107‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√0.1𝑥36
(25)
𝑔1(𝑥)=127−1𝑥1𝑥32𝑥3≥0
(26)
𝑔2(𝑥)=1397.5−1𝑥1𝑥22𝑥23≥0
(27)
𝑔3(𝑥)=11.92−𝑥34𝑥2𝑥3𝑥46≥0
(28)
𝑔4(𝑥)=11.93−𝑥35𝑥2𝑥3𝑥47≥0
(29)
𝑔5(𝑥)=40−𝑥2𝑥3≥0
(30)
𝑔6(𝑥)=12−𝑥1𝑥2≥0
(31)
𝑔7(𝑥)=−5+𝑥1𝑥2≥0
(32)
𝑔8(𝑥)=−1.9+𝑥4−1.6𝑥6≥0
(33)
𝑔9(𝑥)=−1.9+𝑥5−1.1𝑥7≥0
(34)
𝑔10(𝑥)=1300−𝑓2(𝑥)≥0
(35)
𝑔11(𝑥)=1100−(745𝑥5/𝑥2𝑥3)2‾‾‾‾‾‾‾‾‾‾‾‾‾√+1.575×1080.1𝑥37≥0
(36)
where

𝑥1∈[2.6,3.6] indicates the width of the gear face. 𝑥2∈[0.7,0.8] is the module of the teeth. 𝑥3∈{17,….,28} indicates the number of teeth in the gear. 𝑥4∈[7.8,8.3] is the space among the bearings on the first cylinder. 𝑥5∈[7.8,8.3] is the space among the bearings on the second cylinder. 𝑥6∈[2.9,3.9] and 𝑥7∈[5,5.5] are the diameters of the first and second cylinders, respectively.

The third objective is the total of all the constraints, as follows:

𝑓3=∑𝑖=111𝑚𝑎𝑥{𝑔𝑖(𝑥),0}
(37)
In general, the results in Table 11 show that MOLPB was the second-best algorithm to solve this problem. The NSGA-II produced the smallest value for the GD method. Comparing to the rest of the algorithms in this work, the MOLPB algorithm produced the minimum average value of the GD technique. This proves the superiority of both NSGA-II and MOLPB to find the non-dominated solutions with the smallest distance from the optimal Pareto front. Additionally, the superiority of the proposed algorithm was proved for finding non-dominated solutions that have good diversity. The result of the RGD method is reasonable evidence for the superior diversity of the algorithm. Moreover, the results of the Std. showed the stability of the MOLPB algorithm to solve the problem. Figure 11 shows the produced Pareto front by the participated algorithms. The formulated Pareto front is evident to that provided in Table 11. In Table 11, the best produced results are shown in bold.

Table 11 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the speed reducer design problem
Full size table
Fig. 11
figure 11
Non-dominated solutions produced by the MOLPB, MOWCA, NSGA-II, and MODA for the speed reducer design problem

Full size image
The car side impact design problem
This problem was also addressed in [40, 46, 47]. It consists of four objectives. The aim of the first three objectives (𝑓1,𝑓2,and𝑓3) is reduce the heaviness of the car, the pubic force that passengers went through, and the V-pillar’s total velocity which is in charge of resisting the impact load, respectively. The original problem consists of eleven decision variables. However, since we use the problem from [40], the four stochastic variables are excluded. The formulation of the problem is as follows:

𝑓1(𝑥)=1.98+4.9𝑥1+6.67𝑥2+6.98𝑥3+4.01𝑥4+1.78𝑥5+10−5𝑥6+2.73𝑥7
(38)
𝑓2(𝑥)=4.72−0.5𝑥4−0.19𝑥2𝑥3
(39)
𝑓3(𝑥)=0.5(𝑉𝑀𝐵𝑃(𝑥)+𝑉𝐹𝐷(𝑥))
(40)
𝑔1(𝑥)=1−1.16+0.3717𝑥2𝑥4+0.0092928𝑥3≥0
(41)
𝑔2(𝑥)=0.32−0.261+0.0159𝑥1𝑥2+0.06486𝑥1+0.019𝑥2𝑥7−0.0144𝑥3𝑥5−0.0154464𝑥6≥0
(42)
𝑔3(𝑥)=0.32−0.214−0.00817𝑥5+0.045195𝑥1+0.0135168𝑥1−0.03099𝑥2𝑥6+0.018𝑥2𝑥7−0.007176𝑥3−0.023232𝑥3+0.00364𝑥5𝑥6+0.018𝑥22≥0
(43)
𝑔4(𝑥)=0.32−0.74+0.61𝑥2+0.031296𝑥3+0.031872𝑥7−0.227𝑥22≥0
(44)
𝑔5(𝑥)=32−28.98−3.818𝑥3+4.2𝑥1𝑥2−1.27296𝑥6+2.68065𝑥7≥0
(45)
𝑔6(𝑥)=32−33.86−2.95𝑥3+5.057𝑥1𝑥2+3.795𝑥2+3.4431𝑥7−1.45728≥0
(46)
𝑔7(𝑥)=32−46.36+9.9𝑥2+4.4505𝑥1≥0
(47)
𝑔8(𝑥)=4−𝑓2(𝑥)≥0
(48)
𝑔9(𝑥)=9.9−𝑉𝑀𝐵𝑃(𝑥)≥0
(49)
𝑉𝑀𝐵𝑃(𝑥)=10.58−0.674𝑥1−0.67275𝑥2
(50)
𝑉𝐹𝐷(𝑥)=16.45−0.489𝑥3𝑥7−0.843𝑥5𝑥6
(51)
where.

𝑥1∈[0.5,1.5] indicates the width of B-Pillar inner, 𝑥2∈[0.45,1.35] indicates the width of B-Pillar augmentation, 𝑥3∈[0.5,1.5] indicates the width of the interior floor side, 𝑥4∈[0.5,1.5] indicates the width of cross-members, 𝑥5∈[0.875,2.625] indicates the width of the door beam, 𝑥6∈[0.4,1.2] indicates the width of door augmentation, 𝑥7∈[0.4,1.2] indicates the width roof rail.

Objective number four is the total of the constraints, as follows:

𝑓4(𝑥)=∑𝑖=110𝑚𝑎𝑥{𝑔𝑖(𝑥),0}
(52)
As shown in Table 12, the results show the ability of the MOLPB algorithm to solve this problem. In addition to the high number of objective, decision variables, and constraints, the proposed algorithm performed better than the other algorithms to solve the problem. The results proved the super-diversity and performance of the algorithm. It performed superior to produce non-dominated solutions with a small distance from the optimal Pareto front. Additionally, it owned a good diversity and this was proved by the results of the RGD method. The small value of the Std. showed the amazing stability of the algorithm. Moreover, the result of the GD of the MOLPB algorithm was better compared with the other algorithms, and this proves the accuracy of the produced results by the algorithm. Figure 12 shows the produced Pareto front by the participated algorithms. As shown, the proposed algorithm provided a better Pareto front compared with other algorithms. This is evidence of the ability of the proposed algorithm to optimize multi-objective problems and produce accurate results. The best produced results are shown in bold.

Table 12 Comparison of the participated algorithms in the literature based on the average and Std. values of the performance metrics for the car side impact design problem
Full size table
Fig. 12
figure 12
Non-dominated solutions produced by the MOLPB, MOWCA, NSGA-II, and MODA for the car side impact design problem

Full size image
Conclusions and feature works
In this work, a new multi-objective algorithm called MOLPB was proposed. The MOLPB algorithm is a brand new algorithm for solving problems that have many objectives. The basic ideas of the MOLPB algorithm were motivated by the process of transferring graduated learners from high school to university and improving the studying behaviors of the learners at colleges. The proposed multi-objective algorithm was utilized to optimize a group of benchmarks, and five real-world engineering problems. To confirm the efficacy and ability of the algorithm, several criteria were utilized. The produced statistical results from the metrics are evidence that the algorithm can approach the optimal Pareto front and produce a set of good non-dominated solutions compared with other multi-objective algorithms in the literature. Depending on the reported results, the MOLPB algorithm, in general, provides better or competitive results compared with the MODA and MOWCA; this was due to the ability of the algorithm to find well distributed solutions in produced Pareto front. Moreover, the produced Pareto front by the proposed work is very close to the optimal one; this was shown in figures. The MOLPB proved its ability in solving problems with high number of objectives, decision variables, and constraints and provided better results compared with all the participated algorithms; the produced results of the car side impact design problem are a good evidence for this and a good reason to encourage researchers to utilize the proposed algorithm for optimizing similar problems. However, in some cases, the NSGA-II outperformed the proposed algorithm; this was due to the technique utilized by the proposed work to divide the main population into a number of sub-populations, and this, occasionally, affected the diversity of the algorithm, especially when the problem was simpler and the number of objectives and decision variables were small. Although the MOLPB algorithm proved its ability to optimize different real-world engineering problems and a group of benchmarks, the nature of the problem may affect the performance of the algorithm similar to any other algorithms. In general, the proposed multi-objective algorithm is a suitable technique to provide Pareto optimal solutions for various multi-objective optimization problems.

For future works, several research directions can be endorsed. Firstly, the authors recommend using the examined algorithm for optimizing various problems, especially mixed-integer problems, and compare the results with other multi-objective optimization algorithms. To enhance the diversity of the algorithm, providing a technique so that dividing the population into sub-populations would stop somewhere in the middle of the optimization process is highly recommended. Additionally, proposing a new technique to utilize in the MOLPB algorithm to recognize non-dominated solutions instead of the crowding-based technique is advocated.

Keywords
Multiobjective algorithms
Multiobjective evolutionary algorithms
MOLPB
LPB
Learner performance-based behavior algorithm
Optimization
Metaheuristic optimization algorithm