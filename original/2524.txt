Nowadays, artificial neural networks (ANN) are models widely used in many areas; one of these is the classification of urban areas. This work aims to discuss a new framework for the delimitation of functional zones for the city of Naples through deep learning algorithms. More in detail, firstly, a segmentation approach is used to generate the urban zones from the satellite RGB image of interest; then, starting from an extrapolated OSM data, we develop a new labelled dataset used for the training of a convolutional neural network model. Finally, the urban zones are classified with a majority vote procedure. The innovative aspect of this methodology is the use of data provided for different purposes (that is, labelled OSM data) to compensate for the lack of data provided by experts in the field. For the experimentation, we compare two segmentation algorithms (FNEA and selective search) and three CNN models (AlexNet, ResNet-50 and a regularized version of AlexNet), providing good performances in the functional zone classification.

Introduction
A functional zone (FZ) is defined as a â€œform of modern urban developmentâ€ [18]. It describes the characteristics of the soil under analysis and how human activities are organized on that soil. Obviously, different purposes imply different procedures and different FZs to identify different characteristics of data exploited. Recognizing such features is important in many cases, ranging from urban, economic and social planning to agricultural management. However, many of the needed requirements are well supported by the available technology.

Starting from satellite images, the FZ Classification (FZC) consists in finding homogeneous partitions of such images in the sense of functional characteristics and labelling them according to some predetermined classes. Two main issues arise in recognizing an FZ, namely the uncertainty in boundaries determination between contiguous FZs and the correct assignment of functional categories [18]. Regarding the division of homogeneous areas, i.e. identifying the boundaries of functional zones, segmentation algorithms have proven to recognise contiguous regions on images effectively. Once the segments are obtained, a functional class has to be assigned to each of them. The complexity of the problem suggests that one must rely not only on visual characteristics for classification but also on spatial relationships present in data. In this perspective, convolutional neural networks (CNN) constitute the family of neural architectures that allows the more suitable analysis features: these structures consider not only visual information, e.g. form, colour, texture, but also looking for spatial correlations present in the data, result in a powerful tool for solving the problem in exam, i.e. classification of functional zones.

In our work, in particular, we started with an RGB satellite image of Naples, Campania Region, Italy. To proceed, it is necessary to have information on the area in question. The most desirable situation would be to have already a functional classification of the area on which to train the model and evaluate it; however, this is a very hopeful situation because a dataset like this requires a lot of time and a lot of human resources. So, since no functional classification is publicly available for the geographical area of interest, Open Street Map (OSM) data have been used as ground truth for determining functional zones. This choice is dictated by the large coverage information of OSM due to be open data.

Such data have been manipulated through the software QGIS. A segmentation and classification procedure has been designed: in particular, two segmentation algorithms have been explored, i.e. FNEA and Selective Search, while three CNN-based models have been tested for the classification phase, AlexNet, R-AlexNet (a modified AlexNet) and ResNet50. Finally, random points within obtained segments have been labelled through DL models, and, using a majority vote strategy, a predicted classification map for the city of Naples has been obtained.

Related works
The importance of functional zone identification is well known in the literature, as well as the problem of collecting such information. Classifying FZs on a map mainly involves three tasks: the identification of homogeneous areas on the map (i.e. the segmentation), the extraction of the features and their classification [17]. All these require a ground truth that is often difficult to obtain. Particularly in the case, supervised learning frameworks are applied, functional maps are essential not only to train the models but also to evaluate designed pipelines. In many cases, data provided by institutions or providers (such as Points of Interest (POI) data [4, 16]) are processed to generate functional zone maps. However, it is worth underlining that even if the information is available, it may vary from place to place, making it impossible to implement a single procedural scheme. Another option is to use open data from Open Street Map, which provides a partial functional zoning that serves as starting point for the building of functional categories. The great advantage of this approach lies in the easy data availability and in the wide geographical coverage that such service has.

As regards the first of the three tasks, the simplest idea is to divide the map into blocks. Once fixed the dimension of each block, this strategy allows to obtain a grid for the map, where each element can be classified with a label that better describes the features within [10]. Obviously, smaller the blocks, greater the precision in the region boundaries recognition; on the other side, small grid elements mean less information contained in the blocks, and this can lead to poor classification results: for the urban zones classification, the single-pixel information is important but not enough for a correct class recognition, which instead needs for a combination of visual features, object categories (typologies and numbers of objects in the area) and spatial objects to correctly identify the functional zone [16]. A second methodology consists of dividing the map using the road information [4]: the idea is that functional zones are divided in most cases by roads; so, once identified the areas named parcels, the combination of nearby parcels with the same classes will give an FZ. A further approach is to use algorithms for the image segmentation; in the literature, some of the most used segmentation methods, in the presented context, are the multiresolution segmentation algorithms, among which FNEA is a promising one. The multiresolution segmentation often outperforms the above methods by considering the spectral properties and shape heterogeneities [17] of the map image.

As far as classification is concerned, DL models have proven their reliability in dealing with this task; convolutional neural networks are excellent tools for image analysis, allowing to extract not only pointwise information (derived from pixels) but also spatial relations, analysing shapes, contours, objects, etc., present in the input data. One of the commonly used procedures for FZC is to use CNNs to recognize the FZ to which a single point belongs, and by majority voting procedure, to obtain the class of an entire segment. What mainly impacts this strategy is the choice of the segmentation algorithm, the network architecture and the type of images used. For example, [9, 18] use VHR images, FNEA algorithm and a CNN, in particular AlexNet; in [14], selective search algorithm for the segmentation and ResNet50 as CNN model are used, while [8] describes the usage of three ResNets, whose input images are different (Hyperspectral, RGB and LiDAR).

In this work, an RGB image of the city of Naples is used. The reason for this choice is the aim of describing an easy procedure accessible to all: not all types of images are available for all places and are easily accessible by everyone. In addition, the presence of many spectral bands in an image (i.e. satellite images) involves the need for large models and so powerful computers. Nevertheless, our choice of input data does not worsen the results that can be obtained: the usage of only RGB, NIR or Lidar images allows to obtain precision levels comparable to what would be obtained with other types of data [7]. Another important difference between this paper and the literature is the use of OSM data and a detailed description of how to use such data for a general framework, also without the help of domain experts (although it is always recommended if there is the possibility). In conclusion, another difference between this paper and the literature is the use of regularization in the AlexNet with the aim of improving the results.

Framework and methodology
In our work, to get the zoning of the city, the information provided by OpenStreetMap (OSM) in a Shapefile ESRI format has been used. Shapefile ESRI is a popular vector format for geographic information systems: it is a standard for spatial vector data and is used by a wide variety of GIS systems. The shapefiles spatially describe points, polylines, and polygons, which can be used to represent roads, parks, or simply zones. In particular, through the OSM shapefiles, we obtained information about different areas of southern Itaitly. Since the zone of interest in this study is the city of Naples, the information has been filtered to include only information about this area. Finally, shapefiles have been processed by the software QGIS: it is an open-source GIS software that allows to visualize, organize, analyse and represent spatial data.

The Framework The framework takes in input a satellite image and produces, in output, the functional classification of urban areas. The first step consists of the construction of the dataset, whose starting point is the OSM dataset. The second step, the segmentation, divides the input image into parts delimited by internal boundaries, named segments. Then, the classification phase assigns a functional class to unlabelled points; the classification model is trained on a subset of points labelled with their functional category. Finally, the Majority Vote procedure associates a functional category to every segment, produced by the segmentation, based on classified points contained therein.

Construction of the dataset
The procedure described here starts from the OSM dataset and analyses step by step the phases and the relative problems of construction of a new dataset, i.e. the ground truth used in the workflow Sect. 4

Allocation of functional zones
Fig. 1
figure 1
Classification criteria for Naples. Every cloud contains a Functional Zones (FZ) class (Productive Activities, Nature, Services and Residential) and the corresponding OpenStreetMap (OSM) categories

Full size image
Fig. 2
figure 2
Examples of functional zones. On the top the input image of Naples, on the bottom six exemplary windows per functional zone (Productive Activities, Nature, Services and Residential), whose goal is to show the peculiarities of our functional classes

Full size image
In the OSM information, zones are labelled with categories that do not correspond to functional zones. In order to recover an FZ classification map, the aforementioned categories have been associated to the following Functional Classes: Production Activities (PA), identifying all the zones activities of the primary and secondary sectors; Tertiary sector or Services (S), identifying the zones used for activities of the tertiary sector; Nature (N), identifying all nature zones of Naples; Residential (R), identifying the areas used for people houses. In the figures, the information contained in the OSM data (Fig. 1) and some examples of functional zones (Fig. 2) are reported. The choice of discussed areas was made both through literature and based on the territorial conformation of the city. In [18], for example, there are four functional zones: Commercial office zone, Industrial warehouse zone, Urban green zone and Residential zone. In addition to these, other areas are identified by authors who do not belong to any functional zone: Bareland, Water and Road. [4] also uses the same idea, identifying two different areas (the Non-built-up region and the built-up region) tFNEA algorithm and a CNNes: the built-up region is divided into Residential, Commercial, Industrial and Institutional; indeed, the non-built-up region is divided into Agriculture, Green Space, Waterbody and Undeveloped, since the choice of functional zones like Nature and Residential is something very common in literature.

To give an example of the second situation, in the literature, a very used functional area is the industrial zone, as we have seen. This is because in many cities, there are entire areas dedicated to industries. In cities like Naples, this does not happen, and so the small industrial zones present have been merged to the zones intended for the primary field, generating the functional zone Productive Activities. In addition, the data provided by OSM were not suitable for more precise classification, forcing us to opt for four large functional zones.

In addition to these areas, another label has been assigned for large roads such as motorways, secondary roads, railways. Obviously, these are not functional zones, but they are useful for several reasons:

The roads are not part of the functional zones; therefore, points on them must be excluded from the training procedure.

Large roads often divide functional zones, so road-centred images are difficult to label and may cause a deterioration in network learning.

In the random extraction of points within OSM derived data described in Sect. 3.1.2, information related to this last category has been removed since it constitutes noise.

The overlap problem
As already mentioned, the followed approach starts from considering as ground truth a set of â€œpolygonsâ€ coming from the database OSM, whose information was stored in Shapefile ESRI format. Two main issues arise in the use of such kinds of files: the different classes used by OSM with respect to those of our interest (as discussed above) and the overlap of polygons belonging to different files (which therefore provided conflicting information). For the second, we did not consider all the areas belonging to polygons corresponding to different functional zones. As shown in Fig. 3, if there are two or more polygons in the shapefile covering the same area, the intersections are taken off and not considered. In this way, we create new polygons, without overlap, so that we do not lose the information of the rest of the areas.

Fig. 3
figure 3
Procedure for eliminating overlaps by symmetrical difference. This operation allows you to solve the problem by losing only the information on ambiguous areas and not on the surrounding areas

Full size image
The random labelled points
Once obtained the shapefile containing polygons divided into functional zones, random points have been extracted using the QGIS software. It is worth underlining that each random point has the same label of the polygon from which it has been picked. These points may already be used as train points. However, the main issue related to this approach is the low degree of homogeneity, which can strictly affect the accuracy of the classification step (Fig. 5). This problem has been solved by building a new ground truth, characterized by a higher degree of homogeneity obtained by selecting an appropriate segmented image with the FNEA algorithm. Finally, a functional category to each image segment is assigned. The labelling steps are implemented via a majority voting procedure [12] to the segmented image; an example of this approach is given by Fig. 4.

Fig. 4
figure 4
An example of majority voting. In the polygon in the figure, the majority of the points are classified as orange, so the final label of the polygon will be of this colour

Full size image
Fig. 5
figure 5
Example of the non-homogeneity of OSM polygons. As you can see, the green and orange polygons are much larger than the blue and purple ones. This difference is due to a different precision of the data; if not correct, it leads to different ideas of functional zones, generating noise in the procedure

Full size image
At this point, the procedure of random points inside the polygons is repeated, and finally, our dataset points are obtained. The whole procedure of building polygons and extracting the points is described in Fig. 6.

Fig. 6
figure 6
Construction of the training set from OSM shapefile. The first box shows the construction of the polygons, given by the union of the existing polygons with the polygons generated by the lines that represent the roads. Any overlaps are then removed. After the union, we proceed to the classification in functional zones. Using segmentation and labelled OSM polygons, we get the labelled segmentation. The train points are then obtained from this

Full size image
The phenomenon of the class imbalance
One of the main difficulties encountered in the FZ classification on the city of Naples is the phenomenon of class imbalance [5], occurring when some functional areas (as residential ones) are very predominant concerning the other ones. This leads to low accuracy of the classification results, which however can be partially restored by using augmentation techniques [13]. In our case, to avoid this phenomenon, approximately, the same number of random points for each category is extracted.

Creation of train, validation and test set
Before proceeding to the training phase of the network (discussed in 4.1), the dataset containing random points of the ground truth set is divided into three parts, in terms of area of the image, based on the polygons it is composed of: one part of the polygons (and therefore of the respective points) form the test set, corresponding to the 20% of the area, used for network accuracy assessment, another part form the validation set, which amounts to the 10% of the area. The third part constitutes the real train set.

The segmentation
The segmentation procedures used in this work are two: Selective Search and Multiresolution segmentation. The Selective Search, described in [15], initially divides the image into a set of elements by applying the grid-based approach and successively aggregates them based on colour, texture, size and fill similarities. The main parameters of the Selective Search are i) scale, measuring the average size of an image object; ii) sigma, which is the standard deviation of Gaussian kernel used in the preprocessing phase.

The Multiresolution segmentation technique, introduced in [1] and implemented by the eCognition software, initially determines sub-images, corresponding to the image pixels, and iteratively merges them based on local homogeneity criteria. A â€œmerging costâ€, that is called degree of fitting, is assigned to each possible merge. For a possible merge, the degree of fitting is evaluated and, if it is smaller than a threshold parameter, called Scale Parameter, then the merge is implemented. The main parameters of this algorithm are i) scale, measuring the average size of an image object; ii) shape, which measures the colour effect on the segmented image. A remark has to be done regarding the compactness parameter ğ‘Šğ‘: it was set to 0.5, since it little impacts the segmentation results, as reported in [18].

Fractal network evolution approach
The Fractal Net Evolution Approach (FNEA) is a particular segmentation algorithm that falls within the Multiresolution methods. FNEA is a region merging algorithm that aims to construct a network of image objects [2]. The algorithm starts with the initial image units and proceeds towards a pairwise merging of image objects at each iteration. Each image unit (pixel) is initially considered as an individual image object. The merging decision is based on a local homogeneity criterion, i.e. a combination of colour and shape properties (smoothness and compactness), describing the similarity between adjacent image objects. The process terminates when the smallest increase in homogeneity exceeds a user-defined threshold (the so-called Scale Parameter). The scale parameter is used to determine the upper limit in the segmentation process for a change of heterogeneity; in other words, the scale parameter determines the average image object size. In this way, a small scale parameter produces many small objects, while a large one allows more merging, producing few large objects. The segmentation algorithm does not only rely on the single-pixel value but also on pixel spatial continuity.

The deep learning model
As already mentioned, the FZ recognition can be framed as a Multiclass classification problem. Taking a sub-image as input, the aim is to assign a label to its centre based on certain visual criteria. The result will be a set of labelled points that will divide the map into zones. Given the huge amount of data, a Deep Learning approach was chosen to automate the process. In particular, deep learning models can be defined as sets of neural networks organized in different layers, where one or more layers calculate values that will be used by the next layer. The architecture used in the proposed framework is a convolutional neural network (CNN), a neural network composed of weighted convolutional layers. This approach has been chosen since CNNs have been proved to be excellent for the study of 2D images, as they can extrapolate shape and spatial relationships and adaptively learn from them. In this work, two CNN models have been compared: AlexNet, designed by Alex Krizhevsky in collaboration with Ilya Sutskever and Geoffrey Hinton, developed in [6], and ResNet50, presented in [3]. Both networks return four values as output, corresponding to the probability that the image, i.e. its centre, belongs to a given functional zone. We used these two convolutional architectures because, as we mentioned in Sect. 2, is the most used architectures in the literature, and our aim is to describe a new framework for the creation of the dataset (Figs. 7, 8).

Fig. 7
figure 7
The AlexNet Neural Network. The first layer is the input image with 227Ã—227 pixels, while the last is the output. Yellow blocks represent bidimensional convolution layers, the red ones describe the max-pooling operation, while purple represent dense layers. It is a sequential CNN, and all the layers used the ReLU activation function

Full size image
Fig. 8
figure 8
The ResNet50 Neural Network. ResNet50 contains 50 layers: the first layer is the input image with 224Ã—224 pixels, while the last is the output. Yellow blocks represent bidimensional convolution layers, grey the padding operation, red for pooling, while purple represent dense layers. It is not a sequential CNN: it has parallel layers and the plus symbol indicates the add operation applied on the output of the previous layers

Full size image
In addition to standard ResNet50 and AlexNet, a third CNN model, named Regularized AlexNet (R-AlexNet), has been obtained by adding a regularization step to the AlexNet, in order to reduce the overfitting-related issues (Fig. 9).

Fig. 9
figure 9
The regularized AlexNet Neural Network. The first layer is the input image with 227Ã—227 pixels, orange blocks represent regularized bidimensional convolution layers, the red ones describe the pooling operation, while purple blocks represent dense layers. It is a sequential CNN, and all the layers used the ReLU activation function

Full size image
Workflow
The adopted workflow is summarized in Fig. 10. This section discusses in detail the parts constituting the workflow: training of the Neural Network, Classification and FZC generation.

Fig. 10
figure 10
The adopted workflow. Starting from the training set, three different networks are trained, from which three different classifications of random points will be obtained. These points are then used to classify, with a majority vote, the polygons obtained from two types of segmentations, thus obtaining the functional areas for a combination of network and segmentation

Full size image
Neural network training
Taking the train and validation sets that have been prepared as described in 3.1.5, the following procedure to extract the input and the output of the Neural Network model is applied: given a region present either in the training or in the validation set, for each point in such region, a sub-image with a fixed size, called window, is extracted. It is worth highlighting that such an image is centred on the point in question and labelled with the same label as the point. The size of the extracted window may be different from the size required by the input layer of the neural network, therefore, the window is rescaled to the expected size.

This generated labelled image is saved in a new dataset, which is either the training windows set or the validation windows set according to the placement of the original point. After this operation, the neural network is trained on a per-epoch base by adjusting the weights on the training set and evaluating the model on the validation set, with an early stopping procedure to avoid overfitting.

Classification
After the training, the network is used to classify 400 thousand random points spread over the entire area of our interest (Fig. 11). For this scope, the same procedure of window extraction and rescaling applied to the training and validation points described in Sect. 4.1 has been used; then, the windows are classified by the neural network (Fig. 12).

Fig. 11
figure 11
Random points used for classification. All points are taken in such a way as to cover the map evenly and so as not to fall over the segmentation boundaries

Full size image
Fig. 12
figure 12
Example of classification of random points in Fig. 11

Full size image
The same procedure is also applied to the test set in order to obtain the network predictions on these points and compare them with the real labels. Such comparisons allow to evaluate the classification capability of the network.

FZC generation
Segmentation plays a double role: on one hand, the construction of ground truth (see Sect.  3.1.3), on the other hand, the identification of internal regions of an image. The second procedure is similar to the first one: segmented the map and classified the random points within the segments, the majority voting procedure is applied, and the label corresponding to the most present points within the polygon is assigned. An example of a result is shown in Fig. 13.

Fig. 13
figure 13
An example of the final result of the majority voting procedure carried out on a segmentation. In the image, both the roads and the sea have been removed

Full size image
Experiments and results
Experimental set-up
Accuracy analysis
The performance of our framework has been estimated by using the following accuracy metrics: Overall Accuracy (OA), Producerâ€™s Accuracy (PA), Userâ€™s Accuracy (UA), Kappa Index Accuracy (KIA) and F1. To define these measures, we introduce the following quantities:

ğ‘corr the total number of correctly classified elements,

ğ‘test the total number of test elements,

ğ‘tot the total number of elements,

ğ‘class the total number of classified elements,

ğ‘corr(ğ‘–) the number of corrected elements of the i-th class,

ğ‘class(ğ‘–) the total number of the i-th class.

OA is defined as the percentage of points that have been correctly classified over the entire test sample.

KIA measures the reliability of our classification models by comparing their results with the ones produced by a random assignment of functional classes. Mathematically, they can be written as the following:

OA=ğ‘corrğ‘test
(1)
KIA=ğ‘totğ‘testğ‘2testâˆ’ğ‘classğ‘corr
(2)
UA and PA are defined for every class: given a functional class c, UAğ‘ is the ratio between the true positive (tp) and the sum of true positive and the false positive (fp), while PAğ‘ is the ratio between the true positive and the sum of true positive and the false negative (fn). They can be expressed as in the following equation:

UAğ‘=ğ‘¡ğ‘ğ‘¡ğ‘+ğ‘“ğ‘=ğ‘corr(ğ‘)ğ‘class(ğ‘)
(3)
PAğ‘=ğ‘¡ğ‘ğ‘¡ğ‘+ğ‘“ğ‘›=ğ‘corr(ğ‘)ğ‘test(ğ‘).
(4)
Likewise, F1 is given by the harmonic mean of UA and PA; therefore, it is defined by class, like in the following:

ğ¹1ğ‘=21UAğ‘+1PAğ‘=2UAğ‘â‹…PAğ‘UAğ‘+PAğ‘
(5)
In this work, a modified version of these metrics is used, as proposed in [11], in order to take into account the effect of the area size of the classified zones.

All the accuracy measures have been applied over two test procedures: point test and polygon test. The former test estimates the accuracy of our framework by comparing the results of the selected FZC models with the real functional categories associated with a random points sample, while the latter test compares the functional categories applied to a set of polygons.

Parameters selection
Recalling that we have denoted with M and ğ‘Šğ‘  the Multiresolution scale and shape, and with k and ğœ the Selective Search scale and sigma, the parametersâ€ values used in our tests are as follows:

for the Multiresolution segmentation, the scale parameter ranges from 200 to 400 step 100, while the shape parameter ranges from 0.5 to 0.7 step 0.1;

for the Selective Search segmentation, the scale parameter k also ranges from 200 to 400 step 100, while the sigma parameter ranges from 0.5 to 0.7 step 0.1;

for the DL network, the window size N ranges from 160 to 240 step 40.

where N represents the size of the windows, which determines the resolution of the input image with rescaling.

The choice of this range of values is due to mainly visual and conceptual considerations of the problem to be addressed: for example, a scale parameter of less than 200 led to too small segmentations, not corresponding to the functional areas of interest and much more difficult to classify by majority vote, as small polygons involved fewer points within them; similarly, a value greater than 400 involved segments that have within them various functional areas, making classification inaccurate. With the parameters M and k, the motivations are similar, except that they are inverted: indeed, a higher value of M or k generates too small segmentations, while a lower value gives too big polygons.

For the windows size, instead, we chose a range of parameters that allow us to not lose information by the resize phase (with a dimension bigger than 240) but large enough to carry with it the information necessary for classification.

The training and test data
As already described in Sect. 3.1.5, the test data were made in the following way: 20% of the polygons from the ground truth were randomly sampled as test polygons, then a generated subset of random points inside them was considered as test points. The remaining polygons in the ground truth were used to generate the training points for the networks, 10% of those are randomly sampled as validation points.

Hyperparameters
Regarding the neural networks, the adopted training strategy consists of using an adaptive learning rate strategy: when the validation loss does not decrease for 20 consecutive epochs, the learning rate is reduced to 1/10th of the current learning rate, until the learning rate reaches a minimum value, that corresponds to the starting learning rate divided by 1000. For all the models, we set batch size 32, dropout 0.5 and patience 20.

Results
Fig. 14
figure 14
The FZC of Naples and nearby towns through the adopted framework. Each image comes from one of the six combinations of network and segmentation, with the best parameters in terms of overall accuracy. The first column represents the FNEA segmentation, while the second column represents the Selective Search segmentation; the top row represents the AlexNet, the middle row R-AlexNet and the bottom row ResNet50

Full size image
Fig. 15
figure 15
Accuracy results for the model AlexNet for the classification and FNEA for the segmentation on different ranges of parameters. M and ğ‘Šğ‘  are the scale parameter and the shape parameter for the segmentation, respectively, while N is the window size for the DL model

Full size image
Fig. 16
figure 16
Accuracy results for the model based on AlexNet for the classification and Selective Search for the segmentation on different ranges of parameters. k and ğœ are the scale parameter and the shape parameter, respectively, for the segmentation, while N is the window size for the DL model

Full size image
Fig. 17
figure 17
Accuracy results in terms of OA and KIA for the model based on ResNet50 for the classification and FNEA for the segmentation on different ranges of parameters. M and ğ‘Šğ‘  are the scale parameter and the shape parameter, respectively, for the segmentation, while N is the window size for the DL model

Full size image
Fig. 18
figure 18
Accuracy results in terms of OA and KIA for the model based on ResNet50 for the classification and Selective Search for the segmentation on different ranges of parameters. k and ğœ are the scale parameter and the shape parameter, respectively, for the segmentation, while N is the window size for the DL model

Full size image
Fig. 19
figure 19
Accuracy results in terms of OA and KIA for the model based on R-AlexNet for the classification and FNEA for the segmentation on different ranges of parameters. M and ğ‘Šğ‘  are the scale parameter and the shape parameter, respectively, for the segmentation, while N is the window size for the DL model

Full size image
Fig. 20
figure 20
Accuracy results in terms of OA and KIA for the model based on R-AlexNet for the classification and Selective Search for the segmentation on different ranges of parameters. k and ğœ are the scale parameter and the shape parameter, respectively, for the segmentation, while N is the window size for the DL model

Full size image
Figure 14 shows the best results for each configuration. Figures 15, 16, 17, 18, 19, 20 show the accuracy results for several configurations of the following parameters: i) the window size in the CNN models (indicated with N); ii) the FNEA scale (denoted with M) and shape (indicated with ğ‘Šğ‘ ); iii) the Selective Search scale (denoted with k) and sigma (indicated with ğœ). These results show that it is not possible to find the optimal configuration for all the metrics: what arises is that greater M and k (400 for both) does not improve the performances of any of the networks, while a window size in the interval 200â€“240 provides good results, probably because the effect of re-scaling, in this case, fewer impacts the information quality. For this reason, we have analysed the accuracy levels reached by our frameworks for every accuracy measure and we have identified the suboptimal parameters configurations, which are reported in Tables 2, 3, 4, 5, 6, 7.

Table 1 reports the OA results of the three CNN models (AlexNet, ResNet50 and R-AlexNet) for different sizes of the training sets (500, 1000, 2000, 4000, 6000). We observe that ResNet50 proves to be the best model in both the analysis of convergence of the network and the classification problem. For the DL convergence problem, as shown in Table 1, the accuracy stops increasing significantly after 4000 points per class.

For the proposed city, the ResNet50 gives the best values in terms of accuracy metrics (Tables 4 and 5) and of convergence (as shown in Table 1), but the results are not so far from the model R-AlexNet (Tables 6, 7).

Table 1 OA of the CNN models which were trained with a fixed random number of points per class as training points
Full size table
Table 2 Accuracy results of OA, KIA, PA, UA and F1 for the AlexNet + FNEA model, with ğ‘=200, ğ‘€=200 and ğ‘Šğ‘ =0.6
Full size table
Table 3 Accuracy results of OA, KIA, PA, UA and F1 for the AlexNet + Selective Search model, with ğ‘=200, ğ‘˜=300 and ğœ=0.6
Full size table
Table 4 Accuracy results of OA, KIA, PA, UA and F1 for the ResNet50 + FNEA model, with ğ‘=240, ğ‘€=200 and ğ‘Šğ‘ =0.6
Full size table
Table 5 Accuracy results of OA, KIA, PA, UA and F1 for the ResNet50 + Selective Search model, with ğ‘=240, ğ‘˜=200 and ğœ=0.5
Full size table
Table 6 Accuracy results of OA, KIA, PA, UA and F1 for the R-AlexNet + FNEA model, with ğ‘=240, ğ‘€=200 and ğ‘Šğ‘ =0.5
Full size table
Table 7 Accuracy results of OA, KIA, PA, UA and F1 for the R-AlexNet + Selective Search model, with ğ‘=240, ğ‘˜=200 and ğœ=0.5
Full size table
Discussion and conclusions
We point out that the OA results lie in the interval [80%;90%], with a few outliers below 80%; these results are lower than the ones from the literature (for example, FZC approaches presented in [14, 18] achieve an accuracy level overcoming the 90%). This aspect is related to both the high level of complexity of our input images and the absence of manual intervention in our procedure of ground truth construction. Firstly, we observe that the polygonal test produces better results than the points test procedure for most configurations; a probable explanation can be found in the fact that the polygonal procedure can correct the possible errors in the assignment of the functional categories to the test points thanks to the majority vote procedure, which allows not dump the noise effect given by misclassified points. Secondly, we analyse the performances of the classification models. The ResNet50 gives the best values in terms of accuracy metrics (the value of the OA overcomes the 85%, as shown in Tables 4 and 5) and of convergence (as shown in Table 1, the ResNet50 converges for 4000 points) with the parameters ğ‘=240, ğ‘€=200 and ğ‘Šğ‘ =0.5. We highlight the effect produced by introducing the regularization step in the AlexNet architecture, which can improve the best performances of the classical AlexNet. It is evident from the results of OA and KIA reported in Tables 2 and 3 (for the AlexNet) and in Tables 6 and 7 (for the R-AlexNet): the maximum OA and KIA of the AlexNet are, respectively, 0.81136 and 0.73150, while the maximum of OA and KIA of the R-AlexNet are, respectively, 0.85365 and 0.7914. The best parameters for the AlexNet are ğ‘=200, ğ‘€=200 and ğ‘Šğ‘ =0.6; for the R-AlexNet are ğ‘=240, ğ‘€=200 and ğ‘Šğ‘ =0.5.

Finally, the analysis of the results related to PA, UA and F1-score informs us that, thanks to the class balancing in the training set distribution and to our ground truth construction, their values lie in the interval [80%;90%] (in particular, the nature class has the highest accuracy level thanks to its degree of homogeneity). Some limitations of this procedure in our opinions are as follows:

The whole procedure is based on the OSM data: if these data are biased or unavailable, this can influence all the workflow

The choice of functional zones, as already mentioned, was made according to the nature of the area in question (i.e. the city of Naples). For a different area, this choice may not be the optimal one; it is therefore required previous knowledge to identify the best subdivision of functional areas.

In this work, we have presented several AI strategies for the FZC problem, whose performance has been evaluated by using the main accuracy measures. The crucial points of our approach are as follows:

a detailed procedure for the construction of the training set used in the classification step;

the creation of a ground truth, without the assistance of a domain expert.

Future work
As future work, we observe that it would be suitable to adopt incremental learning strategies to compensate for the classification errors due to the heterogeneity of the classes.

In addition, a further step can be a collaboration with domain experts to implement a new procedure for creating a more robust ground truth, increasing the accuracy levels of the classification results. Finally, the approach could also be used in other regions and compare the quality of FZC with those of Naples.

Keywords
Deep learning
Classification
Functional zone segmentation
Convolutional neural networks