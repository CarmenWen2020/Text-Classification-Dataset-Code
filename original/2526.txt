Large-scale knowledge graphs (KGs) play a critical role in question answering over KGs (KGs-QA). Despite of large scale, KGs suffer from incompleteness, which has fueled a lot of research on relation prediction. Since existing researches of relation prediction process each triple independently, the hidden relations which are inherently present can not be captured. Complementarily, to simultaneously capture both entity features and relation features in a given entity’s neighborhood, an entity importance estimation network of attention-based graph embedding is proposed, which consists of the attention-based graph embedding module and the entity importance estimation module. Firstly, the new embedding of an entity from its n-hop neighbor is learned by an attention-based graph embedding module. Then, the learned new embedding is integrated into the entity importance estimation module to find entities of high importance in n-hop neighbors of the central entity. Finally, multi-hop relations are encapsulated and an auxiliary edge of n-hop neighbors is introduced, which realizes the relation prediction task. To the best our knowledge, we are the first to realize KGs-QA while realizing relation prediction, which alleviates the phenomenon of missing relations and the low-precision problem of KGs-QA. On the SQ datasets, the proposed method obtains a high F1 score (49.3%) in 10% missing relation, compared to QASE and MCCNNs with F1 scores of 44.2% and 46.3%, respectively.

Introduction
Question answering (QA) is an important yet challenging natural language processing (NLP) application [1]. The application is a growing research field that employs techniques from Information Retrieval (IR) [2] and Information Extraction (IE) [3] in which a user asks a question phrased in natural language and the system finds the answer automatically. However, in the classical IR (such as web search engines), it is difficult to extract information from extensive result pages; yet the second step is necessary in which the user needs to locate the desired information manually. By contrast, QA systems change how the users interact with the intelligent answering system: the user can now submit a specific question and the system receive a tailored answer. As above mentioned, the design goal of QA system is to generate requested answers automatically [4]. It is worth mentioning that it produces only the concise respond unlike classical web search engines which retrieve a list of matching documents.

QA has been a long-standing research hot spot in NLP field. We note that many possible data sources such as knowledge graphs (KGs) are constructed for QA systems [5, 6]. KGs are the entity and relation directed graphs which contain information needed to answer questions. KGs represent information in the form of triplets which consist of the head entity, the relation and the tail entity [7]. Each triple is referred to as a fact in which a directed relational arrow points from a head entity to a tail entity.

As many real-world data are constructed into KGs such as DBpedia, YAGO and Freebase [8], providing effective and convenient query techniques for end users becomes increasingly important. KGs contain rich structured knowledge where knowledge is encoded to provide direct access for end users via various techniques, one of which is QA over KGs (KGs-QA). KGs-QA is one of the most promising applications to access such structured knowledge. The goal of KGs-QA is to automatically return requested answers from KGs [9, 10]. Most of the proposed methods on the KGs-QA task first synthesize the structured query by parsing the natural language questions and subsequently execute the query on KGs, i.e., traverse KGs to retrieve the factoid answers. For example, neural KGs-QA methods [11, 12] are realized by parsing the natural language question and converting it into a tree-structured query and then executing the structured query on KGs for extracting answers. Other methods [13, 14] first link the mentioned entity with corresponding entity-node in the KGs and then employ another model to map the question to a logical form for extracting answers from KGs.

The performance of KGs-QA systems is hindered by some challenges. For instance, KGs suffer from incompleteness due to the difficulty to enumerate all facts in the real world [15]. Thus, this results in the low accuracy of KGs-QA. Considering Freebase that is the largest open-source KGs [14], Table 1 shows relevant statistics which has an unknown object value for nine commonly used relations: the fraction of subjects of type Person is listed. For example, over 70% of people have no place of birth, over 90% of people have no education, and 75% have no nationality. As Table 1 further shows, coverage for the most frequently searched-for 100K entities is quite low. Furthermore, coverage can be even sparser for less common entities. This problem is not specific to Freebase; analogously, other KGs suffer from the problem due to the inevitable incompleteness and restricted schema [16, 17]. A common remedy is so-called relation prediction: predicting new triples from existing related fact triple sets [18, 19].

Table 1 Percentage unknown of Freebase for some relations that apply to entities of type Person
Full size table
Relation prediction methods are broadly classified as knowledge embedding based methods, path ranking based methods and deep learning based methods. Knowledge embedding based methods map both entities and relations in the KGs to vector representations. For example, knowledge embedding method [20] learns representations of both entities and relations in an embedding space, which is realized by utilizing the link prediction properties of knowledge embeddings to mitigate the KGs incompleteness problem. Another family of methods: path ranking based methods, explicitly model the reasoning process of KGs by using the path as a feature for missing fact prediction. [21] proposes a context-aware path ranking algorithm, which first learns global semantics of entities by word embedding and subsequently leverages the knowledge of semantics to enumerate contextually relevant paths by bidirectional random walk. More recently, researchers are applying deep learning-based methods to knowledge graph embeddings. In [22], convolutional neural networks (CNNs) based method learns more expressive embeddings with a remarkably less number of parameters, so that nonlinear interaction between entities and relations is enabled. However, in the above relation prediction methods, each triple is processed independently; hence, hidden relations can not be captured.

To simultaneously capture both entity and relation features in any given entity’s neighborhood, we introduce a newly emerging embedding model, exploring an entity importance estimation network of attention-based graph for the relation prediction task. In order to learn the new embedding of an entity from n-hop neighbors, an attention-based graph embedding module is introduced. Then, aiming to estimate importance of entity in the neighborhood of a central entity, an aggregation of entity importance estimation scores through predicate-based attention mechanism and flexible centrality adjustment mechanism is introduced, encapsulating multi-hop relations and then introducing an auxiliary edge between n-hop neighbors.

We make the following contributions:

To fully learn knowledge embedding from n-hop neighbors, an attention-based knowledge graph embedding model is proposed, which simultaneously captures both entity and relation features in the n-hop neighborhood of a given entity.

To find entities of high importance in n-hop neighbors of the central entity, an aggregation of entity importance scores through predicate-based attention mechanism and flexible centrality adjustment mechanism is introduced, encapsulating multi-hop relations and then introducing an auxiliary edge between n-hop neighbors.

To the best our knowledge, we are the first to not only realize relation prediction, but also implement KGs-QA. In KGs-QA, if natural language questions can not be answered, we will perform the task of relation prediction that infers latent relations based on existing related fact triples and finally implements KGs-QA.

On the GQ datasets, our proposed method obtains a high F1 score (46.1%) in 10% missing relation, compared to QASE [23] and MCCNNs [24] with F1 scores of 40.1% and 42.8%, respectively.

The remainder of this paper is structured as follows. In Sect. 2, we provide a review of related work. Section 3 presents problem statement and system overview. Our KGs-QA system, which consists of two situations: satisfactory and unsatisfactory, is introduced in Sects. 4 and 5, respectively. Section 6 reports dataset descriptions, implementation details and experimental results followed by our conclusion and future work in Sect.7.

Related work
Related work can be divided into two main fields: the research field about KGs-QA systems and the research field about relation prediction. We briefly review each of these two research fields as follows.

KGs-QA: The past years have witnessed the significant development of KGs-QA systems. KGs-QA systems have a long history, evolving from answering natural language questions via rule based approaches [25], which utilize manually constructed rules to parse the natural language question and then transform it into a structured query. Aiming to reduce traversal space, strong domain knowledge is required to manually design the set of rules in these approaches. In order to overcome the requirement of rules, deep neural KGs-QA approaches that are based on semantic parsing in particular includes [11, 26]. A ground truth query is required in these approaches, but it is often hard to achieve in the real world. To extract the factoid answers from KGs, another recent line of work uses graph nets [27, 28]. However, these approaches depend on heuristics, e.g., shortest paths between the main entity and the factoid answer, most of which are spurious in incomplete KGs. Here, our goal is not just to develop KGs-QA systems, but rather how to use relation prediction technology to alleviate the problem of missing relation of KGs-QA systems.

Relation prediction: As the relation prediction task was introduced as an annual competition in 2008 to the Text Analysis Conference, it has grown in popularity as a research hot spot. Good summaries of standard methods related to this task are given by Deepak Nathani [7]. Most of these knowledge graph embedding methods learn vector representations for entities and relations, obtaining state-of-the-art relation prediction results [29].

ConvE [30] utilizes convolutional filters on 2D reshapings of entity and relation embeddings to capture rich feature interactions between the head entity, relation and tail entity. However, the number of feature interactions that ConvE can capture is limited. InteractE [31] improves upon ConvE by increasing feature interactions. InteractE is a novel knowledge graph embedding method, which alleviates the limitations of ConvE by capturing additional heterogeneous feature interactions.

In this paper, we focus on an entity importance estimation network of attention-based graph embedding to predict missing relations, whereby we try to extract both entity and relation features in a multi-hop neighborhood of a given entity. This is a relatively new method, but there are some related works. The most similar is perhaps Ghorbani M.’s work [32] using a novel embedding model based on CNNs, named multi-layer graph convolutional network (MGCN), to learn an optimal policy for efficiently filling in missing values in KGs. Global relations and transitional features between entities and relations in the KGs can be captured in MGCN. Our relation prediction model is more expressive when compared to other graph embedding methods such as MGCN. As multiple entities in an entity’s neighborhood are learned, our relation prediction model could estimate entity importance to find entities of high importance, which is implemented through the entity importance estimation module.

Another related approach is Dai Quoc Nguyen’s work [6]. Dai Quoc Nguyen introduces the knowledge embedding model, named CapsE, which proposes a capsule network to model triples and then measures the plausibility score of the triple. Conversely, we return all high-confidence object values for a given subject-relation pair. The above mentioned relation prediction technologies can infer hidden relations, which alleviate the phenomenon of missing relations in KGs and obtain the high accuracy of KGs-QA [20].

Problem statement and system overview
In this section, we first define the problem of KGs-QA and then describe system overview.

Problem statement
For answering natural language questions, we assume that the background knowledge is stored in KGs G, consisting of a set of entities E and a set of relations R. Here, each relation 𝑟∈𝑅 is a binary function 𝑟:𝐸×𝐸→{𝑇𝑟𝑢𝑒,False} that indicates (directed) edges of relation r between pairs of entities, and 𝐹⊆𝐸×𝑅×𝐸 is a set of all available KGs facts. A natural language question q is a sequence of words 𝑞𝑥, i.e., 𝑞=(𝑞1,𝑞2,...,𝑞𝑁−1,𝑞𝑁). The problem in KGs-QA involves, given a natural language question q and a main entity 𝑒𝑖∈𝐸 present in the question q, the task is to extract its answer entity 𝑒𝑘∈𝐸 by reasoning on G.

System overview
In this section, we first introduce some background knowledge and give an overview of KGs-QA system.

Binary factoid QA In this paper, we focus on how to answer binary factoid questions. Different from some existing complex questions, we ask questions about a specific property of an entity. For instance, what is the population of Chongqing?

Entity recognition In this paper, the entity recognition task is regarded as the sequence labeling problem, and bi-directional long short-term memory (Bi-LSTM) model is used to predict whether each word in the question is an entity.

Relation link For each QA pair, we extract the entity from the question, then replace the entity in the question by its category c denoted as 𝑄𝑐. The semantic information of 𝑄𝑐 is extracted by the word vector, which is used as the model input. At the same time, all candidate relations are processed with the same model. Finally, 𝑄𝑐 and the candidate relation 𝑟𝑖𝑗 are matched to obtain the most relevant relation.

Fig. 1
figure 1
System overview

Full size image
Fig. 2
figure 2
A toy RDF knowledge graph

Full size image
System architecture Fig. 1 shows a simplified workflow of our KGs-QA system, which consists of two situations: satisfactory situation (namely, existing relations) and unsatisfactory situation (namely, missing relations). For example, in Fig. 2, where was Andy born? A factual answer, “Washington”, is returned by identifying Andy and born in the question and then mapping Andy and born to a triple fact query (𝐴𝑛𝑑𝑦,𝑏𝑜𝑟𝑛 𝑖𝑛,?) over KGs, which is a satisfactory situation. On the other hand, as shown in Fig. 2, if we can not answer such questions, e.g., “Where was Bob born?”, we will perform the relation prediction task. We call this as the unsatisfactory situation, as shown in Fig. 1.

Satisfactory situation: In KGs-QA system, a binary factoid question asks about a property of an entity. A factual answer is returned by identifying the entity and the relation in the question and then mapping the entity and the relation to a triple fact query over KGs, as shown in Fig. 2.

Unsatisfactory situation: If we can not answer such natural language questions, we will perform the task of relation prediction. Apart from entity recognition and relation link, relation prediction is the major issue, which infers latent relations initially hidden, as shown in Fig. 2.

Satisfactory situation
In this section, we discuss the satisfactory situation. More technical details are given as follows.

Entity recognition and entity category
The goal of entity recognition is to obtain the core noun in the question, which corresponds to the entity in the KGs. In this section, we propose the entity recognition algorithm, which utilizes Bi-LSTM to identify the entity. Its overall process is shown in Algorithm 1. Input is the question vector, and output is the labeling sequence. Next, the category of the entity is queried. And then, the entity in the question is replaced with the category c. Finally, we obtain the internal representation: 𝑄𝑐.

figure a
In this section, the entity recognition task is regarded as the sequence labeling problem, and Bi-LSTM model is used to predict whether each word in the question is an entity. For instance, the participle result of a question like this “What is the capital of China?” is “What/ is/ the capital/ of/ China/?/” where the entity is China and the labeling sequence is (0, 0, 0, 0, 1, 0). Note that the part of the output sequence which is 1 represents the entity being sought, otherwise it is not. This process is actually to perform data processing such as word segmentation and dictionary construction on natural language questions, and then put all possible entities as candidates into the candidate entity set.

Bi-LSTM-based model processes the input vector (𝑥0,𝑥1,...,𝑥𝑡−1,𝑥𝑡) separately to obtain the output vector ℎ𝑡 namely ℎ𝑡=[ℎ𝑡→;ℎ𝑡←], where ℎ𝑡→ is the output of the forward network and ℎ𝑡← is the output of the backward network. The output from Bi-LSTM layer is fed into the sigmoid layer for processing, namely 𝑠𝑖𝑔𝑚𝑜𝑖𝑑(ℎ𝑡)=11+𝑒−ℎ𝑡=11+𝑒−[ℎ𝑡→;ℎ𝑡←]. The output vector of the model is 𝑦=(𝑦0,𝑦1,...,𝑦𝑡−1,𝑦𝑡) where t is the length of the output sequence and 𝑦𝑖 corresponds to the marking information of the i-th word in the input question, as shown in Fig. 3. We note that the length of the output sequence is consistent with the input sequence. The model uses mean square error (MSE) as a loss function, with MSE defined as follows

𝐿𝑜𝑠𝑠(𝜔,𝑏)=(1𝑛∑𝑖=1𝑛(𝑧𝑖−𝑦𝑖)2+𝜆‖𝜔‖22)
(1)
where 𝜔 is the weight, b is the bias, 𝑦𝑖 is the predicted value of the model, 𝑧𝑖 is target value, 𝜆 is the hyper-parameter that controls normalization, and ‖𝜔‖22 is L2 regularization.

Fig. 3
figure 3
Bi-LSTM-based entity recognition model

Full size image
After extracting the entity in the question, we query the category of the entity. For example, the category of Beijing and Shanghai is both city. This process is important, which is achieved through a conceptualization mechanism [33]. A corpus-based model, which combines Latent Dirichlet allocation, a widely used topic model and Probase, a large-scale probabilistic knowledge base, is used to conceptualize the entity in the question. It is worth mentioning that Latent Dirichlet allocation topic model can capture the semantic relationship between words, which facilitates the understanding of entities and increases interpretability of entities. The model automatically performs disambiguation on the input question (so that the term “hammer” in what is the headquarter of hammer will be conceptualized to company instead of tool). Based on KGs consisting of millions of concepts, the conceptualization mechanism has enough granularity to represent all kinds of entities in the KGs.

To answer natural language questions, we must transform the question to an internal representation capturing semantics of the question. As an example, “What is the capital of China?” is a natural language question. Firstly, we extract the entity China in the question. Then, we query the category of the entity (namely country). Finally, we represent the question by the template 𝑄𝑐: What is the capital of country?

Relation link
The task of relation link is to link the related relation of the question to the related relation of KGs. This process is similar to the extraction of entity relation. For example, “What is the capital of China?”. After identifying the entity China, the relations of the entity in the KGs are found, such as “alias”, “capital”, “population” and “category”. Finally, the related relation “capital” in the question is linked to the closest relation “capital” in the KGs.

Fig. 4
figure 4
The relational link model based on CNNs

Full size image
In this paper, CNNs are introduced into the relation link task. CNNs use convolution kernel for convolution operation and obtain the most important feature of the sentence through pooling operation. The size of convolution kernel is set according to the experimental requirements, which is generally set to (2,3,4). We note that all operations make CNNs more convenient and advantageous in extracting the overall feature of the sentence.

The semantic information on the question is extracted by the word vector model BERT, which is used as the input of the CNNs-based model. At the same time, all candidate relations are processed separately with the same model. Finally, the internal representation 𝑄𝑐 and the candidate relation 𝑟𝑖𝑚 are matched to obtain the most relevant relation, as shown in Fig. 4. The specific details of relation link can be given in Algorithm 2.

figure b
The relation link task is essentially a measure of relevancy between the relation of the question and the candidate relation in the KGs. It is worth mentioning that the entity of the question is replaced by its category, so that the influence of the entity on the mapping result can be avoided. It can be seen from Fig. 4 that CNNs perform convolution operation on 𝑄𝑐 and the candidate relation 𝑟𝑖𝑚, respectively, to obtain the semantic vectors corresponding to 𝑄𝑐 and 𝑟𝑖𝑚. Finally, the relevancy of the semantic vectors of 𝑄𝑐 and 𝑟𝑖𝑚 is calculated to obtain the relation link result.

During training, the objective function is expressed as

𝐹=max{0,𝑘−𝑆(𝑄𝑐,𝑟𝑖𝑚+)+𝑆(𝑄𝑐,𝑟𝑖𝑚−)}
(2)
where k is constant, 𝑄𝑐 represents the internal representation of the question, and 𝑟𝑖𝑚 represent the candidate relation. 𝑆(𝑄𝑐,𝑟𝑖𝑚+) and 𝑆(𝑄𝑐,𝑟𝑖𝑚−) are positive and negative example scores, respectively.

After CNNs training, the semantic vectors of 𝑄𝑐 and 𝑟𝑖𝑚 can be obtained. Here, cosine similarity is used to calculate the semantic similarity. The calculation method is shown as following

cos(𝜃)=∑𝑛𝑖=1∑𝑗𝑚=1𝑄𝑐𝑖𝑟𝑖𝑚∑𝑛𝑖=1𝑄2𝑐𝑖‾‾‾‾‾‾‾‾√∗∑𝑗𝑚=1𝑟2𝑖𝑚‾‾‾‾‾‾‾‾‾√
(3)
where 𝜃 is the cosine angle between vector 𝑄𝑐𝑖 and vector 𝑟𝑖𝑚, 𝑄𝑐𝑖 is the i-th element of the question semantic vector, and 𝑟𝑖𝑚 is the m-th candidate relation of entity 𝑒𝑖. The cosine distance calculates the cosine angle between two vectors. In the same vector space, the smaller the angle is, the closer the cosine distance is between the two. It is important to note that cosine distance is mainly judged from direction and is not greatly affected by the vector length and the absolute value, which is the advantage of using cosine distance to calculate the similarity.

Entity and relation-based knowledge graph reasoning
In this section, we describe how to find the answer by looking up KGs. Based on entity recognition technology and relation link technology, an entity 𝑒𝑖 and a relation 𝑟𝑖𝑘 in the KGs can be obtained. We note that it is easy to obtain the value of the answer by querying KGs based on 𝑒𝑖 and 𝑟𝑖𝑘. In this example above, let the entity 𝑒𝑖=𝐴𝑛𝑑𝑦 and the relation 𝑟𝑖𝑘=𝑏𝑜𝑟𝑛 𝑖𝑛, as shown in Fig. 2. We easily get the answer 𝑒𝑘 of a question like this “Where was Andy born?”: Washington. Given P(𝑒𝑘|𝑒𝑖,𝑟𝑖𝑘), we aim to find the question sequence maximizing P(𝑒𝑘|𝑒𝑖,𝑟𝑖𝑘). In this example, we note that P(𝑊𝑎𝑠ℎ𝑖𝑛𝑔𝑡𝑜𝑛|𝐴𝑛𝑑𝑦,𝑏𝑜𝑟𝑛 𝑖𝑛)=1.

figure c
Fig. 5
figure 5
Relation prediction for KGs-QA

Full size image
Unsatisfactory situation
In this section, we discuss the unsatisfactory situation. In order to alleviate the phenomenon of missing relations, a relation prediction algorithm is proposed. The goal of relation prediction is to obtain hidden relations between entities. In this section, we propose the relation prediction-based KGs-QA model, which utilizes an entity importance estimation network of attention-based graph embedding to capture both entity and relation features in a given entity’s neighborhood and gets the latent relations among entities. The specific details of relation prediction for KGs-QA can be given in Algorithm 3, which mainly consists of four parts: entity recognition, relation link, relation prediction and entity and relation-based knowledge graph reasoning. There are two aspects of the input: a question phrased in natural language and KGs datasets. Output is the answer (namely, an entity). The simplified architecture of relation prediction for KGs-QA is shown in Fig. 5.

Fig. 6
figure 6
Subgraph of a knowledge graph including existing relations (solid lines) and auxiliary relations (dashed lines)

Full size image
Relation prediction
In this section, the core goal is to find entities of high importance for the relation prediction task. Multi-hop entities in an entity’s neighborhood are learned to infer the relation which is initially hidden. One simple example is a question like this: Where was Bob born? In this example, after finding the entity Bob and the relation 𝑏𝑜𝑟𝑛 𝑖𝑛 in the KGs, we note that KGs suffer from incompleteness where is marked with a red dashed line, as shown in Fig. 6. In this section, we propose an entity importance estimation network of attention-based graph embedding, which consists of the attention-based graph embedding module and the entity importance estimation module. The specific details of relation prediction can be given in Algorithm 4. There are two aspects of the input: entity 𝑒𝑖 and relation 𝑟𝑖𝑘. Output is the inferred triple (𝑒𝑖,𝑟𝑖𝑘,𝑒𝑘). Algorithm 4 consists of three parts: learning of new embedding, estimate of the importance of the entity, and introduction of an auxiliary edge of n-hop neighbors.

figure d
Learning the new embedding for an entity
The goal here is to obtain the new embedding for an entity. Aiming to get the new embedding of an entity 𝑒𝑖, the feature vector of each related triple in 𝑒𝑖’s neighborhood is learned. More specifically, the new embedding of 𝑒𝑖 is the concatenation of entity feature vectors and relation feature vectors. As shown in Fig. 6, for a related triple (Andy, brother, Bob) of an entity Bob, the vector representation of the triple is represented as:

𝑉𝐴𝑛𝑑𝑦,𝐵𝑜𝑏,𝑏𝑟𝑜𝑡ℎ𝑒𝑟−→−−−−−−−−−−=𝜔1[𝐴𝑛𝑑𝑦−→−−‖‖‖𝑏𝑟𝑜𝑡ℎ𝑒𝑟−→−−−−‖‖‖𝐵𝑜𝑏−→−]
(4)
where 𝐴𝑛𝑑𝑦−→−−, 𝐵𝑜𝑏−→− and 𝑏𝑟𝑜𝑡ℎ𝑒𝑟−→−−−− denote vector representations of entities Andy, Bob and relation brother, respectively. Additionally, 𝜔1 represents the linear transformation matrix.

The importance of each related fact triple written as 𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗 is learned. The absolute attention value of the triple is computed as follows:

𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗=𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−)
(5)
where 𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗 indicates the importance of entity 𝑒𝑗’s feature and relation 𝑟𝑖𝑗’s feature to entity 𝑒𝑖, 𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈 is a kind of nonlinearity activation function, 𝜔2 represents the linear transformation matrix, and 𝑉𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−− is the vector representation of a triple (𝑒𝑖,𝑟𝑖𝑗,𝑒𝑗). To make the absolute attention values 𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗 easily comparable across different triples, 𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗 across all choices of entity 𝑒𝑗 is normalized by the softmax function. The relative attention value 𝛽𝑒𝑖𝑒𝑗𝑟𝑖𝑗 is computed as follows:

𝛽𝑒𝑖𝑒𝑗𝑟𝑖𝑗=softmax𝑒𝑗𝑟𝑖𝑗(𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗)=exp(𝛼𝑒𝑖𝑒𝑗𝑟𝑖𝑗)∑𝑒𝑚∈M𝑒𝑖∑𝑟𝑖𝑚∈N𝑒𝑖𝑒𝑚exp(𝛼𝑒𝑖𝑒𝑚𝑟𝑖𝑚)=exp(𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−))∑𝑒𝑚∈M𝑒𝑖∑𝑟𝑖𝑚∈N𝑒𝑖𝑒𝑚exp(𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑒𝑖𝑒𝑚𝑟𝑖𝑚−→−−−))
(6)
where M𝑒𝑖 represents the neighborhood of entity 𝑒𝑖, and N𝑒𝑖𝑒𝑚 represents the relation set connecting entity 𝑒𝑖 and entity 𝑒𝑚. The new embedding of the entity 𝑒𝑖 is represented as follows:

(𝑒𝑖→)𝑛𝑒𝑤==𝜎⎛⎝⎜⎜∑𝑒𝑗∈M𝑒𝑖∑𝑟𝑖𝑗∈N𝑒𝑖𝑒𝑗𝛽𝑒𝑖𝑒𝑗𝑟𝑖𝑗𝑉𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−⎞⎠⎟⎟𝜎⎛⎝⎜⎜∑𝑒𝑗∈M𝑒𝑖∑𝑟𝑖𝑗∈N𝑒𝑖𝑒𝑗exp(𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−))∑𝑒𝑚∈M𝑒𝑖∑𝑟𝑖𝑚∈N𝑒𝑖𝑒𝑚exp(𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑒𝑖𝑒𝑚𝑟𝑖𝑚−→−−−−))𝑉𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−−⎞⎠⎟⎟⎟
(7)
where N𝑒𝑖𝑒𝑗 represents the relation set connecting entity 𝑒𝑖 and entity 𝑒𝑗. The new embedding of entity 𝑒𝑖 is expected to encapsulate more information about the neighborhood of 𝑒𝑖, so multiple head attention mechanisms are introduced. The main principle of multiple head attention mechanisms is that K independent attention mechanisms calculate the embeddings of entity 𝑒𝑖 and then calculate the average of the embeddings of K attention mechanisms. The final embedding for entity 𝑒𝑖 is given as follows:

(𝑒𝑖→)𝑓𝑖𝑛𝑎𝑙=𝜎⎛⎝⎜⎜1K∑𝑘=1K∑𝑒𝑗∈M𝑒𝑖∑𝑟𝑖𝑗∈N𝑒𝑖𝑒𝑗𝛽𝑘𝑒𝑖𝑒𝑗𝑟𝑖𝑗𝑉𝑘𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−⎞⎠⎟⎟=𝜎⎛⎝⎜⎜1 K∑𝑘=1K∑𝑒𝑗∈M𝑒𝑖∑𝑟𝑖𝑗∈N𝑒𝑖𝑒𝑗exp(𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑘𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−))∑𝑒𝑚∈M𝑒𝑖∑𝑟𝑖𝑚∈N𝑒𝑖𝑒𝑚exp(𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(𝜔2𝑉𝑘𝑒𝑖𝑒𝑚𝑟𝑖𝑚−→−−−−))𝑉𝑘𝑒𝑖𝑒𝑗𝑟𝑖𝑗−→−−−⎞⎠⎟⎟⎟
(8)
Estimating importance of entities in the neighborhood of a central entity
Owing to the phenomenon of missing relations in the KGs, the answer could not be retrieved from KGs by identifying the central entity Bob and the main relation 𝑏𝑜𝑟𝑛 𝑖𝑛, as shown in Fig. 6. Knowledge from n-hop neighbors of the central entity Bob is learned to infer the hidden relation. The 1-hop neighbors of the central entity Bob have a number of existing related fact triples, including (Bob, brother, Andy), (Bob, profession, Lawyer), (Bob, date of birth, 1981) and (Bob, wife, Aileen). The goal here is to obtain the high importance entity in 1-hop neighbors of a central entity.

An aggregation of entity importance score through predicate-based attention mechanism and flexible centrality adjustment mechanism is introduced into estimating entity importance, so that aggregating entity importance score instead of entity embedding has the obvious advantage of reducing model parameters. For instance, Andy is the most important entity in the 1-hop neighbors of the central entity Bob, as shown in Fig. 6. That is, in terms of final estimation of importance score, importance score of Andy is the highest.

Entity importance estimation framework is equipped with a scoring network layer and multiple score aggregation layers, followed by a centrality adjustment layer. In this paper, the scoring network is a fully-connected neural network which focuses on how to take in an entity feature vector and return the initial importance score. Aiming to obtain the initial estimation score 𝑠0(𝑒𝑖), the scoring network makes use of input entity features. The scoring network computes the initial score of entity 𝑒𝑖 as

𝑠0(𝑒𝑖)=𝑆𝑐𝑜𝑟𝑖𝑛𝑔𝑁𝑒𝑡𝑤𝑜𝑟𝑘(𝑒𝑖→)𝑓𝑖𝑛𝑎𝑙
(9)
where (𝑒𝑖→)𝑓𝑖𝑛𝑎𝑙 is the input feature vector of entity 𝑒𝑖 as in Equation (8).

The entity importance estimation framework consists of multiple score aggregation layers, each containing a quantity of score aggregation heads, each of which performs score aggregation and attention computation independently. The index of the score aggregation head is marker as (𝜄,𝜅) where 𝜄 represents the 𝜄-th score aggregation layer and 𝜅 represents the 𝜅-th score aggregation head. In each score aggregation head (1,𝜅) of the first score aggregation layer, the initial estimation 𝑠(0,𝜅)(𝑒𝑖) of entity importance scores is received from a separate scoring network. Output from the previous score aggregation layer is used as the input of the following score aggregation layer. 𝜄-th (𝜄≥1) score aggregation layer contains N𝜄 score aggregation heads which independently produce N𝜄 entity importance estimations 𝑠(𝜄,𝜅)(𝑒𝑖). Then, a max-pooling function is executed on N𝜄 score estimations. Estimation of importance scores is given as follows:

𝑠′(𝜄,𝜅)(𝑒𝑖)={𝑆𝑐𝑜𝑟𝑖𝑛𝑔𝑁𝑒𝑡𝑤𝑜𝑟𝑘(𝑒𝑖→)𝑓𝑖𝑛𝑎𝑙if𝜄=0𝑀𝑎𝑥−𝑝𝑜𝑜𝑙𝑖𝑛𝑔[𝑠(𝜄,𝜅)(𝑒𝑖)]  if𝜄≥1
(10)
To directly model relationship between importance scores of neighboring entities, an aggregation 𝑠(𝜄,𝜅)(𝑒𝑖) of these scores is expressed as:

𝑠(𝜄,𝜅)(𝑒𝑖)=∑𝑒𝑗∈ℕ𝑖∪{𝑒𝑖}𝛽(𝜄,𝜅)𝑖𝑗𝑆′((𝜄−1),𝜅)(𝑒𝑗)(𝜄≥1)
(11)
where ℕ𝑖 represents the n-hop neighbor entities of entity 𝑒𝑖, 𝛽(𝜄,𝜅)𝑖𝑗 is a weight parameter between 𝑒𝑖 and 𝑒𝑗 for the 𝜅-th score aggregation heads of the 𝜄-th score aggregation layer. Moreover, in the 𝜅-th score aggregation heads of the 𝜄-th score aggregation layer, the relative attention values is defined as follows:

 𝛽(𝜄,𝜅)𝑖𝑗=exp(𝑓(∑𝜔2(𝑠′((𝜄−1),𝜅)(𝑒𝑖)‖‖𝑟𝑖𝑗−→‖‖𝑠′((𝜄−1),𝜅)(𝑒𝑗))))∑𝑒𝑘∈𝑁𝑖∪{𝑒𝑖}exp(𝑓(∑𝜔2(𝑠′((𝜄−1),𝜅)(𝑒𝑖)‖‖𝑟𝑖𝑘−→‖‖𝑠′((𝜄−1),𝜅)(𝑒𝑘))))
(12)
where f is a nonlinearity activation function, 𝜔2 is a weight vector, 𝑟𝑖𝑗−→ is the vector representation of relation between entity 𝑒𝑖 and entity 𝑒𝑗, and 𝑟𝑖𝑘−→ is the vector representation of relation between entity 𝑒𝑖 and entity 𝑒𝑘.

In addition, the entity importance estimation framework needs flexibility to account for estimation of importance scores on the basis of entity centrality. Score adjustment according to entity centrality is used for the output from the final score aggregation layer. Aiming to make each score aggregation head scaling and shifting, parameters 𝛿(𝜄,𝜅) and 𝜆(𝜄,𝜅) are applied to each score aggregation head. A scaling and shifting centrality, which is applied to 𝜅-th score aggregation head in the final layer L, is given by

𝑐′(𝐿,𝜅)(𝑒𝑖)=𝛿(𝐿,𝜅)∗𝑐(𝑒𝑖)+𝜆(𝐿,𝜅)
(13)
where 𝑐(𝑒𝑖) is the initial centrality of entity 𝑒𝑖.

Based on each score aggregation head in the final score aggregation layer, centrality adjustment of the output from the final score aggregation layer is performed by averaging, and a nonlinearity 𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈 is applied to aggregation of centrality-adjusted scores. And then the final estimation 𝑠∗(𝑒𝑖) is computed as follows:

𝑠∗(𝑒𝑖)=𝐿𝑒𝑎𝑘𝑦Re𝐿𝑈(Averaging  (∑𝜅=1𝐾(𝑐′(𝐿,𝜅)(𝑒𝑖)∗𝑠(𝐿,𝜅)(𝑒𝑖))))
(14)
The central entity Bob has a number of 2-hop neighbors, including (Bob, brother, Andy) + (Andy, born in, Washington), (Bob, brother, Andy) + (Andy, date of birth, 1983), (Bob, brother, Andy) + (Andy, profession, programmer), (Bob, brother, Andy) + (Andy, wife, Amy), (Bob, wife, Aileen) + (Aileen, date of birth, 1986), (Bob, wife, Aileen) + (Aileen, profession, teacher), and (Bob, wife, Aileen) + (Aileen, born in, New York), as illustrated in Fig. 6. As previously mentioned, importance score of Andy is the highest in the 1-hop neighbors of the central entity Bob. Analogously, with entities connected with Andy in 2-hop neighbors of the central entity Bob (namely (Bob, brother, Andy) + (Andy, born in, Washington), (Bob, brother, Andy) + (Andy, date of birth, 1983), (Bob, brother, Andy) + (Andy, profession, programmer), (Bob, brother, Andy) + (Andy, wife, Amy)), we perform an aggregation of entity importance score through predicate-based attention mechanism and flexible centrality adjustment mechanism. We aim to find the most important entity in the 2-hop neighbors of the central entity Bob (namely Washington), as shown in Fig. 6.

Relation prediction based on existing related triples
The relation prediction task is achieved by assigning different relative attention values to entities in the neighborhood. And then, attention is propagated via layers in an iterative way. However, considering the increase in the number of iterations, the contribution of the entity becomes smaller and smaller. A promising solution to the aforementioned problem is relation composition, which is achieved by introducing an auxiliary edge (the dotted line) between n-hop neighbors, in this case n = 2, as shown in Fig. 6.

Our model learns the importance of each related triple from the 2-hop neighbors of the central entity Bob. Based on learning, importance score of Andy is the highest in the 1-hop neighbors of the central entity Bob, and importance score of Washington is the highest in the 2-hop neighbors of the central entity Bob. That is, the importance of (Bob, brother, Andy) + (Andy, born in, Washington) is greater. In our model, the auxiliary edge (the dotted line) between two entities is introduced, as illustrated in Fig. 6. The vector representation of the auxiliary relation is the summation of the vector representations of all existing related triples. In this example, the auxiliary relation can be understood as (Bob, brother, Andy) plus (Andy, born in, Washington), as shown in Fig. 6. Based on these facts, we note that the n-hop neighborhood of a central entity is learned for the relation prediction task.

Table 2 Summary of QA datasets used in the paper
Full size table
Table 3 Summary of KGs datasets used in the paper
Full size table
Entity and relation-based knowledge graph reasoning
In this section, we describe how to find the answer by looking up KGs. Based on entity recognition technology, relation link technology and relation prediction technology, an entity 𝑒𝑖 and a relation 𝑟𝑖𝑘 in the KGs can be obtained. We note that it is easy to obtain the value of the answer by querying KGs based on 𝑒𝑖 and 𝑟𝑖𝑘. In this example above, let the entity 𝑒𝑖=𝐵𝑜𝑏 and the relation 𝑟𝑖𝑘=𝑏𝑜𝑟𝑛 𝑖𝑛, as shown in Fig. 6. We easily get the answer 𝑒𝑘 of a question like this “Where was Bob born?”: Washington. Given P(𝑒𝑘|𝑒𝑖,𝑟𝑖𝑘), we aim to find the question sequence maximizing P(𝑒𝑘|𝑒𝑖,𝑟𝑖𝑘). In this example, P(𝑊𝑎𝑠ℎ𝑖𝑛𝑔𝑡𝑜𝑛|𝐵𝑜𝑏,𝑏𝑜𝑟𝑛 𝑖𝑛)=1.

Experiments
We evaluate KGs-QA system on QA corpus and KGs datasets. (Note that QA corpus and KGs datasets are described in more detail in Sect. 6.1.1.) These experiments serve two goals: (1) to show that KGs-QA system can deliver high-quality results, and (2) that our model provides a natural path toward addressing the problem of missing relations in the KGs.

Experimental settings
Experimental data details
Benchmarks. We use the following benchmarks to evaluate our KGs-QA system and compare our KGs-QA system to previous work:

SimpleQuestions (SQ): SimpleQuestions [34] are a single-relation KGs-QA corpora. This corpus is composed of questions annotated with the corresponding entities from FB15k (Freebase). The QA corpus consists of 101754 questions. Specifically, the whole QA corpus is divided into three categories: the training corpus (71038), the validation corpus (10252) and the testing corpus (20464).The training corpus is used to update the model parameters such as weights and bias; the validation corpus is used to adjust the hyper parameters; the test corpus is used to evaluate the system performance.

WebQuestions (WQ): WebQuestions [35], including 3778 training questions and 2032 testing questions, are collected by Google Suggest API and crowdsourcing. Each question is paired with its own set of answer. All answers are from FB15k. Three quarters of training questions is used as training set, and the rest is used as the validation set.

GraphQuestions (GQ): GraphQuestions [36] are composed of 5166 questions, which are constructed based on FB15k. The dataset presents a high diversity. Another benefit is that it covers a wide range of domains including astronomy, medicine, people, etc. Specifically, the QA corpora consists of 148 domains, 506 classes, 596 relations, 376 topic entities and 3026 words. The whole QA dataset is evenly split into two categories: training set (3445) and testing set (1721). Two-thirds of training set is used as training data, and the rest is used as the validation data.

Question answering over linked data-5 (QALD-5): QALD-5 [37] focuses on multilingual and hybrid QA, which is a benchmark delivered in the fifth evaluation campaign answering over linked data. QALD-5 is composed of 384 questions, which are constructed based on the version of DBpedia 2014. Specifically, the whole QA corpus is divided into two categories: training data (288) and testing data (96). Three quarters of training data are used as training set, and the rest is used as the validation set.

From what has been discussed above, we compare several QA datasets constructed from FB15k and DBpedia 2014 where the statistics are given in Table 2. In addition, for the sake of reproducibility, experiments were conducted on the benchmark KGs, namely FB15k and DBpedia, which have been widely used for evaluating model performance in the KGs-QA task. Table 3 provides statistics of the benchmark KGs used.

Table 4 Experimental results on FB15k datasets. Results of DistMult, ComplEx and ConvE are taken from [30]. *Denotes our new results for MGCN and CapsE
Full size table
Implementation details
In order to keep our model comparable to the comparative models, we keep the same parameter values and experimental environment for our KGs-QA system and the comparison methods. In this paper, the construction and training of KGs-QA system are realized in the following experimental configuration. The experimental platform is installed on Intel Core (TM) i7-8700T, 16G RAM, Windows operating system, and our experiments are run by python 3.7. The setting associated with our model is as follows. For each corpus, the central entity and the main relation are, respectively, obtained by entity recognition technology and relation link technology, which are all for follow-up tasks. The detailed process refers to Sects. 4.1 and 4.2. In relation prediction task, we follow a three-step training procedure. Firstly, we train our attention-based graph embedding model to obtain the new embedding about the graph entities, and then train an entity importance estimation model to find entities of high importance in n-hop neighbors of the central entity. Finally, multi-hop relations are encapsulated and an auxiliary edge of n-hop neighbors is introduced, which realizes the relation prediction task. Adam is used to optimize all the parameters with initial learning rate set at 0.05.

Evaluation metrics
For the relation prediction part, mean rank (MR), mean reciprocal rank (MRR) and Hits@n are adopted to evaluate the performance of the model. MR, MRR and Hits@n are expressed as following:

𝑀𝑅=1𝑁∑𝑖=1𝑁𝑟𝑎𝑛𝑘𝑖
(15)
𝑀𝑅𝑅=1𝑁∑𝑖=1𝑁1𝑟𝑎𝑛𝑘𝑖
(16)
𝐻𝑖𝑡𝑠@𝑛=𝑚𝑁
(17)
where N indicates the total number of questions in the evaluation set, and 𝑟𝑎𝑛𝑘𝑖 indicates the position of the first correct answer in the sorted candidate answer set 𝐶𝑖 for the 𝑖𝑡ℎ question 𝑞𝑖. If 𝐶𝑖 does not overlap with the standard answers 𝑆𝑖 for 𝑞𝑖, 1𝑟𝑎𝑛𝑘𝑖 will be set to 0. m indicates whether the correct answer is in the first n bits of the sorted candidate answer set 𝐶𝑖, counting +1 if so, and 0 if not. It is important to note that lower MR, higher MRR or higher Hits@n mean better model performance.

In order to evaluate the performance of different models, we use the classical metrics precision (written as P ) and recall (written as R). Each question q has a standard answer set 𝑠∗. Given q, our model produces a query which retrieves an answer set s. Thus, precision P and recall R should be defined as following:

𝑃=∣∣𝑠∗∩𝑠∣∣|𝑠|,𝑅=∣∣𝑠∗∩𝑠∣∣|𝑠∗|.
(18)
For simplicity, we also adopt the F1 scores to combine P and R (namely, 𝐹1=2𝑃𝑅𝑃+𝑅). Moreover, the F1 averaged over all evaluation set is introduced, with the averaged F1 defined as follows

𝐹1𝐴𝑣𝑒𝑟𝑎𝑔𝑒𝑑=1𝑁∑𝑖=1𝑁𝐹𝑖
(19)
where 𝐹𝑖 represents the F1 score for the 𝑖𝑡ℎ question 𝑞𝑖.

Effectiveness
To evaluate model performance, we conduct the following experiments. For the relation prediction part, we report MR, MRR and Hits@n. For KGs-QA, we evaluate Average F1 of QA.

Fig. 7
figure 7
Performance of KGs-QA with and without relation prediction as proportion of missing relation, on SQ, WQ, GQ and QALD-5 datasets

Full size image
Fig. 8
figure 8
Performance of QASE, MCCNNs and our work in both configurations on SQ datasets

Full size image
Effectiveness of relation prediction
If KGs-QA gives no reply, which means KGs suffer from incompleteness, we will feed the question into the relation prediction module. We show the improvements of the relation prediction module in Table 4. The results verify the effectiveness of our relation prediction module.

Table 4 compares the experimental results of our relation prediction module with previous state-of-the-art published results, using the same evaluation metrics MR, MRR and Hits@n. Our relation prediction module performs better than its closely similar MGCN [32] and CapsE [6] on experimental datasets FB15k. For instance, compared with CapsE, our module achieves a significant improvement of 47 − 40 = 7 in MR, 0.724 − 0.708 = 0.016 in MRR (which is about 2.26% relative improvement), and 0.774 − 0.762 = 0.012 in Hits@3. Table 2 also shows that the best MR 40, the best MRR 0.724, the best Hits@1 0.603, the best Hits@3 0.774, and the best Hits@10 0.847 are obtained by our relation prediction module. Moreover, our relation prediction module obtains the best MRR 0.724, compared to DistMult [38], ComplEx [39] and ConvE [30] with MRR of 0.654, 0.692 and 0.657, respectively. The experimental results also demonstrate that in terms of MR, MRR, Hits@1, Hits@3 and Hits@10, our module respectively improves 11, 0.067, 0.045, 0.051 and 0.016 compared with ConvE.

Fig. 9
figure 9
Performance of QASE, MCCNNs and our work in both configurations on WQ datasets

Full size image
Effectiveness of question answering over knowledge graphs
Answering performance over proportion of missing relations. Fig. 7 shows how KGs-QA performs after deployment when it obtains question and invokes the relation prediction module where necessary. The average F1 score is computed based on proportion of missing relations. The average F1 scores show a decline over incompleteness of KGs for some relations that apply to entities of some type. We can see that as proportion of missing relations increases, the average F1 score gets smaller and smaller, as shown in Fig. 7. On four datasets, the general trend is a decline in average F1. Compared with KGs-QA no-relation prediction, KGs-QA with relation prediction invokes the relation prediction module to learn hidden relations and improve model performance. As expected, KGs-QA’s average F1 increases significantly when the relation prediction module is invoked. In 80% missing relation, we observe average F1 increase of 21, 17, 18 and 16 points over the no-relation prediction configuration on SQ, WQ, GQ and QALD-5, respectively.

Comparison with state-of-the-art. An intuitive baseline for evaluating QA is to extend existing methods to our setting of KGs-QA through relation prediction. Concretely, we trained both QASE [23] and MCCNNs [24] on the same initial training seed as KGs-QA. Additionally, similar to our work without relation prediction configuration, we performed QA without relation prediction for the two baselines.

To obtain more information, the average F1 for the three systems in both configurations (namely, with relation prediction and no relation prediction) is depicted in Fig. 8. Compared with Fig. 8b, when relation prediction is bypassed, the performance of three systems declines where their performance gets worse over proportion of missing relations, as shown in Fig. 8a. Our work with relation prediction obtains a high F1 score (49.3%) in 10% missing relation, compared to QASE and MCCNNs with F1 scores of 44.2% and 46.3%, respectively. We find that our work beats all other competitors in terms of the average F1, as shown in Fig. 8b. In 10% missing relation, our proposed model improved 5.1% and 3.0% compared with QASE and MCCNNs, respectively.

Fig. 10
figure 10
Performance of QASE, MCCNNs and our work in both configurations on GQ datasets

Full size image
Fig. 11
figure 11
Performance of QASE, MCCNNs and our work in both configurations on QALD-5 datasets

Full size image
We also show the results of QA on WQ in Fig. 9. We compared our work with some state-of-the-art systems by F1 score. Compared with QASE and MCCNNs, the results again show that our work is excellent (the high F1 score), as shown in Fig. 9b. In 60% missing relation, our proposed model improved 3.2% and 1.3% compared with QASE and MCCNNs, respectively, as shown in Fig. 9b. Our proposed method obtains a high F1 score (45.2%) in 10% missing relation, compared to QASE and MCCNNs with F1 scores of 40.7% and 43.9%, respectively. This implies that our work is more effective in QA. In the no-relation prediction configuration, the performance of three systems is nasty where their performance gets worse over proportion of missing relations, as shown in Fig. 9a.

Additionally, we compared with QASE and MCCNNs in GQ in Fig. 10. Figure 10a shows the performance of three systems gets worse over proportion of missing relations. This is because the higher the proportion of missing relation is, the worse the performance of the model is. Compared with Fig. 10a, three baselines in Fig. 10b improve their performance. The major reason is, three baselines in Fig. 10b invoke relation prediction configuration where relation prediction configuration is able to predict hidden relation and then improve the model performance. Our proposed method obtains a high F1 score (46.1%) in 10% missing relation, compared to QASE and MCCNNs with F1 scores of 40.1% and 42.8%, respectively. In 30% missing relation, our proposed model improved 4.9% and 3.3% compared with QASE and MCCNNs, respectively, as shown in Fig. 10b.

Analogously, we also show the results of QA on QALD-5 in Fig. 11. This verifies that our proposed approach is superior to QASE and MCCNNs in terms of the F1 score, as shown in Fig. 11b. Our proposed approach obtains a high F1 score (43.1%) in 10% missing relation, compared to QASE and MCCNNs with F1 scores of 38.9% and 41.9%, respectively. In 20% missing relation, our proposed model improves 5.1% and 1.7% compared with QASE and MCCNNs, respectively, as shown in Fig. 11b. Compared with Fig. 11b, when relation prediction is bypassed, the performance of three systems declines where their performance gets worse over proportion of missing relations, as shown in Fig. 11a.

Table 5 Results compared with existing methods
Full size table
Comparison with existing methods
Table 5 presents results of our work and existing methods on SQ, WQ, GQ and QALD-5. The compared methods are state-of-the-art in separate categories including template-based method [40] and question-answer pairs-based methods [35, 41]. As shown in Table 5, we note that our work outperforms the competitors significantly. Since QATemplate [40] requires query workloads as training data, the performance of QATemplate is not good enough. KBQA [35] is designed to answer the binary factoid questions. Due to the limitation of answering questions, it exhibits limited abilities. QUINT [41] creates the dependency representation based on the existing syntactic parser, and then performs the rewriting by using some predefined rules. Different from them, our main contribution is that we are the first to not only realize relation prediction, but also implement KGs-QA. These results show that our work with relation prediction is indeed effective. We note that the relation prediction module significantly boosts the performance of our work.

Fig. 12
figure 12
Entity recognition and relation link over KGs

Full size image
Fig. 13
figure 13
The visualized attention heat map

Full size image
Table 6 QA over Incomplete KGs with relation prediction
Full size table
Case study
As a newly emerging KGs-QA technique, large-scale KGs have greatly increased the importance and the commercial value of a QA system. In this paper, we focus on how to answer a particular type of binary factoid question. For example, where was Bob born? As mentioned in the previous sections, the analysis process, including entity recognition and relation link, is denoted in Fig. 12 which shows the preliminary work of our proposed KGs-QA system. As previously mentioned, KGs suffer from incompleteness where there is missing relation between Bob and 𝑏𝑜𝑟𝑛 𝑖𝑛, as shown in Fig. 6. Next, we study the case where KGs-QA fails to answer a question. A common remedy is so-called relation prediction: predicting new triples from existing related fact triple sets. Table 6 shows sample test question that was correctly answered using relation prediction. The candidate relations and existing related triples in Table 6 can be found in Fig. 6. (Note that existing related triples are described in more detail in Sect. 5.1.2.)

Let us take a running example as illustration, the attention weights of the user question can be present by the form of heat map, as shown in Fig. 13. It is important to note that our model can capture the attention weights properly. The attention mechanism plays a crucial role in obtaining the attention part of the question while dealing with different answer aspects. The heat map is important that can help us understand which parts of the question are most useful for the selection of the answer. For example, from Fig. 13, we can see that Bob, where and born play a crucial role in answer entity aspect, answer type aspect and answer relation aspect, respectively.

Conclusion and future work
To capture both entity and relation features in an entity’s neighborhood, an entity importance estimation network of attention-based graph embedding is proposed, which is composed of the attention-based graph embedding module and the entity importance estimation module. Firstly, an attention-based graph embedding module is used to learn the new embedding of an entity from its n-hop neighbor. Next, to find entities of high importance in n-hop neighbors, an aggregation of entity importance scores through predicate-based attention mechanism and flexible centrality adjustment mechanism is introduced, encapsulating multi-hop relations and then introducing an auxiliary edge between n-hop neighbors. It is worth mentioning that our work not only alleviates the phenomenon of missing relations but also improves the precision of KGs-QA. However, there is still much work left to do. In future, we intend to extend our method to capture higher-order relations between entities in our attention-based model.

Keywords
Question answering over knowledge graphs (KGs-QA)
Relation prediction
Attention-based graph embedding
Entity importance estimation