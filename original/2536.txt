In electrical load forecasting the prediction of the demand during holidays is a challenging task because of the drift of the demand profile with respect to normal working days. Among holidays, the Easter Week is peculiar because it is a moving holiday: though the weekdays are always the same, it may fall anywhere between March and April. The main contribution of this work is to develop a short-term day-ahead predictor for the load demand during the Easter Week using the Italian data as benchmark. The proposed strategy uses a Gaussian Process (GP) estimator to track the difference between the target Easter Week and an average Easter Week load profile. Differently from usual GP approaches that employ ‘canonical’ kernels, we propose and validate the use of a tailored kernel based on the nonstationary autocovariance of the time series, whose estimation is made possible by the availability of historical load series starting from 1990. On the Italian data the novel approach outperforms both GP methods based on canonical kernels and the forecasts provided by the Italian Transmission System Operator (TSO) Terna. The scarce correlation between the prediction residuals of the novel technique and those of the Terna forecaster motivated the use of aggregation strategies that yielded a further improvement. Indeed, all the main error indexes exhibit a decrease in several tens percent over Terna. The proposed approach is of general validity if, thanks to the availability of historical datasets, the kernel can be tailored to the statistical properties of the time series.

Introduction
The task of energy demand prediction is a crucial ingredient for the national Transmission System Operator (TSO), since it has to know in advance the demanded power so as to ask the producers to generate a secured amount of electricity and maintain the balance within the grid. The management of power systems calls for predictors having different horizons and it is usual to distinguish among long-term predictions and short-term ones. The former ones refer to future times ranging from some months to 20 years ahead and are relevant to the future generation and distribution planning, maintenance schedules, purchasing of generating, transmission and distribution equipment. Because of the long horizon, these predictions strongly rely on the estimation of repetitive patterns such as yearly, weekly and daily seasonalities as well as economic, social and demographic factors. Short-term forecasts refer instead to future times ranging from few minutes to one day ahead. A typical example consists of forecasting the whole 24-hour profile of tomorrow’s electric demand, given load data until today’s midnight and predictors such as tomorrow’s weather forecasts. This kind of predictions are crucial for efficient allocation of power generation and system security. They also have a crucial impact on the energy market as accurate forecasts result in reduction of costs and positive impact on the environment while inaccurate predictions might cause relevant financial losses.

There is an extensive literature dealing with electric load forecasting, where the techniques range from the classical statistical methods, see [1,2,3,4], to more recent machine learning and computational intelligence techniques, see [5,6,7,8,9,10] and [11] for extensive reviews and surveys. One of the challenges of electric load forecasting is given by ‘so-called’ intervention events. According to Box et al. “Time series are often affected by special events or conditions such as policy changes, strikes, advertising promotions, environmental regulations, and similar events, which we will refer to as intervention events” [12]. In the context of load forecasting, holidays and phenomena out of the ordinary such as blackouts and lockdowns can be treated as instances of intervention events. In particular, the different behaviours observed during these periods compared to ordinary ones motivate the classification of days in normal and special ones. During a special day, the typical seasonal and weekly patterns characterizing the normal-day load demand is blurred: the load profile tends to change its shape, typically assuming lower values because of the closure of activities and industries, whose electrical demand usually covers a significant fraction of the overall demand. Therefore, when addressing the prediction of the load demand on special days, it is not safe to rely on the same forecasters used for normal days but, rather, it may be convenient to build ad hoc forecasters.

The Easter Week represents a particular instance of special days, since its date is not fixed but changes every year according to the ‘computus’ [13] and it may fall anytime between March and April. This characteristic enhances the variability of the load profile, since different seasonal phenomena can affect the load depending on the particular date. For instance, in a lot of countries, Daylight Saving Time begins around the end of March and affects the load profile shape by shifting the demand with respect to time [14].

A variety of strategies have been proposed in the literature to deal with the forecast of load demand during the Easter holidays, such as multiple linear regression [15], similar day approach [16], clustering-based methods [17] and artificial neural networks [18]. However, the first approach does not take into account possible nonlinearities while the similar day method, in order to be effective, may require the availability of several years of data as reference. For what concerns the third strategy, the problem of finding an exact way for defining the boundaries that separate the clusters remains open. Finally, artificial neural network algorithms are characterized by long training time and low interpretability.

In this work a novel one-day ahead forecaster, based on Gaussian Process Regression with a ‘custom’ kernel, is developed for the prediction of the load demand during the Easter holidays. Italian country load series, starting from 1990, are used to train the model and validate its predictive capabilities. The proposed approach is compared with the short-term predictor of the Italian TSO Terna and with other Gaussian Process models based on standard kernel choices.

The paper is organized as follows: in Section 2 the dataset is presented and the preprocessing operation is described. In Section 3 the main problem faced in this work is formulated. Section 4 is dedicated to the development of the predictive model. The details of the experiments are given in Section 5, while the results are described in Section 6. Finally, Section 7 summarizes the main findings.

Dataset and preprocessing
The dataset considered in this paper consists of:

the 25-year series (from 1990 to 2014) of quarter-hourly Italian load demand coming from a historical database, whose time plot is displayed in Fig. 1 (top panel).

the 5-year long-time series of quarter-hourly Italian electric load demands (from 2015 to 2019), downloaded from the Transparency Report Platform of Terna available at [19], whose time plot is displayed in Fig. 2 (top panel).

the 3-year long-time series of quarter-hourly forecasts elaborated by Terna (from 2017 to 2019), available as well in [19].

In order to obtain a more stable signal in terms of variance, a commonly adopted preprocessing step consists of a logarithmic transformation of the data [20, 21], which results in the time series displayed in Figs. 1 and 2 (middle panels).

Before extracting the load data associated to Easter days, it is necessary to remove the trend component so that the Easter Week profiles are not affected by differences in the mean which are mainly due to economical and social factors characterizing the different years. For this purpose, the trend component is modelled and then removed from the full log-transformed profile.

In particular, let L(d, q) denote the country load demand at the q-th quarter-hour of the day d, where 1≤𝑞≤96 and d is an integer serial representing the whole number of days from a fixed, preset date (e.g. January 0, 0000) in the proleptic ISO calendar. Then

𝑆(𝑑,𝑞):=ln(𝐿(𝑑,𝑞))=𝑆𝑑𝑒𝑡𝑟(𝑑,𝑞)+𝑇(𝑑)+𝜖
where 𝑆𝑑𝑒𝑡𝑟(𝑑,𝑞) is the detrended log-transformed load demand, T(d) is the trend component of the log-load and 𝜖 is a noise term.

Following the approach proposed in [22], the trend component of the 25-year log-transformed series was estimated using an ideal lowpass filter with bandwidth 1/730 day−1, see the middle panel of Fig. 1.

A linear function is adopted to estimate the trend component in the more recent 5-year dataset. This choice is driven by the fact that the trend term includes, by definition, very low frequency components of the load demand and does not exhibit a ‘more-than-linear’ behaviour in the considered 5-year timespan.

The linear function estimate of T(d) is given by:

𝑇̂ (𝑑)=𝛽+𝛼𝑑
where the parameters 𝛽 and 𝛼 are estimated by means of the Least Squares algorithm. The resulting trend 𝑇̂ (𝑑), shown in red in Fig. 2 (middle panel), is almost constant, as confirmed by the estimate of parameters, 𝛽=3.56 (intercept) and slope 𝛼=9.27×10−8 (slope) (estimate ±2.23×10−8 SE). The associated detrended log-load time series

𝑆𝑑𝑒𝑡𝑟(𝑑,𝑞)=𝐿(𝑑,𝑞)−𝑇̂ (𝑑)
is shown in the bottom panel of Fig. 2

Finally, let  be the set of all the Easter Week days within the range 1990-2019. Then:

𝑌(𝑑,𝑞)={ missing ,𝑆𝑑𝑒𝑡𝑟(𝑑,𝑞), if (𝑑∉) otherwise 
Notice that, in this work, a window of 5 days is associated to each Easter Week, in particular from the Thursday before to the Monday after (Easter Monday). According to this convention, Table 1 summarizes the dates of Easter holidays of the years 1990–2019.

Table 1 Easter holiday dates: years 1990-2019
Full size table
In Fig. 3, the superimposition of all the quarter-hourly Easter Week detrended log-load demand profiles is shown. The plot highlights the high repeatability of the normalized Easter time series over the years, even though each profile has its own features.

Fig. 1
figure 1
Italian quarter-hourly electric load demand from 1990 to 2014: raw time series, log-transformed time series with trend estimated via low-pass filter (middle) and detrended log-transformed time series (bottom)

Full size image
Fig. 2
figure 2
Italian quarter-hourly electric load demand from 2015 to 2019: raw time series, log-transformed time series with estimated linear trend (middle) and detrended log-transformed time series (bottom)

Full size image
Fig. 3
figure 3
Detrended log-load demands of the Easter Weeks from 1990 to 2019 and corresponding average profile (black)

Full size image
Problem statement
Let define 𝑡=1,…,480 as the quarter-hour within an Easter-Week, e.g. 𝑡=1 is the 1st quarter-hour of Thursday and 𝑡=480 is the 96𝑡ℎ quarter-hour of Monday.

The goal of this paper is to build a predictor 𝐿̂ (𝑡) for the Easter Week load demand 𝐿(𝑡). Notice that

𝐿̂ (𝑡)=exp(𝑌̂ (𝑡)+𝑇̂ (𝑡))
where 𝑇̂ (𝑡) is the prediction of the trend and 𝑌̂ (𝑡) is the prediction of the detrended log-load demand over the Easter Week. Letting 𝑌¯(𝑡)=𝐸[𝑌(𝑡)] and 𝑌̃ (𝑡)=𝑌(𝑡)−𝑌¯(𝑡), the detrended log-load demand during the Easter Week 𝑌(𝑡) can be written as

𝑌(𝑡)=𝑌¯(𝑡)+𝑌̃ (𝑡)
where 𝑌¯(𝑡) is the average profile, common to all years, while 𝑌̃ (𝑡) is a shift term specific of the current year.

Leveraging the remarkable repeatability of 𝑌(𝑡), see Fig. 3, the key idea is to model the ‘average’ Easter profile 𝑌¯(𝑡) and then develop a recursive short-term strategy to ‘track’ the shift 𝑌̃ (𝑡).

Let

𝑌̂ (𝑡|𝜏)=𝐸[𝑌(𝑡)|𝑌(1),…,𝑌(𝜏)],𝜏<𝑡
denote the mean squared estimate of Y, given 𝑌(1),…,𝑌(𝜏). Assuming that an external estimate of the average profile, e.g. based on historical data, 𝑌¯̂ (𝑡) is available, then 𝑌(𝑡|𝜏) can be estimated as

𝑌̂ (𝑡|𝜏)=𝑌¯̂ (𝑡)+𝑌̃ ̂ (𝑡|𝜏)
where 𝑌̃ ̂ (𝑡|𝜏) is an estimate of the current year’s shift.

Then, the Easter forecasting problem amounts to solving the following one-day ahead five prediction problems. Find

𝑌̃ ̂ (𝑡|𝑘96),𝑘96+1≤𝑡≤(𝑘+1)96
for the following values of k:

1.
𝑘=0 (Thursday)

2.
𝑘=1 (Friday)

3.
𝑘=2 (Saturday)

4.
𝑘=3 (Sunday)

5.
𝑘=4 (Monday)

It goes without saying that, for 𝑘=0, one has the trivial solution 𝑌̃ ̂ (𝑡|0)=0, 1≤𝑡≤96. It is immediate to see that, from Thursday to Sunday, the objective is predicting tomorrow’s 96 load shifts, based on the data up to midnight of the current day.

Model estimation
The most straightforward approach for modelling 𝑌¯(𝑡) is to compute the average of the available Easter Week profiles for each quarter-hour of each day, that is

𝑌¯̂ (𝑡)=1𝑛𝑦∑𝑖𝑌𝑖(𝑡)
where 𝑛𝑦 is the number of years considered and 𝑌𝑖(𝑡) is the detrended log-transformed observations of the Easter Week of the 𝑖−𝑡ℎ year. The average profile estimated over the years 1990-2019 is displayed in black in Fig. 3 together with the Easter Week observations of the same years.

The ‘shift’ term 𝑌̃ (𝑡) is obtained by subtracting the average profile 𝑌¯̂ (𝑡) from 𝑌(𝑡).

In Fig. 4 the shift profiles 𝑌̃ 𝑖(𝑡), obtained by subtracting the average profile 𝑌¯̂ (𝑡) from each 𝑌𝑖(𝑡), 𝑖=2015,…,2019, are displayed.

Fig. 4
figure 4
Easter Week detrended log-load demands shifts from 1990 to 2019

Full size image
In order to derive a short-term predictive model it is assumed that the shift time series of Fig. 4 are realizations of a zero Gaussian process plus noise, that is:

𝑌̃ (𝑡)=𝑓(𝑡)+𝜂
𝑓(𝑡)∼(0,𝑘(𝑡,𝑡′))
where 𝜂 is an independent identically distributed Gaussian noise with variance 𝜎2 and 𝑘(𝑡,𝑡′)=𝐸[𝑓(𝑡)𝑓(𝑡′)] is the autocovariance function, also called ‘kernel’, that completely specifies the Gaussian process and encodes all the prior informations. The choice of the kernel is crucial in order to optimize the results of regression or classification problems and the literature offers a great variety of possible choices, see [23] for an exhaustive overview.

In this work, instead, a different approach is pursued. Rather than picking up a canonical kernel from the literature, the availability of extensive historical data is exploited in order to directly estimate the autocovariance 𝑘(𝑡,𝑡′) of the shift profiles.

This implies that 𝑘(𝑡,𝑡′)=𝑟̂ (𝑡,𝑡′), where the sample autocorrelation (that coincides with the autocovariance because the stochastic process has zero mean) is given by

𝑟̂ (𝑡,𝑡′)=1𝑦𝑓−𝑦0+1∑𝑖=𝑦0𝑦𝑓𝑌̃ 𝑖(𝑡)𝑌̃ 𝑖(𝑡′),
(1)
with 1≤𝑡≤480, 1≤𝑡′≤480 and where 𝑦0 and 𝑦𝑓 denote the initial and final year used to estimate the autocorrelation.

Once 𝑟̂ (𝑡,𝑡′) has been computed, the so-called kernel matrix

𝐾=[𝐾]𝑖𝑗∈ℝ480×480,𝐾𝑖𝑗=𝑟̂ (𝑡𝑖,𝑡𝑗)
can be displayed as a bidimensional surface, see Fig. 5, where the sample autocorrelation was computed with 𝑦0=1990 and 𝑦𝑓=2014.

In order to assess the potential advantages of employing a kernel which is estimated directly from the data, we carry out a comparison with Gaussian Process models based on standard kernels. For this purpose, two alternatives are considered: squared exponential and periodic, whose mathematical expressions are shown in (2) and (3) respectively:

𝐾𝑠𝑞𝑖𝑗=exp(−(𝑡𝑖−𝑡𝑗)22𝑙2),
(2)
𝐾𝑝𝑒𝑟𝑖𝑗=exp(−2sin2(𝜋|𝑡𝑖−𝑡𝑗|/𝑝)𝑙2),
(3)
The term l is a hyperparameter to be tuned which denotes the length-scale of the bell-shaped kernel. Small values are typical of functions that can change quickly, while large values characterize functions that change slowly.

In the periodic kernel expression the period p is set equal to 96 in order to catch the daily periodicity.

Fig. 5
figure 5
Sample autocovariance surface computed on the Easter shift profiles over the years 1990-2014

Full size image
Before proceeding with the solution of the Easter forecasting problem, it is convenient to recall the representer theorem for Gaussian processes [23].

Theorem
[23] Let 𝑦(𝑡)=𝑓(𝑡)+𝜖(𝑡), where 𝑓(⋅) is a discrete-time zero mean Gaussian Process with 𝐸[𝑓(𝑡)𝑓(𝑡′)]=𝑘(𝑡,𝑡′) and 𝜖(𝑡)∼𝑊𝑁(𝜎2) a white noise independent of 𝑓(⋅). Consider the problem of estimating 𝑓(𝜏), given the knowledge of n observations {𝑦(𝑡̃ 𝑖)} sampled at times {𝑡̃ 𝑖}, 𝑖=1,…,𝑛. Then the optimal (mean square) estimate is given by the conditional expectation

𝑓̂ (𝜏)=𝐸[𝑓(𝜏)|𝑦(𝑡̃ 1),…,𝑦(𝑡̃ 𝑛)]=∑𝑖𝛼𝑖𝑘(𝜏,𝑡̃ 𝑖)
where

𝛼𝐾̃ 𝑦=(𝐾̃ +𝜎2𝐼)−1𝑦=[𝐾̃ ]𝑖𝑗∈ℝ𝑛×𝑛,𝐾̃ 𝑖𝑗=𝑘(𝑡̃ 𝑖,𝑡̃ 𝑗)=[𝑦(𝑡̃ 1)…𝑦(𝑡̃ 𝑛)]𝑇
Proof
By a well known formula for the conditional expectation of jointly normal random variables

==𝐸[𝑓(𝜏)|𝑦(𝑡̃ 1),…,𝑦(𝑡̃ 𝑛)]=[𝐸[𝑓(𝜏),𝑦(𝑡̃ 1)]…𝐸[𝑓(𝜏),𝑦(𝑡̃ 𝑛)]]𝑉𝑎𝑟[𝑦]−1𝑦=[𝑘(𝜏,𝑡̃ 1)…𝑘(𝜏,𝑡̃ 𝑛)](𝐾̃ +𝜎2𝐼)−1𝑦◻
In view of the representer theorem, the prediction 𝑓̂ (𝜏𝑘)=𝑌̃ ̂ (𝜏𝑘|𝑘96), 𝜏𝑘=𝑘96+1,…,(𝑘+1)96, 𝑘=1,2,3,4, is given by the following formula:

𝑓̂ (𝜏𝑘)=∑𝑖=1𝑘96𝛼𝑘𝑖𝑘(𝜏𝑘,𝑖)
(4)
with

𝛼𝑘Δ𝑘𝑦𝑘=(Δ𝑘+𝜎2𝐼)−1𝑦𝑘=[Δ𝑘]𝑖𝑗∈ℝ𝑘96×𝑘96,Δ𝑘𝑖𝑗=𝑘(𝑖,𝑗),1≤𝑖,𝑗≤𝑘96=[𝑦(1)…𝑦(𝑘96)]𝑇
It is worth noting that Δ𝑘 are submatrices of the full kernel matrix K. In the procedure, the noise standard deviation 𝜎 is a hyperparameter that needs to be calibrated.

Of course, the formula (4) has to be computed for 𝑘=1,…,4, namely for each target Easter day from Friday to Monday.

The last open question is how to forecast the Thursday quarter-hourly detrended log-transformed profile 𝑌(𝜏0).

Three possible strategies are:

Average Profile (AP)

Similar Day (SD)

Last Year (LY)

The AP strategy consists of predicting the detrended log-load of Thursday as the average of the detrended log-load of Thursday of the Easter Weeks of the previous years.

𝑌̂ (𝜏0)=𝑌¯(𝜏0)
The SD strategy consists of predicting the detrended log-load of Thursday as the detrended log-load of Thursday of a similar Easter Week, that satisfies two conditions:

Easter falls in a day of year that is closest to the one of this year’s Easter.

The two Easters are not separated by the Daylight Saving Time switch.

𝑌̂ (𝜏0)=𝑌𝑆𝐷(𝜏0)
The LY strategy consists of predicting the detrended log-load of the Easter Thursday as the detrended log-load of the Easter Thursday of the previous year.

𝑌̂ (𝜏0)=𝑌𝐿𝑌(𝜏0)
The prediction of the trend component 𝑇̂ (𝑡), 𝑡=1,…,480, for the target Easter Week profile is taken as a constant value equal to the trend estimated up to the day before the Easter Week starts. A way to further improve the performances of the existing methods is given by the adoption of aggregation strategies: in fact, when different predictors generate uncorrelated residuals, their combination can lead to a more accurate forecast. In the literature, different aggregation techniques are explored (see [24,25,26,27]), with results proving simple average method as an effective and robust technique in order to reduce the variance of the forecasts ([25,26,27]). For these reasons, after evaluating the correlation between the residuals of the proposed model and the Terna ones, the aggregation between our Easter forecasts and the Terna forecasts was computed and assessed. Let 𝑖,𝑖=1,…,𝑚, denote a set of prediction methods and 𝐿̂ 𝑖(𝑡) the corresponding load demand forecasts generated by 𝑖. For the considered case, two aggregation strategies are used:

Simple average aggregate prediction: in this case the aggregated prediction is given by the arithmetic mean of the m base forecasts.

𝐿̂ Avg(𝑡)=1𝑚∑𝑖=1𝑚𝐿̂ 𝑖(𝑡)
Constrained Least Squares (CLS) aggregate prediction: the aggregated prediction is computed as a linear combination of the base forecasts, where the weights are updated recursively for each day of the target Easter Week load:

𝐿̂ CLS(𝜏𝑘)=𝐿̂ CLS(𝜏𝑘|𝑘96),𝜏𝑘=𝑘96+1,...,(𝑘+1)96
𝐿̂ CLS(𝜏𝑘)=∑𝑖=1𝑚𝜃𝑖,𝑘𝐿̂ 𝑖(𝜏𝑘)
In particular, the weight vector 𝜃 is obtained by solving the following constrained optimization problem for each 𝑘=1,...,4:

𝜃=argmin𝜃∑𝑡=1𝑘96(𝐿(𝑡)−∑𝑖=1𝑚𝜃𝑖,𝑘𝐿̂ 𝑖(𝜏𝑘))2
s.t.𝜃𝑖,𝑘≥0,∀𝑖
∑𝑖∈𝜃𝑖,𝑘=1
The constraints on the weight vector prevent instability phenomena that may ensue from the collinearity of the experts and guarantees a more interpretable model as well [24].

Experimental validation setup
The performances of the proposed method were evaluated over the Easter Weeks of years 2017, 2018 and 2019 and compared to the ones of the two Gaussian Process models with traditional kernels and to the ones of Terna forecaster. The performances of the predictors were evaluated using the Mean Absolute Percentage Error (MAPE), the Root Mean Square Error (RMSE), and the Mean Absolute Error (MAE), each one on both quarter-hourly and daily data.

𝑀𝐴𝑃𝐸𝑅𝑀𝑆𝐸𝑀𝐴𝐸𝑀𝐴𝑃𝐸𝑑𝑎𝑖𝑙𝑦𝑅𝑀𝑆𝐸𝑑𝑎𝑖𝑙𝑦𝑀𝐴𝐸𝑑𝑎𝑖𝑙𝑦=100480∑𝑑∈e∑𝑞=196∣∣∣∣𝐿(𝑑,𝑞)−𝐿̂ (𝑑,𝑞)𝐿(𝑑,𝑞)∣∣∣∣=∑𝑑∈e∑96𝑞=1(𝐿(𝑑,𝑞)−𝐿̂ (𝑑,𝑞))2480‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾√=∑𝑑∈e∑96𝑞=1∣∣𝐿(𝑑,𝑞)−𝐿̂ (𝑑,𝑞)∣∣480=1005∑𝑑∈e∣∣∣∣𝐿𝑑𝑎𝑖𝑙𝑦(𝑑)−𝐿̂ 𝑑𝑎𝑖𝑙𝑦(𝑑)𝐿𝑑𝑎𝑖𝑙𝑦(𝑑)∣∣∣∣=∑𝑑∈e(𝐿𝑑𝑎𝑖𝑙𝑦(𝑑)−𝐿̂ 𝑑𝑎𝑖𝑙𝑦(𝑑))25‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾⎷=∑𝑑∈e∣∣∣𝐿𝑑𝑎𝑖𝑙𝑦(𝑑)−𝐿̂ 𝑑𝑎𝑖𝑙𝑦(𝑑)∣∣∣5
where e is the test set of Easter Week days and 𝐿daily and 𝐿̂ daily are respectively the daily averages of electric load observations and of associated forecasts:

𝐿𝑑𝑎𝑖𝑙𝑦(𝑑)=196∑𝑞=196𝐿(𝑑,𝑞),𝐿̂ 𝑑𝑎𝑖𝑙𝑦(𝑑)=196∑𝑞=196𝐿̂ (𝑑,𝑞)
For each test year, the Easter Week observations of the previous years were used for the training phase, while the calibration of the hyperparameters was performed through cross-validation. In particular, for each model and for each hyperparameter, a list of 1000 candidate values ranging from 10−3 to 103 was generated and for each combination the corresponding candidate model was validated on the year preceding the test one, while the training was carried out using the remaining historical data. The chosen set of hyperparameters for each model was the one yielding to the lower validation RMSE. The results of the calibration procedure are summarized in Table 2.

Table 2 yperparameters tuning: cross-validation results of each Gaussian Process model on each validation year
Full size table
Performances
A comparison between the proposed Gaussian Process model with custom kernel and the traditional GP models with squared exponential and periodic kernels was carried out, for each test year, for 𝑘=1,2,3,4, that is from Easter Friday to Easter Monday. The results are shown in Tables 3, 4 and 5, while the associated time plots are displayed in Figs. 6, 7 and 8.

Fig. 6
figure 6
Easter Week of 2017, from Friday to Monday: data versus GP forecasts and residuals

Full size image
Fig. 7
figure 7
Easter Week of 2018, from Friday to Monday: data versus GP forecasts and residuals

Full size image
Fig. 8
figure 8
Easter Week of 2019, from Friday to Monday: data versus forecasts and residuals

Full size image
The results show that, for all the performance indexes, the novel custom kernel approach definitely outperforms the methods based on the traditional kernels. Adopting the traditional kernels increases the performance indexes with respect to the custom one of at least 60% in 2017, 69% in 2018 and 3% in 2019. Observe however that the similar performance between the custom kernel and the squared exponential one is restricted to 2019, when the customized kernel underestimates the load during Easter Day, which is associated to the lowest load during the Easter Week and therefore has the greatest impact on a percentage measure such as MAPE. On the other hand, according to RMSE and MAE, the standard kernels produce an increase in the indexes of at least 12%.

In the following, a comparison between the proposed model and the Terna predictor is done. Depending on the strategy selected for predicting the Easter Thursday load, 3 forecasters are considered and labelled as follows:

𝐺𝑃𝐴𝑃: Gaussian Process with Average Profile Thursday forecast.

𝐺𝑃𝑆𝐷: Gaussian Process with Similar Day Thursday forecast.

𝐺𝑃𝐿𝑌: Gaussian Process with Last Year Thursday forecast.

The results for the three test years are summarized in Tables  6,  7,  8. In the 2017 test year, all the proposed strategies performed better than Terna, with percentage improvements up to 15%, 24% and 19%, respectively for quarter-hourly MAPE, RMSE and MAE, achieved by the 𝐺𝑃𝐿𝑌 forecaster. In the daily framework, the 𝐺𝑃𝐴𝑃 predictor outperformed all the other models achieving improvements up to 62-63% for all indexes. This is due to the fact that the quarter-hourly residual of the 𝐺𝑃𝐴𝑃 on Thursday exhibits positive values in the peak from 13:00 to 18:00 and negative ones until 20:00, see Fig. 9, leading to a compensation of the daily error when upsampling the forecast. The prediction of the 2018 Easter Week load demand, shown in Fig. 10, is characterized by smaller percentage improvements (10% for MAPE, 11% MAE, 3% for RMSE) achieved in the quarter-hourly framework by the proposed model with the Average Profile strategy on Easter Thursday, while in the daily case the prediction of Terna still achieves the best performances. In the 2019 test year, shown in Fig. 11, the 𝐺𝑃𝑆𝐷 strategy brings improvement with respect to Terna on almost all indexes, with improvements of 17%, 8%, 15% respectively for quarter-hourly MAPE, RMSE, MAE and 11% for both daily MAPE and MAE, while the daily RMSE score is slightly worse (1%) than Terna one.

Fig. 9
figure 9
Easter Week of 2017: data versus forecasts and residuals

Full size image
Fig. 10
figure 10
Easter Week of 2018: data versus forecasts and residuals

Full size image
Fig. 11
figure 11
Easter Week of 2019: data versus forecasts and residuals

Full size image
In Fig. 12 we show the scatter plot of Terna’s residuals against ours in the three test years. As confirmed by the correlation coefficients, that range from 0.07 to 0.64, there is not a strong correlation between the two predictors. This suggests that, especially for the test years 2017 and 2019, where the correlation is below 0.32, an improvement might be achieved by aggregating the two predictors. The performances of the simple average aggregated predictors, namely 𝐴𝑣𝑔(𝐺𝑃𝐴𝑃), 𝐴𝑣𝑔(𝐺𝑃𝑆𝐷), 𝐴𝑣𝑔(𝐺𝑃𝐿𝑌) and the constrained least squares aggregated ones, namely 𝐶𝐿𝑆(𝐺𝑃𝐴𝑃), 𝐶𝐿𝑆(𝐺𝑃𝑆𝐷), 𝐶𝐿𝑆(𝐺𝑃𝐿𝑌), are reported in Tables 9, 10 and 11. A sample of the corresponding time series is displayed in Figs. 13, 14 and 15. The aggregated predictors show a substantial improvement with respect to the Terna benchmark predictor in all the considered indexes (e.g. up to 28% for quarter-hourly MAPE and 49% for daily MAE in 2017).

Fig. 12
figure 12
Scatter plots between Terna residual and proposed model residuals on the three test scenarios. The Pearson correlation coefficients indicate a weak correlation between the proposed models errors and Terna forecast error

Full size image
Fig. 13
figure 13
Easter Week of 2017: data versus aggregated forecasts and residuals

Full size image
Fig. 14
figure 14
Easter Week of 2018: data versus aggregated forecasts and residuals

Full size image
Fig. 15
figure 15
Easter Week of 2019: data versus aggregated forecasts and residuals

Full size image
Table 3 Year 2017, Easter Friday to Easter Monday: forecasting performances of the proposed Gaussian Process with custom kernel compared to traditional kernel choices. Between brackets, the percentage variation with respect to the custom kernel approach
Full size table
Table 4 Year 2018, Easter Friday to Easter Monday: forecasting performances of the proposed Gaussian Process with custom kernel compared to traditional kernel choices. Between brackets, the percentage variation with respect to the custom kernel approach
Full size table
Table 5 Year 2019, Easter Friday to Easter Monday: forecasting performances of the proposed Gaussian Process with custom kernel compared to traditional kernel choices. Between brackets, the percentage variation with respect to the custom kernel approach
Full size table
Table 6 Year 2017: forecasting performances and percentage variation with respect to Terna (between brackets)
Full size table
Table 7 Year 2018: forecasting performances and percentage variation with respect to Terna (between brackets)
Full size table
Table 8 Year 2019: forecasting performances and percentage variation with respect to Terna (between brackets)
Full size table
Table 9 Year 2017: aggregated forecasts performances and percentage variation with respect to Terna (between brackets)
Full size table
Table 10 Year 2018: aggregated forecasts performances and percentage variation with respect to Terna (between brackets)
Full size table
Table 11 Year 2019: aggregated forecasts performances and percentage variation with respect to Terna (between brackets)
Full size table
Conclusions
Predicting the electrical load during the Easter Week is a challenging task mainly because, depending on the year, these special days may fall anywhere between March and April. In this paper we showed that the availability of a rich set of historical time series can be exploited to boost the performance of a Gaussian Process (GP) predictor. More precisely the forecasting problem was reformulated as that of predicting the difference between the actual load profile and the average load profile observed during the Easter Week. The key novelty is the use of historical data in order to estimate the time varying autocovariance of the loads throughout the Easter Week. In this way, instead of using traditional kernels, such as the squared exponential and the periodic ones, a customized kernel is obtained, that is tailored to the specific statistical properties of the signal to be predicted. When compared with these two kernels, the new customized kernel exhibited a clear superiority.

Three alternative long-term techniques were experimented for predicting the quarter-hourly profile of Thursday, the first day of the Easter Week, namely ‘Average Profile’, ‘Similar Day’ and ‘Last Year’ forecasts.

The proposed strategies, tested over 2017-2019 yielded a substantial improvement in terms of MAPE, RMSE and MAE on both the quarter-hourly and the daily framework with respect to the benchmark predictor, i.e. the TSO one. The uncorrelatedness between the residuals of our and Terna forecasters suggested that a further improvement was achievable by a simple aggregation of the predictions, which indeed brought to a more than 25% drop in the main error indexes.

Concerning the potential extensions to other problems and the inherent limitations of the proposed method, two comments are in order. First of all, the approach is of general validity and could well be applied to other forecasting problems, offering a valuable and effective alternative to classical GP kernels. Examples may include predictions of vehicular traffic, sales, gas consumption, during holiday periods such as Christmas and Summer holidays. At the same time, it must be observed that the proposed approach requires the availability of a historical dataset rich enough to reliably estimate a time varying autocovariance and this may not be the case in many circumstances.

Keywords
Load forecasting
Energy demand
Intervention events
Kernel methods
Gaussian process regression