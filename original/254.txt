Current research on next generation network design has highlighted the challenges to be overcome before applications and services that require high capacity, low latency, and improved reliability can become the norm. Transport networking has a vital role to play in the delivery of the new and innovative applications and services that fully harness the next generation network architectures. The novel Software Defined Networking (SDN) paradigm has been successfully utilized to enhance networking solutions, for example, data center and enterprise networks, and current research is focused on the broader implementation of SDN-based networking to carrier core and access networks, including wireless mobile backhaul. This paper provides a review of the current status of research into SDN-Based Wireless Mobile Backhaul Architecture and the challenges that have been identified in the literature.

Previous
Next 
Keywords
Transport network

Wireless

Mobile

Software Defined Networking

Challenges

Wireless mobile backhaul

1. Introduction
The Software Defined Networking (SDN) paradigm has emerged over the past decade and it is now poised to be fully adapted to transport networks (ITU-T, 2018a). New technologies that improve performance, reliability, and resiliency are constantly being developed and introduced to meet the rapid growth in data usage (Cisco, 2019, GSMA, 2020) and the requirement for low latency and improved reliability. The next generation of cellular networks, including 5th Generation (5G) mobile cellular communications, will introduce improved Quality of Experience (QoE) and Quality of Service (QoS) outcomes that aim to meet consumer and service provider expectations (Agiwal et al., 2016, Bouras et al., 2017). The next generation cellular networks are seen as the enablers for the networked society (AB, 2015) where ubiquitous high speed data connections will be available to connect consumers and devices to the network. The growth in the machine to machine communications and the anticipated addition of many hundreds of millions of devices have led to the term Internet of Things (IoT) being adopted to highlight the growth and changes that should occur as the next generation cellular networks are rolled out (Juniper, 2015a, Shah and Yaqoob, 2016, Mehmood et al., 2017).

The research and development of new technologies and systems for the Radio Access Network (RAN) has introduced transport network related challenges that need to be overcome to ensure that the next generation cellular networks operate as expected and facilitate growth in new and innovative applications and services (Bartelt et al., 2017). With earlier generation cellular networks, it may have been possible, in some circumstances, to over provision the transport network, thereby removing the need for a sophisticated transport network design and the use of technologies that improve the operation of transport networks. Over provisioning the transport network ensures that it does not become a bottleneck between the core and RAN, however, the total cost of ownership for transport networks has increased as cellular networks have expanded, leading to the adoption of cost reduction strategies. The introduction of small cells, pico cells and ultra-dense small cell networks (UDN) (Ge et al., 2016) have created architectural, provisioning, and optimization challenges for future transport network designs (Bercovich et al., 2015).

Transport networks that include multi-vendor legacy equipment with proprietary protocols, capabilities, and features have been designed, installed, configured, and operated statically by vendor specific management systems. This mode of operation is not expected to efficiently adapt to new challenges, including the introduction of 5G, IoT, and driverless vehicles (Juniper, 2020, Guevara and Auat Cheein, 2020). A new transport network architecture with mechanisms supporting real-time adaptation and flexibility are required. The SDN paradigm supports the real-time multi-dimensional convergence of transport network resources and topologies necessary to meet the demands expected for next generation transport networks (Li et al., 2017, Rostami et al., 2017, Costa-Perez et al., 2017, Öhlén et al., 2016). The optimization criteria of the transport network operational policies may be changed in real-time by utilizing SDN-enabled control and management planes (ONF, 2016a, Hurtado-Borràs et al., 2015). A standardized, logically centralized SDN control plane with global knowledge of transport resources and topology will reduce the network operations complexity and permit real-time adaptation to shifts in traffic load.

A key difference between SDN and legacy networking is that SDN utilizes an extensible software-based paradigm while traditional networking utilized a discrete hardware-based model, e.g., switches, routers and gateways. The SDN paradigm is more flexible, providing network operators with increased control of traffic flows, ease of management, network traffic visibility and improved efficiency. The three-layer SDN architecture includes an application layer that is linked to the SDN controller via a northbound interface. The northbound interface provides application programming interfaces (API) to the applications and services residing in the application layer. The SDN control layer receives instructions from the application layer and relays them to the infrastructure layer via the southbound interface. By employing virtualization, network operators can abstract functionality and capability in a manner that improves operational efficiency and permits a flexible implementation of network elements.

In a mobile cellular network, backhaul networks are used to connect radio base stations to aggregation nodes and then to the core network. The wireless portions of the transport network are an important component of 5G cellular networks (Fiorani et al., 2014). In order to deal with the significant growth in demand for more data (Cisco, 2019, Khatibi et al., 2017, Sharma et al., 2018) and a limited radio resource (Hu and Qian, 2014), the radio resource utilization should be optimized. The RAN consists of cells of different sizes ranging from femto to macro cells. The RAN is monitored and optimized by the network operator to provide reliable connections for user traffic. When a cell capacity limit is reached, cell-splitting is required; however, the increasing number of cells, each supporting a significantly higher throughput, impacts the backhaul network. Reliable and cost-effective backhaul is an important requirement when transporting traffic to the core network.

Wireless Mobile BackHaul (WMBH) networks play a fundamental role in the next generation of cellular networks. Backhaul networks are a bottleneck that may limit throughput and affect latency. Optical fibers are the preferred technology for backhaul networks as they provide high capacity, reliability, and low latency. However, in the RAN, as cell-splitting and smaller cells are deployed, the cost of installing optical fiber becomes prohibitive. The solution to this problem is to deploy wireless transit links as part of the WMBH network. The technologies that might be used in this role include millimeter Wave (mmWave), which is a short-range, high-frequency transmission technology, and satellite links (Niephaus et al., 2015). The noisy wireless environment, which may be degraded by weather conditions or other interference, hardware failure, new buildings, or moving objects, could suffer from reduced transmission reliability that results in congestion during busy periods. Hence, WMBH should be flexible, resilient and able to convey the user data flows optimally. The candidate SDN-enabled WMBH network architectures for the next generation cellular networks should be able to support dense and ultra-dense small cell deployments with high traffic volumes over a distribution region whilst providing flexible resourcing and the capability to support a wide range of network layouts. mmWave meshed SDN-enabled WMBH, which creates a flexible path across the mesh network, is a suitable candidate for dense urban scenarios owing to its ultra-wide bandwidth, short range and flexible low cost deployment (Sakaguchi et al., 2017a, Sakaguchi et al., 2017b, Andrews et al., 2014).

This paper provides a literature review of the WMBH networking from topic-related published papers, the Open Network Foundation (ONF), International Telecommunication Union Telecommunication Standardization Sector (ITU-T) standards, and other published sources. The paper also provides an introduction to SDN and the state of the art for SDN-enabled WMBH architectures and identifies research gaps together with possible solutions. The key contribution of this paper is to investigate the application of the SDN paradigm to WMBH networking. The field of SDN-enabled WMBH networking is not mature and important challenges remain to be addressed. We summary the current research works from three aspect, the transport network architecture, the control architecture and the WMBH architecture. Finally, the paper outlines the current challenges and reviewed the possible solutions in SDN-based WMBH.

The rest of this paper is organized as follows. Section 2 outlines the transport network architecture and components. The SDN control approach for mobile transport networks is presented in Section 3. Section 4 provides a review of SDN-enabled WMBH architectures. Section 5 summarizes the SDN-enabled WMBH research challenges and reviews possible solutions. Concluding remarks are provided in Section 6.

2. Transport network architecture
The term transport network refers to the telecommunications infrastructure used to transport digital messages or signals from one point in the network to another. For network operators, the term transport network can be associated with an overlay network that is used to provision and manage point-to-point connectivity between network end-points.

2.1. Transport network concepts
The transport network can be described by defining the associations between points in the network. As described in ITU-T (2000a) and ITU-T (2016a), in order to simplify the description, the functional architecture of a transport network utilizes the concepts of layering and partitioning in a scheme that permits a high degree of transport network recursion. With the aid of layering and partitioning (Fig. 1), a transmission network can be decomposed into a number of independent transport layers, where the layer networks can, in turn, be separately partitioned in a way that reflects its internal structure or how it will be managed.

•
Layering: Layering is the decomposition of a transmission network into a number of independent transport layers. The characteristics of each of the transport layers describe its generation, transport, and termination (ITU-T, 2000a). Between the adjacent layer networks there exists a recursive client/server relationship where the client refers to the signal being carried and the server refers to the layer network providing its transport. Any particular server layer could itself be a client of another server layer.

•
Partitioning: Partitioning recursively divides a larger transport layer (sub)network into separated subnetworks that are interconnected by links.

Transport layer networks are classified broadly into two classes of layer networks, including path layer networks and transmission media layer networks (ITU-T, 2000a). Each specific path layer network can have independent topology, and the setup of paths across a specific path layer network may be done independently from that of paths in other path layer networks.


Download : Download high-res image (276KB)
Download : Download full-size image
Fig. 1. Transport network layering and partitioning (ITU-T, 2000a).

A transmission media layer network can be decomposed into section layer networks and physical media layer networks. The section layer network may be divided into specific section layer networks, and a physical media layer network is actually a physical transport medium such as fibers, metallic wires or radio frequency channels that provide services to the upper adjacent section layer network. The physical media layer network may be decomposed into specific physical media layer networks to represent, for instance, wave division multiplexing (ITU-T, 2000a).

Transport networks can be segmented into domains to facilitate administration, policy considerations, and the inherent heterogeneity of transport networks (ITU-T, 2012). A domain is typically established by a network operator according to policies that determine management and control arrangements. It incorporates network devices and entities typically in a geographic region that fulfill operational requirements. The membership criteria of a domain express the differing administrative, trust relationships, addressing schemes, infrastructure capabilities, survivability techniques and control functionality distributions.

2.1.1. Flow and connection
A flow is a stream of data that has common criteria such as packet header values, relative time position or frequency and is manipulated and forwarded based on a same set of rules/policies. In transport network a connection is a transport network entity over which flows of data are transported. Flows are unidirectional and can be identified at any layer using match fields associated with that layer. Within a transport connection entity, flows can be manipulated and forwarded to a subset of ports of the connection entity using flow identifier (which is the case of connectionless flow forwarding) or without flow identifier (which is the case of connection-oriented flow forwarding.)

Administration and Maintenance (OAM) flows are used to monitor the status and performance of an individual connection associated with the data flows. Based on the OAM information, the forwarding of an individual flow could also be modified, however the status and performance of the forwarding of an individual flow within a connection is not monitored. The OAM flow are processed within the network equipment only.

2.2. Transport network architecture components
According to ITU-T, 2000a, ITU-T, 2016a and ITU-T (2018b), the transport network architectural components, depicted in Fig. 2, can broadly be divided into five groups: topological components, transport entity, transport information entity, transport processing function, and transport reference point.

2.2.1. Topological components
The topological components provide an abstract description of a network, which is the topological relationship between sets of similar reference points. There are four topological components identified in ITU-T (2016a) including the “layer network, the subnetwork, the link, and the access group”. The relationship between sets of forwarding points within a layer network, encompassing layer network, subnetwork, link, and access group (Fig. 1) is an example. The network topology that forms the transport network is in the plane that transfers the characteristic information, and is represented by the largest subnetwork in the transport plane as shown in ITU-T (2016a).

2.2.2. Transport entities
Transport entities, configured within topological components, encompass the forwarding relationship, subnetwork transport entity, link connection, differentiated connection, multipoint transport entities, access transport entities, transfer association and trail. The transport entities provide the means to transfer information across the transport network between the reference points (ITU-T, 2016a).

2.2.3. Transport information entities
Transport information entities are constructed by a network to convey messages between a sender and receiver (ITU-T, 2016a). They are the combination of client information with appropriate labels and overheads. Transport information entities exist as one of three forms of information including client information, adapted information and characteristic information.

2.2.4. Transport processing functions
Transport processing functions are the processes that describe the behavior of the entity and may be described as a universal algorithmic state machine and other stored information that is used in the processing function. Examples of transport processing functions include adaptation, (trail) termination, layer processor and forwarding.

2.2.5. Transport reference point
Transport network reference points are formed by the binding between the input and output ports of transport processing functions and/or transport entities (ITU-T, 2016a), e.g., the binding of adaptation and termination architectural components is called an access point.

2.3. Transport network topology for next generation mobile networks
Fig. 3 exhibits a typical cellular transport network divided into three segments (Fiorani et al., 2014). In a mobile cellular network the small cell transport segment aggregates the traffic between the small cells, the UDN (Ge et al., 2016), and the first aggregation segment which is the access ring where the macro cell base stations are located. The small cell transport network connects the logical endpoints between the access ring and the small cells and may utilize a combination of wireless, optical and copper media and a tree, ring or mesh topology or any combination of the three (Monti et al., 2012). In a range of scenarios, wireless based solutions are more attractive for the transport network bearers because of the high cost of deploying wired links (Baldemair et al., 2015, Gao et al., 2015). Over short distances, copper-based transmission technologies can offer data rates of up to a few Gbps thereby providing a reasonable option in the areas where copper-based infrastructure has already been installed. Of the three, energy-efficient, low latency and reliable optical transmission technologies can provide the highest data rates over long distances with the longest lifetime before the fiber needs to be replaced. The access rings aggregate the traffic from the macrobase stations and small cell networks to the metro ring. There may be any number of metro rings depending on the network topology and scale. The metro rings are connected to the core backbone transport nodes. The core backbone transport network contains service edge nodes that are used to interconnect different network domains. Dense Wavelength Division Multiplexing (DWDM) centric networks, offering inherent high capacity from tens to hundreds of Gbps that consume relatively low energy, are a favored approach for the metro ring segments. Between the access and metro rings, switching can be carried out using active optical elements, such as Wavelength Selective Switches (WSS) and Reconfigurable Optical Add–Drop Multiplexers (ROADM) (Öhlén et al., 2013, Zhang et al., 2013).


Download : Download high-res image (272KB)
Download : Download full-size image
Fig. 3. Typical high level topology of a mobile transport network (Fiorani et al., 2014).

3. SDN-enabled mobile transport network control architecture
Fig. 4 (Fiorani et al., 2014) shows an example of a multi-layer SDN controller for a cellular transport network. In Fig. 4, the small cell transport controller manages the resources in the dedicated small cell transport network and provides the upper transport controller with an abstract and simplified view of this network segment. The upper transport controller is in charge of managing the transport resources and providing connectivity services to the other controllers or applications. Controllers at the same level interact via the orchestrator, which possesses an abstract and simplified view of the resources and performs ongoing end-to-end provisioning and optimization according to predefined policies.

Multi-layer SDN controllers for next generation mobile transport network architectures that utilize a common DWDM centric access and metro network, including dedicated small cell transport networks, can efficiently perform dynamic resource sharing and Network Function Virtualization (NFV) to achieve high resource utilization, high user traffic volume and throughput whilst reducing deployment costs. NFV can dynamically be used to provide baseband processing, evolved packet core functionality, packet aggregation, and caching in response to the transport requirements. Resources that can be shared are optical fibers, using Wavelength Division Multiplexing (WDM) and wavelength channels, using either time division multiplexing or dynamic wavelength allocation, and spectrum, using time, frequency or code division multiple access. NFV provides the ability to dynamically push network functions at a desired time (busy hour, for instance) from a location that is closer to the users or congested network segments so that a portion of the traffic requests can be served locally during the congestion periods (Fiorani et al., 2014).

3.1. SDN architecture components
The SDN architecture is based upon the separation of functionality into three layers called the Application, Control and Infrastructure Layers. The SDN architecture layers interact through Application Programming Interfaces (API) that are known as the Northbound and Southbound interfaces (ONF, 2016a). The SDN paradigm provides an open virtualized architecture that removes the dependence on single-vendor networking solutions. Fig. 5 shows an SDN architecture where the SDN controller is the core element and it implements a conceptual client server context with the forwarding and data processing devices. The SDN controller, overlay applications and network services can be implemented using an orchestration–virtualization approach. The SDN controller is an entity that delivers transport flow control and management to overlay client services and applications by controlling and usually abstracting the underlying physical resources. An SDN controller can be physically or logically implemented by using centralized or distributed computing technologies, with or without redundancy. Its fundamental task is to provide the real-time multi-dimensional convergence of changing transport network resources for varying topologies and transport service demands. The policy optimization criteria used in the network may also be changed in time (ONF, 2016a). It is this programmatic functionality that has made SDN attractive to network operators.

The underlying data plane, including infrastructure resource groups as shown in Fig. 5, is managed and controlled by the SDN controller using management-control functions through a data-controller plane interface (D-CPI). At the same time, though an Application-Controller Plane Interface (A-CPI), the controller offers services to its Application Layer clients by virtualizing and orchestrating the underlying resources and exposing a resource group, known as a Virtual Network (VN), to each client. An SDN controller can have both non-virtual and virtual networks in the scope of its management-control continuum (MCC) (ITU-T, 2018a, ITU-T, 2018b). Each of the SDN Controller Plane Interfaces (CPI) presents a reference point for traffic and namespace isolation, policy enforcement and information hiding (ITU-T, 2018a, ONF, 2016a).

3.2. SDN resource and service management
SDN controllers can use resources and invoke services offered by subordinate or peer SDN controllers or non-SDN entities. In this manner, the SDN controller, acts as a service-consuming application. It associates with other SDN controllers and non-SDN management-control entities in hierarchical or peer arrangements within or across administrative domains. From the perspective of an SDN controller, it may have multiple clients and multiple servers, and this is referred to as a client server relationship within the SDN architecture. A particular client is served by an information set, e.g., a virtual network relating to that client as well as management-control functions. This is known as the client context. Similarly, when a server is used by an SDN controller, it is supported by an information set relating to that server as well as management-control functions and this is known as the server context. Between any two adjacent SDN controllers in a hierarchy, the server context of the client role SDN controller has a 1:1 relationship with the client context of the server role SDN controller. The virtual network offered by a server controller to a client controller is stored in a server context and the server context is used to identify the server that supplied the resources. The server assembles resources for a given client and an assembly of resources is identified by a client context in the server controller that is communicated to the client (ITU-T, 2018a).

The SDN controller establishes and maintains the state of the underlying resources to serve its clients according to an optimization policy. In this process, the SDN controller participates as the active entity in a feedback control loop (ONF, 2016a), as depicted in Fig. 6.

3.3. SDN client request management
The client invokes service request actions that prompt management-control functions, which are translated into the state of the underlying resources. The actions may vary client to client and service to service (clients come and go, and also as each client modifies its service demands). The actual state of the resources, including load, can change due to failure, repair status, and administrative actions. The resource state is polled on an ongoing basis or updated asynchronously using a notification message. The controller reconciles the desired and actual states according to the optimization policy, which may also change over time, and modifies the state of the underlying resources accordingly. The optimization policy may include the capability to create (or request the creation of) new resources, to scale or migrate existing resources. State convergence may include negotiation with neighboring domains. If the desired and actual states cannot be reconciled within the policy bounds, the SDN controller issues an exception, either immediately by rejecting a client request or as a notification during ongoing operation. In addition to its core feedback control function, an SDN controller may invoke arbitrary supplementary functions, support arbitrary collections of additional features, any number of interfaces and protocols, any number of applications of arbitrary type and complexity, resources of any category according to its particular deployed purpose (ONF, 2016a).

3.4. SDN for transport network control and management
Fig. 7 illustrates a high-level view of transport networks (ITU-T, 2012) including four component planes — Data Communication Network (DCN), Control Plane (CP), Management Plane, and Transport Plane (TP) with multiple Layer Networks (, …). It also shows the interactions between the component planes. The DCN depicted in this figure offers distributed management communications and distributed control plane communications such as transportation of signaling and routing information (ITU-T, 2010).

From the transport network control and management perspective, the management and control functions are essentially the same, and this is reflected in the ITU-T G.7701 (ITU-T, 2018b) definition of the MCC concept. According to this concept, the management and control functions are grouped into one set of MCC functions. There are MCC functions that directly manage transport network resources and MCC functions that manage other MCC capabilities. The management functions include support for Fault, Configuration, Accounting, Performance and Security management (FCAPS) as described in ITU-T (2000b). The initial configuration of the transport network resources, assigning the SDN-controlled transport functionality and configuring the associated SDN controller(s) requires the management entity. This management entity configures policies defining the scope of control given to the SDN application, and monitors the performance of the system. In the application layer, the management function typically configures the interactions according to client server contracts and Service Level Agreements (SLAs). The management function also configures the security associations that allow entities to safely communicate among each other. Additional management functions include equipment inventory, software upgrade capability, fault isolation, performance optimization, energy efficient operations, and autonomic management (continuous adaptation to the network status). SDN overlay application support for transport networks includes MCC functions that provide transport resources, energy efficiency management and transport network services such as connection and routing control related management functions. The SDN controller management function implements the FCAPS capabilities. The MCC concept and its relationship with transport resources is depicted in Fig. 8 (ITU-T, 2018b), whereby the management and control functions operate on transport resources and receive resource state information feedback. The management and control functions themselves require management, depicted as the administration role functions. In a conventional transport system, the transport resources are controlled and managed by the Transport Resource Management entity together with the Operations Support Systems (OSS) and the Network Management Systems (NMS).


Download : Download high-res image (270KB)
Download : Download full-size image
Fig. 7. Relationship between architectural plane components (ITU-T, 2012).

This legacy control scheme can be completely or partially replaced by the novel SDN paradigm. A hybrid or cooperative mode is also possible, which facilitates both legacy and SDN control and management. The SDN controllers are managed by an SDN controller management overlay application which can provide a network wide traffic control and management capability. In the cooperated mode, transport network resources may be partitioned into subsets that have legacy or SDN management applications. Once a resource subset is assigned to a particular MCC instance (e.g., Automatically Switched Optical Network (ASON) control (ITU-T, 2012)), other MCC instances (e.g., SDN controller) cannot modify these resources. This partitioning provides scalability and addresses administrative and business needs.


Download : Download high-res image (303KB)
Download : Download full-size image
Fig. 8. Management Control Continuum with SDN (ITU-T, 2018b).

3.5. Multi-domain and multi-layer networks
In practice, to achieve efficient scalability and management, transport networks could be partitioned into multiple administrative domains. In this scenario, depicted in Fig. 9, a hierarchical structure of SDN controllers including a parent controller and multiple child controllers can be used to support the multiple domains. In this mode of operation, the parent controller acts a network orchestrator.

In some multi-provider scenarios where the administrative domains have independent transport resource infrastructure, either physical or virtual, the relationship between administrative domain controllers is not necessarily hierarchical. In this scenario, the level of transport resource information which is exposed to the internal domain controller differs from the level of transport resource information exposed to the external domain controller, and collaboration among domain controllers will be required to enforce services across domains.


Download : Download high-res image (251KB)
Download : Download full-size image
Fig. 10. Hierarchical SDN structure and resource views in a two-domain transport network.

A hierarchical SDN structure can also be applied in a multi-layer networking implementation. Fig. 11 depicts the scenario in which the transport domains are administratively separate and operate internally with different switching layers. The switching layers are controlled by an SDN controller. The parent SDN controller is a multi-layer networking integration controller that coordinates multiple child SDN controllers, e.g., the integration of optical and IP domains under a common control layer. In Fig. 11, the parent controller has access to topology and resource information for the server domains and can coordinate actions across both domains.

3.6. Multi-layer within a single domain
Multi-layer networking also occurs within a single administrative domain where internal cross-layer adaptation is needed. In Section 3.5, different switching technologies are used for the two domains (e.g. IP and optical), each of the domains (or both) must support adaptation from its internal switching layer into another layer supported by the other domain at its ingress and egress interfaces (ONF, 2016b). Fig. 12 shows the role of a single domain SDN controller in the adaptation from the access interface (yellow) to the internal layer (blue). Section 3.9 includes further discussion on the layer interaction and layer adaptation in a hierarchical SDN controller scenario.

3.7. SDN mapping on transport networks
Transport networks are one or more layer networks that can be partitioned and managed using SDN networking concepts. The ITU-T released a new standard, G.7702 — Architecture for SDN control of transport networks, in March 2018 that recommends different SDN controller arrangements for transport networks (ITU-T, 2018a). Fig. 13 depicts three schemes of SDN controller arrangements including recursive 1:1, k:1 and a 1:k hierarchical stack.

The transport network element control function housed inside the transport data plane element is an SDN instance management and control agent. The clients of the adjacent lower level controllers are shown here as SDN controllers, however the lower level controllers can support applications over the A-CPI, and the applications can appear as controller clients at any level in this hierarchical arrangement.


Download : Download high-res image (523KB)
Download : Download full-size image
Fig. 13. SDN controller arrangement for transport networks (ITU-T, 2018a).

In the context of the control and management continuum, the representation of transport network resources is in a Common Information Model (CIM) (ITU-T, 2018c). A CIM describes domains in terms of objects, their properties (represented as attributes) and their relationships. The CIM is intended to be applicable to the management and control of transport networks regardless of whether the transport networks utilize traditional OSS management (ITU-T, 2016b), an ASON control plane (ITU-T, 2012) or an SDN controller to configure transport connectivity. When the MCC functions embedded in an SDN controller directly control the transport resources, the functions view and take control of the transport resources over the forwarding point name space (ITU-T, 2016a) of those resources and forwarding can be configured. The principal SDN controller directly views the transport resources forwarding point name space and offers an abstract view of the transport resources to client SDN controllers, at other levels in the recursion, using a set of transport entities, termed Subnetwork Point (SNP) and Subnetwork Point Pool (SNPP) (ITU-T, 2018b). The SNP and SNPP entities are organized into routing areas (ITU-T, 2012). The routing area, subnetwork and link topological constructs represent the view of the transport resources as seen by the SDN controller from a connection management perspective.

Fig. 14 illustrates the case where Controller 2 and Controller 3 operate on the transport resources with forwarding point name space directly in their scope; Controller 1 operates on the abstraction of resources offered by both Controller 2 and Controller 3 with SNP and SNPP transport entities in its scope.

In Fig. 15(a), Controller 1 operates directly on transport resources in Subnetwork B, and has a view of the forwarding point name space of Subnetwork B in its scope and has a view of the A-CPI to Controller 2, which has the forwarding point name space of Subnetwork A in scope. The resource and topology view available to Controller 1 consists of its direct view (Subnetwork B) and virtual network abstracted view (Subnetwork A) that is offered by the Controller 2 over the A-CPI interface. Fig. 15(b) illustrates using SDN controllers to control a multi-layer transport network. Transport networks can be controlled by a multi-level SDN controller deployment arranged in a client server hierarchy corresponding to the client server layer relationships in the transport layer networks. A SDN controller acting in a server role manages the client to server adaptation functions and offers resources to client controllers using a client layer SNPP link, or via client layer subnetworks interconnected by SNPP links. The adjacent level controllers communicate with each other by a multi-layer Network Call Controller (NCC) (ITU-T, 2018b).


Download : Download high-res image (139KB)
Download : Download full-size image
Fig. 14. Controllers with forwarding point resource name space directly in scope(ITU-T, 2018a).

3.8. SDN for virtualization
Fig. 16 illustrates the basic mechanism used by a controller in a server role to virtualize the underlying transport resource and offer a virtual network to client controllers. In this figure, a controller in a server role operates on a set of transport resources, virtualizes the set of underlying resources and exposes a customized virtual resource to each of its clients (upper adjacent SDN controllers or overlay applications acting as a client). The SDN controller management capability permits administrators to configure controllers to identify underlying resources and to carry out periodic updates. Network administrators setup client contexts according to the contract terms agreed between the service provider and clients. The SLAs may include route information and performance parameters.

A virtual network (ITU-T, 2016a) is a virtualization of layer network resources including one or more virtual nodes and interconnecting virtual links. A virtual network is constructed in the client context based on the abstraction and mapping of the underlying resources in the server context. In multi-level SDN controllers, a virtual network in the server context of a client controller is the same as the virtual network in the corresponding client context of its server controller. The SDN controller which provides a service for its clients is accountable for resource virtualization function control. It includes orchestration of resources among different server contexts, virtual network resource mapping between server contexts and client contexts, virtual network lifecycle management and exposing the virtual network resources to the corresponding virtual network controllers. The virtual networks have a separate virtualization instance in the server controller. The virtual network controllers are authorized by the server controller to access a virtual network and is accountable for the lifecycle management of the services carried by that virtual network. Resource virtualization in an SDN controller acting as a server includes the virtualization of the network topology and characteristic information of each transport entity, according to the different policies and selection criteria established for the client. Various virtualization methods, such as one node in the server context can be virtualized as more than one virtual node in the client context, or several different nodes can be combined together and presented to the client context as a single virtual node. The transport resources offered by a server controller to a client controller through associated client context can be gathered from one or more server contexts. When a given client controller wants to configure its in-scope resources, its requests to configure resources are processed by a network call from a NCC in the server context of the client controller to the NCC of the client context in the server controller. This network call process occurs recursively according to the layer controller arrangement, and ultimately the controller that has visibility of the resource forwarding point name space is able to directly configure the transport resources.


Download : Download high-res image (541KB)
Download : Download full-size image
Fig. 16. Basic transport resource virtualization (ITU-T, 2018a).

3.9. SDN-enabled transport network connectivity control functions
Connectivity is the basic service provided by a transport network. Connectivity is managed by the cooperation of connection management functions, which includes:

1.
Path computation

2.
Connection creation

3.
Connection modification

4.
Connection teardown

5.
Configuration and activation of Operations, Administration and Maintenance (OAM)

6.
Survivability mechanisms

The following perspectives of SDN-enabled Transport Network Connectivity Control Functions will be discussed.

3.9.1. Common components
The application of SDN connectivity control functions to transport networks (ITU-T, 2018b) are classified in Fig. 17. Forwarding point identifiers are only used in the context of Discovery Agent (DA) and Termination and Adaptation Performer (TAP) components. Other control components use SNP identifiers. The identifiers drawn from the forwarding point name space are used by the transport resources to deliver traffic from a source to a sink. Examples of the resource identifiers are: Multi-protocol Label Switching (MPLS) label; Ethernet source and destination addresses; Wavelength; and the tributary slot of an Optical Data Unit (ODU) server.

3.9.2. Connection control with a single level controller
The controller has a direct view of the forwarding point name space of the transport resource, within a single layer network, for call and connection control. Fig. 18 shows the interaction of control components including NCC, Directory Service, Connection Controller, Routing Controller, DA, and Link Resource Management (LRM) (ITU-T, 2018a). Here the TAP, Discovery Agent and Connection Controller access the forwarding point name space of the transport resources. The calling NCC-1/NCC-2 in the client contexts sends the call request to the NCC of the server context in the controller (#1g, 1b). The NCC sends a client server context mapping request to the Directory Services (#2) for identifier translation and mapping of virtual network name spaces. The NCC then transforms the call request to a connection request to the Connection Controller (#3) based on the identifiers in the server context. The Connection Controller sends a route query to the Routing Controller (#4) for a path. The Routing C computes a path to Connection Controller based on the topology information which was provided by the LRM (#5). Then Connection Controller sends the link connection request to LRM for transport network resource allocation (#6). The LRM interacts with the TAP (#7) for the Link Termination Point (LTP) configuration. The TAP maintains interfaces to resources (#8) that use the forwarding point name space to enable forwarding in the network resources. Connection status maintenance, resource discovery, virtualization (name spaces and mappings) and resource view maintenance are implemented by interactions among the control components (ITU-T, 2018a).

Fig. 19 depicts the interaction between TAP and LRM components when configuring and creating relationships between the resource (forwarding point) identifiers and SNPs, and finally creating a link connection for those SNPs (ITU-T, 2018a). Virtual networks can be facilitated by interaction between TAP and LRM (ITU-T, 2018a) as shown in Fig. 20. The allocated label range is subdivided into three subsets, a subset that can exclusively be used by Virtual Network 1, a subset that can exclusively be used by Virtual Network 2, and a subset that is shared between Virtual Network 1 and Virtual Network 2. The exclusive subset labels have a single SNP associated, whereas each label of the shared subset is associated with two SNPs, one SNP within the scope of LRMVN1 and another SNP within the scope of LRMVN2. When a SNP is assigned, e.g., by LRMVN1 that corresponds to a label from the shared label subset, the SNP in LRMVN2 becomes busy.


Download : Download high-res image (304KB)
Download : Download full-size image
Fig. 18. Control components interaction in a single level controller for connection control (ITU-T, 2018a).

3.9.3. Connection control with a two level controller
Fig. 21 depicts connection control with a two level controller where Controller n+1, which does not have a direct view of the transport resource forwarding point name space, sends a request to set up a connection within a local transport network which is controlled by SDN Controller n1 (ITU-T, 2018a). Controller n+1 views the transport network as a virtual network with an SNP/SNPP name space. It can compute a route in this name space. However, as its control components do not have direct visibility of the forwarding point name space of the transport resources in the network, it requests Controller n1 create a connection by using its NCC. The NCC in Controller n1 returns a pair of SNPs to the NCC in Controller n+1. The LRM and TAP of Controller n+1 cannot be utilized because Controller n+1 does not have forwarding point name space visibility. In case the Controller n+1 wants to set up a connection from Transport Network 1 to Transport Network 2, through interconnection links between Transport Networks 1 and 2 (ITU-T, 2018a), the end-to-end connection set-up and release process are divided into three subnetwork connections. Controller n1 and Controller n2 are accountable for the connection set-up and release processes within Network 1 and Network 2 respectively, and Controller n+1 is responsible for the inter-connection between Network 1 and Network 2. The NCC in Controller n+1 sends the call request to NCC-1 and NCC-2. Interworking between the two levels of controllers is performed via NCC to NCC interaction. Inside each controller, the internal procedure for call and connection configuration is performed as the same component interaction sequence in a single lever controller which has a direct view of forwarding point name space of the transport resource (Fig. 18). The NCC in the server controllers is responsible for sending the connection status information to the NCCs in client controllers.

Consider the case (ITU-T, 2018a) in Fig. 22, Controller 2 makes a request for a connection to its server Controller 1, the NCC in Controller 1 receives the request, proceeds with steps 2–8 as depicted in Fig. 18 and replies to the NCC in Controller 2 with a pair of SNPs in the calling Layer X. Controller 2 views this pair as a Layer X link that becomes part of Subnetwork B. The connection is established using the provided Layer X link. The configuration of the adaptation between layers is performed in the Controller 1 NCC. Controller 2 gains a multi-layer topology view of the additional virtual network representation of Subnetwork C, which is from Layer Y. The Routing Controller in Controller 2 uses this multi-layer topology to calculate a route through both layer networks. The NCC–NCC call is made from Controller 2 to Controller 1 using boundary resource identifiers (call source and destination identifiers) in the context of Subnetwork C. The returned SNPs are in Layer X and Controller 2 views the SNPs as the locations of an adaptation into Layer Y. The connection in Layer X can use the connection that is created in Layer Y.


Download : Download high-res image (457KB)
Download : Download full-size image
Fig. 21. Control components interaction in two level controller for connection control (ITU-T, 2018a).

3.9.4. Control communications network
The control components communicate with each other using a Control Communications Network (CCN), part of a DCN, as described in ITU-T (2010). Protocol Controllers, entities that instantiate control communication functions including generating and processing messages in protocol specific formats, have points of attachment that are identified by CCN addresses. Each Protocol Controller has a distinct CCN point of attachment (CCN attachment). The Protocol Controller provides a means for control components to access the CCN. A Protocol Controller may support one or more control components, therefore, a directory may be needed to relate the control component identifier with the CCN address of its associated Protocol Controller. The independence between the control component identifier and the CCN address allows, for example, the location of a control component to be changed, or for the CCN to be reconfigured, without modifying the identifier of the control component.

The controller’s view of its resources should be kept current since the resources may change over time due to failure, recovery, network build-out or administrative action. In the logically centralized and hierarchical control afforded by SDN, the topology of the transport network is maintained by co-operating multi-level controllers and their locally controlled transport network. Within one control domain, the transport network topology is auto-discovered by the Discovery Agent using the mechanisms described in ITU-T (2005) and ITU-T (2017). The Discovery Agent reports the discovery result to the SDN controller for that domain. When the control domain contains two inter-connected administrative domains, the links between them are often manually configured in the controller.

4. SDN-enabled wireless mobile backhaul network architecture — state of the art
The WMBH segment has been traditionally operated and configured in a static manner. The promise of SDN-enabled programmable management and control offers interesting opportunities in this area of the network.

4.1. G.7702 - A new ITU-T standard for SDN-enabled transport networks
Table 1 summarizes selected published SDN-related standards and corresponding standardization organizations who have focused on SDN and SDN-related standards, such as Internet Engineering Task Force (IETF), Institute of Electrical and Electronics Engineers (IEEE), Internet Research Task Force (IRTF), ONF, ITU-T, and MEF.

In the new architecture in G.7702, all transport control functions, as described in Section 3, are SDN-based. In ITU-T (2018a), a migration path is provided for the migration of a legacy transport network control architecture to an SDN-based transport control architecture. The migration can be completed by adding an SDN controller and an A-CPI agent that support the interaction with a higher level SDN controller or application plane. The Element Management System (EMS/NMS) which is updated with SDN controller capability can re-use the proprietary interfaces to communicate with the legacy transport network element (ITU-T, 2018a).


Table 1. SDN standardization activities.

Organization	Description
ONF	SDN Architectures and its components, SDN interfaces, OpenFlow protocol extensions, OpenFlow Switch Specifications, OpenFlow Configuration and Management Protocol
IETF	ForCES Protocol, SDN Architecture, OpenFlow interworking, Control Plane Requirements
ITU-T	Signaling requirements using SDN technologies in Broadband Access Network, Functional architecture for SDN, SDN Control of Transport Network, and Security aspect in SDN
Broadband forum	Requirements and impacts of deploying SDN in Broadband Networks
IEEE	Applicability of SDN to IEEE 802 infrastructure
IRTF	Identifying the SDN research challenges; SDN approaches that can be defined, deployed
MEF	Service orchestration in Network as a Service
4.2. SDN southbound protocols
Table 2 provides a short description of SDN southbound communication protocols.

Considered to be a de-facto southbound communications protocol for SDN, OpenFlow (McKeown et al., 2008) specifies a common standard interface between the controller and forwarding devices. Due to its vendor neutral design, OpenFlow fosters the integration of heterogeneous transport node implementations, thereby simplifying the operation of heterogeneous multi-vendor infrastructure deployments. With OpenFlow, forwarding rules are installed in the flow tables on the SDN-enabled devices. Flow tables comprise fields that are used to identify flows and to specify what should be done with the information flow packets, i.e., match field; action field, counter, priority, timeout, cookies, and metric. Based on the flow table entries, an appropriate action is taken on matched packets otherwise the packet_in message is sent to the controller. Upon receiving a packet_in message, the controller identifies what should be done with the packet and passes a new flow table entry to the OpenFlow-enabled device. The rules are defined according to the application running on the controller — known as a Network Operating System (NOS). Open VSwitch Database Protocol (OVSDB) (Pfaff and Davie, 2013), OpenFlow Configuration (OF-Config) protocol (Narisetty et al., 2013), and Forwarding and Control Elements Separation (ForCES) (Doria et al., 2010) are examples of other communication protocols for the southbound interface. The OF-Config protocol manages any OpenFlow enabled device while the OVSDB protocol manages and performs resource allocation in the Open VSwitch (Pfaff et al., 2015). The communication between application layer and controller occurs via open APIs such as Representational State Transfer (REST) (Zhou et al., 2014). Open Network Environment (ONE) Platform Kit (onePK) is a Cisco programmable toolkit that extends the network capabilities and configuration automation based on values extracted from Cisco devices (Sowatskey, 2012a, Sowatskey, 2012b, Kampanakis et al., 2014). Path Computation Element (PCE) (Farrel et al., 2006, Vasseur and Le Roux, 2009, Casellas et al., 2013, Feamster et al., 2014) facilitates traffic engineering using graph representation for a constrained path network.


Table 2. SDN southbound protocols (Tayyaba and Shah, 2019).

Protocol	Description
OpenFlow (McKeown et al., 2008)	OpenFlow is the de facto SDN southbound communication protocol that is used to pass messages between SDN controllers and forwarding devices such as switches and routers, both physical and virtual (hypervisor-based). It is responsible for manipulating flow tables in OpenFlow-enabled devices.
OF-Config (Narisetty et al., 2013)	OpenFlow configuration specification addresses the management of resources in OpenFlow-enabled devices.
OVSDB (Pfaff and Davie, 2013)	OVSDB management protocol is used to perform management and configuration operations on the Open vSwitch (OVS) instance. It is responsible for creating, modification, deletion and managing multiple of OpenFlow datapaths
ForCES (Doria et al., 2010)	ForCES defines an architectural framework and associated protocols to standardize information exchange between the control plane and the forwarding plane in a ForCES Network Element (ForCES NE)
PCE (Farrel et al., 2006, Vasseur and Le Roux, 2009)	PCE is a network component, application or node that can apply computational constraints and compute a network path or route based on a network graph. The PCE has access to topology information for the entire network and uses the topology information in path computations
OnePK (Sowatskey, 2012a, Sowatskey, 2012b)	OnePK is a Cisco toolkit for providing access to the internal function of network entities (routers and switches) and provide APIs for creating and integrating application into Cisco hardware.
NETCONF (Enns et al., 2011)	The Network Configuration Protocol(NETCONF) is an XML-based protocol used for install, manipulate, monitor and delete the configuration of network devices in the network.
4.3. Available SDN controller solutions
A summary of available open source and commercial controllers is presented in Table 3, Table 4 respectively. The controllers have their own specific pros and cons which are reflected in Wibowo et al., 2017, Khondoker et al., 2014 and Salman et al. (2016). SDN controller capabilities of running cross-platform, multi-threading, fast memory access and good memory management are essential. The characteristics depend on the programming languages that are used to build the controllers. When choosing a controller for a wireless transport network, the factors have to be taken into consideration because they affect the controller’s performance and development speed. In general, Python, C++, and Java are the most used languages for SDN controllers programming.


Table 3. Summary of open source SDN controllers (Wibowo et al., 2017, Salman et al., 2016, Khondoker et al., 2014).

Name	Owner	Pro. language	Architecture	Description
Beacon	Stanford	Java	Centralized Multi-threaded	Cross-platform, modular, Java based OpenFlow Controller that support event-based and threaded operation (Erickson, 2013).
Maestro	Rice Uni.	Java	Centralized Multi-threaded	A network operating system based on Java which provides interfaces for implementing modular network control applications (Cai, 2012).
FloodLight	Big Switch Network	Java	Centralized Multi-threaded	Java-based OpenFlow Controller, based on the Beacon implementation, works with physical and virtual OpenFlow switches (Floodlight).
RISE	NEC	C & Ruby	Centralized	OpenFlow Controller based on Trema, which is an OpenFlow stack based on Ruby and C (Ishii et al., 2012).
ONOS	ON.Lab	Java	Distributed	Open source SDN controller platform designed specifically for scalability and high-availability. With this design, ONOS projects itself as a network operating system, with separation of control and data planes for Wide Area Network (WAN) and service provider networks (Berde et al., 2014).
RYU	NTT	Python	Centralized Multi-threaded	SDN operating system that aims for logically centralized control and APIs, to create new network management and control applications (Kubo et al., 2014).
NOX/POX	Nicira	Python	Centralized	The first OpenFlow controller (Gude et al., 2008, Sheikh, 2019).
OpenContrail	Juniper	Python	Distribute	An open source version of Juniper’s Contrail controller (Lin et al., 2015, Singla and Rijsman, 2013).
OpenDaylight	Linux Foundation	Java	Distributed	An open source project based on Java. It supports OSGi Framework for local controller programmability and bidirectional REST for remote programmability as Northbound APIs (Medved et al., 2014, Phemius et al., 2014).
OpenMUL	KulCloud	C	Centralized Multi-threaded	C-based multi-threaded OpenFlow SDN controller that supports a multi-level northbound interface for attaching applications (OpenMul, 2015).

Table 4. Summary of commercial SDN controllers (Wibowo et al., 2017, Salman et al., 2016, Khondoker et al., 2014).

Name	Owner	Pro. language	Architecture	Description
Big Cloud Fabric controller	Big Switch Network	Java	Centralized Multi-threaded	The controller is part of Big Switch’s SDN-based Data Center solutions. It is hierarchically implemented SDN controller that capable to be implemented as a cluster of virtual machines or hardware appliances for high availability (BigSwitch, 2014).
Brocade Vyatta Controller	Brocade	Java	Distributed	OpenDaylight Based Controller with additional support services from Brocade (Brocade, 2015).
One Controller	Extreme Networks	Java	Distributed	Extreme Networks offers its SDN controller (OneController) in form of hardware appliance based on OpenDaylight controller and provides Extreme Network’s OpenDaylight-based API, Software Development Kit (SDK) and a developer community (ExtremeNetworks, 2015).
HP VAN SDN Controller	HP	Java	Distributed	OpenDaylight based controller with HP contributions in AAA, device drivers, OpenFlow and Hybrid Mode, clustering for High Availability, multi-application support including the Network Intent Composition (NIC) API, Persistence, Service Function Chaining, OpenStack integration and federation of controllers (“HP VAN SDN Controller Software”).
Programmable Network Controller	IBM	Java	Distributed	OpenDaylight based controller offered by IBM as part of its Data Center Solution (IBM, 2012).
Contrail	Juniper	Python	Distributed	Contrail Controller is a software controller that is designed to operate on a virtual machine (VM). It exposes a set of REST APIs for northbound interaction with cloud orchestration tools, as well as other applications (Juniper, 2015b) .
Programmable Flow Controller	NEC	Java	Centralized	It provides a high performance, fabric-based SDN with advanced network automation, control, and flexibility, enabling full network virtualization and secure, multi-tenant networks (NEC, 2013).
Open SDN Controller	Cisco	Java	Distributed	OpenDaylight based SDN Controller with additional Cisco’s embedded applications, robust application development environment and additional OpenFlow protocol support for Cisco Multiprotocol Label Switching (MPLS) extensions (Cisco, 2015).
Huawei IP SDN Controller	Huawei	Java	Distributed	OpenDaylight based SDN controller with addition of Huawei’s Open Programmability System (OPS), which implements multi-layer capability openness including network control and management (Huawei, 2013).
4.4. SDN in combination with NFV
The European Telecommunications Standards Institute (ETSI) NFV Industry Specification Group (ISG) provides guidance on deploying instances of network functions running in virtual machines (VMs) that provide network operators with the ability to dynamically instantiate, activate, and re-allocate resources and functions (Narmanlioglu and Zeydan, 2017, Ordonez-Lucena et al., 2017). An SDN-enabled wireless backhaul network in combination with NFV facilitates the ability to dynamically push network functions at a desired time (busy hour, for instance) and location that is closer to the users or congested network segments so that a portion of the traffic requests can be served locally during the congestion periods. In González et al. (2016), an SDN/NFV integrated fronthaul/backhaul transport network architecture is proposed. For the control plane design, the authors leverage SDN principles, which fosters network and device programmability. The architecture offers unified control, management, and configuration of the 5G multi-technology transport network. NFV allows infrastructure and function virtualization, where the underlying physical infrastructure and network functions can be virtualized in such a way that they will be appropriately instantiated, connected, and combined over the underlying 5G-Crosshaul infrastructure resources. It also enables the flexible function placement and cost-effective usage of the 5G-Crosshaul infrastructure resources. The proposal uses Open Daylight (Medved et al., 2014) and Open Network Operating System (ONOS) (Berde et al., 2014).


Table 5. SDN-based virtualisation solutions (Tayyaba and Shah, 2019, Blenk et al., 2015).

Name	Abtraction	Description
HyperFlex (Blenk et al., 2015)	Hardware abstraction via software	HyperFlex provides different virtualization function for control plane virtualization. The available physical resources are virtualized. The traffic rate is guaranteed using benchmark measurements.
FlowVisor (Sherwood et al., 2009, Giatsios et al., 2017)	Data plane abstraction	OpenFlow controller act as a proxy between controller and data plane providing switch virtualization for creating production network slices. OpenFlow acts as a hardware abstraction layer. FlowVisor runs at line rate.
ADVisor (Salvadori et al., 2011)	Data plane abstraction	Advanced FlowVisor or ADVisor is developed as an extension of FlowVisor, in which a software proxy or an enhanced abstraction unit is added to improve the virtual resources abstraction
VeRTIGO (Corin et al., 2012)	Data plane abstraction	VeRTIGO allows the vSDN controllers to select the level of virtual network abstraction that they require.
AutoSlice (Bozakov and Papadimitriou, 2012)	Data plane abstraction	The physical infrastructure is segmented into non-overlapping SDN domains, while the hypervisor is split into a management module and multiple controller proxies, one for each SDN physical domain
FlowN (Drutskoy et al., 2012)	Topology abstraction	Policy-based hypervisor manages composite policies for multi-tenant application and reduces policy over-head. FlowN provides controller virtualization for isolating different tenant applications. The resources, such as flow space, are statically assigned on per tenant-based with a constant latency overhead.
OpenVirtex (Al-Shabibi et al., 2014)	Address and Topology Abstraction	It provides flow space virtualization. Administrator handles virtualization for their substrate and share the mapping and send a data packet to their neighbor substrate.
IBM SDN VE (Racherla et al., 2014)	Network abstraction	This solution provides virtual network environment consisting of a virtual agent and virtual agent orchestration. This agent orchestration enables communication between virtual machines. The network configuration and control policies are orchestrated by virtual agent.
xDpd (Doriguzzi-Corin et al., 2014)	Data plane abstraction	Physical resources are virtualized abstracting data plane. Virtual functions are used for isolating resources for individual resources.
4.5. SDN-enabled network virtualisation
Network virtualisation (NV) facilitates multiple tenant sharing physical infrastructure by acquiring virtual network resources according to their service demands. The main drivers for NV are cost reduction (both CAPEX and OPEX), faster network and service deployment, reduced time to market, and improved network resource utilization. Table 5 provides a summary of existing hypervisor architectures that are used to provide SDN-based NV.

4.5.1. Backhaul infrastructure sharing
The authors in Venmani et al. (2012) propose a solution for backhaul infrastructure sharing by using a slicing mechanism and incorporating the Openflow protocol (McKeown et al., 2008) within the access and aggregation nodes to facilitate SDN controller interaction. The slicing mechanism is carried out by the combination of SDN/NFV concept (Ordonez-Lucena et al., 2017, Sherwood et al., 2009, Giatsios et al., 2017). As a result, an operator can lease the backhaul network of another operator when link congestion occurs.

4.5.2. Unified multiple wireless transmission technologies
The authors in Niephaus et al. (2015) propose a WiBACK solution to provide a smart and flexible back-haul network with heterogeneous technologies, including satellite links. WiBACK introduces a Unified Technology Interface (UTI) abstraction module; a bootstrap module; and spectrum and capacity management functions. UTI is implemented in data plane equipment to provide the control plane functions with standardized interfaces by abstracting the network device. This permits network devices to be controlled holistically regardless of the technology or vendor.

4.6. Dynamic resource allocation
In conventional resource allocation, both static and hybrid resource allocations have drawbacks. In static resource allocation schemes, traffic bearers have a predefined guaranteed bit rate and it is impossible to have statistical multiplexing across different channels. Therefore, at the aggregation transmission nodes resources allocated for lightly loaded base stations may not be fully utilized, whereas heavily loaded base stations can encounter congestion. In hybrid resource allocation, traffic bearers are allocated guaranteed bit rate (GBR) resources or share the available resources based on their class of service. Traffic scheduling fairness cannot guarantee hybrid resource allocation, since the end-to-end delivery probability of a packet is the product of delivery probabilities along each hop. An increased number of hops towards the gateway will result in a lower end-to-end packet delivery probability. Finally, packets with similar QoS class types experiencing different hop counts toward the gateway could have a different end-to-end packet delivery probability outcome. As a result, in conventional resource allocation schemes, data plane resources cannot be used efficiently (Bojic et al., 2013). In a WMBH, SDN-based dynamic resource allocation is expected to overcome the drawbacks associated with conventional resource allocation schemes.

4.6.1. Dynamic wireless channel assignment
The authors in Santos and Kassler (2017) implemented an SDN-based architecture that provides a flexible reconfiguration of wireless backhaul links by extending the OpenFlow protocol, adding wireless configuration capabilities and wireless-related statistics. The SDN-managed wireless backhaul nodes can be dynamically manipulated. By monitoring ongoing traffic statistics, the SDN controller can effectively perform wireless channel reassignment. The SDN controller can instruct the backhaul nodes to change the data communication channel based on current traffic load conditions. The wireless backhaul node is provided with the channel to switch to and with the Basic Service Set Identifier (BSSID) that it should associate with. The BSSID is the physical address of the radio interface the wireless backhaul node is currently connected to. Therefore, channel scanning operations can be avoided, reducing complexity, energy and cost. The spectrum management module described in Ashrafi (2018) gathers global network device information through the UTI to build a global view of the physical network topology. With this global knowledge, it centrally plans and assigns suitable frequencies, channel bandwidths, Modulation and Coding Scheme (MCS) and transmit power (Tx-Power) for the device interfaces whilst minimizing interference. Based on the messages from the UTI, the spectrum management module continuously reacts to network events (i.e., new interference, link failures or a decrease in signal quality). The capacity management module calculates the actual available capacity on each link in bits per second; average link latency and jitter; and performs path calculation and resource allocation to construct a global logical network topology view. An application can send requests to WiBACK requesting capacity between two arbitrary nodes, together with maximum latency, jitter, and packet loss ratio. If sufficient resources are available the capacity management module calculates and provides paths as requested by updating the network device flow tables along the calculated path. The established channels are continuously monitored and adjusted if end-to-end QoS violations are identified by a network device UTI.

4.6.2. Selective traffic shaping and re-routing
The degradation of one particular wireless link in a wireless backhaul network due to a fluctuation of the environment (e.g. rain) causes the MCS to be changed, the capacity of the effected link is reduced and data packets subsequently dropped. In this way, it is not only increasing the burden on this degraded link but also wasting the resources of the intermediate nodes because flow data is discarded at the bottleneck. In Bercovich et al. (2015), an optimization function as an SDN overlay application was proposed that instructs the related network nodes (in a wireless transport network or in the core) to reshape the traffic flow adaptively and enables only the time sensitive traffic to pass through the degraded link, whilst the remaining portion of the traffic flow is dropped well before the degraded link. Fig. 23 (Bercovich et al., 2015) illustrates this concept. Rather than being dropped, this portion of the traffic can be rerouted to alternative routes as described in Fig. 24.

4.6.3. Dynamic spectrum allocation
Also in Bercovich et al. (2015), a frequency sharing scheme applies for any two Microwave (MW) links from two separate base stations to an aggregation point. The same frequencies can be reused for the two MW links if the separation angle between the two MW links is large enough for an acceptable and balanced Carrier to Interference Ratio (CIR). The smaller the separation angle is, the better the frequency-reuse scheme is archived.

As shown in Fig. 25, the two links in normal working conditions share the two pairs of frequencies f1f2 and f1’f2’ for uplink and downlink, respectively. In the event of degradation on one of the two MW links (due to heavy rain, for instance), at the aggregation node, the CIR of the degraded link will be reduced and the CIR balanced condition is broken. The SDN optimization application receives a notice from the physical layer of the degraded MW link and populates new rules that request the far-end transmitter of the other MW link lower its transmit power. As a result, CIR of the degraded MW link at the aggregation node increases to a level that balances the CIRs of the two MW links for normal working conditions. Without SDN, the degraded links could become out of service unless the transmission angle between the two MW links is sufficient for an acceptable and balanced CIR. This approach is also applied when frequencies are reused by polarization (Horizontal transmit Horizontal receive, Horizontal transmit Vertical receive, Vertical transmit Vertical receive, and Vertical transmit Horizontal receive). In other words, due to interference, the same frequency can only be reused if a pre-determined minimum angle of separation (called ) is guaranteed. The angle depends on the antenna diameter and antenna technology. The larger the , the lower the frequency reusability becomes. In a conventional non-SDN based frequency allocation scenario, a static frequency configuration is provisioned. The sporadic fading margin must be taken into account when performing the microwave link budget calculation. As a consequence, the , is larger than that in the case where an SDN-based application is used. This SDN-based application detects fading events by continuously monitoring and updating global link information. The application adaptively triggers changes to transmission characteristics between base stations and microwave aggregation nodes. The frequency can now be reused with a smaller separation angle for a given CIR. In addition, in a fading event, the SDN controller can tackle whether to reduce bandwidth or to permit each link to use a polarization that is different from other links.


Download : Download high-res image (466KB)
Download : Download full-size image
Fig. 25. MW dynamic spectrum allocation (Bercovich et al., 2015).

Another use case is when each frequency can be assigned as high priority for one MW link and, at the same time, a lower priority for the other MW link. In the event of deep fading, interference becomes significant, the SDN-based application can request the MW nodes to stop using the lower priority frequency. That would increase the availability of the MW link for which the frequency is a high priority.

4.6.4. Adaptive energy management
In a WMBH that includes dense or ultra dense deployment of small cell backhaul, if all of the nodes are continuously powered on regardless of user data traffic load, the result can be high energy consumption and correspondingly, high operational costs. An adaptive solution that cycles the backhaul node power according to the required capacity will reduce the backhaul energy consumption, however this approach requires effective routing schemes to reduce the reaction time whenever the network topology changes.

4.7. Connection resiliency
It is important for WMBH to have an efficient, flexible forwarding architecture with resilient connections that relay user data and control traffic over multi-hop wireless backhaul between nodes.

4.7.1. Data path connection resiliency
In Santos and Kassler, 2017, Ashrafi, 2018, the proposed architecture makes use of the Bidirectional Forwarding Detection (BFD) protocol (Katz and Ward, 2010) and fast failover mechanisms in OpenFlow that enable the wireless backhaul nodes to locally switch traffic to different neighbors in case a link degrades or if the neighbor goes offline. The authors in Ashrafi (2018) proposed a small cell wireless backhaul architecture where millimeter Microwave (mmWave), Non-line-of-sight (NLOS) sub-6 GHz, and Free-space optical communication (FSO) were used. To react in a rapidly changing wireless environment where wireless backhaul nodes power on or off due to energy saving strategies, an SDN controller application calculates, for the small cell nodes, a primary link and a set of backup links. The set of backup links includes at least one backup link which may be used if the primary link degrades. Using OpenFlow fast failover groups, a fast local repair of mmWave backhaul can be achieved leading to a resilient backhaul mesh architecture. Also in Ashrafi (2018), to further improve the small cell wireless backhaul network reliability, the author proposed an SDN-based channel estimation module that provides the capability to multiplex between line-of-sight (LOS) mmWave, NLOS sub-6 GHz and FSO transmissions. In this multiplex scheme, the small cell backhaul nodes have three transceivers: LOS, NLOS and FSO. Based on the environmental and system operating conditions, the system adaptively switches between the three transceivers. The FSO transceiver will be used if the atmospheric conditions are good, mmWave LOS transceiver will be used if the atmospheric conditions become foggy or it rains, and if the operating environment has physical obstacles between the transmitter and receiver, the system would select the NLOS transceiver.

4.7.2. Control connection resiliency
In an SDN-managed network, a reliable control channel is required for communication with the controller. Nonetheless, for an SDN-enabled wireless backhaul network this requirement cannot be easily achieved due to the nature of wireless environment uncertainty. It is particular true in small cell backhaul network where communication wireless links operate at mmWave or higher frequency ranges. In Ashrafi (2018), an in-band control scheme was proposed. Based on knowledge of the local topology, a bootstrap module, embedded in network devices initiates connectivity to an adjacent node, which is already connected to the network, in order to establish communication with the controller. This bootstrap is a minimalistic controller working with local knowledge to ensure that a connection between the controller and a network device is always (re)established if the node is in communication range.

With in-band connectivity, the control channel shares the same network interface used by the data plane, the infrastructure costs are reduced, but if link failure occurs, the node losses the connection with the SDN controller. In addition, the multi-hop nature of the backhaul may lead to long control cycles between the SDN controller and the backhaul node. Therefore, an out-of-band control channels should be taken into account. One of such options is using Long-Term Evolution (LTE) interfaces on the wireless backhaul nodes for control channel connectivity. This option reduces the SDN control latency, while the data plane can use the backhaul (multi-hop) connectivity. Out-of-band control plane connectivity requires an additional Network Interface Card in the manged devices (Santos and Kassler, 2017, Ashrafi, 2018, Vestin and Kassler, 2017).


Table 6. Simulation/emulation tools for SDN-based WMBH implementation.

Name	Environment	Pro. Language	License
Mininet-Wifi	Linux	Python	Open source
Mininet	Linux	Python	Open source
NS2	Linux	C++/TCL	Open source
NS3	Linux/Unix	C++/Python	Open source
Matlab	Windows/Linux	Matlab	Commercial
OMNET++	Windows	C++	Open source
OPNET	Windows	Proto C	Commercial
CORE	Linux	Proto C	Open source
IMUNES	Linux	Proto C	Open source
Kathara	Windows/Linux	Python	Open source
OFNet	Linux		Open source
EstiNet	Linux		Commercial
4.8. Multi-dimensional optimization policy and path calculation
As presented in Section 3.2, the SDN controller establishes and maintains the operational state of the managed resources according to an optimization policy. The controller participates as the active entity in a feedback control loop (ONF, 2016a), as depicted in Fig. 6. In Ashrafi (2018), an OpenDaylight SDN controller adaptively turns small cell nodes on or off. The controller reconfigures the backhaul forwarding topology according to optimization policies in combination with the state of the backhaul wireless links and small cell transport nodes. The SDN controller (Ashrafi, 2018) shown in Fig. 26 uses a multi-dimensional optimizer module that is configured with different optimization policies based upon a set of three parameters: ,  and . The multi-dimensional optimizer communicates with the backhaul orchestrator that uses an API to reconfigure the small cell backhaul network nodes according to the selected operational point regulated by a set of the three parameters in the policy.

4.8.1. Capacity-aware path computation
Capacity-aware path computation utilizes global topology information knowledge, current link attributes and current traffic loads to build an internal resource database. It uses Genetic Algorithm (GA)-based optimization approaches including GA Static and GA Dynamic. The GA Static algorithm, based on global topology knowledge and a set of traffic matrices capturing the varying traffic demands over 24 h, computes a single static routing configuration. GA Dynamic computes a set of potentially different routing configurations based on the same information to better adapt to the changing traffic. The authors also have a vision of using multiple separate BRM entities for basic topology clusters to make the solution scalable thereby improving or maintaining overall network performance.

4.9. SDN simulation tools
Selected simulators that can be used to implement and evaluate the performance of new SDN-based WMBH architectures are shown in Table 6.

5. SDN-based WMBH research challenges
The wireless mobile backhaul segment has traditionally been statically configured and operated. The promise of SDN programmability offers opportunities to improve reliability and efficiency in this part of the network. The WMBH for next generation cellular deployments (Fiorani et al., 2014, Ashrafi, 2018, Sajjadi et al., 2018) are expected to:

1.
Provide very high capacity on demand that supports very high data rate traffic.

2.
Improve energy efficiency.

3.
Be very low latency.

4.
Improve connection reliability and resiliency by automatically traffic rerouting.

5.
Improve control and management capability that provides on-demand transport resource allocation to meet changing service requirements.

6.
Provide control and management capability that enables a fast/real time/automatically re-configurability, and on-demand transport resource allocation to match changing service requirements and environment/conditions in an optimum way according to pre-defined policies which also are subjected to change overtime.

7.
Provide energy efficiency that is balanced with the need for increased capacity and low latency;

8.
Enable dynamic backhaul transport infrastructure sharing between service providers.

However, on the way to becoming a mature technology for WMBH, especially for dense small cell backhaul network using mmMW frequency ranges, SDN-enabled WMBH must overcome many challenges. Given the constraint of high energy efficiency and limited backhaul radio resources, some of the specific research challenges for the SDN-based WMBH architecture are identified and classified in Table 7, and possible solutions are outlined in Table 8.

The following sessions will discussed in detail possible solutions for specific SDN-based WMBH architecture research challenges.


Table 7. Research challenges for SDN-based WMBH architectures.

No.	Challenge category
1	SDN orchestration (ONF, 2016a, Garroppo et al., 2010, Santos and Kassler, 2016)
2	SDN reliability and availability (ITU-T, 2018a, Niephaus et al., 2015, ONF, 2016a, ITU-T, 2018b, Santos and Kassler, 2017, Ashrafi, 2018, ONF, 2014, Sun et al., 2015, Ballani et al., 2015, Santos and Kassler, 2016, Vestin and Kassler, 2017)
3	Network consistency (Yaghoubi et al., 2018, Maity et al., 2018, Foerster et al., 2018, Mizrahi et al., 2016, Parvez et al., 2018)
4	Distributed SDN Architecture (Wibowo et al., 2017, ONF, 2014, ONF, 2016a, ITU-T, 2018a)
5	Dynamic Resource Allocation (Energy management; Radio resource management) (Sakaguchi et al., 2017b, Bercovich et al., 2015, Chen et al., 2016)

Table 8. Summary of SDN-based WMBH research challenges and possible solutions.

No.	Challenge category	Possible solution
1	SDN orchestration (ONF, 2016a, Garroppo et al., 2010, Santos and Kassler, 2016)	 With advanced computing technologies, Controllers are implemented as a VNF that can be distributed, scaled, or migrated.
 Creating smaller SDN domains; or by allocating separate functional areas to separate SDN controller components
 Algorithm that allows controller to operated to a scope of results that is considered to be satisfactory, rather than seeking to converge on a precise optimum operation point.
 Machine learning or artificial intelligence may play an important role in developing optimization algorithms and validating resource allocation.
2	SDN reliability and availability (ITU-T, 2018a, Niephaus et al., 2015, ONF, 2016a, ITU-T, 2018b, Santos and Kassler, 2017, Ashrafi, 2018, ONF, 2014, Sun et al., 2015, Ballani et al., 2015, Santos and Kassler, 2016, Vestin and Kassler, 2017)	 Traffic processing engines may need to continue their functions unchanged in the absence of active controller connections.
 Using a separate out-of-band transmission medium that provides a more stable connection.
 OpenFlow fast failover group table feature can be used to overcome the unavailability of wireless control channels.
 Dual homing data plane equipment can be controlled by two or more SDN controllers.
3	Network consistency (Yaghoubi et al., 2018, Maity et al., 2018, Foerster et al., 2018, Mizrahi et al., 2016, Parvez et al., 2018)	 Reducing route re-configuration by algorithms that selects the right time to apply the newly computed optimal routes.
 A suitable SDN update scheme for ensuring packet-level consistency in SDN-based networks.
4	Dynamic Resource Allocation (Energy management; Radio resource management) (Sakaguchi et al., 2017b, Bercovich et al., 2015, Chen et al., 2016)	 An SDN adaptive solution that cycles the power on back-haul nodes according to the required capacity could reduce the backhaul energy consumption.
 Energy efficient WMBH operation can be performed by populating WMBH nodes with SDN rules adaptively to allow the nodes to consume just the required power according to the existing climatic conditions (e.g., reducing transmit power in good weather) or workload (e.g., using only requested radio resources)
 Effective coordination between the network segments traversed, utilizing the reconfigurability and adaptability on the underlying transport capacity, can achieve resource optimization.
5.1. SDN orchestration
Challenges.
Orchestration, the core function of an SDN controller, is a multi-dimensional real-time optimization problem over a complex and potentially large space. Further, it must simultaneously work across the underlying resources and all of their various virtualizations. The complexity of the controller is a legitimate concern (ONF, 2016a). In a WMBH network, this optimization is highly complex (Santos and Kassler, 2016, Hasan et al., 2017) because it deals with multiple variables for conflicting goals that include information about the backhaul topology, traffic demands, link configurations, and energy consumption statistics. As a consequence, the optimization process can take a significant amount of time and a centralized orchestration entity could lead to scalability issues.

Possible solutions.
Several approaches to the problem are available, some of which are listed below (depending on certain circumstances, combinations would be used):

1.
Use advanced computing technologies that enable an SDN controller to manage larger workloads, especially when the controller is implemented as a VNF that can be distributed, scaled, or migrated.

2.
Use a common scaling technique that defines a larger number of smaller SDN domains or by allocating separate functional areas to separate SDN controller components or hybrid structures where SDN controllers work in combination with existing operations support system and business support system (OSS/BSS) functionality (ITU-T, 2018b), as shown in Fig. 8.

3.
Dedicate the NFV function that focuses on maintenance of certain resources and an SDN focus on using the resources for service delivery.

4.
If the SDN controller feedback criteria (ONF, 2016a), as shown in Fig. 6, indicates a scope of results that is considered to be satisfactory, rather than seeking to converge on a precise optimum operation point, the optimization problem may be simplified. It also reduces the optimization problem and improves customer QoE if resources are not reallocated while they are in use.

5.
An SDN controller can be simplified if it deals only with the allocation of pre-existing resources.

6.
Machine learning or artificial intelligence may play an important role in developing optimization algorithms and validating resource allocation.

7.
In Santos and Kassler (2016), the authors proposed a solution that orchestrates the balance between energy and performance by utilizing centralized knowledge of the traffic demands, traffic forwarding latency, the power consumption profile of the small cell WMBH nodes, available connectivity options, interference and neighborhood statistics data from the network. The solution requires flexible path calculation strategies with novel centralized routing algorithms providing fast path calculation while supporting multiple constraints such as bandwidth and latency. The authors in Santos and Kassler (2016) proposed a backhaul orchestrator using an optimizer module (which in turn uses a configurable optimization policy) dynamically powers the nodes on or off and configures the forwarding paths and nodes according to traffic demands. The optimizer module can minimize the energy cost or optimize capacity or latency by utilizing different policies.

8.
The scalability issues might be addressed through the adoption of a multi-layer control architecture and resource abstraction models. Different multi-layer SDN-based control architectures are possible depending on how the different segment controllers interact. Another approach for the controller scale challenge is to consider a controller authority segmentation to limit the size of the area for which a controller has control and management authority. For instance, in Schmid and Suomela (2013) various hierarchies and controller topology deployments are proposed.

5.2. SDN reliability and availability
Challenges.
SDN reliability and availability play a very important role in WMBH networks where connections from the controllers to data flow devices may be implemented over fluctuating wireless connections. The separation of the control and data planes implies the need for high availability of the connection between controllers and data flow devices. If a controller fails or is otherwise unable to perform its expected functions due to unstable wireless connections to data flow devices, the WMBH network can malfunction. Communication channels can be in-band or out-of-band to exchange control plane messages. An SDN-managed WMBH node requires a reliable control channel for communication with the controller. This requirement may not be achieved when the control channel shares the same network interface used by the data plane (in-band connectivity) due to the stochastic nature of the wireless environment especially found with mmWave frequency ranges. The multi-hop nature of the backhaul may lead to long control cycles between the SDN controller and the small cell backhaul node. With in-band connectivity, the infrastructure costs are reduced, but if link failure occurs, the node losses the connection with the SDN controller. Out-of-band control plane connectivity requires an additional Network Interface Card (NIC) in the managed devices.

Possible solutions.
1.
Traffic processing engines may need to continue their functions unchanged in the absence of active controller connections. This can be done by creating a partition and delegation of functionality from the SDN controller into data plane elements (Niephaus et al., 2015, ONF, 2016a).

2.
To provide the resiliency required for WMBH forwarding, the OpenFlow fast failover group table feature can be used to overcome the unavailability of wireless control channels. This approach requires the calculation of a disjoint backup path toward the gateway at each WMBH node (Santos and Kassler, 2016).

3.
Resiliency can be improved by using a separate out-of-band transmission medium that provides a more stable connection, e.g., LTE, satellite, or other connection using a lower radio frequency band. In Santos and Kassler, 2016, Ballani et al., 2015, Sun et al., 2015, Santos and Kassler, 2017, Ashrafi, 2018 and Vestin and Kassler (2017), the authors proposed to use an LTE interface on each SDN-enabled small cell WMBH node for SDN control plane connectivity. LTE provides a robust out-of-band control channel and reduces the SDN control traffic latency, while the data plane operates with the backhaul (multi-hop) connectivity.

4.
Dual homing data plane equipment can be controlled by two or more SDN controllers. It is the case where SDN controllers may be implemented to load-share by running in parallel or redundant configurations, with (near) real-time state database synchronization. Subordinate systems (backhaul forwarding elements) may need to support multiple controller sessions or fast establish new controller sessions (ONF, 2016a, ONF, 2014, ITU-T, 2018b, ITU-T, 2018a).

5.
A service request may need to propagate through a number of hierarchical or neighbor SDN controllers before it is satisfied. It will be necessary to unwind intermediate resource commitments, either for a new attempt or for a failure indication to the originating client (ONF, 2016a).

5.3. Network consistency
Challenges.
Wireless backhaul links are subject to random channel attenuation due to shadowing and multipath fading, which may reduce the end-to-end reliability and increase the latency. The effects on high carrier frequencies, such as millimeter-wave, are higher because higher frequencies are more sensitive to weather disturbances. If the wireless connection is used for control channels connecting SDN controllers with underlying WMBH nodes, inconsistent routing problems occur. The variations in control channel transmission, together with processing delays in the switches can cause flow table updates for different network elements to become unsynchronized. Thus, during network state transition, some of the switches may still forward packets based on the existing rules while others may have updated flow tables with the new rules. The resulting transient inconsistencies can lead to link over-utilization, causing transient congestion (also referred to as bandwidth inconsistency) and packet loss during the flow update time. The inconsistencies during network re-configurations are known as the switching cost, a common challenge in all centrally-controlled networks. It is challenging to populate new forwarding rules synchronously among data plane elements whilst guaranteeing loop, congestion, and black hole issues do not arise during network update. In the case where multiple controllers concurrently perform network updates, it is even more challenging. The decision to adopt new optimal forwarding rules, with the risk of inconsistency, or to continue with the existing sub-optimal forwarding rules, with the risk of throughput loss, can be difficult to make. A wireless backhaul environment can have more challenges to overcome when compared to backhaul using wireline (e.g. fiber) due to stochastic wireless characteristics (Yaghoubi et al., 2018, Maity et al., 2018, Foerster et al., 2018, Mizrahi et al., 2016, Parvez et al., 2018).

Possible solutions.
1.
In Yaghoubi et al. (2018), a control policy for SDN-based WMBH networks affected by rain was proposed. In this work, optimal routing for network flows, and the sequence and timing for applying the routes in the network, provide a real-time weather disruption tolerant routing framework that maximizes network throughput. The authors proposed an algorithm that considers the switching cost and the gain from rerouting and calculates the control sequence of rerouting decisions, to minimize data loss during rain. The proposed algorithm is capable of balancing the need for sequential flow table updates in order to avoid congestion at intermediate states and the necessity for quick rerouting of flows affected by link capacity degradation. The proposed SDN-based WMBH architecture (Yaghoubi et al., 2018) depicted in Fig. 27 consists of different control logic units, including: Statistics Manager, Routing Computation component, Flow Manager, and Decision-making Component. The Statistics Manager periodically gathers the flow-level and physical-layer information from the network. This information is used by the Routing Computation component, which calculates the optimal routes based on the network conditions including link capacity and source traffic demand. The Flow Manager is responsible for applying the optimal routes immediately after receiving them from the Routing Computation component. The Decision-making Component runs the proposed consistency-aware rerouting policy that provides optimal routing for network flows as well as the sequence and the timing for applying the routes in the network, resulting in improved network throughput. The evaluation results verify that transient congestion limits the gain made by frequent rerouting and should be considered during network adaptation. The results also indicate that the proposed policy increases network throughput with fewer re-configurations by selecting the right time to apply the newly computed optimal routes.

2.
The authors in Maity et al. (2018) modify the SDN update scheme and propose a multilevel queue-based policy for ensuring packet-level consistency in SDN-based networks. Network update duration based results are summarized in Fig. 28. The authors stated that their proposal algorithm, CURE, significantly reduces the update duration by approximately 38%.

5.4. Distributed SDN architecture
Challenges.
Peer Controller-to-Controller (C2C) relationships for distributed SDN controllers present a challenge in WMBH networks, especially when the architecture does not include an overarching SDN controller and is used in a WMBH network where node connections are based on an unstable, stochastic wireless environment (Wibowo et al., 2017, ONF, 2014). Some of the challenges related to a distributed SDN architecture are:

1.
An SDN controller requires a significant amount of persistent state information, particularly in client and server contexts. It will be important to ensure timely consistency in mirrors, copies, derivations for such information. An SDN controller may be implemented in a distributed computing form, with redundancy or functional separation or both. Orchestration and Resource Database (RDB) (ONF, 2016a) synchronization among the SDN controllers, maintaining synchronized state during operation and during exception recovery, present interesting challenges. It is even more challenging where the redundancy and functional separations are connected by fluctuating wireless links within a WMBH network (ONF, 2016a, ITU-T, 2018a).

2.
There are challenges associated with high traffic volumes, low latency requirements, low control message load, and network scalability.

3.
Different controller technologies or service functionalities.

4.
Different vendor solutions and the requirement for interoperability.

5.
Different infrastructure domains due to the network spanning one or more network operators.

6.
Scalability of the transport network node count or geographic span, including the distinction between backhaul clusters and metro or aggregation clusters.

7.
SDN controller adjacency and capability discovery.

8.
Data plane neighbor and topology discovery, to the extent agreed by policy.

9.
State and attribute information, including the ability to subscribe to state and attribute change notifications, as agreed by policy.

10.
Forwarding-relevant information, such as reachability at one or more layers.

11.
Path computation information such as route cost, protection or restoration policies.

12.
Other information such as OAM configuration, QoS assessment and reporting, usage information for billing.

13.
Security and contractual issues of trust and information hiding become vital when controllers communicate across administrative domain boundaries. Therefore feature negotiation and policy exchange are possible areas for investigation.

14.
The research into the requirements for a new or revised protocol for SDN C2C purposes is topic research.

15.
Security issues in a multi-level SDN controller scenario, as discussed in ONF (2016a).

5.5. Dynamic resource allocation
As briefly discussed in Section 4.6, SDN-based WMBH dynamic resource allocation is a current research topic that includes the following.

5.5.1. Energy management
Challenges.
In a WMBH network including dense or ultra dense deployment of small cell backhaul, energy efficiency remains a significant research challenge  (Sakaguchi et al., 2017b). If the nodes are continuously powered on regardless of user data traffic load, the result can be high energy consumption and correspondingly, high operational costs (Sakaguchi et al., 2017b, Bercovich et al., 2015, Chen et al., 2016).

Possible solutions.
1.
An SDN adaptive solution that cycles the power on backhaul nodes according to the required capacity could reduce the backhaul energy consumption. This solution raises another challenge which is the creation of SDN-based flexible path calculation schemes in the WMBH network in accordance with the time-variant and spatially non-uniform traffic. It also requires these SDN routing schemes to reduce the reaction time whenever the network topology changes.

2.
Energy efficient WMBH operation can be performed by populating WMBH nodes with SDN rules adaptively to allow the nodes to consume just the required power according to the existing climatic conditions (e.g. reducing transmit power in good weather) or workload (e.g., using only requested radio resources) (Bercovich et al., 2015).

5.5.2. Radio resource management
Challenges.
In the WMBH scenario, wireless channels suffer from time variation and randomness. It is a challenging research topic that may be simplified with dynamic radio resource allocation occurring in a SDN-based WMBH network. The challenge encompasses 4.6:

1.
Dynamic backhaul topology re-configuration. In the event of cellular sites being commissioned or degraded microwave links with an increasing failure probability, the needs arises for an automatic transmission network topology reconfiguration that rearranges the transmission rings into a new optimal ring site configuration state and to maintain an overall acceptable availability (Bercovich et al., 2015).

2.
Dynamic wireless channel assignment.

3.
Selective traffic shaping.

4.
Dynamic spectrum allocation.

5.
Multi-technology coordination in a dynamic manner.

Possible solutions.
Possible solutions for the challenges are briefly discussed in Section 4.6. Dynamic multi-technology coordination in WMBH can leverage separation between logical and physical connectivity. The constraint parameters at the logical level are capacity, utilization, latency, availability, packet delay variation, packet loss ratio and general cost functions (user preferences). In contrast, the constraint parameters at the physical level are link power consumption, spectrum frequency, modulation, and received signal level. Additionally, the logical connectivity usually exceeds the scope of the mobile backhaul, extending the connection from access to the network core, and transmission performance results are agnostic about the conditions experienced by the underlying network. Effective coordination between the network segments traversed, utilizing the reconfigurability and adaptability on the underlying transport capacity, can achieve resource optimization.

In mmWave 5G Hetnets, macrobase stations (macro-BS) and small cells employ multiple antennas, leading to considerable spacial domain information. Thus, it becomes a critical task for mmWave 5G Hetnets to retrieve, store, and utilize the spatial information. In Chen et al. (2016), the authors proposed an architecture with SDN being used as the foundation for the spacial domain information to be collected, analyzed and null-space calculations carried to permit massive MIMO coordination. By doing this, the null-space information is integrated, permitting coordination of the entire network.

5.6. Virtualisation related challenges
As mentioned in Section 4.4, network virtualization in combination with SDN applied in WMBH brings many benefits, however, it also creates many challenges. When constructing an NFV platform, besides traditional VM, lightweight virtualization technologies such as containers, unikernels or specialized VMs, and minimalistic distributions of general-purpose OSes also can be used. In the followings, we highlight some of the NFV challenges.

•
Security: In NFV, resources are shared, it makes security and privacy to be two important aspects that need to be taken into account. With NFV, the telecom operator will act as a tenant who runs the VNFs, and this VNFs may be provided by other service providers who own the underlay infrastructure (NFVI). This creates multiple administrative domains, making security policy coordination more complex (Daghmehchi Firoozjaei et al., 2017).

•
Quality of Service: Guaranteeing QoS in an environment which has virtualized and distributed computing, storage, and networking functions is more challenging than providing the same given QoS in discrete non-virtualized components. One of the examples is ensuring a guaranteed and stable forwarding data rate has proven not to be an easy task when the forwarding function is virtualized and runs on top of commercial off-the-shelf (COTS) server hardware (Mostafavi et al., 2021).

•
Portability: It is the ability to run a given VNF on different NFVIs. The VNF should be able to perform its functions with a high and predictable performance given that a set of requirements on the NFVI resources is met. Portability in such environment with different hypervisors, specific hardware dependencies is not an easy task. State-synchronization aspects are also huge challenges for portability purposes (Chatras and Ozog, 2016).

•
Multiple Domains: :Cross-domain orchestration of services over multi-domain Which ensures hierarchy of networks and their association, with respect to provisioning tunnels and overlays is a challenging task. Another main challenge is the integration/harmonization of different management domains (Mijumbi et al., 2016).

•
Resource allocation: Resource allocation aspects of VNF can be identified as the VNF Placement and Traffic Routing problem; VNF Placement problem; Traffic Routing problem in NFV, and the VNF Redeployment and Consolidation problem (Yang et al., 2021).

6. Conclusion
The SDN paradigm has gained the momentum necessary for it to become a fundamental component of next generation WMBH networks. SDN based networking facilitates intelligent, programmatic and automated networking that is low cost, agile, flexible, simple, and resilient. In this paper, a review of the current research into WMBH networking has been provided. How SDN is being incorporated into the WMBH network architecture is discussed. The challenges identified in this paper highlight the work that remains to be carried out to permit a comprehensive SDN-based solution to be implemented. A brief introduction of the recent ITU-T G.7702 standard for SDN-based transport network architectures has been provided.

The future work identified in this paper includes the challenge to maintain network state consistency in SDN-based WMBH systems during network updates. Another challenge is to mitigate redundant or unnecessary network updates to limit the potential of the fluctuating wireless environment conditions to affect flow control and network management traffic. The research goal is to find an approach that reduces flow control and network management traffic whilst improving reliability and data throughput with reasonable network latency.

