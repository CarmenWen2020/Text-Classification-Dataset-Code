In this article, we propose a novel representation learning framework, namely TRajectory EMBedding via
Road networks (Trembr), to learn trajectory embeddings (low-dimensional feature vectors) for use in a variety
of trajectory applications. The novelty of Trembr lies in (1) the design of a recurrent neural network–(RNN)
based encoder–decoder model, namely Traj2Vec, that encodes spatial and temporal properties inherent in
trajectories into trajectory embeddings by exploiting the underlying road networks to constrain the learning
process in accordance with the matched road segments obtained using road network matching techniques
(e.g., Barefoot [24, 27]), and (2) the design of a neural network–based model, namely Road2Vec, to learn road
segment embeddings in road networks that captures various relationships amongst road segments in preparation for trajectory representation learning. In addition to model design, several unique technical issues raising
in Trembr, including data preparation in Road2Vec, the road segment relevance-aware loss, and the network
topology constraint in Traj2Vec, are examined. To validate our ideas, we learn trajectory embeddings using
multiple large-scale real-world trajectory datasets and use them in three tasks, including trajectory similarity
measure, travel time prediction, and destination prediction. Empirical results show that Trembr soundly outperforms the state-of-the-art trajectory representation learning models, trajectory2vec and t2vec, by at least
one order of magnitude in terms of mean rank in trajectory similarity measure, 23.3% to 41.7% in terms of mean
absolute error (MAE) in travel time prediction, and 39.6% to 52.4% in terms of MAE in destination prediction.
CCS Concepts: • Computing methodologies → Learning latent representations; Neural networks;
Multi-task learning; Regularization;
Additional Key Words and Phrases: Trajectory, neural networks, representation learning, road network
1 INTRODUCTION
With the rapid growth of GPS-enabled devices and the tremendous demands of location-aware applications, enormous amounts of trajectory data are being generated at an unprecedented speed. A
trajectory, typically represented as a sequence of spatio-temporal points to describe the movement
of a mobile user over time, can be used for various kinds of prediction tasks, e.g., travel time estimation, destination prediction, and trajectory outlier detection [23, 28, 40]. Moreover, trajectory
Fig. 1. The proposed computational framework for multi-factor user happiness analysis. Given user timeline
posts, the pet classifier first identifies if he/she is a pet owner; then the state-of-the-art facial detection and
recognition technologies provided by Face++ are applied on all the posts with faces for user demographics
inference; user relationship status, and if having children inferences; and finally, user happiness analysis.
happiness from the perspective of psychological well-being. It has shown by Glenn and Weaver
[5] and Budge et al. [1], satisfactory companion relationship is a crucial factor toward our wellbeing; the companionship could be between human and human as well as human and animal; and
those relationships often interweave with each other. In this article, we are particularly interested
in analyzing how pet companionship, relationship status (i.e., having a partner or not), and having
children affect happiness though a data-driven approach.
Our study proposes a novel, efficient, and scalable computational framework, shown in Figure 1,
to assess the effects of pets, relationship status, and having children on individual happiness. More
specifically, for each user obtained from Instagram, we first apply our pet classifier to identify if
he/she is a pet owner; then we use the state-of-the-art facial detection and recognition technologies
provided by Face++ on all the posts with faces for (1) inferring user demographics; (2) inferring
user relationship status, and if the user has children; and (3) analyzing user happiness.
Our contributions can be summarized in fourfold as follows:
—We apply the cutting-edge transfer learning to construct an extremely high-performance
pet classifier retrained specifically on social media posts.
—We propose an efficient way to infer user’s relationship status, and if having children.
—We analyze the effects of pets on happiness, and further analyze the relationship status, and
having children on happiness in pet and none-pet owner groups, respectively.
—We further show the effectiveness and efficiencies of combining social media resources and
computational methods on large-scale screening and analysis of user-level behaviors, and
psychological well-being.
—To help other research involving human faces, we share our dataset1 including nearly 700K
processed human faces from social media posts.
2 RELATED WORK
Several previous studies have demonstrated the positive impacts of possessing pets for the elderly
[4, 12], while our study focuses on further confirming this effect using a large number of samples
from social media regardless of age, gender, and ethnicity.
1https://github.com/xuefeng7/FACE-LIBRARY.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
The Effect of Pets on Happiness 60:3
Our study is inspired by the preliminary research in Wu et al. [23] but we extend the analyses
in four distinguishable ways: (1) using nearly 10 times more data; (2) retraining the final layer of
the Inception v3 model as our pet classifier, which achieves a superior accuracy; (3) improving
the method of identifying user faces in user timeline posts; and most importantly, (4) considering
multiple factors including user’s relationship status and if having children. In contrast, the work
in Wu et al. [23] analyzed 300,000 posts from around 2,900 users, while our study analyzes around
2 million posts from roughly 20,000 Instagram users. Wu et al. [23] has constructed a reasonable convolutional neural network (CNN) as its pet classifier, while we build a high-performance
classifier by retraining the final layer of the Inception v3 model using remarkably fewer training
samples. In addition, Wu et al. [23] assumed that the largest face in a selfie post is the face of
the user, and analyzed the average happiness of this user according to all of those “largest” faces
throughout this user’s timeline posts. While this is usually valid as most likely the user would be
the one who is holding the camera when taking selfies, it is still possible that the largest face is not
from the user. We reduce such inaccuracy by employing face recognition to identify user faces.
Lastly but most importantly, our work extensively analyzes the multi-factor effects of relationship
status, and if having children on happiness among pet and none-pet owners.
3 DATA ACQUISITION
With billions of users, Instagram is a rich source of high-quality and keyword tagged images. In
our study, timeline posts from both potential pet and none-pet owners are needed. For potential
pet owners, considering that dogs and cats are the two most common pets all over the world,
we collected users who have posted either dog or cat images by retrieving posts tagged with dog
or cat related keywords. To reduce sample biases, multiple hashtags were considered; they are
#mydog, #mypuppy, #mydoggie, and #mycat, #mykitten, #mykitty for dogs and cats, respectively.
After obtaining the usernames, we backtracked up to 100 timeline posts from each user for later
analysis. None-pet owners were obtained in a similar fashion, except the hashtags included are
#selfies, #me, and #life. Eventually, we collected nearly 20,000 users and 2 million posts from their
timelines.
Human face analysis is becoming increasingly popular in the fields of computer vision and artificial intelligence. In order to facilitate related research, we have decided to publish our dataset
whose web link can be found in footnote 1. The dataset contains 700K processed faces that originated from social media posts. Facial attributes such as age, gender, race, as well as facial landmarks
for each face, are provided.
4 PET OWNER IDENTIFICATION
Two steps are taken to identify if an Instagram user is a pet owner or not. First, we classify each
image in a user’s timeline into three classes, namely, dog, cat, and others. Next, since a none-pet
owner might post pet images while visiting a friend who is a pet owner, we identify a pet owner
by looking at the frequency of posting pet images throughout the timeline. We describe the details
in the following subsections.
4.1 Classification
4.1.1 Inception v3 Model. Building a robust deep learning model for object recognition can
cost an enormous amount of computing power and time; therefore, we chose to develop our pet
classification model using the state-of-the-art transfer learning [22]. This technique allows us to
take advantage of a fully trained model, and retrain its final layer for new categories with far less
training samples. The fully trained model we adopt is the Inception v3 model built by Google. The
detailed structure of the model can be found in Szegedy et al. [19], and according to Szegedy et al.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
60:4 X. Peng et al.
Fig. 2. Sample training images of three categories. We train the model by samples specifically collected from
Instagram so that the model can produce better prediction performance on the large-scale Instagram dataset
we used for analysis.
[19], Inception v3 outperforms many other state-of-the-art deep convolutional networks such as
VGGNet, GoogleNet, BN-Inception, and so on, on the ILSVR2014 classification challenge validation
set [18].
4.1.2 Retrain Inception v3 Model. We retrain the final output layer of the Inception v3 model
for three new categories: (a) dog, (b) cat, and (c) others. We collected only 2,000 images of each
category from Instagram, and manually labeled them as our training set. The dog and cat images
contain at least one dog or cat, and others can contain any scene except animals. Figure 2 shows
a few sample images from each category. We utilize Tensorflow as our computation backend; and
with a single Nvidia Tesla K20X GPU, the entire retraining process takes approximately 10 hours.
The model is retrained through 600 steps with the 0.1 default initial learning rate. To avoid
over-fitting, we split 80% of the entire dataset as our main training set, 10% as the testing set, and
the remaining 10% as the validation set. Also, during the retraining phase, 10% of these training
images were randomly cropped, flipped, scaled, mirrored, and brightness-adjusted for improving
model adaptability.
4.1.3 Retrained Model Validation. In the final step, the retrained model achieves 98.4% testing
accuracy and 100% validation accuracy. Cross-entropy for testing and validation sets decreased
from 0.9268 and 1.051 to 0.04 and 0.03 at the end of retraining, respectively. Figure 3 shows the
accuracy curves and Figure 4 shows the cross-entropy curves.
We further verify our model by classifying 1,500 manually labeled unseen images for each class
collected from Instagram; the retrained model achieves high accuracy of 99.0%, 96.4%, and 98.5%
for dog, cat, and others, respectively. The confusion matrix is shown in Figure 5.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
The Effect of Pets on Happiness 60:5
Fig. 3. The testing and validating accuracy curves. The testing accuracy curve is marked in orange, and the
validating curve is marked in blue.
Fig. 4. The testing and validating cross-entropy curves.
Fig. 5. The confusion matrix of the retrained Inception v3 pet classifier.
4.2 Identification
We use two criteria to identify if a user is a pet owner. First, we collect users who have posted
images tagged with either a dog or a cat related topic as described in Section 3. Tags such as
#mydog, #mycat, and so on, are strong indicators that these users own pets; however, exceptions
may exist. Therefore, we develop the pet classifier to further assure that there are indeed dogs or
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
60:6 X. Peng et al.
cats in a pet owner’s timeline. Furthermore and more importantly, since a none-pet owner may
post pet images while visiting a friend who is a pet owner, we also took the frequency of posting
pet images into consideration. We treat 1 week as a time window, and a user is considered as a pet
owner only if the user posts images of the same type of pet, namely, a dog or cat, more than one
time window throughout his/her timeline. If a user posts pet images only within one time window
(1 week), this person is not considered as a pet owner regardless of the amount of pet pictures
posted. This is similar to the approach adopted in Wu et al. [23].
5 TIMELINE ANALYSIS
Face++ is an open source face engine with both an online API and an offline SDK that provide
services including face detection, face recognition, and face analysis. The system is built with
a CNN structure similar to the ImageNet structure as discussed in Section IV-A [9], where five
convolutional layers with maxpooling are connected with two fully connected layers and a softmax
layer on top of them.
In addition, Face++’s services have been widely used in commercial applications by many major
companies in China. By integrating Face++, AliPay—used by more than 120 million people—allows
users to transfer money securely by using their faces as credentials. Meanwhile, Didi, China’s dominant ride-hailing company, uses the Face++ software to allow passengers to confirm the driver’s
identity. Lenovo, a world-wide computer manufacturer, also adopts the biologic identification solution from Face++.
We adopt the reliable services provided by the Face++ engine [3] to detect, analyze, and recognize faces in each user’s timeline for three purposes:
—Identify a user’s faces and infer his/her demographics such as age, gender, and race.
—Identify the frequently appeared faces in a user’s timeline, and infer their demographics.
—Analyze the smiles of user faces to infer his/her overall happiness.
5.1 Face Detection
Given a user, face detection is applied to every image within his/her timeline. Note that if a user’s
timeline contains less than five faces, such user will be discarded from further analysis. In addition,
since more posts will assist us to identify more accurately if a user is a pet owner, or if a user has
a partner, we also discard a user whose timeline contains less than 25 posts from further analysis.
For each detected face, its attributes including gender, age, race, smiling, glasses, and pose will
be computed. The attributes we are interested in are age, gender, race, and smiling. Figure 6 shows
a few examples of applying Face++ on faces.
Face++ uses the same methodology developed in Kumar et al. [10] to detect smiling. Note that,
as expected, the smiling values of the faces in Figure 6(a) and (b) are much higher than those in
Figure 6(d) and (c). This score is an important indicator for our later happiness analysis.
5.2 Face Grouping
It is possible that photos in a user’s timeline contain not only his/her own faces, but also the faces
of his/her friends, family members, and even strangers. Therefore, we need to group the faces into
several face sets where each face set consists of only one individual’s faces. To achieve this, for
each user, (1) we create a faceset, (2) detect every face in a user’s timeline posts and add them into
the faceset, and (3) utilize face recognition technology [24] to group faces in the faceset.
Figure 7 shows the entire process from face detection to face grouping.
5.2.1 User Identification. The person listed in Figure 7 is sorted in a descending order by the
number of faces. We consider the most frequently appeared face as the user’s face. Based on
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
The Effect of Pets on Happiness 60:7
Fig. 6. Examples of demographics and smiling attribute extracted from detected faces.
Fig. 7. The process of face detection and face grouping for user identification, inferring relationship status,
and if having children.
this assumption, in the grouped faceset, we can easily locate the user. We conduct the happiness
analysis solely for the faces identified as the user.
5.2.2 Relationship Status, Having-Children Inference. As shown in Figure 7, the second and third
most frequently appeared faces in a user’s timeline may have close relationships with the user. We
further infer such relationship by checking the age. Similar to how we identify pet owners, we
also consider the frequency while determining if a user has a partner or child. A user is considered
to have a partner, if another person’s face appears throughout the user’s timeline for more than a
time window (1 week), and the age difference between the user and the person is less than 5 years.
In the same vein, a user is considered to have a child if (1) the user is older than 18 years old and
(2) another person’s face appears throughout the user’s timeline for more than one time window,
and the age difference between the user and the person is more than 18 years.
5.3 Happiness Analysis
We consider both visual and textual context in our study of happiness.
5.3.1 Visual Context. Our methodology of quantifying user happiness is in the same vein as [4,
17]. Let Ht denote the visual happiness score of a user over a period of t, |Ft | denotes the number
of user faces in the timeline over the time frame t, and Si indicates the confidence score of smiling
for the user face appearing in the post i. Equation (1) calculates the final visual happiness score
for any given user.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
60:8 X. Peng et al.
Table 1. Gender and Race Distribution
Asian African American Caucasian Sum
Male 562 333 2,333 3,228
Female 1,648 348 5,312 7,308
Sum 2,210 681 7,645 10,536
The majority of collected faces are Caucasian, followed by Asian and African American.
Moreover, the female faces are about twice more than male faces.
Ht =

i ∈t Si
|Ft | . (1)
Note that the smiling confidence score for each face is acquired during the face detection phase.
5.3.2 Textual Context. We also utilize the sentiment analysis on the user post captions to infer
user happiness. In particular, we take advantage of Valence Aware Dictionary and sEntiment Reasoner (VADER) [8] as our lexicon and rule-based sentiment analysis tool. This analyzer is specifically attuned to sentiments expressed over social multimedia. Moreover, VADER is particularly
suitable for our study as it can capture many sentiment-laden slangs, emoticons, initialisms, and
acronyms such as “:),” “:D,” “friggin,” “sux,” and “lol,” which are prevalent in Instagram post captions. According to Hutto and Gilbert [8], for each given caption, a normalized, weighted composite score from −1 (most extreme negative) to 1 (most extreme positive) is generated to measure its
emotion. In our study, we use the average composite score to infer user happiness. Let Ct denote
the textual happiness score of a user over a period of t, |Pt | denotes the number of all user captions
in the timeline over the time frame t, and Wi indicates the composite score of the caption for user
timeline post i. Like Equation (1), Equation (2) calculates the final textual happiness score.
Ct =

i ∈t Wi
|Pt | . (2)
6 MAIN RESULTS
In this section, we present our findings. We first show the demographic distribution of our users
in Section 6.1. Then, in Section 6.2, we investigate the happiness over pet and none-pet owners
separately in terms of relationship status, and if having children.
6.1 Demographics
In our study, we process over 20,000 users, but the filter step described in Section 5.1, and the petowner identification step together help us refine our user collection. 10,536 users were kept for
our happiness analysis. In terms of gender, we have 7,308 females and 3,228 males; for race, there
are 2,210 Asians, 681 African Americans, and 7,654 Caucasians. Table 1 summarized the gender
and race distributions.
Figure 8 shows the distribution of pet, partner, and children.
6.2 Happiness
In this subsection, we present happiness score comparisons. Note that we report H¯
t and C¯
t in
parallel along with the significance tests. The statistical significance test we employed is a multiple
comparison test [7], which compares the means of several groups to test the hypothesis that they
are all equal, against the general alternative that they are not all equal. This testing procedure also
provides the information about which pairs of means are significantly different. Also note we used
the 95% confidence level throughout our analysis.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.  
The Effect of Pets on Happiness 60:9
Fig. 8. Pet owner, partner, and children distributions. As shown, in terms of Pet and Partner categories, the
number of users are balanced; however, for the last category, the amount of users without child is much
higher than that of users with child.
Fig. 9. The mean happiness score comparison between dog, cat, and none-pet owners. The upper and lower
charts represent H¯
t and C¯
t , respectively. As shown, users with a pet, either cat or dog, have a higher mean
happiness score than none-pet owners when their photos and captions are analyzed.
Table 2. Multiple Comparison Test Results for Happiness Scores
Over Pet and None-Pet Owners
H¯
t
Categories Lower Est. mean diff Upper p-val
dog-cat 1.6018 3.3093 5.0168 0
dog-none 10.9853 12.5968 14.2084 0
cat-none 7.6883 9.2875 10.8868 0
C¯
t
dog-cat 0.0187 0.0252 0.0317 0
dog-none 0.0323 0.0384 0.0445 0
cat-none 0.0071 0.0132 0.0192 0
6.2.1 Pet and None-Pet Owners. We present the mean happiness scores in Figure 9, and multiple
comparison test results in Table 2.
H¯
t and C¯
t share the same trends among dog, cat, and none-pet owners. Dog owners possess
the highest scores, followed by cat owners, and then none-pet owners. If we combine dog and cat
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
60:10 X. Peng et al.
Fig. 10. The mean happiness score comparisons between genders among pet and none-pet owners. As shown,
both genders show a higher mean happiness score when they have a pet, and females typically have a higher
happiness score than males.
owners as pet owners, then the significant test denotes that H¯
t and C¯
t of pet owner are higher
than that of none-pet owner by 10.92 ± 1.14, with p-values both equal to zero.
Note that we merge dog and cat owners as pet owners for the rest of the analyses.
6.2.2 Gender. We compare the H¯
t and C¯
t over different genders among pet and none-pet
owners in Figure 10.
The test results suggest that for pet and none-pet owners, the differences of H¯
t between female
and male are 11.58 ± 2.05 (p-value = 0), 11.46 ± 2.4 (p-value = 0), respectively. No significant C¯
t
differences were found between genders for both groups.
6.2.3 Race. We also compare the H¯
t and C¯
t over different race groups among pet and none-pet
owners in Figure 11.
In terms of H¯
t , the difference between Asian and Caucasian pet owners is significant, and its
value is −3.17 ± 2.74 (p-value = 0.0016). Similarly, among none-pet owners, the H¯
t of Asian is
−3.46 ± 2.98 (p-value = 0.0121) lower than that of Caucasian. The significant differences of C¯
t
among different racial groups are summarized in Table 3.
In general, in both pet and none-pet groups, Asian has lower H¯
t and C¯
t than those of Caucasian
and African Americans.
6.2.4 Partner. In this subsection, we investigate the effect of having a partner on happiness for
pet and none-pet owners.
As shown in the Figure 12, H¯
t and C¯
t share the same trends over population having partner
and having no partner in both pet and none-pet owner groups. More specifically, in both groups,
those who have partners possess higher H¯
t and C¯
t . The significant tests suggest that among pet
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
The Effect of Pets on Happiness 60:11
Fig. 11. The mean happiness score comparisons between races among pet and none-pet owners. Pet owners
have a higher average happiness score than none-pet owners regardless of race. It also shows that Asians
have a lower average happiness score when compared to African American and Caucasian.
Table 3. Multiple Comparison Test Results for Happiness Scores
Over Races Among Pet and None-Pet Owners
Pet Owner
Categories Lower Est. mean diff Upper p-val
Asian - Caucasian −0.0239 −0.0135 −0.0031 0.0029
Asian - African. A −0.0392 −0.0199 −0.0006 0.0391
None Pet Owner
Asian - Caucasian −0.0363 −0.0250 −0.0137 0
Asian - African. A −0.0527 −0.0326 −0.0124 0.001
owners, H¯
t for those who have a partner are 3.54 ± 1.93 (p-value = 0.0) higher than that for those
who have no partner. No statistically significant difference exists with respect to C¯
t .
Among none-pet owners, H¯
t and C¯
t for those who have partner are 6.77 ± 2.31 (p-value = 0.0),
and 0.01 ± 0.0089 (p-value = 0.0) higher.
6.2.5 Child. In this subsection, we examine the effect of having children on happiness for pet
and none-pet owners.
As Figure 13 shows, in both pet and none-pet owner groups, the population with children possesses higher H¯
t and C¯
t . We present the significant test results in Table 4.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
60:12 X. Peng et al.
Fig. 12. The mean happiness score comparisons between having partner and having no partner among pet
and none-pet owners. According to the chart, pet owners have a higher average happiness score than nonepet owners, and people with partners have a higher average happiness score than people without partners.
Table 4. Multiple Comparison Test Results for Happiness
Scores Over Having Child and Having No Child Populations
Among Pet and None-Pet Owners
Pet Owner
Score Lower Est. mean diff Upper p-val
H¯
t 1.8128 4.7442 7.6756 0.0002
C¯
t 0.0158 0.0270 0.0381 0
None Pet Owner
H¯
t 5.6261 9.0561 12.4861 0
C¯
t 0.004 0.0171 0.0301 0
7 CONCLUSIONS
In this study, we present a computational framework of using user-level multimedia posts from
Instagram to investigate the effects of pets on happiness in terms of multiple aspects of user demographics. An Inception v3, which is retrained specifically on social media data, and timeline
analysis together form the pet-owner classifier. The Face++ engine is employed for face detection,
recognition, and user demographics inference. Among pet and none-pet owners, we also examine
the happiness over different genders, different races, having partner or not, and having child or
not. We believe our proposed framework is applicable to other related domains as a scalable, efficient, and effective methodology of social media user behavioral, and psychological well-being
modeling and analysis.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
The Effect of Pets on Happiness 60:13
Fig. 13. The mean happiness score comparisons between having child and having no child among pet and
none-pet owners. The chart illustrates that pet owners have a higher average happiness score than none-pet
owners, and people with children have a higher average happiness score than people without children.
8 LIMITATION AND FUTURE WORK
Our study infers user relationship status and if having children by checking the posting frequency
of faces, plus age differences. However, there are possible and perhaps rare exceptions. For instance, if a user frequently posts pictures with his/her close friends, this user may be classified as
having a partner (although arguably a close friend serves some of the social fucntions of a partner). It is also possible that a user frequently posts a child star, and this user could be identified as
having a child. Nonetheless, we believe the trends and distributions in our large-scale study will
remain consistent and valid, especially given that a significantly large number of users and images
are analyzed.
Our work only includes data collected from Instagram, so this may not reflect the happiness level
across different cultures outside the United States. Indeed, culture is one of the most important
variables that impacts happiness [11]. In the future, we plan to collect multimedia posts through
other countries’ social media platforms, such as Chinese Wechat and Weibo, to analyze happiness
in terms of culture—another important factor. Also in our current work, we consider the happiness
scores derived from visual and textual contexts separately. It can be even more effective to infer
an individual’s happiness if integrating those two types of scores organically.
According to Ura [21], many other factors, such as education, community, and living standard,
can impact individual happiness; those factors can be integrated into our happiness analysis if
users’ education and employment records are accessible from social media such as LinkedIn.
Furthermore, personality is also associated with the pursuit of happiness [20], and may be used
as a predictor of happiness [2]. According to Gottschalk [6], words people use in their daily lives
can provide rich information about their beliefs, fears, thinking patterns, social relationships,
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 5, Article 60. Publication date: June 2018.
60:14 X. Peng et al.
and personalities. By collecting user-level tweets plus leveraging Language and Inquiry and
Word Count (LIWC2015) [17], Pan et al. [13] successfully connected the personality with career
progression. In the same vein, we can also form an effective and automatic personality analysis
tool for studying the effects of personality on happiness at a large scale.
Furthermore, social multimedia posts offer the potential to provide a method for mass screening for individuals at risk for a range of poor health and psychological conditions. In particular,
insufficient and low-quality sleep, unhealthy work-life balance are highly accountable for one’s
loss of happiness. Peng et al. [15] and Peng et al. [16] used user-level multimedia posts to study
sleep deprivation and human fatigue in a massive scale. With some extension, the correlation between sleep, fatigue, and happiness can also be quantified. In addition, Instagram has been used to
pick up signals when individuals use language that could be related to risky behaviors [14]. In the
same way, our proposed framework can be extended to an automatic tool to monitor individual
happiness to detect risk such as depressions, and allow for early intervention.