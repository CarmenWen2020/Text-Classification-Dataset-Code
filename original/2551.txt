Detecting abnormal behaviors of students in time and providing personalized intervention and guidance at
the early stage is important in educational management. Academic performance prediction is an important
building block to enabling this pre-intervention and guidance. Most of the previous studies are based on
questionnaire surveys and self-reports, which suffer from small sample size and social desirability bias. In
this article, we collect longitudinal behavioral data from the smart cards of 6,597 students and propose three
major types of discriminative behavioral factors, diligence, orderliness, and sleep patterns. Empirical analysis demonstrates these behavioral factors are strongly correlated with academic performance. Furthermore,
motivated by the social influence theory, we analyze the correlation between each student’s academic performance with his/her behaviorally similar students’. Statistical tests indicate this correlation is significant.
Based on these factors, we further build a multi-task predictive framework based on a learning-to-rank algorithm for academic performance prediction. This framework captures inter-semester correlation, inter-major
correlation, and integrates student similarity to predict students’ academic performance. The experiments on
a large-scale real-world dataset show the effectiveness of our methods for predicting academic performance
and the effectiveness of proposed behavioral factors.
CCS Concepts: • Information systems → Information systems applications;
Additional Key Words and Phrases: Campus behavior, student personality, academic performance prediction
1 INTRODUCTION
Education is the foundation of a nation. One important task of educational research is the early
prediction of academic performance, which not only helps educators design in-time intervention
but also facilitates personalized education. The major challenge is to reveal important factors that
affect students’ academic performance. It has been demonstrated that physical status [23, 29], intelligence quotient [9], and even socioeconomic status [38] are correlated with academic performance. However, these characteristics are relatively stable over the long run and are difficult to
change via educational management.
Comparatively, more studies are focused on the perspectives of psychology and behavior, partially due to the possibility of intervening on the student’s mentation and behavior. Extensive
experiments about the correlation between the big-five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) and academic performance have been reported [2, 25, 33], uncovering conscientiousness as one of the strongest predictors. Behaviors like
class attendance [8], lifestyle [34], and sleep habit [10] are also highly associated with academic
performance. However, almost all of these results are obtained from questionnaires or self-reports,
which usually suffer from small sample size and social desirability bias, resulting in the difficulty
to draw a valid and solid conclusion.
Thanks to the development of information technology, there is a growing trend to augment
physical facilities with sensing, computing, and communication capabilities in modern universities. These facilities provide an unprecedented opportunity to collect real-time digital records
about students’ campus activities in an unobtrusive way and to reveal behavioral predictors for
academic performance. In this article, mainly through the campus smart card, we collect 6,597 students’ longitudinal behavioral data spanning almost 3 years. These behaviors include entry-exit of
library and dormitory, book borrowing, consumption on campus places (e.g., canteen, supermarket, and teaching building).
From these records, we quantify diligence and orderliness as two kinds of behavioral predictors
for academic performance, which is motivated by the strong effect of conscientiousness on academic performance [11]. The diligence predictors estimate how much time students spend on
studying while the orderliness predictors quantify the regularity of students’ life and study on
campus. Furthermore, according to the previous study about the correlation between students
sleep patterns and their academic performance [10, 32], we extract students’ sleep patterns from
our dataset and regard it as another important predictor. Empirical analysis shows these behavioral predictors are strongly correlated with academic performance (e.g., the averaged Spearman
correlation of diligence over semesters achieve as much as −0.308).
Motivated by social influence theory, we further analyze the correlation of each student’s academic performance with his/her behaviorally similar students’. As suggested in [40], student’s
behavioral similarity is computed based on their co-occurrence at the same location within a
short time interval. We test the significance of this correlation via t-test and the result indicates
that this correlation is significant. Hence, students with similar lifestyles also have close academic
performance.
These observations and analysis motivate us to predict students’ academic performance for
helping education administrators detect undesirable abnormal behaviors in time and implement
effective interventions. We aim to tackle the following three challenges: (1) These factors’ predictive strength changes across semesters and among different majors, that is, how to model these
changes for academic performance prediction; (2) The number of students varies from major to
major (from 50 to 600), thus the amount of training data in some majors are limited to train a good
prediction model; and (3) It is possible that some students don’t have sufficient behavioral data so
that behavioral factors could be unreliably measured.
To address the aforementioned challenges, we propose a novel Multi-Task Learning-To-Rank
Academic Performance Prediction framework (MTLTR-APP) for predicting students’ academic
performance. Specifically, we impose a sequential smoothing regularization term to model the
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:3
Fig. 1. The framework of proposed MTLTR-APP. First, three behavior features are collected based on campus
behavior data: diligence, orderliness, and sleep pattern. Then, the value of student similarity is calculated
by the campus behavior data. Next, the multi-task learning framework is proposed to predict the score of
each student. Finally, by combining the score with behavioral similar students, the final predicted academic
performance is presented. We use actual academic prediction data to evaluate our model.
inter-semester temporal correlation. In addition, though factors’ predictive strength for academic
performance is varied from major to major, there is still commonality among similar majors (e.g.,
computer science and electronic engineering). We construct a matrix-factorization-based multitask model to capture the inter-major correlation for helping the prediction of majors with limited training data. Our framework further incorporates student similarity to help the prediction
of students without sufficient behavioral data. Figure 1 illustrates the whole framework of our
MTLTR-APP. Specifically, based on campus behavior data, we extract three types of features and
calculate student behavioral similarity value. Then we use the proposed multi-task learning model
and integrate it with student similarity to predict students’ academic performance.
Finally, we train the proposed predictive algorithm on a large-scale behavioral dataset from a
grade of 3,352 college students from 18 majors spanning 5 semesters and test it on another behavioral dataset from the subsequent grade of 3,245 students from 17 majors spanning 5 semesters.
The evaluation results show the effectiveness of our proposed method on academic performance
prediction. The results also demonstrate that each behavioral factor is effective for predicting academic performance.
The contributions of this article are four-fold:
• Based on the big five personality traits, we quantified two personal behavioral factors (diligence and orderliness) and showed their strong correlation with academic performance.
• We measured students’ behavioral similarity and incorporated it into our proposed prediction framework.
• We proposed a novel multi-task learning-to-rank model to predict students’ academic
performance.
• We conducted comprehensive experiments on a large-scale educational dataset. The results
show the effectiveness of our proposed algorithm.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
24:4 H. Yao et al.
2 RELATED WORK
2.1 Analysis of Factors Influencing Academic Performance
In the fields of education and psychology, much research has focused on identifying the predictors
of college student’s academic performance. Many existing studies concentrated on the association
between students’ personality traits, lifestyle behaviors (e.g., physical activity [14, 24], sociability [27], sleep [10, 42]), intelligence level [21] and academic performance. Meta-analysis of the
five-factor model of personality and academic performance indicated that academic performance
is correlated with agreeableness, openness to experience, particularly conscientiousness [2, 25].
However, almost all research is primarily based on students’ self-reports and questionnaires, which
may be susceptible to a range of limitations, such as small sample size, social desirability bias.
2.2 Academic Performance Prediction
With the development of information technology, many efforts have been devoted to predicting
performance based on students’ digital records collected from online learning platform. For example, in an online learning environment, one line of research applied transfer learning [16], graphical
model [12, 35], multi-view semi-supervised learning [22] to predict student dropout by using their
online behavior data. Another line of studies in online learning system utilized multiple instance
learning [41], tensor factorization [31], probabilistic latent semantic analysis [4], and fuzzy cognitive diagnosis framework [39] to predict students’ performance. Unlike previous studies on online
learning platform, in this study, we mainly focus on the offline behavior feature to predict academic
performance.
Based on the students’ previous course records/grades and their demographical data, longitudinal data analysis is leveraged in [28] for predicting whether a student is at risk of getting
poor assessment performance. Regression models [1, 6], support vector machine [19], naive Bayes
model [17] are also utilized to predict students’ academic performance by using historical course
grades. However, temporal granularity of historical course performance is much coarser than campus behavior. In order to better provide timely personalized intervention and guidance according to
campus behavior, the goal of our framework is to detect the effect of students’ campus behavior on
academic performance. These behavioral predictors are then used to predict academic performance.
Recently, some studies started concentrating on predicting academic performance based on daily
behavior data collected by the sensor. StudentLife [36] and SmartGPA [37] studies found correlations between students’ GPAs and automatic sensing behavior data obtained from smartphones.
Another study [26] measured students’ physical activity using a sensor armband in addition to
self-reports and found that changes in physical activity were associated with GPA. However, the
passive sensing behavior data they used was only collected from a small number of student volunteers, which may not be fully spontaneous. Unlike previous works, our behavior data focusses on
the daily life on campus when using smart cards and our prediction is based on a large-scale behavior
dataset which contains a large number of students.
3 PROBLEM STATEMENT
In this section, we will introduce some notations and then formally define the problem in this
work. In a university, let M = {1, 2,..., M} and S = {1, 2,..., S} denote the set of majors and
semesters, respectively. The set of students in every major is defined as Q = {N1, N2,..., NM }.
For every student i in major m at semester s, we define the feature vector and his academic
performance as xs,m
i ∈ Rp and ys,m
i , respectively. Let Xs,m = [xs,m
1 , xs,m
2 ,..., xs,m
|Nm |
]
T ∈ R|Nm |×p
and ys,m = [ys,m
1 ,ys,m
2 ,...,ys,m
|Nm |
] ∈ R|Nm | denote the feature matrix and academic performance
of all students in major m at semester s. Note that, the academic performance in this article is
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:5
represented by the students’ rank. The details of the features will be described in the following
section. Then, we formally define our academic performance prediction problem as follows:
Academic Performance Prediction Problem. At semester s, given the feature matrices Xs,1
i ,
Xs,2
i ,..., Xs,M
i of every major, we are supposed to predict the corresponded academic performance
ys,1
i , ys,2
i ,..., ys,M
i in this semester.
4 BEHAVIORAL ANALYSIS
In this section, we will first introduce the dataset for this problem, and then analyze the relation
between behavioral features (i.e., diligence, orderliness, sleep pattern) and academic performance.
Finally, we measure and analyze student similarity based on social influence theory. Such analysis
motivates us to build a meaningful academic performance prediction model.
4.1 Dataset
We collect data from one university between 9/1/2011 and 6/30/2015. This dataset consists of two
types of data, which are described as follows:
4.1.1 Behavioral Data. In most universities, every student owns a campus smartcard as the
recognition tool for identification. These smartcards could be used for the unique payment (access)
medium for many consumptions (resources), and thus record a large volume of behavioral data,
including almost all potential activities on campus, such as getting boiled water in the teaching
building, entering the library, and paying for meals in the cafeteria. The collection of smartcards
data is unobtrusive, which is different from previous studies whose data is mainly collected from
self-reports and questionnaires and suffer from a small sample size and social desirability [2, 8, 25,
33, 34].
4.1.2 Academic Performance Data. Students’ academic performance is also be recorded, which
contains the grade, credit of each course for each student. For protecting privacy, in this article,
we calculate Grade Point Average (GPA) for each student and then get the rank of GPA. Finally, in
each semester, we normalize the ranking list to [0, 1] within every major and get the normalized
rank list. The normalized rank is regarded as the academic performance of each student, whose
value close to zero means better performance.
4.2 Personality Analysis
Big Five personality traits (i.e., Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism) is a traditional psychology model based on common language descriptors of personality [15]. Previous work has shown the effect of the five-factor model on job/academic performance
(conscientiousness in particular) [2, 25, 33]. Based on the usage data of smartcards and motivated
by this effect, we first extract two types of important predictors: diligence and orderliness, and
then analyze their correlation with academic performance.
4.2.1 Diligence. Diligence is strongly related to a narrow trait of conscientiousness: achievement, which reflects the tendency to strive for competence and success in ones’ work/study [43].
From the usage data of smartcards, diligence is mainly represented by the amount of time that
students spend on their study. Although we couldn’t have an explicit measure, we count the occurrence frequencies at learning areas as a proxy. The most evident study areas include the library and
teaching buildings. In consideration of safety, libraries in modern universities establish entrance
guard systems so that students are required to swipe their smartcards before entering libraries. Besides, the library provides all kinds of books for students to borrow but requiring their smartcards
for authorization. In the teaching building, although there are no such facilities, students may get
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
24:6 H. Yao et al.
Fig. 2. The correlation between diligence and academic performance.
boiled water for drinking when they attend classes or review lessons, particularly in winter. For
the sake of water conservation, students also need to make a small payment (a few cents). These
payment records can be regarded as the proxy of studying in the teaching building.
Therefore, for diligence, we calculated the occurrence frequency at the library and teaching
building. The correlation of these diligence factors with academic performance is shown in Figures 2(a) and 2(b), where we remove the influence of mean value of diligence for comparison across
semesters. The higher value of occurrence frequency at the library and the teaching building means
the higher degree of diligence. We observed that diligence is negatively correlated with the performance rank, where the averaged Spearman correlation over semesters can achieve as much as
−0.308. Such an observation indicates that a student’s hard study can be paid back by achieving
good academic performance. Besides, we also discovered that the correlation varies from semester
to semester. Particularly, the Spearman correlation in the first semester is significantly lower than
the other semesters, whose value are −0.176 and −0.157 in Figures 2(a) and 2(b), respectively, while
the correlation of other semesters are higher than −0.249. One potential reason is that academic
performance in the first semester still highly depends on the knowledge obtained in high school
and there are no large behavioral differences between students. The correlation of more diligence
factors with academic performance is shown in Table 1. It is worth noting that we have put the
frequencies of going to printing room into the diligence characteristics because the students need
to review many teaching materials before the exam.
4.2.2 Orderliness. Orderliness is another important narrow trait of conscientiousness, which
reflects the tendency to keep things organized and tidy [11] and has been reported as another
important factor that can affect academic performance [2, 3, 18, 25]. Orderliness can be measured
as the regularity of activities, such as having breakfast, taking a shower, and the like. In general, the
regularity of each activity can be quantified as the Shannon entropy of its temporal distribution,
which is defined as:
H = −

i
p(i) logp(i), (1)
where p(i) is the probability of carrying out the activity during the ith period of a day and estimated by kernel density estimation. In our case, each period is defined as 1 hour. The entropy H
represents the temporal uncertainty of the activity. We use entropy for measuring regularity of
taking a shower and shopping. In our dataset, all students have records of taking a shower and
almost 95% of the students go to the supermarket in one semester, so these two activities are highly
frequent and can objectively reflect the students’ lifestyle. The larger the entropy, the higher the
temporal uncertainty of these two activities, i.e., the lower their orderliness.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019. 
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:7
Fig. 3. The correlation between orderliness and academic performance.
Breakfast is another important activity that reflects the regularity of students’ life. However, the
time of having breakfast is easily affected by the time of the first class each day, which differs from
day to day for students of the same major. Thus, for measuring the regularity of having breakfast,
we only compute the frequency that each student swipes his card in the cafeteria from 6 am to
9 am. Almost 98% of the students have records in this time period. The larger the frequency, the
higher the regularity of having breakfast.
The correlations of the regularity of having breakfast and taking a shower with the performance
rank are shown in Figures 3(a) and 3(b). The effect of the mean value of orderliness is also removed.
These two figures indicate that regularity is positively correlated to the academic performance.
Besides, similar to the result of diligence, the correlation of orderliness varies among different
semesters and thus can be explained by the same underlying reasons. The correlation of shopping
regularity with performance rank is also computed and shown in Table 1.
4.3 Sleep Pattern Analysis
According to the previous studies about the correlation between students’ sleep patterns with their
academic performance [10, 32], students with good sleep habits tend to achieve better performance.
In particular, the wake-up time and bedtime are of great importance for academic performance [30,
32]. Students with later wake-up times and bedtimes tend to perform worse.
In our dataset, we do not have the actual information of bedtimes and wake-up times. However,
students need to use their smartcard to get hot water, to enter-exit their dormitories, and to take
a shower in the morning or evening. Thus, the last and first smartcard records in each day are
regarded as surrogates of students’ wake-up times and bedtimes, respectively. Considering the
different starting time of classes in the morning and end time in the evening, too specific wake-up
times and bedtimes may not represent the actual sleep pattern. So we calculate the frequency of
first and last hours of smartcard records and choose the timestamp of highest frequency, which are
used to represent each student’s sleep pattern. We only have several concrete values (e.g., wake-up
time concentrates in 6, 7, 8, 9, 10; 6 means students wake up at 6:00 am–7:00 am). The correlation
of each student’s academic performance under different wake-up times and bedtimes are shown
in Figures 4(a) and 4(b), respectively.
In Figure 4(a), students who wake up late may be associated with poorer performance. Since
the earliest classes usually start at 8:30 am, students who wake up at 6:00 am and 7:00 am are both
considered as having an early wake-up, and they achieve the best performance. In Figure 4(b), we
can see students who go to bed too late (after 1:00 am) perform worse, which may be explained by
the addiction of online games. In spite of showing an interesting correlation with academic performance, sleep patterns do not have a significant effect, after being integrated with diligence and
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
24:8 H. Yao et al.
Fig. 4. The correlation between wake-up times and bedtimes. In (b), bedtime with value 0, 1, 2 means students
go to bed in the next day.
Table 1. Student Behavioral Features
Features Correlation Coefficient
Frequency in the lib –0.3063
Frequency in the lib on weekends –0.3262
Frequency in the lib before exams –0.2984
Frequency of borrowing books –0.3031
Diligence Frequency of getting water –0.3258
Frequency of getting water on weekends –0.2997
Frequency of getting water before exams –0.3308
Frequency of printing –0.1324
Frequency of printing before exams –0.0943
Breakfast –0.3621
Orderliness Shower 0.1697
Shopping 0.0809
Sleep1 Bedtime 0.0589
Wake-up time 0.0765
The correlation coefficient of sleep pattern is Cramér’s V value, while others are Spearman value. All
p-value of correlation is greatly smaller than 0.001. “Before exams” means 20 days before final exams.
1Sleep means sleep patterns.
orderliness. One potential reason may lie in bias estimation of sleep/wake-up times. The features
of sleep patterns are also shown in Table 3. Note that sleep pattern features are one-hot features,
so we cannot calculate the Spearman correlation. Instead, we discretize the academic performance
to five groups. Then, we calculate the Cramér’s V value [7] between discretized academic performance and sleep pattern as the correlation coefficient and show the results in Table 1.
4.4 Student Similarity
As suggested in [40], two students may have similar academic performance if they behave in a
similar way. Student similarity is another important factor to analyze students’ academic performance, which is measured by their co-occurrence in this article. Each co-occurrence is assumed
as two students generating records at the same location within a short time interval, which is empirically set as 1 minute. However, some co-occurrence may occur at random, which motivates us
to set a threshold to remove the effect of these random cases.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:9
Fig. 5. (a) (b) (c) represent the comparison of co-occurrence distribution of null model and real case at the
cafeteria, supermarket, and library, respectively.
Follow the settings in [40], we first construct a null model by randomly shuffling the timestamps
of behavioral records. For example, if one student’s record of location-time pair is {(21:50:55, teaching building); (22:03:06, library); (23:00:05, dormitory)}, we shuffle these three timestamps. Then we
compute the mean and standard deviation of co-occurrence frequency by repeating the construction process 20 times. The comparison of the co-occurrence frequency between the null model
and the real case at the cafeteria, supermarket, and library are shown Figures 5(a), 5(b), and 5(c),
respectively. We determine the threshold by keeping the co-occurrence frequency of the real case
above the mean co-occurrence frequency plus two times of standard deviation of the random case,
and in these three locations is 18, 112, and 23, respectively.
Based on the derived threshold, we drop those co-occurrence frequencies below the threshold
at each location. Furthermore, in this study, the co-occurrence frequencies are computed from L
different locations, so we need to combine these frequencies together. However, since we have
neither evidence on the importance of different locations nor real similarity information used as
training data for location importance learning, we simply define the similarity between student i
and student j as:
τij =

L
l=1
τ l
i,j/ maxj τ l
i,j, (2)
where τ l
i,j is the co-occurrence frequency at the location l.
As we mentioned before, if two students behave similarly, they may have similar academic
performance. In other words, each student’s academic performance should be close to those who
are frequently co-occurring with him. For each student i, we can get one student group Fi, which
contains students who frequently co-occur with i. Based on our dataset, we construct a campus
social network and the result of this study is shown in Figure 6. The x-axis represents the rank of
each student i and the y-axis represents the average rank of students in the corresponding student
group Fi . The Spearman correlation between students’ academic performance and the averaged
academic performance of students in the corresponding group is 0.434.
Furthermore, we test the effect of student similarity with regard to academic performance by
comparing the similarity between the similar student group and the nonsimilar student group, As
shown in [13] and [40], we first define the similarity of academic performance between a student
i and a student group R as:
QR (i) =

j ∈R sim(i, j)
|R| , (3)
where sim(i, j) = |ys,m
i − ys,m
j | represents the similarity of academic performance between students i and j. The average similarity between student i and his similar students and the average
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.  
24:10 H. Yao et al.
Fig. 6. Correlation between students’ performance and the average of their similar students’ performance.
similarity between student i and bootstrap-sampled 20 students from his non-similar students’
list are calculated and defined as QF (i) and QNF (i). We then conduct the two sample t-test on the
vector QF and QNF, where the null hypothesis is H0 : QNF  QF and the alternative hypothesis
is Ha : QNF > QF . The number of students (i.e., the size of vector QF and QNF) is 3,245. The degrees of freedom is 6,488 and t-statistic is −28.93. The null hypothesis is rejected at significant
level α = 0.001 with p-value < 0.0001, which indicates similar students have similar academic
performance.
5 PROPOSED MTLTR-APP FRAMEWORK
In this section, we provide details for our proposed Multi-Task Learning-To-Rank Academic
Performance Prediction (MTLTR-APP) framework. First, we introduce the basic pair-wise
learning-to-rank model. Then, we introduce how to model intra-major, intra-semester, and student
similarity into an optimization framework. Finally, we discuss how to optimize the framework and
how to utilize the model to predict academic performance.
5.1 Basic Pairwise Learning-to-Rank Model
According to behavioral analysis, we extract the three behavioral factors xs,m
i ∈ Rp listed in Table 1
in semester s for each student i in major m. Based on these factors, we present the proposed
framework, named as RLTR-SEQ for predicting students’ academic performance. The algorithm
of academic performance prediction is based on the pairwise learning-to-rank model, which maps
a pair of features to their relative performance. The feature scoring function is defined as f (xi ) =
ws,m
i xs,m
i . Then, the pairwise mapping function is defined as:
P (ij) = σ (f (xi ) − f (xj)), (4)
where ij indicates that student i should be predicted to outperform student j. σ (x) = 1/(1 + e−x )
is a Sigmoid function.
Additionally, the difference of the correlations between each behavior factor and the academic
performance among different semesters indicates the factors’ district predictive strength (e.g., the
correlations between diligence and academic performance are shown in Figure 2). Thus, in this
framework, we regard the prediction at a specific semester of one major as a task. As we described
before, there are S semesters and M majors. Furthermore, we exploit the cross-entropy to measure
the inconsistency of the hypothesis and the real relative performance. Since the performance rank
is obtained based on GPA, it is a rare case that two students have the same rank (i.e., rank tie).
Without taking the rank tie into account, the basic loss function of learning-to-rank LRN is then
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.   
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:11
represented as:
LRN = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ (ws,mxs,m
i − ws,mxs,m
j ), (5)
where ys,m
i and ys,m
j means the real performance of student i and student j, and ys,m
i > ys,m
j indicates student i outperforms than student j in a specific task.
5.2 Modeling Inter-Semester Temporal Correlation
As shown in Figures 2 and 3, the correlation coefficients between the predictors and the academic
performance are gradually changed as time goes by. The findings motivate us to model the intersemester temporal correlation. Therefore, we impose a sequentially smoothed regularization for
the gradual change of weight, which is formally defined as:
ΩSEQ = 1
2

S
s=1

K
p>s
A(Δt)Ws − Wp 2
F , (6)
where Δt = p − s, Ws = [ws,1; ws,2; ... ; ws,M ] ∈ RM×p is the weight matrices of semesters. A(Δt)
is a decay function of Δt. ·F is the Frobenius norm of matrix. In this work, we discuss a special
case of A(Δt). A(Δt) = 1, when Δt = 1, otherwise A(Δt) = 0. Then, Equation (6) can be reformulated as:
ΩSEQ = 1
2

S−1
s=1
Ws − Ws+1 2
F . (7)
More specially, the weight of a major at the semester s is actually learned by adding a zero-mean
Gaussian distributed offset on the weight of the preceding semester. In other words, the regularization term can control the weight of parameter to avoid some sudden changes result from potential
outliers among consecutive semesters, which can make the model more robust.
5.3 Modeling Inter-Major Correlation
In our dataset, the number of students varies from major to major and the amount of training
data in some tasks is limited, especially in a pairwise case whose sample number is N2. In our
dataset, the biggest major has about 600 students and the smallest major only has 50 students,
which is corresponded to 360,000 and 2,500 samples. As a consequence, it is necessary to leverage
the relationship between major-specific tasks to alleviate the sparsity problem of some tasks.
In our problem, the relationship between majors may be explained by the similarity of courses
and teaching styles from similar majors, such as electronic engineering and computer science.
Students from these two majors have several common courses and are required to have excellent programming skills. For each semester, we assume that students from different majors
within the same category (e.g., social science, engineering) have similar behavior. Thus, the majorrelated model can be factorized as the product of two low-rank matrices, i.e., Ws = UsVs , where
Us ∈ RM×k and Vs ∈ Rk×p . Us represents the weighted combination of categories to form the
major. Vs denotes the feature representation of these categories. The sparsity constraint of Us ensures that each major-related task depends on a small set of categories. In addition, we add a nonnegative constraint on the matrix Us to ensure the interpretability. Formally, the regularization of
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.            
24:12 H. Yao et al.
inter-major correlation can be defined as:
ΩMS =

S
s=1
λ1 Us 1 + λ2 Vs 2
2
s.t., Ws = Us
Vs
, Us  0,
(8)
where λ1 and λ2 are regularization parameters, Us  0 means Us should be non-negative. Note
that, for each major m, ws,m = us,mVs .
5.4 Modeling Behavior Similarity
In our dataset, some students do not have enough behavioral data. For example, some students
have takeaway food more frequently than having food in the cafeteria, others may study more in
the dormitories rather than the library or teaching buildings. These data can not be collected by
the smartcard, which may result in the unreliability of predictors. To address this challenge, based
on the similarity of academic performance between frequently co-occurring students, students’
predicted performance should not have a large discrepancy from their similar students. We propose
a regularization term defined as follows:
ΩS N = 1
2

S
s=1

M
m=1

j ∈Fi
G(τi,j)

ws,mxs,m
i − ws,mxs,m
j
2
, (9)
where Fi indicates a group contains students who are similar with student i, τij is the similarity
value between studentsi and j, G(τi,j) is a function of τi,j . Note that, since most co-occurrences are
generated from students within the same major, we do not consider the social influence existing
within students from different majors.
In order to determine the formulation of function G, we investigate the correlation between the
strength of similarity and the influence of similar students. We rank the similarity value between
students to 20 levels and then normalize it from 0.05 − 1, and then calculate the average similarity
of academic performance between students and their similar students in every similarity level. Its
correlation with the strength of similarity is shown in Figure 7. The x-axis represents the average
academic performance similarity and y-axis represents the normalized rank of similarity value.
The dots mean the average academic performance of each level of similarity value, and the blue
line is a fitting curve. The result indicates that students’ academic performance should be closer
to those who are more similar with them.
The above analysis indicates that G should be an increasing function of τi,j . When τi,j is larger,
meaning student i and j are more similar, Gτi,j should be larger. As shown in Figure 7, in addition,
the relation between the student similarity and the similarity of academic performance is close to
linear. Thus, we define G(τi,j) = τi,j in this work, and Equation (9) can be rewritten as:
ΩS N = 1
2

S
s=1

M
m=1

j ∈Fi
τi,j

ws,mxs,m
i − ws,mxs,m
j
2
, (10)
Based on this regularization term, if students do not have enough data, we can infer their performance from those who are similar with them.
5.5 Inference Task
Without taking students’ behavioral similarity into account, we can then predict the performance
rank score for each student at semester s based on f (xs,m
i ) = us,mVsxs,m
i . Due to the academic
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.           
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:13
Fig. 7. Correlation the strength of student similarity value and the similarity of academic performance.
performance similarity and the unreliability of data described before, it is necessary to integrate
the performance score of each student with his/her similar students. In particular,
yˆ
s,m
i = (1 − ξ)f (xs
i ) + ξ

j ∈Fi
τij

k ∈Fi τik
f (xs
j ), (11)
where the parameter ξ balances the effect between behavioral factors and similar student’s predicted performance. yˆ
s,m
i is the final prediction score in this work. Then, we rank the final prediction score in each major of each semester and get the final rank list.
5.6 Optimization
Based on the above discussion, by integrating the inter-semester temporal correlation, the intermajor correlation, and behavior similarity, we now formulate the whole loss function of multi-task
learning-to-rank academic performance prediction (MTLTR-APP) framework as follows:
L(Us
, Vs ) = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ

ws,mxs,m
i − ws,mxs,m
j

+
λs
2

S−1
s=1
Ws − Ws+1 2
F +

S
s=1
λ1 Us 1 + λ2

S
s=1
Vs 2
2
+
λn
2

S
s=1

M
m=1

j ∈Fi
τi,j

ws,mxs,m
i − ws,mxs,m
j
2
s.t., Ws = Us
Vs
, Us  0,
(12)
where λs , λn are used to control the effect of inter-semester temporal correlation and behavior
similarity, respectively. The greater the value of each λ (i.e., λn, λs , λ1, λ2), the stronger the effect
of its corresponded part.
Then, we optimize the constrained loss function using a block coordinate gradient descent algorithm, which solves Us and Vs alternately. In addition, we also solve each us,m alternatively. We
describe the details as follows:
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.                 
24:14 H. Yao et al.
5.6.1 Fix Every Us , Solve Vs . When we fix Us , the loss function becomes:
L(Vs ) = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ

us,mVs
xs,m
i − us,mVs
xs,m
j

+
λs
2

S−1
s=1
Us
Vs − Us+1
Vs+1 2
F + λ2

S
s=1
Vs 2
2
+
λn
2

S
s=1

M
m=1

j ∈Fi
τi,j

us,mVs
xs,m
i − us,mVs
xs,m
j
2
.
(13)
It can be solved by stochastic gradient descent (SGD). The gradient of Equation (13) is:
∇L(Vs ) =

M
m=1

ys,m
i >ys,m
j

σ

us,mVs
xs,m
i − us,mVs
xs,m
j

− 1

(us,m )
T

xs
i − xs
j
T
+ λs (Us )
T (2Us
Vs − Us+1
Vs+1 − Us−1
Vs−1) + 2λ2Vs
+ λn

M
m=1

j ∈Fi
τi,j

us,mVs
xs
i − us,mVs
xs,m
j

(us,m )
T 
xs
i − xs,m
j
T
.
(14)
5.6.2 Fix Vs , Solve us,m. When we fix Vs , the loss function becomes:
L(us,m ) = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ

us,mVs
xs,m
i − us,mVs
xs,m
j

+
λs
2

S−1
s=1

M
m=1
us,mVs − us+1,mVs+1 2
F + λ1

S
s=1

M
m=1
us,m 1
+
λn
2

S
s=1

M
m=1

j ∈Fi
τi,j

us,mVs
xs,m
i − us,mVs
xs,m
j
2
s.t.,Us  0.
(15)
This optimization problem can be efficiently solved by using proximal gradient descent, which is
a common used optimization method to solve optimization problem with non-differentiable part.
Let L(us,m ) = Lд (us,m ) + Lh (us,m ), where Lh (us,m ) = λ1
S
s=1
M
m=1 us,m 1, Lд is the rest part
of Equation (15). Then, the gradient of Lд (us,m ) is:
∇Lд (us,m ) =

ys,m
i >ys,m
j

σ

us,mVs
xs,m
i − us,mVs
xs,m
j

− 1


xs,m
i − xs,m
j
T
(Vs )
T + λs (2us,mVs − us+1,mVs+1 − us−1
Vs−1)
(Vs )
T + λn

j ∈Fi
τi,j

us,mVs
xs
i − us,mVs
xs
j
 xs,m
i − xs,m
j
T
(Vs )
T .
(16)
The proximal mapping is defined as proxt (x) = arg minz 1
2t x − z2
2 + λz1. The solution of it is:
zi =
⎧⎪⎪
⎨
⎪⎪
⎩
xi − λt xi > λt,
0, −λt ≤ xi ≤ λt,
xi + λt xi < −λt.
(17)
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.                                        
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:15
In our optimization problem. proxt (x) = proxt (Us − t∇Lд (Us )). A further projection is used to
ensure the elements of Us are non-negative, which is defined as B(x) = max (x, 0). Furthermore,
The whole optimization framework is shown in Algorithm 1.
ALGORITHM 1: Optimization Framework of MTLTR-APP
Input: Given feature {X1,1,..., Xs,m,..., XS,M }, academic performance {y1,1,..., ys,m,..., yS,M },
coefficient parameters λs , λn, λ1, λ2, ξ
Output: Optimized Us , Vs
random initialize Us , Vs ;
while not convergence do
for semester s in {1,..., S} do
Optimize Vs based on Equation (14);
for major m in {1,..., M} do
Calculate gradient ∇Lд (us,m ) based on Equation (16);
Update us,m by proxt (us,m − t∇Lд (us,m ));
Use projection B(·) to make us,m non-negative;
end
end
end
The time complexity of one gradient descent iteration in our optimization algorithm is
O(N2
SMpk). N, M, S, p, k is the maximum number of students among all majors, the number
of majors, the number of semesters, the length of feature vector, the number of hidden categories,
respectively. M and S are often less than 50 and 10, respectively.
6 EXPERIMENT
6.1 Experimental Settings and Data Description
The correlation between behavioral factors and academic performance varies from semester to
semester. Thus, for evaluating the proposed algorithm, we train our algorithm on a grade of 3,352
college students from 18 majors and test it on the subsequent grade of 3,245 students from 17
majors. Both grades’ data include the records in the first five semesters. Furthermore, we randomly
select 10% of the data of training set as validation set. All hyper-parameters are tuned based on
the accuracy of the validation set. Specifically, in our experiment, we set the size of the hidden
variable as 5 (i.e., k = 5). We set λs , λn, λ1, λ2, ξ as 1, 0.01, 0.5, 0.1, 0.2, respectively.
In addition, as we described before, the collection of the behavioral data benefits from the existing information management and operation systems. Currently, these behavioral data include
students’ consumption history at different locations (e.g., cafeterias, campus supermarket), entryexit records in the library and dormitory, and the history of borrowing books. Besides, these data
are accompanied by students’ GPA information from each semester. For protecting privacy, we not
only anonymize students’ sensitive information and randomly assign each student a unique code,
but also convert the GPA information into the relative performance ranking of any two students.
The data statistics are illustrated in Table 2.
6.2 Evaluation Metric
Since we convert the students’ GPA into the performance rank out of privacy concern, we assess
the performance of the proposed algorithm with ranking-based metrics. Assuming the rank prediction of all students are equally important, we exploit the Spearman rank correlation for measuring
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
24:16 H. Yao et al.
Table 2. Dataset Statistics
Training Testing
Number of Students 3,352 3,245
Number of Majors 18 17
Number of Semesters 5 5
Number of Consumptions 10,390,715 9,866,884
Number of Library Entrances & Exits 781,630 727,854
Number of Borrowing Histories 218,719 215,413
Number of Grades 126,683 124,291
the correlation between the predicted rank and the actual rank. The higher the Spearman coefficient, the better the prediction performance. When testing, we are concerned with the prediction
performance of the proposed algorithm at each semester t, which is defined as, after averaging
over majors:
ρt = 6
|N |
i=1 (at
i − bt
i )
|N |(|N |2 − 1) , (18)
where |N | is the number of students, at
i is the real ranking of student i in semester t, and bt
i is the
predicted ranking.
6.3 Compared Methods
Based on the evaluation protocol, we compare the proposed algorithm with the following competing baselines. All methods use the features listed in Table 1.
—Ridge Regression. Similar to SmartGPA [37], we use ridge regression (i.e., original linear
regression with 2-norm regularization) for academic performance prediction.
—Decision Tree (DT). We train a decision tree for academic performance prediction.
—Random Forest (RF). Random forest is used for academic performance prediction.
—XGBoost (XGB) [5]. XGBoost is a boosting-tree-based method and is widely used in various
data mining applications.
—Multiple Layer Perceptron (MLP). Our method is compared with the neural network of four
fully connected layers. The number of hidden unites are 64, 128, 128, and 64, respectively.
—RankSVM [20]. We compare our method with RankSVM for academic performance prediction, which is a pairwise learning-to-rank model based on SVM.
Note that, in decision tree, random forest, multiple layer perceptron, and XGBoost, we also convert the students’ academic performance to their relative performance and use these baselines to
classify the relative performance.
We also study the effect of different variants of our method. The corresponding loss functions
are also listed. The term λe
S
s=1 Ws 2
2 is used for the regularization.
—BLTR. Basic Learning-To-Rank model (loss defined in Equation (5)), considering the academic performance ranking as a whole task. In other words, the weight is constant with the
semesters. The loss function is:
L(Ws ) = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ

ws,mxs,m
i − ws,mxs,m
j

+ λe

S
s=1
Ws 2
2 . (19)
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.           
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:17
—BLTR+SS. Imposing the Basic Learning-To-Rank model with Student Similarity incorporated. The loss function is:
L(Ws ) = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ

ws,mxs,m
i − ws,mxs,m
j

+ λe

S
s=1
Ws 2
2
+
λn
2

S
s=1

M
m=1

j ∈Fi
τi,j

ws,mxs,m
i − ws,mxs,m
j
2
.
(20)
—BLTR+MS. Major-based BLTR, with integrating inter-major correlation. The loss function is:
L(Us
, Vs ) = −

S
s=1

M
m=1

ys,m
i >ys,m
j
log σ

ws,mxs,m
i − ws,mxs,m
j

+

S
s=1
λ1 Us 1 + λ2

S
s=1
Vs 2
2
+
λn
2

S
s=1

M
m=1

j ∈Fi
τi,j

ws,mxs,m
i − ws,mxs,m
j
2
s.t., Ws = Us
Vs
, Us  0,
(21)
—BLTR+SEQ. Semester-based BLTR, which combines BLTR with sequential smoothness regularization. The loss function is:
L(Ws ) = −
S
s=1
M
m=1

ys,m
i >ys,m
j
log σ (ws,mxs,m
i − ws,mxs,m
j ) + λs
2
S
−1
s=1
Ws − Ws+1 2
F + λe
S
s=1
Ws 2
2 . (22)
—MTLTR-APP. The proposed model, imposing sequential smoothness regularization, intermajor correlation on BLTR, incorporating student similarity.
6.4 Performance Comparison
6.4.1 Comparison with Baseline Methods. We test our method and report the average Spearman correlation of each major in each semester. The results are shown in Table 3. By comparing
MTLTR-APP with the best baseline, MTLTR-APP achieves the highest Spearman Correlation in
every semester. More specifically, we can see ridge regression performs the worst, as it only regards the ranking problem as regression. It is difficult to predict the rank directly since the rank
list is converted from GPA. The distribution of GPA is usually Gaussian distribution, while rank
is equally spaced. DT, RF, RankSVM, and MLP, XGB also use the pairwise method to convert the
ranking problem as the binary classification problem. It significantly performs better than Ridge.
However, these methods do not model the inter-semester and inter-major correlation. In addition,
it still overlooks the student similarity. Our proposed MTLTR-APP integrates these informations
and achieves the best performance.
6.4.2 Comparison with Variants of Our Proposed Method. Table 4 shows the performance of
MTLTR-APP and its variants. We also test our method and report the average Spearman correlation of each major in each semester. By comparing BLTR+SS with BLTR, first, we can see that
student similarity does make the improvement to academic performance prediction. Second, by
comparing BLTR+MS with BLTR, due to the better performance of BLTR+MS, we conclude the
necessity of inter-major correlation. This also implies the inter-major correlation. Third, by comparing BLTR+SEQ with BLTR, the superiority of the former to the latter indicates the benefit
of applying sequential smoothness regularization. This also implies the varying correlation across
different semesters. Finally, the proposed algorithm, MTLTR-APP, can achieve better performance,
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.                              
24:18 H. Yao et al.
Table 3. Comparison of MTLTR-APP with Baselines
Semester 1 2 3 4 5
Ridge Regression 0.235 0.365 0.455 0.453 0.477
Decision Tree 0.267 0.366 0.460 0.460 0.489
Random Forest 0.278 0.377 0.463 0.468 0.495
XGBoost 0.281 0.379 0.465 0.470 0.497
RankSVM 0.275 0.374 0.461 0.461 0.496
MLP 0.280 0.375 0.466 0.465 0.498
MTLTR-APP 0.300 0.389 0.481 0.484 0.513
Table 4. Comparison of MTLTR-APP with Its Variants
Semester 1 2 3 4 5
BLTR 0.273 0.372 0.453 0.461 0.493
BLTR+SS 0.286 0.385 0.464 0.466 0.497
BLTR+MS 0.289 0.383 0.471 0.473 0.502
BLTR+SEQ 0.294 0.376 0.466 0.475 0.507
MTLTR-APP 0.300 0.389 0.481 0.484 0.513
compared to each variant, after the incorporation of inter-semester correlation, inter-major correlation, and student similarity, which shows the effectiveness of the integrated model.
6.5 Feature Importance
In order to compare the importance of different types of features (diligence, orderliness, and sleep
patterns) for academic performance prediction, we evaluate the prediction results under various
feature combinations. In this experiment, we run our proposed model MTLTR-APP on five consecutive semesters, semesters 1–5. Since the features of sleep pattern are 0-1 feature vectors which
transferred by one-hot, so we do not use it alone to predict the academic performance. The results
of the Spearman correlation under different settings of feature combinations are shown in Table 5.
In this table, first, we can see that using diligence or orderliness alone to predict academic performance can get similar results (see column 1 vs. column 2), and adding them together can improve
the accuracy significantly (see column 3 vs. columns 1 and 2). Thus, the diligence and orderliness
can reflect the students’ study in different ways, which is consistent with our previous motivation: diligence reflects how much time students spend on studying while orderliness depicts the
regularity of students’ lifestyle. Second, adding sleep patterns only improves the results slightly
(see column 4 vs. column 1, column 5 vs. column 2, column 6 vs. column 3). One potential reason
is that since we do not have the actual information about the students’ sleep patterns, we only
use the first and last times of smartcard records to represent the wake-up times and bedtimes,
which may be insufficient. In conclusion, each feature type extracted from different dimensions of
students’ lifestyle is important for academic performance prediction.
6.6 Sensitivity Analysis
Although we have observed the effectiveness of MTLTR-APP, how the performance changes with
the regularization coefficient is still under exploration. In these studies, we investigate the effect
of sequential smoothness and academic performance similarity. The results of these studies in semester 3 are shown in Figure 8. We can see that the relatively optimal value for λs are 1.0. This
indicates that the sequential smoothness regularization play an important part in improving the
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.
Predicting Academic Performance for College Students: A Campus Behavior Perspective 24:19
Table 5. Performance Evaluation under Different Feature Conditions
Settings
Column ID 1 2 3 4 5 6
Features1
D   
O   
SP  
Semester Spearman Correlation
1 0.230 0.249 0.298 0.231 0.251 0.300
2 0.338 0.352 0.385 0.338 0.352 0.389
3 0.428 0.438 0.477 0.431 0.439 0.481
4 0.436 0.436 0.481 0.438 0.435 0.484
5 0.441 0.455 0.511 0.445 0.460 0.513
1D, O, SP mean Diligence, Orderliness, Sleep Patterns, respectively.
Fig. 8. (a) The effect of sequential smoothness. (b) The effect of academic performance similarity.
learning of the weight of each task. Besides, the optimal value of the parameter ξ in Equation (11)
is set around 0.2, indicating that incorporating student similarity could improve academic performance prediction.
7 CONCLUSION AND DISCUSSION
In this article, we analyze a large-scale students’ behavioral data on campus in order to predict academic performance. We find that there are significant correlations between students
characteristics—diligence, orderliness and sleep pattern—with academic performance. Besides, frequently co-occurring students have close academic performance. Then we design a multi-task
learning-to-rank academic performance prediction framework (MTLTR-APP), which captures the
inter-major and inter-semester dependency and integrate student similarity. By training the proposed algorithm on a grade of students and testing it on the subsequent grade of students, we show
the effectiveness of our proposed MTLTR-APP for predicting academic performance and demonstrate the inter-semester correlation, inter-major correlation, and student similarity are effective
in academic performance prediction. Finally, we show the importance of each characteristic for
academic performance prediction. Our findings and proposed framework can be further extended
in the following directions.
In this article, due to the limitation of data collection, some important factors cannot be captured
and used in our framework, such as intellectual level, psychology factors, sports participation,
and even luck in the exam. In addition, we can not capture all the daily behavior of students.
For example, some students prefer study in their dormitories rather than in the teaching building.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 3, Article 24. Publication date: May 2019.           
24:20 H. Yao et al.
Some students who show abnormal behavior may achieve great performance. We will collect more
relevant data in future research.
In addition, in-class performance is very important for academic performance prediction. In the
future, we will collect more in-class behavioral data and incorporate it with offline campus daily
behavior to enhance the prediction model. We also plan to integrate the academic performance
framework to the modern educational management system. Then, we will be able to use real-time
data to predict students’ academic performance. The educators can guide students and give them
suggestions in advance, based on the prediction results.