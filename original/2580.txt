Learning from very few samples is a challenge for machine learning tasks, such as text and image classification. Performance of such task can be enhanced via transfer of helpful knowledge from related domains,
which is referred to as transfer learning. In previous transfer learning works, instance transfer learning
algorithms mostly focus on selecting the source domain instances similar to the target domain instances
for transfer. However, the selected instances usually do not directly contribute to the learning performance
in the target domain. Hypothesis transfer learning algorithms focus on the model/parameter level transfer.
They treat the source hypotheses as well-trained and transfer their knowledge in terms of parameters
to learn the target hypothesis. Such algorithms directly optimize the target hypothesis by the observable
performance improvements. However, they fail to consider the problem that instances that contribute to
the source hypotheses may be harmful for the target hypothesis, as instance transfer learning analyzed.
To relieve the aforementioned problems, we propose a novel transfer learning algorithm, which follows an
analogical strategy. Particularly, the proposed algorithm first learns a revised source hypothesis with only instances contributing to the target hypothesis. Then, the proposed algorithm transfers both the revised source
hypothesis and the target hypothesis (only trained with a few samples) to learn an analogical hypothesis.
We denote our algorithm as Analogical Transfer Learning. Extensive experiments on one synthetic dataset
and three real-world benchmark datasets demonstrate the superior performance of the proposed algorithm.
CCS Concepts: • Computing methodologies → Visual content-based indexing and retrieval;
Additional Key Words and Phrases: Transfer learning, classification
1 INTRODUCTION
1.1 Background
Despite recent advances in machine learning applications, such as text and image classification,
most conventional supervised learning algorithms can not offer satisfactory schema for learning
new models from little data. Such a challenge of learning from very few samples is refereed as fewshot learning or one-shot learning, and has attracted much attention in recent research [9, 50, 54,
61, 65]. The main difficulty of few-shot learning is how to optimize the model when there comes
new classes of data but few labeled training instances are provided for each class. Given sufficient
pre-known labeled data from related domains, such a problem can be addressed by transfer learning (TL) [48]. TL can benefit few-shot learning by transferring helpful prior knowledge from some
pre-known source domains. With the prior knowledge from the source domains, the performance
of the learning task in the target domain could be improved even with few samples [11, 48].
A critical problem in TL for few-shot learning is the negative transfer. A negative transfer is
considered as an occurrence of the pernicious influence of performance when transfer knowledge
from the source domain to the target domain [33, 48]. Previous TL methods attempt to relieve this
problem mainly on the feature, instance, or model/parameter level. In this work, we focus on the
last two kinds of TL algorithms.
Instance transfer learning (ITL) assumes that negative transfers are caused by some of the source
data that mislead the target task. Therefore, it suggests reweighing or selecting the source instances
[48]. Typical ITL algorithms analyze the relativeness based on the representation or distribution
between the source and the target domain. However, because there are few target instances, it is
difficult to select source instances precisely. Moreover, the source data may not helpful or even
may weaken the performance in practice, due to variously representation and distributions of
real-world data [70].
Parameters transfer learning (PTL) (or model transfer learning) assumes that related tasks
should have shared parameters or hyperparameters of common prior distributions [48]. In the
field, we refer a typical algorithm, Hypothesis Transfer Learning (HTL). HTL considers that the
source hypotheses, e.g., classifiers, have been already well-trained and directly integrate them to
the target hypothesis [33, 64]. The negative transfer in HTL is defined as a failure of satisfying
the improvement condition (IC) [33], which assumes that the negative transfer occurs when hypothesis transfer cannot improve the performance of the target tasks. Since HTL treats the source
hypotheses as already well-trained, it ignores the negative transfer caused by inconsistency of the
source instances and the target instances, as analyzed in ITL [19]. Consequently, it cannot avoid
facing the dilemma that even some of the source instances contribute to the source hypothesis,
they may be harmful to the target hypothesis.
1.2 Analogical Transfer Learning
To relieve the aforementioned problem, in this article, we propose a novel algorithm, Analogical
Transfer Learning (ATL). As in conventional TL researches [48], we assume the target domain
and the source domain are related but not the same. Therefore, only the source instances related
to the target instances can help the learning process in the target domain. We introduce an analogy
strategy to TL based on the cognitive theory of human beings [22, 60]. We propose the analogy
strategy as a two-stage learning schema:
(1) Revision. First, the learner finds out the source instances according to their contributions
directly to the target hypothesis. After that, the source hypotheses are learned with the selected source instances. In this stage, the learner revises the source hypothesis (compared
to the source hypothesis being learned from all of the source instances). The inconsistent
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:3
Fig. 1. An example of our algorithm: “Learning Guava from other fruits.” First, in the Revision stage, when
a new (target) genus of fruit “guava” comes, the learner selects the source instances related to the target
instances (i.e., fruits related to guava) and learn the revised source hypotheses. Second, in the Transfer
stage, an Analogical Hypothesis is concluded based on the observations of guava and the revised source
hypotheses. Detailed discussion is in Section 2.1.
knowledge to the target hypothesis is eliminated. Here, we borrow the term “revision”
from the knowledge representation theory, in which such a process is referred to as belief
revision [18]. In this stage, we relive the potential negative transfer on the instance level.
(2) Transfer. Second, the learner transfers the revised source hypothesis with the target hypothesis together to learn an analogical hypothesis. The analogical hypothesis is suitable
for both the revised source hypotheses and the target hypothesis (trained with only the
target instances). As a result, the source and the target hypotheses are consistent with the
analogical hypothesis, and we, therefore, relive the potential negative transfer problem on
the hypothesis level.
Generally, the proposed algorithm infers the properties of the target domain via learning from
the source domain. In the algorithm, it proposes to learn via a compassion of the structures, the
features of the target, and the source instances such that we denote the proposed algorithm as an
“analogy strategy.”
An example. We provide an illustration example of “Learning guava from other fruits” via
the analogy strategy in Figure 1. First, in the Revision stage, when a new genus of fruit (target
data) “guava” comes, the learner first selects the source instances that are related to guava, such
as “green apples” and revises the source hypothesis “apple” to “apples related to guava.” Second,
in the Transfer stage, an analogical hypothesis is concluded based on the source hypothesis (e.g.,
“apples related to guava”) and the weak target hypothesis of “guava.” Overall, on the target domain,
the analogical hypothesis is suited to the hypothesis of “guava;” on the source domain, it applies
to the source hypothesis “apple related to guava.”
In the schema, we refer to the final optimized hypothesis as the analogical hypothesis. The reason is twofold: First, different from previous works in HTL, our algorithm transfers knowledge
from both the source hypothesis and the target hypothesis to optimize our hypothesis, rather than
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
71:4 W. Liu et al.
transfer the source hypothesis to the target hypothesis such that the optimized hypothesis is different from the definition of the target hypothesis in HTL. Second, in the revision stage, useful
knowledge that contributes to the target hypothesis is picked out, which implies that it is analogically transferred to the target hypothesis. Notice that rather than learning source hypothesis and
directly using it to target tasks, we are learning an analogy hypothesis that is applicable for both
source and target domain. The reason is that there are only a few target data provided and, therefore, the target hypothesis is very weak and biased. The contributions of our work are threefold:
—We propose a novel analogical TL framework. We introduce an analogy strategy for TL,
which attempts to relive the negative transfer problem on both instance and hypothesis
level, simultaneously. To our knowledge, it is the first algorithm considering this problem.
—We introduce an effective revision strategy for the source instances selection based on a
self-paced learning schema. It can efficiently select the “helpful” instances from the source
domain according to their contributions to target the hypothesis.
—Our proposed framework is easy to apply with various base-learners and is easy to extend
to multi-source hypothesis learning scenarios.
2 RELATED WORK
Transfer learning. TL aims to improve the learning task in the target domain (with few instances)
by transferring helpful prior knowledge from some source domains. Multi-source TL focuses on
building an ensemble model from multiple source domains that suit for the machine learning task
on target domains [41, 64, 67]. Based on the knowledge level they transfer, TL can be divided into
three types: feature transfer learning (FTL), ITL, and PTL [48].
In FTL, the algorithms are designed to learn a feature representation in the source domain
and use it for the target domain [12, 46, 48]. The feature representations are desired to minimize the discrepancy between domains such that it could enhance the learning performance of
the target task. For instance, there is Kernelized Bayesian Transfer Learning (KBTL) that finds a
shared subspace of source and target domain by a kernel-based Bayesian dimensionality reduction
model [20].
ITL algorithms aim to reweigh or reallocate samples in the source domain based on the target
domain data [48]. Some classical works are proposed in Refs [25], [26], [29], and [68]. In many
works, the importance of the source instance is stated as the similarity between the source and the
target domain data. Probabilistic methods evaluate the distribution similarity in Refs [3], [49], and
[56]. Graph-based methods evaluate similarity by its local weights or structure similarity [13, 15,
17, 19, 24, 45, 51, 52]. Generally, the mentioned algorithms rely on the estimation of relatedness
between the source and the target domain data. However, the dependence of similarity analysis
also brings obstacles to such algorithms. Considerably different distributions of the source and the
target domain can frustrate the measure of similarity [52].
In PTL, knowledge is transferred in terms of parameter or hyperparameters of common distributions [48]. For instance, there is Projective Model TL, which adopts a regularization term to
standard SVM by analyzing the angle between hyperplanes of the source and the target domain
models [2]. Hypothesis Transfer Learning (HTL) aims to improve target hypothesis by transferring
source hypothesis. It does not require the estimation of relatedness of instances between domains.
Plenty of works have explored reliable performance in the field [36, 47, 59]. In Ref. [33], the authors present a multi-class HTL algorithm. It updates both the target and the pre-trained sources
hypothesis when a new class of target data is observed. A recent work, Ref. [64], presents an unsupervised HTL. In the work, pseudo-labels are first generated to source domain samples. Hypothesis
learning is then conducted on a model transfer SVM. In Ref. [10], an active selection strategy is
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:5
Fig. 2. Hypothesis Transfer Learning (HTL), Analogical Transfer Learning (ATL), and Instance Transfer Learning (ITL). Left: In a typical procedure of HTL, all source domain samples are used to learn a pre-trained
source hypothesis hS. After that, target hypothesis hT is learned by transferring knowledge from hS and
trained with only the target domain samples. Middle: In ATL, first, in source domain, only source instances
contributing to the target hypothesis are selected. Second, source hypothesis is revised by selected source instances to hS. Finally, an analogical hypothesis hA is learned by transferring knowledge from both hS and
hT and trained with examples from both the target instances and the selected source instances. Right: In a
typical procedure of ITL, source instances are reweighed according to their similarity to the target instances.
Then the target model is trained with both of the instances.
used to select semantic constraints rather than transferring hypotheses. In Ref. [42], the authors
discuss the parameter stability for multi-task learning with shared similar feature structures. In
Ref. [1], the effectiveness of the transfer to the target domain and compatibility of the transfer
model HTL algorithms are analyzed. Overall, the mentioned methods consider the source models
as well-trained and unchangeable.
There are also a few joint TL algorithms, which join two or more of the three types of algorithms. In Ref. [23], the authors propose a Max-Margin Domain Transforms algorithm (MMDT) to
learn feature and instance transfer jointly. Some TL algorithms consider combining TL with other
learning algorithms, such as kernel learning methods [43] and metric learning methods [66].
Differences Between Our Algorithm and Former Works. Compared to ITL, our algorithms
select the instance that directly contributes to the target task rather than analyzing similarity or
domain discrepancy of instances. Compared to the HTL, our algorithm breaks the rule of conventional HTL, which considers the source hypothesis unchangeable. Instead, our algorithm revises
the source hypotheses by selecting “helpful” instances. Therefore, our algorithm can be considered
as a TL algorithm attacks the negative transfer problem on both instance and hypothesis level simultaneously. We define our algorithm as ATL. We illustrate the differences between ITL, HTL,
and our ATL in Figure 2.
Self-paced learning. Self-paced learning (SPL) [28, 32] is a study paradigm that could adaptively learn and select subsets of instances according to their easiness in order to improve the
performance of the learning task. In self-paced learning, several discrete regularization terms are
present and used in various applications [58, 69]. For continuous regularization, a work in Ref.
[14] discusses a batch of implicit regularization terms. The diversity learning of SPL is present in
Refs [27] and [68], however in discrete form.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.  
71:6 W. Liu et al.
Table 1. List of Important Notations and Descriptions
Notations Descriptions Notations Descriptions
X The instances θ The parameter of analogical hypothesis
y The labels β The learning pace parameter
|A| Number of instances in A v The indicator vector of instances
t The target hypothesis parameters λj Leverage parameter of hypothesis regularization terms
s The source hypothesis parameters Φ(v) Self-paced regularization term to v
In our algorithm, we apply SPL schema in the revision stage to select helpful source instances.
Different from the standard SPL works, we calculate the loss in the analogical domain rather than
the source domain to evaluate the easiness of source instances. Moreover, we introduce a specialized continuous regular term to analyze and control negative transfers
Few-shot/one-shot learning. Few-shot/one-shot learning [6, 8, 40, 44, 50, 54, 61, 65] aims to
solve the problem that, instead of given one large dataset, there are only a few annotated samples
(or only one annotated example) for each class in training data. There are gradient-based optimization models [39, 50], metric learning models [54, 61], deep embedding methods [57], and TL
methods [55].
Compared to former TL for few-shot/zero-shot learning works, such as those presented Refs [7],
[16], [55], [62], and [63], our work proposes to learn in an analogical domain rather than transfer knowledge from the source domain to the target domain. In the schema, useful knowledge
from both the revised source domain and the target domain are transferred on the hypothesis
and the instance level to the analogical domain to enhance the learning performance. The reason
is the target domain is insufficient with labeled data. Directly transferred from the source domain
to the target domain, the learned hypothesis would be biased.
3 PROBLEM STATEMENT
In this section, we first revisit the TL schema, then introduce our analogical TL algorithm for
few-shot learning.
3.1 Notations
Let the superscript T denote the transpose of a vector/matrix, 0 be a vector/matrix with all zeros,
and v be the 2-norm of a vector v. Let X = {x1,..., xn }
T ∈ Rn×d be the dataset with d features
and n instances. Let Y = {y1,..., yn }
T ∈ Rn×c be the label matrix corresponding to X withc classes.
More specifically, in TL, we denote a source domain data as S = {(xS1 , yS1 ),..., (xSn , ySn )} and a
target domain data as T = {(xT1 , yT1 ),..., (xTm , yTm )}. We denote hS (·) and hT (·) as hypotheses
on the source domain and the target domain, respectively. Here, a hypothesis can be a mapping
from data space to label space, e.g., a classifier. In this work, we focus on the convex hypotheses,
i.e., the hypotheses target to minimize a convex combination of the empirical risks [33]. We denote
|A| as the number of instances in A. We denote hA → hB a hypothesis transfer from A to B.
The symbol → is a map from domain A to B on the hypothesis level. A list of important notations
and descriptions is stated in Table 1.
3.2 Hypothesis Transfer Learning Revisit
Generally, a machine learning task could be formed as an Empirical Risk Minimization (ERM)
problem:
ET = min
θ

(xi,yi )∈T
L(hT (xi, θ ),yi ), (1)
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.    
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:7
where hT (·) denotes a hypothesis learned by domain data T and θ is the parameter. In normal
machine learning tasks, hT (·) is learned and used in the same domain. However, there may be
only a few data for training hT such that the learning performance is hard to guarantee.
To relive this problem, one approach is TL. TL algorithms transfer knowledge from a source
domain with sufficient knowledge to the target domain in order to improve the performance of
the target task. Particularly, we could consider transfer knowledge on the hypothesis level by HTL
[33]. For simplicity, we first consider there is only one source domain, and will expend to the multisource scenario in the next section. We aim to find a transfer of hypothesis from a source domain
S to the target domain T , i.e., hS → hT , to optimize the ERM of hT . Thus, the ERM problem
becomes:
ET = min
θ

(xi,yi )∈T
L(hT (xi, θ ),yi ),
s.t. hS → hT .
(2)
HTL assumes that hS is pre-trained and focuses on pursuing an optimal transfer to improve the
performance of hS on parameter level. For the transfer of hypothesis, the previous works propose
hS → hT as hT (x, u) = ux + hS (x, w). Theses works consider the hypotheses are all in the form
of a linear function. For non-linear tasks, kernel functions are used to project the data to highdimensional spaces.
3.3 The Proposed Algorithm
As discussed in former sections, HTL treats the source hypothesis as well-trained and the source
instances are unaccessible. However, some of the source instances that contribute to the source
hypothesis may harm the target hypothesis. Therefore, it is desired to eliminate the harmful samples when training the source hypotheses. To solve this problem, we suggest to learn an analogical
hypothesis by a new transfer of hypothesis {hT ,hS } → hA, where A = S
∪ T and S
⊆ S is a
revised subset of S that only helpful instances contributing to the target hypothesis are selected.
The analogical hypothesis is not only applicable to the target hypothesis, but also applicable to
revised source hypothesis. We state the ERM problem of our algorithm as:
EA = min
θ

(xi,yi )∈A
L(hA (xi, θ ),yi ),
s.t. {hT ,hS } → hA,
(3)
where we denote θ as the parameter of hA. Next, we will discuss the two-stage algorithm for ATL.
As mentioned in former sections, the algorithms contain a revision stage for select source instances
for revising the source hypothesis and a transfer stage for learning the analogical hypothesis.
Revision. First, we learn an initialized target hypothesis utilizing all of the target instances. We
determine the corresponding parameter t for T as follows:
t
∗ = arg mint
1
|T |

(xi,yi )∈T
L(hT (xi, t),yi ), (4)
where we denote t
∗ as the optimal parameter of hT . Equation (4) can be solved as standard optimization problems depending on the base-learner hypothesis, e.g., SVM classifiers [21]. The parameter t
∗ will not be changed in the next stage. The base-learners can be standard SVM, kernel
SVM, or Least Squared SVM. The discussions of base-learners are in Refs [33] and [34].
In former works, source hypothesis is treated as unchangeable. It is trained by all the source
instances. In our algorithm, we propose to revise this source hypothesis by selecting instances
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.       
71:8 W. Liu et al.
that contribute to the target hypothesis. To revise the source hypothesis, we introduce a self-paced
learning (SPL) schema [32] for selecting S
⊂ S:
minv
1
|A|

(xi,yi )∈A
viL(hT (xi, t),yi ) + Φ(v), (5)
where vi is the leverage parameter for each instance in A = S  T from a leverage vector v =
{v1,...,vN } and Φ(v) is the regularization term that controls the learning rate. For the purpose of
analogy, we aim to analyze the contribution of only the source instances to the target hypothesis
learning such that we fix the indicator vector vi = 1, ∀(xi,yi ) ∈ T to keep all target instances
and only tune the indicator corresponding vector vj, ∀(xj,yj) ∈ S. For simplicity, we denote li =
L(hA (xi, θ ∗),yi ), let |A| = N, and obtain:
minv
1
N

N
i=1
livi + Φ(v). (6)
The classical regularization term in previous works [27, 28] are formed as hard/binary weighted
to select examples. For instance, the previous regularization term in Ref. [28] is
Φ(v) = − 1
β

N
j=1
vj , (7)
where β ∈ (0, 1] is the learning pace parameter. In experiments, β is gradually increased for studying from helpful to harmful source examples according to their contribution to target hypothesis.
In SPL, it is also considered as “easy to complex” analysis. By setting the gradient, with respect to
vj , to zero in Equation (6), the optimal weight for the j-th example is
v∗
j =
⎧⎪⎪⎪⎪
⎨
⎪⎪⎪⎪
⎩
1 if li ≤
1
β
;
0 if li >
1
β .
(8)
However, in practice, since noise is usually non-homogeneously distributed in the data, it is hard
to determine whether one example is easy or complex with hard weights. As shown in Figure 3
(dash lines), when β becomes larger, when values of loss are small, they cannot be divided. In this
case, the self-paced scheme will be invalid.
In this work, we specialize the regularization term as a continuous function. The regularization
form of Equation (5) is
Φ(v) = −

N
j=1
f (vj). (9)
The regularization term of vj is defined as
f (vj) = vj ln 
1 −vj
vj

+ ln  1
1 −vj

+vj

1
β + 2

. (10)
By setting the gradient with respect to vj to zero in Equation (10), we obtain
vj = 1
1 + e
li− 1
β −2
, (11)
where β > 0 is a sensitive controlling parameter. Soft weight can make our algorithm more sensitive when loss is small. As shown in Figure 3 (solid lines), when β becomes larger, the weights are
more sensitive to the loss value. Soft weighting is more effective than the hard weighting and can
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.       
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:9
Fig. 3. Parameter sensitivity of self-paced regularizer. Soft weight drops when loss values are increasing (solid
lines). When β becomes larger, the function becomes more sensitive, i.e., weights drop more dramatically and
even loss values are small. Hard weight (dash lines) do not become sensitive while loss increases.
faithfully reflect the true importance of examples during training [27]. Moreover, by using a soft
weighting, values of our function will be more distinct when β is small.
After obtaining the weights of source instance, we can then select a subset of S
⊂ S. The
weights are directly related to the degree of the contribution of source instances to the target
hypothesis. The revised source hypothesis can be learned:
s = arg mins
1
|S
|

(xi,yi )∈S
L(hS (xi, s),yi ). (12)
Transfer. In order to control the stability of the transfer of the hypothesis, we introduce a hypothesis transfer regularization term [33, 35] to Equation (3):
min
θ
1
|A|

(xi,yi )∈A
L(hA (xi, θ ),yi ) + Ω(θ ),
s.t. {hS ,hT } → hA,
(13)
where we define the hypotheses transfer regularization term Ω(θ ) = 
wj ∈ {s,t} θ − wj 2 to control the hypotheses dissimilarity between the pre-trained hypothesis hS , hT and the analogical
hypothesis hA. Further, we formulate the transfer of hypothesis {hT ,hS } → hA as a combination
of an inner product and hypotheses hS and hT as hA (x, θ ) = θ x + hS (x, s) + hT (x, t), where θ
is the parameter. In this equation, the parameter s and t are fixed after the revision stage. Further,
for the loss function, we use 2-regularization as suggested in Ref. [64] for improvement of the
generalization ability.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.              
71:10 W. Liu et al.
Overall, we formulate the optimization function of ATL as follows:
min
θ
1
|A|

(xi,yi )∈A
hA (xi, θ ) − yi 2
vi +

wj ∈ {s,t}
λj θ − wj 2 + Φ(v),
s.t. hA (x, θ ) = θ x + hS (x, s) + hT (x, t),
(14)
where λj > 0 are leverage parameters. Since 2-norm is convex and all the considered hypotheses are either convex or linear combinations of convex functions. As we assumed, the proposed
problem in Equation (14) is solvable.
ALGORITHM 1: Algorithm of Analogical Transfer Learning
Input: Source domain data S, target domain data T.
1: Initialize v, β. Learn hT by determining t;
2: while not converging do
3: (Revision) Update S
⊂ S by determining v∗, β from solving Subproblem (6) via Algorithm 2;
Update hS by determining s on S
;
4: (Transfer) Update θ ∗ by solving Subproblem (14) according to Equation (15);
5: end while
Output: Analogical hypothesis hA with parameter θ ∗
.
ALGORITHM 2: Optimization Algorithm for optimal v∗
Input: Training data X, hypothesis parameter θ, learning pace parameter β, threshold variable δ.
1: Sort samples xi ∈ X in ascending order by their loss li . Accordingly, denote the labels and weights of xi
as yi and vi .
2: for all xi ∈ X do
3: Calculate score v∗
i according to Equation (11)
4: if v∗
i < δ then vi = si else vi = 0;
5: end for
Output: v∗
.
3.4 Optimization
In this section, we discuss the optimization method for the ATL problem following the two-stage
learning algorithms.
Revision. We start with the revision of the source hypothesis. First, as mentioned in the previous section, we first optimize t by utilizing all the target instances as in Equation (4). Then,
with t fixed, the optimization problem of Equation (5) is simplified to Equation (6), i.e., minv
1
N
N
i=1 livi + Φ(v). The regularization term of Φ(v) = f (vi ) is derivable w.r.t vi . Meanwhile, li is a
convex loss function. Therefore, we could solve Equation (6) similar as in Ref. [27]. Particularly, for
each sample xi , its corresponding optimal indicator value of v is determined as in Equation (11). In
practice, for computation efficiency, we truncate v∗
i to zero by a selection control parameter δ. We
illustrate the method in Algorithm 2. Finally, with v determined, we revise the source hypothesis
hS by optimizing its parameter s as formulated in Equation (12).
Transfer. With v determined, the problem is simplified to Equation (14). First, when s and t are
determined, Equation (14) has a closed form solution by calculating its derivative at θ:
θ ∗ = X 
XX + N

λjI
−1
(y − hS (X, s) − hT (X, t) − X(s + t)), (15)
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.              
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:11
where θ ∗ is the optimal parameter of hA. Matrix X is an embedding matrix representing all training instances x ∈ A and λj > 0 are leverage parameters for hS and hT . Solving Subproblem (14)
is similar to conventional HTL. However, rather than transferring the source hypothesis to the
target hypothesis, ATL transfers the revised source hypothesis and target hypothesis to learn an
analogical hypothesis. We illustrate the entire algorithm in Algorithm 1.
3.5 Extension to Multi-Source ATL
It is easy to expand our algorithm to multi-source domain transfer learning condition, where multiple source domains are considered. We denote the multi-source version of our algorithm as MultiATL. For a k source domain scenario, we formulate the optimization problem for Multi-ATL as:
min
θ
1
|A|

(xi,yi )∈A
hA (xi, θ ) − yi 2
vi +

wj ∈ {S,t}
λj θ − wj 2 + Φ(v),
s.t. hA (x, θ ) = θ x +

s∈S
hS (x, s) + hT (x, t),
(16)
where S = {s
1,..., s
k } is a set of parameters that contains all k source hypotheses and A =
{
k
i=1 S
i }∪T . Each of s
k ∈ S is determined separately in the revision stage in the Multi-ATL
algorithm. Compared to the former HTL works, such as in [60], our algorithm is parameter-free
for hypothesis reweighing. It is because that the source hypotheses are already revised to achieve
best contributions to the target hypothesis.
4 EXPERIMENTS
In this section, we conduct extensive experiments to validate the performance of the proposed
algorithm on both synthetic and real-world datasets. On the synthetic dataset, we demonstrate
the ability of the proposed algorithm to handle the negative transfer. On the real-world datasets,
we use traditional SVM as a baseline. Note that it does not transfer any knowledge.
4.1 Baseline Algorithms
We compare the proposed algorithm with the following TL algorithms. We select algorithms that
transfer knowledge on the instance, feature, and parameter level. Joint TL algorithms, which attempt to joint transfer on multiple levels, e.g., feature and parameter, are also investigated. Classical
classification algorithms SVM and TSVM are also compared in the experiments as baselines.
—Baseline algorithms: Support Vector Machine (SVM): SVM [21] is used as a baseline.
We implement SVM using the libsvm package [5] with a Gaussian kernel. In the experiments, it only uses source data for training and tests on the target domain. Transductive
Support Vector Machine (TSVM) [30]: TSVM is a classical baseline of TL.
—Instance TL algorithms: Hierarchical Active TL (HATL) [31]: HATL exploits cluster
structure shared by domains to perform TL by leveraging sources and a limited number of
target domain data using active learning.
—Feature TL algorithms: Kernelized Bayesian TL (KBTL) [20]: KBTL finds a shared subspace of source and target domain by a kernel-based Bayesian dimensionality reduction
model.
—Parameter TL algorithms: HTL [33]: HTL transfers knowledge from source to target
domain by optimizing target hypothesis as a combination of source domain and an inner
product term. A model transfer regularization term is introduced to minimize the difference
between the source and the target hypotheses. Projective Model Transfer (PMT) [2]:
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.             
71:12 W. Liu et al.
Fig. 4. Experiments on the synthetic data with a standard SVM classifier. Left: In the target domain, given
only a few samples (magenta points), the classifier is fail in the classification task (The decision boundaries
are the solid lines). Middle: In the source domain, given sufficient samples (yellow and green points), the
classifier is success in the classification task. (The decision boundary is the dash line.) Right: Transfer learning. Using selected source samples (dark blue points) and a few target samples (magenta points), in our
algorithm, the classifier is success in the classification task in the target domain. (The decision boundary is
the solid line.) However, it will fail if using all the source samples. (The decision boundary is marked as a
dashed line).
PMT learning analyzes the angle between hyperplanes of source and target domain hypotheses and adopts it as a regularization term to standard SVM. GreedyTL [34]: It is a
multi-source hypothesis TL method with non-negative smooth loss function and convex
regularization terms. Multi-model Knowledge Transfer (Multi-KT) [60]: The multi-KT
algorithm uses a least square SVM adoptive method to operate a multi-source TL that can
handle few training examples from multiple models.
—Joint transfer learning algorithms: MMDT [23]: The MMDT algorithm jointly optimizes
over a feature transformation mapping target domain data and classifier weights to the
source domain.
4.2 Datasets and Setting
We first conduct an evaluation experiment on synthetic data. Then we run comparison experiments on real-world data.
4.2.1 Synthetic Data. Following the experiment in Ref. [4], synthetic source and target data are
independently drawn from a double-moon distribution by 1,000 random sampled instances. The
source data is a distribution rotated 60◦ in a counterclockwise direction from the target domain
distribution. Due to the rotation, the source and target domain results exhibit different distributions. Indeed, the greater the rotation angle, the larger the discrepancy of the domains [4]. Labeled
training instances are sampled, only 20, in each experiment. They are marked as magenta points
in Figure 4(a).
4.2.2 Text Data. We perform our algorithms on two real-world text datasets. (1) Newsgroup: The Newsgroup [37] dataset contains approximately 20,000 newsgroup documents partitioned across 20 different subtopics of newsgroups, around 2,000 documents for each. For several
subtopics, there is a high-level category, such as sci.crypt and sci.electronics belong to category
Sci (S) [17]. As in Ref. [17], we divide the data by their subtopics from four categories, i.e., Comp
(C), Sci (S), Rec (R), and Talk (T). The details of categories are presented in Table 2.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:13
Table 2. Data Description of Newsgroup
Task Source Target
comp.graphics comp.sys.ibm.pc.hardware
C vs S comp.os.ms-windows.misc comp.sys.mac.hardware
sci.crypt comp.windows.x
sci.electronics sci.med
sci.space
rec.autos rec.sport.baseball
R vs T rec.motorcycles rec.sport.hockey
talk.politics.guns talk.politics.mideast
talk.politics.misc talk.religion.misc
rec.autos rec.motorcycles
R vs S rec.sport.baseball rec.sport.hockey
sci.med sci.crypt
sci.space sci.electronics
sci.electronics sci.crypt
S vs T sci.med sci.space
talk.politics.misc talk.politics.guns
talk.religion.misc talk.politics.mideast
comp.graphics comp.os.ms-windows.misc
C vs R comp.sys.ibm.pc.hardware comp.windows.x
comp.sys.mac.hardware rec.autos
rec.motorcycles rec.sport.baseball
rec.sport.hockey
comp.graphics comp.os.ms-windows.misc
C vs T comp.sys.mac.hardware comp.sys.ibm.pc.hardware
comp.windows.x talk.politics.guns
talk.politics.mideast talk.politics.misc
talk.religion.misc
(2) Reuters: The Reuters-21758 corpus dataset [38] contains news articles from the Reuters
website involving three categories: Orgs (O), People (Pe), and Place (Pl). Each category contains
a total number of around 1,200 documents from different subtopics. Similar to on Newsgroup,
single source tests and multi-source tests are run as three binary classification tasks aiming to
divide different categories. Specifically, the classification tasks are run on “O vs. Pe,” “O vs. Pl,”
and “Pe vs. Pl.” The source and the target data are drawn from different subtopics under the same
categories. We only sample 10 labeled training samples from target domain data randomly without
replacement. Details are omitted as in Ref. [17] as there are many more subtopics.
Settings: For both of the text datasets, we perform single-source and multi-source tests.
(1) Single-source Test. First, we run a single-source test. Binary classification tasks are then performed aiming to classify different categories. (2) Multi-source Test. We conduct a multi-source
test for the purpose of exploring the performance of multi-source TL. In the test, the source and
the target samples are still drawn from the different subtopics under the same categories. Different from the single-source test, the multi-source hypothesis is learned on multiple subtopics. For
example, in Newsgroup on “C vs. S,” comp.graphics and sci.crypt are treated as positive and negative samples for one source data while comp.os.ms-windows.misc and sci.electronics are treated
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
71:14 W. Liu et al.
as another source data. In the experiments, we only sample 10 labeled training samples from the
target domain data randomly without replacement for both the single-source test and the multisource test.
4.2.3 Image Data. We perform our algorithms on one real-world image dataset.
AwA: Animals with Attributes (AwA) dataset contains 30,475 images of 40 subclasses of different animals. For each sample, 4,096 features are learned and extracted by a VGG-19 deep neural
network [53]. We collect six groups of animals as positive samples according to their biological
families, i.e., Cetacea (whale-like), Amphibian (beavers, etc.), Felidae (cat-like), Canidae (dog-like),
Muridae (mouse-like). On average, each group contains approximately 2,000 images of five subclasses of animals. The remaining images of animals are used as negative samples. Similar to the
experiment on text data, we produce the source data and the target data by subclasses of animals.
Settings: We perform inner-family and cross-family tests on image data. (1) Inner-family Test.
In the inner-family test, source and target samples are selected as what we did in text data experiments. For each task, the source and the target samples are drawn from different subclasses under
the same families. (2) Cross-family Test. We additionally operate a cross-family test on the image
data. For each task, the source and the target samples are drawn from different animal families. As a
result, the source and the target samples are much more different than that in the inner-family test.
Hence, it is a more challenging test for transfer learning algorithms to avoid negative transfers. In
each experiment, we alter the number of positive target training data in a range of {1, 5, 10, 15} with
an equal number of negative samples. The performances are reported in terms of average results.
4.3 Performance Evaluation
4.3.1 Synthetic Data. The performance of classification of our algorithm on synthetic data is
shown in Figure 4.
(1) Our algorithm can enhance the performance on the target domain with few training samples. As shown in Figure 4(a), in the target domain, when labeled target training data
is insufficient (|T | = 20, marked as magenta points), the classifier (a kernel SVM-base
learner in our experiments) fails in the classification task (The boundary is the solid line).
Meanwhile, in the source domain, when labeled training data is sufficient, it is easy to
divide the two classes in Figure 4(b). Finally, as shown in Figure 4(c), our algorithm can
solve the classification problem by learning an analogical hypothesis (boundary marked
as the solid line), even with only a few examples (|T | = 20, marked as magenta points).
(2) We also display that negative transfers are relieved by the revision of the source hypothesis. First, using all samples to train the source hypothesis and using it in the target domain
will bring negative transfers. As shown in Figure 4(c), the decision boundary of the source
hypothesis (dashed line) fails to divide the two classes; even source data could be successfully classified in the source domain in Figure 4(b). On the other hand, in our algorithm,
only the source samples that contribute to the target hypothesis are picked up to revise
the source hypothesis. Then, an analogical hypothesis is learned, not only to improve
the performance of the target hypothesis but also the source hypothesis. It is shown in
Figure 4(c), the decision boundary of the analogical hypothesis (solid line) successfully
divides the two classes.
4.3.2 Text Data. Accuracy (ACC) is chosen as the evaluation measurement of the performances.
Each experiment is called 10 times independently, and we report the average results with corresponding standard deviations. In the experiments, we observe that:
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:15
Table 3. Performance Comparison (ACC ± Standard Deviation) (%) of Single-source Test
Datasets Newsgroup Reuters
Task C vs. S R vs. T R vs. S S vs. T C vs. R C vs. T O vs. Pe O vs. Pl Pe vs. Pl
SVM 62.82 ± 0.1 60.56 ± 0.2 61.34 ± 0.2 60.12 ± 0.3 61.94 ± 0.2 61.81 ± 0.2 61.79 ± 0.2 60.84 ± 0.2 61.66 ± 0.1
TSVM 66.52 ± 0.1 66.21 ± 0.3 67.85 ± 0.2 66.00 ± 0.3 65.99 ± 0.2 69.17 ± 0.2 68.57 ± 0.1 63.66 ± 0.1 62.26 ± 0.1
HATL 66.90 ± 0.2 64.02 ± 0.1 62.54 ± 0.3 63.97 ± 0.3 69.12 ± 0.2 64.87 ± 0.2 88.92 ± 0.2 88.87 ± 0.1 89.06 ± 0.2
KBTL 65.83 ± 0.3 67.43 ± 0.2 62.77 ± 0.2 67.86 ± 0.1 69.02 ± 0.2 63.00 ± 0.2 79.47 ± 0.2 74.44 ± 0.2 75.34 ± 0.1
PMT 63.73 ± 0.1 60.25 ± 0.1 64.25 ± 0.3 61.33 ± 0.3 65.17 ± 0.2 56.65 ± 0.2 67.96 ± 0.1 67.68 ± 0.1 62.26 ± 0.2
HTL 67.81 ± 0.2 66.69 ± 0.1 65.70 ± 0.3 66.56 ± 0.3 66.71 ± 0.2 66.58 ± 0.2 75.81 ± 0.2 74.51 ± 0.2 74.94 ± 0.1
ATL 67.99 ± 0.2 67.96 ± 0.1 69.07 ± 0.2 67.67 ± 0.2 69.66 ± 0.1 67.14 ± 0.2 77.20 ± 0.1 76.01 ± 0.1 78.00 ± 0.2
Table 4. Performance Comparison (ACC± Standard Deviation) (%) of Multi-source Test (Multi-subtopics)
Datasets Newsgroup Reuters
Task R vs. T C vs. S C vs. T C vs. R S vs. T R vs. S Pl vs. Pe Pe vs. Pl O vs. Pl
SVM 62.93 ± 0.1 63.15 ± 0.1 61.89 ± 0.2 62.81 ± 0.2 61.84 ± 0.2 61.81 ± 0.2 67.86 ± 0.2 63.27 ± 0.2 61.42 ± 0.1
MMDT 63.08 ± 0.2 63.87 ± 0.1 65.18 ± 0.0 64.36 ± 0.1 65.81 ± 0.0 63.91 ± 0.3 67.33 ± 0.1 69.74 ± 0.2 63.87 ± 0.1
Multi-KT 64.93 ± 0.2 65.08 ± 0.1 65.23 ± 0.3 63.97 ± 0.3 64.71 ± 0.2 64.87 ± 0.2 73.14 ± 0.3 72.36 ± 0.2 73.87 ± 0.1
GreedyTL 67.26 ± 0.2 63.55 ± 0.2 73.57 ± 0.2 71.46 ± 0.2 65.67 ± 0.2 63.35 ± 0.1 78.98 ± 0.1 75.57 ± 0.4 80.05 ± 0.2
Multi-ATL 70.85 ± 0.1 70.36 ± 0.1 77.67 ± 0.1 73.92 ± 0.2 71.54 ± 0.1 73.14 ± 0.1 81.79 ± 0.1 80.74 ± 0.1 81.35 ± 0.1
(1) Overall, the TL algorithms show better performances than baseline SVM, which runs with
no transfer of knowledge. It implies that transfer knowledge from the source domain can
help improve the classification task on the target domain.
(2) In a single-source test, as presented in Table 3, our algorithm (ATL) outperforms all the
compared algorithms. More specifically, our algorithm (ATL) consistently shows around
3% better performances than its counterparts on both Newsgroup and Reuters datasets.
It implies that our algorithm is better in generalization in a single-source TL scenario.
Meanwhile, our algorithm consistently outperforms the HTL algorithm, which uses all
source samples, on both Newsgroup and Reuters datasets. It implies that our algorithm
can control negative transfer through self-paced sample selection schema.
(3) In the multi-source test, as presented in Table 4, our algorithm (ATL) consistently outperforms the others on the two datasets. More specifically, all the hypothesis transfer
algorithms Multi-ATL (ours), GreedyTL and Multi-ATL report better performance in the
test. Overall, our algorithm Multi-ATL outperforms the second algorithm around 3% in all
the subtasks. It implies that our algorithm could control negative transfer and is better in
generalization in a multi-source TL scenario.
4.3.3 Image Data. Mean Average Precision (mAP) is used as an evaluation measurement of the
performances. Each experiment is called 10 times independently, and we report the average results
with corresponding standard deviations. As shown in Figure 5, we can observe that:
(1) Overall, the experiments show that the performance is improved when the number of
target training data is increasing. It is reasonable, as target domain information contributes
to the training of analogical hypothesis. Meanwhile, inner-family test results are better
than cross-family results. This is not surprising, as different subclasses of animals in the
same family may have similar features. On the other hand, since animals from different
families may not have similar features, the hypothesis trained with cross-family source
will not perform as well as the one trained in inner-family source.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
71:16 W. Liu et al.
Fig. 5. Performance on Image Data (1) Baseline algorithms SVM is not affected much by the number of target
training samples; (2) Overall, all algorithms perform better in the Inner-family test than the Cross-family test;
(3) Algorithms that use target domain knowledge generally perform better when given more target training
samples; (4) Our algorithm outperforms others early when given over 10 target training samples.
Fig. 6. Parameter sensitivity of learning rate γ on text data. Our algorithm ATL (in red lines) performs consistently better than baseline SVM (green lines) at about 10% in accuracy. Global optimal γ differs on different
datasets.
(2) Our algorithms (ATL) (solid red line) perform better when given more than only 10 target
training samples. Moreover, it consistently performs better than HTL algorithm around 5%
when given more than 10 target training samples. It implies that our algorithm can control
negative transfer through self-paced sample selection schema and improve hypothesis
transfer learning.
(3) Our algorithms (ATL) (solid red line) not only are the best in the inner-family test but also
significantly outperform others in the cross-family test. It implies our algorithm is better
in generalization.
4.3.4 Parameter Sensitivity of Learning Rate. We also test the influence of learning rate on text
datasets. The number of target training samples is fixed at 10. As shown in Figure 6, the learning rate γ is tuned in region {5, 10, 15, 30, 50}. We observe that on Reuters, the corresponding
accuracies are { 81.83, 86.04, 84.05, 82.24, 81.47} in which the peak result is reported when β = 10.
On Newsgroup, it outputs { 70.14, 68.35, 66.55, 64.71, 63.31} in which β = 5 leads the performances.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 6, Article 71. Publication date: October 2018.
Few-Shot Text and Image Classification via Analogical Transfer Learning 71:17
Overall, a small γ seems better than larger β. However, the optimal choice is varied on different
datasets. Overall, our algorithm consistently outperformed the baseline algorithms.
5 CONCLUSION
In this article, in order to solve the problem of learning with few-shot text and image classification, we have proposed a novel analogical TL algorithm. Rather than transferring knowledge from
the source hypothesis to learn the target hypothesis, ATL learns an analogical hypothesis from
both source and target hypotheses. Also, ATL was able to revise the source hypotheses by selecting helpful source instances according to their contribution to the target hypothesis. As a result,
the proposed algorithm efficiently controls the occurrence of the negative transfer on both instance and hypothesis level. Extensive xxperiments on synthetic and real-world datasets presented
a consistent and reliable performance. Moreover, ATL can be easily expanded to the multi-source
scenario.
For the future work, we suggest investigating how to expand our algorithm by integrating nonlinear hypotheses; Another attractive direction is to theoretically analyze the stability of our algorithm. For other machine learning applications, given the flexibility of our algorithm, we suggest
to investigate the transfer between more challenging domains such as from image to video space,
and the like.