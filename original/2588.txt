Point-of-Interest (POI) recommendation has been extensively studied and successfully applied in industry
recently. However, most existing approaches build centralized models on the basis of collecting users’ data.
Both private data and models are held by the recommender, which causes serious privacy concerns. In this
article, we propose a novel Privacy preserving POI Recommendation (PriRec) framework. First, to protect
data privacy, users’ private data (features and actions) are kept on their own side, e.g., Cellphone or Pad.
Meanwhile, the public data that need to be accessed by all the users are kept by the recommender to reduce
the storage costs of users’ devices. Those public data include: (1) static data only related to the status of
POI, such as POI categories, and (2) dynamic data dependent on user-POI actions such as visited counts. The
dynamic data could be sensitive, and we develop local differential privacy techniques to release such data
to the public with privacy guarantees. Second, PriRec follows the representations of Factorization Machine
(FM) that consists of a linear model and the feature interaction model. To protect the model privacy, the
linear models are saved on the users’ side, and we propose a secure decentralized gradient descent protocol
for users to learn it collaboratively. The feature interaction model is kept by the recommender since there is
no privacy risk, and we adopt a secure aggregation strategy in a federated learning paradigm to learn it. To
this end, PriRec keeps users’ private raw data and models in users’ own hands, and protects user privacy to
a large extent. We apply PriRec in real-world datasets, and comprehensive experiments demonstrate that,
compared with FM, PriRec achieves comparable or even better recommendation accuracy.
CCS Concepts: • Information systems → Retrieval models and ranking; • Security and privacy →
Privacy protections;
Additional Key Words and Phrases: Privacy preserving, decentralization, local differential privacy, secret
sharing, POI recommendation
1 INTRODUCTION
The recommender system has been drawing much attention in recent decades, and achieving
great successes in many real-world applications such as vidio [17], E-commerce [57], and Point-ofInterest (POI) (e.g., restaurant and hotel) recommendation [59], to solve the information overload
problem. Take POI recommendation as an example—most promising models are centrally built on
the basis of collecting users’ private data, which causes serious privacy concerns [31, 37, 47].
A motivating example. Figure 1 shows the framework of most existing POI recommendation
approaches, where the data include user profiles (e.g., age and gender), POI descriptions (e.g., category and visitor count), and user-POI actions (e.g., click and check-in). Among them, both user
profiles and user-POI actions are private, whereas POI descriptions are public to all the users. The
model refers to the built recommendation model, e.g., the latent factors of Matrix Factorization
(MF) model [30], which predicts users’ preferences on POIs. First, besides the public POI data,
users’ private data, including user profiles and user-POI actions, are collected; these data explicitly show users’ private information and may be abused by the recommender. Second, the models
of most existing POI recommendation approaches implicitly indicate users’ private information,
e.g., the latent factors of MF can directly infer users’ ratings on items. Therefore, both data and
models of most existing recommender systems could be in high privacy risks [43, 48].
There have been some studies focused on protecting user privacy while building recommender
systems, including the applications to POI recommendation [11, 47]. They mainly belong to two
types. The first type protects the raw data by adding noises to them [4, 26, 37, 38, 44, 47]. These
methods are efficient and easy to implement; however, the recommendation performance decreases when adding too much noise. The second type is based on cryptography techniques [2,
6, 20, 42, 44]. These approaches usually can achieve comparable performance with the traditional
recommender systems; however, their efficiencies are too low to be applied in practice. Therefore,
how to build a privacy preserving recommender system, which can not only protect user data
and model privacy but also has comparable (or even better) recommendation accuracy and high
efficiency, remains a challenge.
To solve previously mentioned challenges, in this article, we take POI recommendation as
a Click-Through Rate (CTR) prediction problem, and propose a novel Privacy preserving POI
Recommendation (PriRec) framework, which has the following advantages.
PriRec protects data and model privacy. First, to protect data privacy, PriRec keeps users’
private data (features and actions) on their own side, e.g., cellphone or tablet. To alleviate the storage costs on users’ devices, all the public POIs’ data are still held by the recommender. These public
data can be divided into two types: (1) the static POI data that describe the status of a POI such
as POI categories, and (2) the dynamic POI data that indicate the popularity of a POI, e.g., visited
count. Since the user-POI actions are kept on users’ devices, to obtain the statistics of these action
data, we propose to use a local differential privacy technique [18] to collect perturbed user-POI
interaction data, and further generate POI dynamic features by the recommender. Here, different
from the existing models [26], which directly use the perturbed data to build models, we only use
the perturbed user-POI interaction data for generating statistical features. Second, to protect model
privacy, motivated by a Factorization Machine (FM) [45], we design the model of PriRec as two
parts: (1) the linear models that are decentralized on each user’s side since they directly indicate
user preferences, and (2) the feature interaction model that is kept by the recommender has no
privacy risk since it can only infer the interaction weights between features. To this end, both
users’ private raw data and models are kept by their own hands, and PriRec is able to protect user
privacy to a large extent.
PriRec has linear time complexity and promising recommendation accuracy. The learning process in PriRec includes two parts, the learning of linear models on each user’s side and the
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
Practical Privacy Preserving POI Recommendation 52:3
Fig. 1. Traditional POI recommendation framework. Users’ private data and models are centrally kept by
the recommender, which raises serious privacy concerns.
learning of the feature interaction model kept by the recommender. First, inspired by decentralized
gradient descent [41, 64], we propose a secure decentralized gradient descent protocol for users to
learn their linear models collaboratively. Second, motivated by parameter server distributed learning paradigm [32] and federated learning [5, 29], we adopt a secure aggregation strategy in federated
learning paradigm to learn the feature interaction model. Both strategies are efficient and make the
learning of PriRec scales linearly with data size in terms of both computation and communication
complexities. Moreover, PriRec belongs to a decentralized model, and it learns the linear models
for different users based on location networks. To this end, PriRec can capture users’ individual
interests in different locations and achieve promising recommendation accuracy.
We apply PriRec in real-world datasets, and comprehensive experiments demonstrate that,
compared with the traditional ranking model, PriRec achieves comparable or even better recommendation performance, and meanwhile keeps user privacy.
Our main contributions are summarized as follows:
—We propose a novel Privacy preserving POI Recommendation (PriRec) framework for POI
recommendation, where we propose a secure decentralized gradient descent protocol for
learning decentralized linear models and adopt a secure aggregation strategy in a federated
learning paradigm to learn the feature interaction model. PriRec keeps users’ private raw
data and models on users’ own side, and therefore protects user privacy to a large extent.
—We propose to adopt local differential privacy techniques to generate dynamic POI popularity features from users’ local user-POI actions. This can not only protect private user-POI
actions, but also significantly improve recommendation performance, as we will show in
experiments.
—We conduct experiments on real-world datasets, and the results demonstrate the effectiveness and efficiency of PriRec.
2 RELATED WORK
In this section, we review related knowledge, including the traditional recommender system, privacy preserving recommender system, local differential privacy, and secret sharing.
2.1 Traditional Recommender System
We first review literature of traditional recommender systems, i.e., non-privacy preserving approaches, including the applications in POI recommendations. The most famous traditional recommender system is Collaborative Filtering (CF) [50, 54, 63], which is based on the assumption
that users who behave similarly on some items will also behave similarly on other items. Among
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
52:4 C. Chen et al.
CF, factorization-based models achieve promising performance [8, 30, 33], which aim to learn user
and item latent factors based on known user-item action histories such as ratings and clicks. Popular factorization-based CF models include MF and its variants [13, 30, 34, 39, 61], regression-based
latent factor models [1], Bayesian personalized ranking [46], deep MF [58], neural MF [25], and
Hash-based MF [10].
Besides the above CF models, in practice, ads, merchandise, and POI recommendations are also
taken as a CTR prediction problem [35]. Logistic Regression (LR) is popularly used in most Internet
companies, e.g., Microsoft [49], Google [36], and Ant Financial [12], due to its simplicity, scalability,
and online learning capability. Deep neural network (DNN) has also been widely used due to its
powerful representation ability [65, 67]. Later on, Wide & Deep [14] combines the advantages of
both LR and DNN for better performance. Besides, FM [45] and its variations, e.g., DeepFM [24] and
Field-aware FM [27], are also extensively used since they can capture the high-order interactions
between features.
Although the traditional recommender systems achieve promising performance, they build centralized recommendation models on the basis of collecting users’ data. Both private data (features
and actions) and models are held by the recommender, which causes serious privacy concerns
[31, 48, 56]. In this article, we take a POI recommendation as a CTR prediction problem, and propose a novel Privacy preserving POI Recommendation (PriRec) framework for it. PriRec keeps
users’ private data and models on users’ own side, e.g., cellphone or tablet, thus solves the privacy
issue.
2.2 Privacy Preserving Recommender System
To date, different approaches have been proposed to solve the privacy issues of the traditional
recommender systems. The first type is based on randomized perturbation or differential privacy
techniques [19]. That is, they protect users’ original data by adding noise to them. Popular methods of this type include [4, 26, 37, 38, 44, 47]. These methods are efficient and easy to implement,
however, there is a tradeoff between privacy and recommendation accuracy, i.e., the recommendation performance decreases when the privacy degree increases. The second type is based on
cryptography techniques such as homomorphic encryption [23] and secure Multi-Party Computation (MPC) [62], and typical methods include Refs [2], [6], [20], [42], and [44]. These approaches
usually can achieve comparable performance with the traditional recommender systems; however,
the low efficiency of the cryptography techniques limits its application in practice.
Besides the above privacy-preserving recommendation models, there are also existing approaches focus on combining the private data of multi-parties, e.g., different hospitals and banks,
meanwhile training machine learning models such as LR [7, 40], which is the so-called collaborative learning or shared machine learning in literature [9]. They do this by using differential privacy
or MPC. The fundamental difference between these works and ours is that they assume users’ data
have been collected by several parties who want to protect their collected data from other parties,
while our approach assumes users’ private raw data are kept on their own devices.
The most similar work to ours is Federated Learning (FL) [5, 29]. However, PriRec is different
from FL in two aspects: (1) FL assumes that data are decentralized on each user’s device and the
model is kept by the server (recommender), while in PriRec, both users’ private data and models
are decentralized on each user’s device, and, therefore, PriRec has better user privacy guarantees;
(2) FL only uses a secure gradient aggregation strategy to learn neural network models while
PriRec uses both secure decentralized gradient descent protocol and secure gradient aggregation
strategy to learn the FM model.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
Practical Privacy Preserving POI Recommendation 52:5
2.3 Local Differential Privacy
Differential Privacy (DP) has been proposed in the global privacy context to ensure that an adversary should not be able to reliably infer whether or not a particular individual is participating
in the database query, while Local Differential Privacy (LDP) was proposed in the local privacy
context, as in when individuals disclose their personal information [16, 28]. LDP has the ability of
estimating statistical values of data, e.g., mean and histogram, without disclosing users’ raw data,
and has been adopted by many companies, including Google [21], Apple [55], and Microsoft [18].
Recently, LDP has also been applied in recommender systems to protect private user-item ratings
[52, 53]. However, directly using LDP to build models will decrease recommendation performance.
In this article, we propose to adopt LDP to generate dynamic POI features (e.g., the visited count
of a POI) instead of directly building models, which can protect user-POI actions and capture the
popularity of POIs. We will show in experiments that the generated POI features can significantly
improve recommendation performance.
2.4 Secret Sharing
Secret sharing was first proposed in Ref. [51]. The basic idea of secret sharing is to distribute a
secret amongst a group of participants (parties), each of whom has a share of the secret. The secret
can be reconstructed only when a sufficient number of shares are combined together, and individual shares are of no use on their own. We focus on n-out-of-n Secret Sharing in this article, i.e., all
shares are needed to reconstruct a secret. To share an -bit value a for party i ∈ P = {1,..., P},
party i generates {aj ∈ Z2 , j ∈ P and j  i} uniformly at random, sends aj to party j, and keeps
ai = a −
j aj mod 2. We use ai = ai to denote the share of party i. To reconstruct a shared
value a, each party i sends ai to one who computes
i ai mod 2,i ∈ P.
The above protocols can not work directly with decimal numbers since it is not possible to
sample uniformly in R [15]. We approximate decimal arithmetics following the existing work
[40]. Suppose a and b are two decimal numbers with at most lF bits in the fractional part; to do
fixed-point multiplication, we first transform them to integers by letting a = 2lF a and b = 2lF b,
and then calculate z = a
b
. Finally, we truncate the last lF bits of z so that it has at most lF bits
representing the fractional part. It has been proven that this truncation technique also works when
z is secret shared [40].
Secret sharing has been popularly used in kinds of machine learning algorithms, including linear
regression [15], neural networks [40], and recommender systems [9]. In this article, we apply secret
sharing into decentralized gradient descent, and propose a secure decentralized gradient descent
protocol for users to learn the linear model of PriRec collaboratively, without compromising users’
private data and models.
3 THE PROPOSED PRIVACY PRESERVING POI RECOMMENDATION FRAMEWORK
In this section, we first describe motivations, notations, and problem definitions. Next, we present
the Privacy preserving POI Recommendation (PriRec) framework, followed by its main components in detail. We then summarize the training and prediction algorithms of PriRec, and, finally,
analyze their complexities.
3.1 Preliminary
We first describe the motivation of our proposed PriRec framework, then present the notations
and problem definition, and finally describe model optimization.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.          
52:6 C. Chen et al.
3.1.1 Motivation. User privacy in POI recommendation should include two parts, i.e., the data
that explicitly expose user privacy and the model that implicitly indicates user preferences or
interests.
Data privacy. Both user and item (POI) features are important to recommendation performance.
User features show the private information of users, e.g., age, occupation, and consumption ability, which is the most important information that needs to be protected when building a privacy
preserving POI recommender system. One of the reasonable ways is to decentralize this private
information on users’ own devices instead of collecting them. POI features show the static profile
and dynamic operation status of the POI, both of which are public to all the users. The POI static
features are usually POI profiles, e.g., the dish category of a restaurant. The POI dynamic features are usually operation status data, e.g., the check-in count of a hotel. However, these dynamic
POI data are related to user-POI interaction histories, e.g., user-hotel check-in history, which are
also a part of the users’ private data. Thus, techniques that can not only protect individual user-POI
actions but also estimate the user-POI action count for each POI should be considered.
To sum up, a privacy preserving POI recommender system should protect both user features
and user-POI interaction data.
Model privacy. We take POI recommendation as a CTR prediction problem and design our
model by following FM [45], since FM and its variants are popularly used due to its scalability and
capability of capturing high-order feature interactions. Suppose each sample has D real-valued
features x ∈ RD , its prediction yˆ of the second-order FM model is defined as,
yˆ = w0 +

D
d=1
wdxd
 linear model
+

D
d=1

D
d=d+1
xdxd

K
k=1
vd,kvd
,k
 feature interaction model
. (1)
FM model has two parts, i.e., linear model and high-order feature interaction model. First,
w0,w1,...,wD are the linear model, and each parameter wd denotes the weight of each feature
xd . Obviously, the linear model indicates the users’ preferences on each feature and implicitly
exposes users’ interests to some extent. Therefore, it should be kept private by each user from
being exposed to other users or the recommender. Second, V ∈ RD×K is the second-order feature
interaction model and K is the dimensionality of feature interaction factorization. It can be seen
that
k=1,...,K vd,kvd
,k is used to capture the weight of each feature interaction pair < xd , xd >.
Clearly, the weights of feature interaction pairs do not expose users’ data or interests and, therefore, can be publish to the recommender.
In summary, a privacy preserving POI recommender system should protect the sensitive models,
e.g., the linear model of FM.
3.1.2 Notations and Problem Definition. Formally, let U be the user set and Xi ∈ Rm be the
private user features of user i ∈ U. Let V be the item (POI) set and Xj ∈ Rn be the public POI
feature of POI j ∈ V. Let (i, j) be an interaction between useri ∈ U and item j ∈ V, Xij ∈ Rm+n =
Xi + Xj be the feature1 of a sample with + being the concatenation operation, and yij ∈ {1, −1}
being the action, e.g., click or not. Let O be the training dataset, where all the user-item interactions
< Xij ,yij > are known.
Let W be the linear models of users with each row Wi = wi
0,wi
1,..., wi
m+n denotes the private
linear model saved on the device of user i ∈ U, and let V ∈ R(m+n)×K be the public feature interaction model held by the recommender. The privacy preserving POI recommendation problem is
1For simplification, we do not formalize contextual features such as distance and period of time.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.                                                                                           
Practical Privacy Preserving POI Recommendation 52:7
Table 1. Notation and Description
Notation Description
U user set
V item set
Xi private features of user i ∈ U
Xj public features of item j ∈ V
(i, j) an interaction between user i ∈ U and item j ∈ V
Xij feature of an interaction (i, j)
yij label of an interaction (i, j)
yˆij predicted label of an interaction (i, j)
W private linear models
Wi private linear model of user i ∈ U
V public feature interaction models
λw and λv regularization parameters
∇wi
d d-th element in the gradient of Wi
∇V gradient of V
α learning rate
f ∈ N (i) neighbor of user i ∈ U
Si f relation strength between user i and f ∈ N (i)
K factorization dimension of V
D feature dimension
σ (x) logistic function with input x
aj j-th share of secret value a
Aϵ ϵ-LDP randomized algorithm
O training dataset
to predict yˆij of unknow user-POI pairs and, meanwhile, keeps < Xij,yij > and Wi private. We
summarize the notations used in this article in Table 1.
3.1.3 Model Optimization. In this article, we take POI recommendations as a CTR prediction
problem. The optimization task is to minimize the sum of losses l over the training dataset O
arg min
W,V

<Xi j,yi j >∈O
−ln(σ (yij · yˆij)) + λw ||W||2
F + λv ||V||2
F , (2)
where σ (x) = 1/(1 + e−x ) is the logistic function, λw and λv are the regularization parameters for
linear models and feature interaction models, respectively, and yˆij is defined in Equation (1). For
each user-POI pair < Xij ,yij >, its gradient with respect to each element wi
d in the linear model
Wi is
∇wi
d =

yij · (σ (yij · yˆij) − 1) + 2λw · wi
0, when d = 0,
yij · (σ (yij · yˆij) − 1) · Xij
d + 2λw · wi
d , when d > 0. (3)
Its gradient in terms of each element Vd,k in the feature interaction model V is
∇Vd,k = yij · (σ (yij · yˆij) − 1) · Xij
d

dd
Vd
,kXij
d + 2λv · Vd,k . (4)
In a traditional centralized setting, all the data and models are kept by the recommender, and
FM can be efficiently learned by using gradient descent [45]. In contrast, as we described earlier,
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.    
52:8 C. Chen et al.
Fig. 2. Privacy preserving POI Recommendation (PriRec) framework.
in our privacy preserving setting, the private data and the linear models are held decentralized by
users. We will present how to learn the linear models and feature interaction models in the privacy
preserving setting in Section 3.4 and Section 3.5, respectively.
3.2 Overview of Privacy Preserving POI Recommendation Framework
Our proposed PriRec framework can protect both private data and models, which is shown in
Figure 2. To protect data privacy, users’ private data, including features and actions, are decentralized on their own side, e.g., cellphone or tablet. Besides, all the public POIs’ data are kept by the
recommender, and they are mainly in two types: the static data that describes the status of a POI
such as a POI category, and the dynamic data that indicate the popularity of a POI, e.g., visitor
count. To protect model privacy, the linear models of PriRec are also decentralized on each user’s
side for privacy purposes, and we propose a secure decentralized gradient descent protocol for users
to learn them collaboratively. The feature interaction model is kept by the recommender since it
can only infer the interaction weights between features, which has no privacy risk. We adopt a
secure aggregation strategy in federated learning to learn it. To this end, both users’ private data and
models are kept by their own hands, and PriRec only collects the perturbed user-POI interaction
data. Therefore, PriRec is able to protect both data and model privacy. We will present each part
of the framework in details in the following sections.
3.3 Generating POI Dynamic Feature
We propose to generate dynamic POI features, e.g., click count of a restaurant, by using Local
Differential Privacy (LDP) to collect perturbed user-POI interaction data. In LDP, each user randomizes his/her private data using a randomized algorithm (mechanism) A locally, before sending
them to the data collector (recommender).
Definition 3.1. A randomized algorithm Aϵ : V→Z is ϵ-locally differentially private (ϵ-LDP)
if for any pair of values v,v ∈ V and any subset of output S⊂Z, we have that
Pr[A(v) ∈ S] ≤ eϵ · Pr[A(v
) ∈ S].
LDP formalizes a type of plausible deniability—no matter what output is released, it is approximately equally as likely to have come from one data point v ∈ V as any other [3, 18]. In other
words, the recommender can not differentiate whether a user has interaction with a POI or not, although it collects a perturbed user-POI interaction. The user-POI interactionyij ∈ {0, 1} is a binary
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
Practical Privacy Preserving POI Recommendation 52:9
Fig. 3. Generate dynamic features for POI j using LDP.
value,2 which can be collected from users’ devices by using the following mechanism:
y
ij =

1, with probability 1
eϵ +1 + yij · eϵ −1
eϵ +1 ,
0, otherwise. (5)
After that, the recommender obtains the bits from all the users U and the total interaction count
for POI j can be estimated as
cj =

I
i=1
y
ij · (eϵ + 1) − 1
eϵ − 1 . (6)
It can be proven that above data collection mechanism preserves ϵ-LDP, and meanwhile achieves
an unbiased estimation of the POIs’ dynamic features [18]. Besides dynamic visited count, LDP can
also be used to estimate dynamic real-valued features, e.g., the average consumption of a POI. We
finally show how to generate dynamic visited count features using LDP in Figure 3.
3.4 Learning Linear Model
The linear models are decentralized on each users’ devices for privacy concerns. Therefore, a key
challenge is how should users collaboratively learn their linear models. To solve this challenge, we
first show the learning procedure of linear models in a traditional centralized setting. By using
gradient descent, the linear model is updated as follows
wd
(t+1) = wd
(t) − α · ∇wd
(t)
, (7)
where α is the learning rate, and ∇wd (t) is the gradient ofwd at time t. In a decentralizing learning
setting, data are held by each individual learner and the traditional gradient descent is not suitable
any more. Existing research proposes to approximate Equation (7) by using the Decentralized
Gradient Descent (DGD) [41, 64],
wi
d
(t+1)
=

f ∈N (i)
Si f · wf
d
(t)
− α · ∇wi
d
(t)
, (8)
where wi
d
(t) is the d-th model of user i at time t, N (i) denotes the neighbors of i on a certain user
network, and Si f denotes the edge weight between i and f . We argue that DGD is not secure in
our privacy preserving setting, since directly calculating the weighted sum of neighbors’ linear
models, i.e.,
f ∈N (i) Si f · wf
d
(t)
, needs the plaintext model of neighbors, i.e., wf
d
(t)
, which directly
reflects the preferences of users.
To solve the above problem, we propose a secure decentralized gradient descent protocol, as
is shown in Algorithm 1. The main idea is to use secret sharing to calculate the summation of
neighbors’ linear models. Its security and correctness can be found in Ref. [51]. Note that the
linear models are usually real-valued vectors, and we adopt the efficient fixed-point arithmetic
2We take yi j , as in {0, 1}, when collecting data, and as in {1, −1} when a learning model.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.   
52:10 C. Chen et al.
Fig. 4. Relationship between user-POI distance and click.
ALGORITHM 1: Secure decentralized gradient descent protocol for learning the linear model
of user i
Input: iteration t, linear model gradient of user i (∇wi
d ), neighbors of user i (N (i)), linear
models of neighbors (wf
d
(t)
, f ∈ N (i)), and the weight between i and neighbors
(Si f , f ∈ N (i))
1 for each neighbor f ∈ N (i) do
2 Calculates weighted linear model swf
d = Si f · wf
d
3 Locally generates shares 	
swf
d


j ∈N (i)
4 Keeps 	
swf
d


f and distributes 	
swf
d


jf to neighbor j ∈ N (i)
5 end
6 for each neighbor f ∈ N (i) do
7 Locally calculates the summation of all f -th shares, i.e.,
j ∈N (i)
	
swj
d


f
8 Sends
j ∈N (i)
	
swj
d


f to user i
9 end
10 User i calculates the summation from all neighbors, i.e.,
f ∈N (i)

j ∈N (i)
	
swj
d


f
, which
equals to
f ∈N (i) Si f · wf
d
(t)
11 User i updates his/her linear model using Equation (8)
method as described in Section 2.4, which has also been proven to work in secret sharing settings.
With the proposed secure decentralized gradient descent protocol, we can train the linear model
without compromising users’ private data and models.
The remaining challenge is how to choose neighbors for model propagation. We address this
challenge by analyzing the real data in POI recommendation channels from Koubei application.
Figure 4 shows the relationship between user-POI distances and actions. We can observe that, in
practice, users tend to click the POIs nearby. In other words, POIs are likely to be interacted by
the nearby users. Therefore, we build the user adjacent network by using user geographical information, similar to the existing research [13, 63]. Specifically, let di,f be the distance between user
i and f , and the edge weight between i and f is defined as Si f = f (di,f ), where f (·) is a mapping
function that transforms distance to edge weight. Various mapping functions have been proposed
in the literature [66].
In practice, one can not communicate with all the other users, because (1) the communication
cost is expensive, and (2) only a handful of users’ devices are online. Therefore, for each user
i, we randomly choose his/her closest top N neighbors based on the distance. Furthermore, for
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.      
Practical Privacy Preserving POI Recommendation 52:11
simplification, we set the edge weights of the built user adjacent network to 1 after choosing
neighbors, i.e., Si f = 1. We will empirically study the effect of the number of maximum neighbors
(N) on our model performance.
3.5 Learning Feature Interaction Model
The feature interaction model is kept by the recommender, the relationship between the recommender and individual learners is similar to that of server and worker in a parameter-server distributed learning paradigm [32]. The existing works propose a secure aggregation strategy to train
a neural network model in federated learning settings [5, 29]. Motivated by this, we adopt a secure aggregation strategy in federated learning for users to learn the feature interaction model
of FM collaboratively. Specifically, once a batch of online users have interactions with a POI, i.e.,
< Xij ,yij >, these users first pull the current feature interaction model V(t) from the recommender.
They then calculate its gradient ∇V based on Equation (4). After that, they securely aggregate the
gradients ∇V . Finally, the recommender updates the feature interaction model. In this article, we
adopt the most simple secure aggregation protocol in Ref. [5], i.e., one-time pad masking based on
secret sharing. Please refer to Section 4.0.1 in Ref. [5] for more details. Finally, the recommender
updates V(t) as follows
V(t+1) = V(t) − α · ∇V(t)
. (9)
This strategy has the similar principle with the parameter server distributed learning paradigm
[32]. That is, the server (i.e., the recommender) saves the model parameters (V), and the worker
(i.e., each user) loads data and updates the models by communicating with the server. It becomes
an asynchronous learning task when multi-users interact with POIs simultaneously, which is also
a common task in parameter server [32].
3.6 Model Training and Prediction Algorithm
The training of PriRec includes two parts, i.e., learning linear models and learning feature interaction models, and we summarize it in Algorithm 1. As we have described in Section 3.4, linear
models are decentralized on each users’ devices for privacy concerns, and we propose a secure
decentralized gradient descent protocol for users to learn them collaboratively. We summarize the
learning algorithm in lines 9–10. The feature interaction model is kept by the recommender, and
we adopt secure aggregation strategy in federated learning for users to learn collaboratively, as is
presented in Section 3.5, which corresponds to lines 12–15 in Algorithm 2.
The prediction of PriRec also needs the communication between users and the recommender,
as is shown in Algorithm 3. In it, line 1 denotes the matching procedure before ranking. Different
matching strategies can be used, e.g., the simplest location-based matching strategy. We do not
describe the matching strategies in details, because it is not the focus of this article. Line 5 omits
the contextual features for conciseness.
In summary, PriRec is able to protect users’ private data and model during model training and
prediction procedures. Similar to most prior privacy preserving machine learning algorithms [40],
PriRec can only protect against semi-honest adversaries using secret sharing techniques. That is,
PriRec assumes the participants strictly follow the protocol execution. We leave how to solve
malicious adversaries as a future work.
3.7 Complexity Analysis
We now analyze the communication and computation complexities of Algorithm 1. Recall that
|O| is the training data size, D is the feature size, K is the dimensionality of feature interaction
factorization, and N denotes the number of maximum neighbors to be communicated.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
52:12 C. Chen et al.
ALGORITHM 2: PriRec Model Training
Input: training set (O), learning rate (α), regularization parameters (λw , λv ), maximum
propagation users (N), feature interaction factorization dimension (K), and
maximum iterations (T )
Output: linear model for all the users (W) and
feature interaction model for the recommender (V)
1 The recommender initializes V
2 for Each user i ∈ U do
3 Initialize Wi
4 end
5 for t = 1 to T do
6 Shuffle training data O
7 for each user-POI pair < Xij ,yij >∈ O, user i do
8 # learn linear model
9 Calculate ∇Wi based on Equation (3)
10 Update Wi based on the secure decentralized gradient descent protocol in
Algorithm 1
11 # learn feature interaction model
12 Pull V from the recommender
13 Calculate ∇V based on Equation (4)
14 Push ∇V to the recommender using secure aggregation
15 The recommender updates V based on Equation (9)
16 end
17 end
18 return W and V
Communication Complexity. For each user-POI pair, the communication relies on two parts.
(1) Users communicate with each other to learn linear models, i.e., lines 9–10, and its complexity is O(N2 · D); (2) users communicate with the recommender to learn feature interaction models, i.e., lines 12–15, and its complexity is O(2D · K). Therefore, the total communication cost in
Algorithm 1 is O(|O| · D · (N2 + 2K)). In practice, since D, N,K  |O|, the total communication
complexity is linear with data size.
Computation Complexity. For each user-POI pair, the computing bottleneck is Equation (1),
and it has linear computation complexity O(K · D) after reformulating it [45]. Therefore, the computation complexity of learning linear models, i.e., lines 9–10, is O(N · D); the computation complexity of learning feature interaction model, i.e., lines 12–15, is O(K · D). In total, the computation cost in Algorithm 1 is also O(|O| · D · (N + 2K)). Since D, N,K  |O|, the total computation
complexity is also linear with data size.
For Algorithm 2, we analyze that, for predicting each user-POI pair, the communication complexity isO(|Xj | + K · D) and the computation complexity isO(K · D), where |Xj | denotes the feature size of POI j. In practice, K is usually very small; therefore, the complexities are linear with D.
4 EMPIRICAL STUDY
In this section, we empirically compare the performance of the proposed PriRec with the existing non-private POI recommendation method. We also study the effects of parameters on model
performance.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
Practical Privacy Preserving POI Recommendation 52:13
ALGORITHM 3: PriRec Model Prediction for User i
Input: features for user i (Xi
), features for each POI j (Xj
), linear model for user i (Wi
) on
his/her device, and feature interaction model on server (V)
Output: recommend top k POIs Vk for user i
1 Get the matched POI set Vm ∈ V
2 Pull V from the recommender
3 for each POI j ∈ Vm, user i do
4 # combine features
5 Pull POI j’s feature Xj from the recommender
6 Concat user i’s feature Xi with POI j’s feature Xj
, and get Xij
7 # predict score
8 Predict user i’s score on POI j based on Equation (1)
9 end
10 Recommend top k POIs Vk for user i with the highest scores
11 return Vk for user i
4.1 Setting
Datasets. We choose two real-world user-POI interaction datasets for experiments, i.e., Foursquare
and Koubei.
First, Foursquare is a famous benchmark dataset for POI recommendation [60]. It contains userPOI action histories in two cities, and we only choose the data in Tokyo. We filter the POIs that are
interacted by less than 10 users. Since Foursquare only has positive user-POI interaction data, we
randomly sample one negative user-POI interaction for each record; therefore, the ratio of positive
and negtive records is 1:1. The original dataset only has user features such as gender and friend
count. We also generate POI dynamic features using our proposed local DP technique. Moreover,
since the Foursquare dataset does not have the geographic locations when a user interacts with
a POI, we can not build a user geographic adjacent network. Instead, we build the user adjacent
network by random. That is, we randomly select (N) neighbors for each user-POI interaction.
Second, the Koubei dataset is collected from the POI recommendation channel in Koubei,
3 which
is a product of Alibaba and Ant Financial in China, and we filter the users and POIs whose interactions are less than 5. There are many kinds of POIs in this channel, such as restaurants, cinemas,
and markets. The Koubei dataset consists of two parts, the positive user-POI interaction (yij = 1)
indicates that a user clicks on a POI, the negative user-POI interaction (yij = 0) implies that a user
ignores a POI after exposure, and their ratio is about 1:3. The Koubei dataset has three kinds of
features, as described in Section 3.1.1, i.e., user features such as hometown and gender, POI static
features like POI category, and the generated POI dynamic features such as the recently clicked
count of POIs. The Koubei dataset has geographic location information, with which we build the
user geographic adjacent network, and we use N to denote the maximum number of neighbors
for each user.
Finally, Table 2 shows the statistics of both datasets after preprocessing.
Metrics. Since we take the POI recommendation as a CTR prediction problem in this article,
we adopt Area Under the receiver operating characteristic Curve (AUC) as the evaluation metric,
which is commonly used to evaluate CTR prediction quality [35]. In practice, AUC of a classifier
3https://www.koubei.com/.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
52:14 C. Chen et al.
Table 2. Dataset Description
Dataset #user #item #interaction #feature
Foursquare 11,824 13,924 924,474 6
Koubei 85,466 118,598 497,838 89
Table 3. Summary of the Existing Models and Our Proposed
Models Users’ Private Information Is Shown in Italics and FM Means
We Want to Study the Corresponding Model Performance
with FM During Experiments
Model Data Information
Leakage Performance
MF rating rating -
DMF rating gradient ≈ MF [11]
FM
rating
user feature
POI static feature
POI dynamic feature
rating
and
user feature
> MF [45]
PriRecrating
user feature
POI static feature
no private
information
leakage
?FM
PriRec
rating
user feature
POI static feature
POI dynamic feature
no private
information
leakage
?FM
is equivalent to the probability that the classifier will rank a randomly chosen positive instance
higher than a randomly chosen negative instance [22]; therefore, the higher the better.
We split both datasets with two strategies—(1) we randomly sample 80% as a training set and the
remaining 20% as a test set; and (2) we randomly sample 90% as a training set and the remaining 10%
as a test set. We use Foursquare80 and Koubei80 to denote the first strategy, and use Foursquare90
and Koubei90 to denote the second strategy. We repeat this procedure three times and report their
average results.
Comparison methods. Our proposed PriRec framework is a novel decentralized algorithm
of the existing FM [45], and it belongs to privacy-preserving decentralized recommendation approaches. FM has been proven to outperform the existing MF [39] model due to its ability to handle
additional feature information besides the user-item interaction (rating) information. As long as
the features are useful, which is always so in practice, FM can beat MF consistently. Therefore, we
only compare our proposed model with FM. Moreover, we would like to study the contribution
of the generated dynamic POI features to the accuracy of PriRec, and, therefore, we use PriRecto indicate the version that PriRec does not use the generated dynamic POI features by LDP.
We summarize the characteristics of the above-mentioned models in Table 3. From it, we can see
that our proposed PriRec framework can utilize more information without compromising users’
private data.
Hyper-parameters. We set ϵ = 1 for LDP when generating dynamic POI features, following the
existing research [18]. We vary the number of maximum neighbors (N) and the feature interaction
factorization dimension (K) of FM and PriRec to study their effects on model performance, and
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
Practical Privacy Preserving POI Recommendation 52:15
Table 4. AUC Comparison on Foursquare Datasets
Datasets Foursquare80 Foursquare90
Model FM PriRec- PriRec FM PriRec- PriRec
K = 5 0.8152 0.4777 0.7834 0.8106 0.4722 0.7818
K = 10 0.8145 0.4771 0.7831 0.8098 0.4727 0.7824
K = 15 0.8131 0.4749 0.7829 0.8083 0.4702 0.7816
Table 5. AUC Comparison on Koubei Datasets
Datasets Koubei80 Koubei90
Model FM PriRec- PriRec FM PriRec- PriRec
K = 5 0.7154 0.7484 0.7605 0.7172 0.7495 0.7695
K = 10 0.7180 0.7519 0.7633 0.7205 0.7534 0.7713
K = 15 0.7192 0.7529 0.7643 0.7207 0.7546 0.7720
vary the maximum number of iterations (T ) to study its effect on model convergency. We find the
best values of other hyper-parameters, including learning rate (α) and regularization parameters
(λw and λv ), in {10−4, 10−3, 10−2, 10−1, 100}.
4.2 Comparison Results
We compare PriRec and PriRec- with the classic FM model on both Foursquare and Koubei
datasets. Note that during the comparison, we use grid search to find the best parameters of each
model.
Results on Foursquare. We first report the comparison results on Foursquare in Table 4. From
the results, we find the following:
—In most of the cases, the recommendation performance of each model decreases with training data size and K, where K is the dimensionality of feature interaction factorization. This
is because the Foursquare dataset only has six features, including three dynamic POI features
generated by LDP, which causes an overfitting problem.
—The AUC performance of PriRec- is even less than 0.5 (random guess), which is quite
unsatisfying. This is because the original Foursquare dataset only has three user features,
with which it is unable to train a reasonable model.
—Our proposed dynamic POI popularity features generated by using LDP can significantly
improve the recommendation performance of PriRec. For example, the AUC of PriRec
improves 65.57% compared with that of PriRec- on Foursquare90 when K = 5.
—PriRec and FM have comparable recommendation performance (0.78+ vs. 0.81+). That is,
our proposed model can protect user privacy by sacrificing little recommendation accuracy.
Results on Koubei. We then report the comparison results on Koubei in Table 5. We observe
the following:
—Recommendation performance of each model increases with K. K is the dimensionality of
the feature interaction factorization; therefore, with enough features, the bigger K is, the
better the learned feature interaction model V captures the real relations between features.
—Our proposed dynamic POI popularity features generated by using LDP can significantly
improve the recommendation performance of PriRec. For example, the AUC of PriRec
improves 2.67% compared with that of PriRec- on Koubei90 when K = 5.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
52:16 C. Chen et al.
Fig. 5. Average training and test losses of PriRec w.r.t. the number of iteration number (T ).
—Recommendation performance of PriRec consistently outperforms FM in all the cases. For
example, the AUC of PriRec improves that of FM as high as 6.30% on Koubei80 when K = 5.
Note that FM uses all the features, including the dynamic POI features, in the traditional
centralized training setting. The reason is in POI recommendation scenarios, the user-POI
interactions obey location aggregation, i.e., most users are only active in a certain location.
Different from FM, which has a centralized linear model, PriRec belongs to the decentralized model, and it learns the linear models for different users by using a secure decentralized
gradient descent. To this end, PriRec is able to capture users’ individual interests in different locations. This is consistent with the reality that users in different places have different
tastes.
4.3 Parameter Analysis
We first analyze the convergence of PriRec in this section. We show the average training loss and
test loss of PriRec w.r.t. the number of iteration number (T ) in Figure 5, where we set K = 5 and
the number of maximum neighbors N = 30. It obviously shows that PriRec converges faster on
Foursquare80 than Koubei80. This is because there are only 6 features on Foursquare dataset, in
contrast, there are 89 features on Koubei.
Next, we study the effect of the number of maximum neighbors (N) on PriRec- and PriRec,
which is shown in Figure 6, where we set K = 5. From it, we find that with the increase of N, the
performances of PriRec- and PriRec first increase and then tend to be stable. It indicates that
PriRec- and PriRec, without and with POI dynamic features, respectively, can achieve a stable
performance with only a handful of neighbors (30/85, 466 ≈ 0.04%) to communicate, which meets
the situations that only a small proportion of devices are online in practice. This experiment proves
the practicality of our proposed models.
Finally, we study the complexity of PriRec. We show the training time of PriRec w.r.t. the
training data size in Figure 7, whereT = 100 and N = 30. Note that our experiments are conducted
on a single PC; thus, the network communication time is ignored. From it, we find that the time
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 5, Article 52. Publication date: July 2020.
Practical Privacy Preserving POI Recommendation 52:17
Fig. 6. Effect of the number of maximum neighbors (N) on the AUC of PriRec- and PriRec.
Fig. 7. Training time (in seconds) of PriRec w.r.t. training data size.
complexity of PriRec is indeed linear with training data size, as we analyzed in Section 3.7, which
proves the efficiency of PriRec.
5 CONCLUSION AND FUTURE WORK
In this article, we proposed a novel privacy preserving POI recommendation (PriRec) framework
for the POI recommendation channel in Ant Financial. To do this, PriRec keeps users’ private
profiles on their own devices and adopts local differential privacy techniques to collect perturbed
user-POI interaction data on a server for generating dynamic POI popularity features. Motivated
by FM, our proposed model of PriRec includes two parts: (1) the linear models that are decentralized on each users’ side for privacy purpose, which are learned collaboratively by our proposed
secure decentralized gradient descent protocol; and (2) the feature interaction model that is kept
by the recommender, which is learned by secure aggregation strategy in federated learning paradigm. PriRec not only can protect data and model privacy, but also enjoys promising scalability.
We applied PriRec in real-world datasets, and comprehensive experiments demonstrated that,
compared with FM, PriRec achieves comparable or even better recommendation performance.
In the future, we would like to deploy PriRec in real products. We will also study how to consolidate our algorithm to protect against malicious adversaries.