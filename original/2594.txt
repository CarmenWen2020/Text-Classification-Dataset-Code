Estimating causal effects by making causal inferences from observational data is common practice in scientific
studies, business decision-making, and daily life. In today’s data-driven world, causal inference has become
a key part of the evaluation process for many purposes, such as examining the effects of medicine or the
impact of an economic policy on society. However, although the literature contains some excellent models,
there is room to improve their representation power and their ability to capture complex relationships. For
these reasons, we propose a novel prior called Causal DP and a model called CDP. The prior captures the
complex relationships between covariates, treatments, and outcomes in observational data using a rational
probabilistic dependency structure. The model is Bayesian, nonparametric, and generative and is not based on
the assumption of any parametric distribution. CDP is designed to estimate various kinds of causal effects—
average, conditional average, average treated, quantile, and so on. It performs well with missing covariates
and does not suffer from overfitting. Comparative experiments on synthetic datasets against several stateof-the-art methods demonstrate that CDP has a superior ability to capture complex relationships. Further, a
simple evaluation to infer the effect of a job training program on trainee earnings from real-world data shows
that CDP is both effective and useful for causal inference.
CCS Concepts: • Computing methodologies → Causal reasoning and diagnostics;
Additional Key Words and Phrases: Causal inference, Bayesian nonparametric, Dirichlet process
1 INTRODUCTION
Imbens and Rubin [30] define causal effect as the impact of event A on event B. Understanding
causal effects is of great significance to scientific development [73], knowledge of our physical
surroundings [63], ensuring social equality [43], and improving quality of life [36, 38]. For example,
understanding the effect of a medicine can help doctors write accurate prescriptions for patients.
Understanding how policies affect national economic growth can help governments make more
rational decisions. Understanding the causal effect of education can help people increase their
earning potential.
One of the most well-known methods of estimating causal effects is the randomized controlled
experiment [42], where an experiment is conducted on two groups of randomly separated subjects.
One group experiences the event A. The control group experiences without the event A. The observed results from the two groups are then compared to assess the causal effect of the event A on
the event B. Although they are commonly believed to be reasonable, such methods are sometimes
unethical, technically impossible, or too costly to implement [78]. For instance, performing controlled experiments in a study on acquired immunodeficiency syndrome (AIDS) would be immoral.
AIDS is so harmful to humans, and it is inhuman to not give medicine to patients with AIDS. Also,
double-blind assessment is impossible in some cases, such as heart transplants. It is not possible
to give someone a heart transplant without him knowing. Thus, there is great practical value in
new and better ways to infer causal effects from uncontrolled observational data. Accordingly,
methods of causal inference have always attracted a great deal of interest from researchers and
practitioners.
Observational data is typically composed of treatments T, covariates X, and outcomes Y. Therefore, causal inference means estimating the causal effect of T on Y for either an average or a specific X. Existing methods of causal inference can be roughly categorized into two groups. The first
group includes discriminative models, which estimate conditional distributions [37], i.e., p(Y |T,X).
These methods are quite effective at estimating causal effects, but they are vulnerable to missing
covariates and are prone to overfitting. The second group includes generative models that estimate joint distributions [46, 57], i.e., p(T,X,Y ). They can generally handle missing covariates and
overfitting is not particularly a problem. However, existing generative models are either based on
the unrealistic assumption that the data have a parametric distribution or they do not consider
the nature of the data at all. For example, some models assume the covariates satisfy a Gaussian
distribution. Yet, in many situations, this assumption is either too restrictive or outright incorrect
[46]. Additionally, generative models usually mix covariates and treatments together when they
should be treated separately [57].
These problems motivated us to develop a new model for causal inference that does not demand
strict assumptions over distributions. Our solution is a Bayesian nonparametric generative model
that can handle observational data with complex structures and does not carry the assumption
of parametric distribution. Called CDP, our model estimates a joint distribution p(T,X,Y ) with
an infinite number of hierarchical and latent mixtures. It is based on a Gibbs sampling inference
algorithm and a novel ad hoc causal Dirichlet prior, called Causal DP, that has been specifically
designed to capture the dependencies between covariates, treatments, and outcomes. As a result,
the model can estimate a range of causal effects, including average, conditional average, average
treated, and quantile. Moreover, Causal DP works especially well in situations with low propensity scores [55], defined as the conditional probability of treatments given the observed baseline
covariates.
Experiments on synthetic datasets demonstrate the proposed model is better able to capture
complex relationships than other methods, such as enriched DP. Further, an inference task with
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:3
real-world data from a job training program highlights the practical value of the model and its
potential with many other scientific problems and applications.
In summary, the main contributions of this study are:
• A novel Bayesian nonparametric prior, called Causal DP, that captures complex relationships between covariates, treatments, and outcomes.
• A Bayesian nonparametric generative model for causal inference, called CDP, that is based
on Causal DP and does not carry the assumption of a parametric distribution. The model
can also handle uncertainty in data, such as missing covariates.
• A Gibbs sampling inference algorithm for model inference. The inference approximates the
joint distribution of observational data; hence, CDP can estimate various kinds of causal
effects, including average causal effects, conditional average causal effects, average treated
causal effects, and quantile causal effects.
The remainder of this article is organized as follows: Section 2 discusses the related work on
causal inference and Bayesian nonparametric learning. We formally define causal effects, introduce three basic assumptions for causal inference from observational data, and briefly introduce
Dirichlet process in Section 3. In Section 4, we propose a Causal DP as the prior for causal inference and a new Bayesian nonparametric model with Causal DP as the prior is developed for causal
inference from observational data. Section 5 evaluates the properties of the proposed model and
details the comparative experiments conducted on both synthetic and real-world data. Finally,
Section 6 concludes this study and discusses possible future work.
2 RELATED WORK
In this section, we provide some background on the existing methods of causal inference, followed
by work in the two key themes that underpin our research. Machine learning approaches informed
our choice for a generative model. Bayesian nonparametric learning motivated the methodology.
Relevant studies in these two areas are discussed below.
2.1 Existing Methods for Causal Inference
Broadly speaking, there are three main forms of causal inference: methods based on treatment
modeling, methods based on outcome regression adjustment, and methods based on doubly robust
estimation.
2.1.1 Methods Based on Treatment Modeling. The idea of treatment modeling is to replicate the
assignment mechanism [30] of a randomized experiment—the assignment mechanism being the
process that determines which individuals receive which treatments. Matching selects individuals
with “similar” covariates, dividing them between the treated and control groups. There are several
different types of matching methods. Nearest neighbor matching selects a certain number of individuals from the control group to match individuals from the treated group. Optimal matching [34]
selects an overall set of matches for both groups by minimizing a global distance measure. Ratio
matching [64] selects multiple matches for each treated individual and places them in the control
group. Notably, these three methods do not use all the individuals from the control group to match
individuals from the treated group. Subclassification, full matching, and weighting, however, do
use all the individuals in the control group. Subclassification [13] creates groups of individuals
that are similar. Full matching [66] selects the number of groups automatically. Kernel weighting
[41] defines weights according to the distance between multiple individuals in the control group
for each treated individual.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:4 A. Lin et al.
Moreover, the keys to all matching methods rest on which covariates are included in the matching process and how similarity is measured. Ignorability is the key to determining which covariates
to include [55]. Based on the assumption ignorability, variable selection for estimating propensity
scores is significant for controlling confounders [80]. A more recent development is the idea of
sufficient dimension reduction [47]. Measuring similarity is usually based on distance, but there
are three different commonly used distance measures: exact, Mahalanobis, and propensity scores.
An alternative to a propensity score is the prognostic score [26]. But using prognostic scores with
matching methods requires stronger assumptions. Propensity scores are perhaps the most widely
used metric [7], but it can be implemented in a few different ways. Propensity score matching [1]
uses the propensity scores to establish matched pairs, while propensity score subclassification [56]
uses the scores to form groups of similar individuals. Inverse probability of treatment weighting
(IPTW) [53] estimates average causal effect based on propensity scores by the mean difference
between weighting outcomes for the treated group and the control group.
Matching methods are complementary to outcome regression adjustment and perform well in
combination. Additionally, matching methods produce acceptable results when there is insufficient
overlap in the covariate distributions of the treated and control groups. Plus, assessing their performance is straightforward. The drawbacks, however, are that most matching methods assume
the covariates are fully observable, and they are not designed to cope with missing covariates. Last,
selecting a suitable matching method can be difficult, as different distance measures often lead to
different results.
2.1.2 Methods Based on Outcome Regression Adjustment. Outcome regression adjustment estimators identify average causal effects [48] by estimating a conditional outcome expectation based
on consistency [52] and positivity assumptions. Alternatively, they estimate the difference between the conditional outcome expectations of the treated group and the control group. Popular outcome regression methods include: Bayesian methods, ensemble methods, metalearners,
approximate residual balancing, neural network–based methods, and causal effect variational autoencoders (CEVAEs) [46].
Bayesian methods, such as Bayesian additive regression trees [28] and multi-task Gaussian processes [3], along with ensemble methods such as random forests based on a causal tree [4, 6], are
good performers with good interpretability. But most of these methods have rigid runtime and
some need a large number of observations to produce good results. Metalearners [39] build on
base algorithms, such as random forests and Bayesian additive regression trees. They can translate a supervised learning algorithm into a conditional average causal effect estimator, but they
do not perform well when the response surfaces in the treated and control groups have different outcomes, and they are not designed for missing covariates. Approximate residual balancing
[5] combines balancing weights with a regularized regression adjustment for estimating unconfounded average causal effects through high-dimensional linear models. The shortcoming of these
models is that it is hard to tune the parameters and approximate residual balancing is restive to
linear models. Neural networks, such as balancing neural networks [31, 62], have a strong ability
to capture complex relationships among treatments, covariates, and outcomes. However, neural
networks need big data and are sensitive to parameters. CEVAEs [46] are neural network models based on latent variables. They are robust to hidden confounders and generally perform well.
However, they have a somewhat limited representation ability, because they assume that the hidden confounders have a normal distribution. These outcome regression methods can approximate
the conditional distribution well and are good at estimating causal effects. But they are vulnerable
to missing covariates and often introduce bias during inference. In addition to these main types of
methods, there is the penalized regression approach [24], which uses the concept of ignorability
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:5
to determine which covariates to include in outcome regression adjustment [55]. Sufficient dimension reduction [48] is another interesting idea for aiding causal inference.
2.1.3 Methods Based on Doubly Robust Estimation. The idea of doubly robust [8] estimation is
to use two models to estimate average causal effects—a model for treatment (mostly a propensity
score model) and an outcome regression adjustment model. However, the asymptotic properties
of these combined models are not well understood. Plus, each model is only unbiased if it is correctly specified. Examples of a doubly robust estimator include the augmented inverse probability
weighting (AIPTW) estimator [54], which combines a propensity score method and an outcome
model to improve IPTW estimators. Targeted maximum likelihood estimation (TMLE) [69] improves on AIPTW by estimating the outcome model with ensemble learning. TMLE first estimates
the conditional outcome distribution, then it estimates the propensity score and updates the estimate of the conditional outcome distribution. Finally, it generates an estimate of the target parameter. The double machine learning estimator [11] combines the residuals of a propensity score
model and the residuals of an outcome regression model into a new regression model to estimate
average causal effects. Machine learning algorithms are used to estimate the nuisance parameters
in the AIPTW estimator for inferring causal effects in the interactive model.
2.2 Machine Learning Tools to Realize Causal Inference Methods
There are mainly two categories of machine learning approaches: generative ones and discriminative ones [50]; thus, we organize the existing works on causal inference into such two categories
as well.
One category of causal inference approaches is based on discriminative models, which are to
model the conditional distribution of outcome given treatment and covariates, i.e., p(Y |T,X) [61].
The first group is matching methods that aim to estimate a conditional distribution according
to the subjects’ nearest neighbors; that is, both treated and control subjects are selected to
estimate causal effects. Some examples of matching methods are optimal matching [33], genetic
matching [15], and kernel matching [41]. Matching methods have several advantages: They
can be combined with regression adjustment, and they can deal with covariate distributions
without a sufficient overlap between the treated and control groups. However, most matching
methods assume fully observed covariates, which makes it hard to deal with missing covariates.
Additionally, matching methods are sensitive to the distance measure selected. The second group
is machine learning algorithms for outcome regression adjustment, Bayesian methods, e.g.,
Bayesian additive regression trees [28], multi-task Gaussian process [3], and Gaussian process
[45]. These methods have good interpretation but are restricted to modeling average causal effects.
Tree-based methods [4, 6, 35] partition data into subpopulations and then ascertain causal effects
from estimates within each subpopulation. Causal forests [4, 6] split data into subpopulations
according to their causal effects and build confidence intervals. The optimal partitioning approach
[35] recursively partitions the data into the regimes determined to be optimal for different
treatments. Tree-based methods are intuitive to understand but require a large sample size to be
effective. Neural network–based methods, e.g., balancing neural network [31] and deep IV [27],
perform well, but they are vulnerable to missing covariates and often experience problems with
overfitting. Double machine learning estimator [11] uses machine learning algorithms to estimate
the nuisance parameters in the AIPTW estimator for inference on causal effects in the interactive
model. It is unclear how double machine learning copes with missing covariates. Discriminative
models are often vulnerable to missing covariates, are limited to a specific causal parameters such
as average causal relative risk, and are easily overfitting.
The other category is based on generative models, which are to model the joint distribution of
treatment, covariates, and outcome, i.e., p(T,X,Y ). Generative models are not prone to overfitting
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:6 A. Lin et al.
and they can model covariates. It is possible to apply generative models for matching or outcome
regression adjustment and so on. For example, Causal Effect Variational Autoencoder (CEVAE)
[46] uses deep neural networks to estimate the joint distribution. The advantage of CEVAE is its
ability to capture the complex relationships between treatments, covariates, and outcomes. One
drawback is its restriction to represent arose from the Gaussian parametric assumption about the
unknown covariate distribution. It also overlooks the hidden clustering properties in the data.
To tackle the Gaussian parametric assumption for unknown distributions, the implicit generative
models [79] conduct inference with an intractable likelihood. However, such an approach is not
robust and is difficult to interpret. Our work follows this last method, but with a view to a model
that can capture the complex relationships between treatments, covariates, and outcomes better
interpretability and without the need to make unreasonable assumptions.
2.3 Bayesian Nonparametric Learning
Bayesian (machine) learning has long played a significant role in machine learning due to its particular merits in embracing uncertainty, encoding prior knowledge, and good interpretability. Following the success of Bayesian learning, Bayesian Nonparametric Learning (BNL) [32, 75] has
emerged as an advancement in this field in terms of more representation power and more flexible
modeling. The first studies on Bayesian nonparametrics were conducted by Thomas S. Ferguson
in 1973 [21] and Kjell Doksum in 1974 [17]. Instead of playing with the fixed-dimensional probabilistic distributions of Bayesian learning, BNL is a “game” of playing with (infinite-dimensional)
stochastic processes (e.g., Dirichlet, Gaussian, Poisson, Gamma, Hawkes, or Negative binomial
processes). BNL builds probabilistic models with a flexible structure that have the ability to autonomically adapt themselves to newly arriving observations—an approach that is often known
as “letting the data speak.” These models can replace unknown functions with priors [22, 59] or
partitions. A typical application scenario is document modeling, where BNL not only learns topics as a document summary but can also increase or decrease the number of topics in line with
new documents as they arrive. Further, the number of topics change smoothly. Beyond document
modeling, BNL is used in many other machine learning tasks, such as supervised learning [25, 76],
nonnegative matrix/tensor factorization [16, 77], factor analysis [16, 44], transfer learning [20],
cooperative hierarchical structure modeling [74], and reinforcement learning [18].
The latest work in causal inference is a Bayesian nonparametric model based on an enriched
Dirichlet process by Roy et al. [57]. The model does not assume a parametric distribution, and it
considers the hidden clustering properties in the observational data. Enriched Dirichlet process
priors were first proposed by Wade et al. [71, 72]. These kinds of priors can deal with missing
covariates and are flexible enough to compute various kinds of causal parameters. However, the
covariates and treatments are combined for modeling, which significantly weakens the model’s
ability to capture the complex relationships between treatments, covariates, and outcomes.
3 PRELIMINARIES
This section begins with the formal definition of causal effect, followed by three commonly applied
assumptions in causal inference from observational data. Then, we briefly review the Dirichlet
process [67] and some ways of constructing representations that are useful for Section 4, where
we outline Causal DP and the generative model.
3.1 Causal Inference
The aim of our research is to build a model that can estimate the causal effects of treatment T
on outcome Y from observed data (T,X,Y). Here, T denotes a discrete/categorical treatment that
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:7
may take one of q possible values. p × 1 denotes the covariate vector as X. The variable of the
ith subject (i = 1,...,n) is described by adding a subscript (such as Ti ). Following the potential
outcome framework [58, 65], causal effect is defined as follows:
Definition 3.1 (Causal Effect). Causal effects are the comparisons of potential outcomes given
various treatments on subjects, where a potential outcome Yt is the value of the outcome variable
that would be observed for a given value of the treatment t.
Thus, the definition of causal effect can be seen as functions of potential outcomes (i.e., p(Yt |X)).
For simplicity, in this article, we have focused on situations where the treatment is binary (i.e.,
q = 2). The causal parameters of interest include: average causal effect E[Y1 − Y0]; average causal
relative risk E[Y1]/E[Y0]; conditional average causal effect E[Y1 − Y0 |V ], where V ⊂ X; average
treated causal effect E[Y1 − Y0 |T = 1]; and quantile causal effect F −1
1 (p) − F −1
0 (p), where F −1
t (p) is
the pth quantile of the cumulative distribution function P (Yt ≤ y).
It is not possible to conduct causal inference from observational data without making some
assumptions, since each data sample is only an observation of one of all possible outcomes [29].
Fortunately, there are three seminal causal assumptions in the literature that make causal inference
on observational data possible:
• consistency [52, 70]: For all treatments t, assume Yt = Y among all the subjects that received treatment t. This assumption means that the potential outcome of subject i given
the treatment ti = t is equal to the observed outcome of the subject given the observed
treatment ti = t.
• positivity: For all X, if p(X) > 0, then p(T = t|X) > 0. The non-zero conditional probability of seeing each treatment given these covariates represents the subject received this
treatment is represented in the data.
• ignorability [55]. A treatment can be assumed to be randomly assigned, conditional on
the confounders X; that is,
Yt ⊥⊥ T |X
. This assumption ensures that there are sufficient
measured covariates for estimating a conditional probability for every treatment.
Based on these assumptions, an observational study can be thought of as a conditional randomized experiment. Thus, we have p(yt |X) = p(yt |T = t,X) = p(y|T = t,X). And the problem
of estimating p(yt |X) is transformed into the problem of estimating p(y|T = t,X). Note that any
statistical quantities related to p(yt |X) can be identified from p(Y,T,X):
E[Yt
] = Ex∼p(x )[E[Y |T = t,X]],
E[Yt |V = v] = Ew∼p(w |v)[E[Y |T = t,V = v,W ]|V = v], where X = (V,W ),
E[Yt |T = t
] = Ex∼p(x |T =t)[E[Y |T = t,X]|T = t
],
P (Yt ≤ y) =
 y
−∞

p(Y |T = t,X)dF (X).
Hence, only the joint distribution p(T,X,Y ) needs to be estimated to ascertain the causal effects.
With these preliminary definitions in hand, the next section provides a brief outline of the Dirichlet
process that is the basis of our new Bayesian nonparametric model.
3.2 Dirichlet Process
The Dirichlet process [21, 67] is the pioneer and foundation of Bayesian nonparametric learning.
Its definition follows:
Definition 3.2 (Dirichlet process). A Dirichlet Process (DP), which is specified by a base measure
H on a measurable space Θ and a concentration parameter α, is a set of countably infinite random
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.  
33:8 A. Lin et al.
variables that can be seen as the measures on measurable sets from a random infinite partition
{Ωk }
∞
k=1 of Θ. For any finite partition {Ωk }
K
k=1, the variables (measures on these measurable sets)
from the DP satisfy a Dirichlet distribution parameterized by the measures from based measure H
(G(Ω1),G(Ω2),...,G(ΩK )) ∼ Dir(αH(Ω1), αH(Ω2),..., αH(ΩK )),
where G is a realization of DP (α,H) and Dir() denotes the Dirichlet distribution.
Since G is a discrete measure with a probability of 1 [21], the mass G(Ωk ) will concentrate on
one point of Ωk (i.e., θk ∈ Ωk , which we interchangeably refer to as a topic/factor/atom in this
article. Therefore, G can alternatively be defined as
G =
∞
k=1
πkδθk ,
∞
k=1
πk = 1, θk ∼ H, (1)
where {θk }
∞
k=1 denotes the countable infinite points in the measurable space Θ. These points are
sampled according to the base measure H, and πk = G(Ωk ) is the measure value from G on a
measurable set Ωk , which is effectively the (normalized) weight of θk in {θk }
∞
k=1 and δθk is a Dirac
measure parameterized by θk (i.e., δθk ( ˆ
θ ) = 1 if ˆ
θ = θk , and 0 otherwise). One sample draw from
G would be one of {θk }
∞
k=1 according to their relative weights {πk }
∞
k=1.
Considering the DP is infinite and discrete nature, it is widely used as a prior for mixture models
[51]. For example,
xi ∼ F (θi ), θi ∼ G, (2)
where xi is a data point generated according to a distribution F () that is parameterized by a draw
θi from G. Due to the discrete nature of G, we have θi ∈ {θk }
∞
k=1 with implied data clustering according to their assigned θi . For computational convenience, F () is normally set as a multinomial
distribution, because it is conjugate to the Dirichlet distribution. Document modeling is a successful application of this type of mixture model. Here, θk is a V -dimensional (normalized) vector
(topic) where V is the number of different words in a corpus of text.
A Bayesian posterior analysis of the DP requires a representation of G. One approach to a marginal constructive representation of G is the Chinese restaurant process [10], which directly generates θi for the ith data point (they are exchangeable) with G marginalized out as follows:
θi |θ1,..., θi−1 ∼

i−1
j=1
1
α + i − 1
δθj +
α
α + i − 1
H, (3)
where 1
α+i−1 is the probability of taking the previous ones and α
α+i−1 is the probability of taking a
new one according to H. Here, the weights πk in Equation (1) are implicitly reflected in the ratio
of θk in {θi}i→∞.
The name comes from a metaphor used to understand Equation (3). In a Chinese restaurant, the
ith customer walks into a restaurant and either picks an occupied table to sit at with a probability
of 1
α+i−1 or a new table with a probability of α
α+i−1 . If the customer picks an occupied table, then
she eats the dish already on the table; if she picks a new table, then she needs to order a new dish
for the table from H. As a result, θi is the dish eaten by the ith customer.
4 CAUSAL DIRICHLET PROCESS
This section begins with an outline of the CDP model, our Bayesian nonparametric generative
model for estimating the joint distribution of observational data, followed by a description of our
CDP prior. Next, we detail the Gibbs sampling inference algorithm that we specifically designed for
model inference. The sampling process alternates between drawing subject cluster memberships
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:9
Table 1. Key Notations
Symbol Meaning
T treatment variable
X covariates variable
Y outcome variable
Yt potential outcome at treatment level of t
αθ , αϕ, αω concentration parameters of Causal DP
θ,ϕ,ω parameters of the proposed generative model
θ ∗,ϕ∗,ω∗ unique values of {θ,ϕ,ω}
G distribution
H base distribution
F () distribution
p() distribution
Pr() probability function
z the indicator vector of cluster membership
kj current number of t-subclusters of the jth y-cluster
kl |j current number of x-subclusters of the lth t-subcluster of the jth y-cluster
−i indicates that the ith object is removed
k−i
j the number of unique and currently non-empty t-subclusters of the jth
y-cluster excluding subject i
k−i
l |j the number of unique and currently non-empty x-subclusters of the lth
t-subcluster of the jth y-cluster excluding subject i
n−i
j , n−i
l |j and n−i
h |j,l the number of subjects in the corresponding subclusters, excluding subject i
d
= is defined to be
and parameter values given the cluster partitions. Then, we show how to estimate causal effects
by integrating covariates over the conditional distribution of the outcomes given a treatment and
the covariates. A Monte Carlo (MC) integration must be performed to estimate the distribution of
covariates for each posterior sample of the parameters. Last, we present the imputation of missing
covariates using the “missing at random” assumption. Some key notations used throughout this
article are summarized in Table 1.
4.1 Model Description
Causal DP is a new Bayesian nonparametric prior, defined as
G ∼ CDP (αθ , αϕ, αω,H)
G d
= Gθ × Gϕ |θ × Gω |θ,ϕ
Gθ ∼ DP (αθ ,Hθ )
Gϕ |θ ∼ DP (αϕ,Hϕ |θ )
Gω |θ,ϕ ∼ DP (αω,Hω |θ,ϕ )
H = Hθ × Hϕ |θ × Hω |θ,ϕ, (4)
whereGθ ,Gϕ |θ , andGω |θ,ϕ are samples from a standard DP. H is the prior forG. CDP defines θ, ϕ,
and ω as having a joint distribution and a hierarchical structure. As illustrated in Figure 1, each θ
is associated with an infinite number of ϕs, and each ϕ is associated with an infinite number of ωs.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:10 A. Lin et al.
Fig. 1. Diagram of the three-layer clusters. The solid squares represent existing clusters or subclusters. The
proposed new clusters and subclusters are illustrated in dashed squares. At each iteration of the Gibbs sampling, the cluster membership is updated for each subject, followed by the parameters θ ∗, ϕ∗, and ω∗, then
the concentration parameters. The probability of each subject assigning to each existing and proposed new
Z is computed and a subject is randomly assigned to a cluster membership according to the corresponding
multinomial distribution. The parameters and concentration parameters are then updated according to the
cluster membership.
Fig. 2. Comparison between the CDP model and the EDP model. The nodes represent a set of variables, and
the arrows describe the cause-effect relationship. X represents the confounders, which affect the treatment
T and the outcome Y. In the CDP model, X is modelled separately to T . In the EDP model, X is modelled
with T , assuming independence of X and T within each cluster.
The corresponding model (hereafter referred to as the CDP model) estimates the joint distribution p(T,X,Y ) using CDP as the prior.
For each observation {Ti,Xi,Yi},i = 1,...,n:
Yi |Ti,Xi, θi ∼ F (y|t, x, θi )
Ti |Xi,ϕi ∼ F (t|x,ϕi )
Xi,r |ωi ∼ F (xi,r |ωi ),r = 1,...,p
(θi,ϕi,ωi )|G ∼ G
G ∼ CDP (αθ , αϕ, αω,H). (5)
The enriched DP mixture model proposed by Roy et al. [57] is closely related to our CDP model.
However, we argue that CDP is more reasonable than enriched DP. As illustrated in Figure 2(b),
the EDP approach models covariates and treatments together by assuming the covariates and
the treatments within a cluster are locally independent. But, because confounders affect both the
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:11
treatments and the outcomes, the covariates X selected as confounders are not independent of either treatment T or outcome Y. This assumption of independence significantly weakens the ability
of the enriched DP model to capture the complex relationships between treatments and covariates.
Figure 2(a) shows that CDP models treatment and covariates separately to explicitly represent the
conditional distribution of a treatment given its covariates. In this way, the CDP model can reveal a more accurate joint distribution for p(T,X,Y ). This is especially so in situations with low
propensity scores, because the conditional probability of treatments can be assigned according to
observed baseline covariates. The dependency structure in Figure 2(a) more reasonably reflects the
intrinsic structure of the causal relations between T , X, and Y. For these reasons, we have called
our model CDP (disambiguated from the prior Causal DP).
CDP is designed to work with the Causal DP prior. Each subject i has its own parameters θi,ϕi ,
and ωi . As G is discrete, subjects in the same cluster will share the same parameters. The concentration parameters αθ , αϕ , and αω control the number of clusters. A lower value indicates a
smaller number of clusters. The nested concentration parameters allow for more subclusters than
upper-level clusters. This is useful when dealing with covariates X with high dimensionality.
We assume that p(y|t, x, θi ) and p(t|x,ϕi ) are local generalized linear models [25], and we assume the covariates are locally independent within the clusters; that is, in a subcluster ωi , the
covariates are independent. Subjects in the same subcluster have similar values of X. Although,
we assume that correctly specified locally generalized linear models of p(y|t, x, θi ) and p(t|x,ϕi )
and locally independent covariates. However, globally, all the variables are potentially dependent
and have non-linear relationships.
The first p1 covariates are assumed to be binary, and the remaining p2 covariates are assumed
to be continuous. The continuous covariates are standardized first.
We then assume
Yi |Ti,Xi, θi ∼ N ((1,Ti,XT
i )βi, σ2
i ) (continuous outcome)
Yi |Ti,Xi, θi ∼ Bern(loдit−1 ((1,Ti,XT
i )βi )) (binary outcome)
Ti |Xi,ϕi ∼ Bern(loдit−1 ((1,XT
i )γi ))
Xi,r |ωr
i ∼ Bern(πr
i ),r = 1,...,p1
Xi,r |ωr
i ∼ N (μr
i , τ 2,r
i ),r = p1 + 1,...,p1 + p2
(θi,ϕi,ωi )|G ∼ G
G ∼ CDP (αθ , αϕ, αω,H), (6)
where θi = βi when the outcome is binary, θi = (βi, σ2
i ) when the outcome is continuous, ϕi = γi ;
and ωi = (πi, μi, τ 2,r
i ).
We setHθ (β) = N (β0, Σ0
β ), where β0 is set to the maximum likelihood estimate from an ordinary
linear or logistic regression of Y on (T,X) and Σ0
β is a diagonal matrix where all non-zero values
are 4. We set Hθ (σ2) = Scale − Inv − χ2 (aσ ,bσ ), and we set Hϕ |θ (γ ) = N (γ0,cΣ0
γ ), where γ0 is set
to the maximum likelihood estimate from an ordinary linear or logistic regression of T on X, and
Σ0
γ is a diagonal matrix with 4 for all non-zero values. We set Hω |θ,ϕ (πr ) = Beta(ax ,bx ), where
ax = bx = 1 for r = 1,...,p1. We set Hω |θ,ϕ (μr |τ 2,r ) = N (μ0, τ 2,r /c0), where μ0 = 0,c0 = 0.5, for
r = p1 + 1,...,p1 + p2.
4.2 Model Inference
We opted for the extension of Algorithm 8 in Reference [49] to draw the samples from the posterior distributions. The approach is to alternate between drawing cluster memberships for subjects
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:12 A. Lin et al.
and drawing samples of the parameters and the concentration parameters given the cluster partitioning. For each Gibbs sample, the cluster membership is updated for each subject, then the
parameters are updated based on the cluster partitions followed by the concentration parameters.
We describe the pseudo-code for the MCMC algorithm in Algorithm 1.
ALGORITHM 1: MCMC Inference
input: Treatments T (n × 1), covariates X (n × p) and outcomes Y (n × 1)
output: Cluster membership {z}, parameters {θ,ϕ,ω}, concentration parameters {αθ , αϕ, αω } and
causal effects
1 initialize: concentration parameters {αθ , αϕ, αω}, cluster membership {z}, parameters {θ,ϕ,ω };
2 for i ← 1 to l do
3 {z} ←− UpdateClusterMembership (T,X,Y ) according to Equation (7);
4 {θ,ϕ,ω} ←− UpdateParameters (T,X,Y, {z}) according to Equation (8), Equation (9), and
Equation (10);
5 {αθ , αϕ, αω } ←− UpdateConcentrationParameters (T,X,Y, {z}) according to Equation (11),
Equation (12), and Equation (13);
6 if i ≥ burnin then
7 ComputeCausalEffect(T,X,Y, {z}, {θ,ϕ,ω}, {αθ , αϕ, αω }) by Algorithm 2;
8 end
9 end
The indicator vector zi = (zi,y, zi,t, zi,x ) is denoted as the cluster membership for subject i. Note
that the value of zi,t, zi,x is only meaningful in conjunction with zi,y , as it describes which cluster
zi,y belongs to. The basic steps of the Gibbs sampling process follow.
zi is sampled for each subject, and the parameters θi,ϕi,ωi are sampled from the conditional
distribution p(θi,ϕi,ωi |ti, xi,yi ) given the data in each cluster or subcluster.
θ ∗
j is denoted as the θ that is associated with the jth of the currently non-empty clusters. ϕ∗
l |j and
ω∗
h |j,l are similarly defined. k denotes the current number ofy-clusters, kj denotes the current number of t-subclusters of the jth y-cluster, and kl |j denotes the current number of x-subclusters of the
lth t-subcluster of jth y-cluster. −i indicates that the ith value has been removed from the subjects.
During the cluster membership draw, each possible new cluster is associated with m auxiliary
parameters. When assigning a cluster membership (see Figure 1), each subject might be assigned
to: one of the existing non-empty clusters; one of m new y-clusters; one of m new t-subclusters
within each existing y-cluster, or one ofm new x-subclusters within each current t-subcluster. We
used m = 5 in our experiments. The cluster membership zi is then updated.
For every observation i = 1,...,n, the following steps are performed: Before updating zi , we
need to relabel the cluster memberships for the subjects, excluding the subject i, and generate
auxiliary parameters for the new potential clusters. k−i is denoted as the number of unique and
currently non-empty y-clusters excluding subject i, k−i
j is the number of unique and currently
non-empty t-subclusters of the jth y-cluster excluding subject i, and k−i
l |j is the number of unique
and currently non-empty x-subclusters of the lth t-cluster of the jth y-cluster excluding subject
i. Label the clusters occupied by the subjects excluding subject i {1,..., k−i} for the y-clusters,
{1,..., k−i
j } for the t-subclusters of the jth y-cluster, and {1,..., k−i
l |j
} for the x-subclusters of the
lth t-subcluster of jth y-cluster.
Draw m values of θ ∗, ϕ∗, and ω∗ from the prior distributions from Hθ , Hϕ |θ , and Hω |θ,ϕ for yclusters {k−i + 1,..., k−i + m}. From each existing y-cluster, e.g., the jth y-cluster), draw m values
of ϕ∗ andω∗ from prior distributions from Hϕ |θ andHω |θ,ϕ fort-subclusters {k−i
j + 1,..., k−i
j + m}.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:13
From each existing x-subcluster (e.g., the jth y-cluster and lth t-subcluster), draw m values of
ω∗ from prior distribution from Hω |θ,ϕ for x-subclusters {k−i
l |j + 1,..., k−i
l |j + m}. The cluster and
subcluster parameters are illustrated in Figure 1.
4.2.1 Updating the Cluster Membership zi . Next, a new value is drawn from the cluster membership zi for subject i in each iteration of the Gibbs sampler. The new value for zi = (zi,y, zi,t, zi,x ) =
(j,l,h) could be represented as “old-old-old,” “old-old-new,’ “old-new-new,” or “new-new-new”
(though the labels “new” and “old” are borrowed from Reference [72], the process of updating
cluster memberships). More explicitly,
• “old-old-old” means subject i is assigned to an existing x-subcluster. Then, we have 1 ≤ j ≤
k−i
, 1 ≤ l ≤ k−i
j , and 1 ≤ h ≤ k−i
l |j
.
• “old-old-new” means subjecti is assigned to an existing t-subcluster but a new x-subcluster,
and we have 1 ≤ j ≤ k−i
, 1 ≤ l ≤ k−i
j , and k−i
l |j + 1 ≤ h ≤ k−i
l |j + m.
• “old-new-new” means subject i is assigned to an existing y-cluster but a new t-subcluster,
and we have 1 ≤ j ≤ k−i
, k−i
j + 1 ≤ l ≤ k−i
j + m, and 1 ≤ h ≤ m.
• “new-new-new” means subject i is assigned to a new y-cluster, and we have 1 + k−i ≤ j ≤
k−i + m, 1 ≤ l ≤ m, and 1 ≤ h ≤ m.
n−i
j , n−i
l |j
, and n−i
h |j,l denote the number of subjects in the corresponding cluster or subcluster,
excluding subject i. The conditional posterior distribution of each cluster membership for the nonconjugate distributions is
Pr(zi = (j,l,h)|z−i, θ ∗
,ϕ∗
,ω∗
, {t, x,y}) =
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪
⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪
⎩
old-old-old, b n−i
j n−i
l|j
n−i
h|j,l
(n−1+αθ )(n−i
j +αϕ )(n−i
l|j
+αω )
F (yi |ti, xi, θ ∗
j )F (ti |xi,ϕ∗
l |j
)F (xi |ω∗
h |j,l
)
old-old-new, b n−i
j n−i
l|j
αω /m
(n−1+αθ )(n−i
j +αϕ )(n−i
l|j
+αω )
F (yi |ti, xi, θ ∗
j )F (ti |xi,ϕ∗
l |j
)F (xi |ω∗
h |j,l
)
old-new-new, b n−i
j αϕ /m
(n−1+αθ )(n−i
j +αϕ )
F (yi |ti, xi, θ ∗
j )F (ti |xi,ϕ∗
l |j
)F (xi |ω∗
h |j,l
)
new-new-new, b αθ /m
n−1+αθ F (yi |ti, xi, θ ∗
j )F (ti |xi,ϕ∗
l |j
)F (xi |ω∗
h |j,l
),
(7)
where b is a normalizing constant, and F (xi |ωi ) = p
r=1 F (xi,r |ωi ) according to the assumption of
local independence between the covariates within each cluster.
4.2.2 Updating the Parameters θ ∗, ϕ∗, and ω∗. The parameters θ ∗, ϕ∗, and ω∗ are then updated
from their conditional posterior distributions in each iteration of the Gibbs sampler. The update
order is: θ ∗ for each y-cluster; ϕ∗ for each t-subcluster within every y-cluster; and ω∗ for each
x-subcluster within each t-subcluster of every y-cluster. The details follow:
For each unique j from 1 to k, θ ∗
j is updated from the conditional posterior distribution
p(θ ∗
j |z, {t, x,y}, θ ∗
−j,ϕ∗
,ω∗) ∝ Hθ (θ ∗
j )

i:zi,y=j
F (yi |ti, xi, θ ∗
j ). (8)
Specifically, for datasets with binary outcomes, update β with the Metropolis-Hastings algorithm,
and for datasets with continuous outcomes β ∼ N (β0, Σ0
β ), where Σ0
β = diaд(σ2
β1
, ..., σ2
βp+2
). The
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:14 A. Lin et al.
prior for each σ2 is σ2 ∼ Inv − Gam(a0,b0). Then, the conditional posterior distribution of β is
β |σ2
,y ∼ N (U, Λ)
Λ = 
Σ0
β
−1 + (1,T,XT )
T (1,T,XT )
	−1
U = Λ

Σ0
β
−1
β0 + (1,T,XT )
T
Y
	
σ2 |β,y ∼ Inv − Gam(an,bn )
an = a0 + n/2
bn = b0 +
1
2

yT y + βT
0 Σ0
β
−1
β0 − UT Λ−1
U
	
.
For each unique (j,l), update ϕ∗
l |j from the conditional posterior distribution with the
Metropolis-Hastings algorithm
p(ϕ∗
l |j |z, {t, x,y}, θ ∗
,ϕ∗
−l |j
,ω∗) ∝ Fϕ |θ (ϕ∗
l |j |θ ∗
j )

i:(zi,y,zi, t )=(j,l))
F (ti |xi,ϕ∗
l |j). (9)
The procedure for updating ϕ∗
l |j is similar to θ ∗
j in cases with binary outcomes.
For each unique (j,l,h), update ωh |j,l from the conditional posterior distribution
p(ω∗
h |j,l |z, {t, x,y}, θ ∗
,ϕ∗
,ω∗
−h |j,l ) ∝ Hω |θ,ϕ (ω∗
h |j,l |θ ∗
j ,ϕ∗
l |j)

i:zi=(j,l,h)
F (xi |ω∗
h |j,l ). (10)
Specifically, for the p1 binary covariates, πr ∗
h |j,l is updated from the beta distribution
Beta 


ax +

i:(zi,y,zi, t )=(j,l)
xi,r,bx + nh |j,l
	



.
And for the p2 continuous covariates, τ 2,∗
h |j,l is updated from Inv − χ2 distributions
Inv − χ2 


ν0 + nh |j,l ,
ν0τ 2
0 + (nh |j,l − 1)s
2,r
h |j,l + c0nh|j,l
c0+nh|j,l
(x¯r
h |j,l − μ0)
2
ν0 + nh |j,l
	



.
Then μr ∗
h |j,l is updated from normal distributions
N




c0
τ 2,∗
h|j,l
μ0 + nh|j,l
τ 2,∗
h|j,l
x¯r
h |j,l
c0
τ 2,∗
h|j,l
+ nh|j,l
τ 2,∗
h|j,l
, 1
c0
τ 2,∗
h|j,l
+ nh|j,l
τ 2,∗
h|j,l
	





,
where x¯r
h |j,l and s
2,r
h |j,l are the sample mean and sample standard deviation of rth covariate among
subjects in the same cluster with the cluster membership z = (j,l,h).
4.2.3 Updating the Concentration Parameters αθ , αϕ , and αω. The first step is to initialize αθ =
Gam(aa0,bb0), αϕ = Gam(aa0,bb0), and αω = Gam(aa0,bb0). The probability density function of
Gam() used here is f (x; α, β) = βα
Γ(α )
xα−1 exp−β x , where α is the shape and β is the rate. These
functions are set to aa0 = 1 and bb0 = 1.
Then, αθ is updated with an auxiliary parameter [19]. η ∼ Beta(αθ + 1,n) is drawn first, and
then αθ is updated from
ρGam(aa0 + k,bb0 − log(η)) + (1 − ρ)Gam(aa0 + k − 1,bb0 − log(η)), (11)
where ρ = aa0+k−1
aa0+k−1+n(bb0−log(η)) .
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:15
In addition, we have extended the posterior sampling for the concentration parameters used in
hierarchical Dirichlet processes [68] with two auxiliary variables w = (wj)
k
j=1 and s = (sj)
k
j=1 to
αϕ and αω. Each wj is a variable that takes values from [0, 1], and each sj is a binary variable that
takes on a value in {0, 1}. αϕ is then updated from the distribution
p(αϕ |w,s, ··· ) = Gam 


aa0 +

k
j=1
kj −

k
j=1
sj,bb0 −

k
j=1
log(wj)
	



, (12)
wherewj and sj have independent distributions conditional on αϕ . Each wj has a beta distribution
p(wj |αϕ, ··· ) ∝ wαϕ
j (1 − wj)
nj−1
and each sj has a Bernoulli distribution
p(sj |αϕ, ··· ) ∝


nj
αϕ
sj
.
Similar to the update for αϕ , αω is updated with
p(αω |w,s, ··· ) ∝ Gam 


aa0 +

j,l
kl |j −

j,l
sl |j,bb0 −

j,l
log(wl |j)
	



. (13)
The auxiliary variables have the following posterior distributions:
p(wl |j |αω, ··· ) ∝ wαω
l |j (1 − wl |j)
nl|j−1
,
which is a beta distribution; and
p(sl |j |αω, ··· ) ∝


nl |j
αω
sl|j
,
which is a Bernoulli distribution.
In simple terms, model inference is conducted in steps: At each iteration of the Gibbs sampler,
the cluster membership zi is updated or each subjecti, then the parameters (θ ∗,ϕ∗,ω∗) within each
cluster are updated and, last, the concentration parameters (αθ , αϕ, αω ) are updated.
4.3 Estimation of Causal Effects
Once the joint distribution of observation data has been estimated, various kinds of causal parameters can be computed. Here, we focus on E[Yt] as an instance. The pseudo-code to estimate causal
effects is present in Algorithm 2.
ALGORITHM 2: ComputeCausalEffect
input: Treatments T (n × 1), covariates X (n × p) and outcomes Y (n × 1), cluster membership {z},
parameters {θ,ϕ,ω}, concentration parameters {αθ , αϕ, αω }
output: Causal effects
1 initialize: concentration parameters {αθ , αϕ, αω}, cluster membership {z}, parameters {θ,ϕ,ω };
2 for i ← 1 to s do
3 draw M samples {xm, zm } from the predictive distribution p(X, z);
4 compute E[Y |T = t, {xm, zm }] according to Equation (15);
5 E[Yt] ←− 1
M
M
m=1 E[Y |T = t, {xm, zm }] according to Equation (14);
6 end
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:16 A. Lin et al.
The steps to estimate the conditional average causal effect E[Y1 − Y0 |V ] and the average effect
of the treatment on the treated E[Y1 − Y0 |T = 1] are almost the same as E[Yt] but integrate over
the conditional distribution W |V = v or X |T = t, respectively, instead of integrating the marginal
distribution of X. From E[Yt] = Ex∼p(x )[E[Y |T = t,X]], we can draw a sample from E[Yt] by integrating over the distribution ofX using MC integration. We can do an MC integration overestimate
of the marginal distribution of X for each posterior sample of the parameters; that is, the sample
can be drawn from the posterior predictive distribution of X. First, M samples are drawn from
p(X, z) as follows: For m = 1,..., M,
(1) zm
y = j is drawn from {1,..., k, k + 1} with a probability of  n1
αθ +n ,..., nk
αθ +n , αθ
αθ +n
	
.
(2) If zm
y = j < k + 1, zm
t = l is drawn from {1,..., kj, kj + 1} with a probability of
 n1|j
αϕ +nj
,..., nkj |j
αϕ +nj
, αϕ
αϕ +nj

.
(a) If zm
t = l < kj + 1, then zm
x = h is drawn from {1,..., kl |j, kl |j + 1} with a probability
of

 n1|j,l
αω + nl |j
,..., nkl|j |j,l
αω + nl |j
, αω
αω + nl |j

.
(b) If zm
t = l = kj + 1, then zm
x = h = 1.
(3) If zm
y = j = k + 1, then zm
t = l = 1 and zm
x = h = 1.
(4) xm is drawn fromp(x |w∗
zm
x |zm
y ,zm
t
); if zm
y = k + 1 or zm
t = kj + 1 or zm
x = kl |j + 1,w∗
zm
x |zm
y ,zm
t
is drawn from the prior distribution.
E[Yt] can be approximated from the obtained M samples {xm, zm } with
E[Yt
] ≈ 1
M

M
m=1
E

Y |T = t,X = xm, θ ∗
zm
y ,ϕ∗
zm
t |zm
y ,ω∗
zm
x |zm
y ,zm
t , zm 
. (14)
Next, we compute E[Y |t, x, θ ∗,ϕ∗,ω∗, z] given the current values of the parameters, θ ∗,ϕ∗,ω∗, z,
from the Gibbs sampler. We can compute E[Y |t, x, θ ∗,ϕ∗,ω∗, z] from
E[Y |t, x, θ ∗
,ϕ∗
,ω∗
, z] = wk+1 (t, x)E0 (Y |t, x) + k
j=1wj (t, x)E(Y |t, x, θ ∗
j )
wk+1 (t, x) + k
j=1wj (t, x) , (15)
where
wk+1 (t, x) = b · αθ
αθ + n
F0 (t|x)F0 (x),
wj (t, x) = b · nj
αθ + n



wwkj+1 (x) +

kj
l=1
wwl (x)
	



,
wwkj+1 (x) = αϕ
nj + αϕ
F0 (t|x)F0 (x),
wwl (x) = nl |j
nj + αϕ
F (t|x,ϕ∗
l |j) 


αω
αω + nl |j
F0 (x) +

kl|j
h=1
nh |j,l
nl |j + αω
F (x |ω∗
h |j,l )
	



,
in which b is the normalizing constant. F0 (x) is the distribution after integrating the parameter
ω over the prior distributions, and E0[y|t, x] is the mean after integrating θ over the prior distributions; that is, F0 (x) =  F (x |ω)dHω (ω) and E0[y|t, x] =  E[y|t, x, θ]dHθ (θ ). We use a Monte
Carlo (MC) integration to obtain these quantities if these distributions are non-conjugate.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:17
F0 (x) can be computed from the product of every marginal distribution of the covariates after
integrating the parameters due to the assumption of local independence in the covariates X. The
distribution for each discrete covariate xr,r = 1,...,p1 is
F0 (xr ) = B(a0 + xr,b0 − xr + 1)
B(a0,b0) .
And the distribution for each continuous covariate xr,r = p1 + 1,...,p1 + p2 is
F0 (xr ) = Γ(νn/2)
Γ(ν0/2)
c0
cn
(ν0τ 2
0 )
ν0/2
(νnτ 2
n )
νn /2
1
√
π
,
where cn = c0 + 1, νn = ν0 + 1 and τ 2
n = 1
νn (ν0τ 2
0 + c0
cn (xr − μ0)
2
). Recall that we assumed a generalized linear model for E[y|t, x, θ]. Therefore, it is not difficult to compute E0[y|t, x] by
 E[y|t, x, θ]dHθ (θ ), and we can alternate between drawing cluster memberships and covariates
from the approximate joint distribution p(z,X) to compute E[Y |t, x, θ ∗,ϕ∗,ω∗, z]. An MC integration is used to integrate z and X. The alternating process to estimate causal effects could be:
(1) draw M samples {xm, zm }, m = 1,..., M, then
(2) estimate the causal effects with Equation (14).
4.4 Imputation of Missing Covariates
Missing covariates can be addressed with the “missing at random” assumption. The values for the
missing covariates X are drawn from the approximate conditional posterior distribution, which is
estimated from the specified joint distribution of ((T,X,Y ) in each iteration for each Gibbs sample.
Suppose the rth covariate xi,r of subjecti is binary and is missing. The current value of the binomial
probability parameter for the rth covariate is denoted as ωr
i . Note that ωr
i depends on the cluster
assigned to subject i. X[k]
i denotes the variable represented as a value of the original vector Xi in
covariate Xi,r is set to a value of k. Xi,r is drawn from a binomial distribution with a probability
of F (Y |t,x[1]
i ,θi )ωr
i
F (Y |t,x[1]
i ,θi )ωr
i +F (Y |t,x[0]
i ,θi )(1−ωr
i )
.
The Metropolis-Hastings algorithm is used to perform the imputation of the missing continuous
covariates. Suppose xi,r is continuous and is missing; the values for the missing continuous covariates are drawn from the posterior distribution, which is proportional to F (xi,r |wi )F (Y |t, xi, θi ).
5 EXPERIMENTS
The experiments described in this section include simulations to evaluate various properties of the
CDP model and empirical studies with both synthetical and real-world data to assess the model’s
practical use as a causal effect estimator. The property analyses include: convergence (Section 5.1);
robustness to assumption violations (Section 5.2); the ability to cope with low propensity scores
(Section 5.3); the effect of covariate dimensionality (Section 5.4); and time complexity (Section 5.5).
We then move on to the ultimate goal: causal effect estimation, where we evaluate the performance
of the proposed model on synthetic data (in Section 5.6) and real-world data (in Section 5.7).
5.1 Convergence Evaluation
The MCMC inference algorithm presented in Section 4.2 is not tractable, which means its convergence needs to be evaluated. The details of data simulation follow:
Sim-1: Following Scenario 1 from Reference [57], we generated covariates from X1 ∼
Bern(0.2), X2 |X1 ∼ Bern(logit−1 (0.3 + 0.2X1)), X3 |X1,X2 ∼ N (X1 − X2, 12), X4 |X1,X2,
X3 ∼ N (1 + 0.5X1 + 0.2X2 − 0.3X3, 22) and treatments and outcomes fromT |X1,...,X4 ∼
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:18 A. Lin et al.
Fig. 3. The log likelihood of the data for post burn-in iterations of the Gibbs sampler. The value of burn-in
is 2K.
Bern(logit−1 (−0.4 + X1 + X2 + X3 − 0.4X4)) and Y |T,X1,...,X4 ∼ Bern(logit−1 (−0.5 +
0.78T − 0.5X1 − 0.3X2 + 0.5X3 − 0.5X4)).
In the experimental design and setting, (1) we generated 10 datasets, each containing n =
100 observations. (2) We ran a long chain with 10K samples, using the first 2K as burn-in in Algorithm 1. (3) We initialized the cluster membership as two y-clusters, two t-subclusters within
each y-cluster, and two x-subclusters within each t-subcluster. (4) We set aa0 = 1 and bb0 = 1
for the prior Gam(aa0,bb0) of the concentration parameters and we set M = 1K as the number of
samples drawn from the posterior predictive distribution of covariates X to estimate causal effects.
(5) To evaluate convergence, we used the data loglikelihood to represent the samples from one long
chain, because this statistic is highly dependent on all the latent variables. If the data loglikelihood
is convergent, then the other latent variables will also be convergent.
The results for Sim-1 are shown in Figure 3, where we can see that the loglikelihood converged
at around −425 with some surrounding weak fluctuations. From this result, we can conclude that
the inference algorithm converges well.
5.2 Violation Evaluation: Robustness
There are two assumptions in our proposed model: (1) We assume local generalized linear models
for outcome; and (2) The covariates within an x-cluster are locally independent. In this simulation,
we evaluated how the model performs when these assumptions are violated. The metrics used
were the absolute difference between the predicted effect and the real effect (Abias) and Empirical
Standard Deviation (ESD).
To evaluate the first assumption, we simulated the synthetic data as follows:
Sim-2: The covariatesX1,...,X4 were generated from a multivariate normal distribution with
a mean of 0, a variance of 1, and a covariance of 0.3. Treatments and outcomes were
then generated from: T |X ∼ Bern(logit−1 (0.3
4
j=1 Xj)), Y |T,X ∼ N (μpp, 1) in which μ =
2T − 0.5X2 − X3 + 0.5X4.
Note that when pp is 1, the outcome model is locally linear, but more non-linearity is introduced
as pp grows larger.
In the experimental design and setting, (1) we changed pp from 1 to 6 in steps of 1 to gradually violate the assumption of linearity and, for each value of pp, we generated 10 datasets containing n = 100 observations. (2) We ran a long chain with 10K samples, using the first 2K as
burn-in. (3) We initialized the cluster membership as two y-clusters, two t-subclusters within each
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:19
Table 2. Results from Simulation for Violation for Local
Generalized Linear Models for Outcome
Local generalized linearity
Method pp 1 2 3 4
CDP Abias 0.1254 0.4030 3.2234 14.0610
ESD 0.1666 0.5244 1.6202 10.2793
BART Abias 0.1402 0.6333 2.4406 15.5895
ESD 0.1899 0.8052 3.3756 20.3892
Abias is the absolute bias, and ESD is the empirical standard deviation. Our proposed method is CDP.
y-cluster, and two x-subclusters within each t-subcluster. (4) We set aa0 = 1 and bb0 = 1 for the
prior Gam(aa0,bb0) of the concentration parameters and we set M = 1K as the number of samples
drawn from the posterior predictive distribution of covariates X to estimate causal effects.
We also included a comparison in this experiment—Bayesian additive regression trees (BART).
The results are shown in Table 2. As expected, the performance of both methods dropped as pp
increased, but the CDP model generally performed better than BART. Note that CDP can be easily applied to situations with non-linear outcomes simply by changing the likelihood function of
outcome in Equation (6) to a non-linear one.
To evaluate the second assumption, we tested CDP using data generated from a mixture model
with dependent within-cluster covariates as follows:
Sim-3: Following Scenario 6 in Reference [57] with small revisions, we generated the
cluster membership from Gi ∼ Bern(0.3) and then four covariates as follows: if Gi =
1, then we generated Xi from a multivariate normal with a mean of (0.5,0.3,-
0.3,-0.5), a variance of 1, and correlation of ρ. If Gi = 0, then we generate Xi
from a multivariate normal with a mean of (−0.5,−0.3, 0.3, 0.5), a variance of
1, and correlation of ρ. The treatments and outcomes were generated from Ti ∼
Bern(logit−1 (0.3 × 4
j=1 Xij)), Yi ∼ N (I (Gi = 1)μi1 + I (Gi = 0)μi0, 22), where μi1 = −4 +
2Ti − 0.5Xi2 − Xi3 + 0.5Xi4 and μi0 = 4 + 0.4Ti + 0.5X2
i2 − 0.8(Xi3) · I (Xi3 > 0). The true
average causal effect is ψr d = 0.88.
Here, ρ controls the independent degrees between covariates in an x-cluster. A larger ρ tends to
lead to weaker independence.
In the experimental design and setting, (1) we changed ρ from 0.1 to 0.9 in steps of 0.2 and, for
each value of ρ, we generated 10 datasets of n = 100 observations. (2) We ran a long chain with 10K
samples, using the first 2K as burn-in. (3) We initialized the cluster membership as two y-clusters,
two t-subclusters within each y-cluster, and two x-subclusters within each t-subcluster. (4) We
set aa0 = 1 and bb0 = 1 for the prior Gam(aa0,bb0) of the concentration parameters and we set
M = 1K as the number of samples drawn from the posterior predictive distribution of covariates
X to estimate causal effects.
As shown in Figure 4, there were only slight fluctuations in Abias as ρ increased. Hence, the
CDP model provided a relatively robust performance in different covariate correlation situations.
5.3 Ability to Cope with Low Propensity Scores
The performance of causal inference models often suffers with data that have low propensity scores
[55]. Therefore, in this simulation, we evaluated performance with different propensity scores.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:20 A. Lin et al.
Fig. 4. Results are from simulated data for robustness evaluation of local independence of covariates within
clusters. The ordinate of a point represents the absolute bias, and the abscissa describes the value of
correlations.
Sim-4: We generated four covariates X1,...,X4 with a multivariate normal distribution,
a mean of 0, and covariance matrix of
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
1 0.3 0.3 0.3
0.310.3 0.3
0.3 0.310.3
0.3 0.3 0.3 1
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
. The treatments were
generated from an αx as T |X ∼ Bern(logit−1 (αx + 0.3
4
j=1 Xj)). The outcomes were generated from Y |T,X ∼ pN (μ1, 1) + (1 − p)N (μ2, 42), where p = exp(−2(X1+1)
2 )
exp(−2(X1+1)
2 )+exp(−2(X1−2)
2 )
,
μ1 = −4 + 2T − 0.5X2 − X3 + 0.5X4, and μ2 = 4 + 0.4T + 0.5X2
2 − 0.8X3 · I (X3 > 0). I (·) is
the indicator function. The true average causal effect of this simulation isψr d = 1.503 for
each setting of αx .
In the experimental design and setting, (1) We changed αx from −3 to −0.6 in steps of 0.3
and, for each value of αx , we generated 10 datasets of n = 1K observations. (2) As the values of
αx increased, the mean propensity scores increased from below 0.1 to 0.5. (3) We ran a long chain
with 10K samples, using the first 2K as burn-in. (4) We initialized the cluster membership as two
y-clusters, two t-subclusters within each y-cluster, and two x-subclusters within each t-subcluster.
(5) We set aa0 = 1 and bb0 = 1 for the priorGam(aa0,bb0) of the concentration parameters and we
set M = 1K as the number of samples drawn from the posterior predictive distribution of covariates
X to estimate causal effects.
The results for the nine different propensity scores compared to EDP are shown in Figure 5. As
the propensity scores increased, EDP’s performance increased significantly from −3 to −1.8. The
CDP model was relatively stable over all the scores with a slight fluctuation between 0.15 and 0.25.
Overall, the CDP model consistently performed better than EDP. From these results, we find that
CDP copes well with low propensity scores.
5.4 Evaluation with Varying Covariate Dimensions
Controlling for high-dimensional confounders with a regularized regression adjustment may result
in substantial bias [9]. Therefore, in this simulation, we tested the model’s sensitivity toward the
dimensionality of the covariates.
Sim-5: We generated p covariates X1,...,Xp with a multivariate normal distribution, a mean of
0, a covariance matrix with a variance of 1, and 0.3 correlations. The treatments were
generated from the distribution T |X ∼ Bern(logit−1 (0.3
p
j=1 Xj)) and the outcomes were
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:21
Fig. 5. Results are from simulated examples with propensity scores generated by different values of intercept.
The ordinate of a point represents the absolute bias, and the abscissa describes the value of intercept. CDP
is our proposed method.
Fig. 6. Results are from simulated data for evaluation on the effect from the dimension of covariates. The
ordinate of a point represents the absolute bias, and the abscissa describes the dimensions of covariates.
generated from Y |T,X ∼ N (μy, 1), where μy = 4 + 1.503T + p
j=1 Xj . The true average
causal effect is ψr d = 1.503 for each run.
In the experimental design and setting, (1) we changed p from 10 to 80 in steps of 10 and,
for each value of p, we generated 10 datasets containing n = 20 × p observations. (2) We ran a
long chain with 10K samples, using the first 2K as burn-in. (3) We initialized the cluster membership as two y-clusters, two t-subclusters within each y-cluster, and two x-subclusters within
each t-subcluster. (4) We set aa0 = 1 and bb0 = 1 for the prior Gam(aa0,bb0) of the concentration
parameters and we set M = 1K as the number of samples drawn from the posterior predictive
distribution of covariates X to estimate causal effects.
The results are shown in Figure 6. CPD showed relatively stable performance no matter the
number of dimensions, with a slight fluctuation between 0.4 and 0.5, whereas EDP’s performance
varied as the dimensions changed. This accords with our claim that CDP can cope with highdimension covariates if, like other models, the model is correctly specified.
5.5 Time Complexity Evaluation
The time complexity for our proposed model for each MCMC iteration is O(C · (
k
i=1
ki
j=1 kj |i +
m ·
k
i=1 ki ), where C is the constant. Using the simulated data from Sim-6 [48], we generated
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:22 A. Lin et al.
Fig. 7. Running time from simulated examples with different data scale. The ordinate of a point represents
the mean running time, and the abscissa describes the data scale. CDP is our proposed method.
covariates X with two distributions as follows: (a) XN ∼ N (0, ΣX ), where the (i, j)th entry of ΣX is
0.5|i−j |
; and (b) XU , whose components followed a uniform distribution on (−2, 2) with a correlation matrix ΣX . In addition, we generated two error distributions independent of the covariates: (a)
εN = 
εN,0,εN,1
 ∼ N (0, 0.25Σε ), where the (i, j)th entry of Σε is 0.5|i−j |
; and (b)εU = 
εU,0,εU,1

,
where εU,0 and εU,1 are uniformly distributed on (−0.5, 0.5) and have correlation matrix Σε . The
data were simulated as follows:
Sim-6: T ∼ Bern(logit−1 (0.1XU,5));Yt = XU,1 + XU,2 + XU,3 + t + εN,t .
In the experimental design and setting, (1) we changed the data scale from 100 to 1K and
generated 10 datasets for each data scale. (2) We ran a long chain with 10K samples on a computing
cluster with 3.1 GHz Intel Xeon E5-2687w v3 and 64 GB memory, using the first 2K as burn-in.
(3) The cluster membership was initialized as two y-clusters, two t-subclusters within each ycluster, and two x-subclusters within each t-subcluster. (4) We set aa0 = 1 and bb0 = 1 for the
prior Gam(aa0,bb0) of the concentration parameters and we set M = 1K as the number of samples
drawn from the posterior predictive distribution of covariates X to estimate causal effects.
The results are shown in Figure 7 with the mean running time for each data scale reported
as the time complexity. Generally, the running time had a linear relationship to the data scale,
with a slightly shorter running time for CDP than for EDP. In conjunction with Sim-4, we were
encouraged to find that the CDP copes well with low propensity scores without taking longer to
run.
5.6 Causal Effect Estimation with Synthetic Data
The fundamental goal of this research is to estimate causal effects. Hence, with the property evaluations complete, we can now turn to assessing the CDP model’s performance at its primary
purpose—causal inference.
Causal inference with binary outcomes was assessed in Sim-1. However, this evaluation did not
include missing covariates, so, following the same procedure as Sim-1, we randomly deleted values
of X based on the following probabilities: logit−1 (−2 + X2 + Y ); X2 missing with a probability of
logit−1 (−2 + X3 +T ); X3 missing with a probability of logit−1 (−1.5 −T + Y ); and X4 missing with
a probability of logit−1 (−0.9 − X1 − X2). About 20% of the covariates were missing values in each
simulation.
Then, to evaluate performance with continuous outcomes, we generated another three datasets
following the procedures outlined for Sim-7 to Sim-9 below.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:23
Table 3. The Comparative Methods
Method ID R package Reference Implementation
Inverse probability of treatment weighting IPTW [7] R
Targeted maximum likelihood estimationa TMLE TMLE & Super Learner [69] R (Accelerating with C++)
One-to-one matching Matching Matching [60] R
Generalized random forest GRF grf [6] R (Accelerating with C++)
XLearnerb XLearner causalToolbox [39] R (Accelerating with C++)
Approximate residual balancing BalanceHD balanceHD [5] R (Accelerating with C++)
Enriched Dirichlet process EDP [57] Matlab
Parametric Bayesian approachc Bayesian par. [23] R
Bayesian additive regression trees BART BART [12] R (Accelerating with C++)
aSince Super Learner is an ensemble machine learning method, we used six algorithms (mean, glm, step, gam, randomForest, and glmnet).
bWith honest random forests as the base algorithm to estimate causal effects with binary outcomes and BART as the base
algorithm to estimate causal effects with continuous outcomes.
cWe use the approach proposed in Reference [23] to fit Bayesian logistic regression models with the treatment and covariates included.
Sim-7: We generated covariates X1,...,X4 from a multivariate normal distribution with a
mean of 0, a variance of 1, and a covariance of 0.3. Treatments and outcomes were
generated fromT |X ∼ Bern( logit−1 (0.3
4
j=1 Xj)),Y |T,X ∼ pN (μ1, 1) + (1 − p)N (μ2, 42),
where p = exp(−2(X1+1)
2 )
exp(−2(X1+1)
2 )+exp(−2(X1−2)
2 )
, in which μ1 = −4 + 2T − 0.5X2 − X3 + 0.5X4, and
μ2 = 4 + 0.4T + 0.5X2
2 − 0.8X3 · I (X3 > 0), where I (·) is an indicator function whose true
value is 1. The true average causal effect is ψr d = 1.503.
Sim-8: Follows Scenario 5 from Reference [57]. The treatments, covariates, and outcomes were generated from hidden variables; i.e., Z1,...,Z4 ∼ N (0, 1). Treatments
and outcomes were generated from T ∼ Bern(logit−1 (−Z1 + 0.5Z2 − 0.25Z3 − 0.1Z4))
and Y ∼ N (210 + 27.4Z1 + 13.7Z2 +13.7Z3 + 13.7Z4, 1). The covariates X were generated from:X1 = exp (Z1/2),X2 = Z2/ (1 + exp (Z1)) + 10,X3 = (Z1Z3/25 + 0.6)
3
, andX4 =
(Z2 + Z4 + 20)
2
. The true average causal effect is ψr d = 0.
Sim-9: Here, the simulation settings were similar to Sim-7 except with a different process
for generating the treatments, which were binary and generated from the distribution
T |X ∼ Bern(logit−1 (−3 + 0.3
4
j=1 Xj)). The true average causal effect is ψr d = 1.503.
In the experimental design and setting, (1) we generated 10 datasets for each simulation,
where each dataset contained n = 100 observations. (2) We ran a long chain with 10K samples,
using the first 2K as burn-in. (3) The cluster membership was initialized as two y-clusters, two tsubclusters within each y-cluster, and two x-subclusters within each t-subcluster. (4) We set aa0 =
1 and bb0 = 1 for the prior Gam(aa0,bb0) of the concentration parameters and we set M = 1K as
the number of samples drawn from the posterior predictive distribution of covariates X to estimate
causal effects.
The comparative methods, implementation details, and publication references are listed in Table 3. Note that the only aim of Bayesian par. is to handle data with binary outcomes, and the
only aim of BART is to handle data with continuous outcomes. The propensity scores for IPTW
and TMLE were estimated with a logistic model on the assumption of a linear additive form of
covariates X. Since the real causal effects are directly obtainable with this synthetic data, i.e., the
average causal relative risk isψr r = 1.5 and the average causal effect isψr d = 0.13, we can compare
the different methods by: evaluating the distance between the estimated causal effect and the real
effect (Abias), and by the ESD.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:24 A. Lin et al.
Table 4. Results from Simulated Data Sim-1: Binary Outcome
Binary outcome
ψr r ψr d
Method Abias ESD Abias ESD
IPTW 0.7764 1.2479 0.2240 0.4761
TMLE 0.5872 0.9907 0.1138 0.1679
Bayesian par. 0.3532 0.4901 0.0803 0.1082
Matching - - 0.1212 0.1683
GRF - - 0.0768 0.1068
XLearner - - 0.0647 0.0955
BalanceHD - - 0.0729 0.1156
EDP 0.3440 0.4123 0.0853 0.7996
EDP missing data 0.3977 0.6091 0.0871 0.1232
CDP 0.2966 0.3879 0.0743 0.0957
CDP missing data 0.3233 0.4700 0.0727 0.1000
The true causal parameters are average causal relative risk ψr r = 1.5 and average
causal effect ψr d = 0.13. Abias is the absolute bias, and ESD is the empirical standard
deviation. Our proposed method is CDP and “CDP missing data” denotes our proposed
method for missing covariates using imputation. “-” in the table represents unavailable.
Table 5. Results from Simulated Data Sim-7 to Sim-9: Continuous Outcome
Continuous outcome
Simulation Method IPTW TMLE BART Matching GRF XLearner BalanceHD EDP CDP
Sim- 7 Abias 0.6722 0.5411 0.4364 0.7316 0.4658 0.4592 0.5122 0.5766 0.4477
ESD 0.8830 0.7382 0.6253 0.9514 0.6216 0.6400 0.6991 0.7996 0.6097
Running time 1 s 3 s 5 s 1 s 2 s 14 s 2 s 160 s 170 s
Sim-8 Abias 39.8174 5.3326 3.1129 5.8313 7.8709 6.1402 6.7417 6.7650 3.1421
ESD 71.7136 1.2340 1.6316 4.5662 3.3954 3.6299 2.1041 1.5357 1.6528
Running time 1 s 3 s 5 s 1 s 2 s 13 s 2 s 150 s 170 s
Sim- 9 Abias 1.1853 0.6900 0.8268 1.2315 0.9743 1.2967 1.4458 0.8329 0.6952
ESD 1.5471 0.7730 1.0014 1.8057 1.3550 1.4417 2.0687 1.5250 0.9521
Running time 1 s 3 s 6 s 1 s 2 s 13 s 2 s 150 s 160 s
Abias is the absolute bias, and ESD is the empirical standard deviation. Running time of methods is described with seconds.
Our proposed method is CDP.
The results for Sim-1: binary outcomes are presented in Table 4. Here, we see that the Bayesian
methods generally achieved better performance than other methods. Of these, the Bayesian nonparametric methods, i.e., EDP and CDP, were better than Bayesian par. CDP had the least Abias in
ψr r both with and without missing data. In fact, only EDP and CDP were able to handle missing
data, and CDP produced consistently better results than EDP. CDP’s results for average causal effect were comparable to the state-of-the-art models, XLearner and BalanceHD. With the exception
of XLearner, the ESDs ψr d for our approach were the smallest.
The results for Sim-7 to Sim-9 (continuous outcomes) are provided in Table 5. In summary,
BART had the lowest bias in two cases. The CDP model had a relatively small bias compared to
BART, and both BART and CDP had small ESDs. TMLE and CDP were the best performers in
Sim-9, and CDP was generally the best performer overall. Notably, IPTW and TMLE had small
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
Causal Dirichlet Mixture Model 33:25
Table 6. Dehejia—Wahha Sample
Variable age education nodegree married Black Hispanic RE74 RE75 RE78
Treated
(185)
Mean 25.8 10.3 0.71 0.19 0.84 0.06 2.10 1.53 6.35
ESD 7.2 2.0 0.46 0.39 0.36 0.24 4.89 3.22 7.87
Control
(260)
Mean 25.1 10.1 0.83 0.15 0.83 0.11 2.11 1.27 4.55
ESD 7.1 1.6 0.37 0.36 0.38 0.31 5.69 3.10 5.48
Earnings data (RE74, RE75, and RE78) is in thousands of dollars.
Table 7. Results from NSW Data Files (Dehejia-Wahha Sample)
Job training program
Method IPTW TMLE BART Matching GRF XLearner BalanceHD EDP CDP
Abias 180.8653 160.1432 152.9996 294.1352 198.5165 250.1644 159.9682 107.3616 117.6645
ESD - 10.9392 15.4099 - 35.6889 - - 15.2367 0.0140
Running time <1 min <1 min <1 min <1 min <1 min <1 min <1 min ≈10 min ≈10 min
The causal effect for the sample is estimated about 1,794. Abias is the absolute bias, and ESD is the empirical standard
deviation. Running time of programs is described with minutes roughly. Our proposed method is CDP. “-” in the table
represents unavailable.
bias largely because they estimate the propensity scores using the same functional form as logistic
regression and used the same confounders.
5.7 Causal Effect Estimation with Real-world Data
To evaluate the CDP model’s practical advantages, we tested the model with an inference task
to estimate the effects of an employee job training program on earnings. We used the dataset
from Dehejia and Wahba [14], which is a subset of Lalonde’s NSW experimental data [40], and
includes 445 observations with 185 treated subjects and 260 control subjects. There is one treatment
indicator—1 if treated, 0 if not; four continuous covariates—age, education, RE74 (earnings in 1974),
and RE75 (earnings in 1975); four discrete covariates—Black (1 if black, 0 otherwise), Hispanic (1 if
Hispanic, 0 otherwise), married (1 if married, 0 otherwise), no degree (1 if no degree, 0 otherwise);
and one outcome variable—RE78 (earnings in 1978)). Table 6 presents the mean values for the
treated group and the control group from our analysis [1]. The causal effect for the sample was
estimated at about 1,794.
In the experimental setting, (1) we ran a long chain with 10K samples, using the first 2K as
burn-in. (2) We initialized the cluster membership as two y-clusters, two t-subclusters within each
y-cluster, and two x-subclusters within each t-subcluster. (3) We set aa0 = 1 and bb0 = 1 for the
prior Gam(aa0,bb0) of the concentration parameters and we set M = 1K as the number of samples
drawn from the posterior predictive distribution of covariates X to estimate causal effects.
The results are presented in Table 7. The CDP model had the smallest bias and competitive
performance compared to the other methods, plus a low ESD. These results show that our proposed
method is effective with potentially useful applications in causal inference.
6 CONCLUSION AND FURTHER STUDY
In this study, we proposed a novel Causal Dirichlet process to capture the complex relationship
between covariates, treatments, and outcomes in observational data. We developed a new Causal
DP-based Bayesian nonparametric generative model for causal inference without any assumption of parametric distributions. Additionally, we designed a Gibbs sampling inference algorithm
specifically for model inference. These tools allow an approximation of the joint distribution of
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 3, Article 33. Publication date: April 2020.
33:26 A. Lin et al.
covariates, treatments, and outcomes has been obtained, which, in turn, provides a method for estimating various kinds of causal effects. Experiments on synthetic datasets demonstrate the superior
ability of the proposed model to capture complex relationships compared to several state-of-theart methods, including enriched DP, targeted maximum likelihood estimation, Bayesian additive
regression trees, the X-learner, and approximate residual balancing. We find that our model is a
more reasonable approach to causal inference, as it based on propensity scores. Our experimental
results support this finding, showing better performance than enriched DP on observational data
with subjects that have low propensity scores. Experiments on a real-world task, i.e., a job training
program, also show the effectiveness and usefulness of the proposed model for causal inference.
An interesting follow-up study would be to combine the proposed model with a deep neural
network to further enhance its ability to capture complex unknown relationships between covariates, treatments, and outcomes in observational data. Another direction would be to adopt
the cutting-edge technique stochastic gradient MCMC [2]. This would improve the efficiency of
model inference with big data. Also, our model could be extended to time-varied situations, i.e.,
estimating the causal effects of treatments that vary over time. It would not be difficult to generate
draws from time-varied confounders, because CDP is a relatively simple model for estimating joint
distributions. Other research for future work is to refine CDP for causal inference in more realworld applications, such as estimating the treatment effect of a medicine with a specific disease,
the effect of a particular policy on an economic market, or effect of education on personal income.
Applying this model to such tasks would help decision-makers make better decisions.