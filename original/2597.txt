For real-world learning tasks (e.g., classification), graph-based models are commonly used to fuse the information distributed in diverse data sources, which can be heterogeneous, redundant, and incomplete. These
models represent the relations in different datasets as pairwise links. However, these links cannot deal with
high-order relations which connect multiple objects (e.g., in public health datasets, more than two patient
groups admitted by the same hospital in 2014). In this article, we propose a visual analytics approach for
the classification on heterogeneous datasets using the hypergraph model. The hypergraph is an extension
to traditional graphs in which a hyperedge connects multiple vertices instead of just two. We model various
high-order relations in heterogeneous datasets as hyperedges and fuse different datasets with a unified hypergraph structure. We use the hypergraph learning algorithm for predicting missing labels in the datasets.
To allow users to inject their domain knowledge into the model-learning process, we augment the traditional
learning algorithm in a number of ways. In addition, we also propose a set of visualizations which enable the
user to construct the hypergraph structure and the parameters of the learning model interactively during the
analysis. We demonstrate the capability of our approach via two real-world cases.
CCS Concepts: • Human-centered computing → Visual analytics;
Additional Key Words and Phrases: Hypergraph learning, data fusion, high-dimensional data
1 INTRODUCTION
Real-world learning tasks typically utilize information that is distributed across many disparate
data sources. These data are often heterogeneous and contain different types of objects and various relations. Fusing these “real-world data” is frequently implemented via a graph structure [16]
where an edge represents the pairwise relation of two objects in different datasets.Fig. 1. (a) An example of predicting hospital readmission level with five heterogeneous tables. The readmission table is partially labeled as shown in the last column. Traditional graph-based methods use pairwise
links to model pairwise relations among the tables. (b) In a hypergraph model, the hyperedges are able to
encode higher-order relationships.
One application, in which these types of heterogeneous data typically occur, is hospital readmission prediction in public health. Readmission is the event when a patient checks back into a
hospital within 30 days after discharge. Readmissions put a significant cost burden on the health
care system (and cause stress for the patients), and therefore should be prevented [17]. We have
been collaborating with a researcher in public health whose job is to predict readmission levels for
specific target hospitals and patient groups. Here prediction can be considered as a classification
problem where the readmission levels are the labels. The basis of this task is a set of disparate
data tables related to readmission, encompassing factors like hospital ratings and past hospital
readmissions (see the tables in Figure 1(a)). Via existing tools, he fuses these tables by connecting
related objects (e.g., hospitals and patients) with the edges of a graph (see Figure 1(a)). Using the
labeled nodes in the graph, classifying other unlabeled nodes can then be done using link mining
methods [16]. For example, he can infer the readmission level of a specific patient group from the
labeled readmission instances.
A shortcoming of the traditional graph model is that it has difficulties in dealing with higherorder relations. For example, in Figure 1(a), patient groups G1, G2 and G5 were all admitted by
Hospital #1 in 2014. Such co-occurrences of multiple objects, however, cannot be easily viewed
from the pairwise edges (red links in Figure 1(a)). This makes it difficult to efficiently recognize
these type of joint relationships, especially at scale. Conversely, the hypergraph is able to represent
these types of high-order relations. It is an extension to the ordinary graph, where a hyperedge can
connect multiple vertices, and not just two. Figure 1(b) shows an example, where vertices G1, G2,
and G5 are contained in the hyperedge “H osp.#1,” but at the same time, they are also included in
the hyperedge “2014.” As a result, they become a part of the intersection of these two hyperedges,
which conveys a possibly interesting relationship.
A crucial property of hyperedges is that they are defined based on the semantic meaning of the
specific relation. For example, the hyperedge “2014” contains objects from both the patient and
the readmission tables (purple and brown nodes in Figure 1(b), respectively). This makes them a
natural representation for disparate heterogeneous data.
Our primary goal is to use the hypergraph to classify heterogeneous data given a partially labeling of it, such as “Readmission level” in the readmission table in Figure 1(a). Existing hypergraph learning methods [5, 15, 25] pre-define the structure of the hypergraph and the parameters
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:3
(e.g., the weights of the hyperedges). However, the construction process of a unified hypergraph
principally is a design task and needs to be done manually during the analysis process. The user
has to test different data sources for a proper hypergraph structure in a specific application. For
example, a census dataset may not work for predicting the unknown readmission levels because
it describes all the residents instead of only the patients. Furthermore, these users, who could be
experienced domain experts, cannot lower or elevate the influences of certain factors by tuning
their weights onto the model and its predictions, although this might be appropriate. In contrast,
we have developed a visual analytics approach that enables such interactions. It allows a domain
expert to assist the hypergraph learning process by applying his or her domain knowledge and
intuition. In this way, a more realistic actionable model can be derived.
In our method, first a hypergraph structure for the heterogeneous data is constructed visually
using a set of interactions defined on the hypergraph’s incidence matrix. The hypergraph structure
is then used for our improved hypergraph learning algorithm, which allows the user to adjust
the parameters, such as hyperedge weights, during the learning process. After each run of the
algorithm, the inspection, exploration, and validation of the learning results is enabled using a
force-directed hypergraph visualization. Based on the feedback of the exploration, the user can go
back to the previous steps to update the hypergraph structure or hyperedge weights, and examine
the effects of the changes on the results.
The main contributions of this article include:
• We propose an improved hypergraph learning algorithm for heterogeneous data, which
allows user input of domain knowledge.
• We propose a set of interactions based on an incidence matrix visualization, which enables
the construction of a unified hypergraph structure on heterogeneous data.
• We extend the concept of force-directed visualization to hypergraphs, which enables the
interactive verification, validation, and exploration of hypergraph learning results.
The remainder of this article is structured as follows. Section 2 reviews related work. Section 3
defines the problem and gives an overview of our approach. Section 4 introduces our improved
hypergraph learning algorithm. Section 5, 6, and 7 describe our visual analytics approach for construction of the learning model, modulation of the learning process, and exploration of the learning
results, respectively. Two real-world cases are used to validate our approach in Section 8. Section 9
ends with conclusions and future work.
2 RELATED WORK
A graph structure (e.g., Resource Description Framework [8]) is commonly used to model pairwise relations among different objects in heterogeneous datasets. Various algorithms have utilized
graph models for link mining tasks [16]. For example, link-based classification [28] improves the
classification accuracy by modeling the link distributions. On the other hand, a number of visualization methods have also been proposed to help the analysis of graph models on heterogeneous
data, such as creating and designing visual representations [7, 27], searching heterogeneous networks [22], and evaluating hypotheses [2], and exploring multi-attribute data [9, 10, 11, 29, 41, 43].
However, as mentioned in Section 1, pairwise edges in a graph are unfit for high-order relations.
Using ordinary graphs to model these relations can lead to unexpected information loss [44].
2.1 Hypergraph Learning on Heterogeneous Data
A hypergraph extends the ordinary graph to formulate complete high-order relations. An edge in
a hypergraph can connect multiple vertices, called hyperedges (Figure 1(b)), as discussed. Existing
hypergraph learning approaches [19, 20, 44] use the hyperedges to model the relations within
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:4 C. Xie et al.
a table. For example, the bag-of-words model can be represented as a hypergraph in which a
document is a hyperedge containing multiple words [38]. For heterogeneous data, hyperedges
can be employed to connect related objects from different datasets, such as audiences and music
tracks [5], readers and news [25], images and textual tags [15]. Most of these existing methods,
however, pre-define the hypergraph structures according to their specific scenarios. They do
not provide users with the means to modify the structure during the analysis (e.g., removing
a biased dataset from the hypergraph). In addition, the parameters of the model are typically
also pre-defined (e.g., hyperedge weights) in the hypergraph learning algorithms. However, as
mentioned earlier, it is beneficial to endow the user with the ability to update the weights of the
learning model during the analysis. Therefore, to deal with these two shortcomings, we improve
the hypergraph learning algorithm [44] such that it accepts domain knowledge from the user. We
embed the algorithm into a visual analytics framework that allows the interactive modulation of
the hypergraph structure and parameters during the analysis process.
2.2 Hypergraph and Set Visualization
Visual exploration of the structure and the learning results of the hypergraph model can render
useful insights for the analyst. Existing set visualization techniques [1, 40] can be used since a
hyperedge can be viewed as a set of vertices. In this article, we adopt two common types of set
visualizations: matrix-based and contour-based methods.
Matrix-based visualizations allow the user to easily get an overview of either the inclusions
of elements in the set [23, 35], or the intersections of two sets [24]. Usually, those relations are
encoded by the visual properties of cells in a matrix, such as color.
Contour-based visualizations can be more intuitive to encode the containment and the intersection relationships of multiple sets. Generally, the nodes inside a contour represent the membership of elements in a set, such as in Euler and Venn diagrams [37]. Some of these approaches
(e.g., Bubble Sets [13], KelpFusion [31], and Data Context Map [12]) generate contours based on a
pre-determined node layout. Other methods adopt existing layout algorithms (e.g., force-directed
layout in Vizster [18]) to calculate the node positions.
Other types of set visualizations have been proposed, such as the Parallel Sets plot [3]. Most
of these existing visualizations focus on the visual representation of the set data (e.g., encoding
or layout), while a few of them exploit a set structure visualization to enhance learning tasks,
such as classification. In this work, we integrate the set visualization approaches with the hypergraph learning model, which allows the visual analysis of the classification using the hypergraph
structure.
3 PROBLEM DEFINITION AND APPROACH OVERVIEW
This article aims to address the classification problem [45] on a set of heterogeneous tables {V }.
We use the data in Figure 1 as an example. Given a part of the readmissions labeled as “High”
(y(v) = +1) or “Low” (y(v) = −1) (see the last column in the readmission table in Figure 1(a)), the
user wants to predict the readmission levels f of all unlabeled instances, including the unlabeled
hospitals, unlabeled patient groups, and the unknown labels in the readmission table (e.g., the
readmission levels in rows 3 and 5 in Figure 1(a)). We will use this example in our article to illustrate
our approach.
The classification problem is defined as follows: suppose Vi = {v(i)
1 ,v(i)
2 ,...} is the instance set
of table Vi and V = V1 ∪V2 ∪··· is the set of all instances; given a partial labeling y of V, assign
labeling f to the rest of the unlabeled instances in V. For binary classification, the vertex label
y(v) is +1, −1, and 0 for positive label, negative label, and unlabeled instance, respectively. The
notations used in this paper are summarized in Table 1.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:5
Table 1. Notations Used in Our Article
Notation Description
G = (V, E,u,w) The unified hypergraph G.
v A vertex in G, which is also an instance in a table.
V = {v1,v2,...,v|V|} Vertex set of G.
Vi Instance set of the ith table.
e A hyperedge in G, which is also a level of a categorical variable.
E = {e1, e2,..., e |E|} Hyperedge set of G.
E A categorical variable in a table.
u(v) The weight of vertex v.
U ∈ R|V |×|V | The diagonal matrix form of u.
w(e) The weight of hyperedge e.
W ∈ R|E |×|E | The diagonal matrix form of w.
d(v) The degree of the vertex v.
Dv ∈ R|V |×|V | The diagonal matrix of d.
δ (e) The degree of the hyperedge e.
De ∈ R|V |×|V | The diagonal matrix form of δ.
H ∈ R|V |×|E | The incidence matrix representation of G.
y = [y0,y1,...,y|V|]
T The given partial labeling vector of V.
f = [f0, f1,..., f|V|]
T The labeling vector of V to be learned.
wd (e) The prior weight of hyperedge e which is set by the user.
Fig. 2. Conceptual overview of our approach for classification on (a) heterogeneous data. The user is able to
(b) construct, (c) modulate, and (d) validate the hypergraph model with visual interactions. The user can go
back to the previous steps in this iterative process.
The classification of the heterogeneous data is accomplished by our visual analytics approach
with the following steps (see Figure 2):
Step 1 Visual construction of the unified hypergraph model: The user can select tables
of interest and present them in an initial incidence matrix visualization. He or she can then link,
merge, include, and exclude the tables interactively within the matrix visualization to construct
the hypergraph structure.
Step 2 Visual modulation of the learning process: With the constructed hypergraph in
hand, our improved hypergraph learning algorithm is engaged to classify the unlabeled instances
in the tables. The user is allowed to change the parameters (e.g., weights of hyperedges) interactively to update the learning results.
Step 3 Visual exploration and validation of the learning results: The user can select a
subset of the interesting hyperedges from the matrix visualization. Then the structure and the
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:6 C. Xie et al.
Fig. 3. The process of unifying all of the tables in Figure 1 with a hypergraph model. (a) The incidence
matrices H1 - H5 are generated from the tables in Figure 1. The empty cells in the matrices represent zeros.
By linking the variables and combining datasets, (b) a unified incidence matrix H can be constructed, which
is the matrix form of the hypergraph G. (c) H can be represented as a matrix of sub-matrices, the orange
and gray cells represent nonzero and zero sub-matrices, respectively. (d) Hypergraph G can be regarded as
a collection of sets, in which each hyperedge is a set of vertices.
learned labels of the hyperedge subset are shown in a force-directed hypergraph visualization for
exploration and validation.
For each step, the user can return to the previous steps to change the structure or parameters
of the hypergraph model until satisfying results are achieved (Figure 2).
4 HYPERGRAPH LEARNING
In this section, we first describe the definition of a hypergraph (Section 4.1) and the traditional hypergraph learning algorithm (Section 4.2), then introduce our improved algorithm for classification
on heterogeneous tables (Section 4.3).
4.1 Formulation of Weighted Hypergraph
A hypergraph G = (V, E,u,w) is a generalization of a graph (Figure 3(d)). In detail, V is the set of
vertices and E is the set of hyperedges in G. While a regular graph edge is a pair of nodes, a hyperedge e ∈ E connects a set of vertices {v}⊆V. w represents the vector of weights of hyperedges
E. Different from the traditional hypergraph model [38, 44], we also add the weights u for the
vertices V. The motivation and the benefits are explained in Section 4.3 and Section 8.3.3. In another perspective, G can also be represented as a vertex-hyperedge incidence matrix H ∈ R|V |×|E |,
whose entry h(v, e) is 1 if v ∈ e and 0 otherwise (Figure 3(b)). Similar to the definition of the vertex
degree in an ordinary graph, the hyperedge degree δ (e) and the vertex degree d(v) is defined in
Equation (1). Additionally, the diagonal matrix form for w, u, δ, and d are denoted as W , U, De ,
and Dv, respectively, which are used in the hypergraph learning algorithm in Section 4.3.
δ (e) =

v ∈V
u(v)h(v, e) and d(v) =

e ∈E
w(e)h(v, e) (1)
Now that we have the definition of a hypergraph, given the categorical tables, a hypergraph can
be built for each table by treating it as set data [44] (Figure 3 (a)). Specifically, let E be a categorical
variable (e.g, “Location”), each of the possible values e ∈ E is a level, such as “Brooklyn.” Then the
levels {e} and the instances {v} in the table are modeled as hyperedges and vertices, respectively.
For example, a hospital vl is a vertex and ek = “Brooklyn” is a hyperedge. If the E value of v is e
(e.g., the ”Location” of hospital vl is Brooklyn ek in Figure 3 (a)), then v ∈ e and h(v, e) = 1 in the
incident matrix. In this way, a hypergraph and its incidence matrix can be constructed for each
table, as shown in Figure 3 (a).
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.  
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:7
For different tables {Vi}, a unified hypergraph G can be constructed (Figure 3 (b)) by linking
the variables in different datasets (Section 5.2.2) and combining the datasets (Section 5.2.3). The
vertex set V and the hyperedges set E of G are the union of all instances V = V1 ∪V2 ∪ ..., and
all variables E = E1 ∪ E2 ∪ ..., respectively. Next, the constructed G can be used as the model for
hypergraph learning.
4.2 Traditional Hypergraph Learning Framework
The hypergraph learning framework of Zhou et al. [44] calculates the labels f of the vertices V
by minimizing the loss function in Equation (2).
f ∗ = arg minf
Ω(f ) + μRemp (f ) (2)
The first term Ω in the loss function is defined in Equation (3). It aims to assign similar labels
f (v) to vertices vi and vj which are contained in many common hyperedges {e}. For example, if
two patient groups are in the same age group and the same disease category, they may have the
same readmission level (e.g., high readmission f (v) = +1). Hyperedges with high weights w(e) in
Equation (3) will dominate the label assignment. In our case, those hyperedges can be regarded as
important factors of readmission.
Ω(f, w) = 1
2

|V|
i,j=1

e ∈E
1
δ (e)

vi,vj ∈e
w(e)u(vi )u(vj)






f (vi )

d(vi )
− f (vj)

d(vj)






2
(3)
The second component Remp (f ) in Equation (2) is defined in Equation (4). It measures the difference between the learned labels f and the pre-given labels y (see the last column y in Figure 3
(b)). The parameter μ in Equation (2) controls the relative importance of Ω and Remp.
Remp (f ) =

|V|
i=1
u(vi )
f (vi ) − y(vi )

2 = (f − y)
T U (f − y) (4)
The traditional method [44] does not define the vertex weightu(v), which is equivalent to setting
all u(v) to 1 in Equation (3) and Equation (4). The hyperedge weight w(e) is usually assigned
manually according to a specific case before the optimization process of Equation (2).
4.3 An Improved Hypergraph Learning Algorithm
To integrate the expert-provided knowledge into the analysis process, we augment the traditional hypergraph learning algorithm by allowing the user’s initialization and modification of the
weights.
In our problem, instances are aggregated in some of the tables. For example, the first patient
group has 24 patients while the second patient group only contains 1 person (see patient group
table in Figure 1(a)). Using uniform vertex weights will reduce the influences of the aggregated
instances on the learning results. A reasonable solution is to set the weight of a vertex to its aggregation size.
For the hyperedge weights w, pre-defined values are not sufficient since the user will wish to
modify the weights according to some domain knowledge or feedback obtained from the learning
results. We integrate the learning algorithm with the prior knowledge wd provided by the user via
adding an additional term Ψ(w) to Equation (2). Ψ(w) is defined in Equation (5).
Ψ(w) =

e ∈E
w(e) − wd (e)2 (5)
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.                       
4:8 C. Xie et al.
The augmented optimization is shown in Equation (6), where ρ sets the importance of Ψ(w). In
this way, injecting domain knowledge is enabled by changing the prior wd during the analysis. For
example, the user can set wd (e) = 0 for all of the edges e (e.g., “Brooklyn”) in “Location” E, if she
or he knows that “Location” is not related to readmission. The reason that the user is prevented
from setting w directly is that w needs to satisfy the vertex degree constraint in Equation (6).
(f, w) = arд min
f,w Ω(f, w) + μRemp (f ) + ρΨ(w)
s.t. d(v) =

e ∈E
w(e)h(v, e) (6)
In Equation (6), it is difficult to optimize f and w at the same time since Ω may not be convex in
(f, w). However, we find that if f and w are optimized independently, the local optimal solution
of (f,w) can still be derived. We propose a two-step iterative method that alternatively finds the
optimal f and w in Equation (6) as follows:
For the ith iteration in our method, we first fix w = w(i−1) in Equation (6). Because Ψ(w(i−1)
) is
a constant, we can get f (i) using Equation (7). Because Ω ≥ 0 and Remp ≥ 0, the minimum value
of Ω + μRemp exists.
f (i) = arg minf
Ω(f, w = w(i−1)
) + μRemp (f ) (7)
It can be proved1 that Ω(f ) can be written in the form: Ω(f ) = f T Δf, in which Δ = U −
U Dv− 1
2 HW De
−1HT Dv− 1
2U. The optimal f (i) of Equation (7) can be found by solving the system of linear equations in Equation (8).
∂(Ω+μRemp )
∂f



f =f (i) = 0
⇒2Δf (i) + 2μU (f (i) − y) = 0
⇒(Δ + μU )f (i) = μUy (8)
In the second step, f is fixed to f (i)
, then Ω(f = f (i)
, w) is a linear function of w and Remp (f ) is
a constant. The optimal w(i) is derived by solving the quadratic programming problem in Equation (9).
w(i) = arg minw Ω(f = f (i)
, w) + ρΨ(w)
s.t. d(v) =

e ∈E
w(e)h(v, e) (9)
The above two steps are repeated until the loss function Ω + μRemp + ρΨ in Equation (6) converges, as shown in Algorithm 1. For the learning results, a vertex v is labeled as positive if
f (v) > 0, otherwise negative. The user can always change the prior wd (Section 6) and run the
algorithm for an updated f.
For multi-class classification, let us suppose there are c classes. Vector f and y can be replaced
with labeling matrices F = [f1, f2,..., fc ] and Y = [y1, y2,..., yc ]. yj (v) = 1 indicates v is labeled as the jth class. Ω(f, w) and Remp (f ) in the learning algorithm is replaced by c
j=1 Ω(f j ,w)
and c
j Remp (f j), respectively. Then v are predicted as the jth class if fj (v) is the largest in
[f1 (v), f2 (v),..., fc (v)].
1The proofs are provided in the supplementary file.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.      
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:9
ALGORITHM 1: Iterative Hypergraph Learning with Prior Weights
Input: w(0) = [1, 1,..., 1]T , f (0) = y(0)
, i = 0, wd , ϵ
1: do
2: i = i + 1
3: Solve f (i) by fixing w = w(i−1) according Equation (8).
4: Optimize w(i) by fixing f = f (i) according to Equation (9).
5: while (The loss function value in Equation (6) changes less than ϵ)
5 VISUAL CONSTRUCTION OF THE HYPERGRAPH MODEL
The first step of our visual analysis is to build a unified hypergraph G which fuses the heterogeneous tables. This is done by constructing the incidence matrix H ofG (Figure 3(b)). As mentioned
in Section 1, testing different hypergraph structures during the analysis is necessary to achieve the
best classification performance. To allow this process, we visualize the incidence matrix H (Section 5.1) in our approach. Along with the visualization, several interactions for initializing and
modifying the hypergraph structure are provided (Section 5.2). The capability of changing hyperedge weights during the analysis can also be incorporated in this visualization (Section 6).
5.1 Hierarchical Incidence Matrix Visualization
It is natural to present the incidence matrix H using a matrix-based visualization [24, 35]. As shown
in Figure 3(b), each row represents an instance v and each column is a level e. The color of each
cell is used to encode h(v, e): a cell is filled with orange if h(v, e) = 1; otherwise, it is gray.
It is challenging to display a matrix with large numbers of rows or columns due to finite screen
space. We therefore combine the rows {v} from the same table into one row V , and aggregate all
levels {e} of a variable in one column E (Figure 3(c)). In the aggregated matrix, each cell represents
a sub-matrix. The color of an aggregated cell is set to gray if it is a zero matrix, otherwise it is filled
with orange. For an aggregated column, the user can expand it to check its level set {e} (see “Nurse
Rating,” “Pain Management,” and “C are Rating” in Figure 4(d)). To show its difference from an
original column, an aggregated column is slightly wider and darker. The user still has the option
to view the columns without aggregation.
5.2 Visual Construction of the Incidence Matrix
With our matrix visualization, we define four operations on H to interactively fuse the subincidence matrices of disparate tables into a unified matrix: inclusion, linking, merging, and
exclusion.
5.2.1 Inclusion of Variables and Tables. At the beginning of the construction, the user can select
a set of interesting tables V = {V } and their variables E = {E} to be included in the initial incidence
matrix H. Figure 4(a) shows that several disconnected tables (V1, V2,...) and their variables (E1,
E2,...) are included in the initial H. An aggregated row and an aggregated column in H represent
a table V and a variable E, respectively.
5.2.2 Linking Variables in Different Tables. Two different tables may have a shared variable. For
example, hospital ID occurs in the hospital and readmission tables. The common variable in the
two tables can be connected using the linking operation.
Linking two variables Ek and El is performed by first combining their levels. Then the same
levels of e (k)
i ∈ Ek and e (l)
i ∈ El are combined into one column ej . For example, both column e (1)
1
and e (2)
1 are “H osp.#1” in the readmission and hospital tables (H1 and H2 in Figure 3(a)), so they are
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:10 C. Xie et al.
Fig. 4. (a) The initial incidence matrix visualization contains multiple disparate tables. An aggregated column
and an aggregated row are a variable and a table, respectively. The orange cells mark the tables that contain
the variables. Linking two variables can be done by dragging a column into another (purple lines). (b) The
merging operation is performed by dragging a row into another (blue line). (c) The final matrix after the linking and merging operations. (d) The bar charts above the columns show the learned weights w and the prior
weights wd . The columns of the matrix are reordered according to w of the variables. The user expands the
aggregated columns of “Nurse Rating,” “Pain Management,” and “Care Rating” to view their levels. (e) The
construction operations such as linking and merging are also supported in the dataset view.
combined into e1 in H in Figure 3(b). Then, in the second step, we assign vertices {v} to each combined edge ej by setting h(v, ej) in H. h(v, ej) is set to 1 if h(v, e (k)
i ) = 1 or h(v, e (l)
i ) = 1; otherwise,
h(v, ej) = 0.
The user can perform a linking operation by dragging the aggregated column El into Ek (see
the purple lines in Figure 4(a)). Figure 4(b) shows the result matrix after the linking operations.
5.2.3 Merging Instances in Different Tables. Two linked tables may describe the same set of
objects. For example, the patient survey and hospital tables are linked by hospital ID, and they
describe the ratings and the general information, respectively, of the same set of hospitals. Two
such tables can be combined with a merging operation.
Merging two tables Vk and Vl is done by first merging their corresponding instances according
to the linked variable E. For instances v(k)
i ∈ Vk and v(l)
j ∈ Vl with the same level e ∈ E, they are
merged into one row vm. For example, both v(2)
1 and v(3)
1 is “Hosp.#1” in the patients’ survey and
hospital tables (see H2 and H3 in Figure 3(a)), so they are combined into vl in H in Figure 3(b).
Then, in the second step, we assign each combined vm to hyperedges {e} by setting h(vm, e) in H.
h(vm, e) is set to 1 if h(v(k)
i , e) = 1 or h(v(l)
j , e) = 1; otherwise, h(vm, e) = 0.
This operation can be done by dragging an aggregated row Vk into another Vl (see blue line in
Figure 4(b)). Figure 4(c) shows the result matrix after merging operations.
5.2.4 Exclusion of Variables and Tables. During the construction, the user can exclude an undesired variable E or a table V from H by deleting the corresponding column or row. The user can
put the deleted tables or variables back into the incidence matrix by the inclusion operation.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:11
5.2.5 Dataset View. When the number of variables or tables is large, it will be inconvenient
to drag a column or a row in the matrix. A dataset view (Figure 4(e)) is provided which supports
the same set of construction operations. The linking operation can be done by connecting two
variables with a link (see purple lines in Figure 4(e)). The merging operation is performed by
dragging a table into another (see blue line in Figure 4(e)).
Since it can still be labor-intensive to perform search and link operations among large amounts
of variables, hints for linking operations will be user-friendly. Specifically, two variables whose
level sets and names are identical may be a candidate pair for the linking operation. The user has
the option to show these pairs with dotted lines in the dataset view, such as the dotted line between
“County” of V2 and V3 in Figure 4(e).
Finally, the user is also able to undo the construction operations to restore a previous constructed
hypergraph model.
6 VISUAL MODULATION OF HYPERGRAPH LEARNING
With the constructed hypergraph, the user is allowed to adjust the parameters of the model and
run Algorithm 1 to see the learned labels f. To be more specific, μ, ρ, and the prior hyperedge
weights wd (Equation (6)) can be modified interactively according to the domain knowledge or
the feedback of the visual exploration. This process can be repeated until the user is satisfied with
the learning results.
In this section, we first introduce the approach we designed for injecting the prior weights
(Section 6.1), then we will discuss methods that deal with scalability and usability of the weight
modification (Sections 6.2 and 6.3).
6.1 Setting the Prior Weights of the Hyperedges
For a better understanding of the hyperedge weights, we use bar charts above the columns to
visualize the learned weights w and the prior weights wd , as shown in the white and gray bars,
respectively, in Figure 4(d). For an aggregated column of a variable E, the weights are defined as
the average wd and w of its levels e ∈ E.
To support the modification of the prior weight wd (e), we initially designed an interaction on
the bar charts, where the user could adjust the bar length of column e to set wd (e). However, in
our experiments, we found that asking the user to set the exact value of wd (e) was not practical,
since (s)he may not understand the meaning and effect of the exact value of a weight. But the user
may have an idea about setting the change ratio of wd (e). As a result, we improve the interaction
by providing a few popular options, such as half the wd value, double the wd value, or set wd to 0
or the maximum value in wd . Alternatively, the user can also input a self-defined change ratio.
Each time the weights are changed, the learning results will be updated. Performance information such as test accuracy is provided so the user can evaluate the effects of the modification.
The test accuracy also reveals whether the change caused overfitting. Since the user may want
to try different wd to find better learning results, there is an undo operation for the modification.
Finally, our system can also be asked to return to a previous analysis step to view the learning
results under a previous wd .
6.2 Reordering of the Hyperedges
Since there are large numbers of hyperedges, it will be time-consuming for the user to examine and
modify all the weights. To deal with this scalability problem, we can focus on the hyperedges which
have major influences in the model. According to Equation (4), hyperedges with higher weights
w have more significant effects on the learning results. Therefore, it is preferable to inspect and
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:12 C. Xie et al.
adjust the hyperedges with higher weights first. A simple reordering of the columns by w enables
this.
Figure 4(d) shows the incidence matrix ordered by the variable weights. The variables related
to hospital ratings (e.g., “Nurse Rating”) have higher weights than those related to counties (e.g.,
“Smoking Rate”), which means hospital ratings are regarded as important predictors of readmission by the algorithm. Because the weights w are affected by their prior wd , ranking the columns
by wd is also available.
6.3 Recommending the Prior Weights
During our experiments, we found that setting the prior weights wd can be impractical in the
following two situations: (1) At the beginning of our algorithm, it is laborious to ask the user to
set the initial wd of the hyperedges one by one. (2) The user is usually interested in only a part of
the hyperedges and may not have priors for others.
Because of the above reasons, a method for recommending wd would be more user-friendly, essentially providing the user the option to set wd to some recommended values during the analysis.
We calculate the recommended wd (e) by making use of the Hellinger Distance [36], which measures the divergence of learned labels f in a hyperedge e (Equation (10)). For example, with the
Hellinger Distance, a disease e which contains only patient groups with low readmission levels will
have high wd (e), and e can be recognized as an indicator of low readmission. In Equation (10), f +
e
and f −
e represent the set of positive and negative instances in e, respectively; f + and f − represent
the set of positive and negative instances in all the datasets, respectively. Other weight measures
can be adopted as well [15, 19] in our algorithm.
wd (e) = 



f +
e


f +

−

f −
e


f −



	
2
(10)
Via the recommended wd , the user is now free to only focus on the weights of those hyperedges
of interest. For example, the user may halve the wd of the hyperedge “Newborns” and keep the
recommended values for the rest of the hyperedges.
The recommended weights bring several additional benefits. First, hyperedges e with highwd (e)
will have low diverse labels, which can be a good predictor of labels. Sometimes wd can be a better
indicator than w since w needs to satisfy the vertex degree constraint in Equation (6), while the
recommended wd is only based on the result f. In our system, ordering the matrix by either w or
wd is enabled for the user to explore potentially important hyperedges. Second, the user does not
have to assign an initial value wd for the algorithm. Instead, a default wd = [1, 1,..., 1]T is used,
which can be updated later by the recommended values based on the learning results.
7 HYPERGRAPH VISUALIZATION: EXPLORATION AND VALIDATION OF THE
LEARNING RESULTS
Although the visual exploration of the learned labels f provides insights both into the model as
well as into the effects of a user’s modifications, this type of interaction is typically not available in
most of the existing learning approaches. Specifically, the following tasks are usually performed by
the user during the visual exploration and validation: T1: Examine the learning results of vertices
or hyperedges of interest. T2: Examine the learned distributions of the intersections of different
hyperedges. For example, the user may want to interactively query the learned readmission levels
of the patient group from “Brooklyn” (e1 in Figure 5) who suffer from “Fever” (e2 in Figure 5). T3:
Compare the learning results of different vertices in a hyperedge. T4: Examine the changes of the
learning results after updating the model.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.                
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:13
Fig. 5. (a) The force-directed layout of the vertices in two hyperedges e1 and e2. (b) For each hyperedge, the
convex hull is calculated and the curved contour is generated by extending the convex hull. (c) Vertices from
the same dataset can be aggregated. (d) The distribution of the learned labels of each aggregated vertex can
be encoded with a pie chart.
7.1 Design Rationales
Learning result visualization is necessary to support the exploration tasks. One straightforward
strategy is showing the labels as an additional column in the incidence matrix H. However, there
are some drawbacks to presenting the learning results in the matrix. First, the distributions of the
learned labels in a hyperedge (T1) are not visualized. Second, the matrix can be large, which makes
it time-consuming for the user to check the vertex labels (T1) row by row. Third, it is difficult to
find the hyperedge-hyperedge (T2) or vertex-vertex (T3) relations in the matrix visualization.
As discussed in Section 2.2, contour visualizations allow the intuitive exploration of the learning
results, especially for T1 - T3. Some approaches (e.g., Bubble Sets [13]) are not applicable in our
case since they require the input of a vertex layout. In contrast, Vizster [18] proposes an effective
solution which generates contours based on the force-directed layout [14] of an ordinary graph.
Following Vizster, our approach extends the force-directed layout for hypergraph visualization.
7.2 Force-directed Hypergraph Visualization
In initial studies with a prototype of our system we observed that during analysis users typically
focused only on a small set of hyperedges at any one time. Hence, our system in normal operation
only visualizes a subset EI of interesting hyperedges which can be selected by the user (e.g, EI =
{e1:“Brooklyn”, e2:“Fever”} in Figure 5(a)).
7.2.1 Force-directed Layout of Vertices. To minimize the visual clutter generated by unnecessary contour overlap, an optimized layout is expected to satisfy the following principles: (i) Vertices sharing more hyperedges should be closer, which keeps the area of a hyperedge compact. (ii)
Vertices with no common hyperedge should be placed as far apart as possible, which reduces the
possibility of an overlap of disjoint hyperedges.
Our algorithm positions the vertices by assigning forces among them. For two vertices vi,vj ∈
V ⊆ EI , their mutual attractive force fa (vi,vj) and repulsive force fr (vi,vj) are defined according
to principle 1 and 2, respectively (Equation (11)).
fa (vi,vj) = m · dis(vi,vj)
2
k and fr (vi,vj) = − k2
dis(vi,vj) (11)
In Equation (11), k is a constant and dis(vi,vj) is the distance of vi and vj . The difference between
Equation (11) and the original force-directed algorithm [14] is that we multiply fa by a factorm.m
is defined as the number of common hyperedges whichvi andvj are in:m = 
e ∈EI h(vi, e)h(vj, e).
For example, m = 2 for v1 and v2 in Figure 5(a) because they share 2 common hyperedges in EI :
e1 and e2. As a result, vertices that share more common hyperedges will be placed closer by fa.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:14 C. Xie et al.
Fig. 6. A subset of interesting hyperedges EI = {e1, e2, e3} are selected from Figure 4 (d) and presented in
the contour visualization. The hyperedges contain the aggregated vertices of high-rating hospitals. The label
distributions inside the vertices show the learning results of Algorithm 1. The readmission levels of these
hospitals are mainly labeled as “Low” or “Medium”. It suggests that high ratings could be good indicators
of low hospital readmission. Different design options are provided for contour and vertex visualizations.
(a) Contours with the same size and grayscale. (b) The contour borders are adjusted to different sizes and
grayscales, which makes the contours more distinguishable. (c) The label distributions of vertices are visualized with histograms. (d) The distributions are shown in aster plots.
Then the regular force-directed layout algorithm is used to calculate the positions of the vertices
(Figure 5(a)).
Each vertex is visualized as a circle, whose size is encoded with the vertex weight u(v). For the
color of a vertex, we provide different options to the user, such as the class label or the dataset
type.
7.2.2 Contour Visualization of Hyperedges. Because the user will set EI interactively during the
exploration, the contours of the hyperedges should be generated in real time. Some approaches
(e.g., Bubble Sets [13]) fail to meet this requirement due to their high complexities. Using the same
method as Vizster [18], we create the contour of a hyperedge by calculating the convex hull of its
vertices (see solid line in Figure 5(b)). The curved contour is computed by extending the convex
hull outwards (see dashed line in Figure 5(b)). Other methods, such as quadratic splines, can also
be used to get a smooth border [18]. The user is able to change the hypergraph layout manually by
dragging the vertex. Then the contours will also be recalculated according to the updated vertex
positions.
After some experiments, we decide to leave the contour areas uncolored. This keeps the vertex
colors well visible and also avoids blending issues when differently colored hyperedges overlap.
The omission of fill colors, however, can lead to ambiguities. Figure 6(a) shows an example of three
overlapped hyperedges e1 − e3, which are selected from Figure 4(d). Initial testing with a prototype
reveals that sometimes it is difficult to recognize the hyperedges (Figure 6(a)). In order to make
the contours more distinguishable in the general case, we randomly resize the contours slightly to
avoid any ambiguity of the contour lines (Figure 6(b)). Finally, for further disambiguation, we can
also use different grayscales for the contour lines.
7.2.3 Vertex Aggregation. The calculation of the convex hull and the visualization of large numbers of vertices are both challenging when the number of vertices in EI is large. We deal with this
problem by aggregating vertices that are of the same data type and have exactly the same inclusion
relations in EI . For two verticesvi ∈ V andvj ∈ V , we aggregate them if ∀e ∈ EI ,h(vi, e) = h(vj, e).
Figure 5(c) shows an example of a hyperedge visualization with aggregated vertices. Patient groups
which are not in “Brooklyn” and have “Fever” (v3 - v6) are merged into vertex v7.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:15
Table 2. Visual Encodings of the Matrix Visualization and the Contour Visualization
Data Notation Matrix Visualization Contour Visualization
An instance A vertex v A non-aggregated row A non-aggregated vertex
A level of a variable A hyperedge e A non-aggregated column A contour
A dataset V An aggregated row Vertex color (optional) (Figure 5(a))
A variable E An aggregated column -
The label of an instance f (v) - Vertex color (optional) (Figure 5(d))
The aggregated vertex weight, which is encoded by the vertex size, is the sum of its original
vertex weights. The data type of an aggregated vertex can be encoded with color. However, the
class information cannot be represented by a single color, since the original vertices may have
different labels. To show the class distribution in an aggregated vertex, we provide several design
options, including pie chart (Figure 6(b)), histogram (Figure 6(c)), and aster plot (Figure 6(d)). For
an aster plot, the size of the inside circle represents the weight and the lengths of the outside pie
slices encode the label distribution. The users in our studies preferred the pie chart, as they found
a label corresponding to a small magnitude (e.g., “High (9-12%)” in Figure 6) in the aster plot or
histogram was too small to be seen. Later in the study, one of our users mentioned that comparing
distributions of different vertices with a pie chart may not be as easy as with a histogram. We
solve this problem by adding histogram visualizations of interesting vertices in a more detailed
view (Section 7.3).
Each time the learned labels are updated, the distributions of the vertices will also change accordingly. The user can also switch to the visualization without vertex aggregation if she or he
wants to see the details of the original hypergraph structure. The visual encodings of the visualizations proposed in this article are summarized in Table 2.
7.3 Visual Exploration
The user can query interesting results by setting the hyperedge subset EI . This can be done by
selecting/deselecting hyperedges of interest either in the dataset view or in the incidence matrix
during the exploration (e.g., EI = {e4, e5} in Figure 7(a)). The vertex aggregation and the contours
are recalculated upon change of EI .
The hyperedge visualization as presented so far is incomplete since the learned class distribution
of a hyperedge (T1) is not visualized, such as the overall label distribution of hyperedge e5 in
Figure 7(d). In addition, it is also difficult to discern the distribution in the pie chart of an aggregated
vertex with small size. For these purposes, we provide a detail view to show the learned class
distribution of an aggregated vertex or a hyperedge (Figure 7(e)). To help the user understand the
effects of his or her modulation (e.g., updating wd ) on the learning results, both the results before
and after the user’s modulation are shown with gray and yellow histograms, respectively. The
user can click on a vertex (e.g., the highlighted vertex in e4 in Figure 7(d)) or a hyperedge (e.g.,
the highlighted hyperedge e5 in Figure 7(d)) to view its distributions. Because the histograms are
vertically aligned, this view also helps to compare the change patterns of different vertices and
hyperedges (T4).
8 CASE STUDIES
We conducted two case studies, which focused on topics in different fields, with two scientific collaborators (call them SC1 and SC2). SC1 was a graduate student majoring in Biomedical Informatics
who was interested in predicting the readmission levels of hospitals in New York State. However,
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:16 C. Xie et al.
Fig. 7. The interface of our system. (a) The dataset view after adding the inpatient discharges dataset (V7).
(b) In the non-aggregated incidence matrix, all levels are ranked by their weights w. (c) Reducing the prior
weights wd of the selected diagnosis categories, as shown in the purple bars above the matrix in (b). (d)
Selecting four hyperedges of “Age 0-17,” “Age 65+,” “Newborns,” and “Circulatory System” from the dataset
view and the incidence matrix. The readmission levels of the patient groups in these hyperedges are shown
in the contour visualization. Highlighting the hyperedge of e5 and the vertex in e4 to show their learned
distributions. (e) There are different patterns of changes in the distributions of “Newborns” and “Circulatory System” after the modification of the weights wd . (f ) Adjusting the hyper parameters of the learning
algorithm.
he could not find a complete table including all the potential risk factors of readmission, and so our
system offered him a welcome opportunity to make such prediction using disparate data sources.
SC2 was a Political Science graduate student with a research focus on the public opinion of the
recent US election. He wanted to analyze the 2016 election polls by comparing the real election
results and the results predicted by the polls. Both users were not experts in visualization and had
no prior knowledge about hypergraphs. The summaries of the two datasets are shown in Table 3.
Before the study, we had a number of thorough discussions with SC1 and SC2 on their problems.
Then we searched online for additional sources to supplement their datasets. Each case study
started with a training session to introduce our system. We then asked each participant to use the
system, followed by an interview to gather evaluations and subjective feedback.
8.1 Case Study 1: Readmission Prediction of Hospitals in New York State
SC1, our public health collaborator, used our system to predict the readmission levels of hospitals
using a collection of history records. He had a dataset of hospital Potential Preventable Readmission (PPR) rates (V1) from the New York Health Department website [33]. We labeled each
readmission instance as one of five levels (“Very low” to “Very high” in Figure 6) according to its
PPR rate in the dataset. The readmissions from 2011 to 2013 were used as the labeled training data,
and the readmissions in 2014 were the test data for our algorithm.
The readmission dataset contained only two variables “Year” and “Hosp. ID,” but SC1 was interested in learning more potential readmission factors. We gathered supplementary information of
hospitals from the Medicare Open Data [30], including their general information (V2), structural
measures (V5), evaluations (V6), and the patient satisfaction surveys (V4). The inpatient discharge
dataset (V7) [33] was also obtained which described the details (e.g., age group and diagnostic
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:17
Table 3. A Summary of the Heterogeneous Datasets That Our Study Participants
Used in the Readmission and Election Case
NY Hospital Readmission Case
Datasets Number of variables Number of levels Number of instances
V1 Readmission (PPR) 3 219 874
V2 Hospital information 6 556 250
V3 County information 17 110 62
V4 Patients’ surveys 13 246 151
V5 Hospital measures 9 217 155
V6 Hospital evaluations 11 240 173
V7 Inpatient discharges 7 272 9,750
US Presidential Election Case
Datasets Num. of variables Num. of levels Num. of instances
V1 History election results by state 3 57 51
V2 History election results by county 3 3,118 3,112
V3 State facts 8 108 51
V4 County facts 13 3,196 3,112
V5 2016 polls by state 111 381 51
Some numerical values in the datasets were discretized into categorical levels.
category) of the inpatient groups of each hospital. To check if the location had effects on readmission, census information of counties in NY state (V3) was collected [6]. We discretized the numerical
variables (e.g., “Smoking Rate”) in the county dataset into three levels: above, around, and below
state average. The first table in Table 3 summarizes all datasets V and their detailed information.
8.1.1 Finding Hospital-level Risk Factors of Readmission. SC1 started his prediction of readmission with a focus on the hospital factors. He selected the readmissions (V1), counties (V3) and the
hospital datasets (V2, V4 - V6) in the dataset view (Figure 4(e)) to generate the initial incidence matrix (Figure 4(a)). By dragging the columns in the matrix, he linked the readmissions (V1) and the
hospital datasets (V2, V4 - V6) by “Hosp. ID.” The hospitals (V2) were also linked to the counties
(V3) by the hospital locations (Figure 4(a)). Because the hospital datasets (V2, V4 - V6) described the
same set of hospital instances, SC1 merged V4 - V6 into V2 by dragging their rows in the matrix
(Figure 4(b)).
With the constructed hypergraph, SC1 trained the model using Algorithm 1 with the default
wd = [1, 1,..., 1]T . The algorithm showed the test accuracy was about 0.80. To find out what
factors of readmission were important according to the algorithm, SC1 ranked the variables by
the learned weights w (Figure 4(d)). He discovered that the variables related to patients’ surveys
had the highest weights, such as “Nurse Rating,” “Care Rating,” and “Pain Management Rating.”
He expanded these variables and selected their levels of the highest rating (e.g., rating 4 of “Care
Rating” in Figure 4(d)) for detailed inspection in the contour visualization (see e1, e2, and e3 in
Figure 6(b)). The hospitals were shown as the vertices in the contours. For example, the aggregated
vertices in e1 represented the hospitals whose “Nurse Rating” is 5. From the pie charts of the
aggregated vertices, he found that the most hospitals contained in these hyperedges were labeled
as “Low” to “Medium” by the algorithm. He confirmed that good quality of health care could solve
the underlying problems and prevent unnecessary readmissions. Then, by exploring the remaining
portion of the incidence matrix, he noticed that the weightsw of county census variables were low,
such as the “Smoking Rate” of each county (Figure 4(d)). This indicated that those variables were
less important with respect to readmission. He suggested that this might be because the county
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:18 C. Xie et al.
dataset described the census of the total population, while the hospital readmission levels were
only decided by the inpatients.
8.1.2 Finding Risk Factors of Readmission in Patient Groups. To find factors of readmission
in the inpatient information, SC1 modified the hypergraph by adding inpatient discharges (V7)
(Figure 7(a)). Then the updated model showed an accuracy of 0.85. He ranked all the levels by w
(Figure 7(b)) in the incidence matrix, then started to examine the hyperedges with high weights w
to find important predictors of readmission. He noticed that the levels in “Length of Stay” might
be closely related with readmission because their weights were among the highest. He guessed
that the length of stay at hospital indicated the severity of the illness, which had correlation with
readmission.
He found that there are several diagnosis categories with high weights, such as “Newborns” (e4)
and “Circulatory System” (e5). He visualized the readmission distributions of the patient groups in
those diagnosis categories and different age groups (e.g., “Age 0-17” and “Age 65+”), as shown in
Figure 7(d). From the pie charts of the vertices, he learned that the patient group of “Newborns” (e4)
had a higher proportion of “High Readmission” than others. He told us that “Newborns” was not
supposed to be a factor of potential preventable readmission (PPR). According to his knowledge,
“Newborns” admissions were rarely related to their previous admissions, and so few of them were
regarded as re-admission [17]. He continued his examination on other diagnosis categories with
high weights. He expressed that some categories such “Trauma” (e6) were also usually excluded in
potential preventable readmission rate calculations, since they were always not “preventable” [17].
After this inspection, he selected some of the diagnostic categories in the matrix (see the purple
bars above the matrix in Figure 7(b)) and reduced their prior weights wd by half (Figure 7(c)).
With the updated wd in the model, he ran the learning algorithm again. The final accuracy was
improved to around 0.89. To see the detailed changes of learned labels, he selected the hyperedges
of “Circulatory System” and the vertex in “Newborns” (Figure 7(d)) to visualize their detailed label
distributions. He found that more “Newborns” readmissions became “Low” after the modification
of wd . While the overall distribution of “Circulatory System” had the opposite change pattern,
it skewed to higher readmission levels (Figure 7(e)). He confirmed that some circulatory system
diseases such as heart arrest had high possibilities of readmission.
8.2 Case Study 2: Bias of US Presidential Election Polls
The second participant (SC2) focused on the prediction of the 2016 US presidential election. He
collected the historical presidential election results by state (V1) and by county (V2) [39] as the
labeled data. We labeled the instances in V1 and V2 as “Republican,” “Democrat,” or “Others.” The
election results of 2004, 2008, and 2012 were used as the training data and the results by state in
2016 were used as the test data.
He also gathered the election polls by state in a month before the election date (V5) [34], which
contained more than 100 poll providers. In the poll table, the value of a poll in a state was assigned
to “Clinton,” “Trump,” or “Others” according to the support rates in the poll, as shown in table V5
in Figure 8(a). Since each poll provider surveyed a part of the states, there might be empty values
in the poll table. For example, “CBS News/YouGov” did not survey “FL” (see tableV5 in Figure 8(a)).
To see if there were other factors related to the election results, we added the census datasets
of the states (V3) and the counties (V4) in the US [6]. They contained the demographic information
such as the population density and bachelor’s degree rate. We discretized each numerical variable
in these datasets into three levels: above, around, and below federal average. The summary of the
datasets is shown in the second table in Table 3.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:19
Fig. 8. (a) The top table shows the details of the poll dataset (V5). Each poll is a categorical variable of
three levels: “C,” “T,” and “O.” We added the bottom candidate table (V6) as the labeled data for training.
(b) Incidence matrices of V5 and V6 respectively showed set relationships of the states and candidates to the
polls.
8.2.1 Prediction by History Election Results. SC2 practiced using our system at the beginning
of the study. He first constructed a hypergraph of the states, counties and their history election
results (V1 - V4). He linked V2, V4 by variable “County Fips” (i.e., county ID) and V1 - V4 by “State.”
Then he trained the model with default wd , the result suggested that Democrat would win 347
out of 538 electoral votes. However, the Republicans won the majority of the electoral votes in the
2016 election. After checking the model, he admitted that using the history data might generate
significant error because the election candidates of the parties were much different from the past.
8.2.2 Prediction by Election Polls. Because the history results did not help much and even misled
the prediction, SC2 removed these two datasets (V1 andV2) and added the 2016 election polls (V5) in
the dataset view (Figure 9(a)) to update the hypergraph structure. Then we realized that there was
no labeled data for training after the removal of the history results, so we added three candidates
(V6) as the labeled instances for the training of the model. To link them with the polls, we put
the candidates into the corresponding levels of the polls (see table V6 in Figure 8(a)). For example,
Democratic party candidate Clinton (v2) occurred in the “Clinton” hyperedges of all the polls, as
shown in the set representation in Figure 8(b).
SC2 linked and merged the state (V3) and poll (V5) dataset by “State” in the dataset view
(Figure 9(a)). Then he trained the model and found that 46 out of 51 states (50 states + D.C.)
were correct (448/538 votes). However, Clinton still would win the majority votes according to
the results. Because the model was still not satisfactory, he told us that he was interested in finding which poll providers had major influences on the learning results. He calculated wd for all
the variables with the Hellinger Distance (Section 6.3). By reordering the incidence matrix, he noticed that the polls of “CNN/ORC,” “NBC/WSJ/Marist,” and “CBS News/YouGov” had the highest
wd values (Figure 9(d)). He selected their levels of “Clinton” (see e1, e2, and e3 in Figure 9(b)) for
further validation in the contour visualization.
The states supporting Clinton in the selected poll were visualized in the hyperedge contours
(Figure 9(c)). For example, e1 contained the vertices of FL, PA, and NC because they supported
Clinton according to the “CNN/ORC” poll (Figure 8). All the vertices were blue because our
learning algorithm also labeled those states as “Democrat.’. SC2 told us that some of these
states actually voted for Trump, such as Florida (FL) and North Carolina (NC). According to
his knowledge, these polls were possibly biased. SC2 showed us some reports mentioning that
media such as NBC, CBS, and WSJ had certain preferences for the Democratic party [42]. He
selected these polls and set the change ratio of their prior weights wd to 0.1 (Figure 9(d)). With
the modified wd , he ran the algorithm again, and more states turned correct (49/51 states, 508/538
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:20 C. Xie et al.
Fig. 9. (a) In the US presidential election case, the user constructed a hypergraph structure on four heterogeneous datasets (V3 - V6) in the dataset view. (b) The constructed structure was represented in an incidence matrix, which was ranked by wd . Some variables (“CNN/ORC Poll,” “NBC/WSJ/Marist Poll,” and
“CBS News/YouGov Poll”) had high wd values, indicating they played important roles in the prediction. (c)
Three hyperedges (e1, e2, and e3) selected from the incidence matrix were visualized as contours. Each hyperedge contained states supporting “Clinton” in its poll (e.g., FL, NC, PA in e1). The candidate vertex v2 was
also in the edges, as we added the candidates in the poll (seeV6 in Figure 8). The color of the vertices encoded
the learned labels. (d) The user reduced the prior weights wd of some polls since they might be biased. (e)
After running the learning algorithm again with the updated wd , some of the learned labels were changed
(e.g., the states FL and NC turned into Republican). (f ) The histograms showed the label distributions before
and after the change of weights.
votes), including Florida and North Carolina (Figure 9(e)). The total electoral vote distributions
before and after changing wd were shown in Figure 9(f). Our model failed to predict only two
states: Pennsylvania and Wisconsin. SC2 checked the poll dataset (V5) and found this was because
almost all the polls predicted them as Clinton, but they actually voted for Trump.
During the examination of the poll providers, an interesting observation SC2 found was that
most university polls showed Clinton would win, such as “Univ. of North Florida” and “Florida
Atlantic Univ.”
He continued his exploration and noticed that several variables about the state census had high
weights, such as “Bachelor’s Degree Rate” and “Population Density.” He expanded these variables
and found that it was because their levels of “Above federal average” had very high wd values (see
e4 and e5 in Figure 10(a)). To examine their detailed class distributions, he selected these two levels
and visualized them in the contour visualization. From the pie charts of the aggregated vertices of
states, he found that states with both high population densities and high bachelor’s rates were all
predicted as “Democrat,” which suggested that the combination of these two hyperedges could be a
good indicator of election results (see the blue vertex in the intersection of e4 and e5 in Figure 10(b)).
He also noticed that the states that were not contained by e4 and e5 were mainly Republican.
8.3 Quantitative Analysis
Based on the datasets and settings of the two case studies, we evaluate the performance, the parameter selection, and the complexity of our algorithm.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:21
Fig. 10. (a) The user selected two hyperedges of “Above Average Population Density” and “Above Average
Bachelor’s Degree Rate” that had high weights. (b) The aggregated vertex of states in the intersection of the
two hyperedges was blue, indicating these two hyperedges together were good predictors for the Democrat
party, while the states outside both hyperedges were mainly Republican.
Table 4. Performance Comparison of Four Algorithms in Two Cases
Methods
Readmission Case Election Case
Test Error F1 AUROC Test Error F1 AUROC
TSVM 0.22 0.80 0.88 0.10 0.93 0.93
LBC 0.21 0.78 0.88 0.10 0.93 0.93
HGT 0.15 0.85 0.89 0.10 0.93 0.94
Ours 0.11 0.88 0.90 0.04 0.96 0.97
Bold indicates the best performance.
8.3.1 Performance Comparison. We compare our algorithm with three baseline algorithms:
Transductive Support Vector Machine [21], Link-based Classification [28], and traditional hypergraph learning [44], which are denoted as TSVM, LBC, and HGT in Table 4, respectively. To train
the TSVM with the complete datasets, we use the fused incidence matrix H constructed by each
user as the set of input features. After testing different kernels, we choose the radial basis function
(Gaussian kernel), which achieves the best performance for TSVM in our datasets. The ordinary
graph structures of LBC are constructed manually with pairwise links on the datasets in the
two cases. Logistic regression is employed as the local classifier in the iterative class assignment
process of LBC. The hypergraph structures constructed in the two studies are adopted for both
the traditional hypergraph and our algorithm. w in HGT (Equation (2)) is set to [1, 1,..., 1]T ,
which is usually used as the default value [44]. For our algorithm, wd set by the users in the
studies are employed.
The test error, macro-average F1 score for multi-class, and macro-average area under the Receiver Operating Characteristic (AUROC) for multi-class are employed as the evaluation metrics.
The results of the two cases are shown in Table 4. Our approach achieves the best performance
among the compared methods. Especially, in the election case, our method is the only algorithm
which predicts Trump’s victory although other baseline methods also have high performances.
The main reason for it may be that our algorithm allows the user to tune the parameters during
visual analysis, which is critical for improving the learning model.
We perform 10-fold cross-validation to detect if there is overfitting in our approach. We use
the wd set by the users in the cases. The F1 scores of the cross-validation in the readmission and
election case are 0.87 and 0.91, respectively. They are close to the F1 scores in the case studies
(Table 4), indicating our models with the user-defined wd do not overfit.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:22 C. Xie et al.
Table 5. The Average Convergence Iterations and the Average Test Errors
of Algorithm 1 with Respect to Different μ and ρ
Settings
Iteration Number Test Error
Readmission Election Readmission Election
μ = 1, ρ = 0.01 5.0 4.0 0.13 0.10
μ = 1, ρ = 0.1 3.3 3.0 0.13 0.10
μ = 100, ρ = 1 4.3 4.0 0.14 0.12
μ = 10, ρ = 1 2.7 2.0 0.13 0.12
μ = 1, ρ = 1 4.0 3.3 0.12 0.06
μ = 0.1, ρ = 1 3.0 2.0 0.12 0.10
μ = 0.01, ρ = 1 2.0 2.0 0.16 0.12
μ = 1, ρ = 10 2.0 2.0 0.14 0.12
μ = 1, ρ = 100 2.0 2.0 0.14 0.12
Our algorithm converges in constant time in both cases. The performance of our algorithm
does not degrade much with different parameter settings.
8.3.2 Parameter Settings. To find the effects of different μ and ρ values on the learning results
in Algorithm 1, we test different settings of (μ, ρ). We adopt the hypergraph models that the users
constructed at the end of their studies. We ask the user to define a set ofwd and use them to test the
average iteration steps for convergence and the average test errors. The threshold ϵ in Algorithm
1 is set to 0.1. The experiment results in the two cases are shown in Table 5.
Rows in Table 5 are ordered according to the value of ρ. When ρ increases, Algorithm 1 converges faster. We conclude that a larger ρ makes the weight regularization term Ψ more important
in Equation (9). As a result, w will converge with less iterations, which leads to faster convergence
of Algorithm 1.
Compared to ρ, μ values have less effects on the iteration numbers. By examining the learning
results, we find that the learned labels f will become closer to y when μ is larger. Therefore, a very
small or very large μ will cause underfitting or overfitting of the algorithm.
The default (μ, ρ) is set to (1.0, 1.0), since Algorithm 1 has the lowest test error around (1.0, 1.0)
in our experiments (Table 5).
8.3.3 Complexity of the Algorithm. The complexity of Algorithm 1 is mainly decided by the
complexity of Equation (8), Equation (9), and the number of iterations. The complexity of matrix
solving in Equation (8) is O(|V|3), |V| is the number of vertices. The quadratic programming in
Equation (9) can be solved with interior-point algorithm [4] with O(|E|3) complexity, |E| is the
number of hyperedges.
According to Table 5, our algorithm converges within five iterations for both cases with different (μ, ρ). This indicates our iterative approach for solving optimization of Equation (6) will not
increase the total complexity. Overall, the complexity of Algorithm 1 is O(|V|3 + |E|3).
The complexity of the traditional hypergraph learning algorithm is O(|V|3), since it presets the
weights w and does not need to solve Equation (9). The complexity of our algorithm is not much
worse than the traditional algorithm when |E| and |V| are of the same order.
When the size of the heterogeneous data is big, there are some strategies to accelerate our algorithm. First, because we introduce vertex weight u, it becomes possible to aggregate the instances
that have identical inclusion relationship in the hyperedges. The vertex weight u of an aggregated
instance will be the sum of weights of the original instances. For example, an individual patient can
be aggregated into a patient group with weight as the number of patients. Second, Liu et al. [26]
provided a trade-off between time and accuracy. They dealt with large data by splitting the vertices
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
Visual Analytics of Heterogeneous Data Using Hypergraph Learning 4:23
into subsets and classifying the subsets in multiple runs. Third, pre-computation is enabled if the
prior wd will not be modified.
8.4 Feedback and Discussion
We evaluated the learning cost and usability of our visual system in the training session and the
interview session, respectively.
8.4.1 Learning Cost. In the training session, our instructor gave a 15-minute demo to explain
the hypergraph learning algorithm and our system. Then SC1 and SC2 practiced our system with
the help of the instructor. They were free to stop practicing when they felt ready. To evaluate
the learning progress, each participant was given a test of six exercises. The exercises tested the
users’ understanding of the proposed visualizations and interactions based on the case scenario.
For example, an exercise for SC1 was linking “Hosp. ID” in “Hospital Measures” and “Hospital Evaluation.” We observed that neither participant practiced for more than 12 minutes. In the tests, the
participants were able to respond to all exercises as expected without any help from our instructor.
When asked to rate the learning cost of our system (1 = very hard, 5 = very easy), SC1 and SC2
gave ratings of 4.5 and 4, respectively. SC1 mentioned that it was easy because the matrix-based
and contour-based visualizations followed commonly used set visualizations. SC2 told us at first
he had some trouble interpreting the contour visualization because he was unfamiliar with the
concept of the hypergraph learning. However, he understood our visual representation as soon as
he found that it basically showed the set memberships of the data instances and the levels.
8.4.2 Usability. In the interview session, both participants rated the usefulness of our system
at 5 (1 = very useless, 5 = very useful). SC1 and SC2 were also required to compare our system with
their usual tools. After that, we asked them to give detailed evaluations of the matrix construction
interactions, weight modulation, and the contour-based visualization.
SC1 mentioned that he used to join the data by database queries and search for interesting
variables in a trial-and-error process until a satisfied result was achieved. Likewise, SC2 said that
he typically would also fuse the data manually, which prevented him from updating the model
in an incremental manner. Both participants commented that they often struggled with the raw
data and statistics due to the lack of an effective visualization of the data structures and learning
results.
For the interactions related to the matrix construction, SC1 mentioned that it enabled him to
test different datasets and variables in a visual interface to find the risk factors of readmission.
He confirmed that the design of the linking and merging operations was natural because they
were equivalent to the join operation in a database. SC2 said, “I realized that using the history
election results for prediction was not suitable, so changing the model during the analysis was
necessary.” Then he expressed that the supported interactions for changing the incidence matrix
of the election datasets were helpful and convenient.
SC1 told us that “Setting the weights in the matrix allowed me to exclude the unrelated factors
of readmission, such as the diagnosis category of ‘Newborns.’” When asked about the strategy to
adjusting the prior wd in the presence of a large number of hyperedges, SC1 mentioned that he
was interested in finding the most important factors of readmission. As a result, he would only
examine the hyperedges with high weights and adjust them according to his domain knowledge.
SC2 also indicated that ranking was useful for finding the hyperedges with important effects on
the predicted election results. He agreed that reordering helped to deal with the scalability problem
of adjusting weights of large numbers of hyperedges.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 1, Article 4. Publication date: December 2018.
4:24 C. Xie et al.
For the contour-based visualization, both SC1 and SC2 confirmed that it supported their visual
exploration tasks (T1–T4). SC1 mentioned that he was able to view the distributions for all interesting hospitals and patient groups at a glance (T1), which provided insights into the potential
readmission factors. SC1 also stated that the detail view (Figure 7(e)) was an efficient supplement
to the contour-based visualization because it informed him about the result changes caused by his
interactions (T4). SC2 noted that he discovered that many election polls might be incomplete or
biased from this contour visualization. He commented that it was very intuitive for visualizing the
structure of interesting polls and the predicted election results at the same time (T2, T3).
8.4.3 Discussions and Limitations. The participants also gave us some suggestions that we implemented in our system, such as setting the change ratios instead of absolute values of the weights.
SC1 recommended to use wider and darker cells for aggregated columns (Figure 9(b)). SC2 suggested changing the sizes of different hyperedge contour lines to distinguish them.
One participant asked if he can predict other missing values (e.g., missing “Income Level” values
of counties in Figure 1(a)) in addition to the labels. To get good performance on predicting “Income Level,” we have to set the known “Income Level” as the new labels and construct a different
hypergraph structure on another set of tables related to the census information.
During the visual modification process, the risk of overfitting can arise from the tuning of the
weights. This is most likely to happen when the user assigns extreme weights to the selected
hyperedges. To prevent this, a widely used solution is to add 2 regularization w − w0 2 as a
penalty term in Equation (6). Here w0 is the default value of w (e.g., [1, 1,..., 1]T ). On the other
hand, cross-validation can be performed every time the weight is changed to prevent overfitting.
For the existing contour-based visualizations, one common limitation is scalability [1]. The contours can become heavily cluttered due to dense overlapping, especially for more than seven hyperedges [40]. Our visualization can potentially be better than existing approaches because it avoids
the color blending of the overlapped regions. In addition, our force-directed layout reduces most
unnecessary overlapping.
During the interview, both SC1 and SC2 agreed that our strategy of only visualizing interesting
hyperedges helped them filter out the less important factors. They told us that they usually focused
on less than seven hyperedges at any one time during the visual exploration. In fact, this bears a
natural relation to the well-known “Magical Number” 7 (plus/minus 2) that has been found to
form an upper bound to a human’s working memory capacity [32]. Hence, the problem with the
limited scalability of the contour visualization is less likely to arise. SC1 also mentioned that the
hyperedges rarely would completely overlap, which limited the risk for visual clutter.
9 CONCLUSION
We described a visual analytics approach for classification on heterogeneous data. We used the
hypergraph paradigm to model the high-order relations of various objects in the datasets. Interactive construction, modulation, and exploration of the hypergraph learning model were supported
in the proposed visualizations. Two case studies showed that our approach is better than existing
learning methods in both performance and usability.
For future work, we would like to set the structure and parameters of the hypergraph model by
various forms of domain knowledge, such as the knowledge graph of the heterogeneous data. 