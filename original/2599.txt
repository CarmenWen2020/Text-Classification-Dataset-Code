In recent years, with the development of deep learning, text-generation technology has undergone great
changes and provided many kinds of services for human beings, such as restaurant reservation and daily
communication. The automatically generated text is becoming more and more fluent so researchers begin to
consider more anthropomorphic text-generation technology, that is, the conditional text generation, including emotional text generation, personalized text generation, and so on. Conditional Text Generation (CTG)
has thus become a research hotspot. As a promising research field, we find that much attention has been paid
to exploring it. Therefore, we aim to give a comprehensive review of the new research trends of CTG. We
first summarize several key techniques and illustrate the technical evolution route in the field of neural text
generation, based on the concept model of CTG. We further make an investigation of existing CTG fields and
propose several general learning models for CTG. Finally, we discuss the open issues and promising research
directions of CTG.
CCS Concepts: • Information systems → Social networks; • Human-centered computing → Collaborative and social computing;
Additional Key Words and Phrases: Human-computer interaction, conditional text generation, deep learning,
dialog systems, personalization
1 INTRODUCTION
Jorge Luis Borges1 once described a magic Library, named “The Library of Babel,”2 where everyone
could find any book he wanted. The readers cannot help but wonder who wrote these books. Are
they all written by human writers? Absolutely, the answer is no. This library seems unlikely to
exist, however, the development of text-generation technology in recent years has made it possible.
For instance, Philip M. Parker, having written and sold more than 100,000 books on Amazon,
utilizes computer programs to collect massive public information on the Internet for automatic
compilation into books.3 Parker’s method is known as text-to-text generation [44], which takes
existing textual materials as input and automatically generates new text.
Text-to-text generation is a typical subfield of text generation [95], which uses diverse types of
information to enable computers to learn to express like human, including image, text, and so on.
According to different data sources, text generation can be divided into data-to-text, text-to-text,
and image-to-text generation. News generation is a typical application of data-to-text generation.
For example, there was an earthquake in California on March 17, 2014, and the Los Angeles Times
first provided detailed information about the time, location, and magnitude of the quake. Actually
that news article was automatically generated by a “robot reporter,” which converted the incoming
registered seismic data into text by filling slots in predefined templates [101]. The data-to-textgeneration technology fills the established template with structured data and generates the output
text containing all key components, which has exerted considerable influence in the field of news
media.
The application of text generation from text-to-text includes machine translation [22], dialogue
system [115], text summarization [111], reading comprehension [51], and so on. By understanding the original text and obtaining its semantic representation, natural language text is generated
for communicating, summarizing or refining. Besides, The application fields from image to text
generation include image captioning [91], visual question answering [2], and so on. By processing
image information, the contents contained in the image can be understood to generate corresponding natural language descriptions and answers.
Deep learning contributes to the most recent advances in the text-generation field. Specifically,
with the help of the recurrent neural networks (RNN) [36], attention mechanism, generative adversarial networks (GAN) [47], reinforcement learning (RL), Variational Autoencoder (VAE) [63],
and Transformer [126], the generated text becomes more coherent, logical and emotionally harmonious, which is more suitable for offering assistance in every aspect of people’s lives. For example,
the dialogue systems, such as Microsoft XiaoIce,4 Cortana,5 and Apple Siri,6 can not only chat with
us but also assist us to operate electronic devices. News-writing-robots have provided creative assistance for journalists, and the machine translation technology has effectively met our needs of
translation.
Advancements in universal text-generation technology prompt researchers to explore more anthropopathic text-generation methods, such as context-based text generation [56], personalized
text generation [86], topic-aware text generation [133], emotional text generation [66], knowledgeenhanced text generation [147], and visual text generation [26]. Obviously, applying additional
1https://www.goodreads.com/author/show/500.Jorge_Luis_Borges. 2http://www.paulrittman.com/JLBLibraryofBabel.pdf. 3https://www.kurzweilai.net/he-wrote-200-000-books-but-computers-did-some-of-the-work. 4http://www.msxiaobing.com/. 5http://www.msxiaona.cn/. 6https://www.apple.com/siri/.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:3
information in text generation may make the generated text more personified and facilitate harmonious human-machine interaction. However, new challenges are summarized as follows.
• How to efficiently integrate the additional conditional information with traditional model
structures is a big challenge.
• Due to the scarcity of text datasets with specific conditions, training the conditional textgeneration models become more difficult.
• There is no reasonable evaluation metrics of the conditional text generation, making it difficult to quantify the performance of models.
This article aims to give an in-depth survey of the development of neural text-generation models. Specifically, we mainly focus on various studies on conditional text generation (CTG), such as
context-based text generation, topic-aware text generation, and knowledge-enhanced text generation. Compared with general text generation, the conditional text generation is more in line with
the needs of precision and friendly services.
To sum up, we summarize the contributions of our work as follows.
• Based on a brief review of current text-generation techniques, we characterize the concept
model of CTG and present the major human-centric services.
• We make an investigation of several different CTG fields, including context-based text generation, personalized text generation, topic-aware text generation, emotional text generation, knowledge-enhanced text generation, visual text generation, multi-conditional text
generation, and pre-trained language model-based text generation. Besides, the evaluation
methods and conditional datasets are also discussed. Based on the summary of existing
researches, we propose several general learning models for CTG.
• We further discuss some promising research directions of CTG, including the consideration
of different types of contexts, the multi-modal data translation, lifelong learning, and so on.
The remainder of this article is organized as follows. In Section 2, we give a brief review of
key text-generation techniques. In Section 3, we characterize the concept model of CTG. We then
summarize the major researches of CTG in Section 4 and propose several general learning models
for CTG in Section 5, followed by the open issues and future research directions in Section 6.
Finally, we conclude this article in Section 7.
2 THE KEY TECHNIQUES OF NEURAL TEXT GENERATION
The past few decades have witnessed a huge leap forward in the text-generation technology.
Specifically, from the original rule-based and statistical methods to the end-to-end neural networkbased methods, the overall quality of generated content is further improved. This section gives a
brief review of key techniques of neural text generation.
DNN-based methods do not require manual feature extraction, and can automatically learn the
continuous vector representations in three steps for the task-specific knowledge in different tasks,
i.e. encoding, reasoning and decoding successively [43]. The inputs of neural network models
will be first encoded into a vector space, where semantically related or similar concepts are close
to each other. Afterwards the neural networks will reason in the vector space according to the
hidden state and current input to produce the system response. Finally, the system response will
be decoded to generate natural language text. Different neural network structures are usually
adopted in the stages of encoding, reasoning and decoding, and all the parameters are optimized
through back-propagation and gradient descent algorithms. The end-to-end learning mechanism
promotes neural networks to fully mine the correlation in the data, and alleviates the requirement
of characteristic engineering greatly.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:4 B. Guo et al.
The key techniques of neural text generation mainly include RNN, GAN, RL, VAE, and Transformer, which will be summarized in the following subsections. Natural language text is a typical
kind of sequential data with specific relationships between contexts, and the natural sequential
structure of RNN is very suitable for modeling text data. Since RNN contain internal memory,
which can remember previous inputs and the current input, it makes sequence modeling much
easier. The output at the current time step depends not only on the instantaneous input but also
on outputs of previous time steps, which makes it highly capable of capturing contextual information and generating sentences that satisfy syntactic structures. However, the word-by-word
sequential generation process of RNN cannot learn representations of full sentences, making it
tend to generate inconsistent and uninformative text because of the absence of global features like
topics or high-level syntactic features. With latent variables in continuous space, VAE can capture
implicit language structure and utterance-level semantics (e.g., topics, syntactic properties), which
are served as the global representations during the decoding process. By the sampling procedure of
the latent variables, VAE is capable of producing more natural, meaningful, and diversified natural
language texts.
The RNN-based text-generation models trained by maximizing the log-likelihood objective
function are prone to the problem of exposure bias, caused by the inconsistency of the sequence
input during training and testing. Therefore, GAN, another powerful deep generative model that
has become a huge success in computer vision, is introduced to text generation that uses adversarial training to replace the maximum likelihood training to simulate the real data distribution and
generate higher-quality text. Through the adversarial training of the generator and discriminator,
the generator of GAN gains the ability to generate almost real data. However, the original GAN is
only suitable for processing continuous data such as images, while text is a typical kind of discrete
data, so it cannot be applied directly to text generation. Many efforts have been made to adjust
the internal calculation mechanism of GAN to deal with this problem, among which the introduction of RL greatly promotes the application of GAN in text generation. By combining the reward
mechanism and the policy gradient technology of RL, GAN skillfully avoids the above problem
that gradient cannot back propagation when facing discrete data and achieves promising results.
VAE and GAN are the two most powerful deep generative models that can generate data with
complex distribution approximate to the real data distribution from random noise with simple distribution. The distinct difference between them is the distribution metric, that is, the loss function
used to measure the quality of the generated data, is different. VAE utilizes an explicit measurement method that measures the KL divergence of training data and noise by assuming that training
data is generated by another distribution. GAN, however, avoids the explicit measurement of distribution difference by making the neural network learning the measurement through adversarial
training. In view of the two distribution measurement criteria are not perfect measurements, VAE
and GAN have their own problems to be solved.
Faced with other problems of RNN, including the inability to effectively capture long-term dependencies, the vulnerability to the problem of gradient vanishing or exploding, and the lack of
parallel computing capability, the Transformer model is proposed, which adopts self-attention
mechanism to replace the sequential structure in RNN. The self-attention mechanism can capture the context dependency among all words in a sequence to achieve more efficient sequence
modeling without distance restrictions and obtain more semantically rich text representations.
Transformer has shown excellent performance in various NLP tasks since it was proposed and has
great development potential.
In summary, these key techniques’ advantages and disadvantages are compared in Table 1.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:5
Table 1. A Summary of Text-generation Techniques
Technique Advantages Disadvantages
RNN Natural sequence structure is very
suitable for the task of sequence modeling
Cannot effectively capture the
long-distance dependence
between sentences
GAN
Unsupervised learning; Generating clearer
and more realistic samples than other
generative models
Instable training process; Not suitable
for processing discrete data,
such as text
Reinforcement
learning
Similar to human learning manners;
Combining with GAN can subtly solve the
existing problems in GAN and generate
realistic text
Quite complicated training process
VAE Leveraging the latent vectors to increase
the diversity of the generated text
The latent variable ensures that the
desired content is generated,
regardless of its quality
Transformer
The attention mechanism can efficiently
capture the long-term context
information; Fast parallel
computing speed
Large amount of calculation and slow
training speed
2.1 RNN
RNN is one of the most commonly used neural network models in text generation, whose natural
sequence structure is suitable for the task of text sequence modeling. The recurrent structure in
RNN determines that it can process textual data sequentially, of which each hidden state takes
the current input and the previous hidden state into consideration. Given the input text sequence
X = (x1, x2,..., xn ), the hidden state st of time step t is calculated as follows:
st = f (U · xt +W · st−1). (1)
After sequential processing, all semantic information of the given text are compressed into
a fixed-length vector, the hidden state vector at the last time step, enabling the RNN model to
have memory of previous content. Nevertheless, the problems of gradient vanishing or exploding still limit the application prospect of RNN. Variants of RNN model, such as long short-term
memory (LSTM) and gated recurrent unit (GRU), combine the short-time and long-time memory
through uniquely designed gating mechanisms, which makes them effectively solving these problems. There are three gate structures in LSTM that control the information in the cell state and
selectively determine whether the information is retained or not. The forget gate determines what
information in the cell state needs to be discarded according to the current input and the previous
hidden state, which is calculated as follows:
ft = σ (Wf · [ht−1, xt] + bf ). (2)
The input gate determines how much new information is added to the cell state, which is calculated as follows:
it = σ (Wi · [ht−1, xt] + bi ), (3)
C˜
t = tanh(Wc · [ht−1, xt] + bc ). (4)
Then the cell state is updated based on the input gate and the forget gate as follows:
Ct = ft · Ct−1 + it · C˜
t . (5)
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:6 B. Guo et al.
Finally, the output gate determines the output of the LSTM unit at time step t according to the
cell state:
ot = σ (Wo · [ht−1, xt] + bo ), (6)
ht = ot · tanh(Ct ). (7)
Numerous researchers have shown that LSTM has the ability to generate natural and realistic texts in many generation tasks. Sutskever et al. [122] first propose the Sequence-to-Sequence
(Seq2seq) learning model, which is a generalized framework for converting one sequence to another. In this framework, a LSTM as the encoder compresses sequences into vector representations.
Then another LSTM as the decoder predicts output words one by one conditioned on the hidden
state, and it takes the previous output as the input to predict the next output. Since this framework
has no limitation of the length of input/output sequences, it has been widely used in text generation, including machine translation [22], text summarization [111], and dialogue system [129].
Consequently, the data-driven end-to-end training based on the Seq2seq model has become the
mainstream method in text generation.
Actually, traditional Seq2seq models generally have two problems. The first is that all the inputs are transformed into a vector with fixed length, which limits the ability of latent vectors to
represent input information, and the second is that assigning all the input words with the same
weight cannot effectively capture the key information. To solve these problems, the Attention
mechanism, an widely utilized mechanism in computer vision, is introduced into NLP. Through
assigning different weights to different parts of the input sequence according to the current decoding state, the Attention mechanism can extract the key components from the input, which helps
generation models make more accurate judgments while reducing the computation and storage
consumption. The Attention mechanism is first applied to the Seq2seq model to fulfill machine
translation tasks [5], and now has gradually become an important part of text-generation models.
For example, Xing et al. [141] introduce an attention-based multi-turn response-generation model
to capture the most relevant content in the conversation context. The Attention mechanism makes
the multi-turn dialogue more coherent and consistent.
2.2 GAN and RL
From the perspective of neural network optimizing, there are still some defects in RNN-based
generation models. First, most RNN-based text-generation models are trained by maximizing the
log-likelihood objective function, which may lead to the problem of exposure bias. Second, most
loss functions are calculated at the level of words, while most evaluation metrics are based on
the level of sentences, which may result in the inconsistency between the optimization direction
of the model and the actual requirements. In this case, researchers introduce the GAN [47] into
the study of text generation. GAN is composed of two parts: the generator and the discriminator.
The generator produces false sample distributions similar to the real data, and the discriminator
distinguishes generated samples and real samples as accurately as possible. For example, Zhang
et al. [153] attempt to combine the LSTM and convolutional neural network (CNN) to generate
realistic text using the idea of adversarial training.
However, the original GAN is only applicable to generate continuous data and has poor performance on processing discrete data, because it is difficult for the gradient of the discriminator
to correctly back-propagate through discrete variables. To solve this problem, Zhang et al. [153]
utilize the smooth approximation algorithm to approximate the output of generator. Instead of
utilizing the standard objective function of GAN, they match the feature distribution and make
the word predictions ‘soft’ in the embedding vector space to generate high-quality sentences.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:7
Researchers have also made some fine-tuning to GAN’s structure to generate discrete data, e.g.,
the Wasserstein GAN model [3].
Although the direct improvement of GAN has achieved some progress, it is still far from meeting
practical requirements. Therefore, the idea of RL begins to be introduced to text generation. RL is
usually a Markov decision process in which the action in each state will be rewarded (or reversely
rewarded–punishment). For maximizing the expected rewards, the RL machine tries various possible actions in different states to evaluate the optimal policy according to the rewards provided by
the environment. It can be seen that the reward mechanism in RL could help the GAN to deal with
discrete data, which provides a new possibility for the application of GAN in text generation. For
example, Yu et al. [148] propose the SeqGAN model to solve the problems of GAN in generating
discrete text data. SeqGAN regards the text generation as a sequence decision procedure in RL,
in which the generated sequence at each timestep represents the current state, the next word to
be generated is regarded as the action to be taken and the returned reward is the discriminator’s
score of the generated sequence. Through gradient policy algorithms, the SeqGAN model directly
avoids the differentiability problem in the generator and obtain remarkable results in generating
realistic natural language text.
2.3 VAE
Although the traditional Seq2seq model has made great progress in text generation, it tends to
produce general and safe sentences with high probability, such as “I do not know” and “I am
sorry.” At the same time, the training of text-generation system needs a large amount of highquality labelled data, namely, supervised training. However, in reality, most of the data is unlabelled
and labelling a large amount of data is very time-consuming. The idea of unsupervised learning
is introduced to solve this problem. VAE is a powerful unsupervised generative model, which
contains an encoder that encodes input data into latent variables, and a decoder that decodes
latent variables to reconstruct the original input data. Given the input x, the encoder will encode
it into latent space pθ (z|x), where θ is the parameters of encoder. The decoder does the opposite,
which finds the probability distribution of the input based on the hidden variable pϕ (x |z), where
ϕ is the parameters of decoder. There is usually a latent hierarchical structure in natural language,
and latent variables in VAE can capture and reflect such inherent language structure, to produce
more natural and expressive natural language text.
The work of Bowman et al. [10] introduce a RNN-based VAE text-generation model that assigns whole sentences with distributed latent vectors. By appending Gaussian prior distribution
regularization on the hidden layers of the encoder, a sequence autoencoder model is constructed
and the output sentence is generated word by word conditioned on the hidden vector to obtain
consistency and diversity. Sequential data usually shows hierarchical structures and complicated
dependencies between sub-sequences. For example, the sentence sequences and word sequences
in a multi-round conversation have massive dependencies. Serban et al. [114] attach the latent
variable to the hierarchical dialogue model to assign the generative model with multiple levels
of variability for meaningful and diverse responses. Specifically, they attach a high-dimensional
latent variable to each sentence in the dialogue history, followed by generating responses conditioned on the latent variable.
2.4 Transformer
From the perspective of neural network training, RNN-based generation models also have some obvious shortcomings. First, RNN processes the input sequence with strict linear order from forward
to back, which leads to the problem of gradient vanishing or exploding due to the long back propagation path. Second, RNN lacks efficient parallel computing capability due to its linear propagation
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:8 B. Guo et al.
structure where the calculation at the next time step relies on the outputs at the previous time steps.
Therefore, RNN faces the issue of low calculation efficiency in large-scale application scenarios. To
address this problem, Google proposes a new sequence modeling model, the Transformer model
[126], which abandons the sequence structure in RNN and just contains Attention modules.
Specifically, the Transformer model is an encoder-decoder structure, only consisting of Attention modules and feed forward neural networks. The self-attention mechanism is the core of Transformer that captures the dependency among words in a sequence to obtain better semantic representations of each word. The self attention module is calculated as follows:
Attention(Q,K,V ) = so f tmax
QKT
√
dk

V . (8)
The Q, K, andV are all vectors, each of which is obtained by multiplying the input vector by the
weight matrix. The multi-head attention mechanism, composed of many self-attention modules to
form an attention module, is proposed to further improve the ability of capturing context semantic
information. After encoded by the self attention module, the output vector will be sent to the feed
forward neural network, calculated as follows:
FFN (z) = max (0,ZW1 + b1)W2 + b2. (9)
Besides the self attention module and the feed forward neural network module, there is also an
encoder-decoder attention module in the decoder, which has the same mechanism as the traditional Seq2seq model. Due to the parallelization of the Attention module, Transformer has powerful parallel computing capacity and broad application prospect. Since Transformer was put forward, the various models based on it have achieved excellent performance in various NLP tasks,
such as BERT [60] and GPT [106], making significant impact on the whole research area of NLP.
3 CONDITIONAL TEXT GENERATION
The development of deep neural networks brings unprecedented progress to text generation. However, there are still some problems with the existing text-generation technology. For example,
many studies train the text-generation model only based on the content of input text, ignoring
many other factors. However, a real person not only considers the context but also adjusts the
content according to their own conditions (such as mood and gender) and external factors (such
as weather and environment) when speaking or writing. In this article, we take conditional text
generation (CTG) as the future research direction, which is the key factor to improve the quality of
generated text. Specifically, it includes context-based text generation, personalized text generation,
topic-aware text generation, emotional text generation, knowledge-enhanced text generation, and
visual text generation. In this section, we formalize the definition of CTG and introduce the wide
application fields of it.
3.1 The Concept Model
The CTG refers to taking certain external conditions into consideration to influence the generated
results in the process of text generation. These conditions usually include context, topic, emotion,
external knowledge, and so on. The general text-generation methods only consider the text content
factor, which makes the generated text less diverse and has a large gap with human expression.
Consideration of external conditions in text generation makes it more anthropomorphic and brings
better services to human beings in various fields.
We first give a formal definition of general text generation. Given the input text sequence X =
(x1, x2,..., xS ), the target of general text-generation model is to generate the output text sequence
Y = (y1,y2,...,yT ), where S and T are the length of the input and output sequence, respectively.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.  
Conditional Text Generation for Harmonious Human-Machine Interaction 14:9
The general text-generation model can be defined as follows:
p(Y |X) =

T
t=1
p(yt |X,y<t ). (10)
At each decoding time step, the decoder will combine the input text and the output in the previous time steps to generate the current result. Finally, a text sequence with the highest probability is
generated. For example, in the machine translation system, X might be a source Chinese sentence
and Y might be an target English sentence, while in the dialogue system, X might be the query and
Y might be the response, without considering other additional information in the generation process. On the basis of general text generation, the CTG models fuse additional condition to generate
more anthropomorphic text. We define various kinds of CTG fields as follows:
Definition 3.1 (Context-Based Text Generation). Integrating contextual information during text
generation to enhance the understanding of environmental state to produce more coherent and
informative text content.
The contexts of natural language refer to the situations they are generated, which are the key
factor to ensure consistency and smoothness of the generated text. Given a set of contexts C =
{ci}i=1,2,...,Kc , each contextci may be a text sequence, a simple word, a sentiment score, and so on,
and Kc is the number of context types. The context-based text-generation model can be defined as
follows:
p(Y |X,C) =

T
t=1
p(yt |X,C,y<t ). (11)
Take human conversation for example, C refers to the historical dialogue content in multirounds conversation. The daily dialogue process of human beings usually lasts for several rounds.
The historical dialogue content in the multi-rounds dialogue is one kind of context information,
and we will generate responses based on the historical dialogue to keep the conversation consistent. While in the advertisements writing scenario, C refers to various types of information about
specific product, such as its brand, function, price, and so on, and may also be information about
user preferences. Only by integrating multi-kinds of contextual information can more appealing
advertisements be generated.
Definition 3.2 (Personalized Text Generation). Assigning specific personalization characteristics
to the text-generation agents to produce personalized text contents that fit the given personalization characteristics.
Personalization means that everyone has characteristics different from others, which will subtly influence how and what we express ourselves. Given a set of personalized characteristics
S = {si}i=1,2,...,Ks , each si represents age, gender, profession, or other characteristics, and Ks is
the number of personalized characteristics types. The personalized text-generation model can be
defined as follows:
p(Y |X, S) =

T
t=1
p(yt |X, S,y<t ). (12)
Similarly, take dialogue as an example. People of different genders and ages have different views
on the same thing, so the personalized characteristics S will have an impact on the dialogue content. When writing commodity description advertisements, it is necessary to combine the personalized features S of users, such as age, gender and shopping preference, to generate descriptions more in line with users’ expectations. Therefore, to make the text-generation agent more
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:10 B. Guo et al.
personified, it is necessary to assign specific personalized characteristics to generate text content
conforming to the personalized information.
Definition 3.3 (Topic-Aware Text Generation). Incorporating a specific topic in the process of text
generation to make the whole text content suitable for the topic and ensure the coherence and
rationality of the generated text.
Natural language text has very strong internal relevance, especially in long text. A piece of text
usually aligns around a specific topic, so considering topic information can generate more coherent
and meaningful text. Given a set of topic words T = {ti}i=1,2,...,Kt , each ti is a topic word and Kt
is the number of topic words. The topic-aware text-generation model can be defined as follows:
p(Y |X,T ) =

T
t=1
p(yt |X,T,y<t ). (13)
When we write an article, we usually expand our thinking according to a specific topicT , such as
maternal love, to ensure the logical consistency and consistency of the whole article. In the process
of foreign language translation, it is necessary to combine the topic of the whole text content, to
get a more fluent and consistent translation around the central topic. Combining topic information
is a key factor to ensure logical coherence and compact semantics in text generation.
Definition 3.4 (Emotional Text Generation). Embodying the emotional expressions of the agents
in the process of text generation, such as positive or negative, happy or sad, to adjust the content
and expression style of the generated text.
Emotion is a very important attribute of natural language, and people usually have certain emotions in daily communication or writing. Different emotions have important effects on what is
being expressed. For example, when we are angry, we usually say something that is not rational or hurts others. Incorporating emotion into text generation can make the generated content
more personified. In dialogue systems, it has a direct and quantifiable impact on product usability
and user satisfaction when considering specific emotions. Given a specific emotion category E,
which may be anger, sadness, joy, and so on, the emotional text-generation model can be defined
as follows:
p(Y |X, E) =

T
t=1
p(yt |X, E,y<t ). (14)
Definition 3.5 (Knowledge-Enhanced Text Generation). Embracing external knowledge, such as
search engine or knowledge base to provide factual basis and reference of the generated content
in the text-generation procedure.
Human has a wealth of prior knowledge, and can flexibly combine our own knowledge in communication, translation or writing to express ourselves. Combining external knowledge in the
text-generation system can make the generated text more informative, more consistent with the
logic of human expression, and reduce the possibility of common sense mistakes. Given a set of
knowledge facts F = {fi}i=1,2,...,Kf , each fi is a text sequence (also called free-text knowledge) or a
knowledge triple from knowledge graph (also called structured knowledge), and Kf is the number
of knowledge facts. The knowledge-enhanced text-generation model can be defined as follows:
p(Y |X, F ) =

T
t=1
p(yt |X, F,y<t ). (15)
When we are asked a specific question, we will combine our knowledge to understand and
reason the question, and find the corresponding answer to reply. For example, the question “What
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:11
Fig. 1. The example of conditional dialogue system.
is the capital of China?” can be answered by combing geographical knowledge “Beijing is the
capital of China.” The combination of knowledge is the key factor to ensure the real humanization
of text-generation system. Only through the interaction and expression of knowledge with the
real world, can text-generation agent be truly integrated into our daily life.
Definition 3.6 (Visual Text Generation). Integrating the semantic information in images into generated text, such as generating text descriptions according to image contents, or answering questions about given images.
Data in our life is multi-modal, including not only text but also images, sounds, and so on. We can
automatically extract the information contained in the image and translate it into understandable
natural language. Images can vividly depict external events and our psychological activities, so
visual text generation has a rich application prospect. Given an image I, the visual text-generation
model can be defined as follows:
p(Y |X, I) =

T
t=1
p(yt |X, I,y<t ). (16)
Having formalized the various kinds of CTG, a real-life actual example, the dialogue system
incorporating several conditions, is shown in Figure 1. In this example, different conditions are
considered to enhance the performance of the dialogue agent. The personalized characteristics S
are two descriptive sentences about the work and preferences of the agent, and the knowledge
facts F is a text paragraph about the content of physics in high school, while the context C is
the historical dialogue. The whole topic T of this conversation is “High school teaching,” and the
emotion E inside the dialogue is “Feeling proud.” Based on these conditions, the dialogue agent
can generate more relevant, personalized, substantial, and context-consistent responses.
We will discuss the technical details of implementing various kinds of CTG fields in the following sections. At present, most text-generation models are based on the encoder-decoder structure,
in which the encoder transforms input sequences into semantic vector representations, and the
decoder generates outputs according to the input information, such as dialogue responses, and
product reviews. Applying constraints of conditions in different parts of text-generation models,
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:12 B. Guo et al.
including encoders, decoders, and their interaction modes, has been widely studied. In the encoding stage, external conditions can be encoded by various techniques, such as RNN and Transformer,
and served as the input of the decoder together with the original input to control the generation
process. The decoder can be modified by weighted decoding [46] or other technologies to control
the decoding procedure to increase or decrease the probability of words with certain conditions.
Meanwhile, the attention mechanism or RL can enhance the interaction mode of the encoder and
decoder, to mine the implicit and deep semantic information in conditions. In short, only considering from multiple aspects including the encoder and decoder to integrate different conditions,
can CTG systems produce content with higher quality and personification to provide us with more
comfortably services.
3.2 Text-generation-based Human-Centric Services
Text-generation technology has a wide range of application scenarios in daily life. It is an ongoing
effort of the academic/industry researchers to use various text-generation technologies to provide
human-centric services, presented as follows.
Goal-oriented dialog systems. The dialogue systems are the most typical applications of text
generation, which can be divided into goal-oriented and non-goal-oriented systems. Goal-oriented
dialogue systems assist human to fulfil various tasks to reduce our operational burden, such as
restaurant reservation, and travel time arrangement. In addition, goal-oriented dialog systems can
also help companies accomplish specific businesses, such as customer transactions in a bank. According to Lauren Foye,7 banks can automate up to 90% of their customer interaction using dialog
systems by 2022. Apple Siri,8 Microsoft Cortana,9 Google Assistant,10 and Amazon Alexa11 are all
typically frequently used goal-oriented dialogue systems in our daily life. Siri is the first virtual
assistant with a voice deployed in Apple devices to assist human to operate smartphones, which
was born of this desire to make our interactions with computers more human-like, while Microsoft
Cortana is the virtual assistant created by Microsoft for Windows 10, Windows Mobile, and all of
Microsoft’s integrated hardware. Google assistant is a smart personal assistant similar to Siri but
can deploy on a wide range of devices, including android phones, android TV, wearable devices,
and so on. Take Siri as an example, we will introduce the detailed technical workflow of it.
On all IOS devices, we can say “Hey Siri” to invoke Siri hands-free. A very small speech recognizer runs all the time and listens for just those two words. When it detects “Hey Siri,” the rest of
Siri parses the following speech as a command or query. The overall working flow chart of Siri is
shown in Figure 2.
The input command of Siri passes through four stages for processing altogether. The first stage
is speech recognition, where the “Hey Siri” detector uses a DNN to convert the acoustic pattern of
our voice at each instant into a probability distribution over speech sounds. It then uses a temporal
integration process to compute a confidence score that the phrase we uttered is “Hey Siri.” If the
score is high enough, then Siri wakes up. After having collected and subsequently converted our
command into a file, Siri sends it to Apple servers for processing. Once in the Apple servers,
our spoken words undergo different flowchart branches to arrive at a possible solution. The third
stage is to understand the meaning of the command using NLP technologies. Apple servers run
NLP algorithms such as tokenization and named entity recognition, on input text to understand
7https://www.juniperresearch.com/press/press-releases/chatbots-a-game-changer-for-banking-healthcare. 8https://www.apple.com/siri/. 9https://www.microsoft.com/en-us/cortana/. 10https://assistant.google.com/. 11https://developer.amazon.com/en-US/alexa/.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:13
Fig. 2. The overall working flow chart of Siri.
the intent of what the user is trying to say. For instance, the NLP engines can differentiate that
when a user is saying “set an alarm for 7 a.m. tomorrow,” the user is asking about setting an alarm
and not about making a call. Finally, Siri communicates with other apps on the phone to provide
the desired deliverable response to us in voice.
Chatbots. The non-goal-oriented dialogue systems, also known as chatbots, can communicate
with humans normally in the open domain. Instead of completing specific tasks, chatbots engage
in chatty conversations with humans and perform like a real person as much as possible. Chatbots
provide us with a realistic and interactive dialogue experience and establish certain emotional
connections with us. In recent years, with the emergence of a large amount of dialogue data and
the breakthrough of machine learning applied to dialogue AI, intelligent dialogue systems have
achieved gratifying results in the academia and industry. Microsoft XiaoIce12 is one of the most
popular social chatbots in the world that has made conservations with hundreds of millions of users
and successfully built long-time emotional connections with them. Zhou et al. [165] describe the
development of the Microsoft XiaoIce system to provide some guidance for chatbot researchers,
which will be briefly summarized below.
XiaoIce is based on an empathic computing framework that enables chatbots to recognize human emotions and states, understand users’ intentions, and respond dynamically to users’ needs.
Integration of IQ, EQ, and Personality is core to XiaoIce’s system design. IQ capacities include
knowledge and memory modeling, image and natural language understanding, reasoning, generating, and predicting. These are the foundations for developing conversational skills that allow
chatbots to meet the specific needs of users and help the user accomplish specific tasks. EQ refers to
the need for chatbots to be emotionally intelligent enough to produce socially attractive responses
(e.g., having a sense of humor, comforting, etc.), and to be able to decide to drive a conversation to
a new topic when it comes to a standstill, or to actively listen when the user engages in the conversation. Personality is defined as the characteristic set of behaviors, cognitions and emotional
patterns that form an individual’s distinctive character. Social chatbots need to hold a consistent
personality and set the right expectations for the user during a conversation to gain users’ longterm confidence and trust. The overall framework of XiaoIce is shown in Figure 3.
12http://www.msxiaobing.com/.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:14 B. Guo et al.
Fig. 3. The overall framework of XiaoIce.
After receiving the information from users, the system will use Dialogue Management (DM)
module to manage the whole dialogue process, in which the Global State Tracker is responsible
for updating the system status. The Global State Tracker utilizes Contextual Query Understanding (CQU), User Understanding (UU), and System Understanding (SU) module, respectively, to
integrate the dialogue context, users’ characteristics, and system state for accurate system state
capturing. Then the Dialogue Policy module decides the following dialogue strategy according to
the updated dialogue status, that is, whether the query is to be answered by the Core Chat or a
certain skill.
The Core Chat is designed for open domain conversation, which is divided into General Chat
and Domain Chat. General Chat mainly answers general questions, while Domain Chat focuses
on answering professional questions in the particular domain. The main realization technique of
chitchat is the combination of retrieval model and sorting model, in which the retrieval model
generates candidate response sets, and the sorting model sorts the candidate responses to output
the response with the highest score. In addition to the Core Chat, XiaoIce also has a number of
constantly updated skills, including Image Commenting, aiming to generate comments based on
user input images, and Content Creation, accomplishing creative work such as poetry creation
and story generation.
Question Answering. In addition to the dialogue systems, the Question Answering (QA) system, providing corresponding answers to users’ different questions, is another typical application
of text generation. The QA system needs to find relevant content through search engines or knowledge bases to organize the corresponding answers, which may relate to commonsense facts or details about specific events. Dehghani et al. [31] propose a QA model, called TraCRNet, to achieve
the goal of open-domain query answering. The TraCRNet model reasons to correctly answer the
question by utilizing information of multiple documents extracted from a search engine that includes not only the high-ranked web pages but also the low-ranked web pages that are not directly
related to the question.
Machine translation. With the development of economic globalization, the world has become
a small village where people from all over the world can communicate with each other via the
Internet. As a result, translation becomes an essential requirement for better communication with
each other. Machine translation systems also provide researchers with the opportunity to exchange
ideas with researchers around the world, enabling scientific researches to develop more rapidly and
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:15
Fig. 4. The model architecture of GNMT.
vigorously. Google translate13 is a free translation service offered by Google. It provides instant
translation between 80 languages and supports the translation of words, sentences, and web pages
between any two languages. According to statistics, Google translate translates over 100 billion
words every day, which is one of the most popular translation software in the world. The Google
Translation team puts forward the Google Neural Machine Translation system (GNMT) [139] for
the first time in 2016, which consists of a deep LSTM network with eight encoder and eight decoder layers using residual connections as well as attention mechanism. The model architecture
of GNMT is shown in Figure 4.
The GNMT is a typical sequence-to-sequence learning framework with the attention mechanism, composed of an encoder, a decoder, and an attention network. The encoder encodes the input sentence into vector representations, and the decoder generates one word at a time according
to the current states. The attention mechanism allows the decoder to focus on the important information in the source sentence to build the connection of the encoder and decoder. With a large
amount of paired translation data for training, GNMT can achieve excellent translation performance. Meanwhile, to solve problems in neural network model training, Google proposes a lot of
training tricks to improve the performance of the model. The low-precision arithmetic is employed
in the inference computations to accelerate the final translation speed, the length-normalization
procedure and coverage penalty are employed in the beam search technique to encourage the output sentence to cover all the words in the source sentence. The words in the input and output
are divide into a limited set of common sub-word units (“wordpieces”) to balance the flexibility
of “character”-delimited models and the efficiency of “word”-delimited models for improving handling of rare words.
After the GNMT system, Google proposes the Transformer model for the machine translation
task, which completely abandons the common network structure in RNN, and only adopts the attention mechanism to carry out sequence modeling. After that, Transformer has become a standard
structure for many NLP tasks, giving a big boost to the development of the NLP field.
Product review and advertisement generation. Due to the large number of product reviews
in the shopping websites, writing reviews for products may puzzle customers and waste their time.
Fortunately, based on the information of a given product and the rating of the review, reviews can
13https://translate.google.com/.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:16 B. Guo et al.
be automatically generated by the review generation technology, providing references for other
customers. Ni et al. [100] build an assistant system for helping users to write reviews. This model
expands the contents of input phrases and conforms to users’ personalized aspect preferences
to generate diverse and smooth product reviews. At the same time, writing specific advertisements for vast products is also a time-consuming task, particularly when we want to generate
personalized ads for each consumer. The personalized advertisement-generation technology can
automatically generate well-suited product description according to different selling points and
user preferences/traits. It not only provides great convenience for consumers but also for sellers.
Chen et al. [18] propose a personalized product description-generation model by leveraging neural
networks combined with the knowledge base.
Text summarization. In recent years, the volume of text data from various sources has exploded. Text summarization systems help people quickly understand the main content of information and improve the efficiency of information acquisition. According to Radef et al. [105], a
summary is defined as “a text that is produced from one or more texts, that conveys important information in the original text(s), and that is no longer than half of the original text(s) and usually,
significantly less than that.” The purpose of a text summarization system is to produce a concise
and fluent summary of the source articles while retaining key information content and overall
meaning. Nallapati et al. [99] first introduce the attentional encoder-decoder architecture into text
summarization system, and achieve the state-of-the-art performance, which provides the direction
for the follow-up research works.
Data storytelling. There is a lot of structured data in real life. Computers are good at analyzing
structured data, while humans are more inclined to read complete stories rather than a jumble of
data. Therefore, how to make use of structured data to create more personified stories is a key
research direction of text generation. Data storytelling is the key technology to achieve this goal,
whose typical applications include news report generation, company report generation, sports
event report generation, and so on. News report-generation systems can produce complete, meaningful, and reasonable news according to the time, place, cause, process, and other factors of the
specific news event, while sports report-generation systems can generate detailed game reports
according to the situation of sports events. Narrative Science14 is a text report-generation company
whose purpose is to give life to data. It is dedicated to the research of automatic text-generation
technology, which can automatically generate a high-quality text after a planning process based
on the key information in the data and its expression in the machine.
Image captioning and visual QA. Text information is just one way for human to obtain information, while we are more likely exposed to image information in real life. Image captioning
technology can automatically generate corresponding text description according to the content of
images, to facilitate readers to better understand image contents. Feng et al. [39] train an unsupervised image captioning model to generate image captions without the paired image-sentence
datasets. Visual QA is another interactive point between text generation and image understanding.
By understanding image content and corresponding questions at the same time, visual QA technology can generate answers of questions related to the images. Li et al. [70] convert visual QA
question into a machine reading comprehension problem combined with the large-scale external
knowledge base to realize the knowledge-based visual QA.
With the rapid development of NLP technology, it is ubiquitous to find the usage of textgeneration technology in our daily life. Nevertheless, text generation has been far from mature.
For example, it is still easy to find out whether we talk to a real person or a chatbot, which means
that an obvious gap still exists between robots and human beings. CTG is the key factor to solve
14https://narrativescience.com/.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:17
Table 2. A Summary of Context-based Text-generation Methods
Work Method Description
Sordoni et al. [121] Context embedding
Embedding all the words and phrases in the dialogue
history into continuous representations as additional
inputs of the decoding stage
Voita et al. [131] Context embedding
Encoding the source and the context sentence
separately and learning the context-aware
representation of the source sentence through
the attention mechanism
Serban et al. [113] Hierarchical context
embedding
Embedding the word sequences in each context
sentences at the low-level and embedding the
sentence sequences in the historical dialogues at the
top-level to efficiently capture the
context information
Xing et al. [141] Hierarchical context
embedding
Leveraging the attention mechanism to extend the
HRED model
Jaech et al. [56] Context Adaption
Using the context information (dialogue history) to
transform the weights of recurrent units in RNN to
effectively capture high-dimensional context
this problem, which aims to generate the high quality and anthropopathic textual content. In this
article, we will study different types of conditional text-generation fields.
4 MAJOR RESEARCH AREAS
After introducing the definition and application scenarios of CTG, in this section, we make a detailed investigation of different CTG fields, including context-based text generation, personalized
text generation, topic-aware text generation, emotional text generation, knowledge-enhanced text
generation, and visual text generation. Furthermore, we summarize the multi-conditional textgeneration and pre-trained language model-based CTG works.
4.1 Context-based Text Generation
In many applications of text generation, the context information is the key factor to realize the
coherence and smoothness of the generated text. The context means the situations in which natural
languages are generated. In dialogue systems, the context usually refers to the dialogue history that
has taken place in multi-rounds dialogues. The ability to consider previous utterances is the core
to build active and engaging dialogue systems [16]. Meanwhile, in review-generation systems,
the context refers to the time, emotions, sentiments and other factors. The context information
provides clues to the generation of natural language [123]. Therefore, to generate high quality text,
it is necessary to consider the context information in CTG. We give a brief summary of contextbased text-generation methods in Table 2.
Context embedding. The most simple and effective way to combine context information is to
embed it directly to get the vector representations as a part of the decoder input, so that context information can be considered in the generated text. Among the numerous tasks of contextbased text generation, the utilization of context in dialogue systems attracts great attention of
researchers. For instance, Sordoni et al. [121] embed all words and phrases in the dialogue history into vector representations. Dialogue history information is encoded into vectors, which are
decoded by another RNN to produce context-aware responses. In addition to the dialogue system, other applications also need to add different types of context information. Tang et al. [123]
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:18 B. Guo et al.
define the context as the information or situations that may influence the output content. The encoder encodes the contexts information (e.g., a sentiment score, a product ID or a user ID) into
continuous semantic representations and concatenates them as the input of the decoder. During
decoding, the context information are attended through a gating mechanism to generate contextsensitive product reviews. Similarly, Clark et al. [24] propose a text-generation model in stories,
which treats entity representations extracted from dialogue history as context. By encoding the
historical conversations together with the entity representations as context, the model can better
determine which entities or words to be mentioned next.
When considering the context information in machine translation systems, multiple sentences
can be treated as a whole, and relevant information between sentences can be captured, which
not only prevents errors in the case of ambiguity but also improves the consistency of translation.
Voita et al. [131] propose a context-aware machine translation model that can control and analyze
the flow of information from context to the translation model. The source sentence needed to be
translated and the context sentence are encoded separately to get the context-aware representation
of the source sentence through the attention mechanism. It is identified that pronoun is the key
information captured by the model. In the field of machine translation, Kang et al. [58] proposed
to select contextual sentences dynamically for each source sentence to be translated. The Context
Scorer module is used to score each context sentence based on the currently translated source
sentence and incorporate important context sentences into the translation module.
Hierarchical context embedding. Instead of embedding context information directly, hierarchical context embedding method divides the embedding process into two steps to capture information in context more effectively. Concretely, the first step is to embed the word-level information, and the second step is to embed the sentence-level information. Serban et al. [113] use
Hierarchical Recurrent Encoder-Decoder (HRED) model to hierarchically encode the dialogue history and guide the generation of replies. In particular, the word sequences in each context sentence
are encoded at the low-level, while the sentence sequences in the historical dialogues are encoded
at the top-level. Xing et al. [141] leverage the attention mechanism to extend the HRED model.
By incorporating attention mechanism at the words and sentences level, respectively, the model
captures the most important parts in the context. Zhang et al. [150] observe that we can have more
smooth conversations without much context information in the multi-user dialogue, and produce
a tree-based hierarchical multi-user dialogue model, which builds a tree structure consisting of
many branches for multi-user conversations to select exact context sequences. Besides, Tian et al.
[124] conduct a comprehensive survey on existing context-aware conversational models and find
that compared with the non-hierarchical model, the hierarchical model is more capable for capturing context information.
Context adaption. The context adaption method changes the model itself rather than regarding
context as an extra input of CTG model. For example, Jaech et al. [56] utilize the context information to transform weights of the recurrent layer in RNN. In particular, they utilize a low-rank
decomposition algorithm to control the degree of parameter sharing in context, which performs
well on high-dimensional and sparse context.
VAE-based methods. How to ensure the coherence of context in the generation of long-form
text (e.g., a single or multiple paragraphs) is a challenging problem. Both high-level abstract features (e.g., topics, sentiments, etc.) and low-level fine-grained features (e.g., specific word choices)
should be considered to generate globally coherent long text sequences. Traditional RNN models tend to generate repetitive and inconsistent long-form text due to the poor feature extraction
ability, while VAE models based on deep latent variables can capture these high-lever features to
generate coherent and high-quality long text. For example, Shen et al. [117] propose a VAE-based
multi-level network structure for CTG, which contains a multi-level decoder to capture coherent
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:19
Table 3. A Summary of Personalized Text-generation Methods
Work Method Description
Li et al. [71] RNN + Speaker model
The speaker model encodes each individual speaker into
a vector to capture characteristics; Generating personal
responses matching a specific user
Luan et al. [84] Autoencoder + Multi-task
learning
Training a response-generation model on a small
personalized dialogue data, and then training an
autoencoder model with non-conversational data;
Sharing parameters of the two models to obtain the
personalized dialogue model
Yang et al. [145] Transfer learning +
Pretrain and fine-tuned
Respectively, using massive generic dialogue data and a
small-scale personalized dialogue data to pre-trained
and fine-tune the dialogue model to generate
personalized responses
Yang et al. [144] Reinforcement Learning +
Persona embedding
Embedding user-specific information into vector
representation; RL mechanism optimizes three rewards –
topic coherent, informative and grammatical, to generate
more personalized responses
long-term structure inherent in long-form text by generating high-level intermediate representations of input sentences. Meanwhile, multiple stochastic layers are used between VAE’s encoder
and decoder to generate more semantically rich latent variables for producing more coherent and
less repetitive long text. Shao et al. [116] first design a sequence of groups, and subsequently generate each sentence conditioned on the planning result and previously generated context sentences.
A hierarchical latent structure containing global planning and local sequence latent variables is
used to improve the diversity of the generated text.
4.2 Personalized Text Generation
Various human characteristics significantly impact interpersonal communication and writing
styles. In other words, personalization plays a key role in enhancing the quality of CTG model.
In dialogue systems, personalization is vital for creating truly smart dialogue agents that can be
seamlessly incorporated into the lives of human beings. In product review-generation systems,
personalization ensures the generated product review depends not only on the attributes of the
product but also on the preferences of specific users, endowing the authenticity for the generated
reviews. Many efforts for personalized text generation are conducted, as summarized in Table 3,
and we will discuss them in details below.
Personalized feature embedding. The simplest method to achieve personalized text generation is to embed the personalized characteristics of different users. Li et al. [71] present a speaker
model that encodes user profile into vectors to capture personalized features and guide the response generation during the decode stage. Instead of encoding personalized features into vector
representations directly, Herzig et al. [52] use an additional neural network to capture the highlevel personalized information based on the personality traits. The additional layer implicitly influences the decoding hidden state to ensure that the personalized features are integrated into
the generated text. Li et al. [72] propose the User-aware Sequence Network (USN), to generate a
summary for a user’s review according to his preference on different aspects or writing style. The
user-aware encoder selects the user-concerned information in a review, and the user-aware decoder combines user characteristic and user-specific language habits into word generation. Zheng
et al. [159] propose a trait fusion module to capture the persona information of each speaker. Each
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:20 B. Guo et al.
persona trait is encoded into vector representation and all traits are merged to get the integrated
persona vectors. The persona aware attention mechanism controls the attention weights of the
context vector and the persona-aware bias estimates the word-generation distribution. Luo et al.
[86] build a personalized goal-oriented dialog system for the restaurant reservation task. The profile model encodes user profiles into vector representations and storages conversation history from
similar users. The preference model captures user preferences over knowledge base entities and
combines with the profile model to enhance the performance in terms of task completion and user
satisfaction. To improve the personality consistence of the generated dialogue responses, Song
et al. [118] propose the generate-delete-rewrite mechanism to delete inconsistent words from a
generated response prototype and further rewrite it to a personality-consistent one.
Multi-task and transfer learning. The personalized text datasets are so scarce that the above
models are difficult to perform very well. Some researchers attempt to enhance the performance of
personalized text generation by transfer learning and multi-task learning models. For instance, the
work of Luan et al. [84] trains a dialogue model to predict responses given previous contexts and
an autoencoder model with large volumes of non-conversational personal data to model the rolespecific characteristics of different users. Through the multi-task learning mechanism that shares
the decoder parameters of the two models, these models can capture speaker roles, expressive
styles and domain expertise characteristic of the targeted user and generate personalized responses
without heavy recourse to each speaker’s conversational data. Yang et al. [145] propose a domain
adaptation-based personalized dialogue model. They, respectively, use massive generic dialogue
data and a small-scale personalized dialogue data to pre-trained and fine-tune the dialogue model,
and apply the policy gradient algorithm to improve the personalized and informative features of
generated responses. Similarly, Zhang et al. [152] put forward the Learning to Start (LTS) model to
optimize the quality of responses, which divides the training process into initialization (modeling
the responding style of human) and adaptation (generating personalized responses) for generating
relevant and diverse responses.
GAN and RL models. Our writing style can be perceived by his specific word usage manners,
which means different language habits can reflect our personalized characteristics. Yuan et al.
[149] propose a personalized sentence-generation model based on GAN. In the training procedure, the frequently used words are incorporated as the input sources. Then the sentence structure is constrained to generate sentences similar to the original sentences of the same author. RL
can control the quality of generated content through different policies or rewards, so researchers
consider incorporating it to implement personalized text generation. Yang et al. [144] present the
attention-based hierarchical encoder-decoder architecture via RL to realize personalized dialogue
generation, which defines three types of reward mechanisms, including topic coherence, mutual
information, and language model to force the text-generation model to generate topic-relevance
and coherent dialogue responses.
VAE-based methods. The above embedding-based personalized text-generation methods learn
user information from training data and cannot discover the common properties among users.
User-level features can also be depicted through latent variables, so VAE-related models are introduced into personalized text generation. Wasserstein Auto-Encoders (WAE) is a typical VAE
variation, which conducts adversarial training on latent variables, instead of assuming that latent
variables subject to a simple Gaussian distribution to fit the real data distribution and improve the
generation ability of VAE. Chan et al. [14] embed and mix the user-level and sentence-level information into multimodal latent distributions. The mixed distribution is then regarded as the prior
distribution of WAE, and extended to the Gaussian Mixture Distributions to guide the decoder
to generate personalized responses for different users. To generate product tips with personalized features of users, Li et al. [77] present the Persona-Aware Tips-generation model (PATG),
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:21
Table 4. A Summary of Topic-aware Text-generation Methods
Work Method Description
Xing et al. [140] RNN + LDA + Topic
embedding
Utilizing LDA to get topic information, and embedding
the topic words into the vector; Generating more
informative, and topic relevant responses
Dziri et al. [35] HRED + LDA + Topic
embedding
Combining topic and context information to produce not
only contextual but also topic-aware responses
Wang et al. [133] CNN + LDA + RL
Using LDA to get topic information, CNN to capture the
dialogue information, and RL to optimize the model with
specific evaluation metric; Generating coherent, diverse,
and informative text summaries
Feng et al. [38] RNN + Topic
embedding
Assigning each topic with different weight to maintain a
multi-topic coverage vector and updating them in the
decoding process in order
which employs adversarial variational auto-encoders to model the persona information of different users. The persona information is distilled from all historical tips and reviews of a target user
and expressed by the latent variables in VAE. An external memory-based Pointer Network is also
deployed to conduct the memory reading to retrieve more accurate persona information.
4.3 Topic-aware Text Generation
Topic information is indispensable in our daily communication, reading or writing. We usually
have a conversation around a specific topic and usually identify the topic of an article before we
read or write it. In this subsection, we give a review of topic-aware text-generation studies, as
presented in Table 4.
Topic extracting and embedding. It is a common idea to extract topic information from existing text and embed it into vector representations to guide text generation. Xing et al. [140] propose
a topic-aware Seq2seq (TA-Seq2Seq) model to generate informative and interesting responses for
chatbots. TA-Seq2Seq incorporates topic information of the dialogue history extracted by the pretrained LDA model with the input sentence, and utilizes the joint attention mechanism to guide the
generation process. Choudhary et al. [23] observe that topic information can be divided into multiple domains (e.g., games, sports or movies) to provide the fine-grained guidance for the generator.
They adopt domain classifiers to capture domain information from the dialogue history for generating domain-relevant responses. Feng et al. [38] develop a multi-topic-aware LSTM (MTA-LSTM)
model to generate a paragraph-level text under target multiple topic words. In the MTA-LSTM
model, each topic will be assigned with different weights to maintain a multi-topic coverage vector, which is updated in the decoding process in order. Then the vector will guide the generator
to generate the topic-aware text with an attention module. A long article usually spans many topics, while a simple text summary usually cannot cover all topics. To generate text summaries of
specific topics of interest to users, Krishna et al. [67] propose to generate multi summarizations
for a given article according to different topics. With an article and a topic of interest as input, the
proposed pointer-generator network will pay higher attention to the relevant parts of the topic
in the input article to generate topic-tuned summarizations. Dziri et al. [35] introduce a Topical
Hierarchical Recurrent Encoder Decoder (THRED) model to generate contextual and topic-aware
responses. THRED hierarchically encode the dialogue history in the word and sentence level, respectively, and capture topic information from dialogue context using a pre-trained LDA model.
In the decoder, the generation probability is biased toward generating topic words by adding an
extra probability to the original generation probability.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:22 B. Guo et al.
CNN-based methods. The above studies mostly employ the RNN model in the task of topicaware text generation. In addition to RNN, several other models are also applied to this task,
which also achieve remarkable results. For instance, Wang et al. [133] propose a topic-aware convolutional Seq2seq (ConvS2S) model, which leverages the joint attention and biased probabilitygeneration mechanism for incorporating topic information. Word and topic embeddings of the
source sequence are encoded by the associated convolutional blocks. Then the joint attention
mechanism attends to words and topics according to the decoder states, and the biased probability generation is performed to generate coherent, diverse, and informative summaries.
VAE-based methods. The latent variables in VAE can capture features implicitly in natural language, which is useful for providing high-level guidance to text generation. If latent variables correspond to a specific topic, then the probability distribution of generated words will be narrowed
down, thus improving the rationality of generated content. Consequently, the VAE is widely used
in topic-aware text generation. For instance, Wang et al. [135] propose a topic-guided variational
autoencoder (TGVAE) method to generate natural language text under the guidance of the designated topic. Specifically, TGVAE generates a Gaussian mixture model (GMM) for latent variables
as the prior distribution, which is parametrized by a neural topic module responsible for capturing
long-range semantic information in the whole document. Each mixture component corresponds
to a specific topic, which guides to generate semantically meaningful sentences under the given
topic. Gao et al. [42] propose a neural variational language model to study the topic-level Gaussian
distributions in latent space. They utilize CNN to get the vector representations of input sentences
and predict the Gaussian distribution of topics using the full connection layer. By sampling the
topic distribution, the proposed model can generate diversified sentences conditioned on given
topics. In previous works of text generation based on VAE, the distribution of latent variables is
usually assumed as Gaussian distribution, which makes it difficult to distinguish which part of
latent variables controls the structure and which part controls the semantics of natural language.
To solve this problem, Li et al. [75] develop the TATGM model, which adopts a sequential VAE
to learn the structural features of text and a topic model to extract the semantic features of text
to generate different expressions of the same structure in different topics. TATGM’s topic model
generates text based on the Gaussian distribution of latent variables, which ensures the capture of
textual semantic information. At the same time, the encoder acts as a discriminator to force the
decoder to generate the text with similar semantics.
4.4 Emotional Text Generation
Natural language is full of emotions, and emotional words are more likely to stimulate the interest
of readers. Additionally, people adjust their speaking style and content according to their own
and other people’s emotional changes in daily communication. Due to the necessity of integrating
emotional information, researchers pay attention to incorporating emotional information into the
generated text to provide users with better experience, as summarized in Table 5.
Emotion extraction and embedding. One common way to generate emotional text is to extract emotional information from input text and embed it into vector representations as the input
of the decoder. Asghar et al. [4] propose an LSTM-based emotional dialogue-generation model with
three designed mechanisms to incorporate affective/emotional aspects into generated responses.
The affective word embeddings introduce an external cognitively engineered affective dictionary
to augment traditional word embeddings with affective vectors. The affective loss functions minimize the Euclidean distance between the affective embeddings of inputs and responses, and maximize the affective content of responses to explicitly train an affect-aware model. The affectively
diverse beam search injects affective dissimilarity across the beam groups based on affective word
embeddings to promote the generation of emotionally rich responses. Zhou et al. [162] produce
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:23
Table 5. A Summary of Emotional Text-generation Methods
Work Method Description
Zhou et al. [162] GRU + Emotional
embedding
Emotion category embedding captures emotional
information and the internal emotion memory
balances the grammaticality and the expression
degree of emotions
Fu et al. [40] GRU + Multi-task
learning
Multi-decoder Seq2seq module generates outputs with
different styles and style embedding module augments
the encoded representations
Kong et al. [66] Conditional GAN (CGAN)
+ Sentiment control
The generator generates sentimental responses based
on a sentiment label and the discriminator
distinguishes the generated replies and real replies
Li et al. [74] RL + Emotional editor
The emotional editor selects the template sentence
based on the topic and emotion, and RL forces the
model to enhance the coherence and emotion
expression of generated responses
the Emotional Chatting Machine (ECM) to generate grammatically correct, context-relevant and
emotionally consistent responses. The ECM leverages emotion category embedding for capturing
high-level abstraction of emotion expressions, an internal emotion state for balancing grammaticality and emotion dynamically, and an external emotion memory to help generate more explicit
and unambiguous emotional expressions. Majumder et al. [88] consider that emotional responses
often mimic the emotion (positive or negative) of the user. The emotion stochastic sampling and
emotion mimicry mechanism are proposed to encode context and emotions to generate appropriate and empathetic responses.
Emotion transferring. In addition to embed emotional information directly, the transfer from
one emotion to another is a promising way to generate emotional text. Fu et al. [40] achieve the
goal of transferring the emotion of reviews from positive/negative to negative/positive through
multi-task learning and adversarial training. They leverage a style embedding module to augment
the language style representations and a multi-decoder Seq2seq model to, respectively, generate
text with different styles. Luo et al. [85] propose the Seq2SentiSeq model, which adopts the Gaussian
Kernel layer to incorporate the numeric sentiment intensity value into the decoder, to finely control the sentiment intensity of generated text. At the same time, the cycle reinforcement learning
algorithm controls the process of model training, which balances both sentiment transformation
and content preservation through the elaborately designed rewards to tackle the problem of lacking parallel data.
GAN and RL models. Several works confirm that GAN and RL have significant effects on emotional text generation. For example, Wang et al. [132] propose the SentiGAN with multiple generators and one multi-class discriminator to enhance the sentiment accuracy and quality of generated
texts. In the SentiGAN, multiple generators are trained simultaneously to generate texts with different sentiment labels, such as positive or negative, and the multi-class discriminator makes each
generator focus on generating its own examples of a specific sentiment label accurately. Kong
et al. [66] introduce a conditional GAN (CGAN)-based sentiment-controlled dialogue-generation
model. The generator of CGAN produces sentimental responses under the given dialogue history
and sentiment label, while the discriminator identifies the quality of generated responses through
checking whether the items (e.g., dialogue history, sentiment label, and dialogue response) belongs
to the real data distribution. Li et al. [74] propose the emotional editor module to select the template sentences according to emotion and topic information in the dialogue history, and introduce
RL to promote the quality of generated responses from three points: emotion, topic and coherence.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:24 B. Guo et al.
Table 6. A Summary of Knowledge-enhanced Text-generation Methods
Work Method Description
Ghazvininejad
et al. [45]
Keyword matching + Facts
embedding
The Facts Encoder module leverages an external
memory for embedding the conversation-related
facts to generate content-rich responses
Dinan et al. [32] Transformer + Memory
Network
Memory Network retrieves knowledge about the
dialogue from the memory and Transformer
encodes and decodes the text representations to
generate responses; Conducting knowledgeable
discussions on open-domain topics
Zhou et al. [163] Knowledge graph attention
Graph attention mechanisms integrate
commonsense information from the knowledge
based on the dialogue history; Generating more
appropriate and informative responses
Mazumder et al.
[93]
Lifelong learning +
Open-world knowledge
base completion
Obtaining new knowledge by asking users when
facing unknown concepts and then inferencing to
grow knowledge over time
VAE-based methods. Utilizing latent variables of VAE to control the sentiment of generated
text has also been explored by researchers. For example, Hu et al. [55] combine VAE and holistic
attribute discriminators for effective imposition of semantic structures. They allocates one dimension of the latent representation to encode “positive” and “negative” semantics, to capture a salient
attribute independent with other features. The global discriminators facilitate effective imposition
of latent code semantics to guide the discrete text generator learning. Chen et al. [17] endow the
poetry generator with the ability to express the specific sentiment (e.g., negative and positive), to
improve the semantics and diversity of generated poems. Since sentiments are often strongly coupled with semantics in poetry, the authors make latent variables conditioned on both sentiment
and text content to capture generalized sentiment-related semantics. Besides, a temporal sequence
module captures sentiment transition patterns among different lines of the poetry to generate diverse poems under the control of semantic-level and line-level sentiments.
4.5 Knowledge-enhanced Text Generation
Nowadays, most text-generation systems take advantage of deep neural network models to generate fluent, semantic and consistent text. However, there is still a big gap between such machinegenerated text and human expression, that is human will combine their knowledge in speaking or writing, while most text-generation systems fail to achieve this. By combining sufficient
knowledge, such as commonsense knowledge and information about specific objects/events, CTG
systems can generate more logical, credible, and informative text. The external knowledge includes structured knowledge graph (KG), which is composed of knowledge triples with the form
of <head,relation,tile >, and unstructured knowledge base (KB), which is composed of natural
language text about specific concepts. There are many ways to combine external knowledge in
CTG systems, as summarized in Table 6, and we will introduce them in details below.
Unstructured KB enhanced models. Unstructured KBs contain abundant knowledge with textual form. How to extract the knowledge related to input and combine it into the generation stage
are main directions of current research. The common way to extract knowledge from unstructured
KB is keyword matching with each word in the input as keywords. For instance, Ghazvininejad
et al. [45] extract relevant knowledge facts from knowledge base using keyword matching and
encode them into vectors to provide factual evidence for the dialogue response generation. To
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:25
extract relevant knowledge more effectively, Ren et al. [110] propose to use the global perspective for selecting appropriate knowledge. A topic transition vector is obtained from the context to
express global information and then used to guide the local knowledge extraction process for generating informative and fluent text. Zhao et al. [157] separate parameters relying on knowledgegrounded dialogues in the whole model to get better results with insufficient knowledge-grounded
dialogue data. In the decoder stage, the Language Model generates common words, the Context Processor module generates context words, and the Knowledge Processor module generates words from
knowledge document by a hierarchical attention mechanism. The decoding manager fuses the generation probability of three modules, and dynamically switches the decoding mode according to
decoding states, to generate context-relevant, informative and reasonable responses.
After extracting the relevant textual knowledge, the next most important thing is to understand its semantics and integrate it into the text-generation process. Young et al. [147] transform
the extracted knowledge triples into a sequence tokens and encode them into vector representations using LSTM. The context vectors and knowledge vectors are concatenated to calculate
match scores with different responses to select the most appropriate response. Wang et al. [136]
build a technical-oriented dialogue system to communicate with people about Ubuntu-relevant
questions. The knowledge text descriptions are embed into vectors by word embedding average
or BERT model, which are concatenated with traditional word embeddings to enhance the understanding of the technical term in dialogue history. A knowledge reader attentively read knowledge
embeddings and retrieve the semantic information at each decoding stage to generate informative
responses. In addition to RNN, Dinan et al. [32] combine Transformer and Memory Network to
build an open-domain knowledge-based dialogue system. The Memory Network retrieves related
knowledge from the Internet according to the input as the knowledge memory. Each sentence in
the memory is independently encoded with a Transformer encoder, and the same Transformer
is used to encode the dialogue context. The standard dot-product attention between the memory
candidates and the dialogue context is performed to select knowledge sentences to be used, which
are served as the input of the decoder to generate knowledgeable responses.
Due to the powerful performance of Transformer, more and more researchers begin to use it
for knowledge understanding. Zhao et al. [156] introduce the hierarchical interaction between the
context and external document knowledge to capture the most important parts in the document
and context using the multi-head attention module in Transformer for selecting the most appropriate response. Li et al. [78] generate vector representations of external knowledge using the multihead attention mechanism and then incorporates them to encode knowledge utterances span in
the multi-turn dialogue. The decoder first generates contextual coherence responses attending on
the context information and then refines them by attending on the knowledge vectors to generate
more informative response. In knowledge-enhanced dialogue systems, there can be one-to-many
relations between the dialogue context and the knowledge, which makes the knowledge selection
is diverse and difficult. Kim et al. [62] propose to keep track of the prior and posterior distribution over knowledge using laten variables to improve the knowledge selection accuracy. Through
sequentially modeling the history of knowledge selection in previous turns, the scope of probable knowledge candidates at current turn is reduced. The posterior distribution over knowledge
leverages the response information to select knowledge more accurate.
Structured KG enhanced models. Knowledge graph is a kind of structured knowledge
base, which describes physical entities and their connections accurately. As its name suggests,
knowledge graph is also helpful to build knowledge-enhanced text-generation systems. Wang
et al. [134] propose an entity linking module to decide the optimal entity in the input question
for selecting knowledge triples from external KG, which will be encoded as common words by
the LSTM. The similarity scores of the question and relation candidates are calculated to select
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:26 B. Guo et al.
the most appropriate triples for question answering. The TranE algorithm [9] is proposed to
transform structured triples into low dimensional vector representations and is widely used
in knowledge-enhanced text-generation systems. Moussallem et al. [98] link knowledge facts
based on the translated document, encode them into vectors by TransE, and concatenate them
with the internal vectors of NMT embeddings as the decoder input to enhance the quality of
generated translations. Gune et al. [49] extract entities from external KG and adopt TransE to
get vectors of them. The knowledge vectors are then fed into the separate multi-head attention
channel to generate coherent text summaries. The attention mechanism is also applied in learning
knowledge form knowledge graphs, which is called graph attention. Guan et al. [48] present an
incremental encoding schema to mine hidden information in the story context and graph, and
a contextual attention mechanism to encode knowledge graph into vectors. The multi-source
attention mechanism is used to comprehensively understand the content of stories to generate
reasonable and consistent story endings. Zhou et al. [163] produce a knowledge-based dialogue
model (CCM) that leverages two graph attention mechanisms to promote dialogue understanding
and knowledgeable responses generating. The static graph attention module encodes the graphs
relevant to the dialogue history and concatenate graph vectors with input vectors to enhance the
semantic information of the input. The dynamic graph attention module attentively reads all the
knowledge graphs and all triples in each graph based on decoder states to adaptively choose a
generic word or an entity from the retrieved graphs for word generation.
To generate text with more entities, Moon et al. [97] propose the DialKG Walker model that
learns the symbolic transitions of dialog contexts as structured traversals over KG, and the graph
decoder that attends on viable KG paths to predict the most relevant entities in the KG, by associating these entities with the dialogue context and entities mentioned in the previous turn.
Koncel et al. [65] study the problem of generating paragraphs with multiple sentences given only
a short title. The Graph Transformer model computes the hidden representations of each node in
a graph by attending over its neighbors following a self-attention strategy to leverage the relational structure of knowledge graph. The decoder attends on encodings of the knowledge graph
and document title using the decoder hidden state to generate informative texts. Chen et al. [19]
propose a data-to-text-generation model, which extracts entities appear in the data field and links
them to Wikidata as external knowledge to form the temporary memory. The dual attention mechanism is applied to generate words conditioned on both input table information and background
knowledge fact information. To consider the dialogue context in the knowledge retrieve process,
Wu et al. [138] design a Felicitous Fact mechanism to help the model focus on the knowledge facts
that are highly relevant to the context.
GCN [64] is an extension of CNN in the graph domain, which can effectively learn the structural information of nodes and edges in the knowledge graph. De et al. [30] regard the question
answering problem as the graph inference problem. Nodes in this graph correspond to named entities in a document whereas edges encode relations between them (e.g., cross and within-document
coreference links or simply co-occurrence in a document). The entity graph relates mentions to
entities within and across documents, the document encoder obtains representations of mentions
in context, and the relational GCN propagates information through the entity graph to generate
correct answers.
Continuous learning models.Although existing studies introduce some real-world knowledge
to CTG systems, the knowledge is usually fixed and cannot be expanded or updated. Continuous
learning in the interactive surroundings is an important capability of human beings. We keep
on learning and updating our knowledge according to our experiences in the daily life, which
should be considered as an important factor when building humanoid text-generation systems.
Mazumder et al. [93] build a knowledge learning model, namely, lifelong interactive learning and
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:27
Table 7. A Summary of Visual Text-generation Methods
Work Method Description
Vinyals et al.
[130] RNN + CNN
Encoder CNN captures information in images, and
decoder RNN generates neural language descriptions
based on their features
Malinowski et al.
[89] LSTM + CNN
CNN and LSTM, respectively, encode the image and
the question into vectors to capture the semantic
information, and then another LSTM generates
corresponding answers
Dai et al. [26] Conditional GAN
(CGAN)
CNN captures information in an image, and LSTM
generates the relevant descriptions; the discriminator
evaluates the quality of generated descriptions
Das et al. [28] Memory Network
Embedding the image, historical dialogue, and given
question, respectively, to consider the image and
dialogue context information in conversation
inference (LiLi), enabling chatbots to interactively and continuously learn new knowledge when
communicating with users. By mimicking humans to acquire knowledge, Lili enquires ask users
for related items when facing unknown concepts and then infers to expand knowledge over time.
4.6 Visual Text Generation
Since people usually gather information from images, visual text generation is also an important
research direction in text generation. Two of the most important applications are image captioning
and visual QA. A summary of visual text-generation methods is given in Table 7.
Combining CNN and RNN. To capture the information in images and generate natural language text, combining CNN and RNN is the main solution for visual text generation. Vinyals et al.
[130] achieve the goal of automatically viewing an image and generating the reasonable description utilizing the encoder-decoder structure. The encoder CNN captures information in the image,
and the decoder RNN generates the text description. Due to the heavy loss of image information
causing by the high-dimension structure of CNN, Xu et al. [142] propose an image caption model
utilizing attention mechanism to extract the most important information in images to generate
more accurate and detailed image description. Malinowski et al. [89] combine CNN with LSTM to
answer questions about the given image. They utilize the CNN to capture the related information
in the image about questions, and an LSTM to generate answers based on latent representations
of the image and question. Zhu et al. [166] build a semantic relationship between text descriptions
and regions in the image by object-level grounding to generate answers of questions correspond
with specific image regions.
Memory Network-based models. Instead of simple single-round visual QA, Das et al. [28] implement a visual dialogue system to communicate with users in multiple rounds about a given
image. They put forward the task of Visual Dialogue and publish a large-scale Visual Dialogue
dataset called VisDial.15 Three novel encoders are designed for the visual dialogue task, in which
the Late Fusion module encodes the image, historical dialogue and the given question, respectively,
the Hierarchical Recurrent Encoder module encodes the dialogue history in the sentence level and
the Memory Network module stores the former QA pair as the “fact” to offer factual basis for the
latter responses generation.
15https://visualdialog.org/.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:28 B. Guo et al.
GAN-based models. Different from the above works, Dai et al. [26] leverage the conditional
GAN (CGAN) model to generate high-quality image descriptions in three aspects, including naturalness, semantic relevance, and diversity. They jointly learn a generator to produce descriptions
conditioned on images and an evaluator to assess how well a description fits the visual content
with the criteria of natural and semantically relevant.
VAE-based methods. In image captioning, it is important to ensure the lexical and syntactic
diversity of generated captions. Chen et al. [15] propose the Variational Multi-modal Inferring
tree (VarMI-tree) to model the lexical and syntactic diversities by inferring their latent variables in
an approximate posterior inference guided by a visual semantic prior. Conditioned on the visual
features and the latent variables, diverse captions of given images are generated. Previous works
usually generate latent variables for entire input sentences, ignoring information about the substructures in the sentences. Aneja et al. [1] develop the SeqCVAE model, which learns a latent space
for every word to capture the “intention” about how to complete the sentence. The data-dependent
transition model captures the “intention,” a representation of the remaining part of the sentence
by encoding them with a backward LSTM, to generate more diverse captions.
4.7 Multi-conditional Text Generation
We have summarized existing works of CTG under a single condition, but in practice, these conditions often act simultaneously on the text-generation system to produce more reasonable and
anthropomorphic content. For example, in daily conversations, generation models usually consider the context information, personality characteristics of the interlocutor, and abundant external knowledge to generate reasonable responses. Therefore, considering the hybrid of different
conditions is essential for improving the quality of CTG systems.
Emotion is an inherent attribute of natural language. Explicit emotion modeling and combining
other conditions can improve the naturalness and humanness of the generated content. To realize
emotional text generation, it is necessary to first detect the emotions contained in the textual content. Based on the observation that people usually express emotions rely on conversation contexts
and external knowledge, Zhong et al. [160] propose to interpret the contextual utterances and
leverage the external commonsense knowledge to enhance the emotion detection performance.
The hierarchical self-attention and cross-attention modules are used to abstract contextual information and the context-aware affective graph attention is used to leverage knowledge to facilitate
the understanding of context and emotion detection in conversations. Kao et al. [59] develop the
chatbot that will change emotions according to the conversation context with users. Through the
sentiment recognition model, the dialogue agent can provide the robot’s emotions as feedback
while talking with a user. Peng et al. [103] believe that topics, like emotions, are important factors
in dialogue systems, which can ensure the semantic coherence of the whole conversation. They
develop the Twitter Latent Dirichlet Allocation (LDA) model to detect the topic words of the input sentences as the prior knowledge, and the dynamic emotional attention mechanism to obtain
the content and affective information related to the input texts and additional topics. To generate
recommended reason text of specific items for users in recommender systems, Bai et al. [7] fuse
aspect sentiment and external knowledge for recommended reasons generation. The fine-tuned
BERT model is applied to get the aspect and aspect sentiment polarity from the reviews. The aspect
fusion module fuses aspects and the item title, and the knowledge fusion module fuses relevant
knowledge by the bi-directional self-attention module to generate personalized and content-rich
recommended reasons. Zhong et al. suggest that persona plays an important role in empathetic
conversations, and first present a novel large-scale multi-domain dataset for persona-based empathetic conversations [161]. Based on this dataset, they propose an efficient BERT-based response
selection model, CoBERT, using multi-hop co-attention to learn higher-level interactive matching.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:29
External knowledge can provide guidance for any CTG system to improve the system’s understanding of conditions and generate more informative texts. For instance, Chen et al. [18] introduce a Knowledge-based Personalized (KOBE) product description-generation model, which fuses
product aspects, user categories, and knowledge base to generate informative and personalized
product descriptions. The self-attention modules in Transformer are used to encode the product
attributes, the relevant knowledge, and the specific user categories into semantic vector representations, and perform deep semantic interaction to capture semantic features for the decoder. Yang
et al. [143] fuse external knowledge into topic-to-essay-generation systems to provide background
information for essay generation. The memory-augmented neural model selects knowledge concepts and then stores them into a memory matrix. The decoder then attends the memory to guide
the text generation and updates it according to the decoder states to generate topic-consistent and
informative essays.
The generation of natural language text is usually influenced by many factors, so the combination of multiple conditions is a promising research trend of CTG systems. By considering
the appropriate context, combining accurate knowledge, expressing specific emotions, and
conforming to unique personalized characteristics, text-generation systems can generate more
anthropomorphic texts.
4.8 Pre-trained Language Model-based CTG
The idea of pre-training has been widely explored in NLP. By pre-training the model on large-scale
text corpus to initialize most of the network parameters, which learn universal knowledge about
syntactic and semantic information of neural language text, and fine-tuning the model using a
small amount of specific downstream task data, excellent performance can be achieved. The pretrained language models are first introduced into NLP for word embedding [96]. Using a large
amount of data to train the LSTM language model in an unsupervised way, the contextual word
vector of each word can be obtained to demonstrate strong results across discriminative natural
language understanding (NLU) tasks [94, 104].
Recent pre-trained language models based on large Transformer architectures prove the ability
of both big models and big data to improve language representation and generation performance.
Transformer is gradually replacing the mainstream position of LSTM in NLP. Among numerous
works, the BERT model [60] and the GPT model [106] receive the most attention. BERT learns bidirectional representations of massive textual data by conditioning on both the forward and backward sequential contexts. Just adding a specific output layer rather than adjusting the model’s
structure, the pre-trained BERT model can be fine-tuned to achieve the state-of-the-art performance in many NLU tasks, such as text classification. Subsequently, a lot of work is done to optimize the pre-training process of BERT to further improve the ability of language representation,
among which the most typical work includes XLnet [146], RoBERTa [81], and ELECTRA [25].
In terms of unconditional natural language generation, the GPT models are regarded as starting
points for pre-trained natural language generation due to its form of standard language model for
text-generation tasks. GPT adopts the typical pre-training and fine-tuning training framework,
with Transformer decoder as the feature extractor. In the pre-training stage, the training task is
the unidirectional language model to encode language knowledge into the decoder, while in the
fine-tuning stage, parameters of the pre-training model are fine-tuned according to specific tasks.
Considering that supervised fine-tuning of the pre-training model with data of specific domains
will reduce the generalization ability of the model, GPT-2 [107] and GPT-3 [11] remove the supervised fine-tuning stage of GPT and directly use massive training samples for zero-shot training.
For all NLP tasks, GPT-3 with 175 billion parameters shows impressive performance without any
gradient updating or fine-tuning.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:30 B. Guo et al.
Designing a pre-trained model for natural language-generation tasks that often adopt Seq2seq
frameworks with attention mechanism, is highly potential and critical. In addition to the GPT series that only contain Transformer decoders, researchers also explore the Seq2seq pre-training for
unconditional text generation to jointly train encoders and decoders for better generation performance, including MASS [120], UniLM [34], BART [68], T5 [108], and so on. For example, MASS
combines the pre-training of encoder and decoder to reconstruct a sentence fragment, which masks
a piece of tokens of input sentences randomly in the encoder and predicts the masked tokens in
the decoder. The joint training process improves the ability of feature extraction and language
modeling, which can achieve promising generative performance with zero-shot or few-shot finetuning on task-specific data. More and more researches show that pre-trained language models
are of great value in text-generation tasks.
After exploring the great potential of pre-trained language models for text generation, CTG
powered by pre-trained language models has become a promising research direction. Based on
the powerful generation ability of pre-trained language models, text-generation models can be
better at controlling the expression of conditions and generating more personified text under specific conditions. The most straightforward way to incorporate pre-trained language models to CTG
systems is to modify the model architecture for extra conditional inputs or condition-specific finetuning. Mao et al. [90] perform intermediate fine-tuning on the story data to adapt the pre-trained
GPT-2 model to the domain of stories, and then fine-tune on the target story-generation dataset
with a multi-task learning objective to generate grammatical and stylistic consistency stories. An
auxiliary training signal is used to provide common sense grounding for generated stories, which
constrains the model to rank sensible text with lower perplexity. Keskar et al. [61] propose to add
a mention, namely, control codes specific to each type of text (e.g., “books” for novel-type texts),
to the input text and include one at the beginning of each text during the pre-training phase. By
this means, the Conditional Transformer Language (CTRL) model learns the relationship between
the control codes and the text that follows to determine the generated text under the desired condition controlled by the specific code. Considering that large pre-trained transformer models are
sensitive to large parameter changes during fine-tuning, Ziegler et al. [167] choose to adapt the pretrained language model to arbitrary conditional inputs. The pseudo-self-attention module learns
a task-specific encoder, which injects learned encoder conditioning directly into the pre-trained
self-attention of the model. Because of the arbitrary length of the input sentence, these additional
conditional inputs can be injected into the pre-trained model without changing the model architecture to affect the generated text. Chen et al. [21] leverage the idea of model distilling for
better text-generation performance. The Conditional Masked Language Modeling (C-MLM) task
is proposed to enable pre-trained BERT with additional conditional input by randomly masking
tokens only in the target sequence. In the knowledge distillation stage, the generated sequences
of word logits by the teacher BERT model contains information from both backward and forward
contexts, providing sequence-level global guidance. This probability distribution is soft targets for
the student text-generation model to mimic, which contains more useful and fine-grained conditional information. To leverage the redundant external knowledge under capacity constraint, Zhao
et al. [158] propose a pre-trained language model-based response-generation model with a knowledge selection module, which formalize knowledge selection as a sequence prediction process.
The knowledge selection and response-generation module are jointly optimized with unlabeled
dialogues to endow a generative model with both rich knowledge and good generalization ability.
Above CTG works based on pre-training language models need to adjust the model structure
or fine-tune the model with the data under specific conditions, entailing the significant cost of retraining. The Plug and Play Language Model (PPLM) [29] allows anyone to flexibly plug in one or
more simple attribute models representing the desired control objective into a large, unconditional
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:31
LM. Instead of training a large language model from scratch, PPLM trains smaller attribute models
to influence the generated results of the existing ones, such as GPT-2. Attribute models are responsible for estimating the probability that a text sequence x with a specific attribute α (e.g. Positive or
Negative). By maximizing the probability of the generated sequence x with the desired attribute α,
the generated sentence has the pre-defined conditions. Considering that PPLM still requires large
amounts of labeled texts to effectively balance generation fluency and proper conditioning, Carbone et al. [12] leverage topic models to enhance PPLM with an unlabeled collection of documents.
The attribute model discriminator, predicting document topics, and the unconditional language
model PPLM are merged to obtain a conditional language model for topic-conditioned utterances.
To equip the dialogue model with multiple skills (e.g., emphatic response, weather information,
etc.) without retraining the whole dialogue model, Madotto et al. [87] propose the Adapter-Bot,
which triggers different skills via different Adapters trained independently. The backbone of the
Adapter-Bot is a pre-trained conversational model such as DialoGPT [154], providing the ability
of response generation. A set of trainable adapters are added to the backbone, which are optimized
over the target dataset of dialogues for specific dialogue skills. Using the trained dialogue manager
to select the right dialogue skill under the dialogue story, Adapter-Bot shows high-level control
over the chatbot.
To generate text under more precise conditions in the word-level and phrase-level rather than
just high-level conditions such as topic and sentiment, Chan et al. [13] propose the ContentConditioner (CoCon) model to control the generated text under the guide of target text content
at a fine-grained level. The encoder and decoder of the model are pre-trained by GPT-2, and the
CoCon block incorporates the target content into the encoded text representation before passing
the content-conditioned representations into the decoder for generation. By self-supervised training without labeling data, CoCon can produce high-quality text with content. Zhang et al. [155]
explore the problem of generating text from a given set of lexical constraints. Given lexical constraints, the proposed POINTER model generates high-level words (e.g., verbs and adjectives) as
the keywords constrains, then inserts other words of finer granularity around the keywords iteratively until the whole sentence is generated. The training objective of POINTER is to generate
a complete text sequence with a set of keywords as constraints, which is similar to the masked
language modeling (MLM) objective in BERT, so pre-trained BERT is used to initialize the model
training to boost the generation performance.
The latent variables in the VAE model can capture higher-level sentence representations, such
as topics, semantics, and patterns, to facilitate CTG. To combine VAE’s powerful ability in the
pre-training language model, Li et al. [69] propose the OPTIMUS model, the first large-scale pretrained deep latent variable models. OPTIMUS includes two stages: pre-training and fine-tuning.
In the pre-training stage, the sentence-level (variational) auto-encoder objectives are trained on
large text corpus to construct a universal latent space for reorganizing sentences. In the fine-tuning
stage, by representing labeled specific tasks’ data in the pre-trained latent space, OPTIMUS finetunes the latent space by updating all/part of the parameters to adapt to the downstream tasks.
Specially, for the stylized response-generation task, through embedding the history, response, and
style-reference into the joint latent space to fine-tune OPTIMUS, the generated responses are closer
to the desired text style.
With sufficient pre-training on huge text corpora, large pre-trained language models have
shown impressive language understanding and language-generation ability. Researches of CTG
leveraging pre-trained language models have also attracted more and more attention, as summarized above. How to integrate conditional information into pre-training language models more
effectively and reduce the cost of retraining is the important future research direction.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:32 B. Guo et al.
4.9 Decoding Strategies for CTG
We have made a detailed investigation of different CTG fields above, such as context-based text
generation and topic-aware text generation. Meanwhile, the hybrid of different conditions and pretrained language models applied in CTG systems are also been discussed. In summary, previous
works focus on modifying the encoder, or the interaction mode between encoders and decoders
to fuse conditional information into the text-generation process. In the decoding stage, different
decoding strategies can have a huge impact on the quality of the generated text. Researchers have
proposed several decoding strategies to improve the quality of generated contents, e.g., reducing
repetitive words or phrases. Through straightforwardly restricting the probability distribution of
different words during the decoding stage under specific conditions, high-quality content with
specific conditions can be generated by CTG models. In this section, we will introduce several
universal decoding strategies, such as Beam Search and Top-k Sampling, and then summarize some
improved decoding strategies proposed for CTG, including Weighted Decoding and Unlikelihood
Training.
Beam Search. Due to the large number of words in the vocabulary, the number of possible sequences in generation is enormous, so researchers propose some heuristics to reduce the searching
space thus making the generation practical. Beam Search is a most commonly used decoding strategy in text-generation models recently. It approximately maximizes the likelihood of the whole
generated sequence given a hyper-parameter β, known as beam size. In the first decoding time
step, β words with the highest conditional probability are selected as the first words of the candidate output sequence. For each subsequent time step, additional words will be attached to β output
sequences of the last time step, in which the β sequences with the highest conditional probability will be selected. The optimal generated sequences are determined from the final β candidates
with the highest conditional probability. Beam Search greatly reduces the time and space requirements for searching in the text-generation process by limiting the beam size. However, since only
β sequences are selected at each time step, the final generated content may not be optimal.
To overcome shortcomings of Beam Search, many improved methods have been proposed. For
example, Vijayakumar et al. [128] propose the Group diverse Beam Search to increase the variety
of generated texts, which divides the beam into groups and utilizes a group dissimilarity penalty to
reduce the similarity between different search groups. Similarly, Li et al. [73] propose the Sibling
diverse Beam Search that contains a penalty proportional to the rank of a candidate token to
encourage preserving hypotheses from diverse sources within the beam.
Top-k and Top-p sampling. The goal of sampling-based decoding strategies is to reduce repetitions and increase the diversity of the generated content, by utilizing stochastic decisions in
the generation process. The Top-k sampling [37] samples from the next-token distribution after
having filtered this distribution to keep only the top k tokens, while the Top-p sampling [53], also
known as nucleus sampling, samples from the top tokens with a cumulative probability just above
a threshold p.
The above decoding strategies are aiming at making the distribution of generated words similar
to the distributions of words in human-generated texts at a higher level. Meanwhile, many studies
focus on decoding strategies serving for specific conditions, to make CTG systems more effectively
fuse the conditional information, which will be discussed below.
Weighted Decoding. Weighted Decoding [46] is a typical decoding strategy that increases or
decreases the probability of words under certain conditions. Ghazvininejad et al. [46] propose an
interactive poetry-generation system, which enables users to edit and polish generated poems
by adjusting from different aspects (e.g., sentiment, alliteration, etc.). In the tth decoding step, a
partial hypothesis y<t = y1,...,yt−1 is expanded by calculating the generation score for the next
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:33
word w:
score (w,y<t ; x) = score (y<t ; x) + loдPRNN (w|y<t, x) +

i
wi ∗ fi (w;y<t ; x). (17)
loдPRNN (w|y<t ) represents the generative log-probability of the wordw and score (y<t ; x) is the
accumulated generation score of all generated words. The fi (w;y<t ; x) refers to decoding features
with corresponding weights wi . A decoding feature assigns a real value to the generation probability of word w, to control the weights of generated words under different conditions. Weighted
Decoding considers 8 types of features to control the generated content, including topical words,
emotions, and so on. Instead of manually designing calculation formulas of decoding features as
additional items of the decoding objective function, Holtzman et al. [54] train a number of discriminative models to construct a more powerful generator under different aspects of conditions, each
of which encodes an aspect of high-quality generation to enhance the generation performance of
the original RNN generator. The decoding objective function is formalized as follows:
fλ (x,y) = loд(Plm (y|x)) +

k
λksk (x,y). (18)
This objective is composed of the traditional RNN language model probability loд(Plm (y|x))
and additional scores sk (x,y) calculated by designed discriminators with learned mixture coefficients λk . Four discriminators are proposed to discriminate between good and bad generations
(e.g., Repetition Model for avoiding word repetitions, Relevance Model for guaranteeing contextual relevance of the generated content, etc.) and are interpolated in the objective function as log
probabilities. The weight coefficient of each discriminator is optimized to minimize the difference
between the scores assigned to the gold continuation and the continuation predicted by the current model. Similarly, Baheti et al. [6] incorporate topic and semantic similarity constraints into
the decoding objective of dialogue systems to encourage the generation of more topic-relevant
and content words in responses. To match the distribution over topics in generated responses and
input, the HMM-LDA model is applied to estimate topic distributions over words in responses
and inputs to compute their topical similarity. The semantic similarity constraints are designed to
encourage generated responses to be semantically similar to inputs.
Weighted Decoding is a useful technique in conditional text generation, which can force the
expected conditional features to appear in the generated text by assigning them a high generation
probability. However, when the weight of the specific feature is too large, Weighted Decoding risks
going off-distribution, thus generating unanticipated words [112].
Unlikelihood Training. The standard approach of training neural text-generation models is to
maximize log-likelihood and approximately decoding the most likely sequence, which is known
to have fatal defects. The likelihood training will force the model to generate common words with
high frequency, making the generated text dull, and to repeat themselves at word and sentence
level. To solve these problems, Welleck et al. [137] optimize the unlikelihood training objective
for training text-generation models more efficiently. The key idea of unlikelihood training is to
decrease the generation probability of certain tokens, making incorrect repeating tokens less likely
and frequent tokens less likely, thus forcing repetitions to have low probability and improving the
quality of generated text.
Considering that existing dialogue systems tend to generate frequent words and repetition
words, Li et al. [76] first incorporate unlikelihood training into dialogue systems to regularize
generated outputs to match human-written distributions. Three different biases needed to be
mitigated are considered, including repetition and copying, vocabulary usage, and contradictions.
The first two biases are mainly responsible for reducing the occurrence of repeated words and
high-frequency words, and the bias of contradictions is designed to assign low probability to
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:34 B. Guo et al.
Table 8. A Review of Conditional Text Datasets
Dataset Type Description
Cornell Movie Dialogs [27] Context-based
dataset
A multi-turn dialogue dataset extracted from raw
movie scripts
Ubuntu Dialogue Corpus [82] Context-based
dataset
A multi-turn dialogue dataset extracted from
the Ubuntu chat logs
PERSONA CHAT [151] Personalized
dataset
A personalized dialogue dataset where two parts
of every conversation are given a group
of profile information
Humeau et al. [92] Personalized
dataset
A profile-based dialogue dataset; Extracting
personalized characteristics from users’ posts in
REDDIT
TaoDescribe [18] Personalized
dataset
A personalized product description dataset
including product basic information, in which
each pair is labeled with knowledge and user
category attributes
Empathetic Dialogues [109] Emotional dataset An emotional dialogue dataset where each
conversation is under a given emotion
EmotionLines [20] Emotional dataset An emotional dialogue dataset in which all
utterances are labeled with emotions
CMU DoG [164] Knowledge-based
dataset
A document grounded conversation dataset where
each conversation are about contents of a
specified document
Wizard of Wikipedia [32] Knowledge-based
dataset
A knowledge-grounded dataset with
conversations directly grounded with knowledge
retrieved from Wikipedia
Zhou et al. [163] Knowledge-based
dataset
A commonsense conversation dataset containing
one-turn post-response pairs with corresponding
commonsense knowledge graphs
VisDial [28] Visual dataset A Visual Dialogue dataset where all queries and
answers are based on the given image
inconsistent and contradictory utterances. Through dividing training samples into positive
and negative coherent behavior, the likelihood training is performed on coherent data, and the
unlikelihood objective is applied to the incoherent data to reduce the probability of generating
the context incoherent response.
Through unlikelihood training, text-generation models can force unlikely generations to be assigned lower probabilities, such as repetitive and dull text generation, to improve the overall quality of generated sentences. In summary, unlikelihood training has great potential for researches
of CTG systems. By controlling the probability of specific conditional features expressed in the
generated content, the efficient fusion of conditional information, and higher-quality conditional
text generation can be achieved.
4.10 Conditional Datasets
The training of CTG models needs the support of a large number of conditional text data, such as
emotional text data or personalized text data, but this kind of data is relatively scarce. To protect
researchers from data scarcity, many high-quality conditional text datasets have been released. We
give a brief summary of conditional text datasets in Table 8.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:35
Context-based datasets. Cornell Movie Dialogs16 [27] is a large-scale multi-turn dialogue
dataset providing contextual information during the conversation, which contains a large
metadata-rich collection of fictional conversations extracted from raw movie scripts. Ubuntu Dialogue Corpus17 [82] is another large multi-turn dialogue dataset containing almost one million
conversations extracted from the Ubuntu chat logs that is a great help for training context-sensitive
technical dialogue systems.
Personalized datasets. Zhang et al. [151] present a high-quality personalized dialogue dataset
named PERSONA CHAT.18 In each dialogue, two parts of the conversation are given a group of
profile information, and the whole dialogue process is conducted around these personalized characteristics. Humeau et al. [92] build an authoritative profile-based dialogue dataset using conversations collecting from REDDIT.19 The personalized characteristics are extracted from users’ social
posts, providing a new opportunity of personalized text generation for later researchers. Chen et al.
[18] provide a personalized and knowledge-based product description dataset named TaoDescribe,
collecting from Taobao,20 a large Chinese shopping website. There are more than two million pairs
basic information and descriptions of products, in which each pair is labeled with knowledge and
user category attributes.
Emotional datasets. Rashkin et al. [109] publish an emotional dialogue dataset called Empathetic Dialogues,
21 including an extensive set of emotions and every speaker in it feels with a given
emotion during conversations. Chen et al. [20] publish another high-quality emotional dialogue
dataset collecting from telescripts and dialogues in Facebook, named EmotionLines.22 All utterances in it are labeled with specific emotion according to textual contents to guide the emotional
dialogue response generation.
Knowledge-based datasets. CMU DoG23 [164] is a document grounded conversation dataset
where each conversation is followed by specified documents about popular movies extracted from
Wikipedia articles. Wizard of Wikipedia24 [32] is another open-domain dataset whose conversations are directly grounded with knowledge retrieved from Wikipedia. Zhou et al. [163] present
a commonsense conversation dataset25 containing one-turn post-response pairs with the corresponding commonsense knowledge graphs. Each pair in it is associated with some knowledge
graphs retrieved from ConceptNet,26 a typical structured knowledge graph.
Visual datasets. VisDial27 [28] is a large-scale visual dialogue dataset where all queries and
answers are based on the given image. Researchers can utilize it to research the visual text
generation.
4.11 Evaluation Methods Toward CTG
We have given a detailed investigation of different CTG fields and summarized some commonly
used conditional text datasets. Another key issue faced by researchers is how to evaluate the performance of these models and make fair and meaningful comparisons among them. Only with
16http://www.cs.cornell.edu/∼cristian/Cornell_Movie-Dialogs_Corpus.html. 17https://github.com/rkadlec/ubuntu-ranking-dataset-creator. 18https://github.com/facebookresearch/ParlAI/tree/master/projects/personachat. 19https://www.reddit.com/r/datasets/comments/3bxlg7/. 20https://www.taobao.com/. 21https://github.com/facebookresearch/EmpatheticDialogues. 22http://doraemon.iis.sinica.edu.tw/emotionlines/index.html. 23https://github.com/festvox/datasets-CMUDoG. 24https://parl.ai/projects/wizard_of_wikipedia/. 25http://coai.cs.tsinghua. edu.cn/hml/dataset/#commonsense. 26https://conceptnet.io. 27https://visualdialog.org/data.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:36 B. Guo et al.
the help of reasonable evaluation metrics, can researchers accurately evaluate the performance
of the designed models, to draw correct conclusions and promote applications of these models in
real life. Natural language-generation technology has made great progress in recent years, but the
reasonable evaluation of the generated text is still a challenging problem to be solved. At present,
researchers have not formed a unified theory on how to effectively evaluate text-generation systems [125], and the lack of reasonable quantitative evaluation metrics will prevent the development of this field. There are mainly two kinds of evaluation metrics at the present stage, namely,
automated evaluation metrics and human evaluation metrics, which will be summarized below.
4.11.1 Automatic Evaluation Metrics. Automated machine evaluation is an intuitive and convenient method to evaluate the quality of text-generation systems. The quality of the generated
text is determined by uniquely designed formulas that compare the difference between the generated text and the ground-truth text. Among various evaluation metrics of text generation, the
n-gram-based metrics are the most widely studied which calculate the word overlap under the
n-gram language unit between the generated text and ground-truth text. They are first applied
in machine translation systems by calculating the degree of word overlap between the translated
text and the target human-written references and then are widely used in the evaluation of many
text-generation systems. Typical evaluation metrics based on n-gram are summarized below.
BLEU. BLEU [102] is the harmonic mean of n-gram precisions of the generated texts with respect
to ground-truth reference sentences, where nϵ {1, 2, 3, 4}. The n-gram precisions refer to the proportion of the generated text that matches any n-gram unit in the reference sentences. Repeated
n-gram matches are clipped to the maximum number of times the n-gram occurs in any single
reference. BLEU contains many variants, such as SentBLEU [80], Δ BLEU [41], NIST [33], and so
on. NIST is a typical variant of BLEU, which improves BLEU’s evaluation accuracy by assigning
higher weights to low-frequency n-gram (e.g., more informative) and imposing length penalties.
ROUGE-L. Rouge-L [79] is calculated based on the length of the longest common subsequences
(LCS) between the generated texts and the target texts, where the common subsequence needs to
include the same words in the same order. Then the F-measure is calculated based on the maximum
precision and recall of reference texts to obtain the final ROUGE-L score, where the accuracy and
recall are calculated by dividing the length of LCS by the length of the generated text and the
reference text, respectively.
METEOR. METEOR [8] calculates the precision and recall of unigrams between generated texts
and reference texts. In addition to the exact word matching, fuzzy matching is adopted in the
calculation process based on the stem analysis and WordNet synonym. The matching degree is
calculated with multiple reference texts and the best-matching one is selected as the final METEOR
score.
CIDEr. CIDEr [127] is an evaluation metric designed for the image captioning task and can also
be used for other text-generation tasks. The CIDEr score is calculated by the average cosine similarity between the generated texts and the reference texts on the level of n-grams, where the importance of individual n-grams is calculated by the Term Frequency Inverse Document Frequency
(TF-IDF) measure.
The above evaluation metrics based on n-gram have been widely used in various text-generation
tasks, including machine translation, dialogue system, text summarization, and so on. However,
numerous studies have shown that the n-gram matching cannot capture semantic information
and effectively evaluate text-generation models. In some specific applications with little variation,
such as machine translation and question answering, metrics based on word-overlap of n-grams
have a higher evaluation accuracy. However, when reference texts have high diversity, such as
dialogue systems and text summarization systems, it is difficult to make effective evaluation using
these metrics.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:37
In addition to evaluating the relationship between the generated text and the reference text,
the characteristics of the natural language itself can also be used to evaluate the quality of textgeneration systems.
Perplexity. Perplexity [57] is a metric used to evaluate the quality of language models, which
measures the average number of uncertain words when predicting words. The smaller the number
is, the better the language model performance is. The fluency and diversity of generated text can
be evaluated based on perplexity.
4.11.2 Human Evaluation Metrics. Most of the automatic evaluation metrics can only measure
the quality of text-generation models based on the similarity degree between generated texts and
reference texts, but they cannot reflect the correctness, informativeness, naturalness, and other
internal characteristics of the generated content. Therefore, human intelligence is introduced into
the evaluation of text-generation systems to provide more reasonable and effective evaluation.
Human evaluation takes the form of the Turing test, which makes humans determine whether the
quality of the machine-generated text is high enough to distinguish it from real data.
Human evaluation is done either on the overall quality of the generated text or at the finergrained level, such as fluency, naturalness, informativeness, persona consistency, and so on. Because the conditions considered in CTG systems (such as topics, knowledge, and personalized features) are difficult to evaluate using automatic evaluation metrics, human evaluation is almost the
only and most effective way to evaluate CTG systems at the current research stage. For example,
in knowledge-enhanced text-generation systems, informativeness is a metric to measure whether
the system effectively combines external knowledge. Only when external knowledge is correctly
and reasonably integrated into the generation process, can more information-rich texts be generated. In personalized text-generation systems, the persona consistency metric is used to evaluate
whether the generated text conforms to the persona characteristics assigned to the text-generation
agent.
Human evaluation is the most effective gold standard for evaluating CTG systems. However,
due to the subjectivity of human, there is often a high degree of variation in the process of human evaluation [125]. In addition, human evaluation is usually expensive, which requires a large
amount of manpower to implement the evaluation process, and is not repeatable and costly. How
to design reasonable evaluation metrics to make the evaluation of CTG systems more reasonable
is still a challenging problem.
5 GENERAL LEARNING MODELS FOR CTG
We make a detailed investigation of various CTG fields under different conditions in above sections, which shows that combining different conditions can make the generated text more appropriate, informative and anthropomorphic. In this section, we attempt to address the CTG by distilling and presenting three different schemas of conditional generation models, including explicit
conditional modeling, implicit conditional modeling and conditional knowledge transferring.
The explicit conditional modeling directly regards external conditions as a part of input, allowing the generator to process the condition information in the same way as the input information.
This method is simple and efficient, which makes CTG systems easy to fuse the information of
conditions from a global perspective, to generate results that are more consistent with external
conditions. The implicit conditional modeling does not directly take conditions as input, but utilize specific algorithms, such as attention mechanism and RL, in the word-generation stage to mine
the implicit and deep semantic information in conditions, to make CTG systems more sensitive to
conditions. Considering that the lack of conditional data makes it hard to fully train deep learning models, the conditional knowledge transferring extracts general text knowledge from a large
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:38 B. Guo et al.
Fig. 5. General learning models for CTG.
amount of text data and transfers it to CTG systems to improve the performance of CTG systems.
The three general learning models mainly focus on how to fuse conditional information into the
language-generation process. Meanwhile, different decoding strategies can be applied to CTG systems to further control the appearance of certain conditions. Three general learning models for
CTG are shown in Figure 5.
5.1 Explicit Conditional Modeling
In CTG systems, different conditions are in the form of natural language text (except for the image
in the visual text generation), so taking them explicitly as a part of the input of the text-generation
system to enhance the input information is a straightforward method, known as explicit conditional modeling. In the same way that text-generation systems process input, the condition will
be transformed into vector representations by word embedding methods when the condition is a
single word, or encoded by an additional neural networks after word embedding when the condition is a text sequence. Then vector representations of conditions will be used as the additional
input information in the decoding stage to guide the text generation. Explicit conditional modeling
is a simple, straightforward and proven method to integrate external conditions in CTG systems,
without increasing the complexity of the model.
For example, in context-based text-generation systems, Sordoni et al. [121] regard the dialogue
history as the context information and embed all words and phrases in the dialogue history into
vector representations, which are then decoded by another RNN to promote context-aware responses. In personalized text-generation systems, Li et al. [71] propose persona-based models to
solve the problem of speaker consistency in dialogue systems. The Speaker Model maps each individual speaker into a vector by encoding speaker-specific information, such as age, gender, and
dialect, that may influence his/her speaking content and style. Then speaker vectors are injected
into decoder hidden layers to generate personalized dialogue responses. For knowledge-enhanced
text-generation systems, Ghazvininejad et al. [45] propose a knowledge-grounded dialogue model
to produce contenful and informative dialogue responses. Given the dialogue history, the relevant knowledge facts are extracted from knowledge base using words in the dialogue history as
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:39
keywords. Then the Facts Encoder module adopts Memory Network to encode facts into vector
representations based on the user input and dialogue history. This module enables the dialogue
system to deeper exploit inter-lexical dependencies between different parts of facts and the input
for effectively fusing knowledge into the generation process. Then both the encoded dialogue history and knowledge facts are fed into the decoder to generate context relevant and informative
responses.
5.2 Implicit Conditional Modeling
To capture the deeper semantic information contained in the condition, the condition information is not directly fed into the decoder after embedding, but interact with the decoding state at a
deeper level using additional algorithms, known as implicit conditional modeling. The attention
mechanism is a typical implicit condition modeling method, which can dynamically capture the
important part of the condition according to decoder states, to realize implicit condition modeling
and make the condition information guide the text-generation process more effectively. The RL
mechanism can give different rewards to actions of different states to give feedback on whether
specific conditions are reflected in the generated results. Therefore, RL is suitable for implicit conditional modeling. By penalizing results that do not reflect conditional information, the RL mechanism forces the model to consider more conditional information in generation.
For example, Zheng et al. [159] propose the persona aware attention mechanism to control the
attention weights of context vectors under integrated persona vectors and the persona-aware bias
to estimate the generation distribution for personalized dialogue responses generation. Zhou et al.
[163] produce two graph attention mechanisms, static graph attention and dynamic graph attention, respectively, to promote dialogue understanding and knowledgeable responses generating.
The model extracts relevant knowledge graphs using the entities in the input as keywords and
then encode graphs into static vector representations by the static graph attention module, which
considers all nodes and relations between nodes in a graph to encode more structural semantic
information. In the decoder stage, the dynamic graph attention attends the knowledge graphs and
knowledge triples in each graph to efficiently integrate information in knowledge graphs for informative response generation.
Li et al. [74] propose a RL-based dialogue model combined with an emotional editor module to
generate customizable emotional responses. The emotional editor selects the template sentence
according to the given topic and emotion to provide references for the generation process. The RL
mechanism constrains the quality of generated responses from three points: emotion, topic and
coherence, to generate emotional, topic-relevant and meaningful dialogue responses. The multitask learning is also introduced to enhance the model discrimination to learn the coherence, topic,
and emotion of a reply.
5.3 Conditional Knowledge Transferring
Compared with general text generation, CTG lacks available conditional text datasets. Although
researchers have released several conditional text datasets, it is generally not enough to train a
well-performing CTG system. By extracting general text knowledge from a large amount of text
data and transferring it to CTG systems, well-performing CTG systems can be trained in the absence of conditional data, known as conditional knowledge transferring.
For personalized text generation, Luan et al. [84] train a dialogue model to predict responses
given previous contexts and an autoencoder model with large volumes of non-conversational
personal data to model the role-specific characteristics of different users. Through the multi-task
learning mechanism that shares the decoder parameters of the two models, these models can capture speaker roles, expressive styles and domain expertise characteristic of the targeted user and
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:40 B. Guo et al.
generate personalized responses without heavy recourse to each speaker’s conversational data.
The work of Yang et al. [145] utilizes domain adaptation mechanism to generate personalized dialogue responses. The general response-generation model with an attention LSTM encoder-decoder
architecture is pre-trained on the large-scale general dialogue data without user-specific information. Then the model is fine-tuned with a small amount of personalized dialogue data by a dual
learning mechanism to generate personalized responses. In the training process, three rewards
are proposed to evaluate the quality of generation results, that are personalization, informativeness, and grammaticality and the policy gradient method is adopted to generate highly rewarded
responses.
6 OPEN ISSUES AND FUTURE TRENDS
Although many advanced technologies have been applied to text generation and some remarkable achievements have been made, there are still many remaining issues. In this section, we put
forward some key issues and point out some future development trends of text generation.
6.1 Different Types of Contexts
Context information can provide the current situation, state, environment and other information
for text-generation systems to realize more accurate simulation of human expression, so it is very
important in CTG systems. For example, in multi-turn dialogue systems, context information usually refers to historical dialogues and can make the conversation more coherent. Sordoni et al. [121]
encode the dialogue history into vector representations and feed them into the decoder to generate
consistent responses. In machine translation systems, Voita et al. [131] propose a context-aware
machine translation model, which can control and analyze the flow of information from context to
the translation model. By encoding the context information, the model can more accurately generate the correct translation text. These works achieve relatively excellent results. However, context
information contains much more than those considered in existing studies. Existing researches
only consider the dialogue history, predefined external information or other types context, but
our expression may be affected by various factors, such as hot events, emotions, time, weather,
and so on. These external context information may be explicit or implicit, so how to extract them
and properly represent them is a major challenge. A humanoid CTG system should be able to effectively integrate various contexts and generate reasonable text, which will be the future research
direction.
6.2 Multi-modal Data Translation and Domain Adaptation
In addition to text data, there are various types of data, such as voice, image and video. Human
can efficiently extract useful information from various types of data and convert them into corresponding text representation, such as describing the content of a painting and summarizing the
content of a movie. Researchers carry out many works on text generation with multi-modal data as
inputs, such as generating description/caption for a given image [83], conducting QA with images
[119], and communicating based on the content of a given image [28]. These studies usually utilize
CNN to extract relevant information in images, and generate corresponding text using common
models in text generation. The existing deep learning models can only process one type of data,
so handling multi-modal data requires to combine multiple models, which may bring a large computational cost. Moreover, the semantic space of different types of data may be different, which
brings great difficulties for the fusion of multi-modal data. How to incorporate different types of
data and develop unified models for multi-source data processing are two huge challenges. Much
more efforts should be conducted on generating informative texts with multi-modal data sources.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
Conditional Text Generation for Harmonious Human-Machine Interaction 14:41
At the same time, in many tasks of CTG, such as personalized text generation and emotional text
generation, the available training data is very scarce. Most text data are totally general data and do
not contain personalized or emotional characteristics, which cannot meet the requirements under
specific conditions. Transfer learning is a promising way to address this problem. By learning
general knowledge of natural language from massive common text data, and then transferring
it to a specific domain training with a small-scale conditional text data, the model can not only
master the general knowledge of the source domain but also learn the specific needs of the target
domain, to make up for the scarcity of data. Yang et al. [145] use the idea of domain adaptation in
transfer learning to address the issue of lacking personalized dialogue data. Through fine-tuning
the general dialogue model with the small size personalized dialogue data, the model can effectively
generate personalized dialogue responses. Transfer learning is a rapidly developing technology in
deep learning, and integrating diverse transfer learning models with scarce usable data for CTG
is also a promising research direction.
6.3 Long Text Generation
Long text has a wide range of application areas, including writing compositions, translating articles, writing reports, and so on. However, the current technology has some bottlenecks in processing long text because of the long-distance dependence existing in the natural language. Humans
have the ability to extract the key information (e.g., contexts and topics) from long text, which is
difficult for machines. Researchers have conducted much efforts on improving the models’ ability
of generating long text. For example, the LSTM and GRU model is produced to address the issue
that the original RNN model cannot capture the long-distance dependence using the gating mechanism. Guo et al. [50] propose the LeakGAN model to generate long texts. The feature extracted by
discriminator is used as a stepwise guidance signal to guide the generator to produce high-quality
text. At the same time, the hierarchical reinforcement learning provides more information to the
discriminator for generating long text. How to effectively model and capture the long-term dependency in long text is a major challenge in the research. For text-generation technology truly
behaving like humans, it needs the ability to freely generate long or short texts, which still has
much to be investigated.
6.4 Lifelong Learning
Lifelong learning is an important ability of human beings. We continuously learn new knowledge and expand and update our knowledge base through various data sources in the physical
world to adapt to the rapidly changing environment. Existing text-generation models are usually
trained on fixed datasets and have no ability to expand and dynamically updated according to the
changes of the external environment. To make text-generation models more personified, lifelong
learning is a necessary ability. Combining external knowledge base is the first step to realize lifelong learning. There have been many text-generation researches, focusing on the dialogue systems
[32, 163], combined with knowledge bases. However, most of them are based on fixed knowledge
base in which the knowledge does not keep updating in real time, so the model still does not
have the ability of continuous learning. Therefore, the dynamic evolution of knowledge base is
very important. Mazumder et al. [93] propose a lifelong learning model that can update its own
knowledge base by asking users. This is a groundbreaking exploration that provides a direction
for the lifelong learning text-generation models. However, the ability to actively gain knowledge
from the environment rather than simply asking the user is very important. How to find and learn
the most effective information from the changeable external environment and achieve efficient
lifelong learning is a very important research direction in CTG.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 2, Article 14. Publication date: February 2021.
14:42 B. Guo et al.
Fig. 6. The concept map of our proposed model.
6.5 Knowledge Extraction and Fusion from Crowdsourced Data
With the rapid development and popularization of social networks, more and more crowdsourced
data appear on the Web, such as the Q&A community Quora28 and Zhihu.29 These data are the
embodiment of human intelligence and can be used as the source of external knowledge of textgeneration systems. However, existing knowledge-enhanced text-generation systems are mainly
based on the structured knowledge graph or unstructured knowledge base built in advance [78,
98], which cannot perform real-time knowledge selection and fusion from crowdsourced data and
usually cover several specific domains. Crowd intelligence data covers a wide range of domains and
dynamically updates itself in real time. However, the noise and heterogeneity of crowdsourced data
prevent its applications in text-generation systems. Therefore, how to mine suitable information
from crowdsourced intelligence data in real time, enhance the semantic understanding, and fuse
information properly in text generation, are promising research directions of CTG.
To solve the problem of incorporating crowdsourced intelligence data in CTG, we have proposed
a preliminary idea, as shown in Figure 6. In the encoding stage, the input text will interact with
the crowdsourced data and select relevant knowledge as the external knowledge source. Then the
knowledge and the input text are encoded separately, and the cross-attention mechanism is used
to obtain fusion vector representations of the input information. In the decoding stage, generation
and copy/reference mechanisms are considered at the same time. The decoder will dynamically
select whether to generate words from the vocabulary or copy words from input sources according
to the current decoding state, to achieve more explicit use of crowdsourced knowledge.
7 CONCLUSION
We have made a systematic review of the research trends of conditional text generation (CTG). In
this article, we first give an introduction to the field of text generation. We then give a brief review
of key techniques in the field of text generation and further give the formal definitions of different
fields of CTG. Finally, we investigate the research status of various CTG fields and propose several
general learning models for CTG. Though there has been a big research progress in CTG, it is still
at the early stage and numerous open research issues and promising research directions should be
studied, such as long text generation, multimodal data translation, and lifelong learning