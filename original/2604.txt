Topic modelling methods such as Latent Dirichlet Allocation (LDA) have been successfully applied to various
fields, since these methods can effectively characterize document collections by using a mixture of semantically rich topics. So far, many models have been proposed. However, the existing models typically outperform
on full analysis on the whole collection to find all topics but difficult to capture coherent and specifically
meaningful topic representations. Furthermore, it is very challenging to incorporate user preferences into
existing topic modelling methods to extract relevant topics. To address these problems, we develop a novel
personalized Association-based Topic Selection (ATS) model, which can identify semantically valid and relevant topics from a set of raw topics based on the semantical relatedness between users’ preferences and
the structured patterns captured in topics. The advantage of the proposed ATS model is that it enables an
interactive topic modelling process driven by users’ specific interests. Based on three benchmark datasets,
namely, RCV1, R8, and WT10G under the context of information filtering (IF) and information retrieval (IR),
our rigorous experiments show that the proposed ATS model can effectively identify relevant topics with
respect to users’ specific interests, and hence to improve the performance of IF and IR.
CCS Concepts: •Information systems→Association rules; Personalization; Document topic models;
Content analysis and feature selection; • Computing methodologies → Topic modeling;
Additional Key Words and Phrases: Topic selection, topic evaluation, topic components, information filtering
1 INTRODUCTION
Topic modelling is an unsupervised model that provides a powerful tool for discovering and
exploiting the hidden thematic structure in large archives of texts (Blei et al. 2003). It can automatically characterize a collection of documents by a mixture of topics, which is represented by a topicword distribution. Topic modelling methods have been extended in many ways, such as extending the basic statistical assumptions to uncover more sophisticated latent structures in texts (Teh
et al. 2006; Mccallum et al. 2009), incorporating metadata Barbieri et al. (2013) or external sources
(Andrzejewski et al. 2009) to guide the sampling process, so that topics with higher quality are uncovered. By extending existing topic modelling methods, there is a great potential to enhance various applications such as text mining, signal processing, human-machine interactions, and so on.
One fundamental problem of existing topic modelling methods is that users may find it difficult
to interpret the uncovered topics and leverage relevant topics to facilitate various applications.
Accordingly, there is a pressing need to develop novel methods for identifying the most semantically valid and relevant topics so users can apply relevant topics to support their specific tasks.
A topic is considered semantically valid if its topical words are related to the underlying domain.
For example, for documents of the finance domain in the AP news dataset, the topical words of
a semantically valid topic could include “merger, acquisition, takeover, consolidation, corporate,
deal, transaction,” which together represent the concept of merger and acquisition in the finance
domain. But some invalid topics are often included in the same topic model, which are represented
by irrelevant words such as “method, takeover, shutter, screen, camera.”
Much current research work is confined to modelling distributions over topics instead of identifying relevant semantic structures that can really facilitate real-world applications. For instance,
various distributions (e.g., Dirichlet, Gaussian, Indian Buffet, Chinese Restaurant, etc.) are incorporated into topic models with respect to different applications. However, these heuristically predefined distributions have their underlying assumptions and characteristics that may not fit well
with different kinds of applications.
Another drawback of existing topic modelling methods is that topics are represented by a set of
words with distributed probabilities. Though it is easy for machine to represent topics with such
a format, humans may find it difficult to interpret such a topic representation. Recently, a patternbased representation scheme has been applied to represent topics in a more meaningful way to
enhance information filtering (IF) performance (Gao et al. 2014, 2015). Different from traditional
topic representation, the main benefit of pattern-based representation is that it can capture the
rich semantics of the underlying corpus, and so it is easier for humans to interpret the uncovered
topics. In this article, we further define a component space to facilitate the transformation of the
word space of a topic model to the transaction space, which can represent topics by using semantic components induced from these topics. Essentially, each topical component contains groups of
patterns and the associations among words. We believe that the induced components from topics can conquer the problem of a simple “bag-of-words” representation. When compared to the
classical topic representation that is characterized by a probability distribution over words, the
semantically enriched topic components can facilitate the identification of semantically valid and
relevant topics with respect to users’ specific information requirements.
Even if a number of semantically valid topics are presented to a user, it is extremely difficult for
the user to manually read through all of these topics to verify if they are relevant or not, especially
when there are a huge number of topics and the user is not very familiar with the problem domain.
Therefore, it is essential to develop an automated method to identify relevant topics from unlabelled textual corpus. To address such a problem, we develop the novel Association-based Topic Selection (ATS) model, which can automatically identify relevant topics by considering users’ specific
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
Finding Semantically Valid and Relevant Topics by ATS Model 3:3
information preferences. More specifically, the ATS model can detect inherent semantic associations between some keywords provided by users and the structural components induced from
topics. According to these semantic associations, the proposed ATS model can identify relevant
and semantically valid topics with respect to specific users’ needs and remove irrelevant topics so
a set of optimized topics are applied to support real-world applications (e.g., IF). The proposed ATS
model operates in the following way. First, the classical LDA model and a pattern mining method
are applied to uncover pattern-based topics from a corpus. Second, accept a user’s input, which
we name query so the ATS model can match the semantic components of topics with respect to
the query, and hence identify relevant topics. Third, divide the set of relevant topics to a subset of
relatively certain topics and another subset of relatively uncertain topics according to the match
of the structural patterns appearing in the user query and each topic, respectively. Finally, we develop an evaluation framework to verify the quality of the selected topics, which will be applied
to IF tasks. In sum, the main contributions of our research are as follows.
(1) Topical Components: Existing topic modelling methods represent topics by various distributions of words. However, such a topic representation is not human interpretable. In
this article, we propose semantically rich pattern-based topic representation. More specifically, topical components consist of primary components (i.e., patterns) and a set of relations between components (i.e., association rules).
(2) Topic Selection: Topics are structurally represented by associative patterns, which provide different levels of abstractions to facilitate user access. The proposed model enables
the effective application of semantically valid and relevant topics to real-world applications with minimal user involvement.
(3) Topic-based Ranking: The relevance of topics is estimated based on a novel topic performance function, which is underpinned by a different level of topic certainty and the notion
of topic significance. For the document ranking task, the proposed algorithm of exploiting
semantically valid topics can enhance task-based analysis of topics. Experimental results
show the outstanding performance of the ATS model, which is verified as an effective and
flexible way to systematically utilise topic models in real tasks.
2 RECONSTRUCTING COMPONENTS OF UNSUPERVISED TOPIC MODELLING
2.1 Background
Topic modelling algorithms are used to discover a set of hidden topics from collections of documents, where a topic is represented as a distribution over words. Topic models provide an interpretable low-dimensional representation of documents (i.e., with a limited and manageable number
of topics). Latent Dirichlet Allocation (LDA) (Blei et al. 2003) is a typical statistical topic modelling
technique and the most common topic modelling tool currently in use. Let D = {d1,d2,...,dM }
be a collection of documents. The total number of documents in the collection is M. For the ith
word in document d, denoted as wd,i , zd,i is the topic assignment for wd,i , zd,i = Zj means that
the word wd,i is assigned to topic j, and the V represents the total number of topics. Let ϕj be the
multinomial distribution over the words for Zj , ϕj = (φj,1,φj,2,...,φj,n ),
n
k=1 φj,k = 1. θd refers
to multinomial distribution of the topics in document d. θd = (ϑd,1, ϑd,2,..., ϑd,V ),
V
j=1 ϑd,j = 1.
ϑd,j indicates the proportion of topic j in document d. LDA is a generative model in which the only
observed variable is wd,i , while the others are all latent variables that need to be estimated. Gibbs
sampling method is an effective strategy for hidden parameters estimation (Steyvers and Griffiths
2007) that is used in this article. The resulting representations of the LDA model are at two levels,
document level and collection level. Apart from these, the LDA model also generates word-topic
assignments, that is, the word occurrence is considered related to the topics.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.  
3:4 Y. Gao et al.
Fig. 1. Visualisation of the whole procedure of generating topical components. The heatmap on the left represents an alignment between words and topics in the LDA model. The columns represent the distribution
over the topics by colours. In the middle, the topic representation is extended into three dimensions, which
forms a word-document-topic triple representation as component space. In the space, each coloured dot represents word assignment for each topic over all documents. As a result, topical components are generated,
which is shown on the right of the figure. The length of circle for each word wi represents the statistical
importance of this word in the topic Ti . The coloured links between different words demonstrate the associations between them.
Pattern-based representations (Gao et al. 2014) were considered more meaningful and more accurate to represent topics than word-based representations (Blei et al. 2003). In the previously
proposed model, the pattern can uncover groups of word combination in the topic, but cannot
find word associations and more complex relations in the topic. Therefore, in this article, we reconstructed components of each topic that contain structural information, which can reveal the
associations between words. In order to discover these underlying structures in the topics and
documents, we transfer word-topic pairs to word-document-topic triples. Based on the triple relationship, we creatively construct a component space to facilitate associations extraction for topics.
Generally, two steps are involved: first, construct a new component space from the LDA model
results of the document collection D; second, generate topical components from the component
space, as shown in Figure 1.
2.2 Construct Component Space
In addition to the standard results of topic models, such as topic distribution over documents and
word distribution over topics, word assignments are also provided after the iterative topic learning
process. Therefore, each word will be assigned with a specific topic.
Specifically, let Rdi,Zj represent the word-topic assignment to topic Zj in document di . Rdi,Zj
is a sequence of words assigned to topic Zj . Let Iij be a set of words that occur in Rdi,Zj , Iij =
{w|w ∈ Rdi,Zj }, that is, Iij contains the words that are in document di and assigned to topic Zj
by LDA. Iij , called a topical document transaction of document i for topic j, is a set of words
without any duplicates.
Let D = {d1,...,dM } be the original document collection, from all the word-topic assignments
Rdi,Zj to Zj , i = 1,..., M, we can construct a component space Γj , where the component space
Γj for topic Zj is defined as Γj =
I1j, I2j ,..., IMj
. From this component space of the topic, we can
easily find the word occurrences in documents as well as in the same topic. For the topics in the
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.  
Finding Semantically Valid and Relevant Topics by ATS Model 3:5
Table 1. Component Space of Topic 7 in Collection 125 of RCV1
Doc. growth scottish scotland power nationalist country british independ
d1 1 0 01 1 00 0
d2 0 1 11 0 00 0
d3 0 1 11 1 10 1
d4 0 1 10 0 01 0
d5 1 0 11 1 00 1
···
collection of D, we can construct a number of V component spaces (Γ1, Γ2,..., ΓV ). For example, in
collection 125 of RCV1 dataset, we create a component space for topic 7 as Table 1. The occurrences
of words assigned by topic 7 in each document are counted in the transactions.
2.3 Generate Topical Components
Based on the discovered component space, we intend to discover more complex relations and word
associations in the topic, using pattern mining techniques. In this article, association rule mining is
leveraged for uncovering the hidden structures in topics. In this article, the pattern and association
rules are particularly defined as:
—Pattern X is a combination of some individual terms, that is, X = {x1,..., xb } is a set of
terms; b is the length of this pattern X, where b = 1 is the special case that means X is an
individual word.
—An association rule is an implication in the form of X ⇒ Y, where X and Y are disjoint
itemsets, we also call them patterns, that is, X ∩ Y = ∅. X is called antecedent and Y is
called consequent; the rule means that X implies Y, X ⇒ Y. The strength of an association
rule can be measured in terms of its support and confidence.
—Support determines how often the rule (X ⇒ Y) is applicable to a given component space,
which is denoted assupp, while the relative support of the rule is the percentage of transactions that contain X and Y.
—Confidence determines degree of interest or strength of the associations of this rule, which
is denoted as con f , and the confidence of the rule is the ratio between the support of the
rule (X ⇒ Y) and the support of X.
We need to mention that confidence measures the reliability of the inference made by a rule,
which provides foundational theory for the proposed topic selection model. For a given X ⇒ Y,
the higher the confidence, the more likely it is for Y to be present in transactions that contain
X, and the stronger relation that represents X to Y. The association rule suggests a co-occurrence
relationship between items in the antecedent and consequent of the rule (Tan and Kumar 2005).
For a topic Zj , we define a Lj to represent all the existing complex and compound association rules
in the topic as follows.
—Lj , a set of strengths of discovered association rules for topic Zj :
From each component space “Γj” for topic Zj , we can generate a set of association rules,
which satisfy the predefined minimum support σ and confidence η for a given component
space.
Here, for the given minimal support threshold σ, an itemset X in Γj is frequent if supp(X) >= σ,
where supp(X) is the support of X, which is the number of transactions in Γj that contain X (X is the
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
3:6 Y. Gao et al.
Fig. 2. Samples of components in topic 7 of the collection 125.
frequent pattern (Han et al. 2007; Tan and Kumar 2005) in Zj). The frequency (also called relative
support) of the itemset Xi is defined fij = supp(Xi )
|Γj | . For simplicity, topic Zj can be represented by a
set of closed patterns (Han et al. 2007; Tan and Kumar 2005), denoted as XZj = {X1j,X2j ,...,Xmj j},
in which mj is the total number of patterns in XZj and each Xij in XZj is a unique pattern with
corresponding weight fij . For the given minimal confidence threshold η, an association Xkj ⇒ Xhj
in Γj is accepted if supp(Xk jXh j )
supp(Xk j ) >= η, and the strength of the association is denoted as lkh.
Based on the above definitions, a topic consists of a set of primary components (i.e., closed
patterns (Han et al. 2007; Tan and Kumar 2005)) with corresponding weightings, and also a set of
relations between components (i.e., association rulesX ⇒ Y, whereX andY are frequent patterns).
These primary components and the rules are called Topical Components of this topic.
In summary, we use Rj to represent the components of topic j:
Rj < XZj , Fj , Lj >,
where XZj is the set of patterns in the topic j, Fj is the set of patterns’ weightings, and Lj is the
set of associations between patterns in the topic. We can find that the components in the topic
are complicated and with different types. After the two-step operation, the reconstructed topic
modelling has richer and in-depth structural representations for each topic. Therefore, we name
the R < X, F, L > in topics as topical components.
For example, the topical components of topic 7 in the collection of 125 are displayed in Figure 2,
followed by the example from Table 1.
3 TOPIC SELECTION MODEL
In the reconstructed model, the components in every topic are modified with underlying associative structures comparing with traditional simple word spaces. The powerful structures can
somehow remove random noises that are derived from distribution-based assumption in the LDA
model. However, in most topic models, latent topics rarely explicitly exist but are created upon a
pre-defined number of spaces. The topics can be biased, and not all of them are necessarily of good
quality or interesting to users. In this section, we propose an ATS model to identify most relevant
topics by incorporating users’ light inputs. In the approach, the topical components creatively
build trustful and strong relations between users’ inputs and topic inside, then the relevant topics
can be chosen and differentiated by varied certainties to the users’ interests from those originally
discovered topics.
In real cases, users’ light inputs, such as tags, click preferences, or chosen categories/titles, are
easily obtained. However, it is expensive and difficult to fully understand users’ preferences. The
gap is that the users’ inputs can be dramatically diverse, as the result, the real user preference
aspect is hardly specified by the minimal prior. Therefore, in this article, we intend to utilise the
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
Finding Semantically Valid and Relevant Topics by ATS Model 3:7
user’s inputs (i.e., queries) and further select those truly relevant topics leveraged by topical components.
3.1 Relevant Topic
In this article, the query is formally represented by a set of terms that can be user tags, categories, or summaries, denoted as S = {s1,s2,...,sn }, where sk is one of the terms in the query S,
k = 1, 2,...,n. Based on the discovered rules (i.e., X ⇒ Y, the relation of components in the topic,
which is introduced in Section 2.3) from pattern-based topics{XZ1 , XZ2 ,..., XZV}, for a given query
S = {s1,s2,...,sn }, we can discover the connection between the query-terms and patterns in topics, thus find the relevant topics. The rationale behind using pattern-based topic models is that
topical patterns contain more strong relations among words and these associations create reliable
links between original query-terms and their relevant topics. The detailed process is described as
follows.
As mentioned above, the pattern-based topic is XZi = {Xi1,Xi2,...,Ximi
} for topic Zi , in which
the pattern Xij = {x1
ij, x2
ij ,..., x
li j
ij } is a set of terms; lij is the length of this pattern Xij ; and
supp(Xij) is the support of Xij . The relevant topics of the query S can be discovered as the following steps:
(1) A term xk
ij ∈ Xij , k ∈ {1,...,lij}, sk = xk
ij , that is, sk ∈ Xij , and sk ⇒ Xij \sk is a rule in Rj
that is defined in Section 2.3, topic Zj is considered as a relevant topic of sk . The pattern
Xij is relevant candidate for sk . The set of relevant topics of the term sk , denoted as RTsk
can be defined as
RTsk = {Zj |∃(sk ⇒ Xij \sk ) ∈ Rj ,sk ∈ Xij}. (1)
(2) The set of relevant topics for a query S is defined as
RTS =
n
k=1
RTsk . (2)
For a term sk , there could be many relevant candidate patterns in XZj that make the topic Zj
a relevant topic of sk . Let Xj
sk be a set of relevant candidates in XZj for sk , Xj
sk can be used to
represent topic Zj in terms of sk . Xj
sk is defined below:
Xj
sk = {X |X ∈ XZj , ∃(sk ⇒ X\sk ) ∈ Rj ,sk ∈ X}. (3)
For each pattern Xij ∈ Xj
sk , the relevant pattern is Xij and the relevance of Xij to sk with respect
to the topic Zj is defined as
f j
sk (Xij) = fij, (4)
where fij is the weighting of the pattern Xij in topic Zj . The relevance f j
sk (Xij) will be used to
determine the relevance of a document to a query in the evaluation stage, which will be discussed
in Section 5.
3.2 Topical Relatedness
The structural components in topics create a reliable mapping “word-association-topic” triple
relation. Strong associations between words can extend the user specific information to a more
meaningful and completed structure. In this way, it helps users to find useful topics. However,
associating with different words, the same word can often represent different topics. For example,
“south” in “south Africa” refers to a country name, but in “south west” the “south” refers to a direction. As a result, not all the relevant topics generated using Equation (2) can “equally” represent
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017. 
3:8 Y. Gao et al.
the user’s real interests just simply based on word-topic relations. This is also the main problem
that the traditional topic models have, in which each topic is represented by individual words.
Normally, the more prior words the user provides, the more concrete meaning for the selection
process, thus the more certain the meaning of the selected topics express. Therefore, in this article, we select the relevant topics not only in terms of detecting relations between query-terms and
topics but also further finding more certain relations between query-patterns and topics. Topic
relatedness analysis is a process that helps differentiating those relevant topics with different certainties. In this section, we will optimise the selected relevant topics, RTS , for the query S, and
define a level of certainty for these relevant topics: certain topics and uncertain topics.
—Certain Topics
A relevant topic Zj is considered as the user’s certain topic if it meets the following conditions:
—Zj is a common relevant topic of a pattern in S, that is, a pattern X = {sh,sk }, which
satisfies ∃sh ∈ S,Zj ∈ RTsh , ∃sk ∈ S,Zj ∈ RTsk , k  h.
Formally, the set of certain topics of the query S, denoted as Tc
S , is defined by Equation (5):
Tc
S =
Zj |Zj ∈ RTsk

RTsh , ∃k,h ∈ {1,...,n} , and k  h

. (5)
The set ofcertain topics can be considered as the closest topics to the user’s interests, because
they are related to a pattern from the query in the user specified information. This feature is
very important, because two or more words can form stronger patterns than single words.
The pattern consisting of multiple words can be considered as a “user-specific pattern.” It
is because of the “user-specific pattern” that the topics in Tc
S are more certain to represent
the user’s interests.
—Uncertain Topics
The other relevant topics other than the certain topics in Tc
S are considered as a set of
uncertain topics, T u
S :
T u
S = RTS \Tc
S . (6)
A relevant topic in the set of uncertain topics contains only one original term in the query,
which satisfies the following condition:
—Zj is a relevant topic of exactly only one term in S, that is, ∃!sk ∈ S,Zj ∈ RTsk .
Let RTc
sk be the set of certain topics of sk and RT u
sk be the set of uncertain topics of sk :
RTc
sk = {Z |Z ∈ RTsk ,Z ∈ Tc
S }, (7)
RT u
sk = {Z |Z ∈ RTsk ,Z ∈ T u
S }. (8)
The other topics rather than the topics in RTS are considered irrelevant topics in the topic model
for the document collection.
For those term-based topic models, they have been extended with domain-related knowledge
(Chen and Liu 2014), lexical priors (Jagarlamudi et al. 2012), or any other supervised information.
However, all the selected useful topics are based on the “word-topic” relationship between prior
information and topics. Alternatively, in the proposed model, it enables patterns in the query connecting with the patterns in the selected topic, which establishes a more strong link between the
query and the chosen topic. This is also the main reason why it is convincing to divide the relevant
topics into certain topics and uncertain topics by the proposed ATS model.
To understand this process clearly, we formally describe the process in two algorithms: Reconstructing Components Algorithm and ATS Algorithm.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.    
Finding Semantically Valid and Relevant Topics by ATS Model 3:9
ALGORITHM 1: Reconstructing Components
Input: a collection of training documents D;
minimum support σj and minimum confidence ηj as thresholds for topic Zj ;
the number of topics V
Output: Topical components in the collection, R1,...,RV
1: Generate topic representation ϕ and word-topic assignment zd,j by applying LDA to D
2: for each topic Zj ∈ {Z1,...,ZV } do
3: Construct component space Γj based on ϕ and zd,j
4: Generate pattern-based topic presentations XZj , for each pattern X ∈ XZj ,
fij = supp(X )
|Γj | > σj
5: for each pattern Xij ∈ XZj , do
6: for each sub-pattern Xk ⊂ Xij do
7: an association Xk ⇒ Xij \Xk is accepted if supp(Xi j )
supp(Xk ) >= ηj , and the strength of the association, denoted as l
k
ij .
8: end for
9: end for
10: Generate topical components Rj < XZj , Fj , Lj > for topic Zj , where Fj is the set of patterns’
relative supports and Lj is the set of associations between patterns in the topic.
11: end for
ALGORITHM 2: ATS Algorithm
Input: Topical components in the collection, R1,...,RV ;
a query S = {s1,s2,...,sn }.
Output: Set of certain topics for query S, Tc
S ;
Set of all related topics for the query S, RTS ;
Set of relevant candidate patterns in XZj for sk , Xi
sk .
1: for each sk ∈ S do
2: RTsk := ∅
3: for each topic Zi ∈ {Z1,...,ZV } do
4: Xi
sk := ∅
5: for each pattern Xij ∈ XZi do
6: Scan patterns and find sk = xij , xij ∈ Xij
7: if (sk ⇒ Xij \sk ) ∈ Ri then
8: RTsk = {Zi} ∪ RTsk
9: Xi
sk = {Xij \sk } ∪ Xi
sk
10: end if
11: end for
12: end for
13: end for
14: RTS = n
k=1 RTsk
Tc
S = {Zi |Zi ∈ RTsk
 RTsh , ∃k,h ∈ {1,...,n} , k  h}
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017. 
3:10 Y. Gao et al.
Fig. 3. An example of topic selection and topic relatedness in collection 125 of the RCV1.
3.3 Example
The query in collection 125 of RCV1 is “Scottish Independence,” and it discusses how the Scottish
people have been pushing for independence from Great Britain. In training dataset, a collection of
36 documents without any relevance judgement are trained by the LDA model to generate a topic
model of 10 topics. The experimental settings will be introduced in Section 5.5.
Figure 3 presents the process of selecting certain topics from all topic candidates and determining semantic-related patterns. The association rules in R satisfy minimum support σ = 0.2 and
minimum confidence η = 0.3. According to Equation (1), take an example of a pattern “Scotland
Scottish” in topic 7, its support is 0.40625 and the confidence of “Scottish ⇒ Scotland” is 0.812 (as
shown in Figure 2), which satisfies the minimum support and confidence. In this way, the related
topics RT(Scottish) = 
Z7 and RT(Independence ) = 
Z7,Z1 are found, and patterns such as “Scottish Scotland British” and “ Scotland nationalist independence” are chosen as the related patterns.
Since topic7 contains two patterns that are related to different query-terms, topic7 is the certain
topic and topic1 is the uncertain topic, other topics uncovered by the LDA are irrelevant. As shown
in Figure 3, topic1 delivers the intention of conferring and opposition, while topic7 expresses more
closed meaning to the title “Scottish independence.” Instead of using all patterns that are generated
in topics, we select more relevant patterns within topics as topic representation.
4 TOPIC QUALITY METRICS
We conduct the following two measures from different perspectives to evaluate the quality of
topics, which are coherence and randomness. Represented by the top words, the topic quality is both
evaluated in terms of how these words coherently convey a concentrated topic (i.e., coherence) and
how stable the specific topic is represented under different iterations (i.e., randomness).
To measure the topic coherence quantitatively, we adapt the measure proposed by Mimno
et al. (2011), which is an intrinsic measure to compute the coherence of topics. It uses document
frequency of the top M most probable terms for a specific topic. Specifically, the topic coherence
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
Finding Semantically Valid and Relevant Topics by ATS Model 3:11
Fig. 4. Coherence (left): The coherence value in 10 topics that are derived from the LDA model and the
pattern enhanced topic model, respectively, both in collection 125 of RCV1. Randomness (right): The average
changes of topic representations between two iterations in the collection 125 of RCV1, using the LDA and
pattern enhanced topic representations. The topic number is 10 in this dataset.
for topic k is given by
coherencek =

M
m=2
m
−1
l=1
loд
D(wk
m,wk
l ) + 1
D(wk
l ) , (9)
where wk
m and wl are the mth and lth most probable terms within topic k, D(wk
m,wk
l ) is the codocument frequency of term wk
m and wk
l , and D(wk
l ) is the number of documents containing term
wk
l . A smoothing count of 1 is included to avoid taking the logarithm of zero. We calculate the
coherence of 10 topics in collection 125 of RCV1 dataset and show the different results of the LDA
model and our proposed topic model in Figure 4.
Statistics in Choo et al. (2013) showed that the word-topic assignment and topic-document assignment of the LDA model are partially no convergence or stability, due to the nature of samplingbased LDA algorithm, denoted as randomness, which indicates the randomly differing results in
the same collection of data. To be specific, in this article, we formulate the randomness of a topic
by averaging the changes of the top words from the topic representations between the results of
different iterations on the semantically same topic from one collection of documents (i.e., the collection 125 of RCV1; the details of the dataset RCV1 is described in Section 5.3). The formulation
is followed as
randomness = 1
V

V
k=1
different(k), (10)
where different(k) is the number of different words of the semantically similar topic within the
results from two consecutive iterations. In the figure, we run 500 to 4500 iterations in the collection
125 of RCV1 and calculate the randomness of the LDA and the pattern enhanced topic model for
each iteration of the collection.
As the figure shows, the coherence of the topical components are superior than the topics in
LDA, and the randomness of them are relatively more stable in the identical topics from the LDA
upon different iteration.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
3:12 Y. Gao et al.
5 EVALUATION
In topic models, developing an effective evaluation method is one of the most important tasks that
has been highlighted in Blei (2012). Open questions are how to evaluate qualities of topics and
how these topics are used. To answer these questions, in this article, we intend to utilise the topic
model by selecting the most interesting topics to users, instead of accepting all topic distributions.
Evaluation is to verify the quality of topics after applying the ATS model and whether the users
are interested in the selected topics. Topic significance is defined to estimate the topical quality in
terms of calculating the importance of all the “user-specific patterns” in a certain topic. In order
to effectively apply the topic significance in estimating relevance between the selecting topicbased users’ interests and documents, only the most representative patterns (Maximum Matched
Patterns) from the topic are used. Therefore, the larger the number of relevant documents are
retrieved for the users, the higher the quality the selected topics are.
The basic idea is that the topic that contains the most specific, coherent, and relevant patterns is
the semantically valid topic. In the following section, we statistically compute topic performance
in the real application of Information Filtering and Information Retrieval (IR), which can be an
application-oriented way to evaluate the quality of the chosen topics.
5.1 Hypothesis
In order to investigate the effectiveness of the proposed topic selection model on selecting semantically valid and relevant topics, we conduct a comprehensive experiment in IF scenario. The
proposed model is discussed under the following three hypotheses:
—H1: The ATS model is effective on identifying semantically valid and relevant topics.
—H2: Topics with further differentiated level of certainty can enhance accuracy of the topic
selection.
—H3: Unsupervised topic modelling underpinned by the proposed ATS model can be an effective solution for IF and IR systems.
5.2 Document Ranking Based on Topical Component Structures
Topic significance has been proposed and successfully applied in Gao et al. (2015), which considered both pattern specificity and patterns’ statistical significance. Let d be a document, Xd
i be one
of the matched patterns that Xd
i ∈ Xj
sk for topic Zj in document d, i = 1,...,ni , and fi1,..., fini
be the corresponding supports of the matched patterns, then the topic significance of Zj to d is
defined as
siд(Zj,d) =
ni
k=1
spe (Xd
i ) × f j
sk (Xij) =
ni
k=1
a|Xd
i |
m × fij, (11)
where m is the scale of pattern specificity (we set m = 0.5), and a is a constant real number (in
this article, we set a = 1). Xj
sk can be used to represent topic Zi in terms of sk as it illustrates in
Equation (3), and ni is the number of patterns in Xj
sk .
In IF environment, incoming documents can be modelled by document relevance ranking, which
accordingly represents the relevance to users’ interests. The relevance is dominantly determined
by topic significance, and correspondingly the document relevance r(d, S) is defined as r(d, S) ∼
Zj ∈RTS siд(Zj,d).
Combining it with Equation (11), the document relevance is formulated by more specific components in topics. Besides, a constant parameter λs can balance the impact of original queries
and associated closed patterns in all selected relevant topics. Specifically, the more related topics a query-term has, the more diverse the term is, thus the higher the diversity of the specific
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017. 
Finding Semantically Valid and Relevant Topics by ATS Model 3:13
query-term is. The number of relevant topics in RTsk is defined as diversity ofsk , denoted as div(sk ).
For the set of certain topics, divc
sk = |RTc
sk |. If a word has high diversity, then it will not be discriminative relevance; therefore, the importance weight should be lower than the word with low
diversity. For details, the relevance r(d, S) is formulated as following Equation (12).
If the model does not find any certain topics among the related topics (i.e., Tc
S = ∅), then
the chosen topics will be all relevant topics; thus, in Equation (12), the Tc
S is replaced by RTS
and the RTc
sk is replaced by RTsk . The higher the r(d, S), the more likely the document is relevant
to the user’s interests:
r(d, S) =

sk ∈ S
sk ∈ d
δ (sk ,d)
⎧⎪⎪
⎨
⎪⎪
⎩
1 + λs
⎧⎪⎪
⎨
⎪⎪
⎩
1
divc
sk

Zj ∈T c
S
siд(Zj,d)
⎫⎪⎪
⎬
⎪⎪
⎭
⎫⎪⎪
⎬
⎪⎪
⎭
=

sk ∈ S
sk ∈ d
δ (sk ,d)
⎧⎪⎪⎪
⎨
⎪⎪⎪
⎩
1 + λs
⎧⎪⎪⎪
⎨
⎪⎪⎪
⎩
1
|RTc
sk |

Zj ∈T c
S

Xi j \sk ∈X j
sk
|Xij \ sk |
m × f j
sk (Xij)
⎫⎪⎪⎪
⎬
⎪⎪⎪
⎭
⎫⎪⎪⎪
⎬
⎪⎪⎪
⎭
where
δ (sk ,d) =

1 if sk ∈ d
0 otherwise .
, (12)
5.3 Data
Datasets: We used three popular datasets to test the proposed model: Reuters Corpus Volume 1
(RCV1), R8 of Reuters 21578, and WT10G from TREC data.
RCV1 contains 100 collections of documents, which were developed for TREC filtering track.
In TREC track, a collection is also referred to as a “topic.” To differentiate from the “topic” in LDA
model, “collection” is used to refer to a collection of documents in the TREC dataset. The first
50 collections are composed by human assessors and the another 50 collections are constructed
artificially from intersections collections. In this article, only the first 50 collections are used for
experiments.
R8 dataset is a widely used collection for text mining. The data was originally collected and
labelled by Carnegie Group, Inc. and Reuters, Ltd. in the course of developing the CONSTRUE
text categorization system.1 In this experiment, we picked up the set of 10 classes. According to
Sebastiani’s convention (Debole and Sebastiani 2005), it was also called “R8,” because two classes,
corn and wheat, are intimately related to the class grain, and they were appended to class grain.
WT10G consists of around 1.7 million documents, totalling 10 gigabytes, which is a relatively
big test collection. WT10G is a TREC test collection in the Terabyte Track, and it contains 100
collections (topics) of documents.
User queries and document format: Documents in both RCV1 and R8 are described in XML.
Documents are treated as plain text documents by a pre-processing, which includes removing stopwords according to a given stop-words list and stemming terms by applying the Porter Stemmer.
The title in the “Topic Statements” file in the RCV1 (i.e., “Economic espionage,” “Scottish Independence”) and the name of classes in the R8 (i.e., “acq,” “crude”) are used as the user’s specified
queries. For WT10G, only the title portion of the TREC topics (from topic 451 to topic 550) are
used to construct queries. The documents are indexed and extracted by modified version of Indri,
which is part of the Lemur Toolkit.2
1Reuters-21578, http://www.daviddlewis.com/resources/. 2http://www.lemurproject.org/lemur.php.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
3:14 Y. Gao et al.
Fig. 5. Filtering results (evaluation on MAP) and selected number of closed patterns on RCV1 with different
values of minimum confidences, σ = 0.2.
5.4 Evaluation Metrics
The effectiveness is assessed by four different measures: average precision of the top K (K =
5, 10, 20) documents, Fβ (β = 1) measure, Mean Average Precision (MAP), and 11-points. MAP
measures the precision at each relevant document first, then it obtains the average precision for
all the collections. It combines precision and overall recall together to measure the performance
of the models. The F-beta (Fβ ) measure is a function to adjust the assessment standard of both
Recall (R) and Precision (P), together with a parameter beta β. The parameter β = 1 is used in this
article, which denotes that precision and recall are weighed equally. Therefore, Fβ is denoted by
F1 = 2P R
(P+R) . 11-Points is used to measure the performance of different models by averaging the precisions at 11 standard recall levels (recall = 0.0, 0.1,..., 1.0, where “0.0” means cut-off = 1 in this
article). We also used a statistical method, the paired two-tailed t-test, to analyze the experimental
results. The statistical method, T-test, is also used to verify the significance of the experimental
results. If the p-value associated with t is significantly low (<0.05), then there is evidence to verify
that the difference in means across the paired observations is significant.
5.5 Parameter Settings
First, we apply the LDA model to construct topic models withV = 10 latent topics for RCV1,V = 50
topics for R8, and V = 300 for WT10G, according to the volume of each data collection, using the
MALLET topic modelling toolkit.3 Our experiments show that an insufficient number of topics
could generate abundant patterns in the topic model. We run collapsed Gibbs inference for 1000
samplings, the hyper-parameters of the LDA model are α = 50/V and β = 0.01.
There are several parameters that need to be determined by experimental results. In the process
of generating pattern-based topic representations, the minimum support σ for every topic in each
collection is set to σ = 0.2 in the RCV1. For selecting related topics, the minimum confidence
of a topical association rule η is specified according to experimental results, shown in Figure 5.
The blue bar indicates the number of selected useful closed patterns when η equals the specific
value, and the red line indicates the mean average precision performance. From the results, η =
0.3 is the best setting for minimum confidence for the association rule in the RCV1. Following
the same process, we determine the parameters σ = 0.1 and η = 0.3 for the R8, and σ = 0.2 and
η = 0.3 for the WT10G. The trade-off parameter in document relevance ranking is set as λs = 0.5
in experiments for the both datasets.
3http://mallet.cs.umass.edu/.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
Finding Semantically Valid and Relevant Topics by ATS Model 3:15
5.6 Baseline Models
For the baseline models, we divided them into three categorizations: language-based model, topicbased model, and ontology-based model.
Query Likelihood Model (LM): The LM (Manning et al. 2008) is a quite classic and effective
language modelling in information retrieval, which can be also implemented in the filtering experiment given only several query-terms. This model is the basic model to compare with for the
following topic-based models. The probability of producing the queries given by document d using
maximum likelihood estimation (MLE) under the unigram assumption is calculated as relevance
ranking of d:rank(d, S) = 	s ∈S
t fs,d
Ld , where t fs,d is the term frequency of the query s in document
d, and Ld is the number of tokens in document d.
LDA-based Document Model (LDBM): The LBDM (Wei and Croft 2006) is a successful document modelling that combines the language model with the LDA statistical model and has been
well examined in IR research. The document model is formulated by linearly combining LM estimation, the maximum likelihood estimate of word s in the collection D and the LDA model with
Dirichlet smoothing part. However, unlike the IR task, for document modelling in IF, documents
are coming one by one and need to be immediately processed, thus the modelling comes up by
a linear combination of LM document modelling and the LDA smoothing, but without collection
smoothing:
rank(d, S)=


s ∈S
(λP
LM (s|d) + (1 − λ)P
LDA (s|d)) =


s ∈S
(λP
LM (s|d) + (1 − λ)

V
j=1
(P ( ˆ ϕs,j) × P ( ˆ θj,d ))),
(13)
where λ is a weighting factor between the two likelihoods. Refer to Wei and Croft (2006), λ = 0.7.
Topical n-gram model: The topical n-Gram model (TNG) proposed in Wang et al. (2007) automatically and simultaneously discovers topics and extracts topically relevant phrases. It has been
seamlessly integrated into the language-modelling-based IR task. Given the posterior estimates
ϕˆ, ˆ
θ,φˆ, σˆ (refer to Wang et al. (2007) for details), the query likelihood of query S given document
d is
rank(d, S) =


|S |
i=1
(λP
LM (si |d) + (1 − λ)P
TNG (si |d))
=


|S |
s=1
(λP
LM (si |d) + (1 − λ)

V
j=1
(P (xi = 0|φi
ˆ−1) × P ( ˆ si |ϕi,j) + P (xi = 1|φi
ˆ−1)
× P (si |σ ˆi−1, j)) × P ( ˆ θj,d )).
(14)
Word embedding model: Recently, Mikolov et al. (2013) introduced word2vec, a novel wordembedding approach. Their model learns a vector representation for each word using a neural
network language model. We implemented the Google’s word2vec4 to train the continuous bagof-words, in terms of negative sampling algorithm and adopting Skip-Gram architectures for computing the word embedding. With regards to the training dataset, we utilize the English Gigaword Fifth Edition (Parker et al. 2011), which consists of standard Gigaword that contains around
9.9 million news articles sources from various domestic and international news articles. From the
dataset, we trained 200-dimensional vectors for 1.53 million words.
4https://code.google.com/archive/p/word2vec/.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
3:16 Y. Gao et al.
Table 2. Comparison Results of All Models on the RCV1, R8, and
WT10G Datasets
Data Models top-5 top-10 top-20 MAP Fβ=1
ATS 0.604 0.572 0.513 0.442 0.439
RCV1 LM 0.436 0.472 0.455 0.419 0.42
LBDM 0.500 0.494 0.461 0.425 0.422
TNG 0.510 0.450 0.460 0.422 0.415
Word2vec 0.532 0.526 0.489 0.417 0.429
POM 0.502 0.50 0.460 0.412 0.420
%chд 13.5% 8.7% 4.9% 4.0% 2.3%
ATS 0.675 0.688 0.669 0.501 0.474
R8 LM 0.475 0.463 0.444 0.427 0.430
LBDM 0.400 0.425 0.431 0.422 0.425
TNG 0.420 0.432 0.430 0.421 0.422
Word2vec 0.620 0.60 0.556 0.482 0.465
POM 0.498 0.475 0.469 0.438 0.460
%chд 8.9% 14.7% 20.3% 4.0% 2.0%
ATS 0.369 0.291 0.232 0.224 0.251
WT10G LM 0.334 0.246 0.196 0.181 0.210
LBDM 0.343 0.256 0.204 0.205 0.233
Word2vec 0.356 0.267 0.212 0.214 0.242
%chд 3.7% 9.0% 9.4% 4.7% 4.1%
The relevance of document d to the query S can be formulated as follows:
rank(d, S) =

|S |
i=1
|ni 
|
j=1
sim(si,cj (si )) =

|S |
i=1
|ni 
|
j=1
si  cj (si )
 si  cj (si ) 
, (15)
where ni is the number of top closed words to query term si , and cj (si ) is jth vector. According to
the experimental experiences, ni = 3 performs best.
Ontology-based method: Ontology-based techniques have been recognized as a critical part
of advanced search over recent decades. It assists to refine search intents within specific domains
and access new knowledge by tracking semantic relations. A Library of Congress Subject Headings (LCSH) database was selected to build the global knowledge base. Its size is 719 mega bytes
stored in Microsoft Office Access. Initially, 491,250 subject headings and their internal references
between the headings were extracted. For this category, we choose an advanced POM model, which
combines local relevance features mined from local instances with concepts existing in a global
knowledge base. In this way, the system can learn personalized ontologies for concept-based retrievals. Please refer to Shen et al. (2012) for details.
5.7 Analysing Results
In this section, we first report the ATS performance in Table 2, with comparisons to the results
of the language model (LM), the LDA model (LDBM), N-gram-based topic model (TNG), Wordembedding model (Word2vec), and POM in IF. All four models are adopted in the same datasets
and given only queries as labelled information. The results are evaluated by measures of top-5,
top-10, top-20, MAP, and Fβ1 . The %chg line at the bottom of each part provides the percentage
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.  
Finding Semantically Valid and Relevant Topics by ATS Model 3:17
Fig. 6. 11-point results of comparison between the proposed ATS model and baseline models, (a) results of
R8 dataset, (b) results of RCV1 dataset, and (c) results of WT10G.
Table 3. T-test p-values for All Models Compared with the ATS Model
Data Models top-5 top-10 top-20 MAP Fβ=1
LM 2.3 × 10−5 0.0003 0.0139 0.0388 0.0033
RCV1 LBDM 0.0047 0.0025 0.0208 0.0933 0.0081
TNG 0.0009 0.00020 0.0121 0.0233 0.0101
Word2vec 0.0188 0.0347 0.1058 0.1754 0.0638
LM 0.0517 0.0709 0.0553 0.1087 0.1048
R8 LBDM 0.0509 0.0424 0.0424 0.1005 0.0922
TNG 0.0050 0.0034 0.0043 0.00015 0.0022
Word2vec 0.0407 0.103 0.0203 0.149 0.1340
of improvement achieved by the ATS model against the second best model in that part for each
measure.
Table 2 contains three separated results in RCV1, R8, and WT10G, respectively. Note that the
TNG model and POM model are not implemented in WT10G data, since they are not efficient on
this very large data collection. From the statistics, the ATS model achieves consistently excellent
performance over two datasets, with the improvement percentage against the second best model
from a minimum of 4.0% to a maximum of 13.5% in RCV1 dataset, and improvement percentage
of a minimum of 2.0% to a maximum of 20.3% against the second best model in R8 dataset, and
improve percentage of a minimum of 3.7% to a maximum of 9.4% against the second best model
Word2vec model. The comparison results clearly support the Hypothesis H3.
The 11-point results of the proposed ATS model and baseline models in RCV1, R8, and WT10G
datasets are shown in Figure 6. The result lines indicate that the proposed ATS model achieves best
performance and is robust to different datasets. Although the ATS is not apparently outperforming
the Word2vec model (i.e., recall = 0.3) in WT10G, the ATS model still performs the best compared
with all of the typical models from each category, such as topic model, word embedding model,
and ontology model. These results can also support the Hypothesis H3.
We also conducted the T-Test to compare the ATS with the other baseline models, whose results
are listed in Table 3. In the table, all the p-values < 0.05 are marked by bold style. The statistical
results indicate that the improvements of the proposed ATS model are quite consistent on most of
the five measures in the RCV1, while in the R8 the consistency of improvements is still acceptable.
We can conclude that the ATS model is an exciting achievement in discovering the relevant and
semantically valid topics.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
3:18 Y. Gao et al.
Fig. 7. The number of selected useful topics from both the LDA and the ATS model in RCV1 dataset.
Table 4. Comparisons of Using Certain Topics and All Related
Topics in the RCV1 Dataset
Models top-5 top-10 top-20 MAP Fβ=1
ATS 0.604 0.572 0.513 0.442 0.439
ATS_rel topics 0.576 0.552 0.507 0.433 0.434
%chд 5.4% 3.6% 1.2% 2.1% 1.2%
6 ANALYSIS AND DISCUSSION
The performance of the ATS model is consistently excellent, whether the queries are specific
phrases or general single words, since the proposed model provides optimised mechanism to find
the most relevant and semantically valid topics. In the model, first, the topics possess concrete
meaning by structural components; second, those components that have reliable associations with
queries can only be selected as related topics; third, mining certain topics from the selected related
topics further support the topical quality. All of these elements benefit the whole system. So, we
can find that the proposed ATS model is sufficiently flexible and effective to support semantically
valid topic selection with minimal user involvement.
6.1 The Quality of Topic Selection
One of the main objectives for the experiment is to verify that the quality of selected topics from
the ATS model. Keep this in mind, we not only tested the performance in IF application, we also
counted the number of the discovered topics from both the ATS model and the LDA model and
present it in Figure 7. The blue bar indicates the number of selected topics by implementing the
LDA model, the red bar indicates the number of related topics by the ATS model, and the green
bar is the number of optimised certain topics by the ATS model, in RCV1 dataset that contains 50
document collections from number 101 to 150. It is obvious that for most of the collections, the
ATS model selects less related topics than the LDA model, but the results in Table 2 and Table 3
show that it performs much better than the LDA model. From this perspective, we conclude that
the ATS model can identify more semantically valid topics than the classical LDA model, which
supports Hypothesis H1.
Moreover, in Figure 7, the number of optimised certain topics are even less than the selected relevant topics in the ATS model. Thus, we intend to deeply investigate how the certain topics affect
the performance of the ATS model. In Table 4, ATS_rel topics denotes the model that utilises all
relevant topics without differentiating certain topics from them. From the results in the table, we
can find that the ATS_rel topics performs worse than the ATS model, which only extracts certain
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
Finding Semantically Valid and Relevant Topics by ATS Model 3:19
Table 5. The Storage Space of Components and the Original
Documents from Sample Collection 101 to 105 in RCV1
Collection Component spaces Original documents
101 25KB 123KB
102 90KB 1.4MB
103 50KB 369KB
104 80KB 1.4MB
105 13KB 365KB
topics, indeed, but the ATS_rel topics is still better than the other baseline models. The results of
Figure 7 and Table 4 together prove the correctness of the two hypothesises, H1 and H2. First, the
selected relevant topics depending on associative relations between queries and patterns are reliable and more precise than the chosen topics from the LDA model with respect to users’ interests.
Second, topics should be used with complete emphasis on certain topics compared with uncertain
topics, thus the differentiated level of relevant topics contributes much to the system.
For example, in the collection 139 of the RCV1, the query is “pig organ transplants.” The relevant
topics could be topic 5 with topical words “organ research,” topic 6 with topical words “transplant
drug,” and also related to topic 1 with “pig organ” according to the counterpart baseline ATS_rel
topics. The ATS model only selects topic 1 as the certain topic, since the pattern “pig, organ” in the
query satisfies the requirement of a certain topic by the ATS model, while the topic 5 and topic 6
are uncertain topics. According to the narrative description from collection 139 of the RCV1, we
should find those relevant documents that show the development of pigs for organ transplants and
the actual use of pig organs for transplants. Development of drugs to assist organ transplants are
not relevant. Based on the discussion, we can confirm that topic 5 and topic 6 are indeed irrelevant
and the proposed ATS can accurately find the right topic with respect to the user specific query.
On the other hand, the MAP performance of the ATS_rel topics in collection 139 is 0.893, and the
performance of the ATS rises to 0.941.
6.2 Complexity
As shown in Table 5, the storage space of components is much smaller than the original documents.
The patterns used to represent topics are generated from the words that are considered to represent
the document topics by the LDA model. These words are part of the original documents.
Moreover, the model combines the topic modelling and pattern mining linearly. Thus, in summary, the time complexity of the ATS model can be comparable to the traditional topic modelling,
since the pattern-mining process is only conducted on a small dataset. This model can also be
conducted off-line for training an IF system; so, the time complexity of the proposed model is
acceptable.
7 RELATED WORK
Semantic Topics: Topic modelling has been widely accepted by various communities, and so far
many models are proposed. Among all the models, how to represent the core semantics of topics
is always a key research target in this area. The topical n-Gram model proposed in Wang et al.
(2007) automatically and simultaneously discovers term relationships within topics and extracts
topically relevant and flexible phrases. Also, topical PageRank can extract keyphrases in Liu et al.
(2010). But syntactically valid phrases often share low frequency in documents that cause poor
performance for some queries. In Bai et al. (2005), dependence models have been incorporated
to extract term relationships for query expansion. This combination of terms are more flexible
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
3:20 Y. Gao et al.
than phrases and the expanded terms are dependent to query and document. In order to enhance
the coherence and cohesiveness of topic representations and solve the sparsity problem in short
texts, word co-occurrences patterns (e.g., biterms) are generated during topic learning process
(Cheng et al. 2014). The biterm topic model assumed that a term pair shares the same topic. This
assumption leads to great success in short texts, since term pairs in short texts would rarely take
completely different topics. However, it is not suitable for modelling queries, because a query could
consist of various topics. Therefore, in Konishi et al. (2016), the proposed PCTM further captured
the topic co-occurrences in a query.
Other popular approaches to generate topics are in terms of adding constraints that enforce sets
of words have to appear together in the same topic (Hu et al. 2011), and incorporating priors to topic
models, in which the priors can re-parameterize the distribution of topics or words. The priors can
be lexical rules (Jagarlamudi et al. 2012), domain knowledge (Chen and Liu 2014; Andrzejewski
et al. 2009), or user interactive experiences (Choo et al. 2013; Hu et al. 2011). However, in the real
world, the users’ inputs are dramatically diverse, in which differing topics and dynamic word patterns are involved in many situations. It will increase the computational costs if topic distributions
are changing for every different user input. Furthermore, the dynamic users’ inputs may cause the
randomness during the topic-learning process. In this article, the proposed ATS model uses postprocessing approach for selecting valid and relevant topics via associative patterns in the queries.
In this way, the ATS model can capture both dynamic word patterns as well as various topic occurrences, and never causes additional computations in the online process. In Kim et al. (2012), frequent patterns are pre-generated from the original documents and then inserted into the original
documents as part of the input to a topic modelling model such as the LDA. The resulting topic representations contain both individual words and pre-generated patterns. The drawbacks are mainly
twofold: first, document inputs are changed by simply putting pre-generated patterns, which may
change the original topic distribution of documents; second, those semantically important patterns
may not highly represent the topic due to the low frequencies in collections of documents.
Topic Quality: Topic models (Blei 2012) have achieved exciting successes in numerous domains
(Cao and Fei-Fei 2007; Wei and Croft 2006; Gao et al. 2015; Ramage et al. 2010). However, one fundamental problem of topic models is that not all topics that are discovered by topic modelling are
semantically meaningful to users. It is necessary to quantitatively evaluate the quality of topics in
terms of topic coherence or interpretability (Tagarelli and Karypis 2013). These standards are evaluated in terms of word intrusion test and topic intrusion test in Chang et al. (2009). However, the
processes heavily rely on the level of human judgement. Thus, further researches direct to automatically evaluating topics by real application or scientifically quantitative methods. Topic coherence
metric was used to find high-quality topics from domain-specific corpora in Mimno et al. (2011).
Musat et al. (2011) incorporate the WordNet hierarchy to capture the relevance of topics. Wikipedia
can also be used as external resources (Chan and Akoglu 2013) to construct linking relations and
build classification models for evaluating the quality of topics. A systematic framework of largescale topic assessment (Chuang et al. 2013) was proposed to evaluate the performance of different
topic models, and investigate some of the above mentioned intrinsic measures of topical quality.
According to the theory that has been claimed in Griffiths et al. (2007), the reconstructed topic
model that will be introduced in following section is sound, because it describes the textual corpus
both from semantic spaces (topics) and semantic representation (associative words). But we never
know the quality of topics that are derived from the LDA and whether they are eligible to represent
the user’s needs in terms of semantic and useful features. Nevertheless, the classification of a
collection into number of “good” or relevant topics is always problematic in statistical topic models.
Therefore, the aim of this article is to develop a method that can select semantically valid and
relevant topics to the users.
ACM Transactions on Intelligent Systems and Technology, Vol. 9, No. 1, Article 3. Publication date: August 2017.
Finding Semantically Valid and Relevant Topics by ATS Model 3:21
8 CONCLUSION AND FUTURE WORK
For most real-world applications of topic modelling methods, labour intensive and time-consuming
processes are often required to interpret and select relevant topics. In this article, we propose
the novel ATS model, which can select semantically valid and relevant topics with minimal user
involvement. By exploring the inherent semantic associations between the patterns captured in
a user query and that embedded in a set of initial topics, the ATS model can effectively identify
relevant topics. Based on large benchmark corpora, our experiments show that the proposed ATS
model can select relevant topics with respect to users’ interests. The benefit of the ATS model is
that only minimal user involvement is required in the topic selection process.
Inspired by the empirical test results of the proposed ATS model, our long-term research goal
is to compare the application performance of different topic modeling methods by assessing the
interpretability of these models and their impacts on supporting various real-world applications.
On the other hand, the topical components contain both topic-level representation that facilitates
a global classification of topics and associations among words that can induce semantically rich
word-to-word patterns. In the future, we will incorporate the word distance information into the
ATS model to enrich the topical components.