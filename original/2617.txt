From facial recognition to autonomous driving, Artificial Intelligence (AI) will transform the way we live
and work over the next couple of decades. Existing AI approaches for urban computing suffer from various
challenges, including dealing with synchronization and processing of vast amount of data generated from the
edge devices, as well as the privacy and security of individual users, including their bio-metrics, locations,
and itineraries. Traditional centralized-based approaches require data in each organization be uploaded to
the central database, which may be prohibited by data protection acts, such as GDPR and CCPA. To decouple model training from the need to store the data in the cloud, a new training paradigm called Federated
Learning (FL) is proposed. FL enables multiple devices to collaboratively learn a shared model while keeping
the training data on devices locally, which can significantly mitigate privacy leakage risk. However, under
urban computing scenarios, data are often communication-heavy, high-frequent, and asynchronized, posing
new challenges to FL implementation. To handle these challenges, we propose a new hybrid federated learning architecture called StarFL. By combining with Trusted Execution Environment (TEE), Secure Multi-Party
Computation (MPC), and (Beidou) satellites, StarFL enables safe key distribution, encryption, and decryption,
and provides a verification mechanism for each participant to ensure the security of the local data. In addition, StarFL can provide accurate timestamp matching to facilitate synchronization of multiple clients. All
these improvements make StarFL more applicable to the security-sensitive scenarios for the next generation
of urban computing.
CCS Concepts: • Security and privacy; • Computing methodologies → Artificial intelligence; Machine
learning; Distributed computing methodologies;
Additional Key Words and Phrases: Federated learning, trusted execution environment, secure multi-party
computation, quantum key distribution
1 INTRODUCTION
In the past decades, we have witnessed the revolutionary breakthroughs brought by Artificial
Intelligence (AI) in many commercial applications, such as computer vision, natural language
processing, automatic speech recognition, and so on. However, existing approaches rely heavily
on high quantity and high quality data. For example, the evolution of image classification benefits
from the emergence of ImageNet[18], with the help of a large amount of human historical games,
AI defeated the top human players in the games of Go [91] and StarCraft [100].
Such reliance on high-quality data is particularly apparent in smart urban computing [117–119].
Urban computing refers to the process of acquisition, integration, and analysis of big and heterogeneous data generated by a variety of sources in edge devices, such as sensors, vehicles, cameras,
and so on, to tackle the challenges that cities face [118]. Data in urban computing are usually private and sensitive, such as bio-metrics, locations, itineraries, and so on. Traditional approaches
require data scattered in each device of different locations should be uploaded to the central database, and processed centrally. However, this approach is facing more and more challenges. First,
due to privacy protection and industry competition, it is difficult to share data between different
organizations (parties). Second, from a legal and ethical perspective, with the increasing awareness of data privacy and security, legislatures are strengthening relevant laws to prohibit data
abuse, such as GDPR [26], CCPA [78], and so on. For example, in October 2017, Sidewalk Labs
launched quayside smart city project in Toronto [17], with the aim of building a livable space from
the ground up using innovations in construction techniques. However, this project had long faced
opposition over issues including data privacy concerns, and eventually led to the termination in
May 2020 [13, 20].
To decouple model training from the need to store the data in the cloud, a new training paradigm
called Federated Learning (FL) was proposed by Google in 2016 [9, 45, 47, 53, 64]. FL enables
multiple devices to collaboratively learn a shared model while keeping the training data on devices
locally, which can significantly mitigate privacy leakage risk. Currently, FL had been widely used
in many high privacy requirements areas, such as financial [106, 108], healthcare [10, 15, 16, 54,
103], computer vision [43, 58, 62], and so on. The superiority of federated learning also makes it
very suitable for urban computing, and some relevant researches are already focused on this area
[42, 59, 61].
FL requires model parameters, rather than raw data, to be transmitted between different participants, greatly mitigating the risk of data privacy leakage. However, direct transmission of model
parameters may still lead to data leakage potentially [28, 89, 120]. Therefore, FL needs to combine
with other security mechanisms to improve the security of model parameters transmission. Current security strategies including homomorphic encryption (HE) [27, 31, 71, 98], differential
privacy (DP) [1, 23, 24], secret sharing [5, 40, 87], and so on. Nevertheless, all these approaches
more or less suffer from security problems when used alone.
HE ensures data security by data encryption. In an HE-enabled FL approach, the first step is
to distribute the secret key to each participant [106]. The security of HE is based on the fact
that large prime number is difficult to be decomposed. However, there is no guarantee that the
key will not be hijacked during transmission. If that is the case, then the attacker can easily obtain original model parameters using the stolen key. However, with the development of quantum
computing, the conventional key distributions are not safe anymore [81]. DP, however, protects
data security by adding noise, which makes it more efficient for computation, but model performance is compromised. Secure multi-party computation also increases the computational and communication time complexity when performing model training, and requires a trustworthy third
party.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:3
Fig. 1. StarFL architecture. StarFL consists of three components: Federated Servers, Federated Clients, and
Beidou Satellite cluster.
In addition to security and efficiency considerations, in some urban computing scenarios, such
as real-time traffic analysis in autonomous driving, training dataset of each client should be aligned
with the same timestamps, and only positioning satellites can provide accurate timestamp service
[22, 73].
Inspired by Starlink, which is a satellite internet constellation being constructed by SpaceX providing satellite internet access [93], our vision is to build a federated learning network based on
(Beidou) satellites and edge devices. On the premise of security, this new network will be compatible with various edge devices in urban computing. In this article, we propose a new hybrid
FL architecture, called StarFL. By combining with Trusted Execution Environment (TEE), Secure Multi-Party Computation (MPC), and Quantum Key Distribution (QKD), StarFL can
provide more security guarantee. First, StarFL leverages satellite and quantum key distribution
technique to distribute the secret key, which ensures key distribution is theoretically safe; second,
StarFL allows each client to equip with TEE, making local model and local data more secure; third,
with the help of satellite services provider, StarFL can unify each device and make the data located
at each device with the same timestamps, respectively; data synchronization and alignment are
especially important in real-time data analysis scenarios.
Our new FL architecture is as shown in Figure 1. StarFL consists of three components: Federated Server, Federated Clients and Satellite cluster (such as Beidou Navigation Satellite System
(BDS) [37, 109],1 Global Positioning System (GPS) [63],2 GALILEO [6]
3). Federated clients consist of a variety of edge devices. Depending on hardware limitations and user requirements, each
device can decide whether to be equipped with TEE environment or not at discretion. Satellite
cluster is used to distribute secret key and provide accurate timestamp service. We will discuss
more details in Section 3. We first summarize our contributions as follows:
1BDS Official website: http://en.beidou.gov.cn/. 2GPS Official website: https://www.gps.gov/. 3GALILEO Official website: https://www.gsa.europa.eu/european-gnss/galileo/galileo-european-global-satellite-basednavigation-system.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:4 A. Huang et al.
Fig. 2. Data privacy categories.
• Compared to vanilla FL, StarFL utilizes satellite and QKD technique to distribute secret key,
which is safer than conventional key distribution.
• By combining with TEE, StarFL can provide more security guarantee for local model and
local data. Furthermore, with the help of model partition technique, StarFL can make the
training procedure more efficient.
• StarFL provides accurate timestamp service, so the data distributed in each device can be
aligned with the same timestamp.
2 BACKGROUND AND RELATED WORKS
2.1 Privacy-preserving Machine Learning
Privacy-preserving machine learning (PPML) has been widely studied for a long time. Training and testing AI model without compromising data privacy and security is the key problem of
PPML. According to the different stages of model training, literature [95] categorized data privacy
into the following four pillars:
• Model Privacy: Model privacy refers to model cannot be stolen by a malicious party. Model
privacy can be further divided into model architecture privacy and model weights privacy.
The capability of model prediction is the core competition among AI companies. Companies
will have little motivation to improve AI model performances if their competitors can easily
copy or steal their models.
• Training data Privacy: Raw dataset is the core and key concern of data protection act.
Risks exist that the attackers can reconstruct raw dataset by reverse-engineering.
• Input Privacy: Generally, raw data should be processed before it can be applied to AI model
for training. Raw data and input data can either reside in the same location or not.
• Output Privacy: Output privacy refers to the scenarios that the output of a model is not
visible by anyone except for the user whose data is being inferred upon.
As data privacy issues capture more and more attention nowadays, privacy-preserving computation technology has also become a hot research area. In this section, we briefly review PPML
techniques that are widely used in practice, including Federated Learning [45, 51, 52, 107], Trusted
Execution Environment [77, 84], and Secure Multi-Party Computation [116].
2.1.1 Federated Learning. The concept of federated learning was first proposed by Google in
2016 [9, 45, 47, 53, 64], which enables multiple devices to collaboratively learn a shared model
while keeping the training data on devices locally. Based on the data relationship between each
participant, federated learning can be categorized into the following three categories [106]:
• Horizontal Federated Learning (HFL): Also known as sample-based federated learning,
which refers to the scenarios that the data between different participants share the same
feature space but different in sample space, as shown in Figure 3. HFL is widely used in our
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:5
Fig. 3. Horizontal federated learning.
Fig. 4. Vertical federated learning.
Fig. 5. Federated transfer learning.
daily lives. The number of participants of HTL can be widely ranged from at least two to
billions.
• Vertical Federated Learning (VFL): Also known as feature-based federated learning,
which refers to the scenarios that the data between different participants share the same
sample space but different in feature space, as shown in Figure 4. Compared to HFL, the
number of participants of VFL is relative small, typically ranged from two to less than a
hundred.
• Federated Transfer Learning (FTL): FTL involves two roles, one is called source party,
the other is called target party. Both roles can involve in multiple parties. The datasets of
these two parties are different not only in samples but also in feature space, as shown in
Figure 5. The key concept of FTL is to learn knowledge from source party and transfer it to
the target party without compromising data privacy and security.
2.1.2 Trusted Execution Environment. The definition of Trusted Execution Environment
(TEE) was first proposed by OMTP (Open Mobile Terminal Platform). In 2009 [74], they released a standard document named “ADVANCED TRUSTED ENVIRONMENT: OMTP TR1,” and
define TEE as a “set of hardware and software components providing facilities necessary to support
Applications,” which had to meet the requirements of one of two defined security levels. The first
security level, Profile 1, was targeted against only software attacks, while Profile 2 was targeted
against both software and hardware attacks. [74]
Briefly, TEE is an isolated environment of the main processor for executing code, which guarantees codes and data loaded inside are confidential [84]. TEE had been widely used in many
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:6 A. Huang et al.
Fig. 6. Traditional TEE architecture.
security-sensitive scenarios, such as premium content protection/digital rights management, mobile financial services, authentication, secure modular programming, government, and so on.
The definition of TEE is clear. However, there can be many different implementation details.
According to the standard introduced by GlobalPlatform [33], a traditional TEE architecture is as
shown in Figure 6. In 2010, GlobalPlatform published a more detailed definition of TEE from the
interface and protocol implementation perspective [94]; it summarizes the characteristics of TEE
into the following three aspects:
• TEE Security is guaranteed by the cooperation of software and hardware.
• TEE is an isolated environment of the main processor, which runs in parallel with the untrusted rich operating system execution environment (REE).
4
• TEE provides interfaces API for applications on the REE side to call.
Since TEE is a hardware-based security solution, most of the current TEE implementations are
developed and supported by well-known hardware manufacturers, such as Intel’s SGX-enabled
CPUs [44], Arm’s TrustZone [3], AMD PSP [2], Apple SEP, and so on.
Intel SGX: Intel Software Guard Extensions (Intel SGX) was first introduced in 2015 with the
sixth-generation Intel Core microprocessors. SGX offers hardware-based memory encryption that
isolates specific application code and data in memory. The key concept behind Intel SGX is an
enclave. Enclave is a protected environment that contains the code and data of a security-sensitive
computation.
Arm TrustZone: TrustZone is an implementation of the TEE GlobalPlatform standard, which
utilizes both hardware and software to protect data; its architecture is similar to Figure 6. Arm
TrustZone was introduced from ARMv6 architecture, it separate CPU World Status into Normal
World Status (NWS) and Secure World Status (SWS). TrustZone relies on trusted OS and requires
trusted OS to be installed on device in advance. Unlike SGX, trusted OS has independent hardware
resources, which does not share with rich OS.
AMD PSP: AMD Platform Security Processor (AMD PSP) is a trusted execution environment
subsystem incorporated since about 2013 into AMD microprocessors. Essentially, AMD PSP is a
processor-embedded secure runtime environment subsystem responsible for creating, monitoring,
4REE is another area inside the main processor, which refers to the standard operating system that the device is running.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:7
Fig. 7. Secure multi-party computation.
and maintaining the security environment, and its duties include managing the PC boot sequence,
initiating security-related mechanisms, and monitoring the system for any suspicious activity or
events [2].
Apple SEP: Apple Secure Enclave Processor (Apple SEP) is a dedicated processor for features
such as data protection, Touch ID, and Face ID. The SEP is responsible for handling keys and
other information such as biometrics that is sensitive enough to not be handled by the application
processor [79].
2.1.3 Secure Multi-party Computation. Secure Multi-Party Computation (MPC) is a cryptographic definition that reveals no intermediate information during the whole computation except
for final results. MPC was formally introduced as secure two-party computation (2PC) in 1982
by Andrew Yao [110, 111] and generalized to the multi-party by Goldreich, Micali, and Wigderson
in 1987 [68].
Definition: Given n participants p1,p2,...,pn, each of which has independent private dataset, denoted as d1,d2,...,dn, respectively. For any given public function f , participants want to compute
the value of f on that private data: f (d1,d2,...,dn ), while keeping their own inputs secret. Furthermore, the output value of f can be split into multiple parts, and each participant can get only
a subset of it, as shown in Figure 7.
The goal of MPC is to design a protocol to exchange messages with each other without compromising privacy and security. We will discuss some common protocols when implementing MPC,
including secret sharing, garbled circuit, zero-knowledge proof, and homomorphic encryption.
Secret Sharing: Secret sharing (also called secret splitting) refers to methods for distributing a
secret among a group of participants, each of whom is allocated a share of the secret. The secret can
be reconstructed only when a sufficient number, of possibly different types, of shares are combined
together; individual shares are of no use on their own. Secret sharing was invented independently
by Adi Shamir [87] and George Blakley [8] in 1979.
Garbled Circuit: Garbled circuit is a cryptographic protocol, which enables two-party secure
computation. Two participants can jointly evaluate a function over their private inputs without
the presence of a trusted third party. In the garbled circuit protocol, the function has to be described
as a Boolean circuit.
Zero-knowledge Proof: Zero-knowledge proof was first proposed in 1989 by Shafi Goldwasser,
Silvio Micali, and Charles Rackoff [34], which refers to one party (the prover) can prove to
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:8 A. Huang et al.
another party (the verifier) that they know a value x, without conveying any information apart
from the fact that they know the value x. The essence of zero-knowledge proof is that it is trivial to
prove that one possesses knowledge of certain information by simply revealing it. The challenge
is to prove such possession without revealing the information itself or any additional information
[101].
Homomorphic Encryption: The concept of homomorphic encryption (HE) was first proposed by Rivest et al. in 1978 [82]. HE is an encryption technology that allows operations on
encrypted data and generates encrypted results; the value obtained by decrypting the result is
the same as direct calculate on plaintext. HE is widely used in federated learning due to its high
security characteristics.
2.2 Federated Learning Security Mechanisms
As we had mentioned above, FL requires model parameters (or gradients), rather than raw data,
to be transmitted between different participants. This strategy can significantly mitigate privacy
leakage risk. However, more and more studies have shown that private information can still be
divulged by analyzing the uploaded parameters or gradients [66, 120], such as model inversion
attack [28, 29, 115] and membership inference attack [30, 88]. In this section, we review security
mechanisms that are widely used in federated learning to protect data and model privacy.
Using differential privacy as the security mechanism of federated learning has been widely studied. McMahan et al. [65] proposed DP-FedAVG algorithm, which incorporates differential privacy
into federated learning, leading to formal guarantees of user-level privacy. Geyer et al. [32] proposed an algorithm for client-side differential privacy preserving federated optimization; the experimental results show that it can hide clients’ contributions during training and balance the
tradeoff between privacy loss and model performance. In Reference [4], the authors interpret federated learning algorithm as a composition of several Markov kernels and express the DP privacy
parameters as the product of contraction coefficients of such kernels.
Due to strong security guarantee, applying HE to federated learning is also a feasible solution.
Hardy et al. [39] implemented third-party vertical federated learning via entity resolution and additively homomorphic encryption. Zhang et al. [114] presented a system solution, called BatchCrypt,
for cross-silo FL that substantially reduces the encryption and communication overhead caused
by HE. Xu et al. [104] proposed HybridAlpha algorithm for privacy-preserving federated learning
employing an SMC protocol based on functional encryption.
Incorporation of MPC and FL is another research direction. Dong [21] utilized secret sharing
as security protocols in federated learning, and the experiment shown this strategy achieves reliable performance, accuracy, and high-level security. Pysyft [83], a federated learning framework
developed by OpenMined, used MPC-based protocols (secret sharing, SPDZ, etc.) to protect data
privacy.
Due to the decentralization, transparency, and immutability, blockchain has became another
research hotspot of trusted computation. Some recent studies have begun to combine federated
learning with blockchain to improve the security of federated learning. Li et al. [55] proposed a
decentralized federated learning framework based on blockchain; the framework uses blockchain
for the global model storage and the local model update exchange to address the attacks to the
global model or user privacy data. Kumar et al. [49] proposed blockchain-based federated learning
framework to collaboratively train a global model for COVID-19 detection. Ramanan et al. [80]
introduced BAFFLE, an aggregator-free, blockchain-driven, FL environment that is inherently decentralized, BAFFLE leverages smart contracts (SC) to coordinate the round delineation, model
aggregation, and update tasks in FL.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:9
2.3 Federated Learning in Urban Computing
In recent years, the rapid development of federated learning has made it among the top choices in
urban computing. Liu et al. [59] proposed federated digital gateway to help algorithm engineers
to easily deploy FML methods for real-life tasks. Lu et al. [61] proposed a differentially private
asynchronous federated learning scheme for resource sharing in vehicular networks. Hu et al. [42]
developed a novel inference framework, named Federated Region- Learning (FRL), for urban
environment sensing.
Generally, in urban computing, data transmission between different devices is usually through
wireless networks, which make the limited communication bandwidth become the main bottleneck
of FL. To this end, many advanced FL architectures were proposed. Chen et al. [14] proposed a
joint learning and communications framework for FL over wireless networks; the authors built an
explicit relationship between the packet error rates and the performance of the FL algorithm, so
the optimization problem can be simplified as a mixed-integer nonlinear programming problem.
By harnessing the signal superposition property of a wireless multiple-access channel, Yang et al.
[105] proposed an algorithm to enable fast global model aggregation for on-device distributed
federated learning. Khan et al. [46] present a Stackelberg game-based approach to develop an FL
incentive mechanism to motivate the participation of the devices in the federated learning process.
Niknam et al. [72] summarized key challenges of federated learning in the context of wireless
communications and described some open problems as future research directions.
2.4 Secret Key Distribution
Key distribution refers to share cryptographic keys between two or more parties for secure computation. As we mentioned in Section 1, key distribution is the first step of HE-based federated
learning. How to distribute secret key safety is a hot research area of cryptography.
Traditional encryption schemes can be divided into symmetric encryption and asymmetric encryption. In symmetric cryptography, both parties must possess a shared secret key for encryption
and decryption, such as AES, RC4, DES, and so on. While in asymmetric cryptography, Asymmetric Encryption encrypts and decrypts the data using two separate cryptographic keys.
2.4.1 Conventional Key Distribution. Diffie–Hellman key exchange [19], and a series of subsequent algorithms based on that, are the most popular methods of securely exchanging cryptographic keys over a public channel. The key point of its success is the use of number theory, that is
to say, the security of conventional key distribution relies on the computational difficulty of certain
mathematical functions. However, there are two major disadvantages when using in practice:
• When we execute conventional Key distribution, we cannot guarantee the security of the
transmission; as shown in Figure 8, this type of attack is also known as Man-in-the-middle
attack (MITM) [12]. Until now, MITM is still the main threat in traditional key distribution.
• Since conventional key distribution relies on the computational difficulty, there is no theoretical guarantee of the security. That is to say, based on the current computer processing
power, it takes a very long time to crack the key; the longer the time, the higher the security.
However, with the development of quantum technology, calculations that take millions of
years to complete on traditional electronic computer may only take a few hours on quantum
computer.
2.4.2 Quantum Key Distribution. Quantum key distribution (QKD) [56, 60, 86, 90] is a new
secure communication approach, which was first proposed in 1984 [7]. QKD can send secret key
between two remote parties. Recent studies demonstrated that entanglement-based QKD between
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:10 A. Huang et al.
Fig. 8. Man-in-the-middle attack.
Table 1. Comparsion of Quantum Key Distribution and Conventional Key Distribution
Quantum key distribution Conventional key distribution.
Theoretical Basis Relies on the foundations of
quantum mechanics
Relies on the computational difficulty
of certain mathematical functions.
Security Guarantee?
Yes, security is guaranteed by
the basic principles of
No-cloning theorem.
No, it make takes long time to be
cracked by electronic computer, but
only a few hours by quantum
computer.
Distribution Devices Satellite Server, Electronic computer
two ground stations separated by 1,120 kilometres at a finite secret-key rate of 0.12 bits per second,
without the need for trusted relays. Entangled photon pairs were distributed via two bidirectional
downlinks from the Micius satellite to two ground observatories in Delingha and Nanshan in China
[113].
Generally, information transmitted by Quantum communication would be encoded as quantum states or qubits, and photons are used for these quantum states. Unlike conventional key
distribution, QKD is unconditionally secure in theory, and its security is guaranteed by the basic
principles of quantum mechanics. The quantum no-cloning theorem [11, 57] shows that any
quantum state cannot be cloned perfectly. Therefore, any eavesdropping on the quantum key
distribution process may change the quantum state itself and cause a high bit error rate. As such,
eavesdropping or hijacking initiated by malicious party can be discovered. There are several
protocols that are widely used to implement QKD, such as BB84 [90], E91 protocol [25].
Based on these advantages, satellite-based QKD becomes a preferred solution of federated learning for key distribution. We summarize the key differences between Quantum key distribution and
conventional key distribution in Table 1.
3 STARFL: HYBRID FEDERATED LEARNING ARCHITECTURE
Our StarFL architecture is shown in Figure 1; it consists of three components, including federated
server, federated clients, and satellite cluster. We first summarize the role and functionality of each
part as follows:
• Satellite cluster: Without loss of generality, in this article, the satellite system refers to the
Beidou Navigation Satellite System (BDS) [37, 109]. As mentioned in Section 2.4.1 and
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:11
Fig. 9. Local training with TEE.
Section 2.4.2, traditional key distribution approaches are not theoretically safe, especially it
cannot prevent the transmission channel from being hijacked. StarFL uses Beidou satellite
cluster as key distribution device and utilizes quantum key distribution to send secret keys
to each participant. Quantum No-cloning theorem ensures that QKD is theoretically safe
[102].
BDS can also provide accurate timestamp service; with the help of this service, data distributed in each device can be aligned with the same timestamp, which is especially important in real-time analysis. We show real-world application cases in Section 4.
• Federated Clients: StarFL clients consist of different edge devices, each of which would be
equipped with TEE environment, as shown in Figure 9. Each client performs model training
inside TEE environment. We will discuss detailed implementation in Section 3.2.
• Federated Server: Like vanilla FL, the main functionality of federated server, including but
not limited to model aggregation, orchestrating the training steps of the algorithms, and
coordinating all the clients during the learning process.
3.1 StarFL Workflow
To make our description more concise, we first simplify StarFL architecture (as shown in Figure 10).
The training procedure can be boiled down to the following five steps:
• step 1: Authentication. Before federated training starts, all participants should upload identification to Beidou satellite, and only authorized devices can participate in federated training.
• step 2: Key distribution. Satellite uses quantum key distribution technique to distribute the
key to each participant for encryption and decryption.
• step 3: Federated server selects subset of participants and sends global model parameters to
these selected clients.
• step 4: Federated client receives global model parameters, replaces local one, and executes
local training with local dataset in TEE environment.
• step 5: Remote attestation. Federated server receives remote attestations of each client provided by TEE and verifies the credibility of the model training. Only verified and trusted
clients will send updated model parameters back to federated server for model aggregation.
After model aggregation is complete, StarFL finishes one epoch, then repeats from step 3 to
step 5 until model converge.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:12 A. Huang et al.
Fig. 10. StarFL workflow.
Fig. 11. Local model training under TEE environment.
3.2 Secure Local Model Training with TEE
Local training refers to fine-tuning global model by local dataset. Recent studies demonstrated
that local model can leak private information [41, 50, 67, 85, 112], making it a potential security
concern of federated learning.
TEE provides an isolated environment of the main processor, couples with a set of software and
hardware security mechanisms powered by hardware manufacturers, making it a powerful tool
to protect data privacy and security [35, 36, 38, 96, 99]. By combining with TEE, StarFL can send
local model and data to TEE environment for secure computation. The classical workflow of model
training inside TEE is as shown in Figure 11. Data and model would be first encrypted and sent to
TEE environment, and then perform model training under TEE environment; the updated model
would be decrypted and returned back to normal environment.
However, due to hardware limitation, it is difficult to train complex model efficiently under TEE
environment. To this end, Mo et al. [69, 70] proposed DarkneTZ, a FL framework that uses an
edge device’s Trusted Execution Environment in conjunction with model partitioning to mitigate
attack against neural network. By model partition, only part of layers would be sent to TEE for
training, thus making it feasible to train complex model efficiently. The detailed procedure is as
follows: Supposing G represents local model, we split G into two parts: untrusted part and trusted
part. Untrusted part (denoted as G1) consists of low-level layers and is mainly responsible for
feature extraction; G1 runs on rich execution environment (REE). While trusted part (denoted
as G2) consists of high-level layers, usually fully connected layers, and is responsible for output
prediction, unlike G1, G2 run on trusted execution environment (TEE), as shown in Figure 12.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:13
Fig. 12. Split model into two parts, untrusted part and trusted part.
Fig. 13. Local model training procedure of StarFL.
In summary, DarkneTZ’s local model training procedure is as shown in Figure 13.
• Step 1: Let G be the initial local model. We first split G into two parts, denoted as G1 and
G2. Usually, G1 is the first few layers of G, G2 can be last few layers, also known as full
connected layer. Fully connected layer can be realized only by matrix multiplication and can
be supported by TEE. G1 part would be trained on normal environment (also known as rich
execution environment, REE), while G2 part would be trained on TEE.
• Step 2: Local dataset D would be fed into G1 and perform forward computation.
• Step 3: The outputs of G1 (denoted as O1), along with G2 and D, would be sent to TEE
and perform the remaining forward operations. After this end, we calculated loss function
L(Yˆ,Y ), where Yˆ represents predicted output, Y represents true output of D.
• Step 4: Using back-propagation algorithm to calculate gradients of G1 and G2, then utilize
gradient descent to update model parameters. Repeat from step 2 until model converge.
To evaluate system performance, Mo et al. [70] conduct experiments on two datasets, CIFAR-100
and ImageNet Tiny, for two popular neural networks, AlexNet [48] and VGG-7 [92]. We summarize
the key experiment settings as follows:
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:14 A. Huang et al.
• The experiments ran on Open Portable TEE (OP-TEE),
5 which provides software environment to run on top of Arm TrustZone-enabled hardware. The model is implemented based
on the Darknet DNN library.6
• The experiments used Hikey 960 board7 to simulate edge device.
• The experiments evaluate the performance of DarkneTZ with three metrics, including CPU
execution time, memory usage, and power consumption for both model training and model
inference.
• Partition strategy refers to partition model layers into two parts, one of which runs inside
REE environment, while the other runs inside TEE environment. To evaluate how partition
strategy would influence the algorithm performance, the experiments set different partition
rate and observe changes of model performance.
• To evaluate partition strategy performance, we set the baseline as when all model layers are
out of the TrustZone during model training, i.e., local model training without TEE.
• AlexNet has five convolutional layers, with kernel sizes 11, 5, 3, 3, and 3, respectively, followed by fully connected layer; VGG-7 has seven convolutional layers, with kernel sizes all
equal to 3, followed by fully connected layer.
We reproduced the experiments with the open source code provided by the author.8 We test the
performance of model training and model inference on CIFAR-100 and ImageNet Tiny.
Figure 14 shows our reproduced results on CPU execution time. Horizontal axis represents the
number of layers in TrustZone, 1 refers to the last model layer (softmax layer) inside the TEE, 2
refers to the last two model layers inside the TEE, and so on. Vertical axis represents average CPU
execution time of each epoch.
We set baseline represents no model layer inside TEE. The results show that training model with
TEE only slightly increases CPU execution time. Even for the last four layers inside TEE, the CPU
execution time is also no more than 5% higher than the baseline.
Figure 15 shows our reproduced results on memory usage. Like CPU execution time, model
training inside TEE only slightly increases memory usage. All these results show that it is practical
to execute the model training in the TEE environment and do not cause much efficiency loss.
4 STARFL EMPOWERS SMART URBAN COMPUTING
Data-driven smart city management is the trend of future urban computing. However, these data
often reside in different devices and are difficult to be shared between each other. In this section,
we provide two application cases and show how StarFL can empower urban computing in practice.
Autonomous Driving: Traditional autonomous driving for path planning mainly relies on realtime roadside data provided by on-board equipment. However, due to limited perception and distance of vehicle devices, it is difficult to capture road information comprehensively. Therefore, recently researchers proposed Vehicle Infrastructure Cooperative Systems (VICS), as shows in
Figure 16, which combines vehicle system and roadside sensors to provide more detailed roadside
information.
Vehicle devices and roadside sensors constitute federated clients. Before we start federated training, we need to ensure the training data of each client is aligned with the same timestamp. With
the help of StarFL, we perform the following two steps to achieve this goal (as shown in Figure 17):
5OP-TEE: https://www.op-tee.org/. 6Darknet: https://pjreddie.com/darknet/. 7Hikey 960 board: https://www.96boards.org/product/hikey960/. 8DarkneTZ code: https://github.com/mofanv/darknetz.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:15
Fig. 14. The CPU execution time of each epoch.
• Step 1: Each client (vehicle or roadside sensors) sends two request signals to BDS and requests BDS to provide two accurate timestamps (T1 and T2) for each client.
• Step 2: Processing local dataset and only those timestamps (t) located betweenT1 andT2 (i.e.,
T1 ≤ t ≤ T2 ) would be satisfied.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:16 A. Huang et al.
Fig. 15. The Memory usage of each epoch.
After filtering out the dataset for each client, we can follow StarFL workflow (described in Section 3.1) to execute federated model training.
Resource Exploration: Resource exploration refers to utilization of satellite images to find out
possible resources, such as oil, minerals, and so on. Some common applications are shown in
Figure 18.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:17
Fig. 16. Intelligent vehicle infrastructure cooperative systems.
Fig. 17. Utilize time service to select training dataset of each device; all these data have the same timestamp.
Fig. 18. Resource exploration applications.
In this case, we utilize remote sensing satellites [75, 76, 97] to provide high-resolution images.
It is worth noting that, unlike communications satellite and navigation satellite, remote sensing
satellite exists as federated client.
Applying StarFL to resource exploration is shown in Figure 19. In this case, each remote sensing
satellite associates with one base station, and this combination constitutes one federated client,
At the beginning, high-resolution images are generated by remote sensing satellite, and then
these images would be sent back to their corresponding base station. After that, We can follow the
steps described in Section 3.1 to perform model training.
5 CHALLENGES AND FUTURE WORKS
In this article, we propose StarFL, a new hybrid federated learning architecture, to provide more
security guarantee during federated training. However, there are still many difficulties and challenges to be solved when applying to real-world application.
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
43:18 A. Huang et al.
Fig. 19. Applying StarFL to resource exploration.
• Challenge 1: Compared to traditional key distribution, QKD ensures key distribution is theoretically safe. However, there are still many challenges to realize long-distance and secure
quantum communication in practice. Channel loss and detector noise restrict the scope of
application of QKD. How to obtain higher key generation rate and longer distance transmission is an urgent problem that needs to be solved.
• Challenge 2: System efficiency. The primary motivation of StarFL is security; to this end,
StarFL introduces two new technologies: QKD and TEE, which make our system theoretically safer than traditional FL architecture. However, due to the additional workload, system
efficiency would become a bottleneck in real-world application.
• Challenge 3: To realize the interconnection between satellite and edge device, it requires
users to rent dedicated devices and transmitters. In most cases, it is not easy to integrate
into the current system, which makes it lack flexibility and need to bear additional costs.
Besides, we notice that, in this article, the system design and applications are mainly focused
on horizontal federated learning. However, in StarFL architecture, satellite cluster is independent
of federated server and federated clients, which makes it easy to extend to support VFL or FTL.
6 CONCLUSION
Privacy-preserving machine learning is one of the hottest research areas in both industry and
academia. The future of urban computing not only relies on the rapid development of AI, but
also needs to pay more attention to the data security and privacy. In this article, we propose
a new FL architecture, called StarFL, to solve the drawbacks when applying federated learning
to urban computing. These drawbacks include insecurity of secret key distribution, lack of verification mechanism for outputs and credibility of client model, and so on. By combining with
TEE and quantum key distribution, StarFL can alleviate these problems effectively. In addition,
from an application perspective, by accurate timestamp service, StarFL is also suitable for realtime sensitive scenarios, such as autonomous driving and other vision tasks. In the future of urban computing, high-frequency and high-volume data will be continuously generated from edge
ACM Transactions on Intelligent Systems and Technology, Vol. 12, No. 4, Article 43. Publication date: July 2021.
StarFL: Hybrid Federated Learning Architecture for Smart Urban Computing 43:19
devices, and StarFL can help to implement large-scale collaborative learning without compromising data privacy.