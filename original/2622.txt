The effective training of supervised Person Re-identification (Re-ID) models requires sufficient pairwise labeled data. However, when there is limited annotation resource, it is difficult to collect pairwise labeled data.
We consider a challenging and practical problem called Early Active Learning, which is applied to the early
stage of experiments when there is no pre-labeled sample available as references for human annotating. Previous early active learning methods suffer from two limitations for Re-ID. First, these instance-based algorithms
select instances rather than pairs, which can result in missing optimal pairs for Re-ID. Second, most of these
methods only consider the representativeness of instances, which can result in selecting less diverse and less
informative pairs. To overcome these limitations, we propose a novel pair-based active learning for Re-ID.
Our algorithm selects pairs instead of instances from the entire dataset for annotation. Besides representativeness, we further take into account the uncertainty and the diversity in terms of pairwise relations. Therefore,
our algorithm can produce the most representative, informative, and diverse pairs for Re-ID data annotation.
Extensive experimental results on five benchmark Re-ID datasets have demonstrated the superiority of the
proposed pair-based early active learning algorithm.
CCS Concepts: • Computing methodologies → Visual content-based indexing and retrieval;
Additional Key Words and Phrases: Active learning, person re-identification
1 INTRODUCTION
Person Re-Identification (Re-ID) has become an attractive real-world application in the field of
computer vision in recent years [9, 37]. It is usually modeled as an image retrieval problem: Given
a probe image of one person, Re-ID models target to re-identify the same person from a gallery of
images of peoples from non-overlapping camera views. Provided with sufficient pairwise labeled
data, existing studies have shown that supervised Re-ID algorithms can achieve encouraging performance [9, 36, 37]. However, producing pairwise labeled data is difficult in practice. First, since
the probe and the gallery images are captured from non-overlapping camera views, there are uncontrollable variations of appearances across camera views, such as view angle, occlusion, and
illumination conditions [30], which makes it hard to assess correctly whether a pair of images is
of the same person. Moreover, in practice, there are a huge number of imposters [11]. Second, the
number of probe-gallery image pairs to be assessed is much more than the number of probe images
themselves. For these reasons, the annotation task for Re-ID is an extremely time-consuming and
tedious procedure in practice.
In this article, we consider person Re-ID as a retrieval problem such that the algorithms designed for this task require a pairwise label rather than an instance label. When the annotation
resource is limited, it is difficult to obtain sufficient pairwise labeled data. Therefore, it is essential
and necessary to carefully select a subset of the most contributive pairs of instances from all of
the unlabeled data for annotation. In this article, we consider a more challenging and practical
scenario, when there are not even any pre-labeled samples available as references. Early active
learning (EAL) [21] has been proposed to address this issue. Conventional active learning (AL)
[27, 34] usually requires a certain number of pre-labeled samples as a reference set and iteratively
or on-timely generating samples for annotation. Different from AL, EAL selects a subset of most
conducive samples for annotating from all unlabeled data without any pre-labeled sets. We illustrate the differences between EAL and AL methods for Re-ID. For AL methods, we simply display
the one-time verifying AL algorithms. For some AL algorithms, the verifying procedure can be
taken several times to gradually generate subsets V for annotation. For all EAL methods, it only
takes one time to select subsets V for annotation. Re-ID method are then trained as downstream
methods with these annotations. The annotations can be used for any kinds of Re-ID methods,
including those with Re-ID algorithms based on metric learning (e.g., with triplet loss) or feature
learning. We show the differences between EAL and AL in Figure 1.
However, straightforwardly, applying existing EAL will cause problems. In the original definition of EAL [17, 21, 35], it only focuses on selecting a representative subset of instances from
the entire dataset for annotation. It did not have a model to consider the pairwise relationship
such that directly using the instances selected from EAL for pairwise annotation in Re-ID will
not provide the best performance. Specifically, there are three problems: First, because existing
EAL algorithms [17, 21, 35] select the most representative samples instead of pairs of samples,
they may miss the most important pairs that are crucial to Re-ID performance. Second, previous
EAL algorithms consider only the representativeness of instances. They fail to take into account
the uncertainty, which is essential in active learning schema [26]. For Re-ID tasks, we notice that
selecting pairs with higher uncertainty (e.g., pairs that are hard to assessed correctly) will bring
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.
Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-ID 21:3
Fig. 1. Illustration of EAL vs. AL methods for Re-ID. For AL methods, we simply display the one-time verifying AL algorithms. For some AL algorithms, the verifying procedure can be taken several times to gradually generate subsets V for annotation. For all EAL methods, it only takes one time to select subsets V for
annotation.
more information and enhance the robustness of the Re-ID models. Third, none of the existing
EAL methods considers the diversity of pairs or instances. As a result, similar instances might be
selected to be annotated, which will negatively affect the performance of Re-ID, as it is sensitive
to relativeness.
To overcome the limitations aforementioned, we propose a novel EAL algorithm for person
re-identification, called Early Active Learning with Pairwise Diversity Maximization (EAL-PDM).
To the best of our knowledge, we make the first effort to consider pair-based active learning and
simultaneously optimize pairwise uncertainty and diversity of samples for person Re-ID in an
early active learning scenario. The main contributions of our work are summarized as follows:
—We propose and define a person re-identification probability especially for the pairwise
uncertainty estimation in EAL for Re-ID task.
—We introduce a pairwise diversity maximization criterion to enhance the diversity of selected pairs of samples. It is the first attempt that considers diversity in EAL.
—We propose an efficient algorithm to optimize the proposed objective function. Our optimization algorithm also guarantees to reach the optimum in the convergence.
2 RELATED WORKS
Active Learning and Early Active Learning. According to Ref. [21], active learning can be divided into two categories. In the first category, the algorithms aim to select the most informative
instances, such as query by committee [26] and uncertainty sampling [12, 28]. In the second category, the algorithms aim to select the most representative instances, such as cluster-based active
learning [20] and early active learning [21]. Early active learning (EAL) targets to solve the early
stage experimental design problem [21, 35]. It considers the scenario when there is no pre-labeled
reference sets available for importance analysis in active learning. EAL directly selects a subset of
the most conducive samples from all unlabeled data for annotation. However, such a problem is
NP-hard [21]. EAL selects a subset of the most representative samples from the entire dataset for
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.
21:4 W. Liu et al.
annotation. A representation learning-based method, Transductive Experimental Design (TED),
was proposed in Ref. [35], which optimizes with respect to the least square of representation loss.
To address the issue that TED is sensitive to outliers [21], an improved function is provided in Ref.
[21], which introduces a structured sparsity inducing norm to relax the EAL problem. In Ref. [17],
an EAL with pairwise constraint is applied to Re-ID. However, it is essentially an instance-based
EAL as the labeled pair are generated after the instances are selected. Moreover, all of the previous
EAL algorithms do not consider the uncertainty and diversity. The TED algorithm is proposed in
Ref. [35], which provides a least square loss function for representation loss, but is claimed to be
sensitive to outliers [19, 21]. In Ref. [21], the authors propose a structured sparsity inducing norm
to relax the EAL problem. In Ref. [17], the authors propose an early active learning algorithm with
pairwise constraint for Re-ID. However, as it is an instance-based EAL, the labeled pairs can only
be generated and annotated after the instances are selected. Moreover, all of the previous EAL
algorithms do not consider the uncertainty and diversity.
Person Re-identification. In this work, we mainly focus on using active learning for the supervised Re-ID methods. There are representation learning methods, such as Null Foley-Sammon
Transform Space learning (NFST) [36], which learns a discriminative space where the representations of the same person are forced to one data point. There are algorithms that provide handcrafted features such as local maximal occurrence (LOMO) features [14] and Local Binary Patterns
(LBP) features [32]. Recently, feature extraction via deep neural network is also applied to Re-ID
task [9]. For instance, in Ref. [13], each of the individuals is considered as one class and used to train
a convolutional neural network for feature learning. There are also metric learning methods, such
as Kernel Canonical Correlation Analysis (KCCA), Cross-view Quadratic Discriminant Analysis
(XQDA), marginal Fisher analysis (MFA) [33], and local Fisher discriminant analysis (LFDA) [32].
Compared with supervised Re-ID methods, semi-supervised and unsupervised methods requires
less (or no) labeled data [9]. There are semi-supervised Re-ID methods [3, 18, 29] and unsupervised
Re-ID methods [4]. It is worthwhile to mention that, in this article, we consider person Re-ID as a
retrieval task; most of the person Re-ID methods follow the setup [38]. As a result, the algorithms
under this setup require a pairwise label. However, in few of the other works [5], the Re-ID task is
formed as a classification task with, e.g., soft-max loss. Algorithms under this setup treat each person as one class and aim to classify if a given image belongs to a certain person. Our active learning
algorithm is not suitable for such algorithms because their training sets require an instance-wise
label.
3 THE PROPOSED FRAMEWORK
In this section, we introduce the overall framework of our pair-based early active learning methods
with pairwise uncertainty and a diversity learning term for Re-ID.
Notation. Let the superscript T denote the transpose of a vector/matrix, 1 be a vector/matrix
with all ones, and I be an identity matrix. Let Tr (A) be the trace of matrix A. Let ai and aj be the
i-th column vector and j-th row vector of matrix A, respectively. Let A, B = Tr(ABT) be the inner
product of A and B, and vp be the p -norm of a vector v. Then, the Frobenius norm of an arbitrary
matrix A is defined as AF = √
A,A. The 2-norm of a vector a is denoted as a2 = √
aT a. Let
vec (A) be a column vector generated from the matrix A by concatenating all column vectors of A.
3.1 Pair-based Early Active Learning
First, we propose the pair-based early active learning schema. The major purpose of early active
learning is to select an optimal subset V ⊂ X with sizem < n, where n is the number of samples in
unlabeled dataset X. The selected subset V is supposed to best represent the whole data X through
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.      
Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-ID 21:5
a linear transformation matrix A. Therefore, it is expected to maximize the potential performance
of the downstream supervised methods by labeling V and utilizing it as the training data.
Unfortunately, learning the optimal subset V is NP-hard [21]. Unlike the former works [17],
which provide a relaxation of the problem, we reformulate the problem to its equivalent problem by
introducing an indicator vector u ∈ Rn×1 with ui ∈ {0, 1}. The sample selected is assigned by ui =
1; otherwise, ui = 0. Therefore, we can represent V = Xdiag (u). Taking uncertainty and diversity
into consideration, the optimization problem of our algorithm is defined as:
min
A,u
R (X,A, u) + αI (X, u) + Ω (u),
s.t. uT1 = m, ui ∈ {0, 1}, (1)
where the first term R (X,A, u) is the representative learning function and the second term I (X, u)
is the uncertainty learning function, with α > 0 as a leverage parameter. The third term Ω (u) is
the diversity maximization term. For the first term, we formulate
R (X,A, u) = X − Xdiag (u) A2
F . (2)
The optimal V will minimize the representation learning loss R (X,A, u). Optimization of this loss
function chooses the most representative subset V to represent the whole set of data X with a
transform matrix A and an indicator vector u.
3.2 Pairwise Uncertainty and Diversity
Pairwise Uncertainty Estimation. To select the most informative subset of pairs of samples, a
common criterion is via uncertainty estimation. Uncertainty is essential in active learning schema
[26], but it is not considered in former EAL algorithms. In information theory, uncertainty is measured by entropy. When the instance has a high entropy, it means it has high uncertainty. In this
article, we propose to evaluate the uncertainty entropy of samples rather than the instance uncertainty, which is a more natural choice for the Re-ID problem. The major difference between
pairwise uncertainty and instance uncertainty is we propose a pairwise probability on pairs of
instances and then define the pairwise entropy such that the uncertainty in our algorithm is on
pairs of samples and measured by pairwise entropy. In order to achieve this, we first define the
person re-identification probability as
p(lij |xi, xj) = 1
1 + exp
xi − xj 2
M − η
 , (3)
where xi and xj are a pair of samples and lij is the pairwise label, and xi − xj 2
M = (xi −
xj)
TM(xi − xj). The person re-identification probability estimates how likely xi and xj belong
to the same person (i.e., lij = 1) or not (i.e., lij = 0). The positive semi-definite matrix M is a predefined metric and η > 0 is a threshold. Accordingly, xi and xj are more likely to belong to the same
person when xi − xj 2
M ≤ η. The matrix M for metric xi − xj M is predefined. In this article,
we use the Euclidean Distance, in which M = I. The discussion of learning M is left for specific
research topics such as metric learning [31]. Overall, the uncertainty of samples is estimated by
the pairwise entropy defined as:
H(xi, xj) = −1
2

i

j
p(lij |xi, xj) logp(lij |xi, xj). (4)
Then, we formulate the uncertainty learning function as
I(X, u) =
n
i
ui



n
ji
−H(xi, xj)


	
= uT ξ, (5)
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.       
21:6 W. Liu et al.
where for each element ξi ∈ ξ, we calculate ξi = n
ji −H(xi, xj), which estimates the sum of
pairwise uncertainty between xi and xj, j  i. Note that, to choose the pairs with high uncertainty,
we should minimize the negative entropy in the objective function.
In this section, we focus on pair-based early active learning for the person Re-ID problem. Person
Re-ID can be formed as an image retrieval task that aims to re-identify the same person across
non-overlapping camera views. Therefore, the analysis of pairwise relativeness of images across
different camera views is essential and important. In the active learning stage, it is desired to
select the most informative and diverse pairs of samples to generate training data to enhance the
performance of Re-ID methods. We evaluate the uncertainty and diversity of pairs of samples as
follows:
Pairwise Diversity Maximization. By maximizing the diversity, the pairs where samples are
similar to each other will be less likely selected. To evaluate the similarity, a similarity matrix K is
introduced. Each element of K can be defined as ki,j = −xi − xj /σ2 with σ as the scale parameter.
Decrease of σ will enlarge the scale of ki,j . We define
Ω (u) = 1
2

i

j
uiujkij = 1
2
uTKu. (6)
Given two samples xi and xj , ki,j will be larger if they are more similar to each other. Therefore,
minimizing Ω (u) will enforce the two samples not to be selected simultaneously (i.e, either ui or
uj or both of them are forced to zero).
Finally, the overall optimization problem in Equation (1) becomes:
min
A,u X − Xdiag (u) A2
F + αuT ξ +
1
2
uTKu,
s.t. uT1 = m, ui ∈ {0, 1}.
(7)
The first term in Equation (1) in the original formulation of vanilla EAL considers the representativeness of the instances in the data. In our algorithm, with the additional pairwise uncertainty
and diversity term, only the instances within important pairs will consider the representativeness.
4 OPTIMIZATION
In this section, we propose an effective algorithm to optimize the active learning problem formulated in Equation (7). Noticing that it is hard to solve Equation (7) with ui being an integer, we
relax the problem to
min
A,u X − Xdiag (u) A2
F + αuT ξ +
1
2
uTKu,
s.t. uT1 = 1,ui ≥ 0.
(8)
The objective function in Equation (8) can be solved by alternately optimizing A and u. After
getting the optimized continuous variable of u∗, the optimal indicator vector can be obtained by a
truncate function u = truncate (u∗,m), which sets the top m larger ui in u to be ones and the rest
to be zeros. Next, we discuss the optimization of Equation (8).
Optimize u with fixed A. With A fixed, solving the objective function in Equation (8) w.r.t. u
is a standard quadratic programming (QP) problem. We propose to solve it by an algorithm based
on the augmented Lagrange multiplier (ALM) framework [2]. First, we rewrite Equation (8) as
follows:
min
A,u 
x − Qu2
2 + αuT ξ +
1
2
uTKu,
s.t. uT1 = 1, u = p, p ≥ 0,
(9)
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.     
Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-ID 21:7
where 
x = vec (X) and Q = [vec (q1) ,..., vec (qn )] where qi = xiai
. The augmented Lagrangian
function of Equation (9) is formulated as
L (u, p,v, λ1, λ2) = v
2

uT1 − 1 +
1
v λ1
2
+ v
2




u − p +
1
v λ21




2
F
+ 
x − Qu2
2 + αuT ξ +
1
2
uTKu,
s.t. p ≥ 0.
(10)
Then, we can optimize u with fixed p = p∗ from
min
u L (u, p∗
,v, λ1, λ2) ⇔ min
u uTb +
1
2
uT Σu, (11)
where Σ = K +vI +v11T + 2QTQ and b = (λ11 −v1) + (λ21 −vp∗) + α ξ − 2QT
x. Thus, the optimal solution of u is
u∗ = Σ−1
b. (12)
After determining u = u∗, we can optimize p from
min
p≥0
L (u∗
, p,v, λ1, λ2) ⇔ min
p≥0




p −

u +
1
v λ2




2
F
. (13)
By solving the above optimization problem, the solution of p is
p∗ = pos 
u +
1
v λ21, 0

, (14)
where pos (z, ϵ ) is a truncate function that assigns zero to each element of z less than ϵ, i.e., ∀zi ∈
z, pos (zi ) = max (zi, ϵ ).
Optimize A with fixed u. Optimizing A in Equation (7) with u fixed can be calculated by a
closed-form solution.
A∗ = (VTV)
−1
VX, (15)
where V = Xdiag (u∗). The overall optimization algorithm for solving u is described in Algorithm 1. It can be verified that Algorithm 1 is converged.
ALGORITHM 1: Algorithm for solving problem in Equation (7)
Input: The data matrix X ∈ Rd×n, parameters α, v
1 Initialize A ∈ Rn×n, ∀ui ∈ u,ui = 1
n . Set p = u, λ1 = 0 and λ2 = 0.
2 while not converge do
3 Update Σ by Σ = K +vI +v11T + 2QTQ.
4 Update b by b = (λ11 −v1) + (λ21 −vp∗) + αξ − 2QT
x.
5 Compute u∗ by solving the linear system Σu = b.
6 Compute p∗ by p∗ = pos 
u∗ + 1
v λ2

.
7 Compute A∗ = (VTV)
−1VX.
8 Update λ1 by λ1 = λ1 +v × n
i=1 ui − 1

.
9 Update λ2 by λ2 = λ2 +v × (u − p).
10 Update v = ρv.
11 end
Output: u∗.
Convergence Analysis. In Algorithm 1, with A fixed, solving the objective function in Equation (8) w.r.t. u is a standard quadratic programming (QP) problem. On Steps 3–6, we propose to
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020. 
21:8 W. Liu et al.
solve it by an algorithm based on the ALM framework [2], which is converged. On Step 7, with
u fixed, optimizing A in Equation (7) can be calculated by a closed-form solution. Overall, Equation (8) will meet optimal by Algorithm 1 when both A and u are solved.
5 EXPERIMENTAL STUDY
We exam the performance of the proposed algorithm EAL-PDM along with six competitive active
learning algorithms. In the experiments, we first select the most representative and/or informative
samples for annotation via the active learning algorithms. Then, five supervised Re-ID algorithms
are trained and tested in order to evaluate the quality of the labeled samples. We run the comparison experiments on four widely referred Re-ID benchmark datasets and report the average result
of 10 trials of independent experiments.
5.1 Experimental Settings
5.1.1 Datasets. Four widely referred Re-ID benchmark datasets are utilized in the experiments.
(1) The VIPeR [6] dataset collects camera shots of 632 persons from two non-overlapping
camera views. The total number of images are 1,264, and for each person, there is one
image captured from each different camera. Variations of viewpoint and illumination condition appear frequently in the dataset.
(2) The PRID [7] dataset captures camera shots of 385 individuals from two distinct cameras.
One of the cameras collects images of 749 persons and the other one collects images of
385 persons. There are 200 persons being captured in both of the cameras.
(3) The i-LID [39] dataset contains camera shots of 119 individuals in an airport terminal.
There are 476 images captured by three non-overlapping cameras. Large occlusions are
observed because of the carry-on luggage and viewpoint variations.
(4) The CAVIAR [1] dataset records images of 72 individuals in a shopping mall. A total
number of 1,220 images are captured by two different cameras. There are 10 to 20 images
for each individual. In the dataset, the size of the camera shots varies significantly from
39 × 17 to 141 × 72. The DukeMTMC [25] datasets contain 1,404 identities. In total, it is
divided to 16,522 training images of 702 identities, 2,228 query images of the rest of the
702 identities, and 17,661 gallery images.
In the pre-processing stage, LOMO features for person image representation [14] are implemented for person images as in previous works [16, 24]. After rescaling all images to 128 × 48
pixels, we follow the default setting in Ref. [14] to produce LOMO features.
5.1.2 Active Learning Algorithms. Six active learning algorithms are compared with the proposed algorithm (i.e., EAL-PDM) in the experiments.
(1) Random: We randomly select samples for labeling as a baseline algorithm.
(2) K-means: As suggested in Ref. [21], we apply the K-means algorithm as another baseline.
Rank of the samples are sorted by their distances to the nearest cluster centers.
(3) QUIRE: [8] Active learning by Querying Informative and Representative Examples
(QUIRE) is an algorithm that uses a min-max margin-based approach to query the most
informative and representative samples. However, it requires a set of pre-labeled samples
to verify the importance of the unlabeled samples.
(4) TED: [35] Active Learning via TED is an early active learning method that selects the
most representative subset of samples from the unlabeled dataset. It formulates the subset
selection task as a regularized linear regression problem.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.
Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-ID 21:9
(5) RRSS: [21] Early active learning via Robust Representation and Structured Sparsity
(RRSS) is another early active learning algorithm. It introduces a 2,1-norm regularization
term to TED for robustness and structure sparsity. In their work, authors also propose a
kernelized algorithm RRSS_K with a Gaussian kernel.
(6) EALPC: [17] Early Active Learning with Pairwise Constraint (EALPC) is a recently proposed algorithm. It introduces a pairwise constraint to EAL in order to force the similar
representations to be close to each other. It also provides a kernelized version EALPC_K
with a Gaussian kernel.
5.1.3 Person Re-identification Algorithms. Five supervised Re-ID methods are applied to evaluate the performance of the compared active learning algorithms on the Re-ID task.
(1) NFST: [36] NFST space learning is a Re-ID method, which learns a discriminative subspace, where samples belonging to the same person are collapsed to a single point.
(2) KCCA: [16] KCCA method aims to learn a common subspace of the images of persons
from the non-overlapping cameras.
(3) XQDA: [14] XQDA seeks a discriminant low-dimensional subspace by cross-view quadratic discriminant analysis and applies metric learning in the space.
(4) kLFDA: [32] kLFDA applies a kernelized method with a closed-form solution to handle
large dimensional feature vectors by maximizing a Fischer optimization criterion.
(5) MFA: [33] MFA learns graphs that characterize the intra-class compactness and interclass
separability, and applies them for dimensionality reduction.
5.1.4 Settings. In the experiments, as advised in previous works [17, 24], we randomly split
each dataset into two subsets with an equal number of samples for training and testing. There are
no overlapping of persons in the training and the testing sets. To generate the probe and gallery
sets for Re-ID task, images captured from one of the camera views are chosen as the probe sets, and
the remaining images from the remaining camera views are assigned as gallery sets. Overall, we
randomly and independently split each of the datasets 10 times to generate 10 trials. The average
performance of all the trials are report as the final result.
The procedure of the experiments is as follows. First, we apply active learning methods to select
a certain number of samples and query a human annotator to label them. In this stage, annotators
are required to annotate each pair of selected samples. Then, the supervised Re-ID methods are
applied to train the Re-ID models. Finally, we evaluate the Re-ID performance on the testing sets.
We measure the performance of Re-ID models by a Cumulative Matching Characteristic (CMC)
curve, which is commonly introduced in Re-ID works [10, 14, 15, 17]. Specifically, CMC computes
the cumulative probability that an image in the top-k gallery set happens to match the probe image.
In the experimental study, we report the Rank One (CMC R1) matching accuracy from CMC for
simplicity. For each algorithm, we run a ten-fold cross validation strategy to grid search the optimal
parameters (if any) in a region of {10−4, 10−3,..., 1,..., 103, 104}.
5.2 Results Analysis
5.2.1 Performance of Active Learning for Re-ID. To investigate the performance of active learning for Re-ID, we employ the active learning methods to select 20% of total data for labeling on
four benchmark datasets. Then, the Re-ID methods are trained with the selected and labeled data.
We illustrate the testing results in Tables 1 and 2 in rank one matching accuracy. In the table,
active learning algorithms are displayed by rows and supervised Re-ID methods are displayed by
columns. In Table 1, we observe that:
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020. 
21:10 W. Liu et al.
Table 1. Rank One Matching Accuracy(%) on the Benchmark Datasets CAVIAR, VIPeR, PRID, and iLIDS
Dataset CAVIAR VIPeR
Algorithm NFST KCCA XQDA kLFDA MFA NFST KCCA XQDA kLFDA MFA
Random† 23.65 23.47 21.38 27.55 25.87 26.65 23.01 27.23 22.78 23.64
K-means† 26.90 25.99 22.05 27.74 27.40 27.59 26.16 27.59 23.15 24.39
TED† 29.78 28.70 29,42 27.94 28.08 27.45 28.53 28.43 25.75 26.09
QUIRE† 30.66 30.87 31.56 28.18 26.16 28.39 27.43 28.54 26.25 25.13
RRSS† 31.87 30.69 33.57 30.95 29.01 31.56 28.54 30.71 27.34 28.04
RRSS_K† 31.69 33.03 35.56 31.41 31.13 31.61 28.73 31.46 28.51 29.40
RRSS_K‡ 29.97 31.28 33.69 30.01 29.47 30.11 27.75 29.89 27.14 27.44
EALPC† 34.12 33.57 37.45 33.09 31.16 32.61 29.45 31.82 28.54 29.56
EALPC_K† 35.00 35.20 38.75 33.29 31.91 33.66 30.44 34.29 29.18 30.03
EALPC_K‡ 33.77 32.91 37.16 31.44 30.17 31.45 29.37 32.93 27.59 29.34
EAL-PDM† 36.29 37.13 39.55∗ 34.22 32.25 34.00 31.24 36.53∗ 30.02 30.53
EAL-PDM‡ 35.18 35.45 37.28 32.70 30.19 32.54 28.98 35.82 28.29 29.87
Dataset PRID iLIDS
Algorithm NFST KCCA XQDA kLFDA MFA NFST KCCA XQDA kLFDA MFA
Random† 24.49 25.47 24.00 23.50 20.00 25.96 23.40 25.00 23.35 25.00
K-means† 26.16 27.54 27.01 24.70 21.20 27.02 23.94 27.00 25.57 25.20
TED† 27.72 27.71 29.32 24.33 22.11 29.15 25.33 28.13 27.33 29.20
QUIRE† 27.24 26.90 29.33 24.40 22.50 28.72 25.74 28.03 29.48 30.20
RRSS† 29.21 28.44 30.00 25.09 23.97 28.11 27.66 30.82 30.08 30.55
RRSS_K† 30.33 29.03 31.05 25.30 24.10 29.17 27.37 32.00 30.30 31.10
RRSS_K‡ 28.29 28.19 29.42 24.71 23.96 28.11 26.28 29.85 29.04 29.71
EALPC† 32.22 30.63 31.03 25.90 25.60 29.26 27.66 32.34 30.43 31.60
EALPC_K† 32.70 31.50 33.40 26.06 25.70 31.19 28.72 34.00 31.60 32.47
EALPC_K‡ 31.76 29.81 33.07 25.96 25.57 29.67 28.30 33.84 29.93 31.67
EAL-PDM† 33.08 33.95 35.27∗ 27.10 25.91 35.39 29.25 36.22∗ 33.42 33.14
EAL-PDM‡ 31.15 32.73 35.01 26.90 25.18 34.29 28.91 35.34 31.93 31.87
Algorithms run with LOMO features are marked with †. Algorithms run with IDE-ResNet features are marked with ‡.
Twenty percent of the samples are selected for labeling. The rows are active learning algorithms. The columns are Re-ID
algorithms. For each Re-ID methods, the best result w.r.t. active learning algorithms is marked in bold. The best result in
all the Re-ID methods is marked with an asterisk(∗).
(1) All of the active learning algorithms achieve higher performance compared to the Random selection algorithm consistently on the four datasets. It verifies that the active learning algorithms can select contributive samples to improve the performance of the Re-ID
methods.
(2) For EAL algorithms, our algorithm EAL-PDM and EALPC, which is specified for Re-ID,
outperforms the former EAL algorithms RRSS and TED at around 5% to 7%. It implies
that the EAL algorithm that considers the pairwise relationships will enhance the active
learning performance for the Re-ID task.
(3) Moreover, our algorithm EAL-PDM consistently reports higher rank one matching accuracy than EALPC at around 2% on all of the four datasets. It further indicates that the
pair-based early active learning can enhance the Re-ID task and get better performance
than the instance-based algorithms EALPC.
(4) We further test the performance of different features LOMO and IDE-ResNet [13]. For
IDE-ResNet, we follow the standard procedure in Refs [9] and [13]. The deep neural
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.
Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-ID 21:11
Table 2. Performance on the Benchmark Dataset DukeMTMC
Algorithms Rank One Matching Accuracy(%) mAP(%)
NFST KCCA XQDA kLFDA MFA NFST KCCA XQDA kLFDA MFA
Random† 19.38 22.91 24.06 21.87 21.33 7.22 7.61 8.35 7.43 7.38
K-means† 21.02 23.39 25.17 22.72 22.22 7.25 8.11 9.30 7.58 7.53
TED† 24.49 24.51 24.89 23.42 23.54 8.62 8.66 8.83 8.18 8.23
QUIRE† 23.91 23.03 24.45 24.22 22.99 8.26 7.83 8.58 8.38 7.71
RRSS† 24.83 24.77 25.11 24.51 23.76 8.72 8.71 9.16 8.65 8.24
RRSS_K† 25.22 24.18 25.22 25.02 24.35 9.35 8.37 9.35 9.12 8.52
EALPC† 25.32 24.90 26.32 25.88 24.23 10.21 9.07 11.13 10.94 8.43
EALPC_K† 26.47 25.33 26.80 25.11 26.39 11.24 10.24 11.53 9.13 11.22
EAL-PDM† 27.13 25.64 28.58∗ 26.29 26.93 12.26 10.66 14.17∗ 11.02 12.01
EAL-PDM‡ 27.91 23.32 27.75 22.10 21.87 12.82 7.99 12.42 7.49 7.43
Algorithms run with LOMO features are marked with †. Algorithms run with IDE-ResNet features are marked with ‡.
Twenty percent of the samples are selected for labeling. The rows are active learning algorithms. The columns are Re-ID
algorithms. For each Re-ID methods, the best result w.r.t. active learning algorithms is marked in bold. The best result in
all the Re-ID methods is marked with an asterisk(∗).
network are pre-trained on the ImageNet dataset and fine-tuned with the annotated
dataset. Images of each person appear as one class and we use output of the fc7 layer
that produces a 2,048-dimensional feature vector. As shown in Tables 1 and 2, our algorithm with LOMO feature outperforms the IDE-ResNet feature on CAVIAR, VIPeR, PRID,
and iLIDS. On DukeMTMC, our algorithm with the LOMO feature outperforms the IDEResNet feature except with NFST as the downsteam Re-ID algorithm. For our task, we only
select 20% of the training data for annotation. Given DukeMTMC is larger than the other
four datasets, the absolute number of training instances is larger than others. We thought
that might be the reason why IDE-ResNet feature algorithm reports better performance
than the LOMO feature with NFST on DukeMTMC.
5.2.2 Influence of the Number of Selected Instances. In order to investigate the influence of
the number of selected instances, we record the rank one matching accuracy while increasing the number of selected instances. We employ XQDA on behalf of the Re-ID methods as it
reports the best performance in Table 1. In Figure 2, specifically for the convenience of comparisons, we record the number of instances rather than the number of pairs for all AL algorithms. In
the experiments, we observe that:
(1) All of the active learning algorithms outperform the baseline algorithm, i.e., random selection. It confirms that even the number of selected samples are very small (e.g., 5); the
active learning algorithms can select contributive samples to enhance the Re-ID methods.
(2) All of the Re-ID algorithms are gradually improved when the number of selected instances
increases. It indicates that increasing the amount of useful labeled data will improve the
performance of the Re-ID task.
(3) Our algorithm EAL-PDM consistently outperforms the rest of the active learning algorithms when the number of selected instances varies. More specifically, our algorithm
distinctly outperforms the remaining algorithms since more than 50 instances are selected.
It implies our algorithm can efficiently select useful pairs of samples to enhance the Re-ID
tasks.
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.
21:12 W. Liu et al.
Fig. 2. Rank One Matching Accuracy(%) w.r.t. Number of Selected Samples. XQDA is chosen as the Re-ID
algorithm and trained with samples determined by the active learning methods with different amounts.
5.2.3 Convergence. In order to verify the convergence, we force our algorithm to run 50 iterations and record the object values on the benchmark datasets. We illustrate the performance of the
CAVIAR dataset in Figure 3(a), and the performance on the other three datasets is very similar. We
fix α = 0.1 and set the percentage of selected samples to 20% in the experiment. It can be observed
that the object values decrease very quickly in around the first 10 iterations and barely changes
after that. It implies that our algorithm converges very fast.
5.2.4 Diversity Analysis. We investigate the diversity of our algorithms compared to EALPC
on dataset i-LID, both of which aims to analyze pairwise relativeness in Re-ID active learning. We evaluate the diversity via calculating the average pairwise similarity (APS) defined as
1
2S

xi,xj ∈V,ij exp{−xi − xj /σ2} where σ = 2 is a scale parameter. S is the number of pairs constructed by the samples V determined by the active learning algorithms. Ideally, higher APS indicates the similarity of selected pairs is averagely large.
As shown in Figure 3(b), we can observe that the average pairwise similarity of our algorithm is
consistently lower than EALPC. When the number of selected instances is lower than 30, the APS of
EALPC is very high. It indicates that the instance-based algorithm cannot select diverse samples.
On the contrary, our algorithm consistently reports lower APS (around 0.8) in the experiments
ACM Transactions on Intelligent Systems and Technology, Vol. 11, No. 2, Article 21. Publication date: January 2020.  
Pair-based Uncertainty and Diversity Promoting Early Active Learning for Person Re-ID 21:13
Fig. 3. Convergence and Diversity Analysis. The leverage parameter is α = 0.1, and 20% of the samples are
selected for annotation.
Table 3. Ablation Study on DukeMTMC Dataset
Algorithms Rank One Matching Accuracy(%) mAP(%)
EAL_rep 31.25 12.88
EAL_rep + uncertainty 33.80 15.37
EAL_rep + diversity 32.62 13.22
EAL_rep + uncertainty + diversity 35.27 17.13
The best result is marked in bold.
even when the number of selected instances are very few. It indicates that our algorithms could
select less similar pairs, which improves the diversity of the selected data.
5.2.5 Ablation Study. The ablation study on DukeMTMC dataset are as follows, which utilizes
LOMO feature and XQDA as the downstream re-ID method. We denote our algorithm with only
the first representativeness term as EAL_rep. As shown in Table 3, utilizing an uncertainty or
diversity term will enhance the performance of naive EAL. Overall, our full algorithm with both
uncertainty and diversity terms reports the best performance.
6 CONCLUSION
In this article, we have proposed a novel pair-based early active learning algorithm with pairwise
diversity maximization for person re-identification. Instead of selecting instances, the proposed algorithm aims to select the most contributive pairs of instances for annotation, which is essential for
supervised person re-identification. Moreover, the proposed algorithm also takes into account both
uncertainty and diversity in terms of pairwise relations. Experimental study on five benchmark
datasets demonstrates the superior performance of our algorithm over several state-of-the-art active learning algorithms in Re-ID tasks. For future works, we suggest applying our algorithm to
our works which are depended on the pairwise relatedness, such as image matching and the like.
It is possible to extend our algorithm to relativeness sensitive algorithms, e.g., image matching
and social network analysis [22, 23]. For feature dimension, our algorithm is not sensitive when
n >> d for large datasets with large sample numbers.