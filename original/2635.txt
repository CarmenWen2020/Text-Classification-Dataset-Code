Cloud computing extends Transportation Cyber-Physical Systems (T-CPS) with provision of enhanced computing and storage capability via offloading computing tasks to remote cloud servers. However, cloud computing cannot fulfill the requirements such as low latency and context awareness in T-CPS. The appearance
of Mobile Edge Computing (MEC) can overcome the limitations of cloud computing via offloading the computing tasks at edge servers in approximation to users, consequently reducing the latency and improving
the context awareness. Although MEC has the potential in improving T-CPS, it is incapable of processing
computational-intensive tasks such as deep learning algorithms due to the intrinsic storage and computingcapability constraints. Therefore, we design and develop a lightweight deep learning model to support MEC
applications in T-CPS. In particular, we put forth a stacked convolutional neural network (CNN) consisting
of factorization convolutional layers alternating with compression layers (namely, lightweight CNN-FC). Extensive experimental results show that our proposed lightweight CNN-FC can greatly decrease the number
of unnecessary parameters, thereby reducing the model size while maintaining the high accuracy in contrast to conventional CNN models. In addition, we also evaluate the performance of our proposed model via
conducting experiments at a realistic MEC platform. Specifically, experimental results at this MEC platform
show that our model can maintain the high accuracy while preserving the portable model size.
CCS Concepts: • Computing methodologies → Artificial intelligence; • Computer systems organization → Embedded and cyber-physical systems;
Additional Key Words and Phrases: Convolutional neural network, model compression, factorization, mobile
edge computing, cyber physical systems, Jetson TX2 module
1 INTRODUCTION
In recent years, we have witnessed the proliferation of various physical objects connected in a
wireless/wired manner to form the Internet of Things (IoT). IoT enables the interactions between
the physical environment and computing platforms, consequently constructing cyber-physical
systems (CPS) [Wang et al. 2018]. During the CPS interaction, learning from massive IoT data is
a critical step to extract valuable information to make intelligent decisions. The recent advances
in machine learning and deep learning bring opportunities in extracting valuable information
from massive IoT data. However, many machine learning (especially for deep learning) methods
have stringent requirements on computing devices while most of IoT devices do not fulfill these
requirements due to the storage and computing limitations. The appearance of cloud computing
can overcome the limitations of IoT devices via offloading computing tasks to remote cloud
servers [Wang et al. 2019].
Despite the strength in data storage and computing capability, cloud computing cannot fulfill
the growing application requirements such as low latency and context awareness. Recently, Mobile
Edge Computing (MEC) [Mao et al. 2017], as a complement to cloud computing, can potentially
overcome the limitations of cloud computing by offloading tasks at edge servers deployed at base
stations (BSs), access points (APs), and gateways in approximation to users [Wang et al. 2017a,
2017b]. Take the traffic-sign recognition in Transportation Cyber-Physical Systems (T-CPS) or
intelligent transportation system (ITS) [Deka et al. 2018] as an example. Traffic-sign recognition
plays an important role in developing T-CPS [Luo et al. 2017]. User requests initiated from mobile
devices can be redirected to a nearest edge server (a device mounted in the car) instead of obtaining
the results from a remote cloud sever. In this manner, the latency can be greatly reduced and the
context awareness can be also improved.
1.1 Architecture of MEC-Cloud Architecture for T-CPS
Figure 1 shows a MEC-Cloud architecture to support T-CPS. This architecture consists of three
elements related to MEC deployments: (1) Road Side Units (RSU) with MEC. In T-CPS, RSU is
an infrastructure node co-located with BSs or APs along the roadside. In the MEC-Cloud architecture for T-CPS, MEC servers can be deployed at RSUs to support the applications of detecting
and tracking vehicles, relaying traffic information (such as traffic signs and traffic lights) sent by
vehicles. (2) Portable Navigation Devices (PNDs) or On Board Units (OBUs) with MEC. A
PND is a portable electronic product that combines a positioning capability (acquired by Global
Positioning System) and navigation functions. An OBU is a device installed at a vehicle. MEC
servers can be deployed at both PNDs and OBUs to collect location information, route structures,
and traffic flow data, consequently offering assistance to drivers. (3) Transportation Control
Center (TCC) with MEC. The TCC is a supporting system for both PND, OBU, and RSU. During
the communication process, information is collected and transferred over the TCC. Without the
resource limitations, the TCC can provide comprehensive support to make an optimal decision
and apply the optimized strategies to the T-CPS.
In such MEC-Cloud architecture for T-CPS, MEC plays a crucial role in offering low-latency and
context-aware services to RSUs, vehicles (especially for PNDs and OBUs), and TCC. Several recent
studies investigate MEC technologies in T-CPS. For example, Yang et al. [2017] and ContrerasCastillo et al. [2017] show that MEC is an efficient technology to support Internet of Vehicles
(IoV). Kaiwartya et al. [2016] have proposed a comprehensive IoV five-layer architecture based
on the cloud, connections, and clients. The work of Showering [2016] proposed a navigation
system based on mobile computing devices.
Nowadays, more and more applications depend on MEC technology, including secure IoT service [Wu et al. 2019], detection of hidden data attacks in sensor-cloud system [Zhang et al. 2018],
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:3
Fig. 1. MEC-cloud architecture for T-CPS.
and resource management in smart city systems [Wang et al. 2019]. In particular, vehicles may
communicate with other vehicles through the network in real-time when they connect to the distributed edge devices. Therefore, MEC is an efficient technology to support IoV, since the MEC
server can be installed in various places at the network edge. Datta et al. [2017] proposed an architecture of IoT that considers additional enablers such as edge and cloud platforms, smart-phones,
and powerful OBUs to support T-CPS.
1.2 Limitations of Deep Learning Models in MEC of T-CPS
However, MEC servers are still incapable of computational-intensive tasks such as deep learning
algorithms due to the storage and computing constraints. For example, deep convolutional neural
network (CNN) models, as one of the most typical deep learning schemes, show the advantages
in learning complicated and hierarchical features of massive image data [Krizhevsky et al. 2012].
The work of Cirean et al. [2012] proposed a Multi-column deep neural network (MCDNN) structure, which has superior performance than other machine learning models in German Traffic Sign
Recognition Benchmark (GTSRB) [Namor et al. 2011]. Meanwhile, other deep CNN models such as
AlexNet [Krizhevsky et al. 2012], VGG [Simonyan and Zisserman 2014], GoogLeNet [Szegedy et al.
2015], and ResNet [He et al. 2016] also demonstrate the outstanding performance in image classification. Nevertheless, deep CNN models usually contain multiple layers with a large number of
parameters. As a result, CNN models typically have a large model size. Moreover, they also require
using strong processing devices (e.g., Graphics Processing Units) to train the models. In addition,
the large size of CNN models also results in the huge communication overhead in distributed CNN
model-training [Iandola et al. 2016]. Therefore, these drawbacks hinder the wide deployment of
CNN models in mobile and portable devices in T-CPS, e.g., RSUs, PNDs, or OBUs.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:4 J. Zhou et al.
1.3 Contributions
In this article, we design and develop a lightweight CNN model to support MEC applications in
T-CPS. Our model has advantages, including much smaller model size than that of conventional
CNN models while maintaining high accuracy in traffic-sign and vehicle classification. The main
research contributions of this article are summarized as follows:
—We put forth a stacked convolutional structure consisting of factorization convolutional
layers alternating with compression layers. In particular, the factorization convolution converts the conventional convolution into a depthwise convolution and a pointwise convolution, consequently reducing the number of unnecessary parameters. Moreover, we further
improve the efficiency of the activation function and reduce the redundant parameters by
using Concatenated Rectified Linear Units (CReLU) for compression layers. We name the
proposed model as lightweight CNN-FC.
—We conduct extensive experiments based on realistic datasets, including GTSRB dataset as
well as a vehicle dataset (namely, VCifar-100). We evaluate the performance of the proposed
Lightweight CNN-FC model with the comparison of other representative CNN models, including MCDNN [Cirean et al. 2012] model, VGG-16 [Simonyan and Zisserman 2014], and
AlexNet [Krizhevsky et al. 2012]. Our model outperforms the conventional models in terms
of higher classification accuracy and smaller model size. For example, our model has the
model size of 4.9 MB in contrast to 118.8 MB of VGG-16 while maintaining high accuracy
(i.e., above 98.9% in GTSRB dataset).
—We also evaluate the performance of our proposed lightweight model in a realistic MEC
platform. In particular, the MEC platform is mounted with a Jetson TX2 chipset released
by NVIDIA, which is a low-power embedded system with the support of lightweight deep
learning schemes. Experimental results also show that our model can obtain high accuracy
in the mobile MEC platform.
The remainder of this article is organized as follows: Section 2 describes related work in this article.
Section 3 presents our model structure. Sections 4–6 give the details of the main methods used in
our model. Experiment results are presented in Section 7. We conclude and discuss the future work
in Section 8.
2 RELATED WORK
We categorize the studies into two categories: (1) traffic sign recognition and vehicle recognition
in T-CPS and (2) lightweight approaches.
2.1 Traffic Sign Recognition and Vehicle Recognition in T-CPS
Nowadays, more and more T-CPS applications are applied in real traffic conditions. In particular,
T-CPS applications mainly focus on traffic sign recognition and they can detect objects of traffic
signs [Luo et al. 2017]. Traditional methods for traffic sign recognition are mainly based on various machine learning algorithms, including support-vector-machine (SVM) classifiers with local
image permutation interval descriptor (LIPID) [Tian et al. 2014] and sparse reprentations [Lu et al.
2012]. It is shown in Hoferlin and Zimmermann [2009] and Nguwi and Kouzani [2008] that Multilayer perceptron (MLP) performs with high accuracy and achieves low false positive rates during
identification of the characters on speed-limit signs in Bargeton et al. [2008]. The work of Sochor
et al. [2016] proposed a scheme that CNN can improve fine-grained vehicle recognition by extracting 3D information of input datasets from video data. In Zhang et al. [2017], a MEC-based model
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:5
Fig. 2. Lightweight CNN-FC model consists of factorization convolution layers and compression layers.
in a vehicular network was developed to support the computation off-loading process, thereby
preserving the service continuity in a mobile environment.
Recently, CNN approaches have shown excellent performance in various computer vision (CV)
applications such as traffic sign recognition. The work of Cirean et al. [2012] depicts Multi-column
deep neural network (MCDNN) structure and implemented the classification experiments for traffic signs on GTSRB dataset. MCDNN consists of multi standard CNNs architecture, which gathers
and integrates the results from each CNN. It is shown in Sermanet and LeCun [2011] that the
local and global features can be used for traffic sign recognization, consequently improving the
performance. The recent advances of CNNs have further promoted the proliferation of CV and
T-CPS applications. For example, deeper (more layers) CNN models have been proposed, including Alexnet [Krizhevsky et al. 2012] with 8 layers, VGG [Simonyan and Zisserman 2014] with 19
layers, and GoogLeNet [Szegedy et al. 2015] with 22 layers. The deeper CNN models can achieve
higher accuracy than shallower models [Simonyan and Zisserman 2014].
However, deep CNN models also result in a number of challenges, especially for the mobile
applications at IoT nodes and MEC devices. Due to the storage and computing limitations, mobile
devices cannot afford the intensive computing taks and the bulky model size of deep CNN models.
Therefore, it is necessary to design portable deep learning models to support T-CPS applications.
2.2 Lightweight Approaches
To reduce parameters while preserving accuracy in convolutional neural network, a common
method is to take an existing CNN model and simplify its structure. A straightforward way is to apply singular value decomposition (SVD) to a pretrained CNN model by Denton et al. [2014]. Meanwhile, network pruning [Han et al. 2015b] was proposed to replace the parameters with zero to
form a sparse matrix via the threshold. Recently, Han et al. [2015a] created an approach called Deep
Compression combining Network Pruning with quantization (to 8 bits or less) and Huffman encoding. In addition, BinaryConnect [Courbariaux et al. 2015], BinaryNet [Courbariaux and Bengio
2016], and XNORNetworks [Rastegari et al. 2016] are effective in quantization CNNs. Furthermore,
recent research has accelerated the CNNs via using simpler filters, such as MobileNet [Howard
et al. 2017] and SqueezeNet [Iandola et al. 2016]. MobileNet structure uses depth-wise seprable
convolutions to construct a lightweight deep neural network. Moreover, MobileNet can be used
for a wide range of applications effectively, such as object detection, face attribute extraction,
and large-scale geo-localization. SqueezeNet is a small CNN architecture and and can achieve the
equivalent accuracy level to AlexNet. SqueezeNet compresses a neural network with about 50
fewer parameters by replacing 3 × 3 convolution with 1 × 1 convolution than conventional CNN.
3 OVERVIEW OF ARCHITECTURE
In this article, we present a Lightweight CNN-FC model, which consists of two major components: (1) factorization convolutional layer and (2) compression layer. Figure 2 shows a layout of
this model, in which several factorization convolutional layers alternate with compression layers
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:6 J. Zhou et al.
to form a stacked structure. We then briefly describe the working procedure of the Lightweight
CNN-FC model.
(1) Image preprocessing. The recent study Buda et al. [2018] shows that the class-imbalance
problem in input datasets is detrimental to CNN models. Meanwhile, the traffic-sign
datasets such as GTSRB dataset often contain blurred, distorted, and blemished images,
consequently affecting the performance of CNN models. Therefore, we adopt data oversampling and augmentation methods [Chawla 2009] to solve the class-imbalance problem
and noisy data.
(2) Standard convolution. We choose a standard convolution structure to process the
traffic-sign images. The standard convolution structure consists of several convolutional
layers, pooling layers, and a fully-connected layer. The convolutional input is anm × m × r
image, wherem denotes the height (and also the width) of image and r denotes the number
of channels (e.g.,r = 3 in RGB model because of red, green, and blue channels). Meanwhile,
we choose b filters, each of which has a size of n × n × q in the convolutional layer, where
n is typically smaller than the dimension of the input image and q is equal to the number
of channels.
(3) Factorization convolutional layer. It is a key component in our Lightweight CNN-FC
model. In this layer, a conventional convolution is decomposed into a depthwise convolution and a pointwise convolution. Moreover, we also optimize the convolution stride to
reduce the computing cost. The number of factorization convolutional layers is denoted
by α. Details about this structure will be given in Section 5.
(4) Compression layer. Another key component in our Lightweight CNN-FC model is the
compression layer. We employ a Concatenated Rectified Linear Unit (CReLU) proposed
in Shang et al. [2016] to design a compression convolution filter that can significantly
reduce the number of unused parameters. Details about this structure will be introduced
in Section 6.
(5) Fully-connected layer. We next employ a fully-connected layer that consists of a number
of neurons to extract the main features of traffic signs. The calculation procedure is similar
to that in the standard convolution layer. In particular, we denote the number of neurons
by β, which is tuneable in our experiments.
(6) Optimizer. The loss function plays a critical role in prediction accuracy of CNN models. In this article, we also employ different optimizers to investigate the impacts of them
on the loss function. In this experiment, we select four optimizers to evaluate the performance of them. The selected optimizers are Stochastic Gradient Desce (SGD), Adagrad,
RmsProp, and Adam. We present the performance comparison of different optimizers in
Section 7.3.4.
(7) Evaluation on MEC platform. Finally, we also deploy our proposed lightweight model
to the mobile device to support MEC. In particular, we adopt Jetson TX2, formally released
by NVIDIA to conduct the experiments. The extensive experiments demonstrate that our
proposed lightweight model can provide a practical solution to T-CPS application with
high prediction accuracy while maintaining a portable model size.
4 IMAGE PREPROCESSING
First, we need to perform image preprocessing for massive traffic signs and vehicle datasets. In
general, raw datasets often have the imbalance class problem [Buda et al. 2018], since the origin
data is always raw and crude during experiments or productions. This problem is due to the fact
that the number of labels in a class is much larger than that of another class. For example, the
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:7
Fig. 3. Effect of oversampling. Origin data and oversampling data are represented in blue and in orange,
respectively. For example, the number of samples in Class 4 is 412 before oversampling becomes 1,020, thereby
balancing the number of samples in each category.
number of incurable-disease labels is much smaller than that of normal-disease labels. As a result, the learning model of incurable-disease group causes under-fitting, compared with that of
normal-disease group [Wang et al. 2014]. Therefore, it is confirmed that the class imbalance problem causes serious damage in classification mission. It will result in slow convergence in training
phase, meanwhile, weaken the generalization ability in test set. To solve this problem, the widely
used approach is oversampling [Jo and Japkowicz 2004].
In this section, we solve the class imbalance problem by adopting oversampling along with
data augmentation. In particular, oversampling directly optimizes the number of samples in each
class and averages the class distribution. This approach can solve the class-imbalance problem of
datasets. Figure 3 illustrates the number of samples before (in blue) and after oversampling (in
orange) in GTSRB dataset. It is shown in Figure 3 that the number of samples per class becomes
even after sampling.
It is worth mentioning that the effect of data augmentation is essential for solving the class
imbalance problem in image preprocessing. In particular, we focus on some specific categories;
the numbers of samples in these specific categories are much smaller than those of normal categories. However, just simply repeating the number of classes will lead to overfitting [Chawla et al.
2002]. To avoid overfitting, we employ data augmentation when oversampling. Data augmentation is an effective method, since it can obtain a number of images with different effects. In data
augmentation, we employ four different data augmentation methods as follows:
(1) Color Augmentation. Color enhancement includes adjusting color saturation, brightness, and contrast;
(2) PCA Jittering [Krizhevsky et al. 2012]. The feature value and feature vector can be obtained via calculating the mean and the standard deviation from RGB channels;
(3) Gaussian Augmentation. Images are processed with the addition of Gaussian noise;
(4) Rotation Augmentation [Szegedy et al. 2015]. Images are rotated within the designated
degrees (chosen within 0 to 10 degrees).
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:8 J. Zhou et al.
Fig. 4. From left to right: Origin picture; Color Augmentation processing; PCA Jittering processing; Gaussian
Augmentation processing; Rotation Augmentation processing.
Figure 4 shows the effectiveness of different data augmentation methods.
As a result, we expand the number of GTSRB dataset after oversampling along with data augmentation. Meanwhile, the major features of each image in the expanded dataset are still well
preserved as before. Therefore, the expanded dataset is beneficial to our model (to be illustrated
in Section 7).
5 FACTORIZATION CONVOLUTION
In this section, we describe the structure of factorization convolutional layer. Factorization convolutional layer can reduce the computing cost effectively, thus it can reduce the consumption of
computing resources at MEC devices. Figure 5 depicts the working procedure of the factorization
convolutional layer. Unlike the standard convolutional layer, a factorization convolutional layer is
decomposed into a depthwise convolution and a pointwise convolution. The depthwise convolution essentially factorizes the standard convolution into M depthwise convolutional filters, each
with a size of DK · DK . The pointwise convolution combines two outputs of depthwise convolution
through N pointwise convolutional filters, each with a size of 1 × 1.
5.1 Computational Cost
We next calculate the computational cost of the factorization convolution and evaluate the cost
reduction in contrast to the standard convolution operation. The computation costs of depthwise
convolutions and pointwise convolutions are denoted by Cdc and Cpc , respectively. Following the
similar steps in MobileNets [Howard et al. 2017], we have Cdc as the following equation:
Cdc = DK · DK · M · DF · DF , (1)
where DK · DK represents the convolution kernel size, the output feature map size is DF · DF , and
M is the number of input channels.
Meanwhile, the computation cost of pointwise convolution is calculated by
Cpc = M · N · DF · DF , (2)
where N is the number of output channels.
We denote the total cost of factorization convolutional operation by Cf , which consists of two
components Cdc and Cpc . In other words, we have
Cf = Cdc + Cpc = DK · DK · M · DF · DF + M · N · DF · DF . (3)
5.2 Cost Reduction
By contrast, we denote the computational cost of the standard convolution operation byCstd, which
can be calculated by the following equation:
Cstd = DK · DK · M · N · DF · DF . (4)
Compared with the standard convolution operation, the factorization convolutional operation
can significantly save the computational cost. In particular, we denote the cost-reduction gain of
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:9
Fig. 5. Factorization convolution layout.
factorization convolutional operation to standard convolution operation by Gr , which is given by
the following equation:
Gr = Cf
Cstd
= (DK · DK · M · DF · DF + M · N · DF · DF )
(DK · DK · M · N · DF · DF ) = 1
N
+
1
D2
K
. (5)
It is shown in Equation (5) that the cost reduction gain only depends on the number of output
channels and the convolution kernel size while it is independent of input size.
6 COMPRESSION LAYER
In our Lightweight CNN-FC model, we also construct compression layer to reduce the model size.
Therefore, the model can be installed at a small storage platform like MEC device. In this layer, it is
necessary to utilize a nonlinear activation function to represent and map features after convolution
operations. Compared with conventional activation functions such as Sigmoid and Tanh, Rectified
Linear Units (ReLU) can effectively mitigate the problem of gradient disappearance [Krizhevsky
et al. 2012]. ReLU is defined as:
y =

x if x ≥ 0,
0 if x < 0, (6)
where x denotes input value andy denotes output of activation function. When x ≤ 0,y = 0; otherwise, y = x. Using ReLU activation function can converge the network more quickly. Since ReLU is
still not saturated, it can resist the problem of gradient disappearance. Moreover, the computation
of ReLU is efficient via using a simple thresholding.
However, the recent study of Shang et al. [2016] shows sophisticated CNN models like AlexNet
taking ReLU, as activation functions may have redundant filters, consequently resulting in the
extra and unnecessary computational cost. Concatenated ReLU (CReLU) activation function can
overcome the drawbacks of ReLU with a simple but effective modification.
Figure 6 shows the structure of a compression layer with CReLU activation function. In particular, a negation operation and a concatenation operation are conducted before invoking the ReLU
activation function in contrast to the conventional ReLU activation function. Moreover, CReLU
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019. 
67:10 J. Zhou et al.
Fig. 6. Concept of CReLU.
can also help to reduce the redundant filters. Specifically, we can compress the CNN model via
halving the number of the filters by using CReLU compression layer.
We next analyze the relationship between CReLU and ReLU. We denote a signal by x. The nonnegative operation on x can be represented by
[x]+ = max(x, 0), (7)
where [x]+ denotes the non-negative value of x. For example, if x = 3, then [x = 3]+ = max(3, 0) =
3. If x = −3, then [x = −3]+ = max(−3, 0) = 0. The term [x]+ essentially represents the ReLU activation function, i.e., ReLU = [x]+. The activation function CReLU(x) is defined as the following
equation:
CReLU(x) = ([x]+,[−x]+). (8)
Combining Equation (7) with Equation (8), the following equation can represent the relation
between CReLU and ReLU:
CReLU(x) = [ReLU(x), ReLU(−x)]. (9)
7 EXPERIMENT
In this section, we conduct the experiments to evaluate the performance of the proposed Lightweight CNN-FC model. We first describe the experimental settings in Section 7.1. We then evaluate the performance of the proposed Lightweight CNN-FC model by comparing with conventional
CNN models in Section 7.2. Moreover, we also evaluate the impacts of parameters on the performance of the proposed Lightweight CNN-FC model in Section 7.3.
7.1 Experimental Settings
7.1.1 Experimental Environment. We perform the experiments on two platforms: a PC and a
MEC platform (i.e., Jetson TX2 module). Table 1 gives the detailed configurations of both the PC
and the MEC platforms. The software framework in our experiments is Keras 2.0 (i.e., Tensorflow
as backend) running on Ubuntu 16.04; this setting is the same as for both PC and Jetson TX2
Module.
It is worth mentioning that Jetson TX2 module is mainly designed for MEC with small size and
low power consumption. Figure 7 gives the description of Jetson TX2 module. In particular, this
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:11
Table 1. Experimental Environment
PC
Processor Intel Core i7-7700HQ
Memory (RAM) 16 GB
Graphics NVIDIA GTX 1050
Operating Systems Ubuntu 16.04
Jetson TX2 Module
Processor ARM Cortex-A57 + NVIDIA Denver2
Memory (RAM) 8 GB
Graphics NVIDIA 256-core Pascal
Operating Systems Ubuntu 16.04
Fig. 7. Detailed specifications of Jetson TX2 module.
embedded platform features an integrated 256-core NVIDIA Pascal GPU, a hex-core ARMv8 CPU,
and 8 GB of LPDDR4 memory.
7.1.2 Dataset Description. We conduct our experiments on two datasets mainly for T-CPS applications. The first dataset is GTSRB dataset, which has been widely used in evaluating classification algorithms in traffic sign recognition. GTSRB dataset contains more than 50K traffic sign
images, which have been categorized into 40 classes. We select three major categories: Speed-limit
signs, Direction signs, and Attention signs. Figure 8 shows some selected examples from each of the
datasets. In addition, we also need to solve the class-imbalance problem, since the number of traffic
sign images in each category has significant difference. Therefore, we first preprocess the dataset
via the aforementioned oversampling and data augmentation. To simplify our discussion, we name
the dataset containing Speed-limit signs as GTSRB-1, the dataset containing Direction signs as
GTSRB-2, the dataset containing Attention signs as GTSRB-3, and the dataset containing all the
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:12 J. Zhou et al.
Fig. 8. Examples from GTSRB dataset.
Fig. 9. Examples from VCifar-100 dataset.
three categories of traffic signs as GTSRB-T (GTSRB Total). After oversampling and augmentation,
the exact number of traffic signs in each category is shown in Figure 8. We can observe that the
class-imbalance problem is solved, since the number of traffic signs in each category becomes even.
Furthermore, we also construct a vehicle dataset consisting of vehicle images via extracting vehicle images from Cifar-100 dataset, which is a well-established object recognition dataset that
contains 100 classes and each class has 600 images collected by Krizhevsky [2009]. We name this
dataset as VCifar-100 dataset, which contains five classes: bicycles, buses, motorcycles, pickup
trucks, and trains. In addition, VCifar-100 dataset has no class-imbalance problem, since the number of samples in each category is identical (i.e., 500). Figure 9 shows several examples selected
from each class of the VCifar-100 dataset.
7.1.3 Comparison Algorithms. We evaluate the performance of the proposed Lightweight CNNFC model with other conventional CNN models as described in the following:
MCDNN [Cirean et al. 2012] is a multi-layer CNN model used for GTSRB dataset and performed
excellently (won the final phrase in the benchmark of German traffic sign recognition with even
better accuracy than human recognition in 2011). This model consists of 6 layers (i.e., 2 convolutional layers, 2 pooling layers, and 2 fully-connected layers).
AlexNet was proposed and developed by Krizhevsky et al. [2012]. It consists of 8 layers: 5 convolutional layers and 3 fully-connected layers. The activation function is ReLU.
VGG-16 was proposed and developed by Simonyan and Zisserman [2014]. This model significantly increases the number of layers in CNN architectures to 16 layers (the 19-layer version is
named as VGG-19). It consists of 13 convolutional layers and 3 fully-connected layers.
Factorization-Net is a CNN model with a single factorization convolutional layer. It can be
regarded as a special case of our proposed Lightweight CNN-FC model without compression
layers.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:13
Table 2. Accuracy on GTSRB and VCifar-100 Datasets
Models Model
Size
# of
Parameters
Accuracy
(GTSRB-1)
Accuracy
(GTSRB-2)
Accuracy
(GTSRB-3)
Accuracy
(GTSRB-T)
Accuracy
(VCifar-100)
AlexNet 30.2 MB 3,889,835 95.02% 96.60% 95.53% 96.31% 95.31%
VGG-16 118.8 MB 15,291,499 96.52% 97.29% 97.70% 98.60% 94.99%
MCDNN 19.7 MB 2,466,507 97.95% 97.79% 97.21% 98.50% 95.91%
Factorization Net 6.1 MB 754,373 96.75% 95.61% 94.95% 97.71% 95.11%
Lightweight
CNN-FC (PC) 4.9 MB 602,475
98.43% 98.61% 97.91% 98.96% 96.98%
Lightweight CNN-FC
(Jetson TX2) 97.14% 97.72% 97.79% 98.15% 97.16%
GTSRB-1: Speed-limit signs; GTSRB-2: Direction signs; GTSRB-3: Attention signs; GTSRB-T: GTSRB Total.
7.1.4 Performance Metrics. We conduct the experiments by considering two performance metrics: classification accuracy and model size. In particular, the classification accuracy is defined as
the ratio of the number of correct classifications to the total number of classifications. To evaluate
the model size, we mainly consider the total number of parameters of the trained models and the
file size of the trained models (in terms of MB).
7.2 Experimental Results
Table 2 presents the performance comparison of our proposed Lightweight CNN-FC model with
other conventional CNN models. It is worth noting that the experiments were conducted on five
datasets: GTSRB-1, GTSRB-2, GTSRB-3, GTSRB-T, and VCifar-100. In the experiments, we choose
the number of the factorization convolutional layers to be α = 4 and the number of of neurons in
the fully connected layer to be β = 256. Factorization-Net has the same number of the factorization
convolutional layers as our model.
Accuracy. It is shown in Table 2 that Lightweight CNN-FC model outperforms other existing
models in all the five datasets (GTSRB-1, GTSRB-2, GTSRB-3, GTSRB-T, and VCifar-100). For example, the accuracy of Lightweight CNN-FC model in GTSRB-T is 98.96%, which is the highest
among all the models even though MCDNN and VGG-16 achieve the close accuracy values to
our model. Furthermore, we ran Lightweight CNN-FC model on the mobile MEC device (Jetson
TX2) and obtained the accuracy on GTSRB-T; the accuracy on TX2 is 98.15%, very close to that
of PC. We can observe that accuracy of our model on MEC device is similar to that on PC with
different datasets even though PC platform has greater computation capability than MEC device
(see Table 1). Therefore, our lightweight structure is feasible after factorization and compression
procedure. The performance improvement of the proposed Lightweight CNN-FC model may be
attributable to the excellent characteristics of Lightweight CNN-FC model such as reducing the
unnecessary and redundant parameters.
Model size. Model size is an important parameter to evaluate the portability of CNN models in
MEC deployment. On one hand, the model can be easily loaded on MEC devices when its model size
is small enough. On the other hand, a portable CNN model is also beneficial in distributing training
in T-CPS. Table 2 also gives the comparison on the model size between the proposed Lightweight
CNN-FC model and other conventional models. It is shown in Table 2 that Lightweight CNN-FC
model has much smaller model size than those of other models. For example, Lightweight CNN-FC
model has the file size of 4.9 MB with 602,475 parameters, which is about 6.2× smaller than that
of AlexNet and 24.25× smaller than that of VGG-16 with high classification accuracy. Lightweight
CNN-FC model has even 4.02× smaller model size than that of the shallow structure MCDNN
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:14 J. Zhou et al.
Table 3. Comparison of Computational Cost
Convolution type Computational cost
Standard convolution 2,359,296
Factorization convolution 335,872
Fig. 10. From left to right: Accuracy and loss of Lightweight CNN-FC model with factorization convolution
only running on GTSRB-T. Left: Accuracy of training set is 97.71% and accuracy of validation set is 98.46%
after 10 iterations (i.e., converges). Right: Loss of training set is 0.0717 and that of validation set is 0.0603
after 10 iterations.
model. In summary, after analyzing both the accuracy and the model size, our Lightweight-FC
model is advantageous to be deployed at MEC equipment.
7.3 Impacts of Parameters
We then investigate the impacts of various parameters on the performance of Lightweight CNN-FC
model.
7.3.1 Effect of Factorization Convolution. In CNN, the computational cost is an important factor
reflecting the efficiency of algorithms. We first evaluate the computational cost of the factorization convolution of the proposed Lightweight CNN-FC model in contrast to that of a standard
convolution. In particular, the computational cost of the factorization convolution and that of the
standard convolution can be calculated by Equation (3) and Equation (4), respectively, as given in
Section 5. Specifically, we set parameters DK = 3, M = 32, N = 32, DF = 16. Table 3 summarizes
the computational costs of the factorization convolution and the standard convolution.
It is shown in Table 3 that the computational cost of the factorization convolution is much
smaller than that of the standard convolution (i.e., it is 7× cost reduction for factorization convolution). As a result, the model size of the trained model with the factorization convolution can also
be greatly reduced. Take Table 2 as an example. The model with factorization convolution only
(i.e., Factorization-Net) has the model size of 6.1 MB, which is much smaller than that of MCDNN
(with the standard convolution).
Meanwhile, the factorization convolution does not significantly affect the classification accuracy. Figure 10 shows the accuracy and loss values of the proposed Lightweight CNN-FC model
with factorization layer only (i.e., Factorization-Net). As shown in Figure 10, both the accuracy
and loss values of the model converge after 10 iterations. Moreover, the accuracy of training set
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:15
Fig. 11. From left to right: Accuracy and loss of Lightweight CNN-FC model with both factorization and
compression layers running on GTSRB-T dataset. Left: Accuracy of training set is 98.07% and accuracy of
validation set is 98.96% after 10 iterations (i.e., converges). Right: Loss of training set is 0.0609 and that of
validation set is 0.0603 after 10 iterations.
Table 4. Evaluation with Different Numbers of Factorization Convolutional Layers
No. of factorization layers Accuracy
(GTSRB-T)
Accuracy
(VCifar-100) Model Size No. of parameters
α = 1 95.25% 87.62% 3.38 MB 434,635
α = 2 97.09% 90.06% 3.5 MB 433,221
α = 3 97.16% 91.11% 4.3 MB 522,309
α = 4 98.96% 96.98% 4.9 MB 602,475
is 97.71%, which is just slightly lower than the accuracy of MCDNN model (i.e., 98.50%). We next
show that the higher accuracy can be achieved with the combination of compression layer.
7.3.2 Effect of Compression Layer. We next evaluate the impact of compression layer in our
proposed Lightweight CNN-FC model. We add compression layers with CReLU activation function. As shown in Table 2, the introduction of compression layers reduces the model size. For
example, Lightweight CNN-FC model has the model size of 4.9 MB, which is smaller than that of
Factorization-Net (with size of 6.1 MB).
However, the compression layers can further improve the classification accuracy. Figure 11
shows the accuracy and the loss values after the compression layers are added. Compared with the
model with factorization layer only (as shown in Figure 10), adding compression layer can further
improve the classification accuracy.
7.3.3 Effect of Number of Factorization Convolutional Layers. We then investigate the impact
of the number of factorization convolutional layers on the performance. We vary the number of
factorization convolutional layers from 1 to 4 (we denote the number of factorization convolutional
layers by α). It is worth mentioning that we also need to supplement compression layers between
factorization convolutional layers (as shown in Figure 2). The experiments were also conducted
on data GTSRB-T and VCifar-100 only.
Table 4 presents the results. It is shown in Table 4 that increasing the number of factorization
convolutional layers results in the increment of the classification accuracy while the model size is
also increased. Note that the increment of the model size is quite insignificant (e.g., enlarges from
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:16 J. Zhou et al.
Fig. 12. Evaluation of optimizers.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
Lightweight Convolution Neural Networks for Mobile Edge Computing in T-CPS 67:17
Table 5. Evaluation of Different Optimizers on Lightweight CNN-FC (α = 1)
Optimizers Model Size Accuracy (GTSRB-T) # of Parameters
Adagrad 3.38 MB 88.71% 434,635
Adam 5.03 MB 87.73% 434,635
RMSprop 3.38 MB 84.81% 434,635
SGD 3.38 MB 95.08% 434,635
3.5 MB to 4.9 MB when α increases from 2 to 4). This result implies that the proposed CNN is quite
portable and may be used for mobile applications.
7.3.4 Effect of Optimizers. In our lightweight structure, a suitable optimizer can improve the
performance during model training and parameter updating. Without loss of generality, our lightweight convolution model uses a single factorization convolutional layer (i.e., α = 1) and a compression layer. We then adopt four optimizers to evaluate the performance: Adagrad, Adam, RMSprop, and SGD.
Adagrad [Duchi et al. 2011]. Adagrad is a gradient-based optimization algorithm suitable for
dealing with sparse data. In our experiment, we adopt the learning rate as the parameter of Adagrad optimizer. Figures 12(a) and (b) show the accuracy and the loss of Adagrad, respectively. The
experiment results show that the convergence of the loss is pretty slow (see Figure 12(b)). For
example, when the accuracy is only 88.71%, the loss still maintains at 0.3328. Therefore, Adagrad
may not be a suitable optimizer in our model.
Adam [Kingma and Ba 2014]. Adaptive Moment Estimation (Adam) is an optimized method
that computes the adaptive learning rate for each parameter. In the second set of experiments, we
evaluate impact of Adam on Lightweight CNN-FC. Figures 12(c) and (d) show the accuracy and the
loss of Adam. We can find that Adam still results in slower convergence (e.g., when the accuracy
of training set is 87.73%, the loss of training set is 0.3610).
RMSprop [Tieleman and Hinton 2012]. RMSprop is an adaptive learning rate method proposed
by Geoff Hinton. It mainly contributes to resolving radically diminishing learning rates of Adagrad
optimizer. Figures 12(e) and (f) show that the accuracy and the loss fluctuate radically in training
phase. Furthermore, the model cannot converge after 10 epochs.
SGD [Bottou 2010]. SGD is an efficient optimizer, since it can eliminate the redundancy of computations for large datasets by performing one update at a time. Figures 12(g) and (h) show the
accuracy and the loss of the SGD optimizer. We observe from the results that SGD can effectively
achieve the convergence after 10 epochs.
Table 5 also compares the model size, the accuracy, and the number of parameters of all the
four optimizers. Compared with Adagrad, RMSprop, and Adam, we can draw the conclusion from
Table 5 that SGD is the best optimizer in our lightweight CNN-FC model, because SGD can achieve
the highest accuracy (i.e., 95.08%) and the minimum model size (i.e., 3.38 MB).
7.3.5 Effect of Number of Neurons in Fully-connected Layer. We also investigate the impact of
the number of neurons in the fully-connected layer. Similarly, we conduct the experiments on
dataset GTSRB-T and VCifar-100 only. In particular, we denote the number of neurons in the fullyconnected layer by β. We vary the values of β from 64 to 256. Meanwhile, we also compare the
lightweight CNN-FC with other conventional models when other parameters are fixed.
ACM Transactions on Intelligent Systems and Technology, Vol. 10, No. 6, Article 67. Publication date: October 2019.
67:18 J. Zhou et al.
Table 6. Evaluation on Number of Neurons in the Fully-connected Layer on GTSRB-T
β AlexNet VGG-16 MCDNN Factorization Net Lightweight CNN-FC
β = 64 78.29% 89.34% 96.17% 82.66% 95.97%
β = 128 93.51% 96.82% 97.85% 96.54% 97.04%
β = 256 96.31% 98.60% 98.50% 97.11% 98.96%
Table 7. Evaluation on Number of Neurons in the Fully-connected Layer on VCifar-100
β AlexNet VGG-16 MCDNN Factorization Net Lightweight CNN-FC
β = 64 91.15% 84.78% 91.55% 92.91% 95.67%
β = 128 93.59% 91.15% 94.71% 93.67% 95.71%
β = 256 95.31% 94.99% 95.91% 95.11% 96.98%
It is shown in Table 6 and Table 7 that the proposed Lightweight CNN-FC outperforms other
conventional models in terms of the highest accuracy when the number of neurons in the fullyconnected layer varies from 64 to 256. Moreover, the highest accuracy is achieved when β = 256.
8 CONCLUSION
In this article, we put forth a lightweight convolutional neural network used for MEC in T-CPS.
In particular, this model contains a stacked structure in which several factorization convolutional
layers alternate with compression layers. Our model has merits, including the small model size
while maintaining high classification accuracy. For example, the proposed Lightweight CNN-FC
model with four factorization convolutional layers has model size of 4.9 MB, which are much
smaller than other conventional CNN models. Meanwhile, the accuracy of the proposed model
also outperforms other models. This is mainly because of the optimized design on convolution
layers and compression layers, consequently removing the redundant parameters. Finally, we also
evaluate the performance of the proposed lightweight CNN-FC models by conducting experiments
on a realistic MEC platform
