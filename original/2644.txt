Transportation recommendation is one important map service in navigation applications. Previous transportation recommendation solutions fail to deliver satisfactory user experience because their recommendations only consider routes in one transportation mode (uni-modal, e.g., taxi, bus, cycle) and largely overlook situational context. In this work, we propose $\mathsf {Hydra}$ , a multi-task deep learning based recommendation system that offers multi-modal transportation planning and is adaptive to various situational context (e.g., nearby point-of-interest (POI) distribution and weather). We leverage the availability of existing routing engines and big urban data, and design a novel two-level framework that integrates uni-modal and multi-modal (e.g., taxi-bus, bus-cycle) routes as well as heterogeneous urban data for intelligent multi-modal transportation recommendation. In addition to urban context features constructed from multi-source urban data, we learn the latent representations of users, origin-destination (OD) pairs and transportation modes based on user implicit feedbacks, which captures the collaborative transportation mode preferences of users and OD pairs. Moreover, we propose two models to recommend the proper route among various uni-modal and multi-modal transportation routes: (1) a light-weight gradient boosting decision tree (GBDT) based recommendation model; and (2) a multi-task wide and deep learning (MTWDL) based recommendation model. We also optimize the framework to support real-time, large-scale route query and recommendation. We deploy $\mathsf {Hydra}$ on Baidu Maps, 1 1.
https://maps.baidu.com/.

one of the world's largest map services. Real-world urban-scale experiments demonstrate the effectiveness and efficiency of our proposed system. Since its deployment in August 2018, $\mathsf {Hydra}$ has answered over a hundred million route recommendation queries made by over ten million distinct users. The GBDT based model and MTWDL based model achieve 82.8 and 96.6 percent relative improvement of user click ratio, respectively.
SECTION 1Introduction
Transportation recommendation is a core component in various map services and has deeply penetrated into the everyday life of citizens. Transportation recommendation refers to a set of routes recommended to users given the specific OD pair input by users. Online map services such as Baidu Maps answer over a hundred million transportation recommendation queries made by over ten million distinct users in China per day.

Despite its popularity and frequent usage, existing transportation recommendation solutions still fail to deliver satisfactory user experience. After analyzing the user query log in Baidu Maps, we find a strong requirement of inter-modal transportation comparison. For example, over 15 percent of the users in Beijing tend to request transportation recommendations on different uni-modal routing engines (e.g., taxi and bus) for the same origin and destination pair. Furthermore, 89.1 percent of routing queries from users in Beijing are answered with feasible transportation recommendations, but over 58.5 percent of the transportation recommendation list has no user clicks (see Table 1 for detail), indicating none of the recommended transportation plans is satisfactory.

TABLE 1 Statistics of Datasets

The above observations indicate two limitations of current transportation recommendation solutions. (i) Ignorance of situational context. For instance, when a big concert lets out, it is difficult to call a taxi. A better solution may simultaneously consider multiple alternative transportation modes (as illustrated in Fig. 1) and recommend the most efficient one. (ii) Uni-modal transportation recommendation. For example, imagine the following scenario that the distance of the OD pair is relatively large, and the trip purpose is in no emergency. In this case, a cost-effective route that includes multiple transport modes, e.g., taxi-bus, maybe more attractive (as illustrated in Fig. 1b). Hence, the transportation recommendation should adapt to the situational context e.g., whether there is a concert, and provides more flexible recommendations, e.g., combining buses and taxis.


Fig. 1.
An example of user interfaces of Hydra on Baidu Maps. The left figure shows the list of plans in various transportation modes ordered by our recommendation model. The right figure shows the details of the top-1 recommendation, which is a multi-modal transportation plan (i.e., first take taxi and then bus). The first recommended plan is 26.3 percent faster than the pure bus plan and 61.2 percent cheaper than the pure taxi plan.

Show All

To address these limitations, we did some preliminary work [1]. First, we propose Hydra, a personalized and context-aware multi-modal transportation recommendation system. Inspired by the availability of existing routing engines and big urban data, we design a novel framework that integrates route plans in different transportation modes (including both uni-modal and multi-modal transportation plans) and heterogeneous urban data. To the best of our knowledge, this is the first product level intelligent routing engine that integrates various transportation modes in a unified service. Second, we design GBDT based recommendation model that is adaptive to the situational context. We extract a rich set of features from multi-source urban data to sense the context variation and adopt a graph embedding based algorithm to capture the transportation preferences of users and OD pairs. Third, in web-scale recommendation, the service scalability and online recommendation latency are also curial for user experience [2]. To address the service efficiency concern, we build a distributed offline data pipeline as well as an RPC based online web service framework. Besides, we propose a dedicated region index structure in online feature processing to reduce the online recommendation latency. Extensive real-world urban-scale experiments on real datasets show that our proposed framework outperforms baseline algorithms in four metrics. The online recommendation service achieves less than 250 ms latency on average and scales well in the production environment.

In this paper, we further improve our Hydra framework, and deliver the following four major contributions. First, we reformulate the multi-modal transportation recommendation problem as multiple binary classification problems and adopt the multi-task learning paradigm to decide the final recommendation across different transportation modes. Second, we propose a novel deep learning based recommendation model, Multi-Task Wide and Deep Learning (MTWDL), which extends the well-known wide and deep model [3] to the multi-task learning paradigm in the transportation area. Compared with the lightweight GBDT based model, MTWDL is more complex but powerful. Third, we provide two deployment strategies for MTWDL (i.e., server mode and mobile mode) and discuss some deployment trade-offs in a hundred million user level online map service. Fourth, we evaluate the efficiency and effectiveness of the MTWDL model and explore its influence on the whole system. Compared with six existing baselines and two new deep learning based baselines, MTWDL achieves the best performance in four metrics and shows impressive online latency and scalability performance.

SECTION 2Data Description and Analysis
This section introduces the datasets that will be used in the following sections, with a preliminary data analysis. All user behavior data, geographical data and user profile data are acquired from Baidu Maps (https://maps.baidu.com/), a large-scale navigation app. All meteorological data are crawled from the China government website (http://www.weather.com.cn/). Table 1 summarizes the statistics of the datasets.

2.1 User Behavior Data
User behavior data captures the user interactions with navigation applications. Our user behavior data are collected from Baidu Maps, from September 2018 to November 2018. According to a user interaction loop, the user behavior data can be further categorized into query records, display records and click records. In short, a query record represents one route search from a user on Baidu Maps; a display record is the routes recommended by Baidu Maps shown to the user; and a click record indicates the user feedback of different recommendations (i.e., a user may click on specific routes displayed to him/her for details, as in Fig. 1). Please refer to Appendix A, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org.ezproxy.auckland.ac.nz/10.1109/TKDE.2020.2985954, for a detailed data description.

We briefly explain the distributions of our user behavior dataset in Beijing (see Fig. 2a, 2b, 2c, 2d, and 2e). Note that similar observations held in Shanghai, which we omit due to the page limit. Fig. 2a and 2b depict the spatial distributions of origins and destinations in the query records. As can be seen, most origins and destinations are within the 6th ring road, i.e., the central area of Beijing. We further employ Moran's I [4] to quantify the spatial auto-correlation. Specifically, the auto-correlation of origin and destination are 0.23 and 0.49, respectively. The larger auto-correlation of destinations is possibly because most queries are about specific POIs such as transport stations and city landmarks. The spatial distribution patterns of origins and destinations motivate us to use geographical data to capture the spatial dependency for transportation route recommendation. Fig. 2c plots the temporal distributions of query, display and click records (i.e., numbers per day). We observe significant temporal fluctuations where peaks often correspond to weekends and holidays. For example, the peaks on the 22nd and 31st days correspond to the mid-autumn festival and the National day, two public holidays in China. Statistically, the 1st-order and 7th-order temporal auto-correlation [5] of queries are respectively 0.42 and 0.37, indicate the strong temporal dependency and week periodicity. Fig. 2d shows the distribution of trip distance from the queries. Here the trip distance is measured by the spherical distance on earth. Over 60 percent trips are within 10 Kms and 80 percent trips are within 20 Kms. This indicates short-distance and mid-distance trips are the major query demand on online navigation applications. Fig. 2e shows the distribution of clicks on different recommended routes. Above 54.64 percent clicks involve buses (i.e., bus and bus-bicycle) and 25.12 percent clicks are drive or taxi, indicating public and car-based transportation are more preferable.


Fig. 2.
Distributions of the Beijing dataset.

Show All

2.2 Geographical Data
Intuitively, geographical characteristics of origins and destinations partially reflect the situational context, and thus affect user preferences on transportation modes. Accordingly, we use a large-scale geographical dataset collected from (i) professional surveyors employed by Baidu Maps (ii) the crowdsourcing platform in Baidu, which include POI data, road network data and transportation station data in Beijing and Shanghai. All data are updated daily. We present a detailed data description in Appendix A, available in the online supplemental material.

2.3 Meteorological Data
Meteorological data tend to reflect the temporal dynamics of the situational context when planning trips, and thus may also affect the user preference on transportation modes. For example, the demand for taxis may be higher in the case of snow, rain and severe air pollution. We collect the meteorological data from September 1st to November 30th. Each record of meteorological data consists of an administrative district, a time stamp, the weather, the temperature, the wind strength, the wind direction and the Air Quality Index (AQI). The weather is categorized as sunny, cloudy, rainy and overcast. The AQI is an integer of the air pollution level.

2.4 User Profile Data
User profile attributes reflect individual preference on transportation modes. For instance, subways are more cost-effective than taxis for most urban commuters, and driving is likely to be the first choice for car owners. We collect user profile attributes from multiple Baidu applications including Baidu search, Baidu App and Baidu Maps. The Beijing dataset contains 1,199,399 distinct user records and the Shanghai dataset contains 1,217,140 distinct user records. Each record consists of a user's demographic attributes including the age, the gender, and social attributes such as the industry, the educational level, and whether the user is a car owner. All user profile records are anonymized and cannot be associated with sensitive personal information such as names and phone numbers. Fig. 2f plots the age distribution of Beijing dataset. Most Baidu Maps users are between 18 and 54 years old.

SECTION 3Problem Statement and Framework Overview
In this section, we first present the problem statement, and then overview the architecture of Hydra.

3.1 Problem Statement
Let M={m1,m2,…,mk} denote k different unary or multi-modal transport modes. Consider a user u∈U, a departure time t, and an OD pair (o,d), where o and d are arbitrary geographical locations represented by a pair of longitude and latitude. Our problem is to recommend the most appropriate transport mode mi∈M for the user u travel between (o,d) at t.

3.2 Framework Overview
Fig. 3 shows an overview of Hydra. It consists of four major components, Route generation, Feature construction, Transport mode preference representation and Transportation recommendation. The Route generation module leverages existing uni-modal routing engines to generate feasible routes in different transport modes. Thereafter, the Feature construction module extracts features from various urban datasets. Meanwhile, the Transport mode preference representation module captures high-order user (resp. OD pair) transport mode preference representation through a graph embedding method. Finally, the Transportation recommendation module integrates handcrafted features and embedding features to make recommendation. In this paper, we consider seven transport modes {drive,taxi,bus,cycle,walk,taxi-bus,bus-cycle}. In particular, the first five modes are uni-modal transport modes whereas taxi-bus and bus-cycle are multi-modal transport modes. taxi-bus and bus-cycle are already well supported in Baidu Maps. Besides, according to log analysis, we find the origin or destination of over 14 percent taxi queries are bus stations, and the origin or destination of over 18 percent cycle queries are bus stations. The above statistics do not mean all such queries are multi-modal trips but indicate a strong multi-modal transportation demand. Note that we treat each uni-modal and multi-modal transport mode as distinct transport modes, which makes our model extendable for other potential transport modes in a straightforward way. We left other multi-modal transport mode recommendation as future work.

Fig. 3. - 
$\mathsf {Hydra}$Hydra Overview.
Fig. 3.
Hydra Overview.

Show All

SECTION 4Route Generation
We adopt existing low level routing engines to generate feasible routes for each transport mode. First, when a query is received, a station binding process is applied to bind origin and destination locations to validate start and endpoints. For example, the location is bound to road segments for drive and taxi, and to transport stations for the bus. After that, we employ a task-parallel paradigm for route candidate generation. Specifically, we initialize multiple individual threads where each thread invokes a different routing engine to generate feasible routes in the corresponding transport mode. For each uni-modal transport mode, a bidirectional shortest-path search [6] is applied to each transportation network. Besides, the contraction hierarchy (CH) [7] is pre-constructed on the transportation network to reduce search latency. A set of valid routes is generated by various criteria, e.g., fastest, distance shortest, and least transfer. For multi-modal transportation, we propose a simple yet effective substitution based heuristic [8]. In particular, to generate multi-modal routes of taxi-bus and bus-cycle, we first generate a set of feasible bus routes based on the existing bus engine. For each bus route, we enumerate each station in the route and invoke the taxi and cycle engine to derive sub-routes from origin to current station and sub-routes from the current station to the destination, respectively. We concatenate the bus sub-route with the taxi sub-route to generate the taxi-bus route candidate, and combine the bus sub-route with the cycle sub-route to generate the bus-cycle route candidate. We restrict the number of modal-transfer less than two to guarantee the utility [9] of the concatenated route. The multi-modal route is added to the candidate set if it satisfies a certain criteria (e.g., faster than bus route, cheaper than the taxi route). We also build a pre-computed cache to prune infeasible mode-transfer stations for each OD pair to speed up the enumeration process. The substitution based heuristic yield about 300 ms multi-modal route generation time in average. The overall route generation process is summarized in Algorithm 1 of Appendix E, available in the online supplemental material. Finally, an internal rule based ranking model is applied in each transport mode to filter out routes with high segment overlap and decide the order of routes. For ease of cross-mode comparison, only one route of each transport mode will appear in the final display. In offline processing, the route is directly retrieved from user behavior data. In the production environment, a query understanding component will be invoked before route generation to bind fuzzy search keywords with concrete POIs. We omit further discussions since they are out of the scope of transportation recommendation.

SECTION 5Feature Construction
We introduce the process of constructing, transforming and augmenting feature vectors below. Appendix B, available in the online supplemental material, lists features we construct based on each dataset with a detailed description.

5.1 Plan Features
Cost of a plan such as Price and ETA are part of considerations for user preferences. For each plan, we extract Road network distance, Route distance, ETA, Price, Transfer count, Transfer model count from display records. The Road network distance is the real travel distance on the road network. For walking and cycling, Price is set to zero.

5.2 Spatial Features
We first extract District and POI category features of the origins and destinations. As shown in Fig. 4a, the transportation mode choices of different destination POI categories vary. For example, the demand for buses to Sports and Tourist Attraction POIs is higher than average. In contrast, the demand for buses to Beauty, Life Service and Food POIs is lower than average. The detailed POI categories in Fig. 4a are listed in Table 2 of Appendix A, available in the online supplemental material. Then we calculate the Spherical distance of OD pairs. Fig. 4b shows the relation between trip distance and the percentage of different transport modes. We observe a strong correlation between Spherical distance and transport mode choice. Walk and cycle are the major choices for trips shorter than 5 km whereas bus and drive are the major choices for trips longer than 10 km. The peak of demand for taxi appears when the trip distance is near 5 km. Since the road connectivity and transport stations in a region are fixed, the transport availability of adjacent OD pairs is similar. To incorporate such regional dependency, we partitioned the city into a set of non-overlapping regions through the road network [10]. For each origin region, we further compute the POI count of each POI category as Regional POI distribution, transport facility count (i.e., road segment, road intersection, bus station and bus line) as Regional transport facility distribution and mode click count as Regional historical mode distribution. We also extract similar features for destination regions and OD region pairs.

TABLE 2 Overall Recommendation Performance
Table 2- 
Overall Recommendation Performance
Fig. 4. - 
Feature distributions of the Beijing dataset.
Fig. 4.
Feature distributions of the Beijing dataset.

Show All

5.3 Temporal Features
We exploit Hour, Minute, Day of week, Day of month and Workday as the temporal features. As shown in Fig. 4c, distributions of transportation mode choices differ in different time periods. The demand for walk and cycle is mainly in daytime whereas the demand for taxi and taxi-bus is still high at night. As illustrated in Fig. 4d, the transport mode preferences during different time periods on weekdays and weekends also differ. For drive, there are two peak hours in a day. However, the peak on weekday mornings is earlier than that on weekend mornings and the peak on weekday evenings is later. Conversely, peak hours at weekends are closer and the demand is more evenly distributed in the daytime.

5.4 Meteorological Features
We adopt Weather, Temperature, AQI, Wind speed and Wind direction as the meteorology features. Fig. 4e depicts the correlation between weather and transport mode preference distributions. The demand for drive is higher on overcast and rainy days whereas the demand for bus on overcast days is lower.

5.5 User Features
We construct user features based on users’ Demographic attribute, Social attribute and User historical mode distribution, as shown in Appendix B, available in the online supplemental material. Fig. 4f depicts the correlation between the age of users and the transport mode choices. We observe that older people have higher demand for drive and taxi, whereas younger people prefer walk and bus more.

5.6 Transport Mode Preference Representation
Transport mode preference representation aims to learn high order collaborative relationship among users, OD pairs, and transport modes. The intuition is, users travelling similar OD pairs via similar transport modes have similar transport mode preference. Inspired by the recent success of embedding methods [11], [12] on preserving local network structures, we construct a heterogeneous graph G=(V,E) of user nodes U, OD pair nodes OD and transport mode nodes M based on the user behavior data (Fig. 5). The target is to project each node v∈V into a low dimensional vector in the latent space, each of which reflects the neighborhood relationship (a.k.a. the second-order proximity) in G. We analogize the constructed click event as a sentence, where a user u clicked on a route in transport mode m over a specific OD pair od is regarded as a short sentence. We adopt Trans2vec [13] and skip-gram [14] on G. Specifically, given a click event, the latent vectors of vu∈U, vod∈OD and vm∈M, denoted as uu, uod, and um, are learned by maximizing the following conditional log probability:
Ot=∑t∈T∑vi∈Vt∑ntj∈Nt(vi)logp(ntj|vi),(1)
View SourceRight-click on figure for MathML and additional features.where T={u,od,m} is the type of nodes in G, and ntj∈Nt(vi) is the type aware context node of vi ever co-occurred in a click event. That is, only heterogeneous neighbour nodes are considered as valid context nodes. For example, for vi∈U, we have Nt(vi)⊆{OD,M}. p(ntj|vi) is the conditional probability of observing type aware neighborhood ntj∈G conditioned on the presence of vi:
p(ntj|vi)=eu′j⊺⋅ui∑|Vt|k=1eu′k⊺⋅ui,(2)
View Sourcewhere u′j is the context representation vector of vj as a context node and |Vt| is the number of nodes with type t in graph G. To reduce the computation complexity, we employ negative sampling [14] for efficient learning. The objective function becomes:
Ot=logσ(u′j⊺⋅ui)+∑i=1KEvtn∼Un(vt)[logσ(−utn⊺⋅ui)],(3)
View Sourcewhere σ is the sigmoid function. The first term models observed edges in click events whereas the second term draws K negative edges from a uniform distribution. In this way, the distance between the learned user (resp. OD) embedding and each transportation mode embedding reflects the preference of a user (resp. OD) to each transport mode. That is, those users (resp. ODs) having similar transportation mode preference should be close to each other in the latent embedding space.

Fig. 5. - 
An illustrative example of the heterogeneous transportation graph. Each edge indicates the frequency of a user $v^u_i$viu (resp. OD pair $v^{od}_j$vjod) clicking on a route of a specific transport mode.
Fig. 5.
An illustrative example of the heterogeneous transportation graph. Each edge indicates the frequency of a user vui (resp. OD pair vodj) clicking on a route of a specific transport mode.

Show All

SECTION 6GBDT Based Recommendation
In this section, we introduce the Gradient Boosting Decision Tree (GBDT) based model for multi-modal transportation recommendation. We model the transport mode recommendation as a multi-class classification problem. Once the embedding vectors are learned, the proper transport mode can be derived by calculating the inner product of embedding vectors (as in [13]). In the production environment, however, the embedding method suffers from the cold-start problem. That is, 62.9 percent queries are from new users (i.e., users migrate from other routing engines and new users of Baidu Maps) or target to new OD pairs (i.e., OD pairs which have not been queried by users). To handle such cases, we concatenate the learned embedding vector of the user and the OD pair with the handcrafted features (as in Section 5) into a d dimensional feature vector.

Given a preprocessed dataset of n instances, m transport modes and d feature dimensions, we transform the raw data into a 2D matrix D={xi,yi} where |D|=n, xi∈Rd is the feature vector and yi∈RM is the ith transport mode. We employ the gradient boosting tree [15] as our recommendation model because gradient boosting tree based algorithms [16] are suited for data mining with sparse and high dimensional features. Specifically, we sequentially generate a set of tree classifiers F(⋅)={f1(⋅),f2(⋅),…,fk(⋅)} and ensemble the result of each classifier to generate the overall predictive result.
y^i=F(xi)=∑j=1kfj(xi),fj∈F,(4)
View SourceRight-click on figure for MathML and additional features.where y^i is the estimated transport mode of ith instance, f(⋅) is a softmax regressor for multi-class classification:
f(xi)=ew⊺qxi∑|M|p=1ew⊺pxi,(5)
View SourceRight-click on figure for MathML and additional features.where wq is the parameter vector of the qth class. The learning objective is to minimize
O=∑i=inl(yi,y^i)+λ12∑jk∥wj∥1+λ22∑jk∥wj∥2,(6)
View SourceRight-click on figure for MathML and additional features.where l(⋅) is is the cross-entropy loss, λ1 and λ2 are hyper-parameters for L1 and L2 regularizations, respectively.

The gradient of the tree function is derived much harder than traditional optimization tasks. Since we train classifiers sequentially, we approximate the gradient based on the previous step. The objective at the tth iteration becomes
O˜i=∑i=1n(gift(xi)+12hif2t(xi))+λ12∑jk∥wj∥1+λ22∑jk∥wj∥2,(7)
View Sourcewhere gi=∂y^t−1il(yi,y^t−1i) and hi=∂2y^t−1il(yi,y^t−1i) are the first order and second order gradient statistics of l(⋅). The detailed deduction can be found in [17].

SECTION 7MTWDL Based Recommendation
In practice, the GBDT based model provides a light-weight yet effective recommendation service. However, tree-based model is less powerful on extracting high-order feature representations from large-scale data, which limit its expressive power on transport mode recommendation. In this section, we introduce a multi-task wide and deep learning (MTWDL) based model for multi-modal transportation recommendation. Compared with the tree-based model, the advantages of MTWDL are three folds. First, by stacking multiple neural network layers, MTWDL is capable of capture high order feature interactions [18]. Second, except latent representations learned from the transportation mode preference representation module, MTWDL further introduces an embedding layer to learn low dimensional representations of high-dimensional categorical features. Third, MTWDL formulates transport mode recommendation and user click prediction as multiple individual tasks and introduce a multi-task learning framework to further improve the recommendation performance.

7.1 Tasks Definition
In the GBDT based model, the multi-class formulation assigns instances without click to a negative class. However, this formulation doesn't distinguish the difference between user click behavior and specific clicked transport mode. To this end, we define multiple related main tasks {Tm1,…,Tmk} as well as an auxiliary task Ta, and learning to optimize them simultaneously. Given the feature matrix D={xi}ni=1 and the corresponding labels {yi}ni=1, we first define each main task. For task Tmi, we aim to learn a binary classifier fmi to predict if transport mode i is preferred for each instance,
y^mji=fmj(xi),(8)
View SourceRight-click on figure for MathML and additional features.where y^mji is the estimated click likelihood of transport mode j for the ith instance. Similarly, the auxiliary task aims to learn a binary classifier fa to predict if the user click any transport mode,
y^ai=fa(xi),(9)
View Sourcewhere y^ai is the estimated likelihood if user would click the ith instance.

7.2 Basic Model
We first introduce the deep learning based model for each individual task. We adopt the wide and deep learning model [3], which is widely used in many recommender systems. As shown in Fig. 6, the wide and deep learning consists of two components: the wide component for user preference memorization and the deep component for high-order feature generalization.

Fig. 6. - 
Architecture of MTWDL. It jointly trains multiple main tasks and an auxiliary task, the embedding layer and deep component are shared among different tasks.
Fig. 6.
Architecture of MTWDL. It jointly trains multiple main tasks and an auxiliary task, the embedding layer and deep component are shared among different tasks.

Show All

Specifically, the wide component is designed for feature co-occurrence memorization, defined as
y^mij=w⊤xj+b,(10)
View SourceRight-click on figure for MathML and additional features.where xj is the input feature vector, w is the learnable weighted matrix and b is the bias.

The deep component stacks multiple neural network layers to capture higher order feature representations. An embedding layer is first applied to transform categorical features into low dimensional dense vectors. Then we concatenate all dense embedding vectors and continuous features and feed the concatenated vector into several fully connected layers. Each fully connected layer transform input vector as follow
z(l+1)=ReLU(w(l)⊤z(l)+b(l)),(11)
View SourceRight-click on figure for MathML and additional features.where z(l) and z(l+1) are the input and output of lth layer, w(l) and b(l) are parameters of layer l, and ReLU is the rectified linear units as the activation function. The deep component explores new feature combinations to improve model generalization power.

The final output is a combination of the wide component and the deep component,
y^i=σ(w⊤wxj+w⊤dz(lf)+b),(12)
View SourceRight-click on figure for MathML and additional features.where y^i is the final output, σ is the activation function, ww is the parameter of the wide component, wd is the parameter of the final output of the deep component z(lf). An Adam [19] optimizer is employed for optimization.

7.3 Multi-Task Wide and Deep Recommendation
In general, there are two paradigms of multi-task learning, the parameter sharing based approach and the constraint based approach [20]. In this paper, MTWDL follow the first paradigm, where lower level parameters in the deep component are shared cross all tasks. The parameter sharing mechanism further improves the generalization power of the model. As shown in Fig. 6, MTWDL consists three components, the wide component, the deep component, and the task-specific component. Specifically, all tasks share the deep component and each task has an individual wide component and a task-specific component. For each task, the wide component and the deep component are identical with the basic model. Each task has two sets of features, general features and task-specific features. General features such as temporal features and meteorological features are identical for all tasks, whereas task-specific features such as ETA, distance, price are different in different tasks.

The difference between MTWDL and the basic model is there are multiple output layers for different tasks. For example, for task Tmi, the output layer is defined as
y^i=σ(wmi⊤wxj+wmi⊤dz(lf)+b),(13)
View SourceRight-click on figure for MathML and additional features.where wmiw and wmid are the task specific parameters of the wide component and the deep component, respectively.

7.4 Objective
In MTWDL, all learnable parameters are optimized jointly. For the main task Tmj, the objective is defined as
Lmj=−1n∑i=1nαymjilogy^mji,(14)
View SourceRight-click on figure for MathML and additional features.where ymji∈{0,1} indicates if a user click transport mode mj or not, α is a hyper-parameter to alleviate class imbalance.

For auxiliary task, the objective is defined as
La=−1n∑i=1nβyailogy^ai,(15)
View SourceRight-click on figure for MathML and additional features.where yai∈{0,1} indicates if a user click any transport mode or not, β is a hyper-parameter to trade-off the click ratio and the recommendation coverage ratio.

Beside the objectives for each task, we consider the relationship between main tasks and the auxiliary task. Consider the output of each main task represents the likelihood a user click on a transport mode mj, denoted by Pmj(xi). The estimated probability a user click on any transport mode is
Q(xi)=1−∏mj∈M(1−Pmj(xi)).(16)
View SourceRight-click on figure for MathML and additional features.

We aim to minimize the Jensen-Shannon divergence [21] between Q(xi) and the probability a user click on the transport mode Pa(xi),
Lr=12DKL(P(xi)||Q(xi))+12DKL(Q(xi)||P(xi)),(17)
View SourceRight-click on figure for MathML and additional features.where P(xi), DKL(P(xi)||Q(xi)) and DKL(Q(xi)||P(xi)) are defined as
P(xi)=Pa(xi)+Q(xi)2(18)
View SourceRight-click on figure for MathML and additional features.
DKL(P(xi)||Q(xi))=∑i=1nP(xi)logP(xi)Q(xi),(19)
View SourceRight-click on figure for MathML and additional features.
DKL(Q(xi)||P(xi))=∑i=1nQ(xi)logQ(xi)P(xi).(20)
View SourceRight-click on figure for MathML and additional features.

By considering all task specific objective and the Jensen-Shannon divergence loss, we aims to optimize the following objective function
L=∑mj∈MLmj+La+λnLr,(21)
View SourceRight-click on figure for MathML and additional features.where λ is a hyper-parameter controls the importance of the Jensen-Shannon divergence loss.

SECTION 8Deployment
Hydra has been deployed on Baidu Maps. In this section, we describe the implementation and deployment details. cost of the mapping process is much lower than that of R-tree.

8.1 Offline Processing
Due to the complex data dependency, we propose an automatic pipeline for data integration and feature engineering. We employ Bigflow2 as the offline data pipeline platform. Bigflow is an open source programming abstraction that allows for programming and processing data on various distributed computing engines (e.g., Hadoop Tez [22] and Spark [23]). In Bigflow, a set of data wrangling operators such as map, filter and join is well supported and the lower level distributed operations are transparent to users.

8.1.1 GBDT Training
We use the XGBoost library3 to train the GBDT based model. The GBDT based model is updated on daily basis to take new data into consideration. To exclude seasonal changes, we define a three-month sliding time window for training data selection. Once the data pipeline is finished, the model update script is triggered to update the model.

8.1.2 MTWDL Training
We use the PaddlePaddle4 platform to implement the MTWDL model. PaddlePaddle is an efficient and scalable deep learning platform, which is supporting a variety of AI empowered products at Baidu. In the deep component, the embedding layer first transforms each categorical feature into a 32-dimensional embedding vector and concatenates them with all the continuous features as the input vector. The input vector is then fed into three fully connected layers. Each fully connected layer consists of 400 hidden units and a ReLU activation function. The hyper-parameters α, β, λ, learning rate and dropout rate are set to 1.0, 10.0, 0.5, 0.0001, and 0.5, respectively. The batch size is 512. The output of the last fully connected layer is used as the input features of the multi-task component. To accelerate model training, in daily update, the embedding parameters are initialized from latest model.

8.2 Online Processing
Baidu Maps answers billions of queries in each day. Thus, it is crucial to offer effective and scalable online service to users. To this end, we build efficient region index and scalable prediction service to enable low latency and high throughput online service.

8.2.1 Region Index
For online feature processing, a batch of statistical features is required to be mapped from coordinates to regions (e.g., join the origin coordinates of a query with the regional POI distribution). Traditional spatial index, such as R-tree, requires O(logn) search time, which is time consuming for cities with a large number of regions. We proposed a dedicated region index to speed up such mapping process. Specifically, we divide the city into fine-grained grids based on coordinates with a unique grid id. We then allocate regions to the corresponding grids. Note that each region is an irregular polygon, therefore, a grid may be intersected with one or multiple regions. For example, the minimum bounding rectangle (MBR) [(116.30,40.05),(116.31,40.06)] is partitioned to grid g1, with id 11630_4005. If there are two regions r1 and r2 intersect with g1, the index in the database is stored as a key-value pair (11630_4005,[r1,r2]), where the value is a list of regions. Internally, the grid-regions pair is stored as a hash table in Redis. Since the region is partitioned based on the road network, most grids are only associated with one or a few regions. In practice, the average time

8.2.2 GBDT Prediction
We build the web service based on BRPC (https://github.com/brpc/brpc), a scalable Remote Procedure Call (RPC) framework used throughout Baidu. The GBDT model is duplicated in four data centers distributed over China to reduce network latency of the service. Specifically, the online service contains three components. First, retrieve geographical information, meteorological data, user profile data in parallel and integrate them with raw route plans. Second, execute the online feature engineering process by leveraging the metadata generated in the offline data pipeline. Third, feed the processed feature vector into the model, sort each mode by model score and return the transport mode with the highest score to the user. About 6 percent of transport modes with the highest score have no corresponding plan. Instead, we recommend the next transport mode that has a feasible plan.

8.2.3 MTWDL prediction
We provide two modes for MTWDL based prediction, i.e., the server mode and the mobile mode. The server mode runs the model on a server in our data centers, whereas the mobile mode runs the model on mobile phones along with the navigation app. Specifically, the server mode implements a high-performance parallel predictor AnalysisPredictor in C++, and adopt the ZeroCopyTensor mechanism in PaddlePaddle to avoid redundant data copy operation. The mobile mode implement a lightweight predictor MobilePredictor in both C++ and Java. Similar to the GBDT prediction, both modes need first request meteorological data from existing online service, retrieve geographical data and user profile data from Redis services, and integrate them with raw route plans. In the production environment, we finally choose the server mode because of the following three reasons. 1) Route plans and corresponding raw features are computed and retrieved on the server-side; the network cost of server mode is smaller than the mobile mode. 2) Routing request is a relatively low-frequency service (several times in each day), the model in mobile mode need load in and flush out before and after query, which induces longer prediction time than server mode. 3) Since our model is updated on a daily basis, mobile mode requires frequent app updates.

SECTION 9Experiments
9.1 Experimental Setup
We conduct experiments on the datasets described in Section 2. We mainly focus on (1) the overall performance, (2) each feature contribution, (3) parameter sensitivity and (4) the robustness of our approach. We also present the user satisfaction analysis and the efficiency and scalability of our system. We split data from September 1 to November 10 as training set, November 11 to November 20 as validation set, and the remaining as testing set.

Metrics. We adopt the overall NDCG [24], weighted precision, recall and F1 metrics to evaluate the performance. The NDCG metric takes all transport modes into consideration whereas the rest metrics only care about the top-1 recommendation.

Baselines. We compare our approach with eight baselines and two variants of Hydra.

UHP recommends the transportation mode of route using the fraction of user historical preference. The most common transport mode choice of the user will be recommended.

ODHP recommends the transportation mode of route using the fraction of OD historical preference. The most popular transport mode between the OD pair will be recommended.

LR recommends the transportation mode of route via the well-known logistic regression model. The input feature is same with our method as described in Section 5.

RF recommends the transportation mode of route using Random Forest. The input feature is same to our method as described in Section 5.

LTR is a popular LambdaMart [25] learning to rank method, where the pairwise loss is minimized. We use the plan feature described in Section 5 as input.

Trans2vec is the state-of-the-art transportation mode recommendation method [13] based on graph embedding. It makes recommendation based on the inner product of user vector and transportation mode vector and the inner product of OD pair vector and transportation mode vector.

WDL is the original wide and deep learning framework [3]. It integrates a wide linear model and a deep neural network. We use a softmax layer to obtain the model output.

DeepFM is a state-of-the-art recommendation model [26] that combines factorization machine for learning feature interactions and the power of the deep neural network.

Hydra-L (ours) is the light-weight version of Hydra where the high level model is the gradient boosting decision tree based recommendation model.

Hydra-H (ours) is the heavy-weight version of Hydra where the high level model is the multi-task wide and deep learning based recommendation model.

9.2 Overall Recommendation Result
Table 2 depicts the overall results of our methods and all the compared baselines with respect to four evaluation metrics. We can make the following observations. (1) Hydra-H achieves better performance than other methods over all metrics except Prec, which indicates the effectiveness of our models. Although ODHP and RF achieves higher Prec score, Hydra-H achieve better balance between Prec and Rec, which is evaluated by F1. (2) Hydra-H consistently outperforms Hydra-L in terms of all metrics, demonstrates the effectiveness of the MTWDL framework. Specifically, Hydra-H achieves 4.55 and 3.07 percent improvement over Hydra-L of F1 on Beijing and Shanghai, respectively. The improvement of Rec are 3.89 and 6.72 percent on Beijing and Shanghai. Note that although Hydra-L performs worse than Hydra-H, it outperforms other non-deep-learning based model and is more time efficient than Hydra-H. Hydra-H takes about ten times longer training time than Hydra-L. (3) Hydra-L is competitive against WDL and DeepFM, which matches our expectation that situational context information and tailored feature engineering is curial for multi-modal transportation recommendation. (3) WDL and DeepFM outperform six other baselines, illustrate the effectiveness of the deep learning based model. (5) The performance of solely Trans2vec is not well on the dataset with large proportion of cold-start users (resp. OD pairs). Overall, incorporating handcrafted features and high-order embedding features with a multi-task wide and deep learning framework outperforms all other baselines.

9.3 Feature Importance Analysis
To evaluate the effectiveness of our feature construction, we exam the importance of each feature in our models. For the gradient boosting decision tree based model, we rank features by information gain [27]. The higher information gain indicates higher frequency the feature used to split nodes in each individual tree. Table 3 reports top-10 features and their relative information gain. The top 4 features are all plan ETA of corresponding modes, which meets our expectation that travel time is the major consideration in the transport mode choice. Besides, we observe user attributes especially user social attributes such as historical mode preferences (walk preference in rank 5) and consumption level (rank 6) also make significant contributions for transport mode prediction. Features from rank 7 to rank 10 are spatial features and temporal features, which validates our intuition that the spatial and temporal dependency influences the transport mode choice. Since we cannot directly obtain information gain from deep neural network, we apply perturbation feature ranking [28] to evaluate the importance of each feature in MTWDL. The importance of each feature is measured by calculating the performance loss of MTWDL when the corresponding feature column is shuffled. Table 4 reports top-10 features and their relative increase in loss. As can be seen, plan feature Bus ETA is the most important feature, but the temporal feature Hour becomes the second feature and the meteorological feature Weather becomes the third feature. User profile features Age and Income level are ranked at 6 and 7, respectively. Compared with the GBDT based model, more categorical features contribute more on multi-modal transportation recommendation, which shows the advantage of MTWDL on handling high dimensional categorical features.

TABLE 3 Top-10 Features Ranked by Information Gain (Hydra-L)
Table 3- 
Top-10 Features Ranked by Information Gain (Hydra-L)
TABLE 4 Top-10 Input Perturbation Feature Importance (Hydra-H)

9.4 Parameter Sensitivity Analysis
We further study the parameter sensitivity of Hydra-L and Hydra-H. we evaluate the performance of different hyper-parameters on Beijing dataset, the results on Shanghai are similar.

For Hydra-L, we report the influence of maximum depth and columns sample rate, two important parameters in tree-based model. First, we vary the maximum depth from 3 to 10. The results are reported in Fig. 7a. In general, Hydra-L performs stable when the maximum depth changes. Hydra-L achieves best performance when maximum depth is 5. Then, we vary the column sampling rate from 0.5 to 1.0. The results are reported in Fig. 7b. As can be seen, there is a performance improvement when we increase the sampling rate from 0.5 to 0.8, but the performance degrades when we further increase the sampling rate from 0.8 to 1.0. The reason is proper column sampling can avoid overfitting, but too low sampling rate limit the model to capture useful feature combinations.

Fig. 7. - 
Parameter sensitivities on Beijing dataset.
Fig. 7.
Parameter sensitivities on Beijing dataset.

Show All

For Hydra-H, we report the influence of embedding size and the regularization parameter λ. We first vary the embedding size in Hydra-H from 4 to 64. As shown in Fig. 7c, the model achieves the highest F1 score when the embedding size is 32. Set embedding size to 16 or 32 is enough to represent information in each categorical feature. Fig. 7d depicts the influence of λ. We observe a performance improvement when we improve λ from 0 to 0.5 and a performance degradation when we further improve λ from 0.5 to 3.0. The result validates modeling relationship between each tasks can improve the model performance.

9.5 Robustness Check
A robust algorithm should perform evenly on different subgroups of queries. We group queries from two perspectives: 1) user profile perspective, and 2) OD profile perspective. For 1), we segment users through gender and age, i.e., women and age lower than 35, men and age lower than 35, women and age older than 35, men and age older than 35. For 2), we segment OD pairs based on region functionality (i.e., we use the POI distribution of corresponding regions), classical K-means is applied to cluster OD pairs into four disjoint groups. Figs. 8 and 9 illustrate the performance of the GBDT based model and the MTWDL based model on different subgroups on Beijing, respectively. The results on Shanghai are similar. For different groups of users, the results are strongly stable on four metrics, which validates the robustness of our method for different users. For different OD pairs, the results of the GBDT based model are also stable on four metrics expect the third group (e.g., for Rec, the difference is over 10 percent). This result indicates the variation from the OD profile perspective is more significant. As shown in Fig. 9b, MTWDL based model improves the performance of the third group and mitigates its impact in the overall result.

Fig. 8. - 
Robustness check on the Beijing dataset (Hydra-L).
Fig. 8.
Robustness check on the Beijing dataset (Hydra-L).

Show All

Fig. 9. - 
Robustness check on the Beijing dataset (Hydra-H).
Fig. 9.
Robustness check on the Beijing dataset (Hydra-H).

Show All

9.6 User Interview and Online Test
The model has been deployed on Baidu Maps since mid 2018. In past months, the model has answered over a hundred million route planning requests and served over ten million distinct users. To assess the user satisfaction of model recommendations, we published survey questionnaires to frequent Baidu Maps users. Overall, 738 valid questionnaires are collected. In the questionnaire, we set five level satisfaction categories, G+,G,S,B,B+, where G stands for good, S stands for same as before, B stands for bad. As shown in Table 5, over 86.7 percent users think the recommendation result is better than before, only 1.6 percent users think the recommendation result becomes worse. That is, our method provides better recommendations in terms of user experience. Moreover, we conduct an online A/B test in the production environment. Hydra-H achieves 2.78 percent click ratio improvement over Hydra-L. The improvement means over 300,000 more queries are satisfied by Hydra-H, which is a significant gain for an online product.

TABLE 5 User Satisfaction
Table 5- 
User Satisfaction
9.7 Efficiency and Scalability
Finally, we evaluate the efficiency and scalability. We randomly test 1,000 queries, and the averaged recommendation time of each baseline and our model are reported in Fig. 10a. As can be seen, learning-based models generally take a longer time than statistical baselines. In particular, deep learning models take longer time than statistical learning models. We further test the query response latency of our framework in the production environment. The query response latency is composed of two parts, low level routing cost and high level recommendation cost. For high level recommendation, we evaluate the latency of GBDT based model in Hydra-L and MTWDL based model in Hydra-H. The results are reported in Fig. 10b. On one hand, when we vary the query per second (QPS) from 1 to 10,000, the low level routing latency increased from 220 ms to 671 ms. On the other hand, the latency of GBDT based model increased from 5 ms to 274 ms whereas the latency of MTWDL based model increased from 73 ms to 566 ms. Above observations demonstrate that although Hydra-H outperforms Hydra-L in terms of recommendation accuracy, it is more time-consuming. Notice that the efficiency gap goes large when the QPS is too small or too large, but the latency gap is relatively small when the QPS is between 100 and 1,000. Since the peak QPS of the online service is less than 1,000, Hydra-H is still applicable and the online workload can be well handled by Hydra-H. Overall, the low level routing is the major bottleneck in Hydra-L and we should pay more attention on the recommendation cost in Hydra-H.

Fig. 10. - 
Results of efficiency and scalability.
Fig. 10.
Results of efficiency and scalability.

Show All

SECTION 10Related Work
Route Recommendation. Route recommendation has attracted much attention from both academia (e.g., [29]) and industries (e.g., Google Maps and Baidu Maps). A common routine of route recommendation is to apply the algorithms of shortest distance queries [30] with predefined cost functions [31]. As another important direction, the quality of recommended routes can be improved by leveraging large-scale historical trajectories [32]. Specifically, T-Drive [33] captures the intelligence of taxi drivers via a landmark graph. Dai et al. [34] recommends routes by considering personal preference (e.g., time efficiency or fuel efficiency) for each individual driver. Recently, the route recommendation for shared mobility also attracted research interest to improve efficiency [35] and revenue [36]. However, all of them consider uni-modal route recommendations and thus cannot be directly applied for multi-modal route recommendation. Trans2vec [13] considers multi-modal recommendation by learning embedding of users, OD pairs and transport modes. But it suffers from the cold-start problem and requires extra models or strategies to handle new instances.

Urban Computing. With the development of city urbanization, various data generated from GPS, sensors, buildings and humans has been applied to tackle various urban issues. For example, Yu et al. [37] predict urban safety by considering multiple spatial and temporal factors. Moreover, Tong et al. [38] and Xia et al. [39] predicts taxi demands based on multi-sourced urban data. Sun et al. [40] mines the urban region-of-interest through map search queries. Motivated by the above studies, we integrate multiple urban datasets to improve the performance of route recommendation among various transport modes. To the best of our knowledge, it is the first work that integrates multiple sources of urban data for route recommendation among various transport modes in a data-driven way at urban-scale.

SECTION 11Conclusion
In this paper, we presented Hydra, a personalized and context-aware multi-modal transportation recommendation system. It is a two-level system that adaptively recommends uni-modal and multi-modal transportation routes according to the user preferences and the situational context. We first extracted a rich set of features from user behavior data and several urban data collectged from other sources. Next, we learnt embedding features via the heterogeneous transportation graph to enhance the recommendation performance. Moreover, a gradient boosting tree based model as well as a multi-task wide and deep learning based model was respectively devised for multi-modal transportation recommendation. Finally, we discussed several deployment issues to optimize Hydra to be scalable, including offline data pipelines, high performance spatial index, as well as the construction of web service framework. Extensive evaluations on real-world datasets validate the effectiveness and efficiency of Hydra.