Traffic over mobile cellular networks has significantly increased over the past decade, and with the introduction of 5G there is a growing focus on throughput capacity, reliability, and low latency to meet the demands of new and innovative applications. Multi-access Edge Computing (MEC) is being developed to achieve a series of challenges posed by the introduction of new applications and services that require ultra-low latency and high bandwidth. This article is a comprehensive survey of recent advances in MEC and provides a description of the MEC concept, framework, and capabilities. We also summarize a set of MEC technology enablers including Software Defined Networking, Network Function Virtualization, Information-Centric Networking, Service Function Chaining, Cloud-Radio Access Networks, Fog-computing based Radio Access Networks and Network Slicing. The MEC use cases and the open research challenges are presented.

Previous
Next 
Keywords
Multi-access Edge Computing

Software Defined Networking

Network Function Virtualization

Information-Centric Networking

Service Function Chaining

Network Slicing

Cloud-Radio Access Network

Fog-computing based Radio Access Network

1. Introduction
Mobile cellular telecommunications technologies have advanced rapidly, and the 5th Generation (5G) mobile cellular rollout promises new capabilities and features that will facilitate new applications and services. The shift from circuit switching (1G and 2G), to hybrid circuit and packet switching (3G), and finally to Internet Protocol based packet switching (4G and 5G) has occurred over several decades. Analog voice calls have transitioned to digital voice calls with the addition of SMS and E-mail capability and more recently to video calls, multimedia and high-quality mobile streaming services that utilize Ultra High Definition(4K) video, and Virtual Reality applications (Gupta and Jha, 2015). With the ongoing development of mobile telecommunications technologies, the emerging Internet of Things (IoT) with billions of devices being connected to digital networks and new interactive mobile applications, we are moving into a new era of massive data usage. Global mobile traffic is expected to increase by 46 percent from 2017 to 2022 (Cisco, 2017), and by 2022, global mobile traffic is expected to reach 77.5 exabytes per month with 12.3 billion mobile-connected devices. Almost three-quarters of all devices will become ‘smart’ devices, and the average global mobile network connection speed will reach 28.5 Mbps, up from 8.7 Mbps in 2017 (Cisco, 2017). The increasing demands for data services poses new challenges. The innovative telecommunication eco-system will become heterogeneous by utilizing global information and communication technology infrastructure and resources to provide a customized, multi-service, and multi-tenancy eco-system. New challenges exist not only for mobile network operators and equipment providers but also for service and application providers, often known as Over-The-Top providers, software vendors, and IT platform vendors (Cisco, 2017). For 5G, the challenges include end-to-end latency, the number of connections, computing, cost, and constraints including end-device battery life, computational power, and memory limitations (Agyapong et al., 2014, Taleb et al., 2017). Over the past decade Fog Computing, Cloudlets, MIST and Mobile Edge Computing were introduced to overcome targeted challenges. More recently Multi-Access Edge Computing (MEC) was introduced by the European Telecommunications Standards Institute (ETSI) Industry Specification Group (ISG) as a replacement for Mobile Edge Computing to reflect the solution being suitable for every type of wireless access network. In order to address mobile device limitations, principally processing capability, storage and power consumption, Mobile Computing (MC) evolved to provide users with data, voice and video in conjunction with cloud and other systems. Mobile Cloud Computing (MCC) was introduced to overcome mobile device limitations and to support resource-intensive applications. MCC provided extended battery lifetime, unlimited storage on demand, improved processing capability, and self-service provisioning (Somula and Sasikala, 2018). By utilizing the cloud for compute and storage, some of the MCC applications were negatively affected by higher latency. Mobile Ad-hoc Cloud Computing (MACC) was introduced to distribute computation tasks among mobile devices in the surrounding MACC network in an effort to reduce latency (Yousefpour et al., 2019).

In 2009, Cloudlet emerged as a micro-data center that provided WiFi access and was deployed in public locations such as shopping malls, hospitals, and commercial buildings. Cloudlets support mobile device computation and storage offloading. By bringing cloud computing capabilities closer to the user devices, latency is reduced (Abbas et al., 2017). Fog computing, first presented by Cisco, introduced Fog as a layer of network connected computing and storage devices, e.g., controllers, switches, routers and servers, between the cloud and user devices. The network connected computing and storage devices were called Fog nodes (Noronha et al., 2014). The Fog layer, being in close proximity to IoT devices, can be used to perform pre-processing of the IoT data and then securely transport it to the cloud for further processing and storage. Fog computing reduces network traffic and addresses the high latency that is a result of the traditional cloud architecture.


Table 1. A list of commonly used acronyms in this paper.

Acronym	Definition	Acronym	Definition
3GPP	Third Generation Partnership Project	API	Application Programming Interface
AR/VR	Augmented Reality/Virtual Reality	BWM	Band-Width Management
BBU	Baseband Unit	CAPEX	Capital Expenditures
C-RAN	Cloud-Radio Access Network	CSMF	Communication Service Management Function
CRRA	Cooperative Radio Resource Allocation	CFS	Customer-Facing Service
CMM	Centralized Mobility Management	DMM	Distributed Mobility Management
EES	Edge Enabler Server	EEC	Edge Enabler Client
EB	Energy Buffer	eMBB	enhanced Mobile Broadband
ETSI	European Telecommunications Standards Institute	ENI	Experiential Networked Intelligence
F-RAN	Fog-computing based Radio Access Network	IETF	Internet Engineering Task Force
ISG	Industry Specification Group	ICN	Information-Centric Networking
LSCP	Large-scale Collaborative Processing	LCM	Lifecycle Management
LS	Location Service	MIoT	Massive IoT
mMTC	massive Machine Type Communication	MACC	Mobile Ad hoc Cloud Computing
MCC	Mobile Cloud Computing	MC	Mobile Computing
MEC	Multi-access Edge Computing	MEPM	Multi-access Edge Platform Manager
MEPM-V	Multi-access Edge Platform Manager NFV	MEO	Multi-access Edge Orchestrator
MTS	Multi-access Traffic Steering	NFV	Network Function Virtualization
NFVO	Network Functions Virtualization Orchestrator	NSI	Network Slice Instance
NSSMF	Network Slice Subnet Management Function	NGMN	Next Generation Mobile Networks
OMA	Open Mobile Alliance	ONF	Open Networking Foundation
OPEX	Operating expenses	OS	Operating System
OSS	Operations Support System	PDU	Protocol Data Unit
RNIS	Radio Network Information Service	RRH	Remote Radio Head
RESTful	Representational State Transfer	RSU	Roadside Units
SFC	Service Function Chaining	SFP	Service Function Path
SFs	Service Functions	SFF	Service Function Forwards
NSMF	Network Slice Management Function	SDN	Software Defined Networking
TM	Traffic Management	uRLLC	ultra-Reliable Low Latency
UAVs	Unmanned Aerial Vehicle	V2X	Vehicle-to-Everything
VM	Virtual Machine	VNF	Virtual Network Function
VIM	Virtualization Infrastructure Manager	ZSM	Zero-touch Network and Service Management
Mist computing was introduced to extend Fog computing by moving some of the computation to the IoT devices, e.g., sensors and actuators. Mist, Fog and Cloudlet computing are complementary to each other and have evolved to become a distributed compute and storage paradigm that focuses on collecting data at the edge, pre-processing the data and passing the results of the pre-processing up the hierarchy of the compute nodes for further processing and finally becoming data that is stored in the Cloud where it can be further analyzed.

Mobile Edge Computing was introduced to provide additional capability by moving computation, storage, and intelligence to the edge of mobile access networks (Sabella et al., 2016). The benefits of Mobile Edge Computing were subsequently introduced to heterogeneous wireless access networks, including mobile cellular networks, WiFi and other fixed wireless access networks and this solution became known as MEC. MEC provides edge support for the Mist, Fog and Cloudlet paradigms (Yousefpour et al., 2019, Kekki et al., 2018).

1.1. Contribution and paper organization
In contrast to the existing surveys on MEC, the objective of this paper is to provide a comprehensive overview of MEC by reviewing current standardization efforts, architecture and architecture harmonization, services, the recent advancement of MEC complementary technologies, including Software Defined Networking (SDN), Network Function Virtualization (NFV), Information-Centric Networking (ICN), network slicing, Service Function Chaining (SFC), Cloud-Radio Access Network (C-RAN) and Fog-computing based Radio Access Network (F-RAN). We also discuss the MEC enabled use cases and challenges. Table 1 provides a list of acronyms found in this paper.

The contributions of this survey can be summarized as:

•
A comprehensive review of recent advances in standardization, architecture, services, complementary technologies and use cases.

•
An updated and holistic review of ETSI standardization is provided.

•
The complementary technologies to MEC, including NFV, SDN, network slicing, SFC, ICN, C-RAN and F-RAN are discussed.

•
Potential use cases are discussed. Open issues and research challenges are identified.

The rest of the paper is organized as follows. In Section 2, an overview is provided of the MEC definition, framework, and possible network architectures. Section 3 briefly describes key technologies, applications and services. In Section 4, popular MEC enabling technologies are presented. MEC use cases, applications, and related research are summarized in Section 5. Section 6 identifies the future research challenges. Finally, Section 7 provides the conclusion.


Table 2. ETSI MEC white paper.

Year	Specification	Contribution
2015	Mobile edge computing a key technology towards 5G (Hu et al., 2015)	Described the concept of MEC and related key market drivers and specifications.
2017	Developing software for multi-access edge computing (Reznik et al., 2017)	Provided a high-level guidance for software developers on how to approach MEC design.
2018	Cloud RAN and MEC a perfect pairing (Reznik et al., 2018a)	Discussed C-RAN as a complementary technology for MEC and described the deployment scenarios and use-cases and the architectural trade-offs.
2018	MEC deployments in 4G and evolution towards 5G (Giust et al., 2018)	Described how MEC is deployed in 4G network and accelerate the transformation to 5G network.
2018	MEC in 5G networks (Kekki et al., 2018)	Explained how to deploy and integrate MEC in the 5G network and 3GPP benefit to MEC system.
2018	MEC in an enterprise setting a solution outline (Reznik et al., 2018b)	Provided a solution overview of MEC deployments in the enterprise environment and indicated key challenges to deploy use cases in the existing enterprise infrastructure.
2019	Developing software for multi-access edge computing (Sabella et al., 2019)	Summarized the MEC key properties and provided high-level guidance on how to approach the interaction with soft development design.
2019	Network transformation; (Orchestration, Network and service management framework) (Chairmen, 2019)	Described the need and how to transfer to autonomous network management including NFV, MEC, Experiential Networked Intelligence (ENI) and Zero-touch Network and Service Management (ZSM)
2020	Enhanced DNS support towards distributed MEC environment (Masaki Suzuki et al., 2020)	Described the DNS support in MEC and introduced a list of solutions and evaluations to support the distributed MEC environment
2020	Harmonizing standards for edge computing (Nurit Sprecher et al., 2020)	Indicated the value of different specifications and how these specifications can be harmonized when it comes to deployments.

Table 3. ETSI ISG MEC specifications summary.

Specification	Theme	Contribution
ETSI Group (2019a)	Proof of concept framework	Indicated an MEC framework and key aspects of MEC technology.
ETSI Group (2020a)	Framework and reference architecture	Presented MEC framework and reference architecture.
ETSI Group, 2018a, ETSI Group, 2019b, ETSI Group, 2019c, ETSI Group, 2019d, ETSI Group, 2020b, ETSI Group, 2020c, ETSI Group, 2020d and ETSI Group (2020e)	API	Specified the necessary API, including User Equipment (UE) Identity, Radio Network Information Service (RNIS), Location, Fixed Access Information, Application Mobility Service, Vehicle-to-Everything (V2X) Information Service, WLAN Information and Traffic Management.
ETSI Group (2019e) and ETSI Group (2020f)	Application interface	Provided user applications lifecycle management over the UE and device application interfaces.
ETSI Group (2019f)	MEC testing framework	Specified MEC test environment including test strategies, test system and test requirements and specifications.
ETSI Group (2019g)	MEC management	Presented MEC application lifecycle management and specified the data model and format
ETSI Group (2020g)	Edge platform application enablement	Presented MEC application and platform enabled functionalities including application availability, traffic rules, DNS and time of day
ETSI Group (2018b)	Use cases and requirements	Detailed descriptions of use cases, their requirements and technical advantages.
ETSI Group (2018c)	MEC deployment in NFV environment	Described a deployment of MEC in a NFV environment.
ETSI Group (2019h)	Support for network slicing	Identified the MEC functionalities to support network slicing.
ETSI Group (2019i)	MEC 5G integration	Described key issues, solutions with regard to MEC integration into 3GPP 5G system.
ETSI Group (2017)	Metrics	Described a series of Metrics of a service which benefit from MEC deployment.

Table 4. Summary and comparison of the recent related survey papers on MEC.

References	Architecture	Services	SDN	NFV	SLICING	ICN	SFC	C-RAN	F-RAN	Use cases
Porambage et al. (2018)	✗	✗	✓	✓	✓	✓	✗	✗	✗	✓
Khan et al. (2019)	✗	✓	✗	✗	✗	✗	✗	✗	✗	✓
Yousefpour et al. (2019)	✓	✓	✓	✓	✗	✓	✗	✓	✓	✗
Pham et al. (2020)	✗	✓	✓	✓	✓	✗	✗	✓	✗	✓
Filali et al. (2020)	✗	✓	✓	✓	✓	✗	✓	✗	✗	✗
Shah et al. (2021)	✗	✓	✓	✓	✓	✗	✗	✓	✗	✓
Our survey	✓	✓	✓	✓	✓	✓	✓	✓	✓	✓
1.2. Development of ETSI MEC standards
MEC was firstly presented by the ETSI ISG in September 2014 in an effort to create a standardized and open environment that promotes a multi-vendor ecosystem. The ETSI ISG has produced a set of specifications for MEC, including the proof of concept framework, service scenarios, reference architecture, and service Application Programming Interface (API). Table 2 provides a summary of the ETSI MEC technology documents. Table 3 provides a summary of the ETSI MEC ISG specification (ETSI Group, 2019a, ETSI Group, 2020a, ETSI Group, 2018a, ETSI Group, 2019b, ETSI Group, 2019c, ETSI Group, 2019d, ETSI Group, 2020b, ETSI Group, 2020c, ETSI Group, 2020d, ETSI Group, 2020e, ETSI Group, 2019e, ETSI Group, 2020f, ETSI Group, 2019f, ETSI Group, 2019g, ETSI Group, 2020g, ETSI Group, 2018b, ETSI Group, 2018c, ETSI Group, 2019h, ETSI Group, 2019i, ETSI Group, 2017).

1.3. Current research
MEC related research has increased with the arrival of 5G and attracted significant interest from academia, business and industry. Surveys that respond to this research focus found in the literature include (Porambage et al., 2018, Khan et al., 2019, Yousefpour et al., 2019, Pham et al., 2020, Filali et al., 2020, Shah et al., 2021). Pawani et al. in Porambage et al. (2018) provide a holistic overview of IoT and MEC and how MEC incorporates SDN, NFV, ICN and network slicing. However, they do not consider MEC architectures and services. Khan et al. (2019) highlight the importance of MEC in real-life scenarios and the requirements for MEC enabling applications. Unlike (Khan et al., 2019), our work not only focuses on the MEC service scenarios and applications but also includes a comprehensive analysis of MEC complementary technologies and MEC architectures. A comparison of the different computing paradigms, architecture and services is presented in Yousefpour et al. (2019), however, the paper does not include a discussion of the latest popular complementary technologies, e.g., network slicing, SFC; and MEC applications. Pham et al. (2020) provide an overview of MEC technology, its enabling technologies, open-source activities and a summary of experimental environments, but do not consider the popular enabling technologies, e.g., ICN, SFC and F-RAN, and the latest proposed MEC architectures. The survey article (Filali et al., 2020) investigates the integration of MEC into mobile telecommunication network architectures. Additionally, the authors identify MEC metrics and discuss the enabling technologies; SDN, NFV, SFC and network slicing. However, the authors only consider the MEC enabling technologies without considering MEC architecture and related use cases. Syed et al. in Shah et al. (2021) present a comprehensive survey on network slicing, including enabling technologies, solutions and current standardization efforts, but the paper does not include a discussion about the MEC architecture and the latest popular complementary technologies, e.g., ICN, SFC and F-RAN.

This article provides a comprehensive review of the most recent MEC related research and standardization efforts. Table 4 provides a summary and comparison of the recent MEC related survey papers.

2. MEC framework and architecture
2.1. MEC framework
The latest version of the ETSI MEC group specification for the MEC framework and reference architecture was published in December 2020 (ETSI Group, 2020a). The specification describes an “MEC system that enables MEC applications to run efficiently and seamlessly in a multi-access network” (ETSI Group, 2020a), the functional elements, the reference points representing channels between the elements, the MEC services that support the system operation and presents key concepts related to the multi-access edge architecture.

The MEC framework groups the general entities into the MEC system level, MEC host level and network level entities. The framework entities include the MEC host (MEC platform, MEC applications and virtualization infrastructure), the MEC system level management, the MEC host level management and external related entities, i.e., network level entities. The network level provides connectivity to the network, including the Radio Access Network (RAN) (ETSI Group, 2020a).


Download : Download high-res image (416KB)
Download : Download full-size image
Fig. 1. ETSI MEC reference architecture (ETSI Group, 2020a).

2.2. MEC architecture
The MEC generic reference architecture, as depicted in Fig. 1, presents the MEC system comprised of the functional elements and reference points. The MEC host entity consists of an MEC platform and the virtualization infrastructure that hosts the applications. The MEC platform collects essential functionalities required to run MEC applications over a particular virtualization infrastructure and provide services for MEC applications.

MEC system level includes the Multi-access Edge Orchestrator (MEO), Operations Support System (OSS), and user application Lifecycle Management proxy (LCM proxy). The MEO is a core component of the MEC system level management capability and works with the OSS to manage the MEC host level. The MEO is also responsible for ensuring the integrity and authenticity of applications, as well as selecting appropriate MEC hosts for MEC applications based on their rules and requirements (ETSI Group, 2020a).

The mobile telecommunication network OSS is responsible for instantiating and terminating MEC applications via the Customer-Facing Service (CFS) portal and end devices. The MEC OSS manages application relocation requests both into and out of the MEC host. The user application LCM proxy enables device applications to obtain user relocation and state information and interacts with the OSS and the MEO to process requests from device applications, such as mobiles, laptops and other devices with internet connectivity (ETSI Group, 2020a).

The MEC host level includes a platform manager, virtualization infrastructure manager (VIM), and interfaces. The MEC platform manager gathers and distributes information about the system, networks and attached user devices including radio network information, resource availability, and enables applications to discover, advertise and consume edge services offered by local or remote MEC systems. The MEC applications, e.g., Virtual Machines (VM) and Containers, consume the MEC host infrastructure. The management tasks include resource allocation for computing, storage, and networking. In order to accurately troubleshoot operations, the VIM supports monitoring, collecting and analyzing data and sending performance and fault reports about the virtualization infrastructure. The VIM also provides a function to configure the virtualization infrastructure to run or store the software images. In terms of allocation and relocation, the VIM can interact with an external cloud manager to perform the mechanism called virtual machine handoff (ETSI Group, 2020a).

In an MEC architecture, there are three groups of interfaces, i.e., the MEC platform reference points (Mp), MEC management reference points (Mm), and MEC external entities reference points (Mx) (ETSI Group, 2020a). These interfaces are among the functional elements to enable MEC service connection, exchange, and management.

2.3. MEC reference architecture variant for MEC in an NFV environment
The generic MEC architecture is designed to operate independently from the NFV environment. However, there are evident advantages when the MEC architecture is deployed in an NFV environment. MEC and NFV are complementary, whereby MEC applications can take advantage of current NFV architectures and functions to run MEC services. Consequently, the MEC architecture variant can reuse the existing NFV Management and Orchestration (MANO) components to complete a part of the MEC management and orchestration functions. MEC applications and NFV virtualized network functions can also share the same virtualization infrastructure. Developing an MEC architecture for an NFV environment could expand the potential for future MEC applications. In 2019, the ETSI MEC group updated the reference architecture to include the deployment of MEC in an NFV environment, as shown in Fig. 2.

In the variant of the MEC reference architecture, two new functional blocks are presented to replace the MEO and the Multi-access Edge Platform Manager (MEPM) found in the generic architecture. This change was made due to the ETSI NFV MANO functional blocks performing some of the MEC functions and task assignments (ETSI Group, 2020a). The MEO is replaced by the MEC application orchestrator (MEAO), which works with the Network Functions Virtualization Orchestrator (NFVO) to manage the MEC applications and NVF capability. The MEPM is replaced by a Multi-access Edge Platform Manager — NFV (MEPM-V), which interacts with the Virtual Network Function Manager (VNFM) for the delegation of LCM.


Download : Download high-res image (543KB)
Download : Download full-size image
Fig. 2. ETSI MEC reference architecture variant for MEC in NFV (ETSI Group, 2020a).

The NFVO is described in ETSI GS NFV 002 (ETSI Group, 2020a) as the lifecycle manager of the MEC applications and Virtual Network Function (VNF) instances. The VNFM is described in ETSI GS NFV 002 (ETSI Group, 2020a) as the manager of the MEC platform and the virtualized MEC application instances. Another vital difference between the generic MEC reference architecture and the variant MEC reference architecture in NFV is a set of new interface points, e.g., Mm3*, Mv1, Mv2, and Mv3. The Mm3* reference point is the updated Mm3 reference point, now identifying the control path from MEAO and MEPM-V. The Mv1 reference point exists on the path between the MEAO and the NFVO. The Mv2 reference point between the VNFM and the MEPM-V is a path along which virtualization related messages are passed. The Mv3 reference point is on the path between the VNFM and the MEC application VNF instances; the path carries messages related to MEC application LCM (ETSI Group, 2020a).

2.4. Synergized MEC architecture
Due to the demands of the different ICT business models, there has been an increase in standardization activities that focus on supporting MEC deployed in conjunction with mobile and IoT networks. The ETSI ISG MEC and Third Generation Partnership Project (3GPP) are focusing efforts on MEC deployed to support mobile and IoT networks. The 3GPP application architecture for edge applications was introduced in September 2019 as the architecture for a new study that aims to enable application to be hosted on the 3GPP network edge. In 2020, Nurit Sprecher et al. (2020) authored an ETSI white paper that provided a synergized mobile edge cloud architecture leveraging the ETSI ISG MEC and 3GPP specifications to support different use cases and related requirements. The synergized MEC architecture, as depicted in Fig. 3, identifies the UE, the MEC nodes and the management and orchestration entities based on the ETSI MEC architecture. The UE include the MEC application clients that connect over the mobile network with an MEC Edge Application Server (EAS) and the Edge Enabler Client (EEC) that connects over the mobile network with the Edge Enabler Server (EES). The MEC Platform provides related functionality including application registration, discovery, and authorization. APIs are exposed by the MEC Platform towards edge cloud applications. EDGE-3 and Mp1 are complementary API functions. The MEC management and orchestration are largely based on the ETSI generic architecture. Nurit Sprecher et al. (2020) discuss the potential of this architecture and flexible deployment options. For example, the services exposed using EDGE-3 and Mp1 could be core or access network services. Common capabilities are supported through the adoption of the Common API Framework (CAPIF). The EDGE-9 and Mp3 interfaces can be used to assist in context migration (Nurit Sprecher et al., 2020).

3. MEC services
3.1. Computation offloading
There are limitations inherent in user devices, especially with their computing capabilities and power consumption. Due to this, computation offloading to MEC nodes emerged for compute-intensive and latency-sensitive applications, e.g., augmented reality and interactive gaming. In practice, when user devices are not able to carry out computation tasks, they can be offloaded to the edge server or to the core. This leads to an improved performance between user devices and core elements of the system, thus reducing the service response delay (Hu et al., 2015).

A series of decisions regarding computation offloading are considered, including whether to offload, how much to offload, what to offload, when to offload, where to offload, which computation offloading policy can be used, and what is the best offloading policy. The primary purpose of the MEC computation offloading is to selectively transfer computation tasks from the core cloud data center to edge servers and devices (to reduce service latency and bandwidth usage). However, considering that a variety of edge devices can be distributed across a vast geographical area, the energy consumption of large scale edge computing can be considerable. Besides that, another aspect to consider is whether the edge computing resources are sufficient for complex computations. Thus, what to offload or whether it is necessary to offload should be considered first. In general, taking into account the offloading objective, the computation can be carried out locally at the UE (local execution), wholly offloaded to the MEC (Full Offloading) or partially offloaded to MEC, while the rest is processed locally (partial offloading) (Jiang et al., 2019a). The best computation offloading policy should create a balance between energy consumption and network performance (Wang et al., 2017b).

Additionally, the availability of edge devices, network conditions, and system status dynamically change, all of which affect how computation offloading occurs. To achieve high network performance and low cost, the decision on whether or not to offload is crucial. Furthermore, the computation offloading scheduling also depends on where to offload by considering multiple factors, e.g., network bandwidth, energy, privacy and security. As such, energy-hungry and high privacy tasks might be offloaded to the cloud to save power and maintain security. In contrast, compute-intensive and latency-sensitive applications could be offloaded to the edge servers to be processed (Jiang et al., 2019a).


Table 5. Summary of computation offloading.

Theme	Contribution	Results
An EECO scheme	Jointly optimizing the computation offloading decisions and the radio resource allocation strategies.	Improved energy efficiency (Zhang et al., 2016).
A NOMA-based partial offloading scheme	Employing the convex approximation method to solve a non-convex form on the server-side.	Reduced the average power consumption (Nouri et al., 2019b).
An EETO algorithm	Breaking down the non-convex problem into several parallel convex sub-problems.	Reduced user’s energy consumption (Hua et al., 2019).
A MOTM mechanism	Jointly considering the computation offloading scheme, the transmission scheduling discipline, and the pricing rule.	Guaranteed individual mobile users were serviced with optimal management in a wide network (Yi et al., 2019).
An ADMM-based decentralized algorithm	Formulating the computation offloading resource, spectrum resource, and content caching issues.	Provided better performance (Wang et al., 2017a).
An RLTBB and a GCGH method	Jointly optimizing the offloading selection, radio resource, and computational resource allocations.	Minimized energy consumption on Smart mobile devices (Zhao et al., 2017).
An OECM algorithm	Leveraging a convex approximation approach to optimize the time, including energy transfer and data transmission, as well as task assignment including offloading decisions, data transmit powers, and CPU-cycle frequencies.	Reduced system energy consumption (Li et al., 2019a).
An IPDC algorithm	Jointly considering computation offloading, computation and communication resource allocation, and defined the weighting factor based on residual energy aware of the Smart mobile devices.	Simplified computation complexity and minimized the total cost (Zhang et al., 2017b).
An artificial fish swarm algorithm	Considering the energy cost at both the fronthaul link and the backhaul link, and modeling energy consumption of transmission tasks and computations tasks.	Minimize the average power consumption (Yang et al., 2018).
An ASCE algorithm	Occupying less memory and has lower computational complexity compared to traditional algorithms.	Provided better performance (Zhu et al., 2019).
An IHRA scheme	Making dynamic computation offloading decisions for multiple users.	Lowered execution delay by 30 percent at most compared to baseline algorithms (Ning et al., 2018).
An SDR-AO-ST algorithm	Utilizing a three-step approach to obtain a local optimum.	Minimized a weighted total cost of energy, computation, and the delay of all users (Chen et al., 2017).
A DTCCRA algorithm	Joint congestion control and resource allocation with power, subcarrier and computation resource constraints to maximize system utility.	Increased by 18.91% and 26.14% of system utility compared to the traditional algorithm (Li et al., 2019b).
An ASM algorithm	Prioritizing task scheduling policy and jointly optimizing the computation and communication resource allocation.	Improved performance (Paymard et al., 2019).
An HR architecture with CCCP-based algorithm	Jointly optimizing the bandwidth allocation, transmit power and the computational resources.	Minimized the weighted sum of the execution delay and energy consumption (Chen et al., 2019).
Solution for an optimized offloading policy	Jointly optimizing the radio resource allocation and computation offloading.	Reduced average energy consumption (Labidi et al., 2015).
An energy-efficient MECO system algorithm	Jointly optimizing computation and communication resource management subject to the energy and delay constraints.	Reached the optimal local frequency scheduling, computation offloading and power allocation (Nouri et al., 2019a).
MEC operates with relatively limited resources, unlike cloud data centers that do not have similar restrictions. Within those parameters, MEC must process multiple tasks simultaneously among a high number of users with scarce wireless resources. Hence, the computation offloading mechanisms should function collaboratively to improve network performance. Shuyue et al. in Ma et al. (2021) designed an improved multi-dependent particle swarm algorithm based on queue order that considers task completion time and execution cost. The flow of the proposed algorithm includes three phases (particle initialization, finding the optimal solution and optimizing the offloading process). Initially the algorithm identifies the priority of task execution by considering the latest task execution time, then a series of task access points and execution points are generated. Next, the algorithm determines the local and global optimal solution from the Pareto optimal solution set, and finally, the effectiveness of the proposed algorithm was verified. In addition, an increase in the number of intensive computation and data analysis applications on edge devices leads to increased energy consumption and network operational costs. Therefore, requirements for energy consumption and low latency are key factors when deciding whether to implement computation offloading. Computation offloading policies take into account different applications and their various requirements. Therefore, potential computation offloading algorithms and mechanisms that minimize energy consumption in MEC were reported in Zhang et al., 2016, Nouri et al., 2019b, Hua et al., 2019, Zhao et al., 2017, Li et al., 2019a, Zhang et al., 2017b, Yang et al., 2018, Chen et al., 2019, Labidi et al., 2015 and Nouri et al. (2019a), while the works in Yi et al., 2019, Wang et al., 2017a, Zhu et al., 2019, Ning et al., 2018, Chen et al., 2017, Li et al., 2019b, Paymard et al., 2019, Chen et al., 2019, Labidi et al., 2015 and Nouri et al. (2019a) revealed various algorithms and schemes for computation offloading that maximize performance.

In Table 5, existing MEC related research in terms of computation offloading is summarized.

3.2. Radio Network Information Service
RNIS, defined by the ETSI, plays an important role in support of MEC by facilitating the authorized MEC application instances to consume RAN level information. RNIS provides up-to-date radio network information at the relevant granularity (per cell, per UE, and per quality class indicator). Typical information includes radio network conditions, user plane measurement data, UE context, radio access bearers, and other information relevant to the MEC host. The MEC platform and MEC applications take advantage of the radio network information, to optimize the performance of existing services, the mobility service continuity, and to support new services. The information is exchanged between the MEC platform, MEC applications, and RNIS through the Radio Network Information API (RNI API), which is a Representational State Transfer (RESTful) API. However, for certain use cases, the amount of information and high update frequency can overwhelm the RESTful interface. In these cases, the message broker (ETSI Group, 2019b) views and utilizes radio network information as well as the information from the network provider.

To optimize the mobility management procedures for service continuity, Denitsa et al. in Kireva et al. (2018) proposed a model in which handover states can be seen by MEC applications and, in turn, they are able to verify the behavior among source eNodeB and target eNodeB. The procedures focus on the notification (RNIS sent to RNI) related to handover procedures, including handover preparation, preparation failure, handover execution, handover completion, and handover cancellation.

In order to explore MEC potential for enhancing radio network performance, Evelina et al. in Pencheva (2018) presented an extension of the RNIS API for the handover control connectivity management function. The extension of RNIS also supports third-party connectivity management and enables MEC applications to dynamically control UE connectivity. The work of Pencheva and Atanasov (2018) presented an extension to mobile edge services with the inclusion of the monitoring control function (this was previously utilized in the core network). By distributing this function to the MEC nodes, resource monitoring can occur from the core network to the network edge. For example, an authorized MEC application with access to this function could monitor resource usage and process traffic at the edge when resources become available. Thus, resource usage monitoring control is deployed at the MEC nodes can improve network performance.

To estimate provisioning related latency using the radio network information, Ivaylo et al. in Atanasov et al. (2019) compared two 5G MEC deployment scenarios for mission-critical communications. Specifically, the Protocol Data Unit (PDU) session resource management and handover procedures were contrasted and analyzed. The MEC and C-RAN co-location deployment have minimal latency when compared to MEC deployment at an aggregation point. The reason provided for this outcome was the internal messages exchanged between gNB-CU and MEC applications being processed using the same virtualized platform.

The research in Pencheva et al. (2019) proposed an extension to RNIS that provides user behavior prognostics, i.e, user activity and mobility. RNIS, with the help of the extension, receives radio access information and computes user related cell changes. Analytic applications can then provide UE behavior prognostic information, during the packet data and handover sessions.

Arora et al. (2019) presented the provisioning of RNIS in the context of MEC and NFV environments. When implementing these provisions, the MEC architecture, elements, and interfaces are integrated into the NFV environment. MEC applications are also processed over the virtualized infrastructure. The authors introduced RNIS as a Service (RNISaaS) as a virtualized function. To determine the most suitable approach to provision RNISaaS, two different message brokers were compared, RabbitMQ and Apache Kafka. In terms of routing capability, RabbitMQ has extensive capabilities and provides direct, fanout, headers, and topic exchanges, while a message in Kafka only provides a topic for routing messages. However, the message in Kafka can be consumed again after initial consumption, whereas In RabbitMQ, the messages can only be consumed once. Besides, Kafka supports a large number of consumers, while RabbitMQ has a single consumer instance. Apart from the drawbacks of an all virtualized system, and considering the computing limitations of MEC, results indicate that RabbitMQ is more suitable for an MEC environment.

3.3. Location Service
A Location Service (LS) in MEC was introduced in the ETSI specification (ETSI Group, 2020a). LS supports a location retrieval and subscribe mechanism, e.g., the anonymous location report and location information. The MEC LS provides authorized applications with location-related information including UE location for UE currently controlled by the radio nodes associated with related MEC hosts. In ETSI Group (2019c), the ETSI defined the MEC LS API, data model and data format. The LS leverages the Zonal Presence service and provides access through the Open Mobile Alliance (OMA) API. The Zonal Presence service uses the ‘zone’ concept where a zone covers a group of the radio nodes, and is related to an MEC host. The Zonal Presence API retrieves information and subscribes to information about user activities within a unit zone. The MEC application and MEC platform can be treated as service consumers which communicate with the LS via the LS API.

Additionally, the ETSI also defined the LS API resources and operations. LS in an MEC environment plays a vital role in location-aware energy routing. The work in Dlamini (2019) discussed energy allocation and routing by using an online Lyapunov algorithm with the MEC LS API. Energy cooperation decisions are made by using the location of the users from LS API and the current Energy Buffer (EB) levels.

3.4. Traffic Management
Different applications may request specific bandwidth and priority for one or more instances. Additionally, resource conflicts occur and an unfair advantage may occur when sessions are linked to nearby UE. The Traffic Management (TM) service can aggregate requirements, thereby resolving resource conflicts, optimizing bandwidth usage and improving user experience. The MEC TM service was presented by ETSI in the specification (ETSI Group, 2020e) including the BandWidth Management (BWM) and Multi-access Traffic Steering (MTS) services. The BWM service manages bandwidth allocation between MEC applications. The MTS service provides steering, splitting and duplicating the MEC application traffic. A set of operations (e.g., register with BWM, unregister from BWM, update requested bandwidth requirements to the BWM, get bandwidth allocation from BWM, get information from the MTS, register with the MTS, unregister from the MTS, update requirements with the MTS and get the session details from the MTS) describes how MEC applications utilize TMS to update and receive BWM and MTS information from the MEC platform. Zbigniew et al. in Kotulski et al. (2020) introduced examples of access control messages. The access control messages have three parts: 5G UE registration, Core UPF discovery, and MEC service access. In the final access control phase, TMS is used to send the service access information to the MEC platforms after the UPF MEC sends the request to TMS. The MEC platform then chooses the service and verification token; and, the MEC platform sends a request back to the service and UE. The proposed solution reduces implementation complexity when compared with previous approaches.

3.5. Application mobility
Application mobility is a unique MEC system service, which provides relocation of user context and application instances between MEC hosts, different MEC systems, and the external Cloud. For example, a mobile phone can be connected with network nodes that are associated with different MEC hosts as it moves around. Relocation decisions are made on the MEC infrastructure capability, customer profiles, application preferences and device mobility. Application mobility service is considered to be a part of the service continuity capability. When the application instance moves to the target MEC host, the user context will be transferred to the application instance permitting the application to continue operating seamlessly with the UE. The user context transfer is only for stateful application continuity. Application mobility may need multiple MEC functional entities based on three implementation approaches (Application self-controlled user context transfer, device application assisted user context transfer, and MEC assisted user context transfer). In addition, the information flows for application mobility in the different environments are provided, such as the information flow for the intra MEC system, the information flow for the service provisioning and registration.

The work in Lee et al. (2019) provided an enhanced mobile support system on MEC for IoT with low operational costs and overhead. Syed et al. in Shah et al. (2020) presented the MEC architecture in NFV environment with an SDN controller, focusing on end-to-end mobility support and service continuity. The proposed architecture was simulated and showed an approach for the vehicle-to-everything service scenario. The work in Lin et al. (2020) proposed an algorithm and a hierarchical MEC architecture for selecting suitable MEC servers and supporting service migration. The effectiveness of the architecture was identified and shown to effectively perform service migration and quickly restore services. Shanmuganathan et al. in Thananjeyan et al. (2020) investigated a method to improve the energy efficiency of MEC hosts selection and service migration, and formulated this problem as a shortest path problem. Using Dijkstra’s algorithm, the research indicated that machine learning and big data analytics could effectively solve such a problem.

4. MEC complementary technologies
4.1. MEC and NFV
Network function virtualization
Virtualization is a crucial technology used in support of cloud computing. Virtualization improves network resilience and flexibility by utilizing software to simulate hardware functionalities where the heterogeneous network functions in software can run on a homogeneous and standard infrastructure. The software can be added or removed in various network locations as required. The introduction of virtualization simplifies network deployment, reduces network operational costs and enables network automation management. This technology has been designed and deployed as an essential part of the modern information communication network.

In order to better understand the benefits of virtualization, Rak and Hutchison (2020) reviewed the implementation of virtualization in cloud application architectures, including microservices, stateless applications and function as a service. The authors described the adoption of virtualization in the mobile core network and IP multimedia subsystem to explore the potential of virtualization as a means to reduce the complexity of network deployment and operation and to improve system resilience.

MEC in an NFV environment
ETSI has commenced publishing a specification series on NFV. In 2016, ETSI GS NFV-EVE 004 (ETSI Group, 2016) reviewed different virtualization technologies, including hypervisor-based solutions, Operating System (OS) containers, higher-level containers, nesting of virtualization technologies, mixing of virtualization technologies and mixing and nesting of virtualization technologies. ETSI also investigated the impact of the selected technologies on the NFV framework. An in depth analysis of the advantages and disadvantages of the selected technologies was conducted related to various factors, e.g., features, performance considerations, security, open-source support, resources and lifecycle management. In 2018, ETSI presented an MEC deployment in an NFV environment (Computing, 2018). After this, ETSI GS MEC 003 (ETSI Group, 2018c) described functional elements and interfaces in a generic reference architecture and MEC in the NFV reference architecture variant in 2019; both reference architectures are compatible with available virtualization technologies. Hence, jointly managing MEC applications in an NFV environment will reduce Capital Expenditure (CAPEX) and Operating Expenses (OPEX) and ensure deployment of MEC services occurs in a timely and flexible manner.

Bing et al. in Bing et al. (2019) proposed an MEC in NFV architecture which was designed with two vertical domains (MEC domain and NFV domain) and three horizontal layers (orchestration layer, the management layer, and resource layer). The orchestration and management layers are responsible for service communication and consistency between the two domains, while the NFV domain controls the resources. More efficient resource usage and low-latency are achieved through shared resources and joint control, fulfilling performance-intensive applications.

Ioannis et al. in Sarrigiannis et al. (2018) proposed an MEC-enabled 5G architecture with a management mechanism for core cloud and edge nodes. Consequently, in this architecture, the NFVO controls the application and VNF migration. When computing is close to the edge, VNF migration is assisted by the MEC service migration entity. The migration procedure improves system resource utilization and reduces network traffic. In addition, an MEC-based LTE testbed was presented to evaluate orchestration utilization. The research also focused on an algorithm that optimized MEC applications in the virtualization environment.

Qiang et al. in Liu and Han (2019) developed a multi-domain resource orchestration algorithm which is a radio resource virtualization algorithm. The algorithm, VirtualEdge, enables resource orchestration and virtualization across multiple domains in mobile edge nodes. Also, the performance of the new system was assessed, theoretically and practically.

MEC support for alternative virtualization technologies
The impact of virtualization technologies on the MEC architecture was analyzed in ETSI GR MEC 027 (ETSI Group, 2019j). Hypervisor-based solutions host isolated VMs that are allocated MEC host resources. The hypervisor is presented as the default virtualization technology in the ETSI specifications. Another solution is container-based virtualization, also known as application-level virtualization, where an isolated instance is called a container. In container solutions, the container provides only the resources necessary for the application to function. In contrast, a hypervisor solution includes a guest OS and the application. In addition, each container can share resources, e.g., network interfaces, and system files within a container pod. Container virtualization is a more lightweight virtualization technology and can rapidly instantiate applications. Fig. 4 shows hypervisor versus container solutions (ETSI Group, 2016).

Multi-layer container virtualization, an enhanced container environment is used to split the virtualization layer into nested sub-layers with different virtualization technologies. As a result, it allows an MEC host to create a VNF for each third-party application, to support multiple environments. The network functions for sub-layers are specific only to that layer. When it comes to mixing, as well as mixing combined with nesting of virtualization technologies, both are flexible solutions for certain MEC applications. Single, or numerous, VIMs can control different virtualization technologies, with the mixing of virtualization technologies. Mixing and nesting of virtualization technologies are permissible, where each virtualization layer consists of multiple nested sub-layers, with different types of virtualization technologies. In this case, each type of virtualization technology can be chosen by a specific application (ETSI Group, 2019j).

Martin et al. in Martin et al. (2018) detail the five types of eco-system vulnerabilities: insecure production system configuration, vulnerabilities in the image distribution, verification, decompression, and storage process, vulnerabilities inside the images, vulnerabilities directly linked to Docker, and vulnerabilities of the Linux Kernel. The research indicates that simple comparison of VMs and containers is inappropriate and it should be based on the different use cases and environments.


Download : Download high-res image (241KB)
Download : Download full-size image
Fig. 4. Hypervisor vs. OS container solutions (ETSI Group, 2016).

4.2. MEC and SDN
Software defined networking
SDN is a network architecture that separates the control and data planes (Kreutz et al., 2014). The control function is moved from the network devices into the control plane where one or more SDN controllers are used to manage traffic flows. Messages between the controller and data flow devices occur over the controller’s Southbound interface using the standardized OpenFlow protocol. An overlay capability through the undefined Northbound interface permits service management applications. The SDN data plane forwards and processes message flows through network devices, e.g., routers, switches, and firewalls. The flexible and programmable nature of SDN permits real-time installation and updates; a far superior approach to that used for legacy networks. Fig. 5 shows the basic SDN architecture (Al-Heety et al., 2020).

SDN protocol
OpenFlow is standardized communication protocol used in the SDN environment to pass messages between the controller and the data flow devices over the controller’s Southbound interface. It is described by the Open Networking Foundation (ONF) (Found, 2015) as a key aspect of the first SDN standard. The SDN architecture is divided into three layers, including OpenFlow-enabled virtual and physical switches, OpenFlow controllers, and overlay applications. OpenFlow-enabled switches have one or more flow tables. The main components of a flow entry in a flow table include match fields, priority, counters, instructions, timeouts, cookie, and flags, which define how the packets are handled. The controller communicates with the OpenFlow-enabled switch to update flow tables in response to requests from the data flow devices. The OpenFlow-enabled switch interface channel supports one or more connections with controllers. There are three categories of messages carried over the OpenFlow channel, including controller-to-switch, asynchronous and symmetric messages encrypted using Transport Layer Security (TLS). Controller-to-switch messages are triggered by the controller and utilized to manage and monitor the switch state. Asynchronous messages are sent from the switch to inform the controller of current network conditions. Symmetric messages can be initiated by both the switch and the controller. Despite the advantages of the SDN architecture, a number of challenges remain including scalability and performance issues.

An open challenge is the need to enhance SDN to support stateful packet processing and improve visibility of the state information. In addition, OpenFlow switches are highly dependent on the controller for network traffic forwarding, which can increase the communication overhead between the data and control planes. The domain-specific Programming Protocol-independent Packet Processors language (P4) was introduced by Google, Microsoft, Intel, Stanford, Princeton, and Barefoot to improve programmability and visibility. SDN combined with the P4 programmable data plane improves network monitoring, DDoS attack detection, load balancing, packet aggregation and disaggregation (Kaur et al., 2021).

Research into the SDN architecture is ongoing. Blial et al. (2016) provide a comprehensive investigation of SDN multi-controller architectures. For distributed multi-controller network architectures, challenges were identified in the paper, e.g., performance optimization, network design, and the integration of the new applications across a multi-controller network architecture. Moin et al. in Moin et al. (2018) proposed an innovative SDN framework called G-SDN that provides improved energy-conservation and security. Another potential energy-conservation solution is the integration of SDN systems and NFV using an approach similar to G-SDN. NFV and SDN, as complementary technologies, have enabled profoundly open and intelligent network environments, far beyond their conventional counterparts. Researchers have been focusing on how to integrate NFV and SDN. In the survey (Bonfim et al., 2019), the authors provided a systematic literature review into SDN and NFV integrated architectures. A comparison was made regarding the disparity of the architecture designs between NFV and SDN. Finally, future research opportunities and challenges were discussed including network service deployment, enhanced programmability, enabling multi-controller scenarios, development of NFV and SDN architectures, and security.

SDN in MEC
ETSI has proposed MEC deployment in an NFV environment. A controller or multiple controllers can be deployed in an MEC and NFV architecture. Several works in Kreutz et al., 2014, Al-Heety et al., 2020, Found, 2015 and Kaur et al. (2021), proposed SDN-based MEC architectures and identified areas undergoing investigation. Abderrahim et al. in Abderrahim et al. (2018) proposed a new architecture based on SDN, MEC, and Machine Learning technologies that enables flexible network management by monitoring and collecting radio network information and prognostic data to achieve efficient resource allocation.

To deal with traffic management challenges, Schiller et al. (2018) assessed MEC by utilizing an SDN and NFV platform. By utilizing a new SDN controller, VNFs, and the NF Manager, the authors presented a solution that improved traffic, mobility management and user experience.

Shantharama et al. (2018) presented a new architecture called LayBack that leveraged a unifying SDN orchestrator to collect resources from various RAN gateways to improve the MEC operation. The authors also proposed a computation mechanism that shares resources from network operators to reduce costs.

An et al. in Wang et al. (2019b) provided a survey on how SDN facilitates control and manages different areas of the network, including access, core, cloud, and enterprise. The authors considered SDN-based networking in several scenarios that highlighted how SDN enables application, service control and management. The authors identified that SDN-based MEC should be an open solution that supports multiple edge devices, data link types, and protocols. In order for a unifying outcome using an SDN-based network, the authors identified the need for management optimization, application and service provision.

4.3. MEC and network slicing
Network slicing
In recent years, the Next Generation Mobile Networks (NGMN), 3GPP, ONF, and ETSI have been investigating and publishing network slicing specifications. According to NGMN, network slicing separates a physical network into several virtual networks; each virtual network can be customized and optimized for a specific application. Logical network slices are deployed and changed with user demands by leveraging cloud computing, SDN control, and NFV (Zhang, 2019).

One of the key features of network slicing is the ability for third-party entities to control the service functions via an API. A network slice may vary across several network domains, including the radio access network, transport networks and core networks. Network slicing is defined in three layers: service instance layer (the end-user service); network slice instance layer (a network instance made available to the service instance); resource layer (providing the physical resources, virtual resources and network functions to a network slice instance).

The ONF has considered an SDN architecture for network slicing where the client context can be associated with a slice, to support control logic and tailored services. In the 3GPP specification (GSMEC, 2017), the NGMN slicing technology forms the basis of the approach implemented. The 3GPP TR 28.801 presented a new slicing model where a slice consists of one or more slice subnets. The 3GPP also identified three network slice management functions: Communication Service Management Function (CSMF), Network Slice Management Function (NSMF) and Network Slice Subnet Management Function (NSSMF). The NSMF is responsible for the Network Slice Instance (NSI), and communicates with the CSMF and NSSMF. NSSMF is responsible for the Network Slice Subnet Instance (NSSI) management. Similarly, the subnets can control network functions and other slice subnets. 3GPP defined three standardized slice service types (SST), including SST value 1 for 5G enhanced Mobile Broadband (eMBB), value 2 for ultra-Reliable Low Latency (uRLLC) and value 3 for Massive IoT (MIoT).

Network slicing in MEC
NGMN first defined the notion of a 5G slice in Alliance (2015). 5G slice technologies focus on 5G network functions deployed in MEC from the perspective of the customer and business. (see Fig. 6). To provide only customized functions, a 5G slice is only responsible for the traffic of a specific use case. The ETSI (ETSI Group, 2020c) described MEC functionalities in support of network slicing and identified the new MEC functionalities, interfaces and changes to the existing MEC functional elements. MEC resources can be assigned to the different slices to meet the different MEC applications. Network slicing in the MEC environment is beneficial for resource usage.

Fast and efficient network slicing is facilitated by the flexible, fast, and programmatic SDN and NFV. When combined with MEC, network slicing provides a versatile approach to support complex applications and services at the edge. Isolation management of the network slices improves network security, and slices can be tailored to improve Quality of Service (QoS) for the selected applications and services. The flexible resource allocation mechanism improves resource allocation on demand, resource optimization and redeployment (Alliance, 2015).

In Khamse-Ashari et al. (2019), a proposed mechanism for network slicing in an MEC environment formulated a series of resource provisioning problems. The authors indicated that there was a Nash Equilibrium which enhanced multi-tenant optimization and reduced operation and management costs for service providers. In addition, an optimal mechanism was proposed that analyzed various resources and the VNF deployment.

Several works, including Macheta et al., 2019, Faraci et al., 2019 and Campolo et al. (2017), presented network slicing applications for different scenarios. Macheta et al. in Macheta et al. (2019) proposed a simulation framework to evaluate end-to-end IoT service latency in a network slicing architecture. Faraci et al. (2019) proposed an extension of 5G network slicing with MEC to minimize power consumption for a fleet of Unmanned Aerial Vehicles (UAV) application, where the number of active Computer Elements (CEs) depend on the run-time computation load and a strategy for selecting job offloading.

Campolo et al. in Campolo et al. (2017) elaborated upon the enablers (NFV, SDN), explored challenges for 5G network slicing, and presented a design for 5G network slicing for V2X services. The proposed architecture considered the resources from the core network, RAN and vehicle end-devices. An analysis was conducted for slicing management and orchestration to guarantee the performance of V2X services, including slice description, slice instantiation, and slice life cycle management.

4.4. MEC and SFC
Service function chaining
Network operators offer end-to-end functionality to users called a network service. A network service consists of several Service Functions (SFs) chained together. An SFC is defined as a sequence of SFs that must be performed in an order based on the classification and policy. SFC is the mechanism of multiple SFs as a chain where packets and flows exchange. The IETF has defined a formal SFC function on top of the ETSI NFV architecture. The defined SFC architecture consists of three different planes, including management, control and data planes as described in Fig. 7. The management plane is responsible for the installation, maintenance and termination of the service functions. SFC manager, Service Function Path (SFP) manager and SF manager are included in this plane. The data plane consists of classifiers and service functions. The traffic will be classified before transferring to the SFP. The path between them is managed by the control plane, including policy controller, SFC controller, SFP controller and user profile. The SFC controller selects an SFC based on the classified packets, then a specific SFC is selected based on the user preferences and subscription information and stored in the user profile. The SFC controller determines SFPs with the SFC to meet the QoS requirement. Finally, the policy controller maintains the forwarding path of SFC policy tables. Additionally, a forwarding element called Service Function Forward (SFF) is introduced for steering network traffic where the virtualized network functions operate over the physical resources (Mirjalily and Zhiquan, 2018).

SFC in MEC
To support eMBB, uRLLC and massive Machine Type Communication (mMTC) services provided by 5G networks, MEC and technologies including SDN, NFV, slicing, and SFC are expected to play a key role. In Lei et al. (2018) indicated the feasibility of SFC in edge caching and proposed a framework in which the mobile edge applications can be supported with dynamic edge service chaining and virtualized RAN functions. As a result, the caching performance was enhanced by using the proposed framework.

In an MEC-NFV enabled mobile network, service functions can be chained as an SFC consisting of several VNFs, which are geographically placed around the edge. Due to the multiple terminals and user mobility, VNF placement and service routes play a key role in performance optimization, e.g., the end-to-end delays. The works in Wang et al., 2019a, Chen and Liao, 2019, Liu et al., 2020b, Liu et al., 2020a and Subramanya et al. (2020) revealed the SFC advantages in an MEC-NFV architecture for dynamic service orchestration. Meng et al. in Wang et al. (2019a) investigated on the SFC problem in an MEC-NFV environment, and proposed an LP-based approach and a Hungarian-based algorithm to solve a graph matching problem and an SFC mapping. The proposed solution improved resource utilization and reduced execution times. Yan et al. in Chen and Liao (2019) proposed an on-line algorithm called Follow-Me Chain that focuses on SFC placement and migration in a 5G network incorporating MEC to solve the long latency and service interruption problem. For SFC migration, the VNFs are moved between MEC servers to minimize service interruptions.

Yicen et al. in Liu et al. (2020b) presented a quantum machine learning-based solution to handle SFC orchestration in a dynamic manner in an MEC environment. The simulation result indicated a more than 8-fold run-time reduction compared to the Viterbi algorithm. Yicen et al. in Liu et al. (2020a) also introduced an SFC dynamic orchestration framework for IoT deep reinforcement learning to solve the SFC dynamic orchestration problem. The experimental results identified the minimum VNF processing delay. Subramanya et al. (2020) proposed a machine learning model in a neural-network that performs auto-scaling of VNFs by predicting the number of VNFs required to meet current traffic demands. The proposed Integer Linear Programming (ILP) techniques solved the SFC placement problem, aiming to reduce the end-to-end latency.

4.5. MEC and ICN
Information-centric networking
ICN is an Internet architecture shifting from host-centric network design to an information-centric network design. The ICN architecture decouples information from its source. In an ICN architecture, routing will occur based on the best path to the source of the requested information.

Xylomenos et al. in Xylomenos et al. (2013), considered a set of key functionalities for ICN architectures, including naming, name resolution and data routing, caching, mobility and security. For the information name function, location-independent information names are the key to the ICN architecture. In terms of name resolution and data routing, coupled and decoupled are two functions that are provided in which the name resolution function does not select the path in the decoupled approach while in the coupled approach the path information is sent by the requesting host. When caching, on-path and off-path caching are identified. In an ICN architecture with coupled name resolution and data routing, off-path caching is supported by the name resolution system while the routing system supports decoupled off-path caching.

ICN architectures support mobility functions. Mobile subscribers can send new information after a handoff; meanwhile, the name resolution system and the routing tables need to be updated to support publisher mobility. ICN architecture security identifies that flat names support self-certification, but this is not readable, therefore, another trusted system is needed to resolve between flat names and human-readable names.

ICN in MEC
MEC and ICN can be deployed independently or in complementary implementation, but both could benefit for 5G network. Several works in Benedetti et al., 2021, Vaiyapuri et al., 2021, Ravindran et al., 2017 and Zhou et al. (2017) provided for network integration with ICN. Benedetti et al. in Benedetti et al. (2021) proposed a protocol architecture to address users’ mobility and improve network performance by integrating ICN, MEC and SDN. The simulation results identified that the communication overhead reduced up to 99.99 and bandwidth saved up to 99.93. Vaiyapuri et al. (2021) described the advantages of ICN deployment for resource-limited wireless sensors network, which improved the data access’s flexibility and reliability when mobility happened. Besides, the authors presented an IoT enabled cluster-based routing protocol for information-centric wireless sensor networks. The proposed protocol improved network lifetime and energy efficiency.

Ravindran et al. (2017) described the feasibility of an ICN network architecture within the 5G core architecture, and how to process ICN PDU sessions. Specifically, the authors proposed an ICN architecture in MEC for the connected car scenario and ICN session mobility. Zhou et al. (2017) presented a novel ICN framework called HetNets by analyzing the virtual resource allocation, e.g., communication, computing and caching resource. The simulation results showed that the proposed ICN scheme enhanced network performance, and optimized computing and caching capabilities.

4.6. MEC and C-RAN and F-RAN
Cloud-radio access network
In 2010, IBM first proposed C-RAN to enhance future network flexibility and to reduce costs. As in traditional mobile telecommunications, Base Stations (BS) consume considerable energy and to reduce energy consumption and improve radio resource efficiency, C-RAN was introduced as a cloud networking architecture to process computation and storage tasks from the distributed BS. Specifically, C-RAN decouples the functions of the traditional BS into the Remote Radio Head (RRH) and a centralized Baseband Unit (BBU) pool. RRH with radio frequency functions can be locally deployed. By introducing the cloud computing approach, the virtualized BBU pool can carry out the Large-scale Collaborative Processing (LSCP), Cooperative Radio Resource Allocation (CRRA), and intelligent networking to reduce inter-tier and inter-cell interference. The BS signal processing and radio resources are moved into the BBU pool. The BBU pool is responsible for the BBUs functions and reduces CAPEX and OPEX. Currently, the fronthaul between the BBU pool and RRH is a problem for C-RAN. The C-RAN system architecture is shown in Fig. 8 (Mugen Peng, 2020).


Download : Download high-res image (279KB)
Download : Download full-size image
Fig. 8. C-RAN system architecture (Mugen Peng, 2020).


Table 6. Differences between MEC and F-RAN (Mugen Peng, 2020).

MEC	F-RAN
Motivation	Enable an open radio access network which can host the third party innovative applications and content at the edge of the network	To overcome the disadvantages of the fronthaul constraints with limited capacity and long time delay.
With C-RAN	Independent with C-RANs	Incorporate an enhancement and evolution of C-RANs
Key technique	Computing offloading	Edge caching and AI
Deployment scheme	Be compatible with 4G/5G RAN architectures	A novel system architecture evolved from HetNets and C-RANs by introducing fog computing
C-RAN in MEC
C-RAN and MEC are complementary technologies. The integration of C-RAN and MEC supports the key 5G applications and saves OPEX and CAPEX for both telecommunication and cloud providers. Deploying C-RAN in MEC reduces the cost of a standalone C-RAN deployment. In an ETSI white paper (Reznik et al., 2018a) C-RAN and MEC were described as a perfect pairing. A C-RAN-MEC site architecture is presented in the ETSI white paper (Reznik et al., 2018a) across four domains, including an OpenStack domain, containerized domain, Bare Metal domain and the 3rd Party IaaS domain.

A series of co-location challenges have been identified including management, security, networking and regulatory. Haibo et al. in Mei et al. (2018) provided a joint cache content placement and user task offloading solution for the multi-layer MEC and C-RAN architecture. The solution optimized the C-RAN fronthaul data transmission by storing selected UE content into the RRH. Jian et al. in Jian et al. (2019) provided a novel task-aware C-RAN with MEC architecture to optimize the offloading strategy and resource allocation by considering the limitations of the fronthaul capacity, radio and computational resources. The simulation results showed the effectiveness of the proposed architecture. Qi et al. in Zhang et al. (2020) investigated the task offloading and resource allocation problem in MEC-enabled C-RAN. The Lyapunov optimization theory was proposed to optimize task offloading. The simulation results verified the effectiveness of this scheme and described the trade-off between energy efficiency and latency.

F-RAN in MEC
F-RAN was first proposed in Mugen Peng (2020) to provide edge caching and AI capability. The difference between C-RAN and F-RAN is the edge cache, edge AI and edge computing function are not considered in C-RAN. Without the cloud computing function, F-RAN is essentially the same as an MEC system. F-RAN benefits include real-time signal processing, dynamic traffic over the radio environment, low latency on the fronthaul and BBU pool, and low cost. The authors also provided a comprehensive survey on F-RAN, including architectures, technologies and applications. Table 6 provides a comparison between MEC and the proposed F-RAN.

MEC enabling technology research is ongoing. Fig. 9 shows a summary of MEC enabler features. Table 7, Table 8 provide a summary of the selected research and development efforts, and list the research area, related work, and contributions.


Table 7. Summary of state-of-the-art MEC enablers.

References	Performance improvement	Energy efficiency	Resource allocation	Cost efficiency	Remarks
NFV (Bing et al., 2019)	✓	✗	✗	✓	The authors proposed a new MEC and NFV integrated network architecture.
NFV (Sarrigiannis et al., 2018)	✗	✗	✓	✗	The authors presented an MEC/NFV-enabled 5G architecture to flexibly manage resources from cloud to edge.
NFV (Liu and Han, 2019)	✗	✗	✓	✗	The authors presented the VirtualEdge system for resource orchestration and virtualization.
SDN (Al-Heety et al., 2020)	✓	✗	✗	✗	The authors provided a vehicular network architecture combined with SDN in different aspects, e.g., routing protocol, mobility management and privacy.
SDN (Abderrahim et al., 2018)	✗	✗	✓	✗	The authors proposed a new architecture based on MEC, SDN and Machine Learning technologies, which improved resource sharing and network performance.
SDN (Schiller et al., 2018)	✓	✗	✗	✗	The authors provided an MEC enabled architecture with SDN controller, which improved the network performance.
SDN (Shantharama et al., 2018)	✗	✗	✓	✗	The authors proposed a new architecture based on SDN/MEC, which enhanced the sharing of communication and computation resources.
SDN (Wang et al., 2019b)	✓	✗	✗	✗	The authors provided a survey of how SDN could be equipped with MEC implementation in where SDN provided a unified framework to manage various IoT devices.
SLICING (Khamse-Ashari et al., 2019)	✗	✗	✓	✓	The authors proposed a mechanism for end-to-end resource allocation to network slices in the mobile network environment, which enhanced resource utilization and reduced operational costs.
SLICING (Macheta et al., 2019)	✓	✗	✗	✗	The authors presented a simulation framework which can evaluate end-to-end latency through network slicing based on the use cases.
SLICING (Faraci et al., 2019)	✗	✓	✗	✗	The authors proposed an MEC enabled 5G network slicing with UAVs for task offloading, which saved the power consumption.
SLICING (Campolo et al., 2017)	✓	✗	✗	✗	The authors described network slicing’s role and how it isolated and guaranteed the performance of 5G use cases.
SFC (Lei et al., 2018)	✓	✗	✗	✗	The authors presented a new architecture for guaranteeing the edge caching requirement in where SFCs can provide the mobile edge applications with MEC/NFV deployment.
SFC (Wang et al., 2019a)	✓	✗	✓	✗	The authors provided an algorithm for SFC placement to enhance execution time and resource utilization.
SFC (Chen and Liao, 2019)	✓	✗	✗	✗	The authors proposed an algorithm in terms of SFC placement and SFC migration to solve the mobile SFC embedding problem.
SFC (Liu et al., 2020b)	✓	✗	✗	✗	The authors proposed a scheme based on machine learning to handle dynamic SFC orchestration in MEC deployment, which reduced the end-to-end latency.
SFC (Liu et al., 2020a)	✓	✗	✗	✗	The authors presented an SFC dynamic orchestration framework and algorithm to deal with dynamic and complex network scenarios. The results indicated the outstanding performance of the proposed algorithm.
SFC (Subramanya et al., 2020)	✓	✗	✗	✗	The authors proposed a machine learning model which can perform auto-scaling of the virtual network function instances to solve the SFC placement.

Table 8. Summary of state-of-the-art MEC enablers.

References	Performance improvement	Energy efficiency	Resource allocation	Cost efficiency	Remarks
ICN (Benedetti et al., 2021)	✓	✗	✗	✗	The authors proposed a novel protocol architecture of integration of ICN, MEC, and SDN network paradigms to address users mobility and improve network performance.
ICN (Vaiyapuri et al., 2021)	✗	✓	✗	✗	The authors proposed an IoT enabled protocol for ICN. The experimental outcome indicated that the proposed model has outperformed the other methods in terms of network lifetime and energy efficiency.
ICN (Ravindran et al., 2017)	✓	✗	✗	✗	The authors explored the future network architecture and proposed a 5G core architecture with ICN and MEC deployment for a connected car scenario.
ICN (Zhou et al., 2017)	✓	✗	✗	✗	The authors presented a novel ICN framework to optimize resource allocation, including computation, communication and caching resources.
C-RAN/F-RAN (Mei et al., 2018)	✓	✗	✓	✗	The authors presented a solution of a joint cache content placement and task offloading for multi-layer MEC enabled C-RAN, in where the proposed model further saved fronthaul data transmission by caching the UEs’ most interesting social-aware contents into the RRHs.
C-RAN/F-RAN (Jian et al., 2019)	✗	✗	✓	✗	The authors presented a novel architecture of C-RAN with MEC to optimize task offloading and resource allocation in consideration of offloading latency, the capacity of fronthaul and the limited bandwidth.
C-RAN/F-RAN (Zhang et al., 2020)	✓	✗	✓	✗	The authors introduced an optimization theory based on MEC-enabled C-RAN to consider task offloading and resource allocation to improve network energy efficiency.
5. Use cases and applications
Emerging MEC based technologies could benefit a variety of service scenarios, including augmented reality services, connected vehicles, and IoT gateway services. MEC enables computing and storage closer to edge devices, and supports a wide variety of applications and services. The network and application traffic information can be used to optimize network performance. In the ETSI white paper (GSMEC, 2018), three primary categories of use cases operating on a similar MEC architecture were identified, including consumer-oriented services, operator and third-party services and network performance and Quality of Experience (QoE) services, as shown in Fig. 10. The following subsections discuss the detailed use case categories and related service scenarios. Table 9 provides a summary of the discussed MEC enabled use cases.

5.1. Consumer-oriented services
Consumer-oriented services focus on the end-user benefits from an MEC deployment, e.g., the reduction in latency and computation offloading for applications, including gaming, remote desktop applications, augmented and assisted reality, and cognitive assistance. The MEC computation offloading services can effectively increase computing and resource storage capacity of end-user devices, and are a significant advantage over legacy scenarios that focus on core cloud-based implementations (GSMEC, 2018, MECISG, 2015).

Augmented, assisted and virtual reality and cognitive assistance applications can enhance various facets of daily life. The applications require low latency and have computation intensive characteristics. Augmented reality applications provide users with additional information within a short time by analyzing their environment. Games designed to run on smart phones are very popular. However, effective operation is affected by bandwidth, latency and computation capacity limitations. In contrast, personal computer and tablet based games leverage the superior specifications of the host devices and may anticipate high speed broadband connections.

To foster an environment that can handle computation-intensive mobile games and provide low latency, MEC computation offloading is essential. Another factor to consider is that one or more users might change their position in a mobile cellular network and the different characteristics of the radio nodes might affect game play. In this situation, the latency for each player should be optimized as they move around the network. The MEC deployment is highly distributed, whereby computation tasks can be partially or fully offloaded to MEC applications. The computation offloading bypasses the conventional limitations of UE resources and high-latency caused by core computation server delivery. Additionally, the MEC system can also provide UE mobility management; this can occur regardless of whether the interaction is between the internal mobile network environments, or the external cloud environments (GSMEC, 2018, MECISG, 2015).

The survey in Westphal (2017) presented the ICN based network architecture for the support of multicast AR and VR applications. Ren et al. (2018) proposed an MEC-based collaborative web AR solution and the effectiveness of the proposed solution was verified. Ejder et al. in Bastug et al. (2017) identified the importance of VR technology by considering different computation paradigms. The limitations of the current VR application network were provided by examining VR cases under various storage, computation and network conditions. Chakareski (2017) formulated an optimization framework to maximize the resource usage for 5G AR and VR wireless clients in a future cooperative multi-cellular network, allowing small base stations to cooperatively select computation and caching strategies. Pandi et al. (2017) provided a demonstration of migration techniques based on the application-level and described an agile migration strategy for gaming applications among multiple edge servers. Braun et al. in Braun et al. (2017), proposed an application-level migration protocol with a gaming application, where the users are migrated between hosts during game play. In Drolia et al. (2017), a system called Cachier was proposed that used the caching model along with novel optimizations for latency minimization by balancing load between the edge and the cloud.


Download : Download high-res image (676KB)
Download : Download full-size image
Fig. 10. MEC use cases and applications (GSMEC, 2018).

5.2. Network operator and third party services
Network operators and third party service providers that utilize MEC will be confronted by fundamental changes to how they provide applications to end users. Challenges have been identified related to the collection, analysis, and management of data and end-user device information. The benefits of MEC may extend to more timely changes to operating conditions, maintenance and knowledge of network conditions affecting end-user devices. This is expected to be particularly important for connected vehicles, IoT, active device location tracking, and security and safety related systems (GSMEC, 2018).

Connected vehicle technologies are anticipated to utilize MEC, initially through systems designed to support connected vehicle focused demands. Roadside units (RSU) will monitor, collect, and analyze operational data that can be used to enhance the safety, efficiency, and transportation network operation. RSU can provide road hazard warnings and propose changes to vehicle behavior to reduce traffic congestion.

Due to the limited computing resources at the edge and user mobility, the works in Hu and Li, 2019, Sharma and Wang, 2017 and Li and Shou (2019) presented a series of algorithms and architectures for the optimization of security, computing and storage resources. The works in  Frascolla et al., 2017, Li et al., 2017, Boban et al., 2016, Grewe et al., 2017, Xie et al., 2019, Abdukodir et al., 2019 and Kanwal et al. (2019) revealed the role of MEC for V2X applications and realization, where the framework design, the architecture, the MEC server and base station deployment, and data migration were considered.

5.3. Network performance and QoE improvements
Network performance and QoE improvements are an ongoing aspect of the evolving technologies used in the network, and the introduction of MEC enables applications and services that can effectively analyze and coordinate real-time traffic from the edge locations. In practice, MEC applications are likely to become a key provider of status information to SDN-based network services that manage traffic routing and shaping (GSMEC, 2018, MECISG, 2015).

The proliferation of complex multimedia applications targeting mobile devices has increased demand for caching at the edge. There remains strong growth in content delivery networks and edge solutions that satisfy content demands whilst improving QoE. MEC offers an improved response to changing network conditions and management of caching and content applications and services. MEC provides a solution for localized management and optimization of radio backhaul links. Real-time traffic monitoring and management of RAN radio backhaul offer the opportunity to reduce network congestion. Timely decision making closer to the RAN is an area where MEC applications can become an important component of network management systems (GSMEC, 2018).

The optimization of content caching, radio and backhaul in MEC was discussed in Zhang et al., 2018, Jiang et al., 2019b, Hou et al., 2018, Zhang et al., 2017a and Pham et al. (2019). In particular, Zhang et al. (2018) proposed a new cooperative edge caching architecture for 5G networks to improve edge caching resource utilization and minimize the latency. Jiang et al. (2019b) proposed a novel content caching policy based on a machine learning approach where the user preferences are predicted to identify video file format and storage location. Hou et al. (2018) proposed a proactive caching mechanism to improve QoE, the computation and storage capacity at MEC nodes. In Zhang et al. (2017a) and Pham et al. (2019), the authors proposed a series of algorithms for radio and backhaul optimization by considering computation offloading strategies.

6. Future research challenges
The development of MEC implementations is timely, as the network and end-user demands continue to stress core networks and cloud solutions. MEC improves reliability by devolving computation, storage and communication functions to the edge whilst satisfying the need for applications and service offerings closer to end users. However, the technology itself is not mature and faces a number of challenges that must be overcome before its potential is fully realized. This section discusses selected MEC challenges and the possible directions for further research.

6.1. Harmonized architecture
The ETSI ISG MEC and 3GPP have been working on MEC architectures from their different perspectives. 3GPP SA6 proposed a new architecture where a new layer was specified to perform communication between application clients and edge applications. 3GPP SA2 introduced an architecture focusing on mobile core networks and provided traffic steering rules for the server placement in the edge. 3GPP SA5 has focused on management issues regarding 3GPP network support and has commenced work on the LCM of application servers and energy management at the edge. From the application perspective, 5GAA is responsible for defining the policies for V2X applications over MEC.

The GSM Association (GSMA) is working on a unified architecture for end-to-end services. In phase 1, GSMA is considering the MEC architecture federation to provide multiple access to a global edge cloud via the standard APIs. ETSI ISG MEC is coordinating with GSMA to define a series of architecture federation requirements (Nurit Sprecher et al., 2020). Recently, ETSI provided an approach to integrate MEC with the 3GPP 5G architecture (ETSI Group, 2019i). Defining a standardized and harmonized architecture for end-to-end services is underway based on the efforts of the standards bodies.

6.2. Hybridization of VMs and containers
In order to improve the efficiency of MEC infrastructure, geographically distributed MEC data centers can communicate with each other and with the core cloud data centers. MEC applications run in a VM or container that can be replicated at multiple sites; thus, traffic can be transferred among the sites where corresponding VMs reside. The resource efficiency and network latency of MEC nodes can be optimized by VM and container placement (Wang et al., 2021). In this context, VM can improve QoE and reduce CAPEX and OPEX. Even though VM can benefit future distributed technologies and applications, it still makes the control signal exchange more complex and thus reduces efficiency and increase latency. Optimization of the control signal remains a challenge.

After developing a set of specifications for operating MEC in NFV, a series of challenges were identified. Although utilizing virtualization technologies offers many benefits to MEC, new challenges to MEC in NFV have emerged based on its characteristics. In Tao et al. (2019) the characteristics and challenges were summarized. The character of distributed mobile devices increases the service migration time between VMs and containers at MEC hosts; this in turn presents a challenge for low-latency MEC applications. Due to the UE mobility, each of the edge nodes covers a limited service area, so VMs and containers need to migrate applications or state regularly to adjacent edge hosts. A wide variety of devices, e.g., vehicles, drones, and mobile phones can result in high demand for NFV provisioning and scheduling.

Unlike cloud servers, edge servers have limited hardware resources, reliability, and communications capability. Under these conditions, fault management with a limited number of VMs and containers remains a challenge. Based on the these issues, the management and combination of VMs and containers used by an end user application in an MEC host remains a challenge. Although the containerized virtualization technology is highly recommended for the MEC deployment due to its lightweight features, VMs also plays a crucial role in NFV for the communication service providers. Therefore, more research is needed to consider the advantages of VMs and the OpenStack cloud operating system and containers orchestrated with the Kubernetes orchestration tool.

6.3. Highly complementary technologies
Performance improvement, energy efficiency, resource allocation and cost are important areas of MEC related research. The distribution of MEC servers, resource allocation, and the end-to-end service requirements can become complex undertakings, especially as the number of MEC nodes deployed at the edge increase. This paper has highlighted how service and resource distribution and enhance network performance can benefit from highly complementary technologies being incorporated into the architecture, e.g., NFV, SDN, network slicing, SFC, ICN, C-RAN and F-RAN. NFV provides virtualized resources for the flexible deployment of new services and to enable network expansion. SDN is responsible for resource control to facilitate network optimization, interoperability and scalability. SFC and network slicing enable the tailoring of instances to meet the needs of end-to-end services. ICN in MEC provides fully information-centric management and network control to enable MEC deployment reliability. Additionally, C-RAN and F-RAN were introduced in MEC to facilitate MEC for caching, task offloading and artificial intelligence. Research into the highly complementary technologies that have become MEC enablers is ongoing.

6.4. Mobility management
Mobility and continuity are an essential part of the MEC environment. They influence a set of service strategies including computation offloading, resource allocation, and service orchestration. In Section 3, the MEC RNIS service was described. ETSI defined RNIS as an MEC service that utilizes radio network information to enhance service continuity and mobility. Research is focusing on the extension of the RNIS API to support handover procedures (Kireva et al., 2018, Pencheva, 2018). In terms of multi-connectivity applications, with multiple paths to different MEC platforms, mobility and continuity management becomes more complex. Hence, research is being conducted into how RNIS might support user behavioral prognostics (Pencheva et al., 2019).

The introduction of SDN-based enhanced network architectures has addressed the long-distance movement of UE between edge hosts across different mobile network operators (Shah et al., 2020). However, end-user mobility in a RAN with MEC hosts is not solely about changes to radio network information and data sharing. Computation offloading and storage resources are needed to support efficient mobility and continuity management. Centralized Mobility Management (CMM) was adopted for the mobility solutions in LTE networks. MEC mobility management solutions are now focusing on 5G networks. However, with the increased number of mobile users, more frequent handovers occur, and this increases the amount of signaling messages being exchanged. Distributed Mobility Management (DMM) was developed to handle the signaling problem in dense networks. In order to avoid signaling overhead and handover delay, various approaches have been proposed to combine SDN and slicing in MEC deployments to enable efficient communications (Akkari and Dimitriou, 2020). Mobility management aims to improve end-user QoE with seamless handovers. The solutions proposed for mobility management are based on the core network, access network, core cloud and MEC paradigms. A comprehensive optimal method for mobility management remains an open challenge.

6.5. Customized design for the use cases
The number of applications and services being developed for MEC deployment is growing, particularly as MEC technologies evolve and more capability is added to MEC servers. The applications and services apply to a broad range of use cases related to MEC and UE operations. Different applications will have different requirements for their optimal performance, e.g., AR, VR and e-gaming require speed at the expense of reliability; e-health and vehicle apps may need reliability and stability ahead of connection speed. In order to support a variety of applications and services, the research range of joint optimization should be extended, both vertically and horizontally. This paper has discussed various MEC enabled use cases in terms of computation, caching and communications. Modeling a framework whereby task assignments are optimized according to their associated tailored services, is a future challenge.

7. Conclusion
MEC is an evolving technology that has generated considerable interest from the telecommunication network operators and over-the-top providers. It brings computation and storage resources to the network edge to support computation-intensive and low-latency applications. MEC should enhance network performance, support new and innovative applications and services, and improve end-user QoE. This paper provides a comprehensive review of MEC technologies, current research and remaining challenges. The MEC framework is described, and the research and standardization efforts by several international bodies are discussed. How MEC might be used to enhance the operation of applications and services, and the underlying networks are described. The effort to introduce MEC affords an opportunity for new and innovative applications and services, and several are described. The MEC complementary technologies, including NFV, SDN, network slicing, SFC, ICN, C-RAN and F-RAN are described, and future research is introduced. MEC applications and use cases are discussed.

MEC is changing the network design paradigm from centralized computing and storage to a more distributed approach. This is a major step forward that offers new and exciting outcomes that are being identified and realized. Research into network and application optimization utilizing RNIS and other factors is ongoing. The effort to acquire dynamic network information is needed to optimize network and application performance, which is a major focus of current research. The development of MEC is ongoing, and a number of open source projects have commenced that are developing lightweight container virtualized platforms. Management, control, orchestration, and networking are current areas of interest for MEC developers. The introduction of MEC into the network has increased network management complexity, and there is a need for a monitoring capability that provides the information needed to optimize MEC operation. Research into how MEC will affect network operation is ongoing.

