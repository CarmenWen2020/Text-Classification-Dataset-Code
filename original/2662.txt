The Cox proportional hazards model is a popular semi-parametric model for survival analysis. In this paper, we aim at developing a federated algorithm for the Cox proportional hazards model over vertically partitioned data (i.e., data from the same patient are stored at different institutions). We propose a novel algorithm, namely VERTICOX, to obtain the global model parameters in a distributed fashion based on the Alternating Direction Method of Multipliers (ADMM) framework. The proposed model computes intermediary statistics and exchanges them to calculate the global model without collecting individual patient-level data. We demonstrate that our algorithm achieves equivalent accuracy for the estimation of model parameters and statistics to that of its centralized realization. The proposed algorithm converges linearly under the ADMM framework. Its computational complexity and communication costs are polynomially and linearly associated with the number of subjects, respectively. Experimental results show that VERTICOX can achieve accurate model parameter estimation to support federated survival analysis over vertically distributed data by saving bandwidth and avoiding exchange of information about individual patients. The source code for VERTICOX is available at: https://github.com/daiwenrui/VERTICOX .
SECTION 1Introduction
Survival analysis is widely used for time-to-event healthcare data and can facilitate the comparative study of treatment effectiveness and outcomes of interest (i.e., mortality, disease, recurrence). Lundin et al. [1] evaluated prognostic factors in oncology to compare and analyze individualized survival estimates for patients with breast cancer. Wiksten et al. [2] adopted multivariate survival analysis to assess panels of tumor markers to improve outcome prediction in gastric cancer. Hagar et al. [3] leveraged Bayesian multi-resolution hazard models to develop survival analysis for chronic kidney disease based on electronic health record (EHR) data. Gamel et al. [4] investigated the mortality of breast cancer patients in the Surveillance, Epidemiology and End Results (SEER) program datasets. In survival analysis, Cox proportional hazards [5] is one of the most popular models. It utilizes the hazard function to assess the significance of covariates to the survival times of individuals or subjects. It can exploit covariate information to determine the importance of predictors [6], establish flexible and robust regression models considering time-varying effects [7], [8], and examine the variation of treatment effects across multiple institutions [9], among other applications.

This paper focuses on building a survival analysis model using distributed data across multiple institutions, while avoiding the transmission of patient-level data. Prediction and analysis of diseases and effectiveness of treatments can be enhanced by making use of massive healthcare data collected by numerous organizations such as hospitals, research institutions and government agencies. For example, the patient-centered Scalable National Network for Effective Research (pSCANNER) [10] integrates data from over 31 million patients to facilitate comparative effectiveness researches and prospective analyses, without sending those data out of their institutions.

For medical data, federated machine learning have multiple benefits including privacy protection, communication reduction, and scalability improvement, when appropriate distributed architectural design is deployed. Currently, inter-institutional exchange of patient-level data is often restricted due to institutional policies, legislation or privacy concerns. For example, in the United States, patient data shall be hosted by covered entities in HIPAA-compliant environments [11], [12] without disclosure to unauthorized third parties. The NIH Genomic Data Sharing (GDS) policy [13] requires participants’ consent to exchange genomic data. Effective May 2018, the General Data Protection Regulation (GDPR) [14] of the European Union (EU) requires institutions collecting or processing personal data of EU citizens to protect their privacy. Analysis and prediction methods that do not explicitly exchange patient-level data must enable distributed data analyses in many practical applications. Federated data analysis methods allow researchers to build global statistical models without sharing patient-level data with other parties. In survival analysis, distributed Cox regression models have only been studied for horizontally partitioned data, where multiple institutions hold various records with the same type of covariates.

In this paper, we develop a distributed method VERTICOX for survival analysis for vertically partitioned data based on the ADMM framework [24]. Our contributions are summarized below.

VERTICOX is the first work to realize privacy-preserving distributed Cox proportional hazards model over vertically partitioned data. It leverages ADMM for exact solution rather than generalizes the Newton-Raphson method.

VERTICOX develops an ADMM-based two-loop algorithm to achieve accurate model parameter estimation with a guarantee of convergence.

A client-server architecture is established for iterative optimization for model parameter estimation. In the proposed framework, each institution only transmits aggregated intermediary results to the server in each iteration while the individual patient data are kept private within their host institutions. Distributed model parameter estimation for the Cox proportional hazards model is developed using the Breslow's partial likelihood function based on the aggregated intermediary results. Thus, model parameter estimation and subsequent survival estimation can be conducted in a privacy-protecting fashion. VERTICOX is demonstrated to converge at a linear rate under the ADMM framework. The proposed method is evaluated on real-world applications over the Internet. Experimental results demonstrate that the proposed method can achieve equivalent accuracy in the estimation of model parameters and statistics when compared to its centralized counterpart.

The remainder of this paper is organized as follows. Section 2 reviews the related works on survival analysis and ADMM. Section 3 states the distributed optimization problem over vertically distributed data. In Section 4, we describe the estimation of model parameters and statistics for the Cox proportional hazards model based on the ADMM framework. Experimental evaluations on the Surveillance Epidemiology and End Results (SEER) [31] and the UMASS Aids Research Unit (UARU) IMPACT study [32] data set are provided in Section 5. Section 6 discusses some limitations of our proposed method and illustrates potential extensions. Finally, Section 7 presents the conclusion.

SECTION 2Related Works
Yu et al. [15] proposed a privacy-preserving Cox regression model based on affine projections for survival analysis over horizontally partitioned data. Patient data were linearly projected into a lower dimensional space optimized via linear programming. Given specific problems, sparse projection matrices were constructed for privacy-preserving mapping to maintain the properties of data with feature selection. This model was shown to achieve nearly optimal predictive performance. O’Keefe et al. [16] presented privacy-protecting approaches for survival analysis from a remote database to mitigate the risk of disclosing patient-level data, but did not consider the distributed model learning. Inspired by the insight of sharing models without sharing data [17], Lu et al. [18] investigated the feasibility of employing federated survival analysis in a distributed Cox model. A Web service, WebDISCO, was developed for the Cox model learning in horizontal partitions in a distributed manner without sharing patient-level data. Global model parameters were estimated from intermediary statistics, e.g., covariate matrices, derived locally at each institution. The distributed Cox model achieved equivalent precision to that of its centralized realization.

Unlike the horizontal data partition scenario, federated data analysis cannot be easily generalized to vertically partitioned data, where multiple institutions own a portion of covariates of the same cohort of patients. Model parameter estimation and statistical tests cannot be achieved with straightforward decomposition, as in federated data analysis for horizontal partition. Secure multiparty computation (SMC) protocols have been adopted as alternative solutions to compute and merge covariance matrices for data held by different institutions. Karr et al. [19] proposed a secure protocol to compute the covariance matrix for data vertically partitioned across various institutions. Based on a conjunction of attribute values, Vaidya et al. [20] developed a Naïve Bayes classifier by revealing the class value of an individual instance rather than its probability distribution. Yu et al. [21] proposed the vertically partitioned privacy-preserving SVM, where each institution built a local model of its own data and merged the model with other parties through a secure summation on a per-node basis. Que et al. [22] developed a collaborative framework for vertically partitioned data, which performed modeling operations like task creation and model aggregation on the server. However, SMC protocols lead to prohibitive computational and communication costs in practice. Motivated by the fact that the gram matrix for a logistic regression model can be vertically split over multiple institutions, Li et al. [23] developed a novel technique VERTIGO for federated analysis of vertically partitioned data, where dual optimization was formulated to build a binary logistic regression model without exchanging patient-level data. The dual optimization was iteratively solved based on the aggregated kernel matrix of local statistics from all the institutions. VERTIGO was demonstrated to obtain equivalent model parameters to those of its centralized counterpart. However, it is not feasible to obtain analytic solutions based on the gram matrix due to the log-sum-exp formulation in the Cox proportional hazards model.

Recently, the alternating direction method of multipliers (ADMM) [24] was developed to improve augmented Lagrangian methods with partial updates for the dual variables. This idea is to decompose a large-scale optimization problem into smaller local optimization problems that can be solved within the secure enclaves of individual data owners. In summary, the algorithm solves the minimization problem of the summation of two convex functions f(x) and g(z) under the equality constraint of Ax+Bz=c with parameters A, B and c. Algorithms and convergence analyses based on ADMM have been widely used for predictive models over horizontally distributed data. Mateos et al. [25] reformulated the LASSO problem into a separable form for distributed estimation of model parameters with ADMM. Iterative estimation for the recursive least-squares algorithm can also be obtained in a distributed fashion using the alternating-minimization algorithm [26]. Leveraging ADMM, Forero et al. [27] developed a distributed alternative for the linear SVM training problem by considering a set of constrained convex sub-problems. Brisimi et al. [46] presented a cluster primal dual splitting algorithm for ℓ1-constrained sparse SVM classifier over horizontally distributed EHRs. Schizas and Aduroja [28] developed a distributed principal component analysis (PCA) framework using the ADMM framework for dimensionality reduction. Analysis on rate of convergence has been made on the iterative algorithms for the ADMM formulations with linear constraints [29], [30]. Splitting x and z among various institutions, ADMM can also be formulated for distributed analysis with a separable regularizer over vertically partitioned data [24]. However, a distributed algorithm with convergence analysis has not yet been developed for the Cox proportional hazards model under the ADMM framework.

SECTION 3Problem Statement
This paper proposes a Cox proportional hazards model for vertically partitioned data using ADMM. Vertically partitioned data would be considered for the scenarios when multiple institutions hold different portions of patient data. For example, Fig. 1 illustrates an example where several parties including a genome sequencing center, a hospital and an insurance company own a portion of patient data. Another prevailing example would be that patients have multiple visits to different specialty hospitals and therefore leave part of their medical records in each hospital they visit. Similarly to previous works on vertically partitioned data [23], we assume that there is a unique identifier for each patient (e.g., study ID) that is shared across institutions while the other patient data are kept private within each institution.


Fig. 1.
Illustration of vertically distributed survival data with T tied times. N records with M covariates are distributed across K institutions, where the kth institution owns Mk covariates. Here, censored observation and event time are known to each institute.

Show All

Given observed time (censoring or event time) t, the hazard function λ(t|x) for the Cox model with regard to covariates x∈RM is formulated as
λ(t|x)=λ0(t)exp(βTx),(1)
View SourceRight-click on figure for MathML and additional features.where β∈RM is the model parameter and λ0(t) is the baseline hazard function representing the survival rate of a patient with covariate values coded as zero. Thus, λ(t|x) provides the hazard for the patient with covariate x at observed time t. Since the hazard ratio between two patients is supposed to be constant over time t, it is not necessary to explicitly specify λ0(t) in model parameter estimation. To estimate β, partial likelihood methods are widely adopted under the assumption of independent events. In this paper, we consider the Breslow's partial likelihood function [33] for tied event times, where covariates for all patients experiencing the event at given time t are accumulated and raised to a power equal to the number of events tied at t
l(β)=∏t=1Texp∑n∈DtβTxn[∑j∈Rtexp(βTxj)]dt,(2)
View Sourcewhere T is the number of distinct event times. At time t, Dt is the index set for samples with observed events, dt is the number of events and Rt is the index set of samples at risk for the event.

In this paper, we consider that the M covariates are distributed across K institutions, where the training set for model parameter estimation is generated by collecting N samples {(xn1,xn2,…,xnK),n=1,…,N} from the K institutions. As shown in Fig. 1, x1k,…,xnk are the vectors of realization values of the Mk-tuple covariates from the kth institution with ∑Kk=1Mk=M. Thus, we can reformulate the partial log-likelihood function
L(β)=∑t=1Tlog∏n∈Dtexp(∑Kk=1βTkxnk)[∑j∈Rtexp(∑Kk=1βTkxjk)]dt=∑t=1T∑n∈Dt∑k=1KβTkxnk−∑t=1T[dtlog∑j∈Rtexp(∑k=1KβTkxjk)].(3)
View SourceRight-click on figure for MathML and additional features.Here, βk∈RMk is the model parameter for the covariates from the kth institution. According to Eq. (3), we study the parameter estimation for the Cox proportional hazards model based on the covariates vertically distributed across multiple institutions. For clarity, we introduce Table 1 to summarize the variables and parameters used in the distributed optimization for survival analysis.

TABLE 1 Summary of Variables and Parameters in Distributed Optimization for Survival Analysis

SECTION 4Distributed Optimization for Survival Analysis
4.1 Formulation
To maximize the partial log-likelihood function over the covariates xn1,…,xnK, n=1,…,N distributed across the K institutions, we solve its surrogate constrained minimization problem
minzjk,βk∑t=1T[dtlog∑j∈Rtexp(∑k=1Kzjk)]−∑t=1T∑n∈Dt∑k=1KβTkxnks.t. βTkxnk−znk=0, ∀n=1,…,N,∀k=1,…,K,(4)
View SourceRight-click on figure for MathML and additional features.where znk is introduced as an auxiliary variable corresponding to the aggregated intermediary results βTkxnk from the kth institution. For clarity, we denote z∈RN×K the matrix of auxiliary variables with its row vector zn=(zn1,…,znK) corresponding to xn1,…,xnK
L(β,z,γ)=∑t=1T[dtlog∑j∈Rtexp(∑k=1Kzjk)]−∑t=1T∑n∈Dt∑k=1KβTkxnk+∑n=1N∑k=1K[γnk(βTkxnk−znk)+ρ2(βTkxnk−znk)2].(5)
View Source

According to the ADMM framework, we formulate the augmented Lagrangian function L(β,z,γ) with regard to the parameters β, auxiliary variables z and dual variables γ. In Eq. (5), γ∈RN×K is the matrix whose element at the nth row and kth column is γnk and the penalty parameter ρ is introduced to balance the prime and dual residual. Therefore, model parameter β=(β1,…,βK) for the K institutions can be estimated by minimizing the augmented Lagrangian function L(β,γ,z)
{β∗,z∗,γ∗}=argminβ,z,γL(β,z,γ).(6)
View SourceRight-click on figure for MathML and additional features.The augmented Lagrangian function L(β,z,γ) can be recursively minimized to obtain β, z and γ in a distributed manner.

4.2 Distributed Optimization
In recursive optimization, the minimization problem is decomposed into three sub-problems for distributed model parameter estimation over the K institutions. In this paper, federated data analysis based on a client-server architecture is adopted for the distributed optimization, where the server collects non-sensitive information from all the institutions to update their local model parameters. At the pth iteration, model parameters β(p)k and dual variables γ(p)nk, n=1,…,N can be separately solved and updated for the kth institution based on its local covariates xnk, n=1,…,N. Consequently, the server updates each auxiliary variable z(p)nk by collecting γ(p)nk and the aggregated results σ(p)nk=[β(p)k]Txnk and sends it back to the kth institution for subsequent update at the (p+1)th iteration. Hence, we elaborate the iterative update of model parameters β, auxiliary variables z and dual variables γ for distributed optimization, separatelly.

4.2.1 Update of Model Parameters
According to Eq. (5), βk can be separately solved for the kth institution, as L(β,z,γ) is decomposable over β1,…,βK. For the kth institution, the augmented Lagrangian is simplified by solely considering terms w.r.t. βk
Lβ(βk)=∑n=1N[ρ2(βTkxnk)2+(γnk−ρznk)βTkxnk] −∑t=1T∑n∈DtβTkxnk.(7)
View SourceThus, β(p)k can be solved at the pth iteration by forcing the gradient ∇Lβ of Lβ(βk) to zero
β(p)k=[ρ∑n=1NxnkxTnk]−1⋅[∑n=1N(ρz(p−1)nk−γ(p−1)nk)xnk+∑t=1T∑n∈Dtxnk].(8)
View SourceRight-click on figure for MathML and additional features.Eq. (8) shows that all the K institutions can compute β1,…,βK in parallel. Consequently, σnk=βTkxnk, k=1,…,K are collected and sent to the server for updating the auxiliary variables z.

4.2.2 Update of Auxiliary Variables
When the server receives σnk and γnk from the K institutions, we can analogically formulate the objective function for updating the auxiliary variables z by fixing β and γ in Eq. (5)
Lz(z)=∑t=1T[dtlog∑j∈Rtexp(∑k=1Kzjk)]+∑n=1N∑k=1K[ρ2z2nk−(ρσnk+γnk)znk].(9)
View SourceRight-click on figure for MathML and additional features.Due to the log-sum-exp term, Eq. (9) cannot be directly solved. Therefore, we transform the unconstrained optimization problem in Eq. (9) by reformulating the log-sum-exp function under the constraint of z¯n=∑Kk=1znk/K
min∑t=1T[dtlog∑j∈Rtexp(Kz¯j)]+∑n=1N∑k=1K[ρ2z2nk−(ρσnk+γnk)znk]s.t. z¯n=1K∑k=1Kznk, n=1,…,N.(10)
View Source

Fixing z¯j, the constrained problem in Eq. (10) is a quadratic programming problem over znk, k=1,…,K. At the pth iteration, z(p)nk can be represented based on z¯(p)n
z(p)nk=z¯(p)n+σ(p)nk+γ(p−1)nkρ−1K∑k=1K[σ(p)nk+γ(p−1)nkρ].(11)
View Source

For simplicity, let us denote σ¯n=∑Kk=1σnk/K and γ¯n=∑Kk=1γnk/K the means of σnk and γnk over all the K institutions. Substituting znk with z¯n in Eq. (10), the equivalent unconstrained optimization problem over z¯n is formulated for the pth iteration
minz¯Lz¯(z¯)=∑t=1T[dtlog∑j∈Rtexp(Kz¯j)]+Kρ∑n=1N[z¯2n2−(σ¯(p)n+γ¯(p−1)nρ)z¯n].(12)
View SourceHere, z¯=(z¯1,…,z¯N) is the vector of z¯n corresponding to the N patients. Since the minimization problem (12) is not separable for z¯, the Newton-Raphson method is leveraged to iteratively derive its solution. Consequently, we consider the first and second derivatives of Lz¯(z¯). Its first-order partial derivatives w.r.t. z¯u, u=1,…,N, are obtained by
∂Lz¯∂z¯u=∑t=1tu[dtKexp(Kz¯u)∑j∈Rtexp(Kz¯j)]+Kρ[z¯u−σ¯u−γ¯(p−1)uρ],(13)
View SourceRight-click on figure for MathML and additional features.where tu is the distinct event time corresponding to z¯u. The uth diagonal element in second derivatives d2Lz¯/dz¯2 is its second-order partial derivatives w.r.t. z¯u
∂2Lz¯∂z¯2u=∑t=1tudt⎛⎝⎜⎜K2exp(Kz¯u)∑j∈Rtexp(Kz¯j)−K2[exp(Kz¯u)]2[∑j∈Rtexp(Kz¯j)]2⎞⎠⎟⎟+Kρ.(14)
View SourceRight-click on figure for MathML and additional features.The off-diagonal elements with 1≤u≠v≤N are determined by
∂2Lz¯∂z¯u∂z¯v=−∑t=1min(tu,tv)⎡⎣⎢⎢dtK2exp(Kz¯u)exp(Kz¯v)[∑j∈Rtexp(Kz¯j)]2⎤⎦⎥⎥.(15)
View SourceRight-click on figure for MathML and additional features.Thus, z¯(p) is iteratively solved with the Newton-Raphson method for the pth iteration
z¯(p,q)=z¯(p,q−1)−[d2Lz¯(z¯)dz¯2∣z¯(p,q−1)]−1⋅(dLz¯(z¯)dz¯∣z¯(p,q−1)).(16)
View SourceRight-click on figure for MathML and additional features.To distinguish from the recursive optimization based on ADMM, we use q to indicate the index of iteration for the Newton-Raphson method. When z¯(p)n is obtained, z(p)nk can be solved using Eq. (9). Subsequently, the server sends back z(p)nk, n=1,…,N to the kth institution.

4.2.3 Update of Dual Variables
Recalling Eq. (11), at the pth iteration, γ(p)nk can be updated by fixing znk=z(p)nk and z¯n=z¯(p)n
γ(p)nk=γ¯(p−1)n+ρ(σ¯(p)n−z¯(p)n+z(p)nk−σ(p)n).(17)
View SourceRight-click on figure for MathML and additional features.According to the constraint that βTkxnk−znk=0, Eq. (17) can be simplified by
γ(p)nk=γ¯(p−1)n+ρ(σ¯(p)n−z¯(p)n).(18)
View SourceRight-click on figure for MathML and additional features.Eq. (18) implies that all the K institutions could share the same dual variables γ¯=(γ¯1,…,γ¯N), where γ¯(p)n is updated by γ¯(p−1)n+ρ(σ¯(p)n−z¯(p)n) at the pth iteration.

4.3 VERTICOX ADMM Implementation
According to the augmented Lagrangian function w.r.t. β, z and γ, we develop the distributed Cox proportional hazards model VERTICOX for vertically partitioned data under the ADMM framework. Fig. 2 illustrates the privacy-protecting implementation of VERTICOX, where a client-server architecture is established for authorized institutions to make iterative optimization of model parameters based on vertically distributed covariates. For security sake, all institutions are required to get authorization from the server for connection and computation. To separately handle authorization and computation, both the server and institutions hold two corresponding processes.


Fig. 2.
Illustrative framework for the privacy-protecting implementation of the distributed Cox proportional hazards model VERTICOX. When authorized by the server, iterative optimization of model parameters is made based on the client-server architecture. At each iteration, the kth institution receives auxiliary variables γ¯n, n=1,…,N and dual variables znk, to update its model parameter βk and sends the aggregated results σnk=βTkxnk, n=1,…,N to the server. The solid and dashed arrows indicate the transmission of intermediary results and authorization for links from institutions, respectively.

Show All

At each iteration, the kth institution receives auxiliary variables znk and dual variables γ¯n, n=1,…,N from the server to locally update its model parameter βk. Subsequently, the aggregated intermediary results σnk=βTkxnk, n=1,…,N are sent to the server. Under the proposed client-server architecture, there is no communication among the K institutions, so sensitive patient-level data are not directly exchanged among the institutions.

Algorithm 1 elaborates the privacy-protecting implementation for the ADMM-based federated survival analysis. Its model parameters can be computed locally for each institution based on the received auxiliary variables znk and dual variables γ¯n using Eq. (8). When βk is obtained, the institution only needs to exchange the aggregated results σnk=βTkxnk with the server. The server updates znk and γ¯n with the aggregated results σnk, k=1,…,K collected from the K institutions. To solve the optimization problem related with the log-sum-exp function, the Newton-Raphson method is leveraged to derive the averaged auxiliary variables z¯n and correspondingly updates znk. This process can be conducted iteratively to obtain the estimation to the optimization problem (4) by forcing ∥z¯(p)−z¯(p−1)∥F→0 and ∥z¯(p)−σ¯(p)∥F→0.

Algorithm 1. Distributed Cox Model for Vertically Partitioned Data
Initialization: p=1, β(0)k=0, z¯(0)n=0, and γ(0)nk=0

while ∥z¯(p)−z¯(p−1)∥F>ε and ∥z¯(p)−σ¯(p)∥F>ε do

for institution k=1,…,K do

Institution k solves β(p)k using Eq. (8)

Institution k sends γ(p)nk and the aggregated result σ(p)nk to the server

end for

Server computes σ¯(p)n=∑Kk=1σ(p)nk/K and γ¯(p)n=∑Kk=1γ(p)nk/K

Server calculates z¯(p) by solving Eq. (12) with Newton-Raphson method

Initialization: z¯(p,0)=z¯(p−1), q=1

while ∥z¯(p,q)−z¯(p,q−1)∥F>ϵ do

Server calculates dLz¯(z¯)dz¯∣z¯(p,q−1) using Eq. (13),

Server calculates d2Lz¯(z¯)dz¯2∣z¯(p,q−1) using Eqs. (14) and (15)

Server updates z¯(p,q) using Eq. (16)

end while

Server updates z(p)nk using Eq. (11)

Server sends z(p)nk, σ¯(p)n and γ¯(p)n to corresponding institution k=1,…,K

for institution k=1,…,K do

Institution k updates γ(p)nk using Eq. (18)

end for

end while

In our implementation, no individual patient data are shared across institutions and only the aggregated results σnk=βTkxnk are communicated with the server. Since neither xnk nor βk are known to the server, they cannot be inferred from aggregated results σnk, unless the covariate distribution is extreme, e.g., the institution only holds one covariate. In future research, we plan to improve our method by considering the use of secure protocols in the communication steps and developing advanced privacy preserving methods for sharing the model and parameters computed in each step of our protocol. A detailed description about these potential extensions is reported in Section 6.2.

4.4 Survival Analysis
When the estimated model parameters β^k, k=1,…,K are obtained, survival analysis can also be made based on the covariates distributed across the K institutions in a privacy-protecting fashion. Considering Breslow's partial likelihood function, the baseline hazard function λ0(t) at the distinct event time t is defined by
λ0(t)=1∑j∈Rtexp(∑Kk=1β^Tkxjk).(19)
View SourceRight-click on figure for MathML and additional features.The cumulative survival function Λ(t|Ω) of the subpopulation Ω is obtained based on the averaged covariates x¯=(x¯1,x¯2,…,x¯K), where x¯k=∑n~∈Ωx~n~k/|Ω| is computed based on the covariates x~n~k∈Ω from the testing data owned by the kth institution
Λ(t|Ω)=[exp(−∑ti≤tdiλ0(ti))]exp(∑Kk=1β^Tkx¯k)(20)
View Source
AUC(t)=E(x~n~1,x~n~2)[(1−Λ(t|x~n~11,…,x~n~1K))Λ(t|x~n~21,…,x~n~2K)I(σn~1>σn~2)]Ex~n~[1−Λ(t|x~n~1,…,x~n~K)]Ex~n[Λ(t|x~n~1,…,x~n~K)].(21)
View Source

Here, ti is the ith tied event time for training data. Eqs. (19) and (20) imply that the cumulative survival function Λ(t|Ω) can be predicted directly based on the covariates distributed across multiple institutions without exchanging patient-level data and local model parameters with the server and other institutions. Algorithm 2 describes the distributed survival analysis for data vertically partitioned across K institutions.

Algorithm 2. Distributed Survival Analysis for Vertically Partitioned Data
Input: β^1,β^2,…,β^K

Output: Λ(t|Ω)

for institution k=1,…,K do

Institution k calculates σ^nk=β^Tkxnk, n=1,…,N

Institution k calculates σ¯k=∑n~∈Ωβ^Tkx~n~k/|Ω|, n~=1,…,N~

Institution k sends σ^nk, n=1,…,N and σ¯k to the server

end for

Server aggregates σn=∑Kk=1σ^nk and σ¯=∑Kk=1σ¯k

for distinct event time t=1,…,T do

Server calculates λ0(t) with risk score ∑j∈Rtexp(σj) using Eq. (19)

Server computes Λ(t|Ω) with λ0(t) and σ¯ using Eq. (20)

end for

The Area Under the ROC Curve (AUC) can also be computed in a distributed manner. Following [34], time-dependent AUCs are obtained based on the survival function Λ(t|x~n~1,…,x~n~K) for test data x~n~k, n~=1,…,N~, k=1,…,K. In Eq. (21), the indicator function I(σn~1>σn~2) is 1 when σn~1>σn~2 and 0 otherwise. Algorithm 3 describes the distributed computation of AUC for the Cox proportional hazards model. Since the survival function can be calculated based on the aggregated intermediary results σnk=β^Tkxnk, it can be decomposed over the K institutions. In Algorithm 3, each institution only exchanges its aggregated intermediary results σnk and σ~n~k for patients in training and testing datasets at time 1,…,T.

4.5 Convergence Analysis
According to Eq. (7), model parameter βk for the kth institution can be locally solved. Thus, we consider the aggregated results in convergence analysis. For clarity, we define f(z¯)=∑Tt=1[dtlog∑j∈Rtexp(Kz¯j)] and g(β)=−∑Tt=1∑n∈Rt∑Kk=1βTkxnk. The original optimization problem can be reformulated based on z¯ and β=(βT1,…,βTK)T
minz¯,βf(z¯)+g(β)s.t. 1KXTβ−z¯=0.(22)
View SourceHere, X=(x1,…,xN)T collects the covariates of N subjects from all the K institutions. In this subsection, we demonstrate that the proposed VERTICOX achieves the optimal solution with a linear rate of convergence.

Algorithm 3. Distributed Computation of Time Dependent AUC Score
for institution k=1,⋯,K do

Institution k calculates and sends σnk=β^Tkxnk,n=1,…,N to the server

Institution k calculates and sends σ~nk=β^Tkx~nk,n~=1,…,N~ to the server

end for

Server aggregates σn=∑Kk=1σnk and σ~n~=∑Kk=1σ~n~k

Server calculates λ0(t),t=1,…,T using Eq. (19)

Server calculates Λ(t|x~n~),n~=1,…,N~ using Eq. (20)

for time t=1,⋯,T do

for patient i=1,…,N~ do

Server calculates Λ¯1(t)=Λ¯1(t)+Λ(t|x~i)

for patient j=1,…,N~ do

if σ~i>σ~j then

Server updates Λ¯2(t)=Λ¯2(t)+(1−Λ(t|x~i))Λ(t|x~j)

end if

end for

end for

Server calculates Λ¯1(t)=Λ¯1(t)/N~

Server calculates Λ¯2(t)=Λ¯2(t)/N~2

Server calculates AUC(t)=Λ¯2(t)/[(1−Λ¯1(t))Λ¯1(t)]

end for

To perform convergence analysis for VERTICOX, we begin with the properties of continuity and convexity for the objective functions f(z¯) and g(β) with regard to z¯ and β in Eq. (22). Since g(β) is linear function with regard to β, we mainly consider f(z¯) in this subsection. Lemma 1 shows that f(z¯) is strongly convex and f(z¯) and its gradient are Lipschitz continuous.

Lemma 1.
Given the closed domain G⊂RN, it holds for f(z¯)=∑Tt=1f(z¯)=∑Tt=1[dtlog∑j∈Rtexp(Kz¯j)] that

f(z¯) is a strongly convex function;

f(z¯) and its gradient ∇f(z¯) are Lipschitz continuous.

Proof.
Please refer to Appendix 1, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org.ezproxy.auckland.ac.nz/10.1109/TKDE.2020.2989301.

Consequently, we perform an analysis of convergence for the iterative algorithm (Algorithm 1) for the Cox proportional hazards model. According to Eq. (22), we reformulate the augmented Lagrangian function L~(β,z¯,γ) for primal variables β, z¯ and dual variable γ
L~(β,z¯,γ)=f(z¯)+g(β)+γT(1KXTβ−z¯)+ρ2∥1KXTβ−z¯∥22.(23)
View SourceRight-click on figure for MathML and additional features.Let us denote β∗,z¯∗,γ∗ the optimum for β,z¯,γ, respectively. In Theorem 1, we demonstrate the convergence of i) primal residual ∥XTβ(p)/K−z¯(p)∥22; ii) dual residual ∥γ(p)−γ∗∥22 and iii) objective function f(z¯(p))+g(β(p)) in VERTICOX with the growth in the number of iterations p.

Theorem 1.
Under the ADMM framework, the proposed VERTICOX for Cox proportional hazards model is linearly convergent to the optimum.

Primal residual ∥XTβ(p)/K−z¯(p)∥22→0, p→∞;

Dual residual ∥γ(p)−γ∗∥22→0, p→∞;

Objective function f(z¯(p))+g(β(p))→f(z¯∗)+g(β∗), p→∞.

Proof.
Please refer to Appendix 2, available in the online supplemental material.

Theorem 1 demonstrates that the primal and dual residuals and the objective function converge with the number of iterations p. This means that the proposed ADMM framework can obtain the optimum for the Cox proportional hazards model over the training data under sufficient number of iterations. Thus, VERTICOX can achieve equivalent accuracy in model parameter estimation in comparison to its centralized realization. Theorem 1 also suggests that the convergence rate of VERTICOX is linearly related to the reciprocal of the penalty parameter ρ. Since a series of Cox proportional hazards models have the similar formulation of f(z¯)+g(β), Theorem 1 can guarantee convergence of ADMM-based optimizations for them, when they satisfy Lemma 1. For example, similar to the proof for Breslow's approach, Efron's approximation [35] with f(z¯)=∑Tt=1∑|Dt|l=1log[∑j∈Rtexp(Kz¯j)−l|Dt|∑j∈Dtexp(Kz¯j)] tends to satisfy Lemma 1 for a guarantee of convergence.

4.6 Complexity Analysis
We analyze the computational complexity for the server and clients, respectively. For clients, the computational complexity comes from the generation and inversion of matrix ∑Nn=1xnkxTnk using Eq. (8). Without loss of generality, we assume that the kth institution owns Mk-tuple covariates x1k,x2k,…,xNk for the N records. The complexities for generating and inverting ∑Nn=1xnkxTnk are O(NM2k) and O(M3k), respectively. Since x1k,x2k,…,xNk are always held by the kth institution, ∑Nn=1xnkxTnk can be stored for each iteration. At the server side, the computational complexity is mainly affected by solving z¯ with the Newton-Raphson method. For each iteration, the Newton-Raphson method with the Hessian matrix requires a complexity of O(N3) for N records. These two facts imply that the computation burden is mainly laid on the server side, as the Cox model typically requires M<N to guarantee a solution.

4.7 Communication Cost
According to Algorithm 1, the server sends znk, γ¯n and σ¯n to the K institutions and collects the aggregated intermediary results σnk at each iteration. Thus, the communication cost between the server and each institution is 4N for each iteration. As a result, the total communication costs are proportional to the number of subjects and to the number of iterations. It is worth mentioning that, contrary to the dual optimization with the Newton-Raphson method [23], VERTICOX does not require additional communication costs, e.g., transmitting N×N gram matrices from the institutions to the server.

SECTION 5Results
In this section, we employed VERTICOX into the Surveillance Epidemiology and End Results (SEER) [31] and the UMASS Aids Research Unit (UARU) IMPACT [32] study datasets to evaluate accuracy and efficiency. VERTICOX was implemented with Julia 0.4 and the source code is available at https://github.com/daiwenrui/VERTICOX. The federated analysis was performed on an Ubuntu 14.04 server with Intel Xeon CPU E5-2687W @3.1 GHz and 256 GB memory.

The SEER dataset was sampled from 55,007 breast cancer patients with first diagnosis from 2001 to 2009. Twenty features were derived from 9 covariates including age at diagnosis (AAD), race, marital status, histology, grade, tumor size (TS), number of nodes examined (NNE), number of positive nodes (NPN) and estrogen receptor (ER) status using dummy coding. The training set for model parameter estimation involved 1,726 records for 97 distinct event times and the test set consists of 1,699 records with 20 features randomly extracted for survival analysis. The UARU study [32] aimed at investigating the effect of various treatment programs on drug abuse reduction and high-risk HIV behavior prevention. To train the model parameters, we employed 295 records with 8 covariates including age, Beck depression score, heroin/cocaine use, IV drug use, number of prior drug treatments, race, length of the treatment, and treatment site. The remaining 279 records were utilized for prediction. For SEER and UARU dataset, non-binary categorical covariates are convert into a vector of binary features using dummy coding. We evaluate VERTICOX over the SEER dataset in a local network and the UARU dataset on Google Cloud.

5.1 Model Parameter Estimation
For evaluation, the estimated model parameters β^ were derived according to Algorithm 1 and compared with their centralized counterpart β using four types of errors: mean square error (MSE) 1M∑Mm=1(β^(m)−β(m))2, summation of the absolute difference (SAD) ∑Mm=1|β^(m)−β(m)|, maximum difference ratio (MDR) ∑Mm=1|β^(m)−β(m)|/β(m) and the maximum absolute difference (MAD) max1≤m≤M|β^(m)−β(m)| between each pair of components β^(m) and β(m), m=1,…,M.

5.1.1 Surveillance Epidemiology and End Results (SEER) Dataset
We evaluated the proposed method on the SEER dataset [31] distributed over 2 and 3 institutions in a local network. In the evaluation, the variables were equally split for the case of 2, 4 and 5 institutions, and segmented into three parts of 7, 7 and 6 covariates for 3 institutions. Table 2 provides the MSE, SAD, MAD and MDR for VERTICOX under various numbers of iterations by setting K to 2, 3, 4 and 5. All these errors were shown to decrease with the number of iterations. Moreover, time costs for computation are provided to illustrate the computational complexity at the server and client sides. We evaluated the time cost for computation by considering the fact that the client needs to wait for the server to exchange intermediary results. The computation time for clients is obtained by averaging over all K institutions. In the iterative optimization, the server consumed most of the computational cost, as complexity is related with the number of records. The proposed method was also tested under real-world network conditions. The client-server architecture was implemented according to the illustrative framework shown in Fig. 2. Table 3 shows the average computation and communication costs for each iteration in the distributed optimization. Furthermore, Table 4 provides the estimation errors obtained under various numbers of patients. We randomly selected 1000, 2000, 3000, 4000 and 5000 patients from the SEER dataset and repeated the random trials for 10 times to obtain the average estimation errors with standard deviations. It shows that VERTICOX can achieve stable and high-precision model parameter estimation when the number of patients varies. For example, MSEs are lower than 1×10−15 for 3000-5000 patients. In Table 9 in the Appendix, available in the online supplemental material, we also provide the estimated model parameters β^ with their standard error (se(β)), z-score and p-value for the SEER dataset under 2,000 iterations. It shows that VERTICOX achieves equivalent results for statistical tests in comparison to the centralized realization. VERTICOX does not change p-value and the confidence intervals (calculated from se(β^) and z-score).

TABLE 2 Estimation Errors and Time Cost for the Model Estimation Over the SEER Dataset Under Various Numbers of Iterations and Penalty Parameter ρ=0.25ρ=0.25

TABLE 3 Detailed Time Cost for Distributed Model Parameter Estimation Over the SEER Dataset Under the Real-World Network Conditions

TABLE 4 Estimation Errors in Terms of Mean Square Error (MSE), Maximum Absolute Difference (MAD), Maximum Difference Ratio (MDR) and Summation of Absolute Difference (SAD), for Model Parameters Over the SEER Dataset Under Various Numbers of Patients and Penalty Parameter ρ=0.25ρ=0.25

5.1.2 UMASS Aids Research Unit (UARU) IMPACT Study Dataset
Similar to the SEER dataset, we split the 10 features into two (5 for each), three (4, 3 and 3) four (3, 3, 2 and 2) and five (2 for each) institutions. For practical purposes, evaluation was done on VMs in Google Cloud, where the server was located in the Central US and institutions in eastern or western coasts. Table 5 provides the MSE, MAD, and SAD for the model parameters obtained by the proposed method and its centralized counterpart. Results show that the MAD and SAD can be reduced to less than 2×10−11 when the number of iterations is large enough, e.g., 1,500 or 2,000. This result implies that VERTICOX tends to achieve identical accuracy in model parameter estimation as its centralized counterpart. Table 5 also shows the time costs for computation in the server and client side, where a majority of computations were conducted in the server. We also provide the average time cost for calculation and for sending and receiving intermediary results in Table 6. Similar to the SEER dataset, VERTICOX obtains equivalent results in the statistical tests over the UARU dataset, when compared with its centralized realization.

TABLE 5 Estimation Errors and Time Cost for the Model Estimation Over the UARU Dataset Under Various Numbers of Iterations and Penalty Parameter ρ=0.25ρ=0.25
Table 5- 
Estimation Errors and Time Cost for the Model Estimation Over the UARU Dataset Under Various Numbers of Iterations and Penalty Parameter $\rho =0.25$ρ=0.25
TABLE 6 Detailed Time Cost for Distributed Model Parameter Estimation Over the UARU Dataset Under the Real-World Network Conditions

5.2 Robustness to Covariate Distribution
VERTICOX was also evaluated over covariates randomly split into K institutions to verify its robustness. Here, we consider K=2, as Tables 2 and 5 show that the divergences between VERTICOX and its centralized counterpart are close for the cases of 2 and 3 institutions. When constraining the maximal number of iterations, we conducted 5 trials to estimate model parameters for the SEER dataset based on the 20 covariates randomly split into 2 institutions. Table 7 implies that covariate distribution did not significantly affect the differences MAE, SAD and MAD, when the number of iterations is large.

TABLE 7 Estimation Error in Terms of Mean Square Error (MSE), Maximum Absolute Difference (MAD), Maximum Difference Ratio (MDR) and Summation of Absolute Difference (SAD), for Model Parameters Derived Over the SEER and UARU Dataset Using Varying Covariates Distributed Across 2 Institutions
Table 7- 
Estimation Error in Terms of Mean Square Error (MSE), Maximum Absolute Difference (MAD), Maximum Difference Ratio (MDR) and Summation of Absolute Difference (SAD), for Model Parameters Derived Over the SEER and UARU Dataset Using Varying Covariates Distributed Across 2 Institutions
Furthermore, we evaluated VERTICOX over the SEER dataset where the covariates were unevenly distributed across the two institutions. The number of covariates held by one institution was set to the proportion of 50, 60, 75, and 90 percent for the SEER dataset and 50, 60, 70, and 80 percent for the UARU dataset, respectively. Table 7 shows that MSE, SAD and MAD for the UARU and SEER datasets tend to be robust with varying distribution of covariates under sufficient number of iterations, i.e., 2,000.

5.3 Penalty Parameter
In this section, we evaluate VERTICOX based on varying penalty parameters. Model parameters of VERTICOX are estimated over the SEER dataset under ρ= 0.25, 0.5, 1.0 and 2.0, respectively. Fig. 3 provides the MSEs with the increase in the number of iterations. It shows that the convergence speed of VERTICOX tends to be enhanced with large ρ. This fact is compatible with Theorem 1 that demonstrates VERTICOX converges linearly with ρ.


Fig. 3.
MSE curves for model parameter estimation under penalty parameter ρ=0.25, 0.5, 1.0 and 2.0.

Show All

5.4 Survival Analysis
5.4.1 Surveillance Epidemiology and End Results (SEER) Dataset
To perform survival analysis, we randomly extracted 1,699 records with 20 features from the SEER dataset of 55,007 breast cancer patients with first diagnosis from 2001 to 2009. In Fig. 4a and 4b, we provided the baseline survival curve (green) and the survival curves for groups of patients from different races and ages for the SEER dataset, respectively. The survival curves were obtained according to Algorithm 2, by averaging over the subpopulations. As in Section 3.4, local model parameters and covariates for each institution were not exchanged during survival analysis.


Fig. 4.
Survival analysis for the SEER dataset. (a) Baseline survival curve (green) and survival curves for the subpopulations white (blue), black (red) and others (black); (b) Baseline survival curve (green) and survival curves for the subpopulations with ages <50 years (blue), 50-59 (red), 60-69 (black) and ≥70 (brown).

Show All

Furthermore, we provided the time-dependent AUCs to assess the discrimination of the fitted Cox proportional hazards model, as shown in Fig. 5. The global time-dependent AUC score and local ones for two institutions were calculated based on the estimation method proposed by Chambless and Diao [34]. Here, the covariates were equally split into two institutions and local AUCs were derived based on the local covariates owned by the corresponding institutions. For the SEER dataset, the global AUC was 0.78, which exceeds the local AUCs by about 0.04 and 0.10.

Fig. 5. - 
Time-dependent AUC measured using the method proposed by Chambless and Diao [34] based on the estimated model parameter $\hat{\boldsymbol{\beta }}$β^ for the SEER data. The solid (red) line indicates the global AUC for VERTICOX. Dashed (blue and green) lines represent AUCs for different institutions based on their local covariates. For the SEER dataset, 20 covariates are equally split into the 2 institutions.
Fig. 5.
Time-dependent AUC measured using the method proposed by Chambless and Diao [34] based on the estimated model parameter β^ for the SEER data. The solid (red) line indicates the global AUC for VERTICOX. Dashed (blue and green) lines represent AUCs for different institutions based on their local covariates. For the SEER dataset, 20 covariates are equally split into the 2 institutions.

Show All

5.4.2 UMASS Aids Research Unit (UARU) IMPACT Study Dataset
Similarly, we performed survival analysis over the UARU dataset using 279 records. Fig. 6a and 6b plot the baseline survival curve (green) and the survival curves for groups of patients with different treatments and races for the UARU dataset, respectively. Global and local AUCs were calculated for the UARU dataset. Fig. 7 shows that the global AUC for VERTICOX varies in the interval [0.64,0.75] for distinct event times, outperforming the local models by a noticeable gap.


Fig. 6.
Survival analysis for the UARU dataset. (a) Baseline survival curve (green) and survival curves for the subpopulations of patients who took short (blue) and long (red) treatments; (b) Baseline survival curve (green) and survival curves for the subpopulations white (red) and non-white (black) patients.

Show All


Fig. 7.
Time-dependent AUC measured using the method proposed by Chambless and Diao [34] based on the estimated model parameter β^ for the UARU data. The solid (red) line indicates the global AUC for VERTICOX. Dashed (blue and green) lines represent AUCs for different institutions based on their local covariates. For the UARU dataset, 10 covariates are equally split into the 2 institutions.

Show All

SECTION 6Discussion
6.1 Limitations
The proposed distributed model enables multiple institutions to collaborate to build a global Cox model without exchanging sensitive patient-level information. These institutions are not required to trust each other, as original patient records are not transmitted to the server and other institutions. However, there is a limitation in deploying the proposed model, especially for handling high-dimensional survival data. According to the proposed method, the kth institution computes the model parameters βk for its own covariates based on the inversion of ∑Nn=1xnkxTnk. Thus, the rank of the Mk×Mk matrix ∑Nn=1xnkxTnk is determined by min(N,Mk). For high-dimensional survival data, the Mk×Mk matrix could be underdetermined, especially when Mk>N. Under such situation, βk cannot be uniquely solved from Eq. (8) for the kth institution. To solve Eq. (8), each institution needs to know whether the patients have observed events (Dt for t=1,…,T), but does not require their survival time. In general, VERTICOX cannot handle the data arbitrarily distributed across multiple institutions. However, it could be extended to deal with the situation, when the sites owning the covariates of part of patients have their covariates aligned with each other. For example, Site A and B own the M1 covariates of part of patients, and Site C holds the remaining M2=M−M1 covariates of all the patients. Since the server updates the auxiliary and dual variables with the corresponding aggregated intermediary results, the distributed optimization is still solvable.

According to Tables 2 and 5, ADMM would require a large number of iterations (i.e., 2,000 for SEER and 1,500 for UARU) to achieve stable estimation accuracy. However, the convergence of ADMM can be further enhanced by assigning a proper initial value to β and adapting the model parameters ρ with the number of iterations. Since a large ρ stands for larger step size towards convergence, it can be set to be inversely proportional to the number of iterations to balance convergence speed and prediction performance.

6.2 Potential Extensions
In this section, we present several extensions aiming at improving the usability and privacy of our proposed method.

6.2.1 Model Generalization
VERTICOX mainly focuses on the Breslow's approach for classic Cox models with N>M (the number of subjects is supposed to exceed the number of covariates). However, it is possible to extend VERTICOX to survival analysis with a general formulation. One natural extension is to extend VERTICOX for Efron's approximation [35], which would fit the Cox model with all arbitrary relationships between the number of events and patients at risk. Since VERTICOX does not require a decomposable partial log-likelihood function for vertically partitioned data, it tends to reformulate updating of auxiliary variables z¯ (in Step (2)) for Efron's approximation. Similar to the Breslow's approach, the convergence for Efron's approximation can also be guaranteed by fulfilling Lemma 1.

VERTICOX can also be extended for distributed Cox models over more general survival data with M>N [36]. Since M>N could lead to underdetermined problems for solving local model parameters in each institution, VERTICOX would be extended by fitting the covariates with methods such as shrinkage of coefficients and feature selection. When a regularization term R(β) is adopted, VERTICOX needs to add it to Eq. (8). Thus, the model parameters for each institution are obtained by a regularized optimization based on its local data. ℓ1 or ℓ2 regularization can be considered for shrinkage of coefficients and feature selection. Note that there is no need to change the optimization problem at the server for the auxiliary and dual variables. Thus, the algorithmic framework and convergence conditions would be maintained. Please refer to Appendix 5, available in the online supplemental material, for details.

6.2.2 Privacy Extension
VERTICOX accomplishes a distributed optimization for the Cox proportional hazards model while enabling institutions to keep their individual patient data private. Therefore, our solution provides stronger privacy protection in comparison to traditional methods that require a central repository to gather data for survival analysis. However, an adversary who observes the released model results may be able to learn some sensitive information about the patients contributing the data. To protect from such a disclosure, we plan to consider the notion of differential privacy [37]. Intuitively, differential privacy aims at hiding the presence of an individual patient in the data by perturbing the output results with calibrated noise. Because differential privacy provides formal privacy protections, this privacy model has gained popularity in the machine learning field [38], [39], [40], [41]. One extension of our VERTICOX solution is to determine a suitable perturbation mechanism to protect the final output of the global survival model β∗, which could be shared with external users (e.g., researchers). Since the function in Eq. (7) is convex, continuous and differentiable, we can use the result proposed by Chaudhuri and Monteleoni [44] to calibrate the perturbation noise and achieve differential privacy. In this way, the institutions can make β∗ differentially private before releasing the final parameters β~∗. Such a mechanism can effectively prevent data recipients from identifying patients in the private cohort from the released parameters. Furthermore, recent works have shown promising results in applying differential privacy to protect against an untrusted data aggregator in a distributed setting [42], [43], [45]. As a future research direction, we plan to investigate how those solutions can benefit our setting.

SECTION 7Conclusion
This paper presented a distributed optimization method for survival analysis. The proposed method constructs a client-server architecture for federated data analysis for the Cox proportional hazards model for vertically partitioned data, including model parameter estimation and survival estimation. The alternating direction method of multipliers (ADMM) is leveraged to enable a privacy-protecting implementation of the proposed method, where sensitive patient-level information is not required by the server. The proposed algorithm is shown to achieve a linear convergence in iterative optimization. We demonstrate that the proposed method can achieve equivalent accuracy in distributed computation to that of its centralized counterpart.

