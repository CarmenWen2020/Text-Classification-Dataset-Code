Automatically discovering message formats of unknown service or system protocols from network traces has become important for a variety of applications, such as emulating the behavior of an unknown protocol in service virtualization, or enabling deep packet inspection in network security. Among existing schemes, the keyword extraction based approaches have been shown to be effective. Inspired by the template structure of protocol messages, recent works leverage the positions of keywords to extract message keywords more accurately. However, these methods are deficient for messages with large variations in length. To address this problem, we propose R-gram, which exploits the relative positions of keywords in messages, allowing the keywords to be robustly detected in variable length messages. It first extracts the common template of the messages in a given message trace with a fast sampling technique, and segments each message into blocks according to the relative positions of the common keywords in the template. It then identifies message keywords in each block by using a new concept and technique — relative positional n-gram (r-gram in short). Finally, the message keywords are used to separate all the messages into type-specific clusters and consequently derive the message format for each cluster. We have implemented and evaluated R-gram on real-world service traces containing either textual or binary protocol messages. Our experimental results show that R-gram is more accurate and robust than existing state-of-the-art tools in protocol message format extraction. Furthermore, R-gram is efficient for processing large-scale message traces.

Previous
Next 
Keywords
Protocol messages

Format extraction

Relative positional keywords

R-gram

1. Introduction
This paper concerns the automatic inference of protocol message formats from the message traces of unknown application protocols. This has become increasingly important in addressing many management- and security-oriented network problems. For example, in service virtualization (Du et al., 2015, Versteeg et al., 2016, Hossain et al., 2018), a virtual service listens for request messages of variable types and returns an appropriate response message in accordance with the request message type. It requires the identification of message formats to distinguish request message types and generate the corresponding response messages. In the area of network security (Lin et al., 2008, Wang et al., 2011b, Wen et al., 2017), an intrusion detection system requires knowledge about the protocol message formats of malicious messages to perform deep packet inspection. All these applications require inferring protocol message formats so as to perform the succeeding downstream analysis.

Over the past few years, researchers have proposed various methods for extracting the formats of protocol messages. Those methods fall into two categories: protocol parsing-based methods and protocol signature-based methods. Protocol parsing-based methods, such as Polyglot (Caballero et al., 2007), Prospex (Comparetti et al., 2009), HFSM (Lim et al., 2006), and AUTOGRAM (Höschele and Zeller, 2016), infer protocol message format by reverse engineering both the executable code and the message traces of a target service or system following a particular communication protocol. However, these methods become inapplicable when the source program implementing the protocol is unavailable, and this is common when proprietary or legacy systems are involved. Protocol signature-based methods, such as Discoverer (Cui et al., 2007), SPI (La Mantia et al., 2010), SANTaClass (Tongaonkar et al., 2013), and ProDecoder (Wang et al., 2012), conduct the analysis only relying on the raw message traces of the given service or system. They incorporate statistical learning techniques from frequent pattern mining (Aggarwal and Han, 2014) and natural language processing (Blei et al., 2003) to mine patterns from raw message traces. However, these methods do not take into account the template structure of protocol messages, which is an essential feature of machine-generated messages and is a main difference between machine languages and natural languages.

Recently, researchers have proposed to leverage the positions of message keywords for protocol format extraction. For example, AutoReEngine (Luo and Yu, 2013) first uses a frequent pattern mining technique, Apriori algorithm (Agrawal et al., 1994), to extract n-grams whose frequencies exceed a pre-defined threshold as keyword candidates. Then, for each keyword candidate, it calculates the distance of the candidate’s all possible positions. The ones with small standard deviations are kept as keywords, while others are discarded. Another example is the approach proposed by Li and Yu (2016). They first extract candidate keywords based on the intuition that a keyword would appear frequently in different messages but would not appear many times in one message. Then, they built a Hidden semi-Markov Model (HsMM) to capture both the temporal and spatial position relations of keywords. Finally, the true keywords are singled out by maximum likelihood estimation. However, these methods are not robust for the protocols with large variability in message payload lengths. Large variability in payload lengths leads to large variations in keywords’ positions. Those keywords are often treated as false keywords by the existing methods. Motivated by this, we propose a novel approach by exploiting the relative positions of keywords.


Download : Download high-res image (780KB)
Download : Download full-size image
Fig. 1. An example LDAP communication session with 8 request messages. There are 5 different message types: Bind, Add, Modify, Delete, and Unbind, and each has its own format. The messages share a common message template “LDAP * Request Message ID: * LDAP * Request Protocol Op*”, where “*” represents a variable block.

In this paper, we propose R-gram to achieve accurate format extraction for protocol messages, by taking the raw protocol traces as input and identifies the formats of the various messages types involved. Hence, our method belongs to the second category—protocol signature-based methods. In practice, we observe that the lengths of message payloads vary from message to message, while the keywords appear in a relatively fixed sequence in these messages (cf. Fig. 1). R-gram is based upon this key insight. It first introduces a fast sampling method to generate the global message template of a target message trace. The template consists of a sequence of keywords common to all messages in the trace. Meanwhile, the template segments each message into multiple blocks (i.e., the variable parts) between common keywords. Then, R-gram extracts the keywords in each block based on a new concept and technique, r-gram. It further clusters the messages into groups based on the keyword co-occurrence patterns. Finally, it extracts the message format for each message cluster through a proposed sampling strategy.

In general, this paper makes the following key contributions.

•
R-gram takes advantage of the relative position of keywords, it addresses the robustness issue in existing position-based methods.

•
R-gram divides each message into multiple blocks and identifies keywords within each message block instead of the entire message set. This decreases the computational cost in keyword identification.

•
R-gram is based on the statistical characterization of messages, and it assumes no knowledge of the protocol concerned (such as delimiters). Accordingly, it can be applied to both textual and binary protocols.

Experimental results on a range of interaction trace datasets from four real world systems/protocols have shown that our approach achieves high accuracy, computational efficiency and scalability, significantly outperforming two existing representative approaches.

The rest of the paper is organized as follows: Section 3 analyzes the problem of extracting protocol message formats using a real-world example. In Section 4, we give the rationale of our proposed method. In Section 5, we present the detailed techniques involved in each step of R-gram. Experimental results on a number of real world service and application protocols are reported in Section 6. Section 2 discusses related work, and Section 7 concludes this paper.

2. Related work
The problem of extracting message formats from protocol message traces has been investigated for a number of years with various approaches having been proposed. In general, the existing message format extraction approaches can be divided into two broad categories: reverse engineering-based methods, and protocol signature-based methods. The former utilizes system source code and interaction traces, and the latter relies on only system interaction traces. The second category of methods extract the statistical protocol signatures from the packet payloads of network traces automatically. As our approach belongs to the second category, we survey the related work in that field. According to the approaches used in extracting message keywords, these methods can be further divided into tokenization based methods, and n-gram based methods.

2.1. Tokenization based methods
Tokenization based methods use separators and/or delimiters in protocol messages to split messages into tokens. The natural separators and delimiters include space(s), tabs, special characters, etc.

Discoverer (Cui et al., 2007) uses a predefined set of delimiters to divide the messages into tokens. It adopts a recursive clustering approach on tokenized messages. Tokens are compared from left to right. If two messages have the same token properties or are very similar, then those two messages are placed in a message type cluster. Finally, an MSA method is adopted to infer message formats.

The technique proposed by Wang et al. (2013) filters out the infrequent tokens using the Jaccard index and then builds a finite state machine (FSM) from the ordered sequence of tokens as the message formats.

Määttä and Räty (2014) adopted Message Sequence Chart to model the sequential activities of legitimate network traffic to detect intrusion. It generates a prototype of legitimate network traffic in XML by searching some predefined fields (i.e., IP address, source port, destination port, etc.) in network traffic. This method is not applicable when such prior knowledge about the protocol is not available or only certain message traces of the protocol are accessible.

Tongaonkar et al. proposed SANTaClass (Tongaonkar et al., 2013, Tongaonkar et al., 2015), a system for automated network traffic classification. The common tokens are extracted as signatures in flows for classification. The signatures were further augmented with context by considering the sequence (or ordering) of tokens in flow content instead of considering the tokens independently. In SANTaClass, Tongaonkar et al. adopts an unsupervised approach to automatically extract statistical signatures from the packet payloads of network traces.

Li and Yu (2016) focused on protocol keyword mining over WebSocket (Fette and Melnikov, 2011). They first extract candidate keywords based on the intuition that a keyword would appear frequently in different messages but would not appear many times in one message. Then, they built a Hidden semi-Markov Model (HsMM) to capture both the temporal and spatial position relations of keywords. Finally, the true keywords are singled out by maximum likelihood estimation.

The above methods require the prior knowledge of the separators and/or delimiters in the protocol messages. However, many protocols, such as LDAP and IMS, present messages in a binary format without explicit separators or delimiters. These methods become inappropriate for those protocol messages.

2.2. n-gram based methods
To learn distinctive keywords for message format inference, many methods further find string patterns of arbitrary length, called n-grams, where n denotes the number of characters or bytes in the pattern.

ProDecoder (Wang et al., 2012, Yun et al., 2016) adopts n-gram for keyword identification in a different way. Instead of identifying a maximum n-gram as a message keyword, it adopts Latent Dirichlet Allocation (LDA) from natural language processing and identifies the keywords as a set of semantically related 4-grams. It first decomposes the inputted messages into 4-grams and treats them as words. Then, it adopts LDA to extract the topics of the words based on the semantic relationship among the 4-grams. The probability of a 4-gram assigning to each topic is calculated. Then, the probabilities are input into the Information Bottleneck (IB) (Tishby, 1999) algorithm to cluster the messages. Finally, a Multiple Sequence Alignment (MSA) algorithm is adopted to extract the message format for each cluster. Due to the difference between natural languages and machine languages, directly applying LDA causes the inaccuracy of ProDecoder in message clustering. Often, different types of messages are put into a single cluster, leading to format over generalization.

AutoReEngine (Luo and Yu, 2013) was the first work using the position of n-grams for message keyword identification. It first splits messages into n-grams with different lengths. Then, the Apriori algorithm (Agrawal et al., 1994) is adopted to identify keywords from the n-grams. The variation of keywords’ positions is further calculated. Those with large variations are filtered out as noise. Finally, messages are clustered based on the intuition that different types of messages contain different sequences of message keywords. The keyword series in each cluster is regarded as the corresponding message format. As AutoReEngine adopts the Apriori algorithm to extract keywords from n-grams, it often treats parts of payloads as keywords, leading to keyword overfitting. If a keyword is overfitted to some messages, AutoReEngine will extract many more formats than the actual formats. Taking the messages in Fig. 1 as an example, if “,ou=S” is extracted as a keyword, then the two Add messages will have two different keyword series. Thus, instead of generating one format, it generates multiple formats for Add messages. Other n-gram based techniques for message format extraction also suffer from keyword overfitting issue.

We recently proposed a method, P-gram (Jiang et al.), for the clustering of machine-generated messages. In P-gram, we first associate the position as meta-data with each n-gram, so that we can more accurately discern which n-grams are keywords of a message, which n-grams are parts of payload information. Then, the positional keywords are used as features to cluster the messages. Finally, K-Medoids is used to leverage the importance of the keywords and cluster messages into groups. We also proposed an approach to extracting fine-grained type-specific message formats for a given service’s API from its interaction traces (Hossain et al., 2018). In this approach, we first identify the message type field through message alignment and entropy analysis and use the message type field to partition the messages into type-specific clusters. Then, we identify the keywords for each type-specific message cluster by breaking the messages down to n-gram and analyzing the frequency of the n-grams. Finally, we use the keywords to tokenize the messages, and derive the message formats by analyzing the order of appearance of the message fields (keywords and payload segments). In this approach, the repetition of keywords and the ambiguity of true keywords and false keywords were not considered. More importantly, it is not particularly suitable for binary protocols as it relies on the identification of message type field, which is difficult to do for binary protocols.

The proposed approach, R-gram, is an n-gram based method for protocol message format extraction. From the above analysis, we see that existing n-gram based methods faced with the keyword inaccuracy issues, in particular with protocols having large variation in payload length, keyword repetition, and keyword ambiguity. Compared to these methods, R-gram successfully addressed these issues by considering the relative position of keywords in messages. Experiments on various textual and binary protocols demonstrate the effectiveness and efficiency of the proposed R-gram for message format extraction.

3. Problem statement
As discussed above, inferring the formats of messages communicated between services and systems from message traces has critical real-world applications. Over the years, many methods have been proposed to address this issue. However, they have major limitations in inferring accurate message formats when faced with the messages presenting large variations in payloads. In the following, we first introduce some basic terminologies used in message format extraction; then, we discuss the problems introduced by large payload variations.

In general, a communication protocol defines the syntax of messages that the communication entities receive and emit. A protocol message often presents a sequence of message fields. These fields can be divided into those with values that are fixed across the same type of messages, and those with values can vary from message to message. We refer to the fixed fields as message keywords, which have a special meaning as defined by the underlying message format. The fields that can differ from message to message are referred to as payloads, which are the message body parts. For example, the messages of the Lightweight Directory Access Protocol (LDAP; cf. Fig. 1) contain such keywords as “ou” and “cn”, representing an “organizational unit” and a “common name”, respectively. Their corresponding value fields contain an organization unit’s name and an individual’s common name, which are the payloads corresponding to “ou” and “cn”, respectively. In this paper, we consider a keyword as a maximum consecutive sequence of characters that are fixed across the same type of messages. Delimiters used in message formats (if any) are regarded as part of the adjacent message keywords. This definition does not impact on the understanding or formulation of messages. For example, “,ou=” and “dn: cn=” are considered two keywords in the messages in Fig. 1.

Due to the large variations of communication contents between entities, the transmitted messages have large differences in their payloads. This introduces the following issues that challenge the existing methods for message keywords extraction and eventually message format extraction. First (large variation in payload length), the payloads of a keyword may have large differences in length across messages. For example, the payloads of the keyword “cn” present different lengths in Fig. 1. The payload “Haydn CURRY” in the first message has a length of 11 characters, while the payload “Catherine JORGENSEN” in the second message has a length of 19 characters. In existing position-based methods, such as AutoReEngine (Luo and Yu, 2013) and P-gram (Jiang et al., 2019), the keywords with large standard deviation of positions will be filtered out as noises (i.e., payloads). The keyword “ou” might not be able to be identified, due to the large variations of its positions in different messages. Hence, existing position-based methods are not robust for protocols with large variations in message payloads. Second (keyword ambiguity), a payload may contain a message keyword as a substring, causing problems in identifying actual keywords in existing approaches. For example, the payload “Haydn CURRY” in the first message contains the substring “dn”, while “dn” is a keyword.

The above problems require us to design a more effective method that not only can flexibly extract keywords from messages with large payload variations, but also can accurately distinguish between true keywords and false keywords (from payloads). In the following, we introduce R-gram to address these problems.

4. Rationale
R-gram aims at effectively extracting message keywords based on the key insight that the keywords in messages appear in fixed positions relative to each other. This relativity occurs at two levels: the global level and the block level.

The global level. Given a message trace of a target protocol, all the messages in the trace generally share a common template (see the top subfigure in Fig. 2). The fixed portions (the color boxes) in the messages represent the common global keywords in the common template, while the variable portions (the white boxes) represent variable parts of the messages. For example, the LDAP messages in Fig. 1 share a common template “LDAP * Request Message ID: * LDAP * Request Protocol Op*”, where “*” represents a variable part which varies from message to message. The first variable (“*”) block contains the various message-type keywords, such as “Bind” and “Add”. The 2nd variable (“*”) block corresponds the payload of the common global keyword “Message ID”. The last variable (“*”) block represents a mix of keywords and payloads. R-gram first identifies the common global keywords, the variable blocks between them, and consequently the common message template.


Download : Download high-res image (237KB)
Download : Download full-size image
Fig. 2. Illustration of relative positions of keywords. The color blocks represent keywords and the white blocks represent payloads in variable lengths. The alignment of the messages gives the relativity of keywords’ positions in messages. .

The block level. R-gram utilizes the common message template to obtain the relative positions of message fields (see the bottom subfigure in Fig. 2). As different “*” blocks in the template carry different structural information, R-gram segments each message into blocks according to the “*” blocks and extracts the keywords in each block on a block basis. There are three noticeable advantages. First, segmenting messages into blocks can help distinguish between true keywords and false keywords, within and across blocks. For example, the messages in Fig. 2 present 5 variable blocks. The red box in the 2nd block and the blue box in the 4th block can be easily filter out as a false keywords due to their low occurrences in these blocks, even though each of them is the same as one of the global keywords. Second, When extracting keywords in each block, R-gram adopts a new concept and technique relative positional n-gram (r-gram for short). It considers the positions of keywords relative to the corresponding blocks where the keywords appear. Intuitively, the true keywords present high probability density in a certain window or windows (for repetitive keywords) of positions of the block, while low density windows often contain false keywords. R-gram distinguishes true keywords from false keywords by comparing their probability densities. Third, segmenting messages into blocks decreases the computational cost. Compared to identifying keywords by scanning the whole messages, keyword searching in separate small message blocks saves computational time. Therefore, R-gram can extract keywords more accurately and efficiently, eventually it can infer the fine-grained message formats.


Download : Download high-res image (522KB)
Download : Download full-size image
Fig. 3. Architecture of the proposed approach R-gram.

In summary, R-gram identifies keywords by exploring their relative positions in messages. This not only addresses the issue of large variations in payload length, but also addresses the keyword repetition issue and the ambiguity between true keywords and false keywords. These ultimately help us in extracting accurate message formats.

5. The proposed approach: R-gram
In this section, we present the details of our proposed approach R-gram, a novel approach which extracts message formats based on keywords’ relative positions. It involves four major steps: (1) common message template generation; (2) r-gram keyword identification1; (3) message clustering; and (4) message format extraction. The architecture of our approach is given in Fig. 3. We particularly used 4 messages in Fig. 1 to explain the detailed process in each of the four steps in R-gram.

5.1. Common message template generation
In this subsection, we introduce a fast method to extract the common message template of a given message trace based on a smart sampling strategy and a fast sequence alignment algorithm.

A group of existing approaches focus on extracting message fields that are common to all messages. For example, Veritas (Wang et al., 2011b) considers the most frequently occurring strings as message structure keywords. Biprominer (Wang et al., 2011a) uses variable length pattern recognition to find distinctive protocol keywords. Catcher (Yu et al., 2007) focuses on the variable portions of the messages and identify them by using a sequence alignment algorithm to align all the messages in the message trace. However, these methods only work on small datasets because they either require multiple sequence alignment across all messages, or they carry out the extraction of common keywords by examining each of the messages. Another possible way of generating the common message template is to randomly retrieve a small sample of the messages and generate the message template from the sample. However, a random sample might not be representative to generate the globally common template. Here, we propose a smart sampling approach that is capable of processing large (as well as small) datasets. It uses a small subset of representative sample messages to generate the same common message template as using all messages (see below).


Download : Download high-res image (327KB)
Download : Download full-size image
In general, the shorter a message is, the fewer keywords it covers. Thus, the shortest message usually covers the fewest keywords, but it must contain all the keywords in the common message template. On the other hand, the common template should be able to accept the largest message variations in terms of keywords and payloads, and the longest message generally has the largest variation. Hence, we first generate a sample  of two messages, including the shortest one and the longest one. Then, we create an alignment for these two messages and generate a message template . For each remaining message , we align the message  with the template  and generate a new template 
. If 
 is the same as , we skip ; otherwise, we add  into . Note that all of the already-checked messages match the new template, as they share the same template with the messages in the sample. We use the new template to check the next messages until we get a global template which can match all messages. Here, we adopt a generalized suffix tree (GST) (Schneider et al., 2015) for sequence alignment. Algorithm 1 gives the details of generating a common message template. The generated message template  is in the format of “[*] 
 * 
  * 
 [*]”, where “[*]” indicates that the variable part “*” is optional. One “*” represents one block in the messages. For the messages in Fig. 1, they share a common message template “LDAP * Request Message ID: * LDAP * Request Protocol Op*”. The template segments each message into 4 blocks.

Now we analyze the computational complexity of Algorithm 1. Note that, we only align “message pairs” (i.e., a template and a message) in each round, and as such we can quickly align the message pairs and generate the templates. Furthermore, we start the message sample with the shortest message and the longest message, so the initial template is in a very short length. Aligning a message with a short template further decreases the computational cost in sequence alignment. By using this smart sampling method, the messages in the final sample are very few.


Download : Download high-res image (803KB)
Download : Download full-size image
5.2. r-gram keyword identification
In this subsection, we introduce a new concept and technique, r-gram, for keyword identification. We first extract all frequent n-grams. An n-gram is a subsequence of n elements contained in a given sequence of at least n elements. For example, treating each character as an element, the 3-grams generated from the first message in Fig. 1 are LDA, DAP, etc. Then, we extract frequent r-grams from the n-grams by considering their relative positions. Finally, we analyze the probability density of r-grams’ positions to determine the true keywords. In this paper, for an arbitrary block, , we call all the corresponding message segments, 
, in the block as a message block, 
. The notations used in this paper are presented in Table 1. The following presents the details of the steps involved in r-gram keyword identification.


Table 1. Notations used in paper.

Notation	Description
A set of messages
The th message
Message segment—the th block of message 
Message block—the th block of all messages
Threshold of keyword selection
The number of message clusters
An n-gram of length n
A r-gram starting at position  of length n in 
5.2.1. Frequent n-gram identification
To identify frequent n-grams in an arbitrary message block 
, we (1) initialize a set 
 and a minimum length n of n-grams; (2) break each message segment 
 down into n-grams, 
; and (3) count the frequency 
 of each n-gram. If the frequency 
 is greater than , we add 
 into 
. Then, we increase n by 1 and get back to step (2) until there is no n-gram with frequency greater than  identified. Lines 3–18 in Algorithm 2 present the details of identifying frequent n-grams in message block 
. For example, if we set the minimum n-gram length  and the threshold ratio  for the messages in Fig. 1, we will get frequent 3-grams such as Del, 4-grams such as Dele, 5-grams such as Delet, and 6-grams such as Delete in the 1st block of the 6-th and 7-th messages. Note that Delete is a candidate keyword, whereas Del, Dele and Delet are its substrings. In the following, we design a fast method to extract these candidate keywords and remove the substrings.

5.2.2. Candidate r-gram keywords extraction
To extract the candidate keywords from the frequent n-grams, we introduce r-gram. The main idea is to capture the longest common n-grams in 
, while considering the position of those n-grams. We initialize a multiset 
 to store r-grams and a multiset 
 to store longest common n-grams. We first sort 
 decreasingly in terms of n-gram length. Then, for each message segment 
, we initialize a set 
 to store the r-grams presenting in 
. We check if the first n-gram (i.e., the longest n-gram) 
 exists in 
. If it exists, we create a new r-gram 
, where  is the starting position that the n-gram 
 presents in 
; add 
 into 
 and 
, and add 
 into 
; and, replace 
 in 
 by wild cards. If it does not exist, we continue to check the next n-gram in 
 until no r-gram can be generated for 
. Once we get 
 for all message segments in 
, we count the frequencies 
 for all n-grams 
 in 
. If 
, we remove 
 from 
, and remove the corresponding r-grams 
 from 
 and 
. Lines 19–40 in Algorithm 2 present the details of identifying r-grams in message block 
.

Compared with other keyword extraction methods, which requires expensive computations on comparing n-grams and merging short n-grams to generate long n-grams, our method can quickly identify the candidate keywords. For example, in the first block of the messages in Fig. 1, Delete 
 will be extracted as a candidate keyword, while all the substrings such as Del 
 and Dele 
 will not be considered as candidate keywords, as Delete is the first one to be extract and the longest one covering them. Note in the last block that, the 4-gram “,ou=” is extracted as a candidate keyword, but with variable positions: “,ou=”
, “,ou=”
, “,ou=”
, “,ou=”
, “,ou=”
, etc. In the following, we analyze the probability density of these candidates to determine true keywords.

5.2.3. Position variation analysis of r-gram keywords
In general, a keyword may not appear at the exact same position across all messages containing it. As such, we consider the frequency of a n-gram over a window of positions rather than at an exact position. For an arbitrary n-gram 
, we use 
 to denote the set of all the possible positions of 
 in 
. We can calculate the probability density for 
 in a window 
 as follows, (1)
 
where 
 is the frequency of 
 in the window, and 
 is the volume of 
. Intuitively, the high-density window is more likely to contain the true keywords, while the low-density window may contain false keywords (see Fig. 4). In order to identify those high-density windows of frequent n-grams, we adopt Parzen-Window Density Estimation (Babich and Camps, 1996) to estimate the window size. As suggested by Babich and Camps (1996), we set the window size as (2)
where 
 is the standard deviation of 
’s positions. If the density in a window is lower than a given threshold , we drop the window. Meanwhile, we assume a maximum repetition  of a keyword. If the window number calculated based on the window size is greater than , we treat the corresponding n-gram 
 as a floating keyword 
 with window size . Floating keywords, therefore, can appear anywhere in a message. Otherwise, we use the first r-gram 
 in each window as the r-gram keyword associated with window size 
 to represent all possible positions of the keyword in the window. For example, we obtain the window size for the 4-gram “,ou=” as , which ends up with  windows beyond our default maximum value . We treat “,ou=” as a floating keyword. That means, wherever “,ou=” appears in the message block, it is a true keyword.

Then, we need to update 
 for each message segment such that the r-grams in each window 
 is replaced by the first r-gram 
 in the window. We first count the frequency 
 of each r-gram 
 in 
, and convert 
 from a multiset to a set. We then update the frequency of 
 in each window as in (3)
and, remove 
 from 
 if 
. We finally update the r-gram keywords in 
 for each message segment 
, as follows: (4)
Lines 41–51 in Algorithm 2 present the details of position variation analysis of keywords. Hence, we obtain a set, 
, of r-gram keywords for each message segment 
.

5.3. Message clustering
After we obtain the r-gram keyword sequence for each message, we can apply well-known clustering algorithms on the keyword sequences to separate all the messages into type-specific clusters. For example, we can calculate the edit distance (Needleman and Wunsch, 1970) between keyword sequences. Then, we apply clustering algorithms, such as K-Means and DBSCAN, on the edit distances between messages. Message clustering based on edit distance has been adopted by many approaches such as Du et al., 2015, Versteeg et al., 2016. Needleman and Wunsch (1970) computes the edit distance for two sequences in  time, where  and  are the lengths of the sequences. Therefore, the complexity of computing the edit distance between keyword sequences of the messages is closer to 
, where  is the average sequence length. The computational complexity of a general clustering method is 
. These give the overall complexity of message clustering being 
, which is too computationally expensive, especially for large-scale datasets.

Here, we introduce a new method to compute the distance between keyword sequences. We first vectorize each message segment, 
, based on the extracted r-gram keywords in 
 and 
. For message segment 
, we define a vector 
 as follows: (5)
where, 
 
 if 
, and 
 otherwise. That is, 
 is the TF-IDF vector of the th block in message .


Download : Download high-res image (253KB)
Download : Download full-size image
Then, we concatenate all the block vectors for each message and generate a larger vector 
 for the message: (6)
We use  to denote the weighted matrix for all of the messages. Finally, we can adopt any of the well-known clustering algorithms on matrix . In particular, we adopted K-Medoids for clustering in the experiments. The complexity of K-Medoids is 
, where  is the number of clusters and  is the number of iterations. Therefore, the use of message vectorization decreases the computational cost for clustering. Algorithm 3 gives the details of message clustering. See Fig. 3 for some illustrative example message clusters for LDAP.

5.4. Message format extraction
Finally, we extract the message format for each cluster (i.e., each message type). Given a message cluster, inferring the message template is to identify the common keyword sequence from the messages in the cluster. To do so, we adopt the method introduced in Algorithm 1 to extract the common keywords for each cluster and construct a regular expression for the keyword-payload sequence as the corresponding message format.

Note that due to the fact that the words and their frequencies in payloads may overwhelm the actual keywords, the number of shared common words from the payload parts of messages of different types may overwhelm the differences between their keyword parts, leading to these messages being mixed in one cluster. Here, we use the following strategy to easily detect mixed message clusters. We first use Algorithm 1 to generate the message template for each of the clusters. Then, for any two templates 
 and 
 of two clusters 
 and 
, we use GST (Schneider et al., 2015) to align 
 and 
 and obtain a new template 
. If template 
, it means 
 is over-generalized. Then, we zoom into cluster 
 and perform a second level clustering on cluster 
. Similarly, if template 
, we perform a second level clustering on cluster 
. For the sub-level clusters, we again apply Algorithm 1 to extract the common keywords for each cluster and construct a regular expression of the cluster as the corresponding message format. For example, if the “Add” messages are correctly clustered, but “Modify” and the “Delete messages are mixed in a cluster, we will get a format “LDAP Add Request Message ID: (.*) LDAP Add Request Protocol Op dn: cn=(.*),ou=(.*),ou=(.*),o=DEMOCORP,c=AU mail: (.*)@ca.com” for the “Add” messages, and a format “LDAP (.*) Request Message ID: (.*) LDAP (.*) Request Protocol Op dn: cn=(.*),ou=(.*),ou=(.*),o=DEMOCORP,c=AU” for the mixed cluster. Note that, the alignment of the two formats is the same as the format for this mixed cluster. Hence, we can detect the mixed cluster and zoom into it, perform a further clustering, and ultimately separate the “Modify” messages and the “Delete” messages.

6. Experimental results
We have evaluated our approach R-gram in extracting protocol formats on real-world protocol traces. In the following subsections, we first describe the datasets used to evaluate our approach, then we define the evaluation metrics, and finally present the experimental results. All the experiments are conducted on a Huawei RH1288 V3 server (Intel(R) Xeon(R) CPU E5-2690 v3@2.60 GHz, 128GB of RAM).

6.1. Datasets
We have used Combs et al. (2007) – an open source packet analyzer – to capture the system interaction traces and exported them into a format suitable for input into our implementation of R-gram. We have applied our approach to four datasets corresponding to four different protocols.

Lightweight Directory Access Protocol (LDAP) is used for accessing and maintaining distributed directory information services over an Internet Protocol (Yeong et al., 1995). LDAP is a binary protocol that uses an ASN.1 (Bapat, 1994) encoding to encode and decode text-based messages to and from its binary representation, respectively. We use both the binary and the text representation of LDAP interaction traces that contain 2,181 messages of 8 different types of LDAP messages.

IBM Information Management System (IMS) is a joint hierarchical database and information management system with extensive transaction processing capabilities. IMS is a binary mainframe protocol. The IMS traces used in experiments consists of 800 messages of 5 IMS operations.

Simple Object Access Protocol (SOAP) is a lightweight protocol intended for exchanging structured information in a decentralized, distributed environment (Blei et al., 2003). SOAP messages use XML technologies to define an extensible messaging framework, which provides a message construct that can be exchanged over a variety of underlying protocols. A bank SOAP trace dataset is used in our experiments, which contains 2,000 messages of 6 different types for a banking service.


Table 2. Statistics of the datasets.

Dataset	msg	types	Avg msg length	Content
LDAP	2,181	8	253.9	Binary/text
IMS	800	5	512.5	Binary
SOAP	2,000	6	207.2	Text
REST	1,825	6	128.2	Text
NOTE: types stands for the number of message types; avg msg length stands for the average number of characters in each message.

Representational State Transfer (REST) enables developers to access information and resources using a simple HTTP invocation (Inc., 2014). The Twitter REST API provides Web application developers a number of services to enable automation of Twitter functionality. The Message contents are in JSON format. The Twitter (REST) traces dataset used in our experiments contains 1,825 messages of 5 different types.

The basic statistics of the datasets are presented in Table 2. All the datasets can be downloaded from http://quoll.ict.swin.edu.au/doc/message_traces.html. For these datasets, we manually separated the messages into clusters according to the message types and obtain the ground truth of message clustering.

6.2. Evaluation metrics
We use three standard evaluation metrics, that is, Precision, Recall and F-measure to quantitatively evaluate and compare the effectiveness of our approach in terms of message clustering and format extraction. The following formula give the definitions for Precision, Recall and F-measure: (7)
 
 (8)
 
 (9)
 

Message Clustering: TruePositive is the number of messages whose types are accurately identified. FalsePositive is the number of messages whose types are incorrectly identified as the type concerned, and FalseNegative is the number of messages whose types are not identified as the type concerned but should be. We compute these TruePositive, FalsePositive and FalseNegative using the method described in Manning et al. (2008).

Format Extraction: For a particular message type, TruePositive is the number of messages accepted by the inferred format of the corresponding message type, FalsePositive is the number of messages of other types that are accepted by the inferred format of that type, and FalseNegative is the number of messages of the type concerned that are rejected by the inferred format of the corresponding message type. We have applied 10-fold cross-validation (McLachlan et al., 2004) in evaluating format extraction.

6.3. Results
In this subsection, we present the experimental results in terms of the accuracy of message clustering, the effectiveness of format extraction, and the scalability of our approach in handling large datasets. In our approach R-gram, there are three parameters involved. Specifically, we set the keyword threshold , the minimum n-gram length  for binary messages and  for textual messages, and the probability density threshold . Here, we compare the result of our approach with two state-of-art tools (ProDecoder (Wang et al., 2012) and AutoReEngine (Luo and Yu, 2013)) and one baseline method: P-gram. Compared to R-gram, the P-gram method considers the absolute position of keywords in keyword identification. It does not involve the first step (common message template generation) used in R-gram, but directly applies all the other steps on the entire messages. By comparing R-gram and P-gram, we can evaluate the effectiveness of considering the relativity of keywords’ positions.


Table 3. Common message template generation.

Dataset	msg in the final sample	Running time (s)
LDAP	3	1.458
IMS	2	6.940
SOAP	2	0.924
Twitter	4	1.022

Table 4. Accuracy of message clustering.

Approaches	LDAP (text)	LDAP (binary)	SOAP	REST	IMS
P	R	F	P	R	F	P	R	F	P	R	F	P	R	F
ProDecoder	0.97	0.81	0.88	0.75	0.57	0.66	0.89	0.98	0.93	0.99	0.88	0.93	0.78	0.58	0.68
AutoReEngine	0.97	0.13	0.23	0.82	0.38	0.60	1.00	0.82	0.90	0.85	0.15	0.26	0.99	0.99	0.99
P-gram	0.90	0.78	0.84	0.79	0.77	0.78	1.00	1.00	1.00	0.92	0.92	0.92	1.00	1.00	1.00
R-gram	0.98	0.98	0.98	0.81	0.78	0.80	1.00	1.00	1.00	1.00	0.99	0.99	1.00	1.00	1.00
*Note: P is Precision, R is Recall, and F is F-measure.


Table 5. Accuracy of format inference.

Approaches	LDAP (text)	LDAP (binary)	SOAP	REST	IMS
P	R	F	P	R	F	P	R	F	P	R	F	P	R	F
ProDecoder	0.88	0.65	0.75	0.80	0.58	0.67	0.93	0.93	0.93	0.79	0.71	0.75	0.78	0.53	0.63
AutoReEngine	0.70	0.19	0.30	0.32	0.18	0.23	0.97	0.60	0.74	0.30	0.17	0.22	1.00	0.31	0.47
P-gram	0.83	0.85	0.84	0.81	0.77	0.79	1.00	1.00	1.00	0.91	0.89	0.90	1.00	1.00	1.00
R-gram	0.92	0.94	0.93	0.88	0.79	0.83	1.00	1.00	1.00	0.94	0.97	0.95	1.00	1.00	1.00
*Note: P is Precision, R is Recall, and F is F-measure.

6.3.1. Common message template generation
We first evaluate the effectiveness and efficiency of the smart sampling method (Algorithm 1) for generating the common message template. Table 3 reports the time and the average number of messages used in generating the common message template for each of the datasets in the experiments. The number of messages used for generating the common templates for the datasets used in our experiments are 3 messages for LDAP, 2 for IMS, 4 for Twitter REST, and 2 for SOAP. The time in generating the common message templates is around 1–1.5 s for LDAP, SOAP and Twitter. On the IMS dataset, our algorithm took about 7 s to generate the common template. This is due to the IMS messages being averagely longer than other messages (see Table 2). The results in Table 3 demonstrate that the smart sampling method is very efficient and it also contributes to the overall approach’s scalability greatly (see Section 6.3.4).

6.3.2. Message clustering
Table 4 reports the message clustering results. It shows that R-gram outperforms the state-of-art methods and the baseline method in terms of Precision, Recall and F-measure in message clustering for all datasets. More specifically, R-gram achieves 1.00 Precision and Recall on the SOAP and IMS datasets, and it achieves more than 0.93 F-measure for both text LDAP and REST datasets. R-grams shows a slightly lower F-measure, 0.80, on the binary LDAP dataset than on other datasets. According to our observation, this is due to the extreme shortness of keywords (i.e., one character), which are often covered by payloads.

ProDecoder clusters messages through keywords identification based on the relationship between keywords learned by using LDA (Blei et al., 2003), from natural language processing. However, protocol messages are machine languages, which do not present the strong power-law term distribution as in natural languages. Hence, LDA sometimes fails to extract the relationship between message keywords correctly. Therefore, ProDecoder shows lower performance than R-gram. More specifically, it shows only 0.88 and 0.66 F-measure in text and binary LDAP, while R-gram has 0.98 and 0.80 F-measure. It shows 0.93, 0.93 and 0.68 F-measure on SOAP, REST and IMS, where R-gram presents about 1.0 F-measure.

AutoReEngine also clusters messages based on keywords by learning the absolute positions of keywords. However, the position information is only used in filtering out false keywords, and the ones that have low standard deviation of positions are treated as true keywords. Other keyword-related issues, such as the repetitiveness of keywords and the appearance of short keywords as part of long keywords, are not considered. Hence, AutoReEngine has lower performance than R-gram. It shows lower than 0.30 F-measure on text LDAP and REST messages. Additionally, as AutoReEngine does not require prior knowledge of the number of clusters, which is required by ProDecoder, R-gram, and the baseline method P-gram. AutoReEngine often generates many more clusters than the ground-truth clusters. For instance, our results show that AutoReEngine generates 72 clusters for the LDAP messages, which have only 8 message types. Thus, it shows high Precision but low Recall in most datasets.

Comparing to the baseline method (P-gram), the proposed R-gram outperforms the baseline method. Both P-gram and R-gram achieves 1.00 F-measure on the SOAP and IMS datasets. R-gram presents 0.98 and 0.80 and 0.99 F-measure on text LDAP, binary LDAP and REST, but P-gram shows 0.84, 0.78 and 0.92 F-measure on these datasets. The results justify the effectiveness of considering relative positions instead of the absolute positions of n-grams for keywords identification.

6.3.3. Format extraction
Table 5 reports the results of message format extraction. Overall, our approach R-gram presents significant out-performance over the two state-of-art methods (ProDecoder and AutoReEngine) and the baseline method (P-gram) for all the four datasets. As we can see, R-gram achieves above 0.92 Precision, Recall and thus F-measure for all the datasets, except for binary LDAP. For binary LDAP, it shows 0.83 F-measure, which still outperforms the other methods.

As the ProDecoder and AutoReEngine infer message format by identifying common portions across the messages of a cluster, their accuracy in extracting message format are highly dependent on the message clustering. Table 5 shows that AutoReEngine shows comparatively very low Recall in format extraction, as it generates many more clusters than indicated by the ground-truth, i.e., over-classifying. As a consequence, the inferred message formats become too specific to messages and could not accept the messages of same type in the test dataset. Thus, AutoReEngine achieves a low Recall value in message format inference, especially on the LDAP datasets (0.19 and 0.18 Recall for text and binary LDAP respectively) and the REST dataset (0.17 Recall). Although the Precision and Recall of ProDecoder are comparatively better than AutoReEngine, it often put different types of messages in one cluster due to the imprecision of keyword identification. As a consequence, ProDecoder often generates over-generalized message formats, which decreases the Precision and Recall of format extraction. As our approach achieves comparatively high accuracy in message clustering, it ultimately achieves high accuracy in message format extraction, compared to ProDecoder and AutoReEngine.


Table 6. Format extraction performance on large-scale (20 K–30 K) datasets.

Approaches	LDAP (#msg 32,387)	SOAP (#msg 21,575)	REST (#msg 21,000)
Time (s)	F-measure	Time (s)	F-measure	Time (s)	F-measure
ProDecoder	773.0	0.730	723.8	0.944	923.5	0.725
AutoReEngine	969.3	0.319	881.3	0.718	1238.2	0.247
R-gram	143.3	0.927	116.9	1.00	192.6	0.947

Table 7. Format extraction performance on large-scale (200 K–300 K) datasets.

Approaches	LDAP (#msg 343,642)	SOAP (#msg 255,069)	REST (#msg 257,394)
Time(s)	F-measure	Time (s)	F-measure	Time (s)	F-measure
ProDecoder		0.719		0.916		0.705
AutoReEngine		0.335		0.730		0.216
R-gram	876.2	0.922	727.9	1.00		0.960

Table 8. Format extraction performance on large-scale (2 M–3 M) datasets.

Approaches	LDAP (#msg 3,859,586)	SOAP (#msg 2,335,113)	REST (#msg 2,722,763)
Time (s)	F-measure	Time (s)	F-measure	Time (s)	F-measure
ProDecoder	–	–	–	–	–	–
AutoReEngine	–	–	–	–	–	–
R-gram		0.919		1.00		0.934
Similar to the clustering results, the baseline method P-gram shows lower performance than our proposed R-gram. This again justifies the use of the relative positions of n-grams in message keywords identification.

6.3.4. Scalability of R-gram on large datasets
From Section 3, we note that R-gram takes advantage of message template structure to divide messages into blocks and extracts keywords based on each block, while existing methods carry out keywords extraction by scanning the entire messages. Hence, we expect a high time-efficiency of R-gram in message format extraction. To evaluate the time efficiency of R-gram on large-scale protocol traces, we have collected three larger sizes (20K-30K, 200K-300K and 2M-3M) of datasets from each of the LDAP (text), SOAP and Twitter REST services. More specifically, the three LDAP datasets contain 32,387, 343,642 and  messages, respectively; the three SOAP datasets contain 21,575, 255,069 and  messages, respectively; the three Twitter datasets contain 21,000, 257,394 and  messages, respectively.

The format inference running time and accuracy (F-measure) on these larger sizes of datasets are reported in Table 6, Table 7, Table 8, respectively. For simplicity, we only report the F-measure in accuracy. As we can see from Table 6, the running time for R-gram is substantially less than the time for ProDecoder and AutoReEngine. More specifically, on the large-scale LDAP dataset, R-gram only requires 143.3 s to extract the message formats, while PreDecoder and AutoReEngine require 773.0 s and 969.3 s, respectively. Similarly, on the large-scale SOAP and REST datasets, R-gram extracts message formats in 116.9 s and 192.6 s, respectively; however, ProDecoder requires 723.8 s and 923.5 s, respectively; AutoReEngine requires even more time, i.e., 881.3 s for SOAP and 1,238.2 s for REST. Similarly, on the 200K-300K datasets (see Table 7), R-gram outperforms the other two state-of-art methods. On the 2M-3M datasets (see Table 8), R-gram completes message formats on the LDAP dataset in about 2.3 h (8325.8 s), while ProDecoder and AutoReEngine run into out of memory errors and fail to return results after more than 48 h.

Regarding the accuracy of message format extraction, we note that R-gram achieves about the same good performance on all the larger datasets as it achieves on the small-size datasets. For example, R-gram achieves 0.93 F-measure on the small-size LDAP dataset (with 2,181 messages), and it remains achieving 0.927, 0.922 and 0.919 F-measure on the three larger-scale LDAP datasets. This suggests that R-gram’s performance in accurate message format extraction remains stable with the increase of dataset size.

7. Conclusion
In this paper, we have proposed a novel approach, R-gram, for protocol message formats extraction. In our approach, we identify message keywords based on the relative positions of message words and keywords, which addresses the keyword imprecision and high computational cost problems in previous methods. In particular, the consideration of relative positions of words and keywords in messages has enabled us to more accurately distinguish words/keywords at different locations relative to each other, overcoming the issues coming with large variations in message payload lengths. The segmentation of messages into blocks based on a discovered top-level message template has substantially increased the processing efficiency and therefore scalability of R-gram. To evaluate our approach, we have compared it with two state of the art approaches using four datasets from real world systems that correspond to four different application protocols. The experimental results have shown that our approach outperforms existing approaches in accuracy (both precision and recall), efficiency and scalability.

There are a few issues we intend to further explore as future work. As presented in Algorithm 2, a threshold  is required for r-gram keyword extraction. In our experiments, we set  as , where  denotes the number of message types. However, this threshold may miss some keywords in small clusters. For example, Bind and Unbind are rare operations in the LDAP protocol. In thousands of LDAP messages, there might be only a dozen Bind and Unbind messages. For this kind of unbalanced data, R-gram might miss some keywords of the small clusters. Another future work is to address a common drawback faced by existing methods, where the payloads overwhelm the message structure. The payloads can be highly structured, having frequent ‘false keywords’ and structural patterns. The ‘true keywords’ may be out-voted, due to the large number of ‘false keywords’, which leads to inaccurate clustering of protocol messages and eventually inaccurate message formats. These two issues will be the main focuses of our future work.

