Implicit feedback is widely used in collaborative filtering methods for sequential recommendation. It is well known that implicit feedback contains a large number of values that are missing not at random (MNAR); and the missing data is a mixture of negative and unknown feedback, making it difficult to learn users’ negative preferences. Recent studies modeled exposure , a latent missingness variable which indicates whether an item is exposed to a user, to give each missing entry a confidence of being negative feedback. However, these studies use static models and ignore the information in temporal dependencies among items, which seems to be an essential underlying factor to subsequent missingness. To model and exploit the dynamics of missingness, we propose a latent variable named “ user intent ” to govern the temporal changes of item missingness, and a hidden Markov model to represent such a process. The resulting framework captures the dynamic item missingness and incorporates it into matrix factorization (MF) for recommendation. We further extend the proposed framework to capture the dynamic preference of users, which results in a unified framework that is able to model different evolution patterns of user intent and user preference. We also explore two types of constraints to achieve a more compact and interpretable representation of user intents . Experiments on real-world datasets demonstrate the superiority of our method against state-of-the-art recommender systems.
SECTION 1Introduction
Recommender systems have been widely studied and deployed in real-world applications. Nowadays recommender systems become indispensable as they help to alleviate the information overload problem and provide personalized recommendations to meet users’ needs. Collaborative filtering methods based on implicit feedback are widely used in recommender systems. Implicit feedback denotes various sorts of user behaviors that are passively tracked by web applications, such as purchase history, watching habits and browsing activity. Compared with explicit feedback that records explicit input by users regarding their interests in products (e.g., 1-5 star ratings), implicit feedback is more abundant and accessible in real-world applications. However, the missing data problem of implicit feedback also brings two challenges. First, the data is missing not at random (MNAR). Only positive feedback is collected in implicit feedback and all negative feedback is missing, leading to a severely biased dataset. We can not infer valid user preference only based on the observed data. Second, the missing data is a mixture of negative and unknown feedback; a missing entry may indicate the user either dislikes or does not know the item, which makes it hard to learn user’s negative preferences. Several previous works [10], [20] provided evidence that both ignoring missing data and treating all missing data as negative feedback will lead to biased recommendations.

A possible solution is to model the MNAR mechanism and treat the missing data properly. Several researchers have proposed various methods to address this issue. Popular methods [10], [27] are based on the uniformity assumption that assigns a uniform weight to degrade the importance of the missing data, assuming that each missing entry is equally likely to be negative feedback. This is a strong assumption and limits models’ flexibility for real applications. Recently, researchers [14], [39] treated missing entries differently with the so-called “exposure” variables and achieved improved results. An exposure variable indicates whether or not an item is missing to a user. They make predictions in two steps: They first model exposure variables for each user to get the candidate items that are not missing and then recommend top-ranked items in the set of candidate items based on user preferences.

However, these modeled exposure-based missingness mechanisms are static and the temporal dependencies among items are not utilized, which can naturally influence the subsequent missingness greatly. Consider the following example in Fig. 1. If a user has just bought a mobile phone, it is more likely for him/her to buy some phone accessories next so missingness probabilities of candidate phone accessories will be lower than if the user had not bought the phone. Moreover, the effect of item dependencies on the missingness is asymmetric: purchase of phone accessories indicates that the user has probably owned a mobile phone and the missingness probabilities of phones should be high during his/her next purchase. Thus the key to modeling the dynamic missingness is how to utilize the temporal information of implicit feedback to capture the asymmetric item dependencies. Instead of finding explicit item dependencies, we assume that the missingness of items for a user at one time is generated by a latent variable called “user intent”, and that the dynamics of missingness are driven by a Markov process of user intents. In other words, user intents capture item relations implicitly and generate time-sensitive exposure variables.

Fig. 1. - 
An example of asymmetry influence of temporal dependencies among items to the missingness.
Fig. 1.
An example of asymmetry influence of temporal dependencies among items to the missingness.

Show All

Particularly, in this paper, we use a hidden Markov model (HMM) to represent the dynamic missingness of implicit feedback and the estimated missingness of items is incorporated into a probabilistic matrix factorization (MF) model for recommendation. To the best of our knowledge, the proposed framework, namly “H4MF”, as a strategy of “leveraging HMM and MF to model the dynamic Missingness for sequential recommendation,” is the first model to address the dynamic missingness of implicit feedback in recommendation area. The HMM and MF are seamlessly incorporated in H4MF, making the framework interpretable and extensible. A preliminary version of this work previously appeared in our work [38], but its static user preference assumption limits its effectiveness for sequential recommendation. We propose a novel approach to capturing dynamic user preference with an efficient approximate method. We select extra two baseline methods and offer more detailed analysis with additional experiments. The major contributions of our work are summarized next:

We provide a principled approach to model dynamic missingness of implicit feedback for sequential recommendation. The modular design (user intent and user preference) and the technique choice (HMM and MF) make H4MF more interpretable and extensible.

We extend the proposed framework to capture the dynamic preference of users, which results in a unified framework that is able to model different evolution patterns of user intent and user preference.

We introduce two types of item constraints for the missingness variables to make user intents less redundant. The compact user intents can promote the recommendation performance and provide meaningful interpretations.

We conduct extensive experiments on three real-world recommendation datasets to demonstrate the effectiveness of the proposed framework.

The rest of the paper is organized as follows: In Section 2 we present a brief review of related work. We introduce the problem definition, our proposed model and its parameter inference in Section 3. Next, we present item constraints on items to learn compact user intents in Section 4. A variety of experimental results and analysis are presented in Section 5. Finally, we provide some concluding remarks and suggestions for future work in Section 6.

SECTION 2Related Work
In this section, we briefly review some related work on the problems of missing data and sequential recommendation.

2.1 Missing Data
Missing data presents a common challenge for empirical sciences. Little and Rubin [16] divided missing data into three categories: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). MCAR occurs if the missingness mechanism is independent both of observable variables and unobservable variables, and MAR occurs if the missingness is random given the complete information of observable variables. MNAR is data that are neither MCAR nor MAR. Most prior studies on recommender systems assumed data are missing at random (MAR); however, Marlin and Zemel [20] demonstrated that data in real recommender systems are not MAR and recommendation algorithms based on MAR assumption may lead to biased results.

Several studies have modeled different missingness mechanisms to address the MNAR problem. For explicit feedback, a widely accepted mechanism [9], [15], [20], [21] is that missingness is related to the potential ratings (e.g, 1-5 star ratings). Data for items with high ratings are less likely to be missing compared to items with low ratings. Marlin and Zemel [21] proposed a missing model for modeling MNAR rating data in collaborative filtering. The missing model used a Mixture of Multinomials, assuming that there are K clusters of users and each item has K multinomial rating distributions associated to it. Ling et al. [15] incorporated probabilistic matrix factorization with two response models to address the MNAR problem for recommendation; one response model adopted a rating dominant approach based on Bernoulli distribution and the other model utilized context information with ratings to model missingness via a logistic function. Hernández-Lobato et al. [9] proposed a missing data model based on matrix factorization for collaborative filtering, which captured dependencies between the missing data and the observation process. For implicit feedback, some researchers [2], [14], [33], [39], [48] explored techniques of causal inference and achieved promising results. Schnabel et al. [33] propose an empirical risk minimization approach to learn unbiased estimators from biased rating data. The propensity score depends on user’s preference and is a self selection. Yang et al. [44] consider popularity bias and learn unbiased estimator with an Inverse-Propensity-Scoring technique. Liang et al. [14] propose a Bayesian model to capture propensity score by user exposure. They first model user exposures toward each item to infer the missingness probability and then recommend top-ranked items based on user preference and user exposure. Wang et al. [39] utilized social information to model the user exposures, proving that social information has an influence on the MNAR problem. The above-mentioned works ignored that the influence of temporal information to the missingness. Different from these studies, we address the MNAR problem with a dynamic missingness assumption.

2.2 Sequential Recommendation
Sequential recommendation utilize temporal information to model user dynamic behaviors for next-item recommendation. Since historical behaviors in different time periods have different effects on users’ behaviors, the importance of sequential information in recommender systems has been gradually recognized by researchers [17].

A widely used approach is to utilize Markov chains [8] to model the sequential information. Rendle et al. [30] proposed a factorized personalized Markov chain (FPMC) model that combines both a common Markov chain and a matrix factorization model. Sahoo et al. [31] chose a hidden Markov model to capture the dynamic of user preferences for personalized recommendation. Wang et al. [40] proposed a hierarchical representation model (HRM) fot next-item recommendation; they used a nonlinear max pooling operation to depict the interactions among multiple factors. timeSVD++ [11] presented a temporal model for the matrix factorization approach by introducing time-variant biases for each user and each item. TMF [47] modeled the evolution by a latent transition matrix that captures the time-invariant property of user’s temporal dynamics. There are several matrix factorization based methods that address the dynamic preference problem. Some researchers [3], [28] also utilized Poission factorization to handle dynamic user preferences, which has rigorous statistical properties such as sparse representation and ability to capture the long-tailed user activities. Recently, Recurrent Neural Networks (RNN) based methods have have achieved satisfactory performances in sequential prediction [18], [26], [37], [45]. Combined with the multiple external information, RNN can predict a user’s next behavior more accurately [17]. Some other researchers also used extensions of RNN (e.g., LSTM [42] and GRU [5]) for sequential recommendation. However, the deep learning related works are limited in interpretability.

One common drawback of the above-mentioned studies is that they do not consider the MNAR problem and the missing data problem is not well explored. In this paper we model the dynamic missingness for the MNAR problem, and incorporate it with collaborative filtering techniques for sequential recommendation.

SECTION 3Our Proposed Framework
In this section, we first introduce the problem formula and model settings. Then we describe our framework with static user preference and with dynamic user preference separately. After that we detail the parameter inference and the prediction formula. We give the notation in Table 1.

TABLE 1 Notation
Table 1- 
Notation
3.1 Problem Formulation
Suppose we have N users and M items. For each user i, a T-length rating history in chronological order is given as Yi={y1i,y2i,…,yTi}, where yti denotes the item that user i rated at time t (Note that the rating denotes implicit feedback in this paper). The goal of recommender systems is to predict which item the user will rate next, more specifically, yT+1i.

Before describing our model, we first introduce the representation of yti and the definition of missingness variables, which can help to understand the proposed dynamic missingness mechanism. We represent yti as a M×1 rating vector. As one user can only rate one of M items at one time, there is a “1” in one position of yti and “0” elsewhere. Thus the missing data of implicit feedback refers to “0” entries, which contain negative and unknown feedback. For each ytij in dataset, we use a Bernoulli missingness variable αtij (same as the exposure variable in [14]) to indicate the missingness: αtij=1 means item j is exposed to user i at time t, and αtij=0 means the user does not see the item. The missingness variables have a reasonable interpretation: users first have to see the items, then they have the possibility to rate them. Thus αtij can be utilized to extract negative feedback from the missing data: if user i has seen item j (αtij=1) but the rating ytij is 0, this rating is more likely to be negative feedback rather than unknown feedback, which can be further utilized to learn user preference. Note that αtij may be different for different t and our model aims to capture its dynamics.

3.2 H4MF With Static User Preference
We assume that user intent and user preference work together for recommendation: User intent determines the missingness of items and user preference determines recommendations from the non-missing items. In this paper we propose a framework named “H4MF” that combines HMM and MF to model the dynamic Missingness for recommendation. As shown in Fig. 2, H4MF has two components: the User Intent Component and the User Preference Component. In the User Intent Component we use a first-order hidden Markov model to capture the missingness mechanism. αt is a M×1 missingness vector of items at time t generated by a latent state variable St (named “user intent”), and the probability of St depends only on the last state St−1. The user intent is a single categorical random variable that can take one of D discrete values, St∈{1,…,D}. We assume that user intents are shared by all users so the generated αtj represents αtij for all possible users. The state transitions follow a categorical distribution and the conditional observation distribution is defined as:
p(yti|St,P)=∏j=1M∑αtijp(ytij|αtij,Pij)p(αtij|St),  αtij∈{0,1}.(1)
View Source


Fig. 2.
Graphical model of H4MF with static user preference.

Show All

In the User Preference Component, we adopt a classical but effective matrix factorization model [23]: the user preference P∈RN×M is decomposed as a product of two submatrices U∈RK×N and V∈RK×M, which represent user-specific and item-specific latent feature factors respectively. More specifically, we use Pij=UTiVj to show the preference of user i toward item j. The conditional distribution over the observed ratings Yti∈R1×M (the likelihood term) for user i and the prior distribution are given by:
 p(Yi|αTi,P)=∏t=1T∏j=1M[αtijN(ytij|Pij,λ−1y) +(1−αtij)I[ytij=0]], p(αtij|St)=Bernoulli(μStj),  μtj∼Beta(at,bt), p(U|λu)=∏i=1NN(Ui|0,λ−1uIK), p(V|λv)=∏j=1MN(Vj|0,λ−1vIK),(2)
View Sourcewhere N(x|μ,λ) denotes the Gaussian distribution with mean μ and precision λ, I[ytij=0] is the indicator function that evaluates to 1 when ytij=0 is true, and 0 otherwise. μStj indicates that μtj is St-specific. IK stands for the identity matrix of dimension K. p(Yi|αTi,P) can be interpreted as follows: when αtij=0, the rating is missing so ytij is definitely 0; when αtij=1, the rating is not missing so ytij is either 0 or 1, depending on the user preference Pij. In this paper we present our method and its inference for the case of one user’s sequential records; but it is straightforward to apply them to multiple user cases. Note that users have variable-length rating records so that T is not a fixed number for different users.

Next we explain the underlying design of H4MF. We choose HMM for user intent because HMM can well utilize the temporal data to mine the asymmetric item dependencies; and the latent states (user intents) can be shared by all users, which simplifies the structure of the missingness mechanism. We choose MF for user preference because MF can model a low dimensional representation for both users and items, which has been proved effective in recommender systems. Meanwhile, H4MF is more explainable and reasonable with this modular structure. Most existing sequential recommendation algorithms [34], [43] only used “dynamic preference” to account for the temporal user behaviors; they assumed time-varying user preference is the only cause for the noisy user behaviors. In this case the learned user preference will fluctuate rapidly and be difficult to explain.

Although choosing a dynamic preference model will make H4MF more reasonable, we assume user preference to be static for two main reasons: 1) User preference evolves steadily and is rather stable compared to user intent. [25] visualized dynamic user preference via trajectories. Their results show that user preferences change steadily and slowly in a long time (month level), especially for older users. In contrast, user intent changes every user-item interaction in H4MF. So it is reasonable to choose static preferences in H4MF. 2) Simplicity for inference is a concern. As our goal to explore the effects of dynamic missingness to recommender systems, MF is also fair for comparison to baselines.

3.3 H4MF With Dynamic User Preference
In this section we will explore dynamic user preference in H4MF. Dynamic user preference is widely explored in sequential recommendation and is more reasonable compared with static user preference in a real-world setting. Unlike user intents that change every user-item interaction, user preferences evolve steadily and slowly in a long time [25]. So we assume that there are Z time windows, which were divided evenly from the very beginning to the very end of the whole dataset, and user preferences change from one time window to another time window, but keep static in a single time window. More specifically, the user preference feature Uz at time window z is dependent on the user preference feature Uz−1 at time window z−1. We use a linear mapping to capture a possible gradual drift of use preference. Let Bi∈RK×K denotes the transition matrix of user preference for user i, we model the temporal dependence via Uz=Uz−1Bi (B∈RN×K×K is the transition hypermatrix for all users). As for the item latent features Vj, we assume item features are stable and fix them as time-invariant variables. Fig. 3 shows the graphical model of H4MF with dynamic user preference.


Fig. 3.
Graphical model of H4MF with dynamic user preference (H4MFD). Note that one time window z may contain multiple observed ratings Y.

Show All

Similar to H4MFS, we adopt a probabilistic linear model with Gaussian observation noise. We define the conditional distribution over the user preference as
p(P|U,V,σ)=∏z=1Z∏i=1N∏j=1MN(Pzij|(Uzi)TVj,σ2),(3)
View SourceRight-click on figure for MathML and additional features.where item feature V is defined in Eq. (2). Then the conditional distribution over the observed ratings becomes:
 p(Yi|αTi,P)=∏z=1Z∏t=Ts(z)Te(z)∏j=1M[αtijN(ytij|Pzij,λ−1yIK) +(1−αtij)I[ytij=0]],(4)
View SourceRight-click on figure for MathML and additional features.where Ts(z) is the start time in time window z and Te(z) is the end time in time window z. To model the user features, we place Gaussian priors with mean Uz−1Bi on user latent feature Uz and assume that the latent user feature Uzi of user i at time z is a linear combination specified by the rows of Bi, of the user’s latent vector Uz−1i at time z−1, that is
p(Uzi|Uz−1i,Bi,σU)=N(Uzi|Uz−1iBi,σ2UI),(5)
View SourceRight-click on figure for MathML and additional features.where we define p(U1|U0,Bi,σU)=N(U1|0,σ2UI) by setting U0i=0. Then the conditional distribution of user latent features U becomes:
p(U|B,σU)=∏z=1Z∏i=1Np(Uzi|Uz−1i,Bi,σU)=∏z=1Z∏i=1NN(Uzi|Uz−1iBi,σ2UI).(6)
View SourceRight-click on figure for MathML and additional features.

We model the temporal dependence for each user i through a transition matrix Bi∈RK×K, where K is the dimensionality in the latent space. Bi follows a matrix normal distribution, which is defined as:
p(B|σB)=∏i=1NMN(Bi|I,σBI,σBI).(7)
View SourceRight-click on figure for MathML and additional features.We denote H4MF with dynamic user preference as H4MFD.

Note that the time window z is different from the time order t in last subsection. z denotes one time period and t denotes one time order. In other words, user intents evolve more rapidly than user preferences and H4MFD can model different patterns of dynamics. The idea of user preference transition is similar to that of hidden Markov model. The reason why we choose current “dynamic version” of matrix factorization rather than another HMM model for user preference is that matrix factorization can model low representations of both user side and item side.

3.4 Parameter Inference
Parameter Inference for H4MFS. We choose expectation-maximization (EM) to find the maximum a posteriori (MAP) estimations of the parameters of H4MF. In the E-step, we compute the expected log posterior of the observed data and the user intents, which is:
 logp(αTi,P|ST,Yi)∝logp(Yi|αTi,P)+logp(αTi|ST) +logp(ST)+logp(P)(8)
View SourceThe logp(P) is computed as logp(U|λu)+logp(V|λv) and logp(αTi|ST) is computed as logIs(μtj)+logp(Is(μtj)|at,bt); we add a prior to regularize the μtj. As the exact expectation of HMM is computationally intractable, we use Gibbs sampling to infer the posterior probabilities of St. For a given rating sequence {Yti} by user i. St is sampled from
p(St|St−1,St+1,Yi,αti,P)∝p(St|St−1)p(St+1|St)p(yti|αti,P),(9)
View Sourcewhere p(St|St−1) and p(St+1|St) can be obtained from the state transition matrix of the HMM, and the expectation of log likelihood of one rating record yti is given by:
 logp(yti|αti,P) =∑j=1Mlog(ytijμtjN(1|UTiVj,λ−1y)N(0|UTiVj,λ−1y)+N(1|UTiVj,λ−1y)+ (1−ytij)(1−μtj+μtjN(0|UTiVj,λ−1y)N(0|UTiVj,λ−1y)+N(1|UTiVj,λ−1y))).(10)
View SourceRight-click on figure for MathML and additional features.

In the M-step, we maximize the log posterior with respect to μ, U, V, and {St}. We use gradient ascent to update μ, and compute optimal U and V by setting their derivatives to zero. For μ, we choose the gradient ascent method. The gradient of μtj for one rating point ytij is:
∂L∂μtj=(1−ytij)Qij−1μtj(Qij−1)+1+ytij1μtj+at−1μtj−bt−11−μtj,(11)
View Sourcewhere Qij=N(0|UTiVj,λ−1y)N(0|UTiVj,λ−1y)+N(1|UTiVj,λ−1y). This process is repeated until convergence. For U and V, we set their derivatives to zero and get the following update formulas:
Ui←(λy∑jα¯ijVjVTj+λVIK)−1(∑jλyα¯ijytijVj),(12)
View Source
Vj←(λy∑iα¯ijUiUTi+λUIK)−1(∑iλyα¯ijytijUi),(13)
View SourceRight-click on figure for MathML and additional features.where
 α¯ij=μ¯ijN(0|UTiVj,λ−1y)μ¯ijN(0|UTiVj,λ−1y)+1−μ¯ij, μ¯ij={μtij,∑Dd=1μdj/D,if ytij=1otherwise(14)
View SourceRight-click on figure for MathML and additional features.When ytij is not rated (ytij=0), the μ¯ij is set as the average of all possible μdj.

Note that we update U and V and fix the hyperparameters λu, λv, and λy. This strategy follows the original PMF [23] for simplification. For user intents {St}, we use the Baum-Welch algorithm [7] to update the transition matrix and initial states probability distribution of the HMM; as a strict EM-type algorithm it is guaranteed to converge to at least a local maximum.

Parameter Inference for H4MFD. We also use EM mehods to estimate the parameters. The objective function to be maximized is the same as eq. (8) except the user preference component. The user intent component of H4MFD is the same as that of H4MFS. So in this section we describe the parameter inference of the user preference component. In the E-step, the log posterior of user preference logp(P) can be approximated by
logp(U,V,B|P,σ,σU,σV,σB)∝logp(U|,σU)+logp(V|σV)+logp(B|σB)+logp(P|U,V,σ)(15)
View SourceRight-click on figure for MathML and additional features.

For a given rating sequence {Yti} by user i, the expectation of log likelihood of one rating record yti in time window z is given by:
 logp(yti|αti,Pz) =∑j=1Mlog(ytijμtjQzij+(1−ytij)(1−μtj(1−Qzij)))(16)
View SourceRight-click on figure for MathML and additional features.where Qzij=N(0|(Uzi)TVj,λ−1y)N(0|(Uzi)TVj,λ−1y)+N(1|(Uzi)TVj,λ−1y).

In the M-step, maximizing the log posterior of eq. (15) is equivalent to minimizing the sum-of-squared-errors objective function with quadratic regularization terms:
 λy2∑z=1Z∑t=Ts(z)Te(z)∑i=1N∑j=1M(α¯ijytij−α¯ij(Uzi)TVj)2+λv2∑j=1M∥Vj∥2 +λu2∑z=1Z∑i=1N∥Uzi−Uz−1iBi∥2+λB2∑i=1N∥Bi−I∥2(17)
View SourceRight-click on figure for MathML and additional features.We adopt gradient descent with learning rate η in U, V and B to find the local minimum of the objective function. The gradients of the parameters are as follows:
 ∂L∂Uzi=λu(Uzi(1+Bzi)−(Uz+1i+Uz−1i)Bi) −∑z=1Z∑j=1M(α¯ijytij−α¯ij(Uzi)TVj)Vj, ∂L∂Vj=λvVj−∑z=1Z∑j=1M(α¯ijytij−α¯ij(Uzi)TVj)Ui, ∂L∂Bzi=λB(Bi−I)−λu(Uzi(1+Bzi)−(Uz+1i+Uz−1i)Bzi),(18)
View SourceRight-click on figure for MathML and additional features.Note that Uz+1i is a zero matrix when z=Z because Z is the latest time window. As there are too many hyperparameters (i.e., σ,σU,σV,σB), it is hard to search best values. One possible solution is to extend current model to a full Bayesian version, which has shown its effectiveness [32].

3.5 Making Prediction
In the recommendation phase we are interested in the prediction of yT+1ij for user i given his/her previous rating records. In H4MFS, we make predictions by integrating out the uncertainty from the missing variable αT+1j:
Ey[yT+1ij|Pij] =Eα[Ey[yT+1ij|αT+1j,Pij]] =∑αT+1j∈{0,1}p(αT+1j) Ey[yT+1ij|αT+1j,Ui,Vj] =μT+1j⋅UTiVj,(19)
View SourceRight-click on figure for MathML and additional features.where μT+1j is determined by the next user intent ST+1, which can be predicted with the forward algorithm of HMM. In H4MFD, we use the newest user preference UZ for prediction, that is,
Ey[yT+1ij|Pij]=μT+1j⋅(UZi)TVj,(20)
View SourceRight-click on figure for MathML and additional features.In experiments we focus on the next items that users will interact, so we assume the user preference will not change during his/her next interaction. The prediction formula would be μT+1j(UZiBi)TVj if the future interactions are in the next time window.

SECTION 4Further Constraints on Items
Currently all missingness variables αtj share the same Beta priors as defined in Eq. (2). One limitation here is that the exposure variable αtj is determined by at and bt, which are independent of item index j. Since user intents can be reused, items under the same user intent tend to have similar missing probabilities. In this section we define two kinds of constraints, namely inner constraint and outer constraint, to specialize the Beta priors of missingness variables of different items under different user intents. The intuitions are simple but reasonable: we assume that items under the same user intent have correlated exposure variables (e.g., phones and chargers). We use the inner constraint to denote the influences from other items under the same user intent to one item’s missingness. Meanwhile, the missingness of one item under different user intents should follow some patterns to resolve the redundancy (e.g., a dress under party and wedding intents should be different). And we use the outer constraint to denote the influences from the same item under different user intents to one item’s missingness. Fig. 4 shows a graphical representation of item constraints.

Fig. 4. - 
A graphical representation of item constraints. C$_{in}$in denotes inner constraints and C$_{ou}$ou denotes outer constraints.
Fig. 4.
A graphical representation of item constraints. Cin denotes inner constraints and Cou denotes outer constraints.

Show All

We adopt a simple implementation: we update the Beta priors in every M-step as follows:
adnew←adini+σdjλInner+ωdjλOuter,bdnew←bdini+λInner+λOuter,d∈{1,…,D}(21)
View SourceRight-click on figure for MathML and additional features.Where adini and bdini are initial Beta priors, λInner and λOuter are the scale parameters, σdj=#recordsofitemjunderuserintentd#totalrecordsunderuserintentd indicates the occurrence probability of item j with respect to other items under user intent d, and ωdj=#recordsofitemjunderuserintentd#totalrecordsofitemj indicates the occurrence probability of item j that is “triggered” by user intent d. Then the ad and bd are not global constants during the EM procedure and play a constraint role. The items with similar occurrence probabilities under the same user intent will have similar Beta priors. Instead of putting constraints directly on μdj, this strategy can avoid sophisticated inferences and later experiments prove its effectiveness. In experiments we denote this constrained version as H4MFc. Note that the item constraints are designed to compact the user intents and are independent from user preference component, H4MFc can be seamlessly integrated with static and dynamic user preference assumptions, which we call H4MFcS and H4MFcD, respectively.

SECTION 5Experimental Results
In this section we describe the used datasets and experimental settings, evaluate the performance results, and analyze the user intent and the item constraints.

5.1 Datasets and Settings
We evaluate the performance of our method on three real-world datasets: 1) MovieLens-100K dataset1 (∼100 thousand ratings from 943 users on 1,682 movies). The dataset was collected during the seven-month period from September 19th, 1997 through April 22nd, 1998. 2) MovieLens-1M dataset2 (∼1 million ratings from 6,040 users on 3,706 movies). The dataset was collected from April 25th, 2000 through February 28th, 2003. 3) LastFM dataset3 (∼100 thousand ratings from 1,892 users on 17,632 movies). The time period is from August 1st, 2005 through May 1st, 2011. We transform the two MovieLens datasets into implicit data by setting ratings that are ≥3 to “1” and the others to “0”. In H4MFD, we set time windows Z=10 and partition each of the dataset evenly with an interval defined by its max and min timestamp difference divided by 10. The last time window is used for testing. The statistics are shown in Table 5.

TABLE 2 Performance of Different Models on MovieLens-100K
Table 2- 
Performance of Different Models on MovieLens-100K
TABLE 3 Performance of Different Models on MovieLens-1M
Table 3- 
Performance of Different Models on MovieLens-1M
TABLE 4 Performance of Different Models on LastFM
Table 4- 
Performance of Different Models on LastFM
TABLE 5 Dataset Statistics

We then choose the following six prevalent methods for comparison, including: (1) PMF [23], a classical matrix factorization approach that is widely applied as a benchmark. (2) WMF [10], a standard matrix factorization model for implicit data, which uses a simple heuristic where all unobserved user-item interactions are equally down weighted against the observed interactions. (3) FPMC [30], a sequential recommendation algorithm based on personalized transition graphs over underlying Markov chains. It used a variant of Bayesian Personalized Ranking (BPR) [29] for optimization. (4) ExpoMF [14], a probabilistic approach that incorporates user exposure to items into collaborative filtering. (5) timeSVD++ [11], a temporal model that extends the matrix factorization approach by introducing time-variant biases for each user and each item. (6) RNN-CCE [6], a recurrent neural networks based recommendation algorithm. At each time step, the input is the one-hot encoding of the current item, and the final output is a fully-connect layer with a neuron for each item in the catalog. The baselines are chosen for the following reasons: PMF and FPMC can been seen as sub-models of H4MFS, while they overlook the missing data problem. WMF treats the missing data as a MAR problem. ExpoMF takes a static method to the MNAR problem. The main goal of the experiments is to show that how we treat the missing data makes a difference. As for timeSVD++ and RNN-CCE, they utilize temporal information for recommendation. Compared with H4MFD, these two methods focus on modeling dynamic user preferences and ignore the missingness mechanism.

We adopt Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG) to measure the item ranking accuracy of different algorithms. HR measures whether the ground truth item is present on the ranked list, while NDCG measures the ranking quality by considering the positions of hits. The definitions of HR and NDCG are as follows:
HR@n=∑u∈UI(Tutu⋂R(u)≠ϕ)|U|,NDCG@n=1Nn∑j=1n2I(Rj(u)∈Tutu)−1log2(j+1).(22)
View SourceRight-click on figure for MathML and additional features.where Ru is the recommended item list for user u, ϕ denotes the empty set, U is the user set, I(⋅) is an indicator function, and Nn is a constant which denotes the maximum value of NDCG@n given R(u). In our study we always report the averaged HR and NDCG across users. We split the dataset for experiments with the following strategy: we first sort the historical ratings of each user by time order. Then the last records of users are used as test data, the second last records are used as validation data, and the remaining records are used for training. We search for the optimal parameters to maximize the performance on validation data and evaluate the model on test data. For the parameters of baseline models, we refer to their original papers and follow their tuning strategies.

5.2 Analysis of Prediction Performance
We report the performance of our methods and baseline models with optimal parameters. For PMF, we set K=10. For WMF, we set K=10, α=0.4. For ExpoMF, we set λθ=0.01, λβ=0.01, λy=0.01, and K=30. For time SVD++, we set α=0.05, β=0.9, and K=15. For RNN-CCE, we set hidden units = 20, learning rate = 0.01, and use the Adam optimizer. For our models, we set λθ=0.1, λβ=0.1, λy=0.1, K=30, adini=1, and bdini=2. For item constraints, λOuter is set as 1, and λInner is set 10, 1, and 0.1 for MovieLens-100K, MovieLens-1M, and LastFM, respectively. We show the performance of our methods with other baseline models in Tables 2, 3, and 4.

As shown in the results, H4MFcD achieves higher item ranking accuracy than the other compared algorithms due to the capability of better capturing the missingness of implicit feedback. Note that PMF, WMF, ExpoMF, H4MFS, and H4MFcS model user preference similarly: they all use a basic matrix factorization method and the main difference is the way they model the missing data. Moreover, they all assume a static user preference, which may be a potential drawback when it comes to sequential recommendation. PMF performs poorly because the datasets are sparse and all the missing entries are treated as negative feedback. So the positive feedback is overwhelmed by negative feedback, leading to a biased user preference learning. FPMC has the same reason for its poor performance. Besides, it is originally proposed for next-basket recommendation. Here we set basket size as 1 as we do not have basket information, which also limits the effectiveness of FPMC. WMF is better than PMF as it treats the missing data with a globally fixed low confidence. ExpoMF models exposure variable αui for every user-item pair so it can capture more information from the missing data compared to WMF and PMF. H4MFS is better than ExpoMF because it considers the dynamic missingness of items. Note that the experimental results of WMF, ExpoMF, and H4MFS are very close; WMF even beats WMF and H4MFS on LastFM. This is because modeling missingness for each missing entry adds model complexity and is prone to overfitting. On the other hand, the superiority of H4MFcS compared to H4MFS proves the effectiveness of the user intent constraints.

As for dynamic user preference based models, we can see that timeSVD++ is the worst baseline model; it only performs better than PMF and FPMC. The main reason is the way timeSVD++ utilizes temporal information. The time deviation function of timeSVD++ is rather heuristic and lacks theoretical analysis. Moreover, timeSVD++ does not address the missing data problem in sequential recommendation. RNN-CCE achieves a competitive performance against other methods, including our proposed H4MF. RNN-CCE can learning better representations, which is the advantage of deep learning techniques. However, the common drawback of deep learning related methods are lack of explanations. They are rather “black box” algorithms. In contrast, H4MF can provide interpretable recommendations and its modular design can make the model more extensible, which we will discuss later. H4MFcD and H4MFD beat H4MFcS and H4MFS, separately, showing that a dynamic user preference setting is superior than a static user preference. This meets our expectation that in sequential recommendation user preference changes dynamically.

5.3 Analysis of User Intents
Compared with traditional recommendation methods that only use user preference to provide explanations, the learned user intents of H4MF can provide intuitions from another aspect. In this section we study the user intents in three aspects: recommendation overlaps, sensitivity of user intent number, and interpretation of user intents.

Recommendation Overlaps. In H4MF, we use user preferences and user intents for recommendation. User intents determine the candidate sets of items that users will be very likely to interact with. As we have shown the superiority of H4MF on prediction accuracy, we can also evaluate how well the user intents contribute to the improvements. Ideally a user will be recommended with totally different items under different user intents. So we explore the effectiveness of user intents as follows: For a particular user with fixed preference, we sample different user intents and see how different are the recommendation lists. We use the term “recommendation overlap” to denote the ratio of common items in Top-N recommendation lists generated by two different user intents. A large recommendation overlap indicates that the two user intents have similar missingness mechanisms and they don’t contribute much to the sequential recommendation as expected. We choose N=10 and show the average of recommendation overlaps across users in Table 6. We can see the recommendation overlaps of H4MFcS are much smaller than those of H4MF, proving that the item constraints can reduce the redundancy of user intents. That is, the user intents in H4MFcS are more effective than those of H4MF. Meanwhile, the recommendation overlaps decrease both in H4MF and in H4MFcS when D increases. This result conforms to our expectations because our methods can capture more aspects of user intents with a large D.

TABLE 6 Recommendation Overlaps of Different User Intents on Three Datasets

Interpretation of User Intents. Besides improving the prediction accuracy, user intents could also be utilized to interpret user behaviors and provide explainable recommendations. Table 8 shows a recommendation example of one user in Movielens-100K under two different user intents. From the results we can see the genres of recommended movies under user intent 1 are mainly about “Crime” and “Action”, but the genres under user intent 2 are mainly about “Comedy”, “Romance”, and “Drama” (Note that the genre information is not used in model training). Thus we can infer that the user mainly has two tastes in movies. As H4MF can predict the user’s next user intent, we will know which genres the user want to see next and provide more precise and interpretable recommendations. The main advantage of H4MF in interpretability is two-folds: to improve user experience and to make the model more controllable. Studies [1], [36] show that recommendation explainability can help users make much more accurate decisions, improve user acceptance of recommendations, and enhance trustfulness in the recommender system. We can display the user intents to convince consumers as explanations can promote sales; When tuning or extending our models, the user intent of H4MF is available for inspection, making the model more controllable than traditional “black box” algorithms.

TABLE 7 Experimental Results of H4MFcSSc on Pruned Movielens-1M Dataset
Table 7- 
Experimental Results of H4MF$_{S}^{c}$Sc on Pruned Movielens-1M Dataset
TABLE 8 Top 10 Recommendations for One User on Movielens-100K Under Two User Intents

Sensitivity of User Intent Number. The number of user intents D is vital to the performance of H4MF, which influences the dynamic missingness mechanism. We varied D to train our proposed H4MF methods and presented the prediction results in Figs. 6 and 7. From Fig. 6 we can see that H4MFcS performs consistently better than H4MFS on all the three datasets. From Fig. 7 we can draw the same conclusion about H4MFcD and H4MFD. The optimal D is between 2−3 for the four methods on three datasets. When D increase after D=3, the performance decreases monotonously. Note that in last paragraph we find that the recommendation overlaps decreases when D increase; but this does not guarantee the recommendation performance because a large D will also add model complexity. Meanwhile, we can see the optimal user intent number does not change when we change the static user preference assumption to the dynamic user preference assumption (H4MFS to H4MFD and H4MFcS to H4MFcD). This finding shows the stability of the user intent component, which is an advantage of our modular design.

Fig. 5. - 
Movie genre distribution in Movielens-1M.
Fig. 5.
Movie genre distribution in Movielens-1M.

Show All

Fig. 6. - 
Performances of H4MF$_S$S with different numbers of user intents ($D$D).
Fig. 6.
Performances of H4MFS with different numbers of user intents (D).

Show All

Fig. 7. - 
Performances of H4MF$_D$D with different numbers of user intents ($D$D).
Fig. 7.
Performances of H4MFD with different numbers of user intents (D).

Show All

The current optimal D is 2 for all the three datasets. The number of user intents is closely related to the groups (or categories) of items and we assume movie genres as labels to distinguish movies. Then we further explore the relation between the user intent number and the movie genre distribution. Fig. 5 shows the movie genre distribution in Movielens-1M. We can see that genres are unbalancedly distributed and two genres (”Drama” and ”Comedy”) dominated the dataset. Moreover, the rating record of movies with ”Drama” or ”Comedy” genre is 638,838 in the 1 million dataset (63.88 percent), which accounts for the optimal number of the user intent. We then delete the ratings related to ”Drama” or ”Comedy” genre, and run the experiments on H4MFS to check the effectiveness of user intents. The results on Table 7 show that the optimal D is 3. One explanation is that the dominating genres are ”Action”, ”Thriller”, and ”Romance” after deletion. The settings of this additional experiment is rather heuristic and we choose Movielens-1M as it has sufficient data after pruning. But the goal of this experiment is to show the item distribution plays a role in the underlying number of user intents, which is worth further exploring.

5.4 Effectiveness of Item Constraints
To evaluate the effectiveness of item constraints, we tune the λInner and λOuter to observe how they influence the HR@50 of H4MFc. We fix other parameters as described in Section 5.2 and show the results in Figs. 8 and 9. In both H4MFcS and H4MFcD, the optimal parameters are λInner=10, λOuter=1 for Movielens-100K, λInner=1, λOuter=1 for Movielens-1M, and λInner=0.1, λOuter=1 for LastFM. The optimal λOuter is around 1 for all the three datasets; When it increases, the HR@50 decreases dramatically. Meanwhile, the optimal λInner varies across datasets and the performance is less sensitive to the change of λInner. One main reason is that the total item records under user intents are huge when we have a small D. So the ratio measure σdj is very small for all items and there are fewer differences among different σdj, which limits the effectiveness of λInner. The black dashed lines are the performances of H4MF (λInner=0 and λOuter=0). We can conclude that H4MFc can achieve improvements with proper constraints, which supports the effectiveness of the two item constraints.

Fig. 8. - 
Effectiveness of $\lambda _{\mathrm{Inner}}$λ Inner  and $\lambda _{\mathrm{Outer}}$λ Outer  in H4MF$^{c}_{S}$Sc.
Fig. 8.
Effectiveness of λInner and λOuter in H4MFcS.

Show All

Fig. 9. - 
Effectiveness of $\lambda _{\mathrm{Inner}}$λ Inner  and $\lambda _{\mathrm{Outer}}$λ Outer  in H4MF$^{c}_{D}$Dc.
Fig. 9.
Effectiveness of λInner and λOuter in H4MFcD.

Show All

5.5 Discussions
In this section we first discuss the extensibility and efficiency of H4MF, and then discuss utilization of item relations in recommendation.

Extensibility. User intent and user preference can be seen as a factorization of user behavior, which makes H4MF more modular and extensible. We can extend one component without considering the other component. Moreover, both HMM and MF are well studied techniques and their variants can bring insights into H4MF. For example, we can use local low-rank MF [12] and mixture-rank matrix approximation [13] to learn user preference by exploiting the underlying group information of users and items. We can also use hidden semi-Markov model [46] to model the durations of user intents: it is always the case that users purchase serveral items to meet one intent. Several sequential recommendation algorithms [34], [43] used the words “long-term and short-term preference” to denote the two kinds of factors that account for the user behaviors. By contrast, our setting “user intent and user preference” is more reasonable and acceptable. Note that in H4MF the user intent and user preference are conditionally independent given the observed feedback {Yt} (can be inferred from Figs. 2 and 3). This condition is a bit strong in reality and the relations between user intent and user preference needs further exploring.

Efficiency. A potential limitation of H4MF is the time complexity. The inference of the HMM is a bottleneck; its theoretical complexity is O(T^D2) for each iteration of the EM method, where T^ is the length of training data and D is the state number. The experimental runtime results in Table 9 also reveal that the runtime increases dramatically when D and T^ increase. A straightforward solution to reduce the runtime is to apply stochastic gradient descent rather than the current inference method. However, the comparison of the two inference methods is beyond the scope of our paper. In real-world applications customers’ data are collected accumulatively, so the T^ will become very large. One of the possible extensions is to devise an online version of H4MF. Currently there are several studies related to the online learning of HMM and MF [19], [24], which can be utilized to make H4MF more scalable.

TABLE 9 Runtime results of H4MFcSSc
Table 9- 
Runtime results of H4MF$_S^{c}$Sc
Item Relations in Recommendation. Most recommendation algorithms mainly focus on mining and utilizing the information of item similarity. However, item similarity may lead to meaningless recommendations (e.g., the phone and phone case example in introduction). The key to address this issue is to find asymmetric relations of items. Several researchers [22], [41] proposed methods to discriminate substitutes and complements from similar products. But their methods are supervised and the ground truth of labels are directly extracted from user log files, which may contain biases and noise. A more principled approach is to apply techniques of causal discovery to find the directed relations among items. However, current techniques of causal discovery (e.g, modified PC [35] and GES [4]) may not work well on the recommendation data as they are extremely sparse and MNAR. Instead in our model, the asymmetric relations of items are revealed from the temporal data by the dynamical missingness mechanism. In this regard our H4MF can be seen as a step toward causality-based recommendations from similarity-based recommendations.

SECTION 6Conclusion
In this paper we aim to model and leverage properties of dynamic item missingness to improve recommendation. We proposed a framework that seamlessly combines HMM and MF to model the dynamic missing mechanism of implicit feedback for sequential recommendation. We extend the proposed framework to capture the dynamic preference of users, which results in a unified framework that is able to model different evolution patterns of user intent and user preference. To make the user intents less redundant, we introduced two types of constraints for the missingness variables. Empirical results on three datasets show that our method not only outperform alternatives but also provide interpretable recommendations. Further analysis demonstrates the effectiveness of user intent and its constraints. Future work includes extending H4MF with recent advanced variants of HMM and MF.

