Deep learning has been shown to be successful in a number of domains, ranging from acoustics, images, to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, substantial research efforts have been devoted to applying deep learning methods to graphs, resulting in beneficial advances in graph analysis techniques. In this survey, we comprehensively review the different types of deep learning methods on graphs. We divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods. We then provide a comprehensive overview of these methods in a systematic manner mainly by following their development history. We also analyze the differences and compositions of different methods. Finally, we briefly outline the applications in which they have been used and discuss potential future research directions.
SECTION 1Introduction
Over the past decade, deep learning has become the “crown jewel” of artificial intelligence and machine learning [1], showing superior performance in acoustics [2], images [3] and natural language processing [4], etc. The expressive power of deep learning to extract complex patterns from underlying data is well recognized. On the other hand, graphs1 are ubiquitous in the real world, representing objects and their relationships in varied domains, including social networks, e-commerce networks, biology networks, traffic networks, and so on. Graphs are also known to have complicated structures that can contain rich underlying values [5]. As a result, how to utilize deep learning methods to analyze graph data has attracted considerable research attention over the past few years. This problem is non-trivial because several challenges exist in applying traditional deep learning architectures to graphs:

Irregular structures of graphs. Unlike images, audio, and text, which have a clear grid structure, graphs have irregular structures, making it hard to generalize some of the basic mathematical operations to graphs [6]. For example, defining convolution and pooling operations, which are the fundamental operations in convolutional neural networks (CNNs), for graph data is not straightforward. This problem is often referred to as the geometric deep learning problem [7].

Heterogeneity and diversity of graphs. A graph itself can be complicated, containing diverse types and properties. For example, graphs can be heterogeneous or homogenous, weighted or unweighted, and signed or unsigned. In addition, the tasks of graphs also vary widely, ranging from node-focused problems such as node classification and link prediction to graph-focused problems such as graph classification and graph generation. These diverse types, properties, and tasks require different model architectures to tackle specific problems.

Large-scale graphs. In the big-data era, real graphs can easily have millions or billions of nodes and edges; some well-known examples are social networks and e-commerce networks [8]. Therefore, how to design scalable models, preferably models that have a linear time complexity with respect to the graph size, is a key problem.

Incorporating interdisciplinary knowledge. Graphs are often connected to other disciplines, such as biology, chemistry, and social sciences. This interdisciplinary nature provides both opportunities and challenges: domain knowledge can be leveraged to solve specific problems but integrating domain knowledge can complicate model designs. For example, when generating molecular graphs, the objective function and chemical constraints are often non-differentiable; therefore gradient-based training methods cannot easily be applied.

To tackle these challenges, tremendous efforts have been made in this area, resulting in a rich literature of related papers and methods. The adopted architectures and training strategies also vary greatly, ranging from supervised to unsupervised and from convolutional to recursive. However, to the best of our knowledge, little effort has been made to systematically summarize the differences and connections between these diverse methods.

In this paper, we try to fill this knowledge gap by comprehensively reviewing deep learning methods on graphs. Specifically, as shown in Fig. 1, we divide the existing methods into five categories based on their model architectures and training strategies: graph recurrent neural networks (Graph RNNs), graph convolutional networks (GCNs), graph autoencoders (GAEs), graph reinforcement learning (Graph RL), and graph adversarial methods. We summarize some of the main characteristics of these categories in Table 1 based on the following high-level distinctions. Graph RNNs capture recursive and sequential patterns of graphs by modeling states at either the node-level or the graph-level. GCNs define convolution and readout operations on irregular graph structures to capture common local and global structural patterns. GAEs assume low-rank graph structures and adopt unsupervised methods for node representation learning. Graph RL defines graph-based actions and rewards to obtain feedbacks on graph tasks while following constraints. Graph adversarial methods adopt adversarial training techniques to enhance the generalization ability of graph-based models and test their robustness by adversarial attacks.

TABLE 1 Main Distinctions Among Deep Learning Methods on Graphs


Fig. 1.
A categorization of deep learning methods on graphs. We divide the existing methods into five categories: graph recurrent neural networks, graph convolutional networks, graph autoencoders, graph reinforcement learning, and graph adversarial methods.

Show All

In the following sections, we provide a comprehensive and detailed overview of these methods, mainly by following their development history and the various ways these methods solve the challenges posed by graphs. We also analyze the differences between these models and delve into how to composite different architectures. Finally, we briefly outline the applications of these models, introduce several open libraries, and discuss potential future research directions. In the appendix, we provide a source code repository, analyze the time complexity of various methods discussed in the paper, and summarize some common applications.

Related Works. Several previous surveys are related to our paper. Bronstein et al. [7] summarized some early GCN methods as well as CNNs on manifolds and studied them comprehensively through geometric deep learning. Battaglia et al. [9] summarized how to use GNNs and GCNs for relational reasoning using a unified framework called graph networks, Lee et al. [10] reviewed the attention models for graphs, Zhang et al. [11] summarized some GCNs, and Sun et al. [12] briefly surveyed adversarial attacks on graphs. Our work differs from these previous works in that we systematically and comprehensively review different deep learning architectures on graphs rather than focusing on one specific branch. Concurrent to our work, Zhou et al. [13] and Wu et al. [14] surveyed this field from different viewpoints and categorizations. Specifically, neither of their works consider graph reinforcement learning or graph adversarial methods, which are covered in this paper.

Another closely related topic is network embedding, aiming to embed nodes into a low-dimensional vector space [15], [16], [17]. The main distinction between network embedding and our paper is that we focus on how different deep learning models are applied to graphs, and network embedding can be recognized as a concrete application example that uses some of these models (and it uses non-deep-learning methods as well).

The rest of this paper is organized as follows. In Section 2, we introduce the notations used in this paper and provide preliminaries. Then, we review Graph RNNs, GCNs, GAEs, Graph RL, and graph adversarial methods in Sections 3, 4, 5, 6, and 7, respectively. We conclude with a discussion in Section 8.

SECTION 2Notations and Preliminaries
Notations. In this paper, a graph2 is represented as G=(V,E) where V={v1,…,vN} is a set of N=|V| nodes and E⊆V×V is a set of M=|E| edges between nodes. We use A∈RN×N to denote the adjacency matrix, whose ith row, jth column, and an element are denoted as A(i,:),A(:,j),A(i,j), respectively. The graph can be either directed or undirected and weighted or unweighted. In this paper, we mainly consider unsigned graphs; therefore, A(i,j)≥0. Signed graphs will be discussed in future research directions. We use FV and FE to denote features of nodes and edges, respectively. For other variables, we use bold uppercase characters to denote matrices and bold lowercase characters to denote vectors, e.g., a matrix X and a vector x. The transpose of a matrix is denoted as XT and the element-wise multiplication is denoted as X1⊙X2. Functions are marked with curlicues, e.g., F(⋅).

To better illustrate the notations, we take social networks as an example. Each node vi∈V corresponds to a user, and the edges E correspond to relations between users. The profiles of users (e.g., age, gender, and location) can be represented as node features FV and interaction data (e.g., sending messages and comments) can be represented as edge features FE.

Preliminaries. The Laplacian matrix of an undirected graph is defined as L=D−A, where D∈RN×N is a diagonal degree matrix with D(i,i)=∑jA(i,j). Its eigendecomposition is denoted as L=QΛQT, where Λ∈RN×N is a diagonal matrix of eigenvalues sorted in ascending order and Q∈RN×N are the corresponding eigenvectors. The transition matrix is defined as P=D−1A, where P(i,j) represents the probability of a random walk starting from node vi landing at node vj. The k-step neighbors of node vi are defined as Nk(i)={j|D(i,j)≤k}, where D(i,j) is the shortest distance from node vi to vj, i.e., Nk(i) is a set of nodes reachable from node vi within k-steps. To simplify the notation, we omit the subscript for the immediate neighborhood, i.e., N(i)=N1(i).

For a deep learning model, we use superscripts to denote layers, e.g., Hl. We use fl to denote the dimensionality of the layer l (i.e., Hl∈RN×fl). The sigmoid activation function is defined as σ(x)=1/(1+e−x) and the rectified linear unit (ReLU) is defined as ReLU(x)=max(0,x). A general element-wise nonlinear activation function is denoted as ρ(⋅). In this paper, unless stated otherwise, we assume all functions are differentiable, allowing the model parameters Θ to be learned through back-propagation [18] using commonly adopted optimizers such as Adam [19] and training techniques such as dropout [20]. We denote the sample size as s if a sampling technique is adopted. We summarize the notations in Table 2.

TABLE 2 A Table for Commonly Used Notations
Table 2- 
A Table for Commonly Used Notations
The tasks for learning a deep model on graphs can be broadly divided into two categories:

Node-focused tasks: These tasks are associated with individual nodes in the graph. Examples include node classification, link prediction, and node recommendation.

Graph-focused tasks: These tasks are associated with the entire graph. Examples include graph classification, estimating various graph properties, and generating graphs.

Note that such distinctions are more conceptually than mathematically rigorous. Some existing tasks are associated with mesoscopic structures such as community detection [21]. In addition, node-focused problems can sometimes be studied as graph-focused problems by transforming the former into egocentric networks [22]. Nevertheless, we will explain the differences in algorithm designs for these two categories when necessary.

SECTION 3Graph Recurrent Neural Networks
Recurrent neural networks (RNNs) such as gated recurrent units (GRU) [30] or long short-term memory (LSTM) [31] are de facto standards in modeling sequential data. In this section, we review Graph RNNs which can capture recursive and sequential patterns of graphs. Graph RNNs can be broadly divided into two categories: node-level RNNs and graph-level RNNs. The main distinction lies in whether the patterns lie at the node-level and are modeled by node states, or at the graph-level and are modeled by a common graph state. The main characteristics of the methods surveyed are summarized in Table 3.

TABLE 3 The Main Characteristics of Graph Recurrent Neural Network (Graph RNNs)

3.1 Node-Level RNNs
Node-level RNNs for graphs, which are also referred to as graph neural networks (GNNs)3, can be dated back to the “pre-deep-learning” era [23], [32]. The idea behind a GNN is simple: to encode graph structural information, each node vi is represented by a low-dimensional state vector si. Motivated by recursive neural networks [33], a recursive definition of states is adopted [23]:
si=∑j∈N(i)F(si,sj,FVi,FVj,FEi,j),(1)
View SourceRight-click on figure for MathML and additional features.where F(⋅) is a parametric function to be learned. After obtaining si, another function O(⋅) is applied to get the final outputs:
y^i=O(si,FVi).(2)
View SourceFor graph-focused tasks, the authors of [23] suggested adding a special node with unique attributes to represent the entire graph. To learn the model parameters, the following semi-supervised4 method is adopted: after iteratively solving Eq. (1) to a stable point using the Jacobi method [34], one gradient descent step is performed using the Almeida-Pineda algorithm [35], [36] to minimize a task-specific objective function, for example, the squared loss between the predicted values and the ground-truth for regression tasks; then, this process is repeated until convergence.

Using the two simple equations in Eqs. (1) and (2), GNN plays two important roles. In retrospect, a GNN unifies some of the early methods used for processing graph data, such as recursive neural networks and Markov chains [23]. Looking toward the future, the general idea underlying GNNs has profound inspirations: as will be shown later, many state-of-the-art GCNs actually have a formulation similar to Eq. (1) and follow the same framework of exchanging information within the immediate node neighborhoods. In fact, GNNs and GCNs can be unified into some common frameworks, and a GNN is equivalent to a GCN that uses identical layers to reach stable states. More discussion will be provided in Section 4.

Although they are conceptually important, GNNs have several drawbacks. First, to ensure that Eq. (1) has a unique solution, F(⋅) must be a “contraction map” [37], i.e., ∃μ,0<μ<1 so that
∥F(x)−F(y)∥≤μ∥x−y∥,∀x,y.(3)
View SourceRight-click on figure for MathML and additional features.Intuitively, a “contraction map” requires that the distance between any two points can only “contract” after the F(⋅) operation, which severely limits the modeling ability. Second, because many iterations are needed to reach a stable state between gradient descend steps, GNNs are computationally expensive. Because of these drawbacks and perhaps a lack of computational power (e.g., the graphics processing unit, GPU, was not widely used for deep learning in those days) and lack of research interests, GNNs did not become a focus of general research.

A notable improvement to GNNs is gated graph sequence neural networks (GGS-NNs) [24] with the following modifications. Most importantly, the authors replaced the recursive definition in Eq. (1) with a GRU, thus removing the “contraction map” requirement and supporting modern optimization techniques. Specifically, Eq. (1) is adapted as follows:
s(t)i=(1−z(t)i)⊙s(t−1)i+z(t)i⊙s˜(t)i,(4)
View SourceRight-click on figure for MathML and additional features.where z is calculated by the update gate, s˜ is the candidate for updating, and t is the pseudo time. Second, the authors proposed using several such networks operating in sequence to produce sequence outputs and showed that their method could be applied to sequence-based tasks such as program verification [38].

SSE [25] took a similar approach as Eq. (4). However, instead of using a GRU in the calculation, SSE adopted stochastic fixed-point gradient descent to accelerate the training process. This scheme basically alternates between calculating steady node states using local neighborhoods and optimizing the model parameters, with both calculations in stochastic mini-batches.

3.2 Graph-Level RNNs
In this subsection, we review how to apply RNNs to capture graph-level patterns, e.g., temporal patterns of dynamic graphs or sequential patterns at different levels of graph granularities. In graph-level RNNs, instead of applying one RNN to each node to learn the node states, a single RNN is applied to the entire graph to encode the graph states.

You et al. [26] applied Graph RNNs to the graph generation problem. Specifically, they adopted two RNNs: one to generate new nodes and the other to generate edges for the newly added node in an autoregressive manner. They showed that such hierarchical RNN architectures learn more effectively from input graphs than do the traditional rule-based graph generative models while having a reasonable time complexity.

To capture the temporal information of dynamic graphs, dynamic graph neural network (DGNN) [27] was proposed that used a time-aware LSTM [39] to learn node representations. When a new edge is established, DGNN used the LSTM to update the representation of the two interacting nodes as well as their immediate neighbors, i.e., considering the one-step propagation effect. The authors showed that the time-aware LSTM could model the establishing orders and time intervals of edge formations well, which in turn benefited a range of graph applications.

Graph RNN can also be combined with other architectures, such as GCNs or GAEs. For example, aiming to tackle the graph sparsity problem, RMGCNN [28] applied an LSTM to the results of GCNs to progressively reconstruct a graph as illustrated in Fig. 2. By using an LSTM, the information from different parts of the graph can diffuse across long ranges without requiring as many GCN layers. Dynamic GCN [29] applied an LSTM to gather the results of GCNs from different time slices in dynamic networks to capture both the spatial and temporal graph information.


Fig. 2.
The framework of RMGCNN (reprinted from [28] with permission). RMGCNN includes an LSTM in the GCN to progressively reconstruct the graph. Xt, X~t, and dXt represent the estimated matrix, the outputs of GCNs, and the incremental updates produced by the RNN at iteration t, respectively. MGCNN refers to a multigraph CNN.

Show All

SECTION 4Graph Convolutional Networks
Graph convolutional networks (GCNs) are inarguably the hottest topic in graph-based deep learning. Mimicking CNNs, modern GCNs learn the common local and global structural patterns of graphs through designed convolution and readout functions. Because most GCNs can be trained with task-specific loss via backpropagation (with a few exceptions such as the unsupervised training method in [74]), we focus on the adopted architectures. We first discuss the convolution operations, then move to the readout operations and some other improvements. We summarize the main characteristics of GCNs surveyed in this paper in Table 4.

TABLE 4 A Comparison Among Different Graph Convolutional Networks (GCNs)
Table 4- 
A Comparison Among Different Graph Convolutional Networks (GCNs)
4.1 Convolution Operations
Graph convolutions can be divided into two groups: spectral convolutions, which perform convolution by transforming node representations into the spectral domain using the graph Fourier transform or its extensions, and spatial convolutions, which perform convolution by considering node neighborhoods. Note that these two groups can overlap, for example, when using a polynomial spectral kernel (please refer to Section 4.1.2 for details).

4.1.1 Spectral Methods
Convolution is the most fundamental operation in CNNs. However, the standard convolution operation used for images or text cannot be directly applied to graphs because graphs lack a grid structure [6]. Bruna et al. [40] first introduced convolution for graph data from the spectral domain using the graph Laplacian matrix L [75], which plays a similar role as the Fourier basis in signal processing [6]. The graph convolution operation, ∗G, is defined as follows:
u1∗Gu2=Q((QTu1)⊙(QTu2)),(5)
View SourceRight-click on figure for MathML and additional features.where u1,u2∈RN are two signals5 defined on nodes and Q are the eigenvectors of L. Briefly, multiplying QT transforms the graph signals u1,u2 into the spectral domain (i.e., the graph Fourier transform), while multiplying Q performs the inverse transform. The validity of this definition is based on the convolution theorem, i.e., the Fourier transform of a convolution operation is the element-wise product of their Fourier transforms. Then, a signal u can be filtered by
u′=QΘQTu,(6)
View SourceRight-click on figure for MathML and additional features.where u′ is the output signal, Θ=Θ(Λ)∈RN×N is a diagonal matrix of learnable filters and Λ are the eigenvalues of L. A convolutional layer is defined by applying different filters to different input-output signal pairs as follows:
ul+1j=ρ(∑i=1flQΘli,jQTuli)j=1,…,fl+1,(7)
View SourceRight-click on figure for MathML and additional features.where l is the layer, ulj∈RN is the jth hidden representation (i.e., the signal) for the nodes in the lth layer, and Θli,j are learnable filters. The idea behind Eq. (7) is similar to a conventional convolution: it passes the input signals through a set of learnable filters to aggregate the information, followed by some nonlinear transformation. By using the node features FV as the input layer and stacking multiple convolutional layers, the overall architecture is similar to that of a CNN. Theoretical analysis has shown that such a definition of the graph convolution operation can mimic certain geometric properties of CNNs and we refer readers to [7] for a comprehensive survey.

However, directly using Eq. (7) requires learning O(N) parameters, which may not be feasible in practice. Besides, the filters in the spectral domain may not be localized in the spatial domain, i.e., each node may be affected by all the other nodes rather than only the nodes in a small region. To alleviate these problems, Bruna et al. [40] suggested using the following smoothing filters:
diag(Θli,j)=Kαl,i,j,(8)
View Sourcewhere K is a fixed interpolation kernel and αl,i,j are learnable interpolation coefficients. The authors also generalized this idea to the setting where the graph is not given but constructed from raw features using either a supervised or an unsupervised method [41].

However, two fundamental problems remain unsolved. First, because the full eigenvectors of the Laplacian matrix are needed during each calculation, the time complexity is at least O(N2) for each forward and backward pass, not to mention the O(N3) complexity required to calculate the eigendecomposition, meaning that this approach is not scalable to large-scale graphs. Second, because the filters depend on the eigenbasis Q of the graph, the parameters cannot be shared across multiple graphs with different sizes and structures.

Next, we review two lines of works trying to solve these limitations and then unify them using some common frameworks.

4.1.2 The Efficiency Aspect
To solve the efficiency problem, ChebNet [42] was proposed to use a polynomial filter as follows:
Θ(Λ)=∑k=0KθkΛk,(9)
View SourceRight-click on figure for MathML and additional features.where θ0,…,θK are the learnable parameters and K is the polynomial order. Then, instead of performing the eigendecomposition, the authors rewrote Eq. (9) using the Chebyshev expansion [76]:
Θ(Λ)=∑k=0KθkTk(Λ~),(10)
View Sourcewhere Λ~=2Λ/λmax−I are the rescaled eigenvalues, λmax is the maximum eigenvalue, I∈RN×N is the identity matrix, and Tk(x) is the Chebyshev polynomial of order k. The rescaling is necessary because of the orthonormal basis of Chebyshev polynomials. Using the fact that a polynomial of the Laplacian matrix acts as a polynomial of its eigenvalues, i.e., Lk=QΛkQT, the filter operation in Eq. (6) can be rewritten as follows:
u′=QΘ(Λ)QTu==∑k=0KθkQTk(Λ~)QTu∑k=0KθkTk(L~)u=∑Kk=0θku¯k,(11)
View Sourcewhere u¯k=Tk(L~)u and L~=2L/λmax−I. Using the recurrence relation of the Chebyshev polynomial Tk(x)=2xTk−1(x)−Tk−2(x) and T0(x)=1,T1(x)=x, u¯k can also be calculated recursively:
u¯k=2L~u¯k−1−u¯k−2,(12)
View Sourcewith u¯0=u and u¯1=L~u. Now, because only the matrix multiplication of a sparse matrix L~ and some vectors need to be calculated, the time complexity becomes O(KM) when using sparse matrix multiplication, where M is the number of edges and K is the polynomial order, i.e., the time complexity is linear with respect to the number of edges. It is also easy to see that such a polynomial filter is strictly K-localized: after one convolution, the representation of node vi will be affected only by its K-step neighborhoods NK(i). Interestingly, this idea is used independently in network embedding to preserve the high-order proximity [77], of which we omit the details for brevity.

Kipf and Welling [43] further simplified the filtering by using only the first-order neighbors:
hl+1i=ρ⎛⎝⎜∑j∈N~(i)1D~(i,i)D~(j,j)−−−−−−−−−−−√hljΘl⎞⎠⎟,(13)
View SourceRight-click on figure for MathML and additional features.where hli∈Rfl is the hidden representation of node vi in the lth layer6, D~=D+I, and N~(i)=N(i)∪{i}. This can be written equivalently in an matrix form as follows:
Hl+1=ρ(D~−12A~D~−12HlΘl),(14)
View SourceRight-click on figure for MathML and additional features.where A~=A+I, i.e., adding a self-connection. The authors showed that Eq. (14) is a special case of Eq. (9) by setting K=1 with a few minor changes. Then, the authors argued that stacking an adequate number of layers as illustrated in Fig. 3 has a modeling capacity similar to ChebNet but leads to better results.

Fig. 3. - 
An illustrative example of the spatial convolution operation proposed by Kipf and Welling [43] (reprinted with permission). Nodes are affected only by their immediate neighbors in each convolutional layer.
Fig. 3.
An illustrative example of the spatial convolution operation proposed by Kipf and Welling [43] (reprinted with permission). Nodes are affected only by their immediate neighbors in each convolutional layer.

Show All

An important insight of ChebNet and its extension is that they connect the spectral graph convolution with the spatial architecture. Specifically, they show that when the spectral convolution function is polynomial or first-order, the spectral graph convolution is equivalent to a spatial convolution. In addition, the convolution in Eq. (13) is highly similar to the state definition in a GNN in Eq. (1), except that the convolution definition replaces the recursive definition. From this aspect, a GNN can be regarded as a GCN with a large number of identical layers to reach stable states [7], i.e., a GNN uses a fixed function with fixed parameters to iteratively update the node hidden states until reaching an equilibrium, while a GCN has a preset number of layers and each layer contains different parameters.

Some spectral methods have also been proposed to solve the efficiency problem. For example, instead of using the Chebyshev expansion as in Eq. (10), CayleyNet [44] adopted Cayley polynomials to define graph convolutions:
Θ(Λ)=θ0+2Re{∑k=1Kθk(θhΛ−iI)k(θhΛ+iI)k},(15)
View SourceRight-click on figure for MathML and additional features.where i=−1−−−√ denotes the imaginary unit and θh is another spectral zoom parameter. In addition to showing that CayleyNet is as efficient as ChebNet, the authors demonstrated that the Cayley polynomials can detect “narrow frequency bands of importance” to achieve better results. Graph wavelet neural network (GWNN) [45] was further proposed to replace the Fourier transform in spectral filters by the graph wavelet transform by rewriting Eq. (5) as follows:
u1∗Gu2=ψ((ψ−1u1)⊙(ψ−1u2)),(16)
View SourceRight-click on figure for MathML and additional features.where ψ denotes the graph wavelet bases. By using fast approximating algorithms to calculate ψ and ψ−1, GWNN's computational complexity is also O(KM), i.e., linear with respect to the number of edges.

4.1.3 The Aspect of Multiple Graphs
A parallel series of works has focuses on generalizing graph convolutions to multiple graphs of arbitrary sizes. Neural FPs [46] proposed a spatial method that also used the first-order neighbors:
hl+1i=σ⎛⎝⎜∑j∈N^(i)hljΘl⎞⎠⎟.(17)
View SourceBecause the parameters Θ can be shared across different graphs and are independent of the graph size, Neural FPs can handle multiple graphs of arbitrary sizes. Note that Eq. (17) is very similar to Eq. (13). However, instead of considering the influence of node degree by adding a normalization term, Neural FPs proposed learning different parameters Θ for nodes with different degrees. This strategy performed well for small graphs such as molecular graphs (i.e., atoms as nodes and bonds as edges), but may not be scalable to larger graphs.

PATCHY-SAN [47] adopted a different idea. It assigned a unique node order using a graph labeling procedure such as the Weisfeiler-Lehman kernel [78] and then arranged node neighbors in a line using this pre-defined order. In addition, PATCHY-SAN defined a “receptive field” for each node vi by selecting a fixed number of nodes from its k-step neighborhoods Nk(i). Then a standard 1-D CNN with proper normalization was adopted. Using this approach, nodes in different graphs all have a “receptive field” with a fixed size and order; thus, PATCHY-SAN can learn from multiple graphs like normal CNNs learn from multiple images. The drawbacks are that the convolution depends heavily on the graph labeling procedure which is a preprocessing step that is not learned. LGCN [48] further proposed to simplify the sorting process by using a lexicographical order (i.e., sorting neighbors based on their hidden representation in the final layer HL). Instead of using a single order, the authors sorted different channels of HL separately. SortPooling [49] took a similar approach, but rather than sorting the neighbors of each node, the authors proposed to sort all the nodes (i.e., using a single order for all the neighborhoods). Despite the differences among these methods, enforcing a 1-D node order may not be a natural choice for graphs.

DCNN [50] adopted another approach by replacing the eigenbasis of the graph convolution with a diffusion-basis, i.e., the neighborhoods of nodes were determined by the diffusion transition probability between nodes. Specifically, the convolution was defined as follows:
Hl+1=ρ(PKHlΘl),(18)
View Sourcewhere PK=(P)K is the transition probability of a length-K diffusion process (i.e., random walks), K is a preset diffusion length, and Θl are learnable parameters. Because only PK depends on the graph structure, the parameters Θl can be shared across graphs of arbitrary sizes. However, calculating PK has a time complexity of O(N2K); thus, this method is not scalable to large graphs.

DGCN [51] was further proposed to jointly adopt the diffusion and the adjacency bases using a dual graph convolutional network. Specifically, DGCN used two convolutions: one was Eq. (14), and the other replaced the adjacency matrix with the positive pointwise mutual information (PPMI) matrix [79] of the transition probability as follows:
Zl+1=ρ(D−12PXPD−12PZlΘl),(19)
View SourceRight-click on figure for MathML and additional features.where XP is the PPMI matrix calculated as:
XP(i,j)=max(log(P(i,j)∑i,jP(i,j)∑iP(i,j)∑jP(i,j)),0),(20)
View SourceRight-click on figure for MathML and additional features.and DP(i,i)=∑jXP(i,j) is the diagonal degree matrix of XP. Then, these two convolutions were ensembled by minimizing the mean square differences between H and Z. DGCN adopted a random walk sampling technique to accelerate the transition probability calculation. The experiments demonstrated that such dual convolutions were effective even for single-graph problems.

4.1.4 Frameworks
Based on the above two lines of works, MPNNs [52] were proposed as a unified framework for the graph convolution operation in the spatial domain using message-passing functions:
ml+1i=∑j∈N(i)Fl(hli,hlj,FEi,j)hl+1i=Gl(hli,ml+1i),(21)
View Sourcewhere Fl(⋅) and Gl(⋅) are the message functions and vertex update functions to be learned, respectively, and ml denotes the “messages” passed between nodes. Conceptually, MPNNs are a framework in which each node sends messages based on its states and updates its states based on messages received from the immediate neighbors. The authors showed that the above framework had included many existing methods such as GGS-NNs [24], Bruna et al. [40], Henaff et al. [41], Neural FPs [46], Kipf and Welling [43] and Kearnes et al. [55] as special cases. In addition, the authors proposed adding a “master” node that was connected to all the nodes to accelerate the message-passing across long distances, and they split the hidden representations into different “towers” to improve the generalization ability. The authors showed that a specific variant of MPNNs could achieve state-of-the-art performance in predicting molecular properties.

Concurrently, GraphSAGE [53] took a similar idea as Eq. (21) using multiple aggregating functions as follows:
ml+1i=AGGREGATEl({hlj,∀j∈N(i)})hl+1i=ρ(Θl[hli,ml+1i]),(22)
View Sourcewhere [⋅,⋅] is the concatenation operation and AGGREGATE(⋅) represents the aggregating function. The authors suggested three aggregating functions: the element-wise mean, an LSTM, and max-pooling as follows:
AGGREGATEl=max{ρ(Θpoolhlj+bpool),∀j∈N(i)},(23)
View SourceRight-click on figure for MathML and additional features.where Θpool and bpool are the parameters to be learned and max{⋅} is the element-wise maximum. For the LSTM aggregating function, because an neighbors order is needed, the authors adopted a simple random order.

Mixture model network (MoNet) [54] also tried to unify the existing GCN models as well as CNNs for manifolds into a common framework using “template matching”:
hl+1ik=∑j∈N(i)Flk(u(i,j))hlj,k=1,…,fl+1,(24)
View SourceRight-click on figure for MathML and additional features.where u(i,j) are the pseudo-coordinates of the node pair (vi,vj), Flk(u) is a parametric function to be learned, and hlik is the kth dimension of hli. In other words, Flk(u) served as a weighting kernel for combining neighborhoods. Then, MoNet adopted the following Gaussian kernel:
Flk(u)=exp(−12(u−μlk)T(Σlk)−1(u−μlk)),(25)
View Sourcewhere μlk and Σlk are the mean vectors and diagonal covariance matrices to be learned, respectively. The pseudo-coordinates were degrees as in Kipf and Welling [43], i.e.,
u(i,j)=(1D(i,i)−−−−−√,1D(j,j)−−−−−−√).(26)
View Source

Graph networks (GNs) [9] proposed a more general framework for both GCNs and GNNs that learned three sets of representations: hli,elij, and zl as the representation for nodes, edges, and the entire graph, respectively. These representations were learned using three aggregation and three updating functions:
mli=GE→V({elij,∀j∈N(i)}),mlV=GV→G({hli,∀vi∈V})mlE=GE→G({elij,∀(vi,vj)∈E}),hl+1i=FV(mli,hli,zl)el+1ij=FE(elij,hli,hlj,zl),zl+1=FG(mlE,mlV,zl),(27)
View SourceRight-click on figure for MathML and additional features.where FV(⋅),FE(⋅), and FG(⋅) are the corresponding updating functions for nodes, edges, and the entire graph, respectively, and G(⋅) represents message-passing functions whose superscripts denote message-passing directions. Note that the message-passing functions all take a set as the input, thus their arguments are variable in length and these functions should be invariant to input permutations; some examples include the element-wise summation, mean, and maximum. Compared with MPNNs, GNs introduced the edge representations and the representation of the entire graph, thus making the framework more general.

In summary, the convolution operations have evolved from the spectral domain to the spatial domain and from multistep neighbors to the immediate neighbors. Currently, gathering information from the immediate neighbors (as in Eq. (14)) and following the framework of Eqs. (21), (22), and (27) are the most common choices for graph convolution operations.

4.2 Readout Operations
Using graph convolution operations, useful node features can be learned to solve many node-focused tasks. However, to tackle graph-focused tasks, node information needs to be aggregated to form a graph-level representation. In the literature, such procedures are usually called the readout operations7. Based on a regular and local neighborhood, standard CNNs conduct multiple stride convolutions or poolings to gradually reduce the resolution. Since graphs lack a grid structure, these existing methods cannot be used directly.

Order Invariance. A critical requirement for the graph readout operations is that the operation should be invariant to the node order, i.e., if we change the indices of nodes and edges using a bijective function between two node sets, the representation of the entire graph should not change. For example, whether a drug can treat certain diseases depends on its inherent structure; thus, we should get identical results if we represent the drug using different node indices. Note that because this problem is related to the graph isomorphism problem, of which the best-known algorithm is quasipolynomial [80], we only can find a function that is order-invariant but not vice versa in a polynomial time, i.e., even two structurally different graphs may have the same representation.

4.2.1 Statistics
The most basic order-invariant operations involve simple statistics such as summation, averaging or max-pooling [46], [50], i.e.,
hG=∑i=1NhLior hG=1N∑i=1NhLior hG=max{hLi,∀i},(28)
View SourceRight-click on figure for MathML and additional features.where hG is the representation of the graph G and hLi is the representation of node vi in the final layer L. However, such first-moment statistics may not be sufficiently representative to distinguish different graphs.

Kearnes et al. [55] suggested considering the distribution of node representations by using fuzzy histograms [81]. The basic idea behind fuzzy histograms is to construct several “histogram bins” and then calculate the memberships of hLi to these bins, i.e., by regarding node representations as samples and matching them to some pre-defined templates, and finally return the concatenation of the final histograms. In this way, nodes with the same sum/average/maximum but with different distributions can be distinguished.

Another commonly used approach for aggregating node representation is to add a fully connected (FC) layer as the final layer [40], i.e.,
hG=ρ([HL]ΘFC),(29)
View Sourcewhere [HL]∈RNfL is the concatenation of the final node representation HL, ΘFC∈RNfL×foutput are parameters, and foutput is the dimensionality of the output. Eq. (29) can be regarded as a weighted sum of node-level features. One advantage is that the model can learn different weights for different nodes; however, this ability comes at the cost of being unable to guarantee order invariance.

4.2.2 Hierarchical Clustering
Rather than a dichotomy between node and graph level structures, graphs are known to exhibit rich hierarchical structures [82], which can be explored by hierarchical clustering methods as shown in Fig. 4. For example, a density-based agglomerative clustering [83] was used in Bruna et al. [40] and multi-resolution spectral clustering [84] was used in Henaff et al. [41]. ChebNet [42] and MoNet [54] adopted another greedy hierarchical clustering algorithm, Graclus [85], to merge two nodes at a time, along with a fast pooling method to rearrange the nodes into a balanced binary tree. ECC [63] adopted another hierarchical clustering method by performing eigendecomposition [86]. However, these hierarchical clustering methods are all independent of the graph convolutions (i.e., they can be performed as a preprocessing step and are not trained in an end-to-end fashion).


Fig. 4.
An example of performing a hierarchical clustering algorithm. Reprinted from [56] with permission.

Show All

To solve that problem, DiffPool [56] proposed a differentiable hierarchical clustering algorithm jointly trained with the graph convolutions. Specifically, the authors proposed learning a soft cluster assignment matrix in each layer using the hidden representations as follows:
Sl=F(Al,Hl),(30)
View SourceRight-click on figure for MathML and additional features.where Sl∈RNl×Nl+1 is the cluster assignment matrix, Nl is the number of clusters in the layer l and F(⋅) is a function to be learned. Then, the node representations and the new adjacency matrix for this “coarsened” graph can be obtained by taking the average according to Sl as follows:
Hl+1=(Sl)TH^l+1,Al+1=(Sl)TAlSl,(31)
View Sourcewhere H^l+1 is obtained by applying a graph convolution layer to Hl, i.e., coarsening the graph from Nl nodes to Nl+1 nodes in each layer after the convolution operation. The initial number of nodes is N0=N and the last layer is NL=1, i.e., a single node that represents the entire graph. Because the cluster assignment operation is soft, the connections between clusters are not sparse; thus the time complexity of the method is O(N2) in principle.

4.2.3 Imposing Orders and Others
As mentioned in Section 4.1.3, PATCHY-SAN [47] and SortPooling [49] took the idea of imposing a node order and then resorted to standard 1-D pooling as in CNNs. Whether these methods can preserve order invariance depends on how the order is imposed, which is another research field that we refer readers to [87] for a survey. However, whether imposing a node order is a natural choice for graphs and if so, what the best node orders are constitute still on-going research topics.

In addition to the aforementioned methods, there are some heuristics. In GNNs [23], the authors suggested adding a special node connected to all nodes to represent the entire graph. Similarly, GNs [9] proposed to directly learn the representation of the entire graph by receiving messages from all nodes and edges.

MPNNs adopted set2set [88], a modification of the seq2seq model. Specifically, set2set uses a “Read-Process-and-Write” model that receives all inputs simultaneously, computes internal memories using an attention mechanism and an LSTM, and then writes the outputs. Unlike seq2seq which is order-sensitive, set2set is invariant to the input order.

4.2.4 Summary
In short, statistics such as averaging or summation are the most simple readout operations, while hierarchical clustering algorithms jointly trained with graph convolutions are more advanced but are also more sophisticated. Other methods such as adding a pseudo node or imposing a node order have also been investigated.

4.3 Improvements and Discussions
Many techniques have been introduced to further improve GCNs. Note that some of these methods are general and could be applied to other deep learning models on graphs as well.

4.3.1 Attention Mechanism
In the aforementioned GCNs, the node neighborhoods are aggregated with equal or pre-defined weights. However, the influences of neighbors can vary greatly; thus, they should be learned during training rather than being predetermined. Inspired by the attention mechanism [89], graph attention network (GAT) [57] introduces the attention mechanism into GCNs by modifying the convolution operation in Eq. (13) as follows:
hl+1i=ρ⎛⎝⎜∑j∈N^(i)αlijhljΘl⎞⎠⎟,(32)
View Sourcewhere αlij is node vi's attention to node vj in the lth layer:
αlij=exp(LeakyReLU(F(hliΘl,hljΘl)))∑k∈N^(i)exp(LeakyReLU(F(hliΘl,hlkΘl))),(33)
View Sourcewhere F(⋅,⋅) is another function to be learned such as a multi-layer perceptron (MLP). To improve model capacity and stability, the authors also suggested using multiple independent attentions and concatenating the results, i.e., the multi-head attention mechanism [89] as illustrated in Fig. 5. GaAN [58] further proposed learning different weights for different heads and applied such a method to the traffic forecasting problem.

Fig. 5. - 
An illustration of the multi-head attention mechanism proposed in GAT [57] (reprinted with permission). Each color denotes an independent attention vector.
Fig. 5.
An illustration of the multi-head attention mechanism proposed in GAT [57] (reprinted with permission). Each color denotes an independent attention vector.

Show All

HAN [59] proposed a two-level attention mechanism, i.e., a node-level and a semantic-level attention mechanism, for heterogeneous graphs. Specifically, the node-level attention mechanism was similar to a GAT, but also considerd node types; therefore, it could assign different weights to aggregating meta-path-based neighbors. The semantic-level attention then learned the importance of different meta-paths and outputed the final results.

4.3.2 Residual and Jumping Connections
Many researches have observed that the most suitable depth for the existing GCNs is often very limited, e.g., 2 or 3 layers. This problem is potentially due to the practical difficulties involved in training deep GCNs or the over-smoothing problem, i.e., all nodes in deeper layers have the same representation [62], [70]. To remedy this problem, residual connections similar to ResNet [90] can be added to GCNs. For example, Kipf and Welling [43] added residual connections into Eq. (14) as follows:
Hl+1=ρ(D~−12A~D~−12HlΘl)+Hl.(34)
View SourceRight-click on figure for MathML and additional features.They showed experimentally that adding such residual connections could allow the depth of the network to increase, which is similar to the results of ResNet.

Column network (CLN) [60] adopted a similar idea by using the following residual connections with learnable weights:
hl+1i=αli⊙h˜l+1i+(1−αli)⊙hli,(35)
View Sourcewhere h˜l+1i is calculated similar to Eq. (14) and αli is a set of weights calculated as follows:
αli=ρ⎛⎝blα+Θlαhli+Θ′lα∑j∈N(i)hlj⎞⎠,(36)
View Sourcewhere blα,Θlα,Θ′lα are parameters. Note that Eq. (35) is very similar to the GRU as in GGS-NNs [24]. The differences are that in a CLN, the superscripts denote the number of layers, and different layers contain different parameters, while in GGS-NNs, the superscript denotes the pseudo time and a single set of parameters is used across time steps.

Inspired by personalized PageRank, PPNP [61] defined graph convolutions with teleportation to the initial layer:
Hl+1=(1−α)D~−12A~D~−12Hl+αH0,(37)
View SourceRight-click on figure for MathML and additional features.where H0=Fθ(FV) and α is a hyper-parameter. Note that all the parameters are in Fθ(⋅) rather than in the graph convolutions.

Jumping knowledge networks (JK-Nets) [62] proposed another architecture to connect the last layer of the network with all the lower hidden layers, i.e., by “jumping” all the representations to the final output, as illustrated in Fig. 6. In this way, the model can learn to selectively exploit information from different layers. Formally, JK-Nets was formulated as follows:
hfinali=AGGREGATE(h0i,h1i,…,hLi),(38)
View Sourcewhere hfinali is the final representation for node vi, AGGREGATE (⋅) is the aggregating function, and L is the number of hidden layers. JK-Nets used three aggregating functions similar to GraphSAGE [53]: concatenation, max-pooling, and the LSTM attention. The experimental results showed that adding jump connections could improve the performance of multiple GCNs.


Fig. 6.
Jumping knowledge networks proposed in [62] in which the last layer is connected to all the other layers to selectively exploit different information from different layers. GC denotes graph convolutions. Reprinted with permission.

Show All

4.3.3 Edge Features
The aforementioned GCNs mostly focus on utilizing node features and graph structures. In this subsection, we briefly discuss how to use another important source of information: the edge features.

For simple edge features with discrete values such as the edge type, a straightforward method is to train different parameters for different edge types and aggregate the results. For example, Neural FPs [46] trained different parameters for nodes with different degrees, which corresponds to the implicit edge feature of bond types in a molecular graph, and then summed over the results. CLN [60] trained different parameters for different edge types in a heterogeneous graph and averaged the results. Edge-conditioned convolution (ECC) [63] also trained different parameters based on edge types and applied them to graph classification. Relational GCNs (R-GCNs) [64] adopted a similar idea for knowledge graphs by training different weights for different relation types. However, these methods are suitable only for a limited number of discrete edge features.

DCNN [50] proposed another method to convert each edge into a node connected to the head and tail node of that edge. After this conversion, edge features can be treated as node features.

LGCN [65] constructed a line graph B∈R2M×2M to incorporate edge features as follows:
Bi→j,i′→j′={10if j=i′and j′≠i,otherwise.(39)
View SourceIn other words, nodes in the line graph are directed edges in the original graph, and two nodes in the line graph are connected if information can flow through their corresponding edges in the original graph. Then, LGCN adopted two GCNs: one on the original graph and one on the line graph.

Kearnes et al. [55] proposed an architecture using a “weave module”. Specifically, they learned representations for both nodes and edges and exchanged information between them in each weave module using four different functions: node-to-node (NN), node-to-edge (NE), edge-to-edge (EE) and edge-to-node (EN):
hl′i=FNN(h0i,h1i,…,hli),hl′′i=FEN({elij|j∈N(i)})el′ij=FEE(e0ij,e1ij,…,elij),el′′ij=FNE(hli,hlj)hl+1i=FNN(hl′i,hl′′i),el+1ij=FEE(el′ij,el′′ij),(40)
View Sourcewhere elij is the representation of edge (vi,vj) in the lth layer and F(⋅) are learnable functions whose subscripts represent message-passing directions. By stacking multiple such modules, information can propagate by alternately passing between node and edge representations. Note that in the node-to-node and edge-to-edge functions, jump connections similar to those in JK-Nets [62] are implicitly added. GNs [9] also proposed learning an edge representation and updating both node and edge representations using message-passing functions as shown in Eq. (27) in Section 4.1.4. In this aspect, the “weave module” is a special case of GNs that does not a representation of the entire graph.

4.3.4 Sampling Methods
One critical bottleneck when training GCNs for large-scale graphs is efficiency. As shown in Section 4.1.4, many GCNs follow a neighborhood aggregation scheme. However, because many real graphs follow a power-law distribution [91] (i.e., a few nodes have very large degrees), the number of neighbors can expand extremely quickly. To deal with this problem, two types of sampling methods have been proposed: neighborhood samplings and layer-wise samplings, as illustrated in Fig. 7.


Fig. 7.
Different node sampling methods, in which the blue nodes indicate samples from one batch and the arrows indicate the sampling directions. The red nodes in (B) represent historical samples.

Show All

In neighborhood samplings, the sampling is performed for each node during the calculations. GraphSAGE [53] uniformly sampled a fixed number of neighbors for each node during training. PinSage [66] proposed sampling neighbors using random walks on graphs along with several implementation improvements including coordination between the CPU and GPU, a map-reduce inference pipeline, and so on. PinSage was shown to be capable of handling a real billion-scale graph. StochasticGCN [67] further proposed reducing the sampling variances by using the historical activations of the last batches as a control variate, allowing for arbitrarily small sample sizes with a theoretical guarantee.

Instead of sampling neighbors of nodes, FastGCN [68] adopted a different strategy: it sampled nodes in each convolutional layer (i.e., a layer-wise sampling) by interpreting the nodes as i.i.d. samples and the graph convolutions as integral transforms under probability measures. FastGCN also showed that sampling nodes via their normalized degrees could reduce variances and lead to better performance. Adapt [69] further proposed sampling nodes in the lower layers conditioned on their top layer; this approach was more adaptive and applicable to explicitly reduce variances.

4.3.5 Inductive Setting
Another important aspect of GCNs is that whether they can be applied to an inductive setting, i.e., training on a set of nodes or graphs and testing on another unseen set of nodes or graphs. In principle, this goal is achieved by learning a mapping function on the given features that are not dependent on the graph basis and can be transferred across nodes or graphs. The inductive setting was verified in GraphSAGE [53], GAT [57], GaAN [58], and FastGCN [68]. However, the existing inductive GCNs are suitable only for graphs with explicit features. How to conduct inductive learnings for graphs without explicit features, usually called the out-of-sample problem [92], remains largely open in the literature.

4.3.6 Theoretical Analysis
To understand the effectiveness of GCNs, some theoretical analyses have been proposed that can be divided into three categories: node-focused tasks, graph-focused tasks, and general analysis.

For node-focused tasks, Li et al. [70] first analyzed the performance of GCNs by using a special form of Laplacian smoothing, which makes the features of nodes in the same cluster similar. The original Laplacian smoothing operation is formulated as follows:
h′i=(1−γ)hi+γ∑j∈N(i)1dihj,(41)
View SourceRight-click on figure for MathML and additional features.where hi and h′i are the original and smoothed features of node vi, respectively. We can see that Eq. (41) is very similar to the graph convolution in Eq. (13). Based on this insight, Li et al. also proposed a co-training and a self-training method for GCNs.

Recently, Wu et al. [71] analyzed GCNs from a signal processing perspective. By regarding node features as graph signals, they showed that Eq. (13) is basically a fixed low-pass filter. Using this insight, they proposed an extremely simplified graph convolution (SGC) architecture by removing all the nonlinearities and collapsing the learning parameters into one matrix:
HL=(D~−12A~D~−12)LFVΘ.(42)
View SourceRight-click on figure for MathML and additional features.The authors showed that such a “non-deep-learning” GCN variant achieved comparable performance to existing GCNs in many tasks. Maehara [72] enhanced this result by showing that the low-pass filtering operation did not equip GCNs with a nonlinear manifold learning ability, and further proposed GFNN model to remedy this problem by adding a MLP after the graph convolution layers.

For graph-focused tasks, Kipf and Welling [43] and the authors of SortPooling [49] both considered the relationship between GCNs and graph kernels such as the Weisfeiler-Lehman (WL) kernel [78], which is widely used in graph isomorphism tests. They showed that GCNs are conceptually a generalization of the WL kernel because both methods iteratively aggregate information from node neighbors. Xu et al. [73] formalized this idea by proving that the WL kernel provides an upper bound for GCNs in terms of distinguishing graph structures. Based on this analysis, they proposed graph isomorphism network (GIN) and showed that a readout operation using summation and a MLP can achieve provably maximum discriminative power, i.e., the highest training accuracy in graph classification tasks.

For general analysis, Scarselli et al. [93] showed that the Vapnik-Chervonenkis dimension (VC-dim) of GCNs with different activation functions has the same scale as the existing RNNs. Chen et al. [65] analyzed the optimization landscape of linear GCNs and showed that any local minimum is relatively close to the global minimum under certain simplifications. Verma and Zhang [94] analyzed the algorithmic stability and generalization bound of GCNs. They showed that single-layer GCNs satisfy the strong notion of uniform stability if the largest absolute eigenvalue of the graph convolution filters is independent of the graph size.

SECTION 5Graph Autoencoders
The autoencoder (AE) and its variations have been widely applied in unsupervised learning tasks [95] and are suitable for learning node representations for graphs. The implicit assumption is that graphs have an inherent, potentially nonlinear low-rank structure. In this section, we first elaborate graph autoencoders and then introduce graph variational autoencoders and other improvements. The main characteristics of GAEs are summarized in Table 5.

TABLE 5 A Comparison Among Different Graph Autoencoders (GAEs)

5.1 Autoencoders
The use of AEs for graphs originated from sparse autoencoder (SAE) [96]. The basic idea is that, by regarding the adjacency matrix or its variations as the raw features of nodes, AEs can be leveraged as a dimensionality reduction technique to learn low-dimensional node representations. Specifically, SAE adopted the following L2-reconstruction loss:
minΘL2=∑i=1N∥∥P(i,:)−P^(i,:)∥∥2P^(i,:)=G(hi),hi=F(P(i,:)),(43)
View SourceRight-click on figure for MathML and additional features.where P is the transition matrix, P^ is the reconstructed matrix, hi∈Rd is the low-dimensional representation of node vi, F(⋅) is the encoder, G(⋅) is the decoder, d≪N is the dimensionality, and Θ are parameters. Both the encoder and decoder are an MLP with many hidden layers. In other words, a SAE compresses the information of P(i,:) into a low-dimensional vector hi and then reconstructs the original feature from that vector. Another sparsity regularization term was also added. After obtaining the low-dimensional representation hi, k-means [106] was applied for the node clustering task. The experiments prove that SAEs outperform non-deep learning baselines. However, SAE was based on an incorrect theoretical analysis.8 The mechanism underlying its effectiveness remained unexplained.

Structure deep network embedding (SDNE) [97] filled in the puzzle by showing that the L2-reconstruction loss in Eq. (43) actually corresponds to the second-order proximity between nodes, i.e., two nodes share similar latten representations if they have similar neighborhoods, which is a well-studied concept in network science known as collaborative filtering or triangle closure [5]. Motivated by network embedding methods showing that the first-order proximity is also important [108], SDNE modified the objective function by adding another Laplacian eigenmaps term [75]:
minΘL2+α∑i,j=1NA(i,j)∥hi−hj∥2,(44)
View Sourcei.e., two nodes also share similar latent representations if they are directly connected. The authors also modified the L2-reconstruction loss by using the adjacency matrix and assigning different weights to zero and non-zero elements:
L2=∑i=1N∥(A(i,:)−G(hi))⊙bi∥2,(45)
View SourceRight-click on figure for MathML and additional features.where hi=F(A(i,:)), bij=1 if A(i,j)=0; otherwise bij=β>1, and β is another hyper-parameter. The overall architecture of SDNE is shown in Fig. 8.


Fig. 8.
The framework of SDNE [97]. Both the first and second-order proximities of nodes are preserved using deep autoencoders.

Show All

Motivated by another line of studies, a contemporary work DNGR [98] replaced the transition matrix P in Eq. (43) with the positive pointwise mutual information (PPMI) [79] matrix defined in Eq. (20). In this way, the raw features can be associated with some random walk probability of the graph [109]. However, constructing the input matrix has a time complexity of O(N2), which is not scalable to large-scale graphs.

GC-MC [99] took a different approach by using the GCN proposed by Kipf and Welling [43] as the encoder:
H=GCN(FV,A),(46)
View Sourceand using a simple bilinear function as the decoder:
A^(i,j)=H(i,:)ΘdeH(j,:)T,(47)
View Sourcewhere Θde are the decoder parameters. Using this approach, node features were naturally incorporated. For graphs without node features, a one-hot encoding of node IDs was utilized. The authors demonstrated the effectiveness of GC-MC on the recommendation problem on bipartite graphs.

Instead of reconstructing the adjacency matrix or its variations, DRNE [100] proposed another modification that directly reconstructed the low-dimensional node vectors by aggregating neighborhood information using an LSTM. Specifically, DRNE adopted the following objective function:
L=∑i=1N∥hi−LSTM({hj|j∈N(i)})∥.(48)
View SourceRight-click on figure for MathML and additional features.Because an LSTM requires its inputs to be a sequence, the authors suggested ordering the node neighborhoods based on their degrees. They also adopted a neighborhood sampling technique for nodes with large degrees to prevent an overlong memory. The authors proved that such a method can preserve regular equivalence as well as many centrality measures of nodes, such as PageRank [110].

Unlike the above works that map nodes into a low-dimensional vector, Graph2Gauss (G2G) [101] proposed encoding each node as a Gaussian distribution hi=N(M(i,:),diag(Σ(i,:))) to capture the uncertainties of nodes. Specifically, the authors used a deep mapping from the node attributes to the means and variances of the Gaussian distribution as the encoder:
M(i,:)=FM(FV(i,:)),Σ(i,:)=FΣ(FV(i,:)),(49)
View Sourcewhere FM(⋅) and FΣ(⋅) are the parametric functions that need to be learned. Then, instead of using an explicit decoder function, they used pairwise constraints to learn the model:
KL(hj||hi)<KL(hj′||hi)∀i,∀j,∀j′s.t.d(i,j)<d(i,j′),(50)
View Sourcewhere d(i,j) is the shortest distance from node vi to vj and KL(q(⋅)||p(⋅)) is the Kullback-Leibler (KL) divergence between q(⋅) and p(⋅) [111]. In other words, the constraints ensure that the KL-divergence between node representations has the same relative order as the graph distance. However, because Eq. (50) is hard to optimize, an energy-based loss [112] was adopted as a relaxation:
L=∑(i,j,j′)∈D(E2ij+exp−Eij′),(51)
View Sourcewhere D={(i,j,j′)|d(i,j)<d(i,j′)} and Eij=KL(hj||hi). The authors further proposed an unbiased sampling strategy to accelerate the training process.

5.2 Variational Autoencoders
Different from the aforementioned autoencoders, variational autoencoders (VAEs) are another type of deep learning method that combines dimensionality reduction with generative models. Its potential benefits include tolerating noise and learning smooth representations [113]. VAEs were first introduced to graph data in VGAE [102], where the decoder was a simple linear product:
p(A|H)=∏Ni,j=1σ(hihTj),(52)
View SourceRight-click on figure for MathML and additional features.in which the node representation was assumed to follow a Gaussian distribution q(hi|M,Σ)=N(hi|M(i,:),diag(Σ(i,:))). For the encoder of the mean and variance matrices, the authors also adopted the GCN proposed by Kipf and Welling [43]:
M=GCNM(FV,A),logΣ=GCNΣ(FV,A).(53)
View SourceThen, the model parameters were learned by minimizing the variational lower bound [113]:
L=Eq(H|FV,A)[logp(A|H)]−KL(q(H|FV,A)||p(H)).(54)
View SourceHowever, because this approach required reconstructing the full graph, its time complexity is O(N2).

Motivated by SDNE and G2G, DVNE [103] proposed another VAE for graph data that also represented each node as a Gaussian distribution. Unlike the existing works that had adopted KL-divergence as the measurement, DVNE used the Wasserstein distance [114] to preserve the transitivity of the nodes similarities. Similar to SDNE and G2G, DVNE also preserved both the first and second-order proximity in its objective function:
minΘ∑(i,j,j′)∈D(E2ij+exp−Eij′)+αL2,(55)
View Sourcewhere Eij=W2(hj||hi) is the 2nd Wasserstein distance between two Gaussian distributions hj and hi and D={(i,j,j′)|j∈N(i),j′∉N(i)} is a set of triples corresponding to the ranking loss of the first-order proximity. The reconstruction loss was defined as follows:
L2=infq(Z|P)Ep(P)Eq(Z|P)∥P⊙(P−G(Z))∥22,(56)
View SourceRight-click on figure for MathML and additional features.where P is the transition matrix and Z represents samples drawn from H. The framework is shown in Fig. 9. Using this approach, the objective function can be minimized as in conventional VAEs using the reparameterization trick [113].

Fig. 9. - 
The framework of DVNE [103]. DVNE represents nodes as distributions using a VAE and adopts the Wasserstein distance to preserve the transitivity of the nodes similarities.
Fig. 9.
The framework of DVNE [103]. DVNE represents nodes as distributions using a VAE and adopts the Wasserstein distance to preserve the transitivity of the nodes similarities.

Show All

5.3 Improvements and Discussions
Several improvements have also been proposed for GAEs.

5.3.1 Adversarial Training
An adversarial training scheme9 was incorporated into GAEs as an additional regularization term in ARGA [104]. The overall architecture is shown in Fig. 10. Specifically, the encoder of GAEs was used as the generator while the discriminator aimed to distinguish whether a latent representation came from the generator or from a prior distribution. In this way, the autoencoder was forced to match the prior distribution as a regularization. The objective function was:
minΘL2+αLGAN,(57)
View Sourcewhere L2 is the reconstruction loss in GAEs and LGAN is
minGmaxDEh∼ph[logD(h)]+Ez∼G(FV,A)[log(1−D(z))],(58)
View Sourcewhere G(FV,A) is a generator that uses the graph convolutional encoder from Eq. (53), D(⋅) is a discriminator based on the cross-entropy loss, and ph is the prior distribution. The study adopted a simple Gaussian prior, and the experimental results demonstrated the effectiveness of the adversarial training scheme.

Fig. 10. - 
The framework of ARGA/ARVGA reprinted from [104] with permission. This model incorporates the adversarial training scheme into GAEs.
Fig. 10.
The framework of ARGA/ARVGA reprinted from [104] with permission. This model incorporates the adversarial training scheme into GAEs.

Show All

Concurrently, NetRA [105] also proposed using a generative adversarial network (GAN) [115] to enhance the generalization ability of graph autoencoders. Specifically, the authors used the following objective function:
minΘL2+α1LLE+α2LGAN,(59)
View Sourcewhere LLE is the Laplacian eigenmaps objective function shown in Eq. (44). In addition, the authors adopted an LSTM as the encoder to aggregate information from neighborhoods similar to Eq. (48). Instead of sampling only immediate neighbors and ordering the nodes using degrees as in DRNE [100], the authors used random walks to generate the input sequences. In contrast to ARGA, NetRA considered the representations in GAEs as the ground-truth and adopted random Gaussian noises followed by an MLP as the generator.

5.3.2 Inductive Learning
Similar to GCNs, GAEs can be applied to the inductive learning setting if node attributes are incorporated in the encoder. This can be achieved by using a GCN as the encoder, such as in GC-MC [99], VGAE [102], and VGAE [104], or by directly learning a mapping function from node features as in G2G [101]. Because the edge information is utilized only when learning the parameters, the model can also be applied to nodes unseen during training. These works also show that although GCNs and GAEs are based on different architectures, it is possible to use them jointly, which we believe is a promising future direction.

5.3.3 Similarity Measures
In GAEs, many similarity measures have been adopted, for example, L2-reconstruction loss, Laplacian eigenmaps, and the ranking loss for graph AEs, and KL divergence and Wasserstein distance for graph VAEs. Although these similarity measures are based on different motivations, how to choose an appropriate similarity measure for a given task and model architecture remains unstudied. More research is needed to understand the underlying differences between these metrics.

SECTION 6Graph Reinforcement Learning
One aspect of deep learning not yet discussed is reinforcement learning (RL), which has been shown to be effective in AI tasks such as playing games [122]. RL is known to be good at learning from feedbacks, especially when dealing with non-differentiable objectives and constraints. In this section, we review Graph RL methods. Their main characteristics are summarized in Table 6.

TABLE 6 The Main Characteristics of Graph Reinforcement Learning
Table 6- 
The Main Characteristics of Graph Reinforcement Learning
GCPN [116] utilized RL to generate goal-directed molecular graphs while considering non-differential objectives and constraints. Specifically, the graph generation is modeled as a Markov decision process of adding nodes and edges, and the generative model is regarded as an RL agent operating in the graph generation environment. By treating agent actions as link predictions, using domain-specific as well as adversarial rewards, and using GCNs to learn the node representations, GCPN can be trained in an end-to-end manner using a policy gradient [123].

A concurrent work, MolGAN [117], adopted a similar idea of using RL for generating molecular graphs. However, rather than generating the graph through a sequence of actions, MolGAN proposed directly generating the full graph; this approach worked particularly well for small molecules.

GTPN [118] adopted RL to predict chemical reaction products. Specifically, the agent acted to select node pairs in the molecule graph and predicted their new bonding types, and rewards were given both immediately and at the end based on whether the predictions were correct. GTPN used a GCN to learn the node representations and an RNN to memorize the prediction sequence.

GAM [119] applied RL to graph classification by using random walks. The authors modeled the generation of random walks as a partially observable Markov decision process (POMDP). The agent performed two actions: first, it predicted the label of the graph; then, it selected the next node in the random walk. The reward was determined simply by whether the agent correctly classified the graph, i.e.,
J(θ)=EP(S1:T;θ)∑t=1Trt,(60)
View Sourcewhere rt=1 represents a correct prediction; otherwise, rt=−1. T is the total time steps and St is the environment.

DeepPath [120] and MINERVA [121] both adopted RL for knowledge graph (KG) reasoning. Specifically, DeepPath targeted at pathfinding, i.e., find the most informative path between two target nodes, while MINERVA tackled question-answering tasks, i.e., find the correct answer node given a question node and a relation. In both methods, the RL agents need to predict the next node in the path at each step and output a reasoning path in the KG. Agents receive rewards if the paths reach the correct destinations. DeepPath also added a regularization term to encourage the path diversity.

SECTION 7Graph Adversarial Methods
Adversarial methods such as GANs [115] and adversarial attacks have drawn increasing attention in the machine learning community in recent years. In this section, we review how to apply adversarial methods to graphs. The main characteristics of graph adversarial methods are summarized in Table 7.

TABLE 7 The Main Characteristics of Graph Adversarial Methods
Table 7- 
The Main Characteristics of Graph Adversarial Methods
7.1 Adversarial Training
The basic idea behind a GAN is to build two linked models: a discriminator and a generator. The goal of the generator is to “fool” the discriminator by generating fake data, while the discriminator aims to distinguish whether a sample comes from real data or is generated by the generator. Subsequently, both models benefit from each other by joint training using a minimax game. Adversarial training has been shown to be effective in generative models and enhancing the generalization ability of discriminative models. In Section 5.3.1 and Section 6, we reviewed how adversarial training schemes are used in GAEs and Graph RL, respectively. Here, we review several other adversarial training methods on graphs in detail.

GraphGAN [124] proposed using a GAN to enhance graph embedding methods [17] with the following objective function:
minGmaxD∑i=1N+(Ev∼pgraph(⋅|vi)[logD(v,vi)]Ev∼G(⋅|vi)[log(1−D(v,vi))]).(61)
View SourceRight-click on figure for MathML and additional features.The discriminator D(⋅) and the generator G(⋅) are as follows:
D(v,vi)=σ(dvdTvi),G(v|vi)=exp(gvgTvi)∑v′≠viexp(gv′gTvi),(62)
View SourceRight-click on figure for MathML and additional features.where dv and gv are the low-dimensional embedding vectors for node v in the discriminator and the generator, respectively. Combining the above equations, the discriminator actually has two objectives: the node pairs in the original graph should possess large similarities, while the node pairs generated by the generator should possess small similarities. This architecture is similar to network embedding methods such as LINE [108], except that negative node pairs are generated by the generator G(⋅) instead of by random samplings. The authors showed that this method enhanced the inference abilities of the node embedding vectors.

Adversarial network embedding (ANE) [125] also adopted an adversarial training scheme to improve network embedding methods. Similar to ARGA [104], ANE used a GAN as an additional regularization term to existing network embedding methods such as DeepWalk [131] by imposing a prior distribution as the real data and regarding the embedding vectors as generated samples.

GraphSGAN [126] used a GAN to enhance semi-supervised learning on graphs. Specifically, the authors observed that fake nodes should be generated in the density gaps between subgraphs to weaken the propagation effect across different clusters of the existing models. To achieve that goal, the authors designed a novel optimization objective with elaborate loss terms to ensure that the generator generated samples in the density gaps at equilibrium.

NetGAN [127] adopted a GAN for graph generation tasks. Specifically, the authors regarded graph generation as a task to learn the distribution of biased random walks and adopted a GAN framework to generate and discriminate among random walks using an LSTM. The experiments showed that using random walks could also learn global network patterns.

7.2 Adversarial Attacks
Adversarial attacks are another class of adversarial methods intended to deliberately “fool” the targeted methods by adding small perturbations to data. Studying adversarial attacks can deepen our understanding of the existing models and inspire more robust architectures. We review the graph-based adversarial attacks below.

Nettack [128] first proposed attacking node classification models such as GCNs by modifying graph structures and node attributes. Denoting the targeted node as v0 and its true class as ctrue, the targeted model as F(A,FV) and its loss function as LF(A,FV), the model adopted the following objective function:
argmax(A′,FV′)∈Pmaxc≠ctruelogZ∗v0,c−logZ∗v0,ctrues.t.Z∗=Fθ∗(A′,FV′),θ∗=argminθLF(A′,FV′),(63)
View SourceRight-click on figure for MathML and additional features.where A′ and FV′ are the modified adjacency matrix and node feature matrix, respectively, Z represents the classification probabilities predicted by F(⋅), and P is the space determined by the attack constraints. Simply speaking, the optimization aims to find the best legitimate changes in graph structures and node attributes to cause v0 to be misclassified. The θ∗ indicates that the attack is causative, i.e., the attack occurs before training the targeted model. The authors proposed several constraints for the attacks. The most important constraint is that the attack should be “unnoticeable”, i.e., it should make only small changes. Specifically, the authors proposed to preserve data characteristics such as node degree distributions and feature co-occurrences. The authors also proposed two attacking scenarios, direct attack (directly attacking v0) and influence attack (only attacking other nodes), and several relaxations to make the optimization tractable.

Concurrently, Dai et al. [129] studied adversarial attacks for graphs with an objective function similar to Eq. (63); however, they focused on the case in which only graph structures were changed. Instead of assuming that the attacker possessed all the information, the authors considered several settings in which different amounts of information were available. The most effective strategy, RL-S2V, adopted structure2vec [132] to learn the node and graph representations and used reinforcement learning to solve the optimization. The experimental results showed that the attacks were effective for both node and graph classification tasks.

The aforementioned two attacks are targeted, i.e., they are intended to cause misclassification of some targeted node v0. Zugner and Gunnemann [130] were the first to study non-targeted attacks, which were intended to reduce the overall model performance. They treated the graph structure as hyper-parameters to be optimized and adopted meta-gradients in the optimization process, along with several techniques to approximate the meta-gradients.

SECTION 8Discussions and Conclusion
Thus far, we have reviewed the different graph-based deep learning architectures as well as their similarities and differences. Next, we briefly discuss their applications, implementations, and future directions before summarizing this paper.

8.1 Applications
In addition to standard graph inference tasks such as node or graph classification10, graph-based deep learning methods have also been applied to a wide range of disciplines, including modeling social influence [133], recommendation [28], [66], [99], [134], chemistry and biology [46], [52], [55], [116], [117], physics [135], [136], disease and drug prediction [137], [138], [139], gene expression [140], natural language processing (NLP) [141], [142], computer vision [143], [144], [145], [146], [147], traffic forecasting [148], [149], program induction [150], solving graph-based NP problems [151], [152], and multi-agent AI systems [153], [154], [155].

A thorough review of these methods is beyond the scope of this paper due to the sheer diversity of these applications; however, we list several key inspirations. First, it is important to incorporate domain knowledge into the model when constructing a graph or choosing architectures. For example, building a graph based on the relative distance may be suitable for traffic forecasting problems, but may not work well for a weather prediction problem where the geographical location is also important. Second, a graph-based model can usually be built on top of other architectures rather than as a stand-alone model. For example, the computer vision community usually adopts CNNs for detecting objects and then uses graph-based deep learning as a reasoning module [156]. For NLP problems, GCNs can be adopted as syntactic constraints [141]. As a result, key key challenge is how to integrate different models. These applications also show that graph-based deep learning not only enables mining the rich value underlying the existing graph data but also helps to naturally model relational data as graphs, greatly widening the applicability of graph-based deep learning models.

8.2 Implementations
Recently, several open libraries have been made available for developing deep learning models on graphs. These libraries are listed in Table 8. We also collected a list of source code (mostly from their original authors) for the studies discussed in this paper. This repository is included in Appendix A, available in the online supplemental material. These open implementations make it easy to learn, compare, and improve different methods. Some implementations also address the problem of distributed computing, which we do not discuss in this paper.

TABLE 8 Libraries of Deep Learning on Graphs
Table 8- 
Libraries of Deep Learning on Graphs
8.3 Future Directions
There are several ongoing or future research directions which are also worthy of discussion:

New models for unstudied graph structures. Due to the extremely diverse structures of graph data, the existing methods are not suitable for all of them. For example, most methods focus on homogeneous graphs, while heterogeneous graphs are seldom studied, especially those containing different modalities such as those in [157]. Signed networks, in which negative edges represent conflicts between nodes, also have unique structures, and they pose additional challenges to the existing methods [158]. Hypergraphs, which represent complex relations between more than two objects [159], are also understudied. Thus, an important next step is to design specific deep learning models to handle these types of graphs.

Compositionality of existing models. As shown multiple times in this paper, many of the existing architectures can be integrated: for example, using a GCN as a layer in GAEs or Graph RL. In addition to designing new building blocks, how to systematically composite these architectures is an interesting future direction. In this process, how to incorporate interdisciplinary knowledge in a principled way rather than on a case-by-case basis is also an open problem. One recent work, graph networks [9], takes the first step and focuses on using a general framework of GNNs and GCNs for relational reasoning problems. AutoML may also be helpful by reducing the human burden of assembling different components and choosing hyper-parameters [160].

Dynamic graphs. Most of the existing methods focus on static graphs. However, many real graphs are dynamic in nature: their nodes, edges, and features can change over time. For example, in social networks, people may establish new social relations, remove old relations, and their features, such as hobbies and occupations, can change over time. New users may join the network and existing users may leave. How to model the evolving characteristics of dynamic graphs and support incremental updates to model parameters remain largely unaddressed. Some preliminary works have obtained encouraging results by using Graph RNNs [27], [29].

Interpretability and robustness. Because graphs are often related to other risk-sensitive scenarios, the ability to interpret the results of deep learning models on graphs is critical in decision-making problems. For example, in medicine or disease-related problems, interpretability is essential in transforming computer experiments into applications for clinical use. However, interpretability for graph-based deep learning is even more challenging than are other black-box models because graph nodes and edges are often heavily interconnected. In addition, because many existing deep learning models on graphs are sensitive to adversarial attacks as shown in Section 7.2, enhancing the robustness of the existing methods is another important issue. Some pioneering works regarding interpretability and robustness can be found in [161] and [162], [163], respectively.

8.4 Summary
The above survey shows that deep learning on graphs is a promising and fast-developing research field that both offers exciting opportunities and presents many challenges. Studying deep learning on graphs constitutes a critical building block in modeling relational data, and it is an important step towards a future with better machine learning and artificial intelligence techniques.