Finding the fastest path in the time-dependent road network is time consuming because its problem complexity is Ω(T(|V|log|V|+|E|)) , where T is the size of the result's time-dependent function, |V| and |E| are the number of vertices and edges. There are three kinds of fastest path problems: SSFP (Single-Staring Time Fastest Path) that has a fixed departure time, ISFP (Interval-Staring Time Fastest Path) that selects the best departure time from an interval, and FPP (Fastest Path Profile) that returns the travel time of the entire time domain. In this paper, we aim to answer these three queries in time-dependent road network faster by extending the 2-hop labeling approach, which is fast in answering shortest distance query in the static graph. However, it is hard to construct index for SSFP and ISFP because there are |T| and |T|2 possible time points and intervals, where T is the time domain. Therefore, we first propose the time-dependent hop-labeling for FPP , then provide the specific optimizations for SSFP and ISFP query answering. Moreover, it is both time and space consuming to build an index in a large time-dependent graph, so we partition road network into smaller sub-graphs and build indexes within and between the partitions. Furthermore, we propose an online approximation technique AT-Dijkstra and a bottom-up compression method to further reduce the label size, save construction time and speedup query answering. Experiments on real world road network show that our approach outperforms the state-of-art fastest path index approaches and can speed up the query answering by hundreds of times.
SECTION 1Introduction
With the fast development of GPS technology and mobile network, traffic condition is easier to obtain than ever. For example, Google Map has provided a feature called Google Traffic, which displays traffic conditions in real time on major roads and highways by analyzing the GPS-determined locations transmitted to Google from a large number of mobile phone users. GPS navigators like TomTom also have collected traffic data during the past decade to provide traffic prediction feature. In addition to that, lots of approaches and applications are developed to infer traffic speed on roads from the drivers’ trajectory data [11], [33]. With traffic condition information at hand, the measurement used in path planning has changed from the distance to travel time. So finding the fastest path from one place to another has become an essential query. In fact, there is a much wider range of applications other than trip planning, such as the spreading of information [21] and disease [34], metabolic pathway analysis in biochemist [32] and interactome within cells [31], just to name a few.

Different from the shortest path problem whose edge weights are static values, the fastest path problem uses a time-dependent function of each edge to describe how much time it costs to travel through it at different departure time. Besides, the fastest path between two vertices could be different when the departure time changes. Depending on the length of the departure time, the fastest path problem can be categorized into three different types: SSFP (Single-Staring Time Fastest Path), ISFP (Interval-Staring Time Fastest Path), and FPP (Fastest Path Profile). SSFP takes one single departure time point as the input, and the arrival time of all the vertices during the search is fixed actually. Therefore, it has a similar complexity as the Dijkstra's [8], [10], [28], [39], [40], except that it needs an extra time to retrieve the travel time from the cost function of each edge. When the departure time point becomes a time interval, the fastest path problem becomes ISFP, which is often used to find an optimal departure time that would result in a path with the least traveling time. Because the result is a cost function from source to destination instead of a value, its complexity lower-bound grows to Ω(T(|V|log|V|+|E|)) [12], where T is the size of this cost function (not the edge's function). If we extend the departure time interval to the entire time domain, we are facing the FPP, which is useful in bulk query answering and is a fundamental query for traffic analysis. In fact, FPP is a generalized query that can answer any SSFP and ISFP. Unfortunately, it is even slower than ISFP because it has a larger T. Therefore, in this paper, we aim to speedup the query answering of these three fastest path problems. Additionally, we use the term fastest path to denote FPP throughout this paper because FPP is essentially a fastest path, and fastest path is widely used and can self-explain. Furthermore, all the edges’ time-dependent weight functions follow FIFO property, which forbids overtaking.

We classify and compare the existing approaches, in terms of index construction time, query answering time and index size, as illustrated in Fig. 1. Such a classification also applies for reachability query [25] and distance query [1] on static graph. On one extreme, we can compute the fastest path between each vertex pair by calling the existing fastest path algorithms [9], [20], [24], [26], [37], [38] directly. It consumes no extra space because it has no index at all. However, even the fastest one has to take several seconds to answer the IFSP in a normal city network with hundreds of thousands of vertices, which is too slow to serve as the foundation for other applications. On the other extreme, we could answer this query in O(1) time by retrieving the result from the precomputed all-pair fastest paths. But such an approach is not applicable even on static graph due to its unrealistically long preprocessing time (O(|V|2log|V|+|V||E|))) and quadratic large index size (O(|V|2)), not to mention multiplying a large T. Therefore, some speed-up techniques are proposed for answering fastest path query in an online fashion, based on their original static versions. For example, Bidirectional A* Search [30] augments ALT [15], Time-dependent CH (TCH) [3] expands the original CH [14], Time-dependent SHARC (TSHARC) [6] extends Arc-Flag [23] with CH, and Core-ALT [4] combines landmark, bidirectional search and contraction. However, since these speed-up approaches still have to traverse the graph, they are still time-consuming. And that is why although they claim they can achieve query answering time in ms level, they all conduct their experiments on histogram-based speed profile, which constrains T to a small fixed number that makes the query much easier and faster to answer, rather than linear piecewise functions which is widely used in the original fastest path algorithms. Nevertheless, the benefits of them are the shorter construction time and smaller index size.


Fig. 1.
Comparison between approaches.

Show All

In this work, we aim to speed up the fastest path query answering even faster by taking advantages of 2-hop labeling [5]. By assigning two sets of labels for each vertex's in- and out-distance information to other vertices, static 2-hop labeling can answer the shortest path query only using the labels [1], [16], [17], [19]. However, no existing work ever tries to extend it to the time-dependent scenario due to the following challenges: First, achieving the minimum label size (Ω(|V||E|1/2) on the static graph is already NP-H, and adding another temporal dimension would definitely make it even harder. Second, there is no time-dependent index using linear piecewise function. It is already hard enough for online approaches to stay away from it and only test on histogram-based speed profile. Moreover, unlike in the static version, where the shortest path between a vertex pair is fixed, the fastest path changes over time. In another word, there could be a set of hops instead of only one. Therefore, answering a query is no longer finding the minimum value, but constructing a result minimum function from a set of functions. Last but not least, it is impossible to create a specialized index for SSFP and ISFP, because there are |T| possible departure time points for SSFP and |T|2 possible departure time intervals for ISFP, where T is the time domain. Although both of them can be answered by the result of a FPP query, its efficiency is largely affected by answering the unrelated intervals. For example, for a long distance ISFP query, running a Dijkstra's search is always faster than using the FPP index.

Fig. 2 shows an example of the time-dependent graph we use in this paper. Table 1 only presents the labels of v0 and v8. Because v0 has no in-neighbor, it has no in-label. Similarly, v8 has no out-label. Suppose we are answering the fastest query from v0 to v8, we only need to use v0's out-labels and v8's in-labels. The intersection of these two label sets is (v1,v4,v7), and the corresponding cost functions are illustrated in Figs. 3a, 3b, 3c, 3d, 3e, and 3f. Thus, we only need to compute the cost functions from v0 to v8 via v1, v4 and v7, and return the minimum of them as the result. The three functions are shown in Fig. 3g. If we depart from 0 to 18, the fastest path travels via v4; If we depart from 18 to around 160, the fastest path travels via v7; If we depart later than 160, the fastest path travels via v1. The combination of these three parts is the result of FPP from v0 to v8. Any time point of it is the result of a SSFP, and any interval of it is the result of a ISFP.

TABLE 1 Time Dependent 2 Hop Labels of v0v0 and v8v8
Table 1- 
Time Dependent 2 Hop Labels of $v_0$v0 and $v_8$v8
TABLE 2 Important Notations
Table 2- 
Important Notations
Fig. 2. - 
Example Time-Dependent Graph. (a): Directed graph. (b)-(p): Linear piecewise cost functions for each edge, time domain is [0,300].
Fig. 2.
Example Time-Dependent Graph. (a): Directed graph. (b)-(p): Linear piecewise cost functions for each edge, time domain is [0,300].

Show All


Fig. 3.
(a)-(c): Out-label functions of v0. (d)-(f): In-label functions of v8. (g): Result functions via hop v1,v4 and v7.

Show All

In this paper, we propose a time-dependent hop labeling (THop) approach to answer the fastest path queries efficiently. We first partition the road network into subgraphs and then create labels with and between them. All the labels are stored on disk with index for fast retrieval and sampling for search pruning. After that, we demonstrate how to use THop to answer SSFP, ISFP, and FPP efficiently. Furthermore, we propose an Approximate Time-dependent Dijkstra (AT-Dijkstra) technique for faster construction, and a Bottom-up compression method to further reduce the label size. Extensive experiments using real road network and speed profile shows that we can speed up fastest path query answering by hundreds of times. We also re-construct the state-of-art online search approaches TCH and TSHARC using linear piecewise functions, and shows that our approach outperforms them by hundreds of times.

Our contributions are listed as follows:

We propose a disk-based time-dependent hop labeling approach to speed up the fastest path query answering with linear piecewise function.

We propose three corresponding query answering techniques for SSFP, ISFP, and FPP.

We propose two approximation approaches: AT-Dijkstra technique for faster construction and Bottom-up compression method for smaller index size. Both of them can also speed up query answering.

We thoroughly evaluate our approach with extensive experiments on the real-life road network with linear-piecewise-function-based speed profile. Results show than our approach outperforms the state-of-art ones.

This paper extends the work in [27] where we first introduced the THop. However, the query time of SSFP and ISFP were slower than FPP because we constructed the result for FPP first and used it derive the SSFP/ISFP result. In fact, the original method is always slower than answering SSFP directly in the inter-partition environment, as shown in Fig. 13. In other words, it was specialized for FPP query. In this paper, we extend the THop to support all three kinds of fastest path queries efficiently.

Fig. 4. - 
Example of $Min()$Min() function. Hop set $H_{v_s,v_d}=\lbrace v_{i1},v_{i2},v_{i3}\rbrace$Hvs,vd={vi1,vi2,vi3}. Three dashed lines are the inputs, the solid red line is the output $f_{v_s,v_d}(t)$fvs,vd(t).
Fig. 4.
Example of Min() function. Hop set Hvs,vd={vi1,vi2,vi3}. Three dashed lines are the inputs, the solid red line is the output fvs,vd(t).

Show All


Fig. 5.
Continuous time-dependent hop labeling construction example.

Show All

Fig. 6. - 
Time-dependent path query answering.
Fig. 6.
Time-dependent path query answering.

Show All

Fig. 7. - 
Index Loading Optimization Approaches using ISFP as example. Blank Rectangle: The loaded function. Shaded Rectangle: The actual useful and retrieved function.
Fig. 7.
Index Loading Optimization Approaches using ISFP as example. Blank Rectangle: The loaded function. Shaded Rectangle: The actual useful and retrieved function.

Show All


Fig. 8.
Inter-partition SSFP boundary computation.

Show All


Fig. 9.
Comparison of Departure Time. (a) Intra-ISFP (b) Inter-ISFP.

Show All


Fig. 10.
Index size and construction time.

Show All


Fig. 11.
Inner subgraph query time and speedup.

Show All


Fig. 12.
Road network query time and speedup.

Show All


Fig. 13.
SSFP and ISFP query time and speedup.

Show All

The rest of this paper is organized as following: We discuss the related works in Section 2. Section 3 defines the problem and its corresponding notions. Section 4 presents how to construct the hop labels using graph partitions. Section 5 describes how the labels can be utilized to answer FPP, SSFP, and ISFP efficiently. Section 6 presents the two approximation methods. We evaluate our methods in Section 7 and conclude the paper in Section 8.

SECTION 2Related Work
2.1 Fastest Path Speed-up Techniques
Just like many speedup techniques for reachability and shortest distance queries, there are some time-dependent online search speedup techniques, which are extended from their static versions, to support fastest path queries on the time-dependent graph.

The first category of approaches apply simple augmentation on their original static versions. Bidirectional A* Search [30] augments A* Search Using Landmarks (ALT) [15] by applying the landmarks on the lower bound graph G––, whose edge weights are the lower bounds of their corresponding cost functions. Although the correctness is guaranteed by using the lower bound, it is a loose approximation of the original time-dependent graph so its effectiveness is weak. [6] extends Arc-Flag [23] by counting an edge as important if it appears in a fastest path at least once. Therefore, unlike the original Arc-Flag, this approach has to label even more edges because the fastest path changes over time. Besides, it is time-consuming to construct so [6] applies approximation on preprocessing. Time-dependent CH [3] expands the original CH [14] by adding a shortcut when it is the fastest path for at least once within the whole time period. The second category of approaches combines the previous methods in different ways. Core-ALT [4] is the combination of time-dependent Landmark, bidirectional search and CH, while TSHARC [6] is the combination of TCH and Arc-Flag.

It is obvious that all of the above speedup approaches only apply basic extension to time-dependent scenario by projecting the time dimension to the static graph. In this way, the time-dependent graph is treated as a denser static graph, and those speed-up techniques can be applied directly. Although the query has to adapt to the time-dependent version, the speedup performance is limited by these static structures since the temporal information is discarded to some degree. The reason of this is that the total number of the turning points is much larger than the edge number and the vertex number, which would result in a much longer preprocessing time, although it would speed up the query.

Finally, all of them are online search approaches, which are actually different search space pruning strategies, so they still have to search the graph when answering a query.

2.2 2-Hop Labeling
The 2-Hop labeling was originally proposed by [5] to answer the shortest distance and reachability query efficiently on the static graph. The basic idea of 2-hop labeling is to pre-compute a set of labels for each vertex and answer the query only by the labels of the involved vertices. For example, on an undirected graph, each vertex vi keeps a label set L(vi)={(vj,dvi,vj)}, which stores its shortest distance to vj (dvi,vj). When answering a shortest distance query from vs to vd, we only need to find the vertices {vj} that exist in both of L(vs) and L(vd), and selects the smallest dvs,vj+dvj,vd as the result. By deriving it to the 3-SAT problem, they proved that finding a 2-hop labeling with the minimal size Ω(nm1/2) is NP-H. So they provided an approximate algorithm that can return a label size of log(n) times the optimal lower bound.

From then on, several works are proposed to build the label faster while keeping the size small [1], [13], [18], [22], [35]. However, not too many of them work on the large graph. Highway-centric labeling [19] is inspired by the highway structures in the road network and the existing works of the online search approaches like [22]. By selecting a set of vertices as highway vertices, it can answer the query between them in constant time. In this way, the 2-hop is converted into three parts: the distance from the source vertex to one of the entries in highway, the distance from one entry to exit, and the distance from the exit to the destination. IS-Label [13] breaks the graph into a set of independent sets, such that the graph can be represented in a hierarchical structure. The distance information is preserved in the process of vertex hierarchy construction. Thus, the vertex order is generated directly from the hierarchical structure. By visiting the vertices in this order, and only visiting the vertices of higher level, we can attach labels to the starting vertex. Pruned Labeling [1] mainly focuses on undirected and unweighted graph. By running BFS vertices one by one, the labels are created incrementally. During the search, if the distance to the current vertex can be answered by the existing labels, the searching would not expand from it. The label size can be further compressed in bits, which could speed up the query processing and index construction. Hop Doubling [18] can only work on unweighted scale-free graph. Under the constraint of scale-free, a vertex's betweenness centrality can be approximated by its degree, which derives an effective vertex order naturally.

2.3 Approximation
[36] proposes the α-Dijk to speed up the constraint shortest path search. Although it shares similar spirit with our AT-Dijkstra, they are quite different. α-Dijk aims to prune the dominated paths during search with an upper-bound, which complies with their α-CSP problem, while we want to reduce the time-dependent functions size with an approximation lower-bound.

SECTION 3Preliminary
3.1 Time-Dependent Road Network
A time-dependent road network is represented as a directed graph G(V,E), where V is a set of vertices and E⊆V×V is a set of directed edges, which has a weight function w(E,t)→R mapping edges to time-dependent real-valued weights. The weight of an edge e(u,v)∈E at time t in a time domain T is w(u,v,t), which represents the amount of time required to reach v starting from u at time t. w(u,v,t)=∞ if there is no edge from u to v.

A path p from u to v in G is represented as p=<v0,v1,…,vk>, where v0=u, vk=v and (vi−1,vi)∈E, ∀1≤i≤k. Let α(vi) be the arrival time of vi, and β(vi) be the departure time of vi. The time-dependent cost of p is the sum of the weights on edges at each vi's departure time: w(p)=Σki=1w(vi−1,vi,β(vi−1)). The single starting time fastest path problem on time-dependent road network is defined below.

Definition 1 (Single Starting-Time Fastest Path Problem (SSFP)).
Given a time-dependent graph G(V,E) and a query Q(vs,vd,t), where t is the departure time, SSFP is to find a path with minimal w(p,t)=Σki=1w(vi−1,vi,β(vi−1)), where β(vs)=t,v0=vs and vk=vd.

The road network naturally follows FIFO property: ∀t1≤t2,t1+w(u,v,t1)≤t2+w(u,v,t2), which means no overtaking is considered. Such a property ensures waiting on a vertex would increase w(p). In other words, no waiting on the intermediate vertex is essential to minimize w(p). If we extend the departure time point t to a departure interval [t1,t2], we are facing the ISFP problem, which aims to find the optimal departure time that result in the fastest path:

Definition 2 (Interval Starting-Time Fastest Path Problem (ISFP)).
Given a time-dependent graph G(V,E) and a query Q(vs,vd,t1,t2), where [t1,t2]⊆T is the departure interval, ISFP is to find a path with minimal w(p,t)=Σki=1w(vi−1,vi,β(vi−1)), where β(vs)=t∈[t1,t2],v0=vs, and vk=vd.

If we further extend the departure interval to the whole time domain T, we can get a minimum cost function fvs,vd(t) that records the least travel time at different departure time:

Definition 3 (Fastest Path Profile Problem (FPP)).
Given a time-dependent graph G(V,E) and a query Q(vs,vd), FPP is to compute a minimum cost function fvs,vd(t) such that fvs,vd(t)=min(w(p,β(vs))), ∀β(vs)∈T.

Problem Definition. We study the following problem: given a time-dependent graph G(V,E), construct an index L that given any pair of (vs,vd), it could answer the SSFP query Q(vs,vd,L,t), ISFP query Q(vs,vd,L,t1,t2), and FPP query Q(vs,vd,L) only using L.

3.2 Time-Dependent Hop Cover
For each vertex vi∈V, we pre-compute two sets of labels: out-labels Lout(vi)={(vj,fvi,vj(t))} and in-labels Lin(vi)={(vj,fvj,vi(t)}, where vj is a hop vertex and fvi,vj(t) returns the minimal cost from vi to vj at different departure time t. We use L={(Lout(vi),Lin(vi))|∀vi∈V} to denote the set of all the labels. If L can answer all the queries on G, then we say L is a time-dependent hop cover.

A minimum cost function query Qf(vs,vd,L) returns fvs,vd(t) only using the labels, as shown below:
Qf(vs,vd,L)=Min(fvs,vd,vi(t))=Min(fvs,vi(t)⊕fvi,vd(t))=Min(fvi,vd((fvs,vi(t)+t))=fvs,vd(t),t∈T∀vi∈Hvs,vd=Lout(vs)∩Lin(vd)
View SourceRight-click on figure for MathML and additional features.

If vi exists in both vs's out-label set and vd's in-label set, vi is a hop vertex of this query. For all the hop vertices vi∈Hvs,vd, we compute the minimum cost functions from vs to vd via vi: {fvs,vd,vi(t)} by the concatenation operation ⊕ of two time-dependent functions, which is computed as fvs,vd,vi(t)=fvs,vi(t)⊕fvi,vd(t)=fvi,vd((fvs,i(t)+t). Min() is a function that takes all the {fvs,vd,vi(t)} as input, and combines the smallest function pieces at each sub-time interval as the minimum cost function fvs,vd(t). An example is shown in Fig. 4. As for the example of Fig. 3, the input functions are {f7,3,0(t),f7,3,1(t),f7,3,4(t)}. Because f7,3,0(t) is always smaller than the others, f7,3(t)=Min({f7,3,i(t)})=f7,3,0(t). Both ⊕ and Min() operations are also used in the label construction.

Within each minimum cost function piece fvs,vd,vi(t), we use Vs,d,i to denote the set of vertices along the fastest paths from vs to vd via vi. The number of hops in the hop cover L is |L|=Σ|V|i=1(|Lin(vi)|+|Lout(vi)|).

SECTION 4Time-Dependent Hop Label Construction
In this section, we describe how to construct the time-dependent hop labels. Like the static hop labels, the index size and construction time grows fast as the graph becomes larger. Therefore, our labels are organized in a partition-based fashion: the road network is partitioned into several vertex-disjoint subgraphs, and the labels are constructed within and between the subgraphs. In the following, we first describe how to partition the graph in Section 4.1. After that, we present how to construct the labels within and between the subgraphs in Sections 4.2 and 4.3. Finally, correctness analysis is provided in Section 4.4.

4.1 Graph Partition
Given an input graph G, we partition it into a set C={G1,G2,…,G|C|} of vertex-disjoint subgraphs of G, such that ⋃i∈[1,|C|]Gi=G. If an edge appears in two different subgraphs, it is a Boundary Edge. The two end vertices are called Boundary Vertices. Graph partitioning is a well-studied problem and we could use any existing solutions. In our implementation, we use the state-of-art Natural Cut method [7], because such an approach can create only a small number of boundary vertices.

Based on if a vertex is boundary or not, we construct the THop differently. For all the boundary vertices, we create a Boundary-THop for them, where all the hops are boundary vertices, and the path information is still computed from the original graph. For all those vertices that belong to the same subgraph, we construct a THop for each subgraph, which also includes the boundary vertices it contains.

4.2 Subgraph Label Construction
In order to help understand our construction procedure, we first demonstrate a naive one. Suppose the vertices are ordered in V={v1,v2,…,vn} and we visit them in this order. Intuitively, we run a single source fastest path search from each vi∈V to get fvi,vj(t) from vi to all the other vertices vj∈V−{vi}, and run another reverse backward fastest path search to get fvj,vi(t) from all the other vertices vj to vi. We use Li={(Liout(vj),Liin(vj))|∀vj∈V} to denote the label set we get after the searchings from vi. Initially, L0=ϕ. Suppose after the searchings from vk−1, we obtain a label set Lk−1={(Lk−1out(vj),Lk−1in(vj))|∀vj∈V}. Then we run a fastest path search from vk, and get all the minimum cost functions from vk: {fvk,vj(t)}. Therefore, we update the in-label sets Lkin(vj)=Lk−1in(vj)∪(vk,fvk,vj(t)), ∀vj≠vk. Meanwhile, we run a reverse backward fastest path search from vk and get all the minimum cost functions from vj to vk: {fvj,vk(t)}. Correspondingly, we update the out-label sets Lkout(vj)=Lk−1out(vj)∪(vk,fvj,vk(t)), ∀vj≠vk. This procedure continues until the last vertex vn finishes searching.

Algorithm 1. Time-Dependent 2-Hop Construction
Input: G(V,E)

Output: L

begin

for i=1,…,|V| do

//Forward search, create in-labels

//FM stores all temporay labels: FM[vd]=fvi,vd(t)

FQ.push(vi)

while !Forward_Queue.empty() do

vj←Forward_Queue.pop()

if Qf(vi,vj,L^i−1) domintes FM[vj] then

continue

for vk←vj's out-neighbor do

fvi,vk,vj(t)←fvi,vj(t)⊕wvj,vk(t)

FM[vk]←Min(FM[vk],fvi,vk,vj(t))

Forward_Queue.update(vk)

//Similar for backward search, create out-labels

for vd∈FM and vd was not skipped do

L^iin(vd)=L^i−1in∪(vi,FM[vd])

for vd∈BM and vd was not skipped do

L^iout(vd)=Li−1out∪(vi,BM[vd])

return L^|V|

Obviously, the result of this approach is exactly the same as all-pair pre-computation, so it has generated a hop cover that can answer query correctly. However, it is inefficient in both construction time and label size. Therefore, we apply a pruning approach to reduce the search space, which could further reduce the construction time and Size(L). We use L^i to denote the result after the ith pruning search on vi.

Suppose we just finish visiting vk−1 and get a label set of L^k−1={(L^k−1out(vj),L^k−1in(vj))|∀vj∈V}. Then we start a fastest path searching from vk. During the search, each time when we settle a vertex vi, we can obtain a function fvk,vi(t). At the same time, we also run a query Qf(vk,vi,L^k−1) to obtain an intermediate function fk−1vk,vi(t)=Min({fvk,vj(t)⊕fvj,vi(t)|vj∈L^k−1out(vk)∩L^k−1in(vi)}). If fvk,vi(t) is dominated by query result fk−1vk,vi(t), i.e., fvk,vi(t)≥fk−1vk,vi(t), ∀t∈T, then we prune the search from vi, which means we do not add (vi,fvk,vi(t)) to Lk^ and we also do not visit the edges from vi. The same pruning strategy also applies on the reverse backward fastest path search. We demonstrate this procedure in Algorithm 1.

Fig. 5 demonstrates an example of the index construction using the time-dependent graph of Fig. 2. We visit the vertices in order (v1,v4,v7,v2,v5,v6,v3,v0,v8) (from Figs. 5a, 5b, 5c, 5d, 5e, 5f, 5g, 5h, and 5i). The first row shows the behavior of pruned forward search while the second row shows the pruned backward search. The green edges are the visited edges, while the black ones are skipped. We use blue vertex to denote where we start from. Red vertices denote the ones that are dominated by the existing THop labels. We do not update the red vertex's neighbors, so their out/in-edges stay black. The yellow ones are the visited during the search, and the white ones are not visited in the current search. For example, Fig. 5a is the first round of two searches from v1. Because no hop exists at this stage, nearly all vertices that v1 can reach are visited and the results are put into the in- and out-labels. Fig. 5b shows the second round of search from v4. In the backward search, v1 is skipped because fv1,v4(t) exists in the in-label of v4. The remaining searches follow the same procedure, and it is obvious that the searching spaces of latter searches are smaller than the earlier ones.

When the construction is applied to a subgraph with boundary vertices, we have to make sure we already have the boundary labels. This is because the fastest paths may not always reside inside the subgraph, it could travel out of the boundary and go back via another boundary. Therefore, the existing boundary labels could help to capture this information. The boundary label construction is discussed in the following section.

4.3 Boundary Label Construction
Since the boundary vertices separate the vertices from different subgraphs, all the paths that involve different subgraphs have to pass through them. Therefore, the boundary vertices are naturally hop vertices. Although the number of the boundary vertices is on the same level of the subgraphs’, its space consumption is larger. This is because the paths between boundary vertices are longer than the paths within each subgraph, and longer paths have more turning points.

One straightforward approach is to construct the labels directly like the sub-graph. However, it would be much slower because the fastest path searches actually run on the entire large graph. Meanwhile, the space consumption is also too huge to tolerate. Moreover, searches of different iterations can only run one by one rather than in parallel, which further prolongs the construction time. Therefore, our boundary-THop construction runs in 2 phases: parallel all-pair construction phase and pruning phase. During the first phase, we take advantage of the modern multi-thread technique and compute the all-pair results of the boundaries in parallel. The searches still origin from each boundary vertex. The result of each search is written to disk right after it finishes. When all the searches finish, we have obtained all the searching results of each boundary vertex. Then during the pruning phase, we load these searching results in a predefined order and prune them in a similar way as described in Section 4.2. We use L^Bi to denote the result after processing the ith boundary vertex. Suppose we just finish visiting vBk−1 and get a label set of L^Bk−1. Then we load results of vk and test each fastest path fvk,vd(t) (or fvd,vk(t)). If it is dominated by the result of query Qf(vk,vd,L^Bk−1) (or Qf(vd,vk,L^Bk−1)), we can safely drop it. Otherwise, it is added to L^Bk. After the last result is processed, we get a time-dependent hop cover of boundary vertices L^B.

4.4 Correctness Analysis
In this part, we prove L^ is a time-dependent hop cover in a subgraph. The correctness of the boundary and between the partitions can be easily extended. First, the following lemma gives an instance of correct hop cover.

Lemma 1.
Ln is a time-dependent hop cover.

Proof.
Since Ln is an all pair fastest path index, then ∀vs,vd∈V, both of (vd,fvs,vd)∈Lnout(vs) and (vs,fvs,vd)∈Lnin(vd) hold. Therefore, Lnout(vs)∩Lnin(vd) contains at least {(vs,fvs,vd),(vd,fvs,vd)}, and their functions are the same. Thus, Qf(vs,vd)=Qf(vs,vd,Ln)=fvs,vd(t). So Ln is a time-dependent hop cover.

To prove L^ is a time-dependent hop cover, we only need to prove Qf(vs,vd,L^n)=Qf(vs,vd,Ln),∀vs,vd∈V. In fact, we prove it by showing the both label sets created in iteration k has the same cover capability in Theorem 2.

Theorem 2.
Qf(vs,vd,L^k)=Qf(vs,vd,Lk), ∀k∈[0,n].

Proof.
We prove it by math induction on the search iteration number i. Initially, i=0⇒L0=L^0=ϕ. Then suppose Qf(vs,vd,L^i)=Qf(vs,vd,Li) for 0≤i≤k−1. Now we prove it still holds for i=k.

First of all, suppose the minimum cost function query Qf(vs,vd,Lk−1) that using label set Lk−1 can return a result fk−1vs,vd(t). Otherwise, just simply ignore the query and use the search result as the hop labels. Thus, we need to prove the result of Qf(vs,vd,L^k−1), f^k−1vs,vd(t), is exactly same as fk−1vs,vd(t). Second, as mentioned in Section 3.2, fk−1vs,vd(t) is made up of a set of functions from different vertices in Hvs,vd. Thus, we only need to prove one of the functions fvs,vd,vh(t), which is created by hop vertex vh, can also be created by query using L^k−1. In this way, we can prove each part of f^k−1vs,vd(t) equals to the corresponding part of fk−1vs,vd(t), which leads to f^k−1vs,vd(t)=fk−1vs,vd(t).

Although the paths of minimum cost function change over time, we can still break it into pieces based on the time interval such that within each piece, the vertices along each fast path is fixed. For any piece of fk−1vs,vd(t), suppose h is the smallest vertex order (or earliest search iteration) that creates that piece. Otherwise, we use a smaller one to replace vh for proof. Obviously, (vh,fvs,vh(t))∈Lk−1out(vs) and (vh,fvh,vd(t))∈Lin(vd)k−1. All we need to prove is that both of (vh,fvs,vh(t)) and (vh,fvh,vd(t)) also exist in the pruned sets L^k−1out(vs) and L^k−1in(vd), respectively.

We prove (vh,fvs,vh(t))∈L^k−1out(vs) first. In fact, we prove ∀vx∈Vvs,vh,(vh,fvx,vh(t))∈L^k−1out(vx), where Vvs,vh is the set of vertices along the path from vs to vh during that piece of time interval. In other words, we prove labels (vh,fvx,vh(t)) are added to L^out(vx) at the hth iteration. First, the labels that contain vh can only be inserted when we run the hth search from vh. Second, Vvx,vh⊆Vvs,vh because vs is the source vertex along the path vs to vh while vx is an inner vertex. Since vh is the smallest hop vertex that results in fk−1vs,vd,vh(t), then ∀i<h, hop vertex vi∉Vvx,vh. In other words, no hop vertex exists along the path vs to vh, so label set L^h−1 cannot return a result same as fvx,vh(t). Therefore, the result of Qf(vx,vh,L^h−1) cannot dominate fvx,vh(t), so (vh,fvx,vh(t)) is added to L^h−1out(vx) during the hth backward search. Thus, (vh,fvs,vh(t)) exists in L^k−1out(vs). As for (vh,fvh,vd(t))∈L^k−1in(vd), it can be proved symmetrically.

So when k=n, we can safely draw the conclusion that Qf(vs,vd,L^n)=Qf(vs,vd,Ln), which means the result of the pruned approach is the same as all pair approach.

Corollary 3.
The label set L^ constructed from Section 4.2 is a time-dependent hop cover.

Theorem 4.
If we remove any hop vh from any vertex vi's L^out(vi) or L^in(vi), L^ is not a time-dependent hop cover.

Proof.
Suppose we remove (vh,fvs,vh(t)) from L^out(vs). This would directly cause fvs,vh(t)≠Qf(vs,vh,L^). First of all, ∀i<h, Qf(vs,vh,L^i) cannot dominate fvs,vh(t), otherwise (vh,fvs,vh(t) would not be added to L^out(s) during the hth iteration. Second, because vh was in vs's out-label, vh appeared earlier during the construction. Therefore, vs would not be added in vh's in-label set during the sth iteration since it was dominated by Qf(vs,vh,L^s−1) and (vh,fvs,vh(t))∈L^s−1out(vs). Thus, the incomplete L^ is not a time-dependent hop cover.

As for the complexity analysis, please refer to [27].

SECTION 5Query Processing
In this section, we present how to use the labels to answer different kinds of fastest path queries. The query answering has two situations: If vs and vd are from the same partition, we use the inner labels of that subgraph to answer the query directly; If they are from different partitions Gi and Gj, we decompose the query result into three components: from vs to its boundary vertices GBi, from vs's boundaries GBi to vd's boundaries GBj, and from GBj to vd. Then we concatenate the three results and construct the final result. The first case is called Intra-Partition, and the second one is called Inter-Partition. Because the FPP query processing is the basis of the label construction and the other query types, we first present it in Section 5.1. Then we dig into the query optimization of SSFP and ISFP in Sections 5.2 and 5.3.

5.1 FPP Query
5.1.1 Intra-Partition FPP Query
A straightforward way to answer Q(vs,vd,L) is checking the hops Hvs,vd one by one. First, we use a hash table to retrieve the common hop vertex set Hvs,vd=Lout(vs)∩Lin(vd). This process takes O(min(|Lout(vs)|,|Lin(vd)|)) time. If vs∈Lin(vd) or vd∈Lout(vs), we can return hop function as the query result directly because it is guaranteed to be the minimum cost function. Otherwise, we construct cost functions fvs,vd,vi(t) using the concatenation operation fvs,vi(t)⊕fvi,vd(t)=fvi,vd(fvs,vi(t)+t) on each vi∈Hvs,vd. The final result fvs,vd(t) is generated by Min({fvs,vd,vi(t)}). Therefore, this query process approach takes O(|T|∗|Hvs,vd|) time, where |T| is the average number of linear piecewise functions of fvs,vd(t).

However, it might be acceptable to put the index of one subgraph in memory, but it is unrealistic to store the indexes of all the subgraphs and boundaries, so our indexes are store on disk. Moreover, many hop results cannot contribute to the final minimum cost function, so it is not only a waste of time to concatenate them, but also time consuming to load them from the disk. Therefore, in the following, we first describe how the indexes are organized on disk, then we present how to speed up the query answering by pruning the unnecessary IO and computation.

The label file consists of four parts: Index I~, Hop H~, Sample S~ and Function F~. Index I~ stores the address of each vertex's S~ and F~ on disk for fast retrieval. Hop H~ only stores the in/out-label IDs of each vertex. Sample S~ is the approximation of each hop's function. It divides the function into 12 two-hour intervals and records the minimum and maximum costs. Function F~ stores the actual time-dependent functions. Both S~ and F~ have their inner indexes for fast retrieval.

Now we are ready to describe how to utilize these structures to reduce the query time on disk. The involved structures and the query procedure are illustrated in Fig. 6. First of all, the Hop H~ of all the vertices are maintained in memory as their sizes are small. When a query Q(vs,vd,L) is issued, we first use their hops to obtain the candidate hop set Hvs,vd. This step is the same as the previous approach. After that, we load the samples of the corresponding hops from disk and create a 12-dimensional sampling vector S~i for each of them. For example, ∀j∈[0,11], its jth element is a pair of (S~i.minj,S~i.maxj), where S~i.minj=fvs,vi(t).minj+fvi,vd(t).minj and S~i.maxj=fvs,vi(t).maxj+fvi,vd(t).maxj. Among these sampling vectors, if S~i's minimum values are all larger than S~j's corresponding maximum values, then there is no need to compute the exact function of the hop vi. In other words, S~i is dominated by S~j. Therefore, we only need to consider the skyline vectors of Hvs,vd, which is denoted as H′vs,vd.

For all the hops in H′vs,vd, we use fvs,vi(t).min+fvi,vd(t).min as key and push them into a minimum heap. It should be noted that this key is the lowerbound of the actual function using each hop. Each time we retrieve the top hop and compare it key with maximum value of the current result fvs,vd(t).max. If the key is not smaller than fvs,vd(t).max, then we are safe to return fvs,vd(t) as the final result because all the hops remaining in heap have larger values than fvs,vd(t) and have no chance to update fvs,vd(t). Otherwise, we do the actual time-dependent function concatenation and update the temporal result fvs,vd(t) with minimization.

During the label construction phase, because all the queries are related to the current subgraph, we keep all the temporal indexes in memory. The in-memory query answering follows the same procedure without IO.

Finally, we analyze the query answering time. The average label number of each vertex is |L|/2|V|. During the query time, we check the common hop vertices of vs and vd. Obviously, |Hvs,vd|=O(min(|L|/|V|)). For each hop vertex, it takes O(T) time to concatenate and minimize. Therefore, the worst case is O(T|L|/|V|).

5.1.2 Inter-Partition FPP Query
The inter-partition FPP query is made up of two sets of inner queries (vs to GBi and GBj to vd) and one set of boundary queries (GBi to GBj). Because the FPP query takes the entire time domain as the input, these three sets of queries are independent to each other. In other words, their input time intervals are constraint by the other's output. Therefore, it is safe to run them in parallel. In the following, we first describe how to answer these three queries, then we present how to combine them to obtain the final result.

First of all, the query set from vs to GBi is made up of queries from vs to all the boundary vertices in GBi. Obviously, these queries can run in parallel, so the actual query set running time is the same as one single query in a subgraph. Meanwhile, the query set from GBj to vd is symmetric to vs to GBi. Their result sets are denoted as Fvs,GBi(t) and FGBj,vd(t), respectively.

Second, the boundary query set from GBi to GBj has |GBi|×|GBj| queries and it is time-consuming to compute all of them. In order to avoid loading all the hop functions, we first visit the two hops Hi~ and Hj~ and construct two hop reading lists. Suppose vi∈GBi and vj∈GBj. If vj∈Hi~ or vi∈Hj~, then we only need to read (vj,fvi,vj(t)) or (vi,fvi,vj(t)) and return the result without further computation. If this condition holds for vi to all vj∈GBi, then we do not need to load the any other hop functions from vi. In other words, vi's reading list is empty except for vj∈GBj. Otherwise, we takes ∪|GBj|j=1(Hi~∩Hj~),(∀vj∉Hi~ or vi∉Hj~) as vi's reading list. Similarly, another reading list can be obtained for vj∈Hj~. After that, we can compute the results of the boundary query set in parallel.

Finally, after obtaining the three result sets, we concatenate them to generate the final result. However, the combination space is |GBi|×|GBj| and each of them involves two concatenations. Hence, we have to prune the search space as much as possible. Similar to the intra query, we sample the results of the query sets but do not generate the sampling vectors at this stage. Instead, we first sort the boundary functions based on their minimum values and retrieve them in the increasing order. This is based on the observation that those boundary functions which are made up of two boundary vertices from opposite directions of the query search direction would result in much larger results and are useless (easier to be dominated by the final one), and we try to avoid visiting them. In fact, some of the boundary results could be larger than the final result. Each time we retrieve a fvBi,vBj(t) and compute a lowerbound with its minimum value and those of its two corresponding inner results. If this lowerbound is larger than the result's maximum value, we can discard fvBi,vBj(t) directly. Otherwise, we generate the sampling vector with its two corresponding inner results. If it is dominated by the current result's sampling vector, we can also ignore it. If it worths trying, we concatenate it with two inner result functions: fvs,vBi(t)⊕fvBi,vBj(t)⊕fvBj,vd(t). Then use this result to update the current existing fvs,vd(t). When no function can update fvs,vd(t), we return it as the query result. The inner subgraph query time is O(T|LC||V|/|C|), where |LC| is label size of the subgraph. The boundary query time is O(T|LB|×(2|B|/|C|)2)=O(T|B|2|LB||C|2). The concatenation and update operation takes O(T|LB|2|C|2) time. The overall query time is the maximum of inner- and boundary query time plus update time.

5.2 SSFP Query
The previous sections present how to answer the FPP query. Although the result of a FPP query cover all the SSFP and ISFP query results with the same source and destination, lots of unnecessary computation is involved. For example, if the query only asks for the fastest path at 9 am, there is no need to construct the entire function of 24 hours. Or if the query ask for the fastest path between 4 pm and 6 pm, there is no need to compute the cost functions before 4 pm and after 6 pm. Therefore, if we avoid the useless computation as much as possible, then the query answering time could be much faster. Obviously, optimizations for the SSFP and ISFP queries are also critical in reality, and we present them in the following two sections. Although some details are different, similar pruning procedures are also applied to any type of query answering.

The essential idea of speeding up query answering is to avoid the unnecessary file reading and function computation as much as possible. When a query is issued within a partition, the optimization mainly focuses on reducing the computation as the file index loading is not big; when the query is issued between partitions, the optimization is mainly about reducing the disk reading because more indexes are involved.

5.2.1 Intra-Partition SSFP Query
Given a SSFP query Q(vs,vd,L,t), in terms of the computation, the intra-partition SSFP query essentially returns min(fvi,vd(fvs,vi(t)+t)), where t is a static value rather than a variable, and min(fvi,vd(fvs,vi(t)+t)) is also a single value. Therefore, we only need to find the exact values of fvs,vi(t) and fvi,vd(fvs,vi(t)+t) and take the sum of them instead of concatenation and minimizing any cost function to determine the cost of each hop.

The most straightforward approach of finding the value is loading the entire functions, creating a complete cost function, and returning the travel cost at t. Obviously, the function construction is unnecessary, so the first improvement would be retrieving the fvs,vi(t) and fvi,vd(fvs,vi(t)+t) values from the loaded index without concatenating fvs,vi and fvs,vi explicitly, and we call this approach THop-1. However, loading the values larger than t is useless so we can stop the disk reading when t is reached, and this approach is called THop-2. To further reduce the data loading, binary search can also be applied to the search of t and we label this approach as THop-3. The examples of these three approaches are illustrated in Fig. 7. Although it uses the ISFP as the example, SSFP shares the similar spirit. Apparently, the first and third methods have stable reading times of |T| and log|T|, while the performance of THop-2 is affected by the position of t. If t appears earlier, little data is retrieved so it has better performance than the third one; if t appears later, it could deteriorate to THop-1. The time complexity of these algorithms are O(α(⋅)|L|/|V|), where α(⋅) is the complexity to load the retrieve the data. We did not show this term in FFP because it is dominated by T. THop-1's α(⋅) is α(T), while THop-2's is α(t<T) and THop-3's is α(logT).

5.2.2 Inter-Partition SSFP Query
Like the FPP query, the basic inter-partition SSFP query Q(vs,vd,L,t) is also made up of three parts: fvs,vBi(t)⊕fvBi,vBj(t)⊕fvBj,vd(t). However, these three parts cannot run in parallel because we cannot know the exact departure time of {vBi} before fvs,vBi(t) is obtained, and similarly for {vBj}. Besides, disk reading takes longer time than computation for SSFP. Therefore, computing these three parts in a linear way seems inevitable. In order to reduce the influence of this restriction, we identify some improvements where parallel and pipeline can step in. First of all, the reading list and hop candidate generation phase can work in parallel. Second, whenever a result of t+fvs,vBi(t) is obtained, it can move to the boundary query part. Third, whenever a result of a boundary query is obtained, it can move to the third query part. In this way, the three big query sets are split into |GBi|+|GBj| sub-query sets and they can run in pipeline.

Fig. 8 illustrates how the query logic works. First, the construction of fvs,vBi(t) is similar to intra-partition one, except it creates temporal results for all the boundaries of GBi. Each temporal result can run in pipeline to find its arrival time to each vBj using boundary query. After that, for each boundary vBj from GBj, when all of the temporal results from vBi in its reading list are obtained, its earliest arrival time is determined by taking the minimum of them (due to the FIFO property). Finally, the destination arrival time from the boundary vBj is computed in pipeline with the helps of the labels from GBj's boundaries. All these three steps also follow the three improvements introduced previously, and their complexity times the corresponding α(⋅).

5.3 ISFP Query
Unlike the SSFP query, which only needs the result of a time point, ISFP query needs the result from a time interval. Therefore, the cost function construction and computation are inevitable. The essential part of ISFP is determining the arrival/departure intervals of the related hops.

5.3.1 Intra-Partition ISFP Query
Like the case of SSFP, the intra-partition query is also the basis of the inter-partition query. The first approach is also loading the entire function first, but it generates sub-functions for faster computation. The interval of the out-label is the same as the departure interval, while the interval of the in-label depends on the arrival time of the hop. By limiting the size of the functions to the useful parts, shorter concatenation and minimization time can be achieved. The second approach reads through the label function but starts constructing at the beginning of the interval and stops at the end. The third approach uses binary search to determine the beginning of the interval and constructs the function to the interval end (only on binary search is needed as the end is eventually visited with the data loading). These approaches are shown in Fig. 7. The complexity of these three algorithms are O(α(⋅)I|L|/|V|), where I is the turning point number of the result interval, THop-1's α(⋅) is α(T), THop-2's is α(t+I), and THop's is α(logT+I).

5.3.2 Inter-Partition ISFP Query
The main difference of the inter-partition ISFP lies in the interval determination. For the first part fvs,vBi(t), it generates the sub-function of each boundary in the first partition. For the second inter-boundary part, because one hop may come from different boundary's out-label, its interval is the union of these out-labels’ intervals (the minimum of the beginnings and the maximum of the ends). Then the in-labels use these intervals as the limit to organize their sub-functions. The third part follows the same procedure as its hops also come from different out-labels. The difference compared with the Intra- version is illustrated in Fig. 9. The three parts also cannot run fully parallel but in the partial parallel and pipeline way as we cannot estimate the interval of the labels accurately. Their time complexities are similar to the FFP, except replacing T with I and multiplying the corresponding α(⋅).

SECTION 6Approximation Techniques
As analyzed in the previous sections, the turning point number T has a big influence on the time complexity. Therefore, reducing its size is essential to speed up construction and query time. In this section, we propose two techniques for this task. Section 6.1 presents the Approximation Time-dependent Dijkstra method that reduce T on the fly, and Section 6.2 describes the Bottom-up compression.

6.1 AT-Dijkstra
Given an approximation ratio α∈(0,1), we aim to construct an approximate minimum cost function Avi,vj(t) that ∀t∈T,αfvi,vj(t)≤Avi,vj(t)≤fvi,vj(t). However, we cannot apply the approximation ratio on the edges along the route directly. Suppose a path is made up of a series of consecutive edges E^=<e1,e2,…,en> and ||E^|| is the length of E^. If we apply an approximation factor α1 on e1, α2 on e2 and so on, the final error does not grow linearly, as shown in
||E^||′=((((e1α1+e2)α2)+e3)α3+...en)αn=α1α2α3...αn e1+α2α3...αne2+...+αnen=∑i=1n∏j=inαjei.(1)
View SourceTo achieve ||E^||′≥||E^||, we have to guarantee ∏nj=1αj≥α. In another word, we can view α as a total budget of pruning power along the path, the larger the budget assigned to a vertex, the stronger pruning power it has to reduce the turning points. Because the turning point numbers of the earlier visited vertices are much smaller than those of the latter visited ones, we concentrate the pruning power to the latter vertices by setting a global turning point number threshold ρ: Only those vertices whose turning point numbers exceed ρ will be pruned. We run several sampling searches and use 1/3 of the average T as ρ.

Suppose at some searching stage we have a |fvi,vj(t)|>ρ and its pruning power is αi. The pruning process visits the turning points one by one in a sliding window way. Each time we visit a turning point pi, we put it into a PointList. It can be pruned only if all the points pj in PointList can be safely replaced by point pj,i+1 on line (pi−1,pi+1). The safe replacement has two conditions. First, pj,i+1 has to be no smaller than αipj, as required by approximation bound. Second, pj is no smaller than pj,i+1, because the smaller value has a higher possibility to result in the final optimal result. If any pj does not satisfy these two conditions, pi cannot be pruned and we empty the PointList. When all the points are visited, we return the remaining points as the approximate function Avi,vj(t). Since pj,i+1≥αipj is strictly required, Avi,vj(t)≥αifvi,vj(t).

Algorithm 2. Bottom-Up Approximation
Input: fvs,vd(t), error threshold ε

Output: f^vs,vd(t)

begin

size←|fvs,vd(t)|, R=<0,1,…,size−1>

do

minError=inf

for j from 1 to |R|−1 do

errorTmp=Error(fvs,vd(t),R[j−1],R[j+1])

if errorTmp<minError then

minError=errorTmp, breakPoint=j

if minError<ε then

R.erase(breakPoint)

while minError⩽ε

return fvs,vd(R)

Function Error(fvs,vd(t),R[i],R[j])

error←0

f′(t)←linear<fvs,vd(t[R[i]]),fvs,vd(t[R[j]])>

for k from R[i]+1 to R[j] do

error←error+f′vs,vd(t[k])−fvs,vd(t[k])

return error

Now it remains how to distribute the pruning power. We choose to reduce it exponentially. Initially, we keep the pruning power's logarithm Δi for each vertex and set them to 1. The first pruning vertex vk has the pruning budget αΔk2=α12. During the pruning, we can get its actual pruning usage by βk=max(pi,j/pi), where pi is the pruned point. Then the remaining pruning power logarithm for v′ks out-neighbor vj is Δk−logαkβk. If vj is to be pruned, its pruning budget is αΔk−logαβk2. Because each time we only take half of the remaining power, the sum of the used power β is smaller than 1 (αβ1αβ2...αβn=α∑ni=1βi), as proved in Equation (2). That is to say, the actual approximation ratio αβ is larger than α. In this way, the approximation bound α is guaranteed. We also set a lower bound for αi to avoid the useless pruning.
∑i=1nβi=∑i=1n−1βi+βn<∑i=1n−1βi+1−∑n−1i=1βi2=12+∑n−1i=1βi2<12+12+∑n−2i=1βi22<⋯<∑i=1n12i+β12n<∑i=1n+112i<1.(2)
View Source

6.2 Bottom-Up Compression
Although the partition approach can reduce the label size of the direct THop, it is still huge when the road network is big. Therefore, we provide a Bottom-Up method to compress the labels, which guarantees the approximation ratio is bounded by a given ϵ.

The detail of the approximation is shown in Algorithm 2. It takes fvs,vd(t) and an error bound ϵ as input, and returns the approximated function f^vs,vd(t) with fewer turning points. The algorithm runs in iterations. Within each iteration, it removes the turning points that would introduce the smallest error. It stops when no remaining turning point can produce an error smaller than ϵ. We use an array R to store the indexes of the remaining turning points, initially from 0 to the number of turning points in fvs,vd(t) (line 2). For all the turning points except the two ending points, we compute the error that introduced by removing every single one of them at a time (line 6), and actually remove the one introducing the minimum error. The removal is implemented by erasing the index in R (line 10). The introduced error is computed by a function Error (line 7). It first constructs a linear function f′(t) with two ending points (t[R[i]],fvs,vd(t[R[i]])) and (t[R[j]],fvs,vd(t[R[j]])), where t[R[i]] is the R[i]th time point (line 16). It should be noted that although j−1 and j+1 is separated by only one number, their actual values R[j−1] and R[j+1] could be separated by multiple numbers because they were erased in the previous iteration. We need to accumulate the errors of all these intermediate values, by computing the differences between original value and its corresponding value on the linear function f′vs,vd(t), to get the total error (line 18). When no error is smaller than the input error bound, the iteration stops and a new minimum cost function is returned by only keeping the remaining turning points in R.

Because the query answering considers two labels, the error bound of inner partition result is 2ε. As for the query between partitions, it is 6ε obviously.

SECTION 7Experiment
In this section, we experimentally evaluate the proposed THop labeling on real-life road network against the current state-of-the-art methods. Section 7.1 describes the experiment settings. The influence of subgraph size on construction time and label size is discussed in Section 7.2. Sections 7.3 and 7.4 present the evaluations on subgraph and large road network, respectively.

7.1 Experiment Setup
All the algorithms are implemented in C++, compiled with full optimizations, and tested on a Dell R730 PowerEdge Rack Mount Server which has two Xeon E5-2630 2.2 GHz (each has 10 cores and 20 threads) and 378G memory. The data are stored on a 12 × 4 TB Raid-50 disk.

Dataset. We obtain our road network of Beijing from NavInfo. It consists of 312,350 intersections and 403,228 roads, which covers a 184 km × 185 km spatial range. Then we partition it using Natural Cut [7] with subgraph sizes set to 1000, 2000 and 4000. The 1000-partition has 339 subgraphs with 6888 boundary vertices, while the 2000-partition has 171 subgraphs with 4022 boundaries, and 4000-partition has 84 subgraphs with 3014 boundaries. The speed profile is derived from trajectory data we obtained from DiDi [29]. The average turning point number is 26. Most roads in the inner city have more than 60 turning points, while the rural roads typically have less than 20 turning points.

Query Sets. The subgraphs are categorized based on their speed profile density (average turning points per edge weight function): Sparse (≤20), Medium (from 25 to 40) and Dense (≥45). For the subgraph evaluation, we run four tests with densities of 5, 20, 45 and 60. For the road network evaluation, we run tests between different subgraph categories. The variation of the tests is distance. For each test set, we generate 100 vertex pairs randomly.

Methods. Our method is denoted as THop. The AT-Dijkstra is denoted as THopAT and α=0.97. The Bottom-up compression is denoted as THopBU and ϵ=20. We implement the time-dependent CH (TCH) using the heuristic method described in [2], with hop limit set to 20. The time-dependent SHARC (TSHARC) is implemented using the method of [6]. The baseline approach is the fastest path algorithm (FP) [24]. The three optimizations of SSFP and ISFP are denoted as THop-1, THop-2, and THop-3.

7.2 Construction Time and Label Size
The label sizes are illustrated as bars and the construction time is illustrated as circle in Fig. 5. As the subgraph size increases, the boundary number decreases, which leads to smaller boundary labels and larger inner labels. Because the boundary construction is much slower than the inner one, the 1000-partition takes the longest time to construct. The 4000-partition is also slow because its subgraphs are larger. Obviously, the 2000-partition is the fastest to construct and has the smallest label size, so we use it as our testing partition. The AT-Dijkstra method can save the construction time dramatically, while reduce the label size nearly by half. As for the bottom-up compression, it has the highest compression rate, but it takes the longest time because it works on the original result.

7.3 Evaluation of FPP in Subgraph
The experiment results are shown in Fig. 11. The bars are the actual running time, and the markers are the speedup ratio compared with FP. Both of these two values are shown in log. Since the sparse subgraphs cover larger area (rural regions) and the dense subgraphs cover smaller area (urban regions), we test long queries in sparse subgraph and short queries in dense subgraph.

First, all three THop approaches have shorter query time than FP and TCH. The THopBU is the fastest because it has the smallest label size. The THopAT is the second fastest due to the same reason. Second, the speed profile density has a higher impact on query time than the distance. As shown in Figs. 11c and 11d, it takes longer time to answer queries with similar distance in dense subgraph than in sparse one. Meanwhile, it takes longer time to run a 3km dense query than a 50km sparse query, as shown in (a) and (b). This is because this sparse graph is in the rural region. The longer queries are derived from the rural roads that are long and have sparser speed profile, while the shorter queries are derived from the urban roads which are short but have denser speed profile. Third, the query answering time increases a little bit as the distance increases, but on a much smaller scale than FP. Thus, even though the query answering time does not increase a lot, the speedup increases dramatically. In fact, it is also affected by the order to visit the vertices when we create the labels. Lastly, the distance between two vertices does not have a significant effect on TCH as expected. For some short queries, it is even slower than FP. As the distance grows, its speedup performance becomes better but still worse than THop. This is because it contains many shortcuts. Among them, some link to the vertices far away, which help reduce the searching space for long queries. However, for those short queries, we still have to visit those shortcuts, as long as they still have the possibility to contribute to the final result. Therefore, TCH might have to visit more vertices than FP when the query is short, which makes it slower. On the other hand, it could have speedup performance up to tens of times, as long as the query distance is long. Nevertheless, it is still slower than our approach.

7.4 Evaluation of FPP in Road Network
Apparently, our approach has a shorter query time than the online speedup approaches, and the approximate methods are even much faster. Like the evaluation on subgraph, the speed profile density, especially the starting subgraph's, plays an important role in searching time. For example, Fig. 12's query distance is smaller than (f), but it takes longer time to search. (c), (d) and (f) have the same distance, but (c) and (d) are slower because they are from denser subgraphs. The search time also increases as the distance increases, especially in dense subgraphs. The THop query time does not change too much as the distance increases. It is slower than the subgraph query because it involves concatenation of three result sets and the search space is much larger (|B1|×|B2|). The dense query is slower because their hop functions have more turning points. The running time of TCH and TSHARC does not change too much. Because they need to visit a large number of shortcuts for each vertex, no matter the path is short or long. For the short paths, they suffer from the wasteful computation; For the long paths, they benefit from it. The TSHARC is slightly faster than TCH, because it is essentially a pruning strategy of TCH that avoids some of the apparently useless shortcuts. In addition, the average error of the AT-Dijkstra is less than 5 percent of the exact result.

7.5 Evaluation of SSFP and ISFP
The experiment result is shown in Fig. 13. The early tests use 4 am and [4 am, 8 am] as departure time, while the late tests use 4 pm and [4 pm, 8 pm] as departure time. In general, the THop-3 and THop-2 are faster than THop-1. All of the three approaches are faster than the original THop. The speedup of the Intra-partition is much larger than the Inter-partition, because the Inter query computes the three label parts linearly against the original's parallel. Specifically, for the SSFP-Intra, the optimization can achieve up to 7 times faster than the original. In case of SSFP-Inter, the original THop is slower than running SSFP directly because SSFP is essentially a variant of the Dijkstra's, while our optimization approach can achieve 4 times faster than the SSFP. As for the ISFP-Intra, the optimization can speedup THop by 5 times, which is 10k times faster than FP. As for the ISFP-Inter, the optimization can speedup the FP query time from 200 times to 500 times. THop-2 performs better when the departure time is earlier.

SECTION 8Conclusion
In this paper, we extend the hop labeling approach to time-dependent environment and use it to answer the fastest path queries quickly. Unlike the case under static environment, where the shortest path indexes are well studied and widely used, little work has been done on the time-dependent environment. Even the state-of-art approaches fall into the easier and smaller but slower online search category, and only tested on the simple histogram-based speed profile rather than the common linear piecewise function. In this work, we first propose a time-dependent hop labeling approach to answer fastest path using the linear piecewise function that works on a partition-based road network. After that, we describe how to use the labels to answer FPP, SSFP, and ISFP queries. To further reduce the label size, construction time, and query time, we provide an online approximation searching strategy AT-Dijkstra and a post-construction compression method Bottom-up. Our extensive experiments show the query answering time is sped up to hundreds of times and also much faster than the online search approaches.