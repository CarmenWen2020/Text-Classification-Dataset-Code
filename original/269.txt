With the increasing use of the Internet of Things (IoT) in various fields and the need to process and store huge volumes of generated data, Fog computing was introduced to complement Cloud computing services. Fog computing offers basic services at the network for supporting IoT applications with low response time requirements. However, Fogs are distributed, heterogeneous, and their resources are limited, therefore efficient distribution of IoT applications tasks in Fog nodes, in order to meet quality of service (QoS) and quality of experience (QoE) constraints is challenging. In this survey, at first, we have an overview of basic concepts of Fog computing, and then review the application placement problem in Fog computing with focus on Artificial intelligence (AI) techniques. We target three main objectives with considering a characteristics of AI-based methods in Fog application placement problem: (i) categorizing evolutionary algorithms, (ii) categorizing machine learning algorithms, and (iii) categorizing combinatorial algorithms into subcategories includes a combination of machine learning and heuristic, a combination of evolutionary and heuristic, and a combinations of evolutionary and machine learning. Then the security considerations of application placement have been reviewed. Finally, we provide a number of open questions and issues as future works.

Previous
Next 
Keywords
Fog computing

Edge computing

Artificial intelligence

Application placement

Service placement

Task scheduling

Resource management

1. Introduction
The Internet of Things (IoT) becomes so popular in recent years and we expect with the help of Artificial Intelligence (AI), interaction of objects with each other becomes more and more intelligent (Yousefpour et al., 2019, Gazori et al., 2020). According to the estimation of Cisco by 2030, 500 billion devices are connected with each other and become a member of IoT big family (Yousefpour et al., 2019). Cloud computing is an efficient processing paradigm for storing and processing huge volumes of generated data. Despite the power of Cloud, there are a number of challenges to host IoT applications. Firstly, connected geo-distributed sensors and devices rapidly generate a huge amount of data. Secondly, responses to real-time latency of IoT applications’ interaction in centralized Cloud data centers is not feasible to handle. Fog computing extends the Cloud computing paradigm with the aim of making an efficient bridge from IoT to Cloud, support low latency and increase performance (Yousefpour et al., 2019).

Fog computing architecture consists of three layer as shown in Fig. 1. The terminal layer is the first and also the lowest layer in this hierarchical architecture. This layer consists of IoT devices that produce massive data and potentially are heterogeneous, geographically distributed and have mobility features. Fog nodes in terminal layer plays a role as a sensor or has a computational capability. The distance of smart devices and Cloud is not feasible, so applications run in the middle layer with the near distances from users which needs an acceptable response time (Hu et al., 2017).

The Fog layer is an intermediate layer that interacts with IoT devices and the Cloud layer. Fog layer extends closer to IoT devices in an efficient and timely manner. This layer consists of nodes (physical devices named Fog nodes) that are capable of supporting IoT devices, due to heterogeneity and decentralization as well as their mobility. In order to execute real time and latency-sensitive applications, this layer has a key role in the system (Hu et al., 2017).

It is worth mentioning although Edge computing provides Cloud computing services and increases the speed of responding to the requests of end-users, there are differences between Edge computing and Fog computing. Edge computing is located in end devices but Fog computing is located in near end devices such as network switches, routers and other equipment work in between to enable requests to travel from end devices, resources of Edge computing are more limited than Fog computing, computation and storage capabilities of Edge computing are more limited than Fog computing, unlike Fog computing, Edge computing cannot perform multiple IoT applications, last but not least, Edge computing focused on end devices level but Fog computing focused on the infrastructure level (Hu et al., 2017). The placement of applications on the Edge of the network has also attracted the attention of authors (Chen et al., 2018).

The Cloud layer is the most famous layer. It consists of data centers that have high processing and storage capability. This layer is centralized and is associated with the Fog layer, and if the request in the Fog layer is accepted, it means that the Fog layer has the ability to process and respond, otherwise it will be sent to the Cloud layer for more complex computing (Hu et al., 2017).

IoT applications comprise some common activities such as receiving data from IoT devices, preprocessing, and analysis of the received data, and handling events. Each application module performs some specific operations to generate corresponding output based on defined instructions. Then, based on data dependency, the output of one module is considered as the input of another module. Each module needs sufficient resources such as CPU, memory, bandwidth, and etc. to process the input in a reasonable amount of time.


Download : Download high-res image (405KB)
Download : Download full-size image
Fig. 1. An overview of the Fog computing structure.

Modern applications are not monolithic and include independent components that can be run near Fog devices. However, each Fog device has certain resources, and each application is composed of specific modules, application placement policies look for the best match between modules and resources in order to meet QoS and QoE constraints (Gazori et al., 2020, Mahmud et al., 2018).

The main objective of this paper is to review and analyze the efficient execution of applications with a distributed manner in a highly dynamic Fog environment by considering application module management policies based on existing proposed solutions with non-AI-based and AI-based perspectives to address latency-related issues, resource utilization-related issues, energy consumption-related issues, and cost-related issues.

Based on our literature review, we concluded that the Fog Application Placement (FAP) consists of six categories with two perspectives. Non-AI perspective include quantum computing-based, blockchain-based, mathematical-based, Fuzzy-based, and basic algorithms. AI-perspective include Evolutionary Algorithms, Machine Learning Algorithms and Combinatorial Algorithms.

Due to the widespread adoption of artificial intelligence, we focused on the AI-based perspective in the Fog application placement problem. To achieve this aim, we target three main objectives with considering a characteristics of AI-based methods in FAP: (1) categorizing evolutionary algorithms based on common intrinsic features of algorithms into subcategories includes swarm intelligence, genome mimetic, and search-based algorithms. (2) categorizing machine learning algorithms into subcategories includes classic machine learning algorithms and deep learning algorithms; and (3) categorizing combinatorial algorithms into subcategories includes combination of machine learning and heuristic, combination of evolutionary and heuristic, combinations of evolutionary and machine learning.

To achieve the mentioned objectives, we formulated the following research questions:

RQ 1: Which performance metrics were optimized in the FAP problem? Answering RQ1 helps researchers to identify performance metrics, as well as the main purpose of each performance metric that is targeted for optimization based on the FAP problem. (Section 2)

RQ 2: How the FAP problem can be categorized in general? Answering RQ2 helps researchers to identify various algorithms, methods, and strategies relevant to the FAP problem in a classified structure with two perspectives: Non-AI Techniques for Application Placement in Fog Computing and AI Techniques. (Section 3)

RQ 3: What is the main classification of AI-based techniques for the application placement problem in Fog computing? Answering RQ3 helps researchers to understand the overall classification of AI-Techniques. FAP with an AI approach is divided into three general categories. (i) evolutionary algorithms, (ii) machine learning algorithms, and (iii) combinatorial algorithms. The first category emphasizes the resource management and service placement aspects by focusing on evolutionary optimization approaches that divided into three subcategories includes swarm intelligence-based, genome mimetic, and search-based. The machine learning category is divided into subcategories includes classic machine learning algorithms and deep learning algorithms. The last category is divided into three subcategories involves the combination of the first category and the heuristics, the combination of the second category and heuristics, and the combination of the first category and the second category. (Section 3)

RQ 4: What are the main advantages and disadvantages of AI-based algorithms relevant to the FAP problem? Answering RQ4 could help researchers to identify, compare, and choose algorithms to optimize performance metrics, according to their proposed methods. (Section 4)

1.1. Motivation
Fog computing is a distributed computing paradigm that extends the Cloud at the edge of the network with resource limitations constraints. Although Fog can improve application placement time and resist network congestion, efficient distribution of IoT application tasks in Fog nodes is still challenging.

Several reviews have been conducted that cover various types of application placement challenges in Fog computing.

Mahmud et al. (2020) reviewed, classified and characterized a number of approaches for application management and discussed their associated research gaps in Fog computing from the perspectives of application architecture, placement and maintenance. Their proposed taxonomy of application placement was divided into eight subcategories includes placement strategy, resource type, placement metric, mapping technique, resource estimation, offloading approach, resource orientation, and placement controller.

Salaht et al. (2020) proposed a classification of the service placement problem according to identified scenarios, provided a taxonomy and optimization strategies. Their devised service placement taxonomy includes four categories: control plan design (centralized vs. distributed), placement characteristic (online vs. offline), system dynamicity (static vs. dynamic), and mobility support (no mobility support vs. support mobility).

Brogi et al. (2020) proposed a classification of the application placement problem in Fog computing with two perspectives, an algorithmic perspective, and a modeling perspective. Algorithmic perspective reviews contributions based on the methodologies along with a study on the available prototypes and experiments. Modeling perspective analyses constraints and optimization metrics to determine the best candidate application placements.

To the best of our knowledge, there is no work that has focused on providing a comprehensive classification of artificial intelligence techniques in the Fog application placement problem.

Moreover, none of the researchers has focused thoroughly on comparing and analyzing artificial intelligence algorithms in the Fog application placement problem based on the advantages and disadvantages of AI-based techniques.

Consequently, a comprehensive taxonomy is required to provide an in-depth understanding of the Fog application placement challenges and opportunities based on the AI perspective that can be useful for future researchers.

1.2. Research methodology
It is important to note that this paper extensively reviews the FAP problem based on AI techniques. We have followed a systematic literature review methodology to select most suitable papers in this area of research. First of all, we devised a search query based on the formulated research questions (see Fig. 2). :

[ ( application placement) OR ( service placement) OR ( task scheduling) OR ( resource management) AND ( ( ( artificial intelligence) AND ( evolutionary) AND ( machine learning) ) AND ( challenges) OR ( metrics) OR ( aspects) AND ( approaches) OR ( algorithms) OR ( methods) ) ) AND ( ( Fog computing) OR ( Edge computing) ].

In total, we collected about 300 potential papers published in journals and conferences. Next, we manually removed the duplicates by checking the title of the collected papers. After that, we selected and refined the potential papers which focus on the objectives of this literature review. Finally, we selected and used 109 most relevant papers for this literature review.

According to our literature review, most of the evolutionary algorithms such as ant colony optimization in Hussein and Mousa, 2020, Zahoor et al., 2018, artificial bee colony in Ismail et al. (2018), cuckoo optimization algorithm in Javaid et al. (2019), firefly algorithm in Hassan et al. (2018), particle swarm optimization in Wan et al. (2018), and genetic algorithm in Zubair et al. (2018), applied to solve the FAP problem focused on providing efficient load balancing methods. The main aim of load balancing is to transfer load explicitly from overloaded and some are under load (Zubair et al., 2018). In the result of a literature review related to evolutionary algorithms to solve the problem on hand, we classify evolutionary algorithms into two categories: hybrid meta-heuristic approach and further meta-heuristic approach categorized in Table 4 that try to minimize or maximize one or more performance metrics as the objective function(s) with considering problem constraints. Most of the authors along with evolutionary algorithms used traditional algorithms to compare their methods, which include: Round robin Hussein and Mousa, 2020, Yasmeen et al., 2018, Throttled (Zubair et al., 2018, Nazir et al., 2018), First Fit (Wu et al., 2012), Random search, and local search (Nardelli et al., 2019). Also, most of the evolutionary algorithms papers applied service broker policy (Yasmeen et al., 2018) in their methods.

Based on the studies conducted in the machine learning algorithms section, we concluded that most machine learning algorithms focused on the reinforcing learning category and used deep learning models in their own heuristics that collected in Table 8 with the aim of optimizing the performance metrics in Table 1. Some authors combined machine learning algorithms with evolutionary algorithms to solve the FAP problem (Talaat et al., 2020, Li et al., 2019b), some authors add new parameters to get better solutions and some authors proposed policies to improve the base methods.

Due to the fact that each of the proposed algorithms have advantages and disadvantages, in review articles, one algorithm has been used to cover the weaknesses of the other algorithm (Yasmeen et al., 2018, Li et al., 2019b, Mai et al., 2018). For example, to solve the problem of getting stuck in the local optimum (Zahoor et al., 2018, Rafique et al., 2019). Also, for search speed along with accuracy (Wang and Li, 2019, Ren et al., 2021) or to calculate the time complexity of algorithms (Boveiri et al., 2019, Yadav et al., 2019, Tang et al., 2019) and the convergence improvement process (Butt et al., 2019, Farhat et al., 2020), various methods have been proposed.

Although our focus is on solving the application placement problem in the Fog computing environment (Shooshtarian et al., 2019), due to the relevance of the problem on hand with service placement (Tang et al., 2019, Fröhlich and Gelenbe, 2020), task scheduling and load balancing (Sharma and Saini, 2019b), resource allocation (Mseddi et al., 2019) and resource management (He et al., 2017, Manukumar and Muthuswamy, 2020), these problems have also been examined in literatures review of this survey that summarized in Table 3, Table 8.

This survey is organized as follows: in Section 2 the problem for Fog application placement is formulated. Also, the key performance metrics in literature reviews considered. Section 3 explains literature reviews and important features with two perspectives. Non-AI perspective and AI-perspective. Section 4 compares the advantages and disadvantages of AI-based methods in FAP. Section 5 provides security considerations for Fog application placement. Section 6 includes open challenges and future works. Finally we conclude the paper in Section 7.

2. Background
In this section, background and performance metrics related to application placement in Fog computing are presented.

2.1. Problem formulation for fog application placement
In this section, we formulate the task scheduling of Fog-based IoT applications. The task scheduling problem determine when to execute tasks and where to place the tasks on the Fog nodes.

•
Definition 1: It is assumed that we have a number of (n) applications and each application contains a number of (t) tasks. These applications are represented by the following application set (1): (1)
 

We define a task as a service request established by a Fog user. These tasks are represented by the following task set (2): (2)
 

Fog nodes are represented by the following Fog set (3): (3)
 

Each task (j) among (t) tasks which runs on application (i) among (n) applications can be partitioned into a set of (p) tasks. Each task (k) among (p) tasks is disseminated to one Fog node (f) among (m) Fog nodes in order to be executed, such as (4): (4)

Therefore, each Fog node (f) can execute a set of disjoint subset of the decomposed tasks set. For its assigned tasks, 
 ensures the execution of its tasks as follows (5): (5)

Another mode is task distribution among the Fog nodes virtual machines (VMs) as the abstraction of task scheduling defined above. A set of Fog nodes 
 and each Fog contains a set of VMs 
 where 
 It was assumed. It is worth mentioning that virtualization technology uses Virtual Machine Migration (VMM) technology to improve Fog performance and optimize energy efficiency (Sharma and Saini, 2019a). The VMM has complete information about active VMs, the task queue length of the hosts, and the availability of resources in different hosts.

•
Definition 2: Further definition is VMs placement/migration among physical machines (PMs) or placing containers in PMs. Based on our literature review the main objective of VM or container placement was selecting policies to reduce the number of the PMs used for VM placement, therefore, the power consumption of servers can be minimize (Akintoye and Bagula, 2019).

As illustrated in Fig. 3, the FAP problem, in general, is placing application modules on distributed Fog nodes that guarantee the deadline of service delivery for different types of applications. Each application is composed of several modules or microservices, indicated by circles. The arrows between the modules show that they exchange data with each other in Directed Acyclic Graph (DAG) model. The output from one module is sent to another module as input. As each module requires a certain amount of resources to process the input at a reasonable time, the modules are located near data sources and run at the Fog layer. Properly assigning modules to the limited Fog resources is a challenge. Various suitable management policies for application placement to ensure the quality of service and resource optimization proposed that in this paper reviewed and categorized.

2.2. Review of performance metrics
According to the reviewed articles, the important performance parameters that the authors seek to optimize them are listed below in Table 1 along with the definition of each of the parameters and the purpose of their application. Investigated performance metrics classification considered as follows. Based on our literature review, response time, resource utilization cost and energy consumption were the most used metrics in the articles.

The performance metrics include five general categories: time, cost, network, energy, and resource. Each metric contains subsets of that parameter as shown in Table 1. Time metrics include response time, scheduling time, service time, latency, computation time, task execution time, round trip time, waiting time, propagation time, deadline hit/miss, application placement time, average turnaround time, deployment time. In all the evaluated articles, the response time was the dominant factor (Gazori et al., 2020, Mahmud et al., 2018, Sharma and Saini, 2019b, Canali and Lancellotti, 2019, Lera et al., 2019, Tran et al., 2019, Bittencourt et al., 2017, Mahmud et al., 2019, Xia et al., 2018, Tang et al., 2019, Skarlat et al., 2017, Zhang et al., 2017, Selimi et al., 2019, Hassan et al., 2018, Rahbari and Nickray, 2020, Moallemi et al., 2019, Ghobaei-Arani et al., 2020, Hussein and Mousa, 2020, Bashir et al., 2019, Zafar et al., 2018, Lin et al., 2018). Network metrics include network load balancing/load scheduling, bandwidth, and service delay/network delay. based on our literature review, load balancing was the dominant factor (Mahmud et al., 2018, Akintoye and Bagula, 2019, Hassan et al., 2018, Hussein and Mousa, 2020, Zafar et al., 2018, Bhatia et al., 2019, Naranjo et al., 2019, Zhu et al., 2018, Bitam et al., 2018, Nazir et al., 2018, Talaat et al., 2019, Li et al., 2019b, Yin et al., 2018). The network is a platform for Fog nodes such as routers and switches with processing capabilities that exchange data between the end users layer, the Fog layer and the Cloud layer. For these reasons, in the literature, the optimization of network parameters was strongly focused. Cost metrics with the aim of cost reduction include resource usage cost (CPU usage cost, bandwidth usage cost, memory usage cost), migration cost and execution cost. According to our literature review, execution cost was the dominant factor (Akintoye and Bagula, 2019, Hassan et al., 2018, Li et al., 2020b, Nguyen et al., 2019b). Energy metric includes energy consumption (Akintoye and Bagula, 2019, Sharma and Saini, 2019b, Tran et al., 2019, Tang et al., 2019, Rahbari and Nickray, 2020, Zafar et al., 2018, Lin et al., 2018, Bhatia et al., 2019, Naranjo et al., 2019, Bitam et al., 2018, Nazir et al., 2018, Goudarzi et al., 2021, Shuja et al., 2018, La et al., 2019, Mehran et al., 2019, Al-Moalmi et al., 2019, Yadav et al.). Energy depends on the processing time of requests, the volume of requests, and the load volume of the network in the energy consumed. Due to the limited resources in the application placement problem in the Fog environment, minimizing resource utilization is also important as mentioned in the papers (Mahmud et al., 2018, Lera et al., 2019, Mahmud et al., 2019, Skarlat et al., 2017, Lin et al., 2018, Zhu et al., 2018, Li et al., 2020b, Guerrero et al., 2019). Allocating resources to user requests to run applications in the shortest possible time is the main goal. All mentioned scheduling algorithms and computational parameters were evaluated for the purpose of running applications in the Fog.


Table 1. List of investigated performance metrics.

Metrics type	Performance metrics	Abbreviation	Parameters definition	Main aim
Time	Response Time	RT	Time elapsed from user request to request result Waiting Time + service time	Minimize user response time that depends on network bandwidth, number and type of user request.
Scheduling Time	ScT	The length of time a task starts to run until it is completed in the simulator	Proper use of resources, which depends on memory, CPU, execution time and cost.
Service Time	ST	Time required to service customer request	Reduce communication delay
Computation Time	CT	The time required to perform the computational process based on the type of customer or user request	Optimal use of computational resources due to limited processing capacity.
Task Execution Time	TET	Time required to execute the request using processor resources	Efficient utilization of resources
Round Trip Time	RTT	Latency + processing time	Measuring network latency
Waiting Time	WT	The time it takes for the scheduler to select the tasks that are queued for execution	The lower average waiting time, the better the scheduling algorithm
Propagation Time	PT	The Time required to propagate data	Reduce the delay of the propagation time
Deadline Hit/Miss	DH/M	Tasks are executed before the deadline	Response time is optimized
Propagation Time	PT	The Time required to propagate data	Reduce the delay of the propagation time
Deployment Time	DT	Data placement time	Increase the QoS and QoE
Completion Time	CPT	Total time required to complete the task	Measure the performance of processor, memory and network communication
Turn Around Time	TAT	Turnaround time is the amount of time elapsed from the time of submission to the time of completion	Minimize Average Turnaround Time
Latency	LT	Latency is the time it takes for a request/response to be transmitted to/from the processing component	Increase the QoS and QoE
Application Placement Time	APT	The time required to place applications	Reduces application placement time
Processing Time	PcT	Processing time is the time to process a request and provide user with the required results	Minimizing the time taken by Fog to process a generated request by the user
Service Delay	DL	Time elapsed to assign all tasks to Fog nodes	Use policies to minimize delays to maximize user satisfaction
Scheduling Length	SL	The total finish time	Measure the performance of processor, memory and network communication
Cost	Resource Usage Cost	RUC	Minimize the use of necessary Fog entities	Minimize total cost optimally. Costs may include communication costs, optimization costs, resource management costs, service placement cost or virtual machine deployment costs
Deployment Cost	DC	The bill that the service provider needs to pay for the running instances provided by the Cloud/Fog computing platform	Minimizing deployment operational costs at runtime
Execution Cost	EXC	Computational Fog resources while running the applications	Minimize the computational Fog resources while running the applications
Migration Cost	MC	The cost of virtual machines migration or container migration in terms of money and time	Increase the QoS and QoE
VM Cost	VC	The cost of allocating virtual machine	Minimizing VM migration cost
Data Transfer Cost	DTC	The cost of transferring data	Minimizing data transfer cost
Network	Bandwidth	BW	Capacity data transfer rate of communications links	Depending on how much bandwidth each application requires, the symmetrical or asymmetrical download and upload capacity are determined
Reliability	RA	The success rate of the task execution under the constraints	Determining the validity of task execution
Failure Ratio	FR	The ratio of the number of tasks not completed within the deadline to the total number of scheduled tasks	Determining the number of tasks that fail to schedule
Load Scheduling	LS	Balance in users requests with scheduling algorithms according to resources	Proper use of resources according to the algorithm policy is considered
Resource	Resource Utilization	RU	Calculate resources consumed	Reduce resource consumption
Energy	Energy Consumption	EC	All energy consumed all entities in the system	Energy consumption is either static or dynamic. It is important to facilitate the use of computing resources and network devices
3. Literature reviews
The reviewed articles addressed the application placement problem in Fog computing, with various algorithms, methods, and strategies to improve the speed of data transmission, processing, storage, and network load.

According to the review articles, as illustrated in Fig. 4, FAP-based algorithms include AI-based algorithms, Blockchain-based algorithms (Zhu et al., 2018, Qiu et al., 2019, Nguyen et al., 2019a), mathematical model-based (Dai et al., 2018), Fuzzy-based (Reddy and Krishna, 2020), Quantum-based (Bhatia et al., 2019), Basic algorithms such as First Come First Served (FCFS) (Bittencourt et al., 2017), greedy algorithm (Yang et al., 2016), and graph coloring (Zhang et al., 2018), and graph partitioning (Lera et al., 2019).


Download : Download high-res image (269KB)
Download : Download full-size image
Fig. 4. Classification of Fog application placement.

Since artificial intelligence techniques are more efficient than other techniques, we reviewed the literature with two perspectives: Non-AI Techniques for Application Placement in Fog Computing and AI Techniques.

3.1. Non-AI techniques for application placement in fog computing
3.1.1. Quantum-based techniques
Quantum computing is the combination of classical information theory, computer science, and quantum physics (Steane, 1998). Bhatia et al. (2019) introduced the Quantum Computing inspired (QCi) approach for load scheduling in industrial IoT applications. Since Fog servers are composed of heterogeneous computing units, the node availability index integrates with the computing power of the Fog nodes so that resource allocation is done efficiently. Using a neural network model with a QCi approach (QCi-NN) can optimize Fog selection. They implemented QCi-Optimization (QCiO) algorithm based on average task completion time and average energy consumption. They compared proposed algorithm with the Min–Max algorithm, the Minimum Completion time algorithm, and the Round Robin algorithm. The proposed strategy generally consists of three main modules: Quantum mapping module, Quantum computing inspired optimization and Quantum computing inspired neural network. In the first module, different load scheduling features and characteristics of Fog nodes are considered as a quantum representation, and each Fog node is distinguished by node availability index parameter value. In the second module, the QCiO algorithm was represented with the aim of optimal allocation. In the third module, the QCi-NN strategy based on the execution index for predicting optimal Fog node was proposed.

3.1.2. Blockchain-based techniques
Zhu et al. (2018) are applied stochastic programming to introduce a cost model for pricing Edge hosts, latency and service chaining. Then, according to the cost model and blockchain technology a heuristic mobile Edge computing (MEC) placement algorithm is suggested. In this paper two points were determined: first, all users’ information and their communications are stored in the Blockchain. Global resource availability, allocation, and consumption information has an important role in order to make optimized decisions. Second, Placement decisions must be neutral so decentralized public ledge was used. Based on the available information on the blockchain, the EdgeChain framework offered to run the algorithm.

3.1.3. Mathematical model-based techniques
Lera et al. (2019) proposed an algorithm for service placement in Fog devices with the graph partitioning algorithm. Their policy involves two-phases for supporting service availability which includes mapping applications to device communities and mapping services of an application to those communities. In the first-phase for generating device communities, the Girvan–Newman algorithm is run. In the second-phase, inside of each community, the service allocation process is determined. The authors considered each Fog device has a fitness that measured with node execution time and the network latency. So the device with the highest fitness obtained and application services placed efficiently. They compare their algorithm with the integer linear programming (ILP) and the results show higher QoS and service availability but mobility did not determine.

Mahmud et al. (2018) assumed that identical Fog nodes confirm in clusters and communicate with each other. To ensure the quality of service, a module placement algorithm is presented that supports the network delay. The presented algorithm is applicable to scenarios where nodes are inactive. Two approaches were evaluated for optimal placement of modules in Fog nodes. The first approach was linear programming. This approach was not appropriate because of the slowness in the decision-making process. For this purpose, a heuristic approach, module forwarding algorithm was proposed for resource optimization within clusters. Module forwarding algorithm prune constraints and transported inactive modules to idle modules.

Liu et al. (2018) studied the problem of energy consumption, delay performance, and payment cost in a mobile Fog computing system. To minimize energy consumption, delay performance, and cost, the offloading probability was optimized. Then three different models based on queueing theory for mobile devices, the Fog node, and the central Cloud and wireless channel proposed.

Zhang et al. (2017) proposed a framework that was based on data service operators (DSOs), data service subscribers (DSSs) and Fog Nodes (FNs). In this paper, four problems are considered to be solved includes 1) resource purchasing problem for DSSs. 2) pricing problem for DSOs. 3) DSO-FN pairing problem and 4) FN-DSS pairing problem. First, DSOs set the price for the computing resources, then DSSs determine the amount of resources needed. The pricing problem for DSOs and the resource allocation problem for DSSs were modeled as a Stackelberg game. Given that each FN sells computing resources to DSOs, a many-to-many matching game between FNs and DSOs proposed. After DSO-FN determined, FNs try to compete with each other to allocate their computing resources to the DSSs of the DSOs. So a many-to-many matching game between FNs and DSSs determined. The results showed that both DSSs and DSOs achieved optimal performance.

Chiti et al. (2018) proposed a new framework to modeled a many-to-one distributed matching game to solved task offloading problem in the Fog environment. Also, based on the deferred acceptance algorithm, a new strategy to achieve efficient allocation and minimize the worst total task completion time by considering that all tasks had the same priority were suggested.

Shah-Mansouri and Wong (2018) applied a process sharing method to allocate computing resources then a computation offloading game is used to model the competition between end devices and presented an efficient Fog nodes allocation computation capabilities. The proposed approach maximized the QoE.

3.1.4. Fuzzy-based techniques
The Fuzzy inference system is carried out in the sequential steps: fuzzification of inputs, applying the fuzzy rules, and defuzzification. Fuzzification is transforming crisp values into grades of membership of the considered Fuzzy set via an input membership function. In applying the fuzzy rules describe the relationship between defined input variables and outputs based on suitable linguistic variables. Defuzzification is the process of converting a fuzzified values into a single crisp value (Das et al., 2013).

Mahmud et al. (2019) consider the QoE along with the QoS in the application placement problem. The authors assume that the Fog layer consists of Fog computational nodes and Fog gateway nodes. Fog computational nodes are responsible for assigning the application to suitable micro computing instances in order to execute, however, capacity score unit is proposed to consider remaining resources which save in data container. Fog gateway nodes are responsible for receiving requests from the terminal layer, extracting user expectations, prioritized based on user expectation metric, so expectation rating unit and application placement unit are proposed to accomplish these duties. The authors suggested firstly, each application placement request is prioritized based on the user expectation metric. Secondly, two separate fuzzy logic models are applied to the Fog computing instances based on their status performance metrics such as the application’s rating of expectations and the capacity class score of the instances. Finally, prioritized application placement requests are a map to the computational instances.

Talaat et al. (2019) proposed Effective Load Balancing Strategy (ELBS) for real-time Fog Environment based on Fuzzy and Probabilistic Neural Networks. Proposed ELBS is suitable for healthcare applications that guarantee efficient interconnection between Fog, Cloud, and edge layers. Quickly prioritization was the main reason for using Fuzzy in the proposed strategy. Three parameters including predefined priority, deadline time, and task size are the crisp inputs of the Fuzzy System and new priority is the crisp output of the Fuzzy system. Probabilistic neural networks generate valid predicted targets and is much faster than multilayer perceptron neural networks, hence it is used in ELBS strategy. ELBS managed the unexpected high load real-time task failure with rescheduling the critical task to a new server and migrate the task to find the suitable host for that task.

3.1.5. Basic algorithms
Basic Algorithms refers to algorithms that do not belong to any of the other categories. Basic algorithms such as First Come First Served (FCFS) (Bittencourt et al., 2017), greedy algorithm (Faticanti et al., 2019), Hungarian method and graph coloring (Zhang et al., 2018), graph partitioning (Chen et al., 2018), and branch and bound (B&B) (Lawler and Wood, 1966).

Bittencourt et al. (2017) proposed new Fog computing model that used Cloud, Cloudlet and Edge devices for supporting IoT applications. With the help of EEG tractor beam game (EEGTBG) and video surveillance/object tracking (VSOT) scenarios, applications were modeled in two classes including near-real-time and delay-tolerant. According to application characteristics, the applications assign to one of these classes. Three cloudlets were considered. Each cloudlet is assumed to run a specific application. Two cloudlets run the EEGTBG and one cloudlet run VSOT, but when users move from one region to another, the cloudlet in that region must present the solutions to satisfying application delay for all new module placement requests. Under these conditions, three different scheduling policies for application scheduling includes Concurrent strategy, First Come-First Served (FCFS) strategy and Delay-priority. Three strategies had three different outcomes with increasing number of application modules. It should be noted that users of the EEGTBG were moving. When users moved in, there was a situation that two different applications had to run, in one cloudlet. Concurrent strategy keep both applications in a cloudlet, so the delay was increased. FCFS strategy keeps VSOT modules in the own cloudlet and sent EEGTBG modules to the Cloud after the second player arrived. Delay-priority strategy sent VSOT modules to the Cloud after the second EEGTBG player arrived in cloudlet. When the last EEGTBG player arrived according to CPU limitation in the cloudlet, EEGTBG modules sent to Cloud and VSOT modules brought back to the cloudlet. Based on these analyzed, the concurrent strategy had the least network usage than the other two strategies.

Faticanti (Faticanti et al., 2019) proposed an optimization framework for microservice scheduling in Fog computing. A greedy algorithm namely FAP with a gradient approach proposed. FAP selects a set of tagged applications that related to a specific region and deployed applications in Fog nodes iteratively, and the optimal deployment achieved.

Zhang et al. (2018) proposed a distributed joint computation offloading and resource allocation optimization in heterogeneous networks with mobile Edge computing. The offloading strategy with the distributed potential game algorithm modeled and analyzed. Then for the offloading mobile terminals, a Cloud and wireless resource allocation algorithm proposed. Also, hungarian method and graph coloring for allocation among mobile terminals applied.

Chen et al. (2018) proposed a delay-aware task graph partition algorithm and the optimal virtual machine selection method to minimize the IoT device’s Edge resource occupancy. Based on the structure of the task graph, and node ordering by topological sorting the delay-aware task graph partition problem by the principle of backward induction investigated.

B&B method is a pattern design algorithm for optimization problems. This method explores the possible solutions to the problem in the search space. A set of possible solutions is considered as a tree that the root corresponds to all the solutions and its branches are subsets of possible solutions. The lower bound and upper bound of solutions are generally checked and if the sub-branch is not able to generate a more optimal solution to the problem, the entire sub-branch will be excluded (Lawler and Wood, 1966). One of the advantages of the branch and bound is no repetition in this algorithm due to finding the minimum path instead of finding the minimum substitute. Therefore, the time complexity of this algorithm is less than other algorithms. Disadvantages of this algorithm: load balancing aspects require parallelization, which creates difficulties. This algorithm is not usually used in large scale solution space problems. Vu et al. applied the B&B algorithm to find the optimal solution to achieve optimal task offloading and resource allocation for Fog computing (Vu et al., 2019).

Naranjo et al. (2019) proposed a Fog Computing Architecture Network (FOCAN) that is a multi-tiered framework involved Internet of Everything (IoE) tier and Fog Node (FN) tier. In IoE layer client devices are clustered according to their locations. IoE layer categorized in three tiers includes inter-primary, primary and secondary that has a relation with the FN layer to arrange traffic and manage tasks whenever thing to thing connections in the IoE layer cannot satisfy for running the IoE applications so the thing to FN connections determined. FN to FN connections also recognizes in device mobility conditions or more computational resources needed. The FN layer classified as primary communication/inter-primary communications and secondary communications. Inter-primary communications is supported by near local connections but secondary communications had inverse rules. Average power consumption minimization is the result of a scalable routing algorithm in the FOCAN framework. The results show that FOCAN supported effective management and scalable energy-aware applications.

Tran et al. (2019) presents a three-tier architecture with an intelligent approach. The first layer consists of devices. The second layer is the regional layer and the third layer is the global layer. This architecture does not involve computational details. Instead, it knows what kind of providers should respond to the customers. They considered two default modes: firstly, all the applications and their modules are pre-defined by service providers in the Cloud and Fog. Second, the code for the IoT applications is already loaded to the corresponding devices. The general procedure of the proposed method is that the user first sends the request to the service providers through Service Fog Endpoints (SFEs) and Service Cloud Endpoints (SCEs). Then SFEs or SCEs can determine which task is relevant to which application and which providers can perform that task in terms of two default modes. At the end, after executing tasks, results send back to (SFEs or SCEs) to integrate the results and present them to the user. They apply real-world applications to test their proposed framework.

Mobile Edge Cloud (MEC) is the complementary of Cloud computing at the Edge of the network to provide low-latency mobile services. Wang et al. (2017) utilized tree topology to solve application placement problem in MECs. Depending on the model, each application in MEC has a hierarchical structure to run. Due to this structure, the authors used optimization algorithms for application placement. The user requests are considered as application graph, whereas resource requirements to run each application component are created as a physical graph. Then, the best map of the application graph on a physical graph is found by on-line non-linear objective function that minimizes the maximum resource utilization and load balancing. In this paper, firstly, the placement of a linear application graph is examined, and then the algorithm for finding an optimal solution is proposed.

Xia et al. (2018) reduced the average response time of users requesting that have a demand to run an application. Due to the intensity of user requests two algorithms for deploying applications were presented in the Fog. Exhaustive search and Naïve search were introduced, however, the Backtrack search algorithm is applied to find the initial placement. Exhaustive search did not support large-scale spaces. Naïve search is terminated as soon as finding the first solution and was low quality. Two suggested heuristic algorithms namely Anchor-based Fog nodes ordering (AFNO) and dynamic components ordering (DCO) were used to improve weighted average latency by naïve search. Unlike Naïve search that sort components in random order, anchor-based Fog nodes order sorted components in an ascending order. When components are not located in the right resources, dynamic components ordering accelerated the placement process, without using the Backtrack search algorithm. Then they proved a combination of heuristic algorithms, AFNO-DCO, speeds up the decision-making.

Brogi et al., 2020, Brogi et al., 2017 proposed a general model based on only latency and bandwidth as QoS metrics to solve multi-components application placement problem that follows two steps: at the first stage, according to predefinition of an application, a Fog infrastructure, a deployment policy, and a things binding are used for preprocessing to bound search space. After that, a backtracking algorithm was applied to achieve eligible deployment. Their model was implemented in the FogTorch simulator (Brogi et al., 2017) which includes three main sections: at design time, it performs capacity planning of Fog devices. In the deployment time, application components automatically are deployed based on QoS limitations. In the runtime, it monitors the deployed application and applied reconfiguration if required. With determining suitable average latency and bandwidth of communication links, QoS is realized.

3.2. AI-based techniques for application placement in fog computing
Due to the widespread adoption of artificial intelligence, we decided to examine AI section in more detail. It should be noted that the classification in this section is based on the placement of applications or services in Fog, task scheduling, task offloading and resource allocation. Therefore, the algorithms mentioned in each category were the most favored by the authors and refrained from bringing other algorithms into this category. The related works to each of the mentioned algorithms are also referenced in Table 3, Table 4, Table 8. As illustrated in Fig. 5, FAP with an AI approach is divided into three general categories: Evolutionary algorithms (EV) (Zedadra et al., 2018), Machine Learning algorithms (ML) (Praveen Kumar et al., 2019), and combinatorial algorithms (Talaat et al., 2020).

3.2.1. Evolutionary Algorithms in FAP
Evolutionary algorithms (EAs) mimic the behaviors of natural evolution. An important number of studies have addressed resource management and service placement problems with evolutionary algorithms (Hussein and Mousa, 2020, Ismail et al., 2018, Bitam et al., 2018, Djemai et al., 2019, Zafar et al., 2018, Ghobaei-Arani et al., 2020, Nazir et al., 2018, Hassan et al., 2018, Skarlat et al., 2017, Goudarzi et al., 2021, Manasrah et al., 2019, Mouradian et al., 2019, Karamoozian et al., 2019, Rezazadeh et al., 2018). According to Table 2, load balancing evolutionary algorithms divided into three subcategories includes swarm intelligence-based, genome mimetic, and search-based. According to service placement and resource placement evolutionary algorithms, the authors try to minimize or maximize one or more performance metrics gathered in Table 1.

Based on Eq. (6) for example makespan time or energy consumption as an single objective function minimized with one or more constraint(s). (6) 
In multi-objective placement problems with one or more constraint(s), as illustrated in Eq. (7), multi performance metrics can be determined. For example both makespan time and energy consumption can be minimized. (7)
 Where  is the decision space and  is a decision vector.  consists of  objective functions 
 where 
 is the objective space. Examples of evolutionary algorithms in Fog computing for FAP are illustrated in Table 3, Table 4.


Table 2. Review of evolutionary algorithms.

Evolutionary algorithms
Category	Algorithms	Related papers
Swarm intelligence	Ant Colony Optimization	Hussein and Mousa, 2020, Xu et al., 2019a, Wang and Li, 2019, Pham and Le, 2017
Artificial Bee Colony	Rastkhadiv and Zamanifar, 2016, Nguyen et al., 2019b
Bee Life Algorithm	Bitam et al. (2018)
Bat Algorithm	(Zafar et al., 2018, Mishra et al., 2018)
Cuckoo Optimization Algorithm	(Nazir et al., 2018, Abbasi and Mohri, 2016)
Firefly Algorithm	Hassan et al., 2018, Saleh et al., 2019
Particle Swarm Optimization	Bitam et al., 2018, Hussein and Mousa, 2020, Nguyen et al., 2019b, Yadav et al., 2019, Gill et al., 2019
Moth–Flame Optimization	Ghobaei-Arani et al. (2020)
Genome mimetic	Genetic Algorithm	Guerrero et al., 2019, Canali and Lancellotti, 2019, Skarlat et al., 2017, Bitam et al., 2018, Yang et al., 2016, Nguyen et al., 2019b, Martin et al., 2020, Xu et al., 2019b
Memetic Algorithm	Goudarzi et al., 2021, Chen et al., 2011
Differential Evolution	Manasrah et al. (2019)
Search-based	Tabu Search, Simulated Annealing, Gravitational
Search Algorithm	Mouradian et al., 2019, Wu et al., 2012, Karamoozian et al., 2019
Swarm intelligence.
The swarm intelligence-based includes Ant Colony Optimization (ACO), Artificial Bee Colony (ABC), Bee Life Algorithm (BLA),Bat Algorithm (BA), Moth–Flame Optimization (MFO), Cuckoo Optimization Algorithm (COA), Firefly Algorithm (FA), Particle Swarm Optimization (PSO). A brief description of algorithms in the placement problem is reviewed in the following.

•
ACO is one of the meta-heuristic methods that is inspired by the ant behavior to find food sources. The idea behind ACO is to find the shortest path between colony and food that can be detected by pheromones of other ants. This algorithm consists of three main steps. The first step: construct ant solutions, the second step: apply local search (optional), the third step: update pheromones (Dorigo et al., 2006). The advantages of ACO: positive feedback accounts for rapid discovery of good solutions, effective in dealing with distributed problems, It is easy to combine with other algorithms, can be used in dynamic applications. Disadvantages of ACO: Although convergence is guaranteed in this algorithm, the convergence time is not known, the probability distribution changes by iteration, it is easy fall into local optimum, it is not suitable for large-scale issues because it takes a lot of time to search. Hussein et al. proposed ACO algorithm and PSO for scheduling IoT tasks based on formal model that considered network latency and service rate on the Fog. The proposed algorithms are compared with the round robin scheduler. ACO task offloading algorithm provides a significant improvement in IoT applications average response time and effectively balances the tasks of Fog nodes (Hussein and Mousa, 2020).

•
ABC is an optimization strategy that mimics the behavior of a bee colony to solve multi-dimensional and multi-modal optimization problems. The food source illustrates all possible solutions to the problem ahead. The quality of the solutions is determined by the amount of nectar in the food source. Each of the bees tries to find best quality food sources according to the tasks they have in the colony, so the algorithm reaches the optimal solutions (Bitam et al., 2010). The advantages of ABC: finding the global optimal solution, strong robustness and high flexibility, using very few control parameters. Disadvantages of this algorithm include its accuracy and slow convergence speed. Bitam et al. proposed BLA with the aim of solving job scheduling problem in Fog computing. In this paper, a tradeoff between execution time and the allocated memory achieved. The results were proper for mobile users in response time and cost aspects (Bitam et al., 2018).

•
BA is one of the meta-heuristic algorithms that works based on the principle of reflecting the sound of a bat. All bats use sound reflection to detect distance and know the difference between food and the obstacles ahead. They can automatically adjust the transmitted waves and the rate of their transmitted pulses according to the proximity of their prey. Thus, imitating bat behaviors leads to optimal solutions (Chawla and Duhan, 2015). The advantages of BA: simple, flexible, efficient for nonlinear problems, reaching an optimal solution in complicated problems as well as in quick time. Disadvantages of BA: converges very quickly, limited accuracy in low function evaluation. In Zafar et al. (2018) the use of BA for energy management in efficient allocation of computational resources on Fog has been suggested.

•
MFO imitates the moth’s behavior in the night around the flame. Moths are moved around the flames in a spiral path with a fixed angle and update their positions in order to find better positions (Mirjalili, 2015). The advantages of MFO: having few setting parameters, very quick convergence at a very initial stage by switching from exploration to exploitation, having a balance between exploration and exploitation. The disadvantage of this algorithm happens when the algorithm is diverging to the exploitation stage by changing the number of flames. Also, this algorithm suffers from a slow speed convergence which leads to stuck at local optima. Ghobaei-Arani et al. proposed a task scheduling algorithm based on MFO for assigning cyber–physical system applications to Fog Computing with the aim of minimizing task execution time and supported QoS parameters (Ghobaei-Arani et al., 2020).

•
COA is based on the life of the cuckoo bird. The cuckoo lays its eggs in the nests of other birds. If the host bird notices the presence of cuckoo eggs, it destroys the eggs. Due to the increase in the number of saved eggs in an area, it causes other cuckoos to migrate to that area. Each cuckoo lay eggs in nests based on egg laying radius randomly. Then the profit value of nests is calculated. Also, the population of cuckoo birds is grouped using the K-means algorithm and the value of each group is calculated. The group with the highest fitness is selected for optimization. The advantages of COA: tuning few parameters and robustness, the Levi flight enhances its global searchability. Disadvantages of COA: utilization of the random number to initiate locations of nests has created two problems: first, the location of these nests will be the same, second, sometimes the location of these nests are not properly dispersed in a defined area and caused stuck in the local optimum. Based on Lévy flights and random walk to find nest location in the COA algorithm, the nest’s locations may be out of the boundary, therefore, the boundary value to replace these locations considered in COA. The bound dealing method will result in a lot of nests at the same location on the boundary, which is an inefficient method. COA is used for task scheduling optimization in Fog computing in Nazir et al. (2018). According to COA, the tasks are located in the appropriate Virtual Machines (VMs) based on optimization response time and cost parameters. Also, this algorithm reduces energy consumption by detecting underutilized VMs and turn off them (Nazir et al., 2018).

•
FA mimics the behavior of fireflies (Fister et al., 2013). Fireflies’ attractiveness is based on light intensity and they are moved towards the more attractive individuals. The light intensity of a firefly fits with fitness function. This algorithm is efficient for multi-modal optimization problems. The advantages of FA: automatically subdivision and the ability to deal with multimodality. Also, convergence can be speed up by tuning parameters for controlling the randomness as iterations proceed. The main disadvantages of FA is high computational time complexity and slow convergence speed. Hassan et al. (2018) applied FA for dynamic load balancing along with cost reduction in Cloud–Fog platform. Finally, based on FA, a trade-off between cost and processing time in Fog was reached. Also GSO is mimic the explore behavior of lightning worms. Glow-worms select a brighter glow. This algorithm can be suitable for IoT scenarios (Zedadra et al., 2018).

•
PSO is modeled based on the social behavior of bird groups. This algorithm starts with an initial population of random solutions and it searches for optimum solutions by updating generations. The crossover and mutation operators in the standard PSO algorithm are not calculated. Based on the particles’ fitness value and velocity move around in the search space, the optimal location or the optimal solution is achieved (Masdari et al., 2017). The main advantage of the PSO algorithm is that it does not overlap and mutation calculation, and the main disadvantage of this algorithm is suffering from partial optimism. Nguyen et al. proposed a time–cost aware scheduling algorithm in the Cloud–Fog environment with the aim of processing large-scale bag-of-tasks applications to reached trade-off between execution time and monetary cost. The results proved an improvement of 11.4 percent compared to modified PSO (Nguyen et al., 2019b). Yadav et al. (2019) proposed both GA and PSO (GA-PSO) for service allocation in Fog computing with the aim of minimizing total makespan and energy consumption for IoT applications.

Genome mimetic.
The Genome mimetic-based includes GA, Memetic Algorithm (MA) and Differential Evolution (DE).

•
GA is the first evolutionary algorithm was proposed by John Holland in 1975. This algorithm mimics the natural selection to create the next generation. The GA consists of five general phases. Initial population, fitness function, selection, mutation, and crossover (Yu and Gen, 2010, Whitley, 1994). The advantages of GA: this algorithm is able to deal with complex problems and parallelism, works well in various types of fitness function such as stationary or nonstationary, linear or nonlinear, continuous or discontinuous, or with random noise, possessing robust search space in many directions simultaneously with the help of offsprings in the population. The most famous disadvantage of the genetic algorithm is its costly computation. Other challenges in this algorithm should also be noted such as objective function formulation, the size of the population, the selection of the appropriate parameters and rates for each, and the selection criteria of the new population must be attentively considered. Skarlat et al. (2017) proposed a conceptual Fog computing framework. In this framework, they used genetic algorithm for solving service placement problem in IoT applications. Genetic algorithm optimized network communication delay and utilize the usage of Fog resources.

•
MA is a refinement of GA and applied in optimization problems. The idea behind the memetic algorithm is the special local search performed by each individual. This new special feature point that individuals can find more suitable (fit) individuals who are close to them in the search space. Goudarzi et al. proposed MA for batch application placement with the aim of minimizing the weighted cost in bandwidth and execution time of IoT devices according to GA functions. Initialization, selection, crossover, mutation, and local search are the main steps of the proposed algorithm (Goudarzi et al., 2021). Canali and Lancellotti (2019) presented an optimal model for assigning generated data from sensors over the Fog nodes. The proposed model considered two influential parameters: processing time on the Fog nodes and the latency between sensors and Fog nodes. Then a heuristic algorithm based on genetic algorithm to support large-scale instances was proposed. To select the appropriate parameters, a variety of genetic algorithm parameters and strategies were evaluated. Uniform crossover, uniform integer mutation, tournament selection, and simple strategy had the best results based on the experiments. The proposed solution to the service placement problem was evaluated based on real traffic data in a smart city. A combination of different modes with different parameters was performed to analyze the system performance according to the average load of the system parameter and the ratio between the average network delay and the average service time. The population size sensitivity and genetic algorithm operators sensitivity show the competence of the proposed model.

•
DE is a direct search optimization algorithm. Algorithm operators, like GA, include crossover, mutation, and selection. GA depends on crossover while DE depends on mutation operator. Differential evolution has some weaknesses such as complex procedure, stagnation, and poor search ability. Manasrah et al. proposed an optimized service broker routing policy based on the DE algorithm in Fog/Cloud with the aim of finding the most proper data center for users’ requests and minimized processing time, response time, and cost (Manasrah et al., 2019).

Search-based.
Search-based includes Tabu search (TS), Simulated Annealing (SA), Gravitational Search Algorithm (GSA), and Differential evolution which have been used in reviewed articles.

•
TS algorithm is based on the use of dynamic tabu memory or dynamic list that prevents the algorithm gets stuck in a local optimum. TS algorithm uses the aspiration criterion. When a better solution than the current best solution has been found, the algorithm moves to a better solution, even if that move is banned. It is worth mentioning the act of changing the current solution and going to the neighbor’s solutions is called move, and the different moves get different neighbors. The main advantage of the tabu search algorithm is avoiding fall into the local optimum and the main disadvantage of this algorithm is required massive memory resources. Mouradian et al. proposed a TS-based component placement algorithm that improved the makespan and execution cost in Cloud computing (Mouradian et al., 2019).

•
SA simulates a gradual decrease in the temperature of solids. At each step, the SA takes into account a neighboring state and decides whether to move between the new state or stay in the previous state. The idea of an algorithm is to accept a worse solution with a defined possibility. The advantages of SA: the ability to deal with highly nonlinear models, chaotic and noisy data, and many constraints. The ability to avoid getting stuck at local minimum, and also, the ability to easily tune. SA guarantee a convergence in large numbers of iterations. Disadvantages of SA: the precision of determine sufficient amount of iterations at each temperature. Also, determining the initial temperature is difficult and affect the quality of the solutions and the time required to compute them. Wu et al. suggested using SA algorithm to solve the VM placement problem to optimize the power consumption. The proposed algorithm improved 25 percent compared with the First Fit algorithm (Wu et al., 2012).

•
GSA is an optimization algorithm based on interactions between particles and the Law of Gravity. The advantages of GSA: fast convergence, and low computational cost, suitable for highly nonlinear optimization problems, high precision, ability to scape from local optimum, memory-less and efficient in terms of CPU time. Disadvantages of GSA: Slow searching speed in the last iterations, determining gravitational constant parameter is difficult, and have long computational time. Karamoozian et al. proposed GSA with the aim of modeling the IoT applications and Fog infrastructure for minimizing response time (Karamoozian et al., 2019). The summary of evolutionary algorithms to solve the FAP problem categorized in Table 3, Table 4.


Table 3. Summary of evolutionary algorithms in FAP.

Evolutionary algorithms in FAP
SI-based	Paper	Aim	Algorithm	Performance
Metrics	Highlights
ACO	Hussein and Mousa (2020)	A formal model of IoT task offloading on the Fog nodes	ACO	RT,LS	Effectively load balance IoT tasks over the Fog nodes under communication cost and response time.
Huang et al. (2020)	Modeling the service placement and data flow management into multi objective scheduling problem	MRPACO	LT, DC	Proposed multireplicas Pareto ant colony optimization (MEPACO) based on pareto-ACO Based on the authors’ observations, a good-quality solution is more likely to be formed if the ant greedily selects the flow direction by
minimizing the increased latency and service cost.
Gill and Singh (2020)	Minimize the makespan of tasks
placed on containers	ACO	CPT	Proposed a mechanism based on ant system for
container placement on virtual machines.
Zahoor et al. (2018)	Load balancing between an
smart grid user’s requests
and service providers	HABACO	RT,PcT,
DTC, VC	Proposed an efficient resource management with
combination two ABC and ACO algorithms namely
(HABACO) to assign tasks to VM and find the global
optimum solutions.
Wang and Li (2019)	A new architecture for smart production line to minimize
energy consumption and delay	IACO	CPT, EC, RA	Proposed a hybrid heuristic algorithm for the task
scheduling problem which combines IPSO and IACO.
Boveiri et al. (2019)	Achieve the optimal task-order	MMAC	CPT, SL	Max–Min Ant System (MMAC) to solve the
static task-graph scheduling.
Xu et al. (2019a)	Approximate optimal scheduling to minimize the total energy consumption	LBP-ACS	EC, SL, FR	(1) Applying the laxity-based priority algorithm
to construct a task scheduling sequence.
(2) Approximate optimal scheduling based on ant
colony system.
(3) A new proposed scheme namely laxity and ant
colony system algorithm(LBP-ACS).
ABC	Ismail et al. (2018)	Distribute the user requests among the VMs to minimize the service
delay and to increase the performance of Fog	ABC	RT, PcT, VC, DTC	Artificial Bee Colony (ABC) Load balancing algorithm
proposed to integrate the concept of Fog and Cloud computing with the smart grid for the effective utilization
of resources in residential buildings.
Sharma and Saini (2019a)	Prioritize the user demand	ABC	EC	proposed ABC for load management and minimize
energy consumption rate and reduction of the
schedule length run time.
Ghalehtaki et al. (2019)	Place micro-caches to improve
end-users’ QoS	MCP	LT	Deployment of micro-cache storage units at set-top
boxes in Fog-based content delivery networks with
ABC optimization algorithm-Micro-cache Placement
(MCP).
BLA	Bitam et al. (2018)	Addressing the job scheduling problem in the Fog	BLA	TET, EXC	Efficient execution of tasks and satisfy the service
requests of mobile users while minimizing the CPU
execution time and allocated memory for the job
based on bee life algorithm.
BA	Zafar et al. (2018)	Energy management for smart homes	BA	RT, ST, PcT	A new energy management bio-inspired technique,
Bat Algorithm (BA), was proposed for resource
allocation among the Fog.
Mishra et al. (2018)	Efficient service allocation for industrial applications	BAT-SAA	CPT, EC	Presentation a general Fog system model, including
host model, VM model, and service model based on
BAT Service Allocation Algorithm (BAT-SAA).
Arshad et al. (2020)	Bill estimation based on resource
utilization and cost	BBA	RU, EXC	(1) For estimating the bill through the time of use
pricing four nature-inspired algorithms include: Pigeon
inspired optimization (PIO), Enhanced Differential
Evolution(EDE), Binary Bat Algorithm (BBA), and
Simple human learning optimization (SHLO) are analyzed.
(2) BAT performs better than other three algorithms in
terms of both resource utilization and bill reduction.
MFO	Ghobaei-Arani et al. (2020)	Choose the best destination for each task on the Fog nodes	TS-MFO	TET	Scheduling cyber–physical system (CPS)
tasks based on moth–flame optimization (MFO)
FA	Hassan et al. (2018)	Dynamic load balancing along with cost reduction	FA	RT, VC, DTC	Schedule tasks among VMs based on firefly Algorithm (FA)
Adhikari and Gianey (2019)	Finding an optimal computing device
based on minimization the computation time and energy
consumption	FA	CT, EC	Development a new bi-objective energy-efficient
offloading strategy (EES) according to FFA.
COA	Nazir et al. (2018)	Detection under-utilized and over-utilized Fogs and switch
off the under-utilized VMs also minimization the cost in on-peak
hours	COA	RT, PcT	(1) Detection of under and over-utilized Fogs
by applying the COA.
(2) Move some of the over-utilized VMs to some
other hosts.
(3) Transfer the VMs of the under-utilized host
to other hosts and turn them into sleep mode.
Javaid et al. (2019)	Efficient load balancing with minimizing the latency and delay
in Cloud and Fog	CLW	RT, PcT, MC,
VC, DTC	(1) Cuckoo search with Levy Walk distribution
(CLW) and Flower Pollination (FP) proposed.
(2) Proposed algorithms were compared with
COA and BAT.
PSO	Djemai et al. (2019)	IoT service placement in Fog infrastructure	DPSO	EC	(1) Discrete Particle Swarm Optimization (DPSO)
find a good tradeoff between Cloud, Fog, and IoT
for service placement in a physical Fog topology.
(2) Evaluation of the applications total delay
violations and system’s energy consumption.
Xu et al. (2018)	Workflow scheduling in Cloud–Fog environment	IPSO	CPT, EXC	(1) Designing a nonlinear decreasing function,
which facilitates to balance and adjust the global
and local abilities of particles.
(2) Each particle in PSO is encoded as a scheduling
plan according to the number of workflow tasks.
Javanmardi et al. (2020)	Resource management to reduce network utilization and application
loop delay	FPFTS	LT, DL	Combining PSO and fuzzy methods to address
the Fog task scheduling problem.
Wan et al. (2018)	Optimal scheduling and load balancing for the smart factories	IPSO	LS	(1) IPSO algorithm is applied to solve the mathematical
model of load balancing.
(2) IPSO was responsible for solving the model and get
the solution vector to obtain the priority of agent request task.
(3) presentation an energy-aware load balancing
and scheduling (ELBS) method in smart factories.
Butt et al. (2019)	Optimization response time in smart
societies	IPSOLW	RT, PcS, VC, DTC	In Improved PSO with levy walk (IPSOLW), the velocity
of particle swarm is updated with levy walk, because of it’s
premature convergence.
Rafique et al. (2019)	Reducing the average response time and management the Fog available resources	MPSO	EC, TET, EXC, RT	(1) Introduced a bi-inspired hybrid algorithm (NBIHA),
the combination of modified particle swarm optimization
(MPSO) and modified cat swarm optimization (MCSO).
(2) MPSO is responsible for scheduling the task among
Fog nodes.
(3) MPSO and MCSO is applied to manage resources
at the Fog device level.
Genome-based	Paper	Aim	Algorithm	Performance Metrics	Highlights
GA	Skarlat et al. (2017)	Reduction service communication
delay for Fog service placement	GA	RT, DL, EXC	(1) Introduction a conceptual framework for
resource management and service placement.
(2) The genetic algorithm (GA) produced a
lower deployment delay compare with first fit
heuristic and exact optimization method.
Zubair et al. (2018)	Efficient load balancing in the smart grids while minimizing the total cost
for end users and optimization response time	HGABP	RT, PcT, VC	Hybrid genetic algorithm using bin packing
(HGABP) compared with Round Robin and
throttle had a better performance at processing time and response time also HGABP technique was less
costly compared with values of two other algorithms
Brogi et al. (2019)	Multi-service application placement in the Fog with maximizing QoS
assurance and minimizing Fog
resource consumption and
operational cost	GA	TET, EXC	A new combination of GAs with Mont Carlo
simulation and improving the exhaustive search
based on QoS-aware application deployment.
Akintoye and Bagula (2019)	VM placement to improve QoS in the Cloud/Fog environment	GABVMP	PcT, EC, DC	Genetic algorithm based virtual machine placement
(GABVMP) compared with Random placement and
First Fit placement had a lower cost to place virtual
machines (VMs) on physical machines (PMs).
Canali and Lancellotti (2019)	Map sensors over Fog nodes	GASP	LT, PcT, CT	Utilization of genetic algorithm for service placement
(GASP) to reduce the total latency and processing
time in Fog.
Evolutionary Algorithms in FAP
Genome-based	Paper	Aim	Algorithm	Performance Metrics	Highlights
GA	Reddy et al. (2020)	Minimization the energy consumption
and minimization the overall service
delay	SCS-GA	EC, DL	(1) Utilization of GA in conjunction with smart
context sharing (SCS) for VM management at
Fog layer.
(2) Utilization of reinforcement learning
for reducing the energy consumption.
Bourhim et al. (2019)	Finding optimal locations for placing
containers at Fog	CPGA	RT, TET, RU	(1) Introduction of a new containerize
microservices strategy based on GA.
(2) Container placement based on genetic
algorithm (CPGA) outperformed ILP and greedy.
Guerrero et al. (2019)	Service placement for optimizing the
network latency, the service spread, and the use of the resources	WSGA,
NSGA-II	LT, RU	Non-dominated sorting genetic algorithm II
(NSGA-II) outperformed weighted sum genetic
algorithm (WSGA) and multiobjective evolutionary
algorithm based on decomposition (MOEA/D).
MA	Goudarzi et al. (2021)	Minimizing the overall execution time of IoT applications and
energy consumption of IoT devices	APMA	TET, EC	(1) Utilization an optimized version of the Memetic
Algorithm (MA) to finding a suitable solution in
reasonable decision time.
(2) Applying an application placement memetic
algorithm (APMA) for task scheduling while
considering the server assignments of previous
schedules.
Sami and Mourad (2020)	Optimizing the number of pushed services to devices, the number of active devices to host all of these
services, the QoS, the survivability factor, and the distance range from
the hosting device to the requesting node	MA	RT	Solving the multi-objective Fog selection
and container placement according to
memetic algorithm (MA)
Sami et al. (2020)	Finding the best distribution of services on the set of available
vehicles based on available resources, service requirements, network stability of the moving cluster,
maintenance of attached micro-services, and proximity
from the user during the serving time	MA	RT	Vehicular container placement according
to memetic algorithm
DE	Manasrah et al. (2019)	Suggestion an optimized service broker routing policy	DE	RT, PcT,
VC, DTC	(1) Selecting a suitable datacenter based
on a new broker policy and applying
Differential Evolution (DE) optimization
algorithm in Fog/Cloud environment.
(2) The algorithm balances between the
delay, bandwidth, and the request size
in selecting the most suitable datacenter.
Hussain et al. (2019)	Offering a cost optimization model for investigating data consumer association, workload distribution,
virtual machine placement, and QoS constraints	MDE	cost-EC, RT	The proposed cost optimization model
was formulated based on a Mixed-
Integer Nonlinear Programming (MINLP)
problem which was solved using the
Modified Differential Evolution (MDE)
algorithm.
Arshad et al. (2018)	Estimating the bills on the basis of
the energy consumed by the cloudlets	EDE	RU, EC, EXC	(1) Utilization of the Pigeon Inspired Optimization
(PIO) and the Enhanced Differential Evolution
(EDE) for estimating the consumed electric bill of
the users.
(2) PIO gives significantly better results than EDE
in terms of resource utilization whereas for bill
reduction, EDE outperforms PIO based technique.
Hussain and Beg (2021)	(1) Dynamically allocate the
computing resources of Fog nodes to the client vehicles
(2) Finding an optimal vehicle-to-Fog node association coupled with an
appropriate set of Fog nodes to host
the VMs for each application	CODE-V	LT, EC	Computation Offloading with Differential Evolution
in Vehicular Fog Computing (CODE-V) was applied
to solve multi-hop computation offloading.
Evolutionary Algorithms in FAP
Search-based	Paper	Aim	Algorithm	Performance Metrics	Highlights
TS	Mouradian et al. (2019)	Efficient application component placement with considering
mobility manner in the Fog/Cloud	TSCP	CPT, EXC	(1) Implementation application components as
virtual network functions (VNFs).
(2) Utilization of waypoint mobility model for
Fog nodes to calculate the expected makespan
and execution cost.
(3) The problem was modeled as integer linear
programming.
(4) Utilization of Tabu Search-based component
placement (TSCP) to find sub-optimal placement.
Siasi et al. (2019)	Network function virtualization (NFV) placement at Fog nodes	TS	PT, EC	Applying a Tabu search algorithm for virtual
function placement and heuristic routing schemes
with load balancing for efficient resource utilization.
Nardelli et al. (2019)	Placing data stream processing (DSP)
applications over geo-distributed
infrastructures with considering the
heterogeneity of optimization goals and computing and network resources	TS	RT, RU	(1) For solving the optimal data stream
processing (ODP) problem, two types of heuristics
were applied include model-based and model free.
(2) Well known model free heuristics such as greedy, local search and tabu search were compared and the local search
got the best result to solve this problem.
SA	Rezazadeh et al. (2018)	Finding the appropriate device for the modules in a Fog	SAMP	EC, DL, RUC	(1) Utilization of simulated annealing for module
placement (SAMP) in Fog devices.
(2) The proposed approach was applied to health
care application.
GSA	Karamoozian et al. (2019)	Efficient distribution of the IoT applications processing elements (PE)
over the Fog–Cloud infrastructure	GSA	RT	(1) The PE scheduling and placement problem
was formulated with gravitational search algorithm
(GSA).
(2) The proposed approach was compared to PSO
and the results showed that GSA outperforms PSO

Table 4. Categorizing Evolutionary Algorithms in FAP.

Heuristic Evolutionary Algorithms in FAP
Category	Ref.	Algorithms	Purpose of Combination and Idea
Hybrid Meta-Heuristic Approach	Wang and Li (2019)	IPSO, IACO	Purpose: improving accuracy and search speed.
Idea: based on the fast convergence characteristics of the IPSO algorithm the optimal solution collected then the optimal solution is the initial pheromone distribution of the IACO algorithm for optimal task scheduling.
Zahoor et al. (2018)	ABC, ACO	Purpose: to find the global optimum.
Idea: although ACO is used in search of new sources of food (VM) based on best source utilization, it cannot change the obtained pheromone value for the VM in some iterations and stuck in the local optimum. To find the best optimal solution, the ABC fitness function integrated into ACO to find the global optimum solution.
Rafique et al. (2019)	MPSO, MCSO	Purpose: improving resource utilization with help of MPSO and improving the search efficiency with help of MCSO.
Idea: For task assignment and finding the global optimum the MPSO algorithm was applied for managing resources, include CPU and memory, hybrid MPSO-MCSO was applied.
Yasmeen et al. (2018)	PSO, SA	Purpose: enhancing sampling and searching PSO with SA.
Idea: PSO can be improved by sampling the Global best with SA after every iteration improving the search of PSO effected to increase the probability of coming out of local optimum.
Yadav et al. (2019)	PSO, GA	Purpose: PSO has fast convergence, but sometimes the final solution falls in local optima GA provides poor performance, and it takes more convergence time.
Idea: applying GA along with the PSO: crossover, mutation and fitness function of each solution calculated based on a selected random population by GA then PSO following the local best position and global best position of the particle, due to the allocation of services on VMs particles.
Ren et al. (2021)	ACO, GA	Purpose: precision and speed of GAs convergence can be optimized by the ACO algorithm.
Idea: the algorithm uses GA’s universal investigation power, and then it is transformed into ACO primary pheromone.
Hosseinioun et al. (2020)	IWO, CEA	Purpose: IWO accelerates the convergence of solutions in a problem space.
Idea: presenting a hybrid Invasive Weed Optimization and Culture IWO- CEA evolutionary algorithm to evaluate an energy-aware task scheduling approach.
Further meta-heuristic approach	Javanmardi et al. (2020)	Fuzzy theory and PSO	(1) Utilization of Fuzzy logic in the PSO fitness function (2) The proposed algorithm, FPFTS, considered the features of resources and tasks simultaneously
Xu et al., 2019a, Xu et al., 2019a	Laxity-based priority, Ant colony system	The goal of laxity: constructing a task scheduling sequence with reasonable priority The goal of ant system: minimizing the total energy consumption
Huang et al. (2020)	Multireplicas Pareto ant colony optimization (MRPACO), P-ACO	Accelerate the convergence speed and improved the accuracy of the pareto front.
Butt et al. (2019)	Improved PSO with levy walk	Updating the velocity of particle swarm with levy walk, because of it’s premature convergence.
Xu et al. (2018)	Improved PSO	Inertia weight updated as a nonlinear decreasing function, which facilitates to balance and adjust the global and local abilities of particles then each particle in PSO is encoded as a scheduling plan according to the number of workflow tasks.
Wan et al. (2018)	Improved PSO	(1) Sorting the bidding agent collection priority. (2) Obtaining an optimal solution and the priority for achieving tasks is built towards the manufacturing cluster.
Djemai et al. (2019)	Discrete PSO	(1) Reducing response delay violations (2) Offering fast and powerful computation capacity while reducing as much as a possible system energy consumption.
Zubair et al. (2018)	GA by Bin Packing	(1) GA was applied for selecting the best VM (2) Bin Packing was applied to shut down unused VMs
Brogi et al. (2019)	GA by Monte Carlo	(1) GA was applied to generate best deployment set and worst deployment set (2) Monte Carlo method estimate the QoS-assurance
Reddy et al. (2020)	GA by smart context sharing and RL	(1) GA was applied for allocating service requests with a minimal number of active fog nodes (2) A reinforcement learning algorithm was applied to achieve optimal duty cycle for sleep and wake ups
Wu et al. (2012)	SA for VM placement	Using SA to solve the VM placement to optimize the power consumption SA is suitable for static VM placement
Nardelli et al. (2019)	TS for Data stream placement	Tabu list was used to avoid cycles and improving exploration
Abdel-Basset et al. (2020)	Harris Hawks based Local search	(1) Improving the QoS for task scheduling IoT applications (2) A swap mutation operation and a local search strategy adapted to balance the task distribution among VMs
3.2.2. Machine learning algorithms in FAP
Machine learning algorithms divided into two subgroups includes classic learning algorithms and deep learning algorithms. Classic learning algorithms divided into three subgroups involves supervised learning, unsupervised learning and Reinforcement Learning (RL) as listed in Table 5.

Supervised learning.
The supervised learning algorithm is a general method of machine learning (ML) algorithms that rely on the labeled data set. The main purpose of supervised learning is to create a model for communication between inputs and predict the desired outputs. Supervised learning categorized into regression and classification. The classification includes Decision Tree (DT), ANN, Random decision Forest (RF), K-Nearest Neighbor (K-NN), Support Vector Machine (SVM), Apriori and Logistic Regression (LR). Regression involve regression tree.


Table 5. Review of Machine Learning Algorithms.

Classic Machine Learning Algorithms
Category	Algorithms	Related papers
Supervised Learning (Regression and classification categories)	Regression tree	Rahbari and Nickray (2020)
Logistic regression	Bashir et al., 2019, He et al., 2017
KNN, SVM	Peng et al., 2018, He et al., 2017
ANN	Fei et al., 2019, Priyabhashana and Jayasena, 2019
Apriori	Liu et al. (2018)
Decision tree	He et al., 2017, Liu et al., 2018, Govindan et al., 2017, Alsaffar et al., 2016
Random forest	Liu et al., 2018, Lin et al., 2017
Unsupervised Learning (Clustering)	K-means	Sharma and Saini, 2019b, Maiti et al., 2019, Li et al., 2018a, Selimi et al., 2019, Yuan et al., 2020
Hierarchical	Mahmud et al., 2018, Shooshtarian et al., 2019
Fuzzy-c-means	Li et al., 2019b, Yadav et al.
Reinforcement Learning	Q-Learning	Tang et al., 2019, Gazori et al., 2020, Wang et al., 2019, Farhat et al., 2020, Dehury and Srirama, 2019
R-Learning	(Farhat et al., 2020)
SARSA	(Orhean et al., 2018)
•
Regression is a statistical process for estimating relationships between variables. It is also used to identify the relationship between the independent and dependent variables (Praveen Kumar et al., 2019). The advantages of linear regression: works well irrespective of the data set size and when the dataset is linearly separable, gives information about the relevance of features. Linear Regression is prone to over-fitting but it can be avoided by applying some dimensionality reduction techniques such as regularization techniques, and cross-validation. Disadvantages of linear regression: the assumption of linearity, prone to noise and overfitting, prone to outliers, prone to multicollinearity. The advantages of polynomial regression: works on any size of the data set, works very well on non-linear problems. Disadvantages of polynomial regression: need to choose the right polynomial degree for good bias, variance tradeoff, too sensitive to the outliers. Rahbari et al. proposed a module placement method based on classification and regression tree in mobile Fog computing to find the best Fog device. The proposed algorithm was superior compared with the First Fit algorithm in power consumption, response time, and performance (Rahbari and Nickray, 2020).

•
LR is mathematical modeling that belongs to the classification category and generalized form of the linear regression model (Praveen Kumar et al., 2019). The advantages of logistic regression: performs well when the dataset is linearly separable, this algorithm is less prone to over-fitting but it can overfit in high dimensional datasets. Disadvantages of logistic regression: Unlike real-world data that is rarely linearly separable, this algorithm assumes a linearity relation between the dependent variable and the independent variables. Logistic Regression should not be applied, if the number of observations is lesser than the number of features. Otherwise, the probability of overfitting increases. Logistic Regression can only be applied to predict discrete functions. Bashir et al. proposed a dynamic resource management model in Fog computing and applied logistic regression for calculating the load of individual Fog node and effect on the next decisions. Proposed algorithm improved the performance with 98.25 percent accuracy (Bashir et al., 2019).

•
KNN algorithm is one of the simplest data mining and classification algorithms. This algorithm simply performs classification operations and returns reliable results as predictions. The word nearest is the basis of K’s classification operation. In this algorithm, each of the new samples is compared with all previous samples, and each of the previous samples that are closest is assigned to those samples (Praveen Kumar et al., 2019). One of the advantages of this algorithm is that it has no training steps so, new data can be added seamlessly that will not impact the accuracy of the algorithm. The implementation of this algorithm is easy and its uses for both classification and regression. The disadvantages of this algorithm include: does not work well with a large dataset, does not work well with high dimensions, need feature scaling and sensitive to noisy data, missing values, and outliers. Pastor et al. proposed deployment of IoT Edge and Fog computing technologies and integrated Edge and Fog paradigms into a new architecture to develop smart building services. KNN and decision tree algorithms used to manage power consumption and renewable generation (Ferrández-Pastor et al., 2018).

•
SVM is a non-linear ML algorithm that used for classification and regression. The job of SVM is to create a hyper plane to separate the classes (classify the data) so that this hyper plane can be the maximum distance from the samples in the classes. The advantages of the SVM algorithm include: suitable for situations where we have no idea about the data, suitable for unstructured and semi-structured data, most complex problems can be solved with the help of SVM strength of kernel, SVM is not solved for local optima, SVM models have generalization in practice, the risk of over-fitting is less in SVM. Disadvantages of this algorithm include: choosing the right kernel is not easy, the training time for large datasets is long. He et al. proposed a multi-tier Fog computing model with large-scale data analytics services for smart cities applications. Two classification algorithms for presenting the experiments include logistic regression and SVM applied for presentation purposes (He et al., 2017).

•
ANN is the simulated structure of the human neural network. ANN can make connections between the input and expected output. One of the most popular neural network models is the Multi-Layer Perceptron (MLP) which simulates the transfer function of the human brain. Key points about neural networks include: first, neural networks are highly dependent on data sets. Second, the neural networks are slow in the learning phase, but they are fast in the execution phase (Fei et al., 2019, Priyabhashana and Jayasena, 2019). The advantages of ANN: storing information on the entire network, having fault tolerance, possess a distributed memory, gradual corruption, and parallel processing capability. Disadvantages of ANN: hardware dependency, unexplained behavior of the network, design proper network structure, the duration of the network is unknown, and neural networks are getting stuck in the local optimal. Priyabhashana et al. suggested the use of deep learning libraries includes TensorFlow and Keras, Google Cloud Platform, and Deep Neural Network in Fog servers with the aim of object detection. The ANN model trained with thousands of labeled samples for around hundreds of objects. TensorFlow object detection application in Fog was reduced CPU usage and required spaces (Priyabhashana and Jayasena, 2019).

•
Apriori is a classification ML algorithm for frequent item set mining and association rule learning over relational databases (Ye and Chiang, 2006). The advantages of Apriori: easy implementation, can be easily parallelized, and uses large itemset property. The disadvantages of this algorithm: requires scanning of many databases, also is very slow. Liu et al. proposed task scheduling in the Fog computing algorithm based on the I-Apriori algorithm. The proposed algorithm was reduced execution time of tasks and average waiting time. Extracted association rules by the I-Apriori algorithm were combined with the minimum completion time of every task in the task set. Therefore tasks with minimum completion times were selected in Fog. The proposed algorithm was reduced execution time of tasks and average waiting time (Liu et al., 2018).

•
DT is a classification ML algorithm that relies on if-then rules and training models for predicting categories based on decision rules (Praveen Kumar et al., 2019). The advantages of the decision tree: compared to other algorithms decision trees require less effort for data preparation during pre-processing, it does not require normalization of data and scaling of data as well, missing values in the data also do not affect the process of making a decision tree to any considerable extent, and the number of hyper-parameters to be tuned is nearly null. Disadvantages of the decision tree: the probability of overfitting in this algorithm is high, generally, it gives low prediction accuracy for a dataset compared to other ML algorithms, if there are too many class labels, the calculations get complicated. The DT algorithm is inadequate for applying regression and predicting continuous values. Alsaffar et al. proposed a new algorithm based on decision rules of a linearized decision tree according to three conditions include services size, completion time, and VMs capacity. The proposed algorithm improved resource allocation as well as performance (Alsaffar et al., 2016).

•
RF is decided by several DTs and merges them to create more accurate and stable predictions. In fact, a set of DTs together produce a forest, and this forest can make better decisions than a tree. The advantages of the random forest: by creating many trees on the subset of the data and combines the output of all the trees, overfitting problem in decision trees and the variance can be reduced, therefore the accuracy become improve. Random Forest can be applied to solve both classification and regression problems, this algorithm works well with both categorical and continuous variables, it handles missing values, no feature scaling required, it efficiently handles non-linear parameters, it robust to outliers and stable, and this algorithm less impacted by noise. The disadvantage of the random forest: given a large number of trees and the combination of outputs to achieve a decision tree, this algorithm requires high computational power and more resources, and therefore the complexity of this algorithm must be considered. Random forests require more training time than decision trees because they have to choose one from several decision trees based on the majority of votes. Lin et al. proposed a new classification model based RF algorithm for traditional insurance business data base (Lin et al., 2017).

Unsupervised learning.
Unsupervised Learning is a set of machine learning methods used to discover patterns from unlabeled data (Praveen Kumar et al., 2019). Unsupervised learning with the clustering approach involves K-Means, Hierarchical and Fuzzy-c-means (FCM).

•
K-Means is a clustering algorithm. In this algorithm, the K data as the center of the clusters are selected, then the distance between the rest of the data and the center of the clusters is determined. Closest data to the center of each cluster placed in that cluster. The average of each cluster as the new center of clusters is selected. These steps are continued until the clusters remain unchanged (Praveen Kumar et al., 2019). The advantages of the k-means algorithm: guarantees convergence, scales to large data sets, this algorithm operates faster than the hierarchical algorithm when the variables are huge. It generates tighter clusters than hierarchical clustering, especially if the clusters are spherical. Disadvantages of k-means: K-value prediction is difficult, different initial partitions can result in different final clusters, it does not work well with clusters of various sizes and various densities. Selimi et al. grouped nodes based on naive K-means partitioning algorithm in micro-Cloud service placement approach for community network (Selimi et al., 2019).

•
Hierarchical is a clustering machine learning algorithm that organized as tree and groups similar objects into categories based on top-down (divisive clustering) or bottom-up (agglomerative clustering) order (Praveen Kumar et al., 2019). The advantages of the hierarchical algorithm: no need to define a number of clusters in advance. Disadvantages of this algorithm: the best solution is seldom offered, does not work well with missing data and on very large data sets, and this algorithm works poorly with mixed data types. Shooshtarian et al. grouped the Fog nodes with agglomerative Hierarchical clustering for efficient resource allocation and reduce application placement time in Fog computing (Shooshtarian et al., 2019).

•
FCM algorithm is similar to the K-means algorithm, except that the FCM is suitable for the overlapping clusters and objects can belong to more than one cluster (Yadav et al.). The advantages of the fuzzy-c-means algorithm: for overlapped datasets, it gives better results than the K-means algorithm a data point is assigned membership to each cluster center as a result of which data point may belong to more than one cluster center, while in the k-means algorithm data points must exclusively belong to one cluster center. Disadvantages of this algorithm: very sensitive to good initialization. Li et al. proposed a new resource scheduling algorithm in Fog computing with a combination of FCM clustering and PSO algorithm (Li et al., 2019b). Yadav et al. applied FCM to allocate tasks to minimize system cost and response time (Yadav et al.).

Reinforcement learning.
Reinforcement Learning is a type of machine learning method that enables an agent to learn in an interactive environment using trial and error actions and experiences. Although both supervised learning and RL use the mapping between input and output, RL uses rewards and punishments as signals for positive and negative behavior (Kaelbling et al., 1996). RL algorithms (Montague, 1999) include Q-Learning (QL), R-Learning, State–Action–Reward–State–Action (SARSA) also, the deep reinforcement learning category has been applied in the Fog computing environment which explained in the next subsection.

•
QL is a value-based learning algorithm that uses the Q function to find the optimal policy. The selection of the appropriate action is evaluated based on the action–value function. The goal of this algorithm is maximization the Q function value (Montague, 1999). Farhat et al. proposed Fog scheduling decision model-free based on reinforcement QL for maximum available resources in Fog computing based on the concept of average reward (Farhat et al., 2020).

•
SARSA algorithm is similar to the QL algorithm. The QL algorithm uses an off-policy strategy while SARSA using an on-policy to find the optimal strategy. Unlike the QL algorithm which chooses the best action, SARSA is relying on the exploration path for taking action.(Orhean et al., 2018). Orhean et al. proposed the RL model and applied SARSA and QL to task scheduling in distributed systems (Orhean et al., 2018). Q-learning has the following advantages and disadvantages compared to SARSA: Q-learning directly learns the optimal policy, while SARSA learns a near-optimal policy whilst exploring. Q-learning is off-policy, and has a higher per-sample variance than SARSA, and may suffer from problems converging as a result. This turns up as a problem when training neural networks via Q-learning. SARSA will approach convergence allowing for possible penalties from exploratory moves, whilst Q-learning will ignore them. SARSA is more conservative as if there is the risk of a large negative reward close to the optimal path, Q-learning will tend to trigger that reward whilst exploring, while SARSA will tend to avoid a dangerous optimal path and only slowly learn to use it when the exploration parameters are reduced. In general, it can be concluded the main difference between SARSA and Q-learning is that SARSA is on-policy, that is, it learns action values related to the policy it follows, while Q-learning is off-policy, not depending on the policy which is being used.

•
R-Learning is a new reinforcement learning model proposed for time scheduling of on-demand Fog placement by Farhat et al. (2020) with the aim of decreasing the cloud’s load by utilizing the maximum available Fogs resources over variant locations. Although the R-Learning algorithm is similar to the QL algorithm and uses Q-tables, states, actions, reward, and loss, it applies the average reward instead of using the discounted reward. Indeed in R-Learning, the average reward is a result of rewards gained during all transition between states. The advantages of R-Learning include better prediction, and distributions of clusters over locations at the proper time. The proposed model anticipated the time and location of the required Fog and minimize the number of Cloud processed requests while serving the biggest number of requests produced by users or IoT devices and therefore maximize the usage of candidate resources. By applying the proposed model, the number of Cloud processed requests reduced from 100 percent to more than 30 percent and outperforms random-based and threshold-based approaches.

3.2.3. Deep learning algorithms in FAP
Deep learning is a subset of machine learning methods that consist of several layers which each layer responsible for extract features and train based on the previous layer from high-dimensional space input data therefore the output has a good description of inputs data. Deep learning covers the weaknesses of traditional machine learning. The biggest advantage of deep learning algorithms is that powered by massive amounts of data and these algorithms try to learn high-level features from data in an incremental manner. While in traditional machine learning algorithms most of the applied features need to be identified by a domain expert in order to reduce the complexity of the data. Due to the mentioned advantage, deep learning more applied when the data size is large. The problem-solving approach is different in machine learning and deep learning. Deep learning techniques tend to solve the problem end to end, whilst machine learning techniques need the problem statements to break down to different parts to be solved first and then their results to be combined at the final stage. Also, training time and testing time are different in machine learning and deep learning algorithms. Deep learning algorithm takes a long time to train due to a large number of parameters. Whereas, traditional machine learning algorithms take a few seconds to a few hours to train. At test time, the deep learning algorithm takes much less time to run while machine learning test time increases on increasing the size of data. Deep learning has two major disadvantages: the first being the tendency to abruptly forget previous learning, and the second being the inability to rationalize the information provided (Pouyanfar et al., 2018). As shown in Table 6, deep learning divided into three subgroups include Deep Reinforcement Learning (DRL), Deep Neural Network (DNN), and Deep Robot Learning.

Deep reinforcement learning.
Deep reinforcement learning is Deep learning + Reinforcement learning. The main difference between reinforcement learning and deep learning is that in deep learning, the process of learning is based on a training set and then using it in a new data set. While reinforcement learning dynamically learns by adjusting actions based on continuous feedback to maximize a reward. Utilization of existing data for learning and predicting patterns is a feature of deep learning. While learning from its experience through trial and error is a feature of reinforcement learning (Qiu et al., 2019, Nguyen et al., 2019a). Deep reinforcement learning involves Deep Q-Network (DQN), Deep Q-Learning (DQL), Double Deep Q-Learning (DDQL) and Deep Deterministic Policy Gradient (DDPG). DQN belongs to the deep reinforcement learning category. The main reason to propose DQN algorithm is the weakness of QL in high state–action spaces for large problems. DQN improve itself based on experience replay method. Yan et al. applied online DQN learning for content placement strategy in Fog radio access networks (Yan et al., 2020). DQL (Deep Learning + QL) applies NN to approximate the Q-value function instead of using the Q-table. Alam et al. proposed a DQL for computation offloading in the mobile Edge IoT applications. The power consumption of the proposed solution was improved compared to state-of-the-art algorithms (Alam et al., 2019). DDQL (DQL + DQL) uses two neural networks to learn and predict what action to take at every step. Zhang et al. proposed DDQL model for energy efficient Edge scheduling (Zhang et al., 2018). DDPG is similar to DQL that only usable in continuous action spaces with an off-policy strategy. Lu et al. proposed a novel QoE model computation offloading with the DDPG algorithm. Also, improved DDPG namely Double-Dueling-Deterministic Policy Gradients was suggested for the determined problem (Lu et al., 2020).


Table 6. Review of Deep Learning Algorithms.

Deep Learning Algorithms
Category	Algorithms	Related papers
Deep Reinforcement Learning	DQN	Tang et al., 2019, Gazori et al., 2020, Yan et al., 2020
DQL	Tang et al., 2019, Gazori et al., 2020, Alam et al., 2019
DDQL	Gazori et al., 2020, Zhang et al., 2018
DDPG	Tang et al., 2019, Gazori et al., 2020, Lu et al., 2020
Deep Neural Network	CNN, RNN	Li et al., 2019c, Lu et al., 2020
LSTM	Yuan et al., 2020, Chen et al., 2020
DBN	Cao et al., 2018, Alelaiwi, 2019, Naveen and Kounte, 2018
GAN	Wu et al., 2019, Naveen and Kounte, 2018
Deep Robot Learning	–	Tanwani et al., 2019, Gudi et al., 2017
Deep neural network.
Deep neural network trained by using a large sets of labeled data to perform classification tasks or regression from any types of data sets. DNN includes Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Generative Adversarial Networks (GAN) and Deep Belief Networks (DBN). CNN is a NN algorithm using convolution layer. Despite the most use of CNN in the object detection field, Li et al. proposed a four-layer CNN-based model to solve the scheduling problem in Fog computing (Li et al., 2019c). RNN was actually created to process trail signals. These networks have a type of memory that records the information. In fact, RNN learn to use the past information. Chen et al. applied hidden Markov model based on kernel Bayes rule and RNN to predict the traffic volumes (Chen et al., 2016). LSTM is special type of RNN that have the ability to learn long-term dependencies. Yuan et al. proposed dynamic virtual Edge node placement for Edge cloud systems in a mobile environment. With the help of LSTM, the service requests of end-users, and the resource prices were predicted (Yuan et al., 2020). DBN was introduced by Hinton. The proposed network has made significant progress in deep learning. DBN is a potential generator model that distributes shared probability on observable data and tags. A DBN first uses an efficient greedy learning strategy layer by layer for deep initialization (parameters) of the deep network, and then carefully adjusts all the weights together with the expected outputs (Zhang et al., 2016). Alalawi et al. proposed an efficient ML model for computation offloading in Edge/Cloud environment. DBN and logistic regression suggested for classification phase in proposed model (Alelaiwi, 2019). GAN is an approach to generate new model from the original data set. Wu et al. predicted the future trajectories of mobile users in Edge computing based on the GAN algorithm with the aim of task offloading in mobile Edge computing environments (Wu et al., 2019).

Deep robot learning.
Like a human, Robots need to make real-time decisions about any activity. Due to Robots duties, machine learning algorithms can be deployed in the Fog nodes with advanced hardware capabilities like Graphic Processing Units and embedded platforms to run small-scale analytic tasks on locally collected data.(La et al., 2019). Fog Robotics (FR) is an extension of Cloud Robotics that brings computational resources closer to mobile Robots to perform pre-processing, filtering, deep learning and inference (Gudi et al., 2017). As illustrated in Fig. 6, FR architecture (bottom-up) consist of a Robot, Fog Robot Server (FRS) and a Cloud system (Gudi et al., 2017). Due to the Robot’s data requests, the FRS responds. If the request needs more computational, storage and networking resources, or for training models on huge datasets it will be sent to the Cloud system (Gudi et al., 2017). Also, Robots share their knowledge even if they are in different places and collaborate to achieve common tasks (Gudi et al., 2017). FR is suitable for real-time interactions and has advantages include: sharing data, computing resources being closer, increase data security and improve mobility (Gudi et al., 2017). Tanwani et al. proposed to deploy object recognition and grasp planning model with deep Robot learning in Edge. The proposed model reduces the round-trip communication time for inference with a mobile Robot (Tanwani et al., 2019). Deep learning models are trained with the saved images in the Cloud datacenters knowledge-based. The trained model can be applied to real images in the private Edge environment. This approach implemented where a mobile Robot picks and sorts objects from a cluttered floor by learning deep object recognition and a grasp planning model (Tanwani et al., 2019).

3.2.4. Combinatorial algorithms in FAP
Combinatorial algorithms are a combination of two introduced AI categories. According to Table 7, combinatorial algorithms category includes a combination of machine learning algorithms and heuristic, a combination of evolutionary algorithms and heuristic and combination of evolutionary algorithms and machine learning algorithms .

Combination of machine learning algorithms and heuristic.
A combination of machine learning algorithms and heuristic is one of the categories of the combinatorial algorithm that authors proposed new algorithms or new machine learning models for achieving more efficient solutions than raw machine learning algorithms. Li et al. proposed a heuristic model-based method for VM allocation in Fog computing according to a generic semi-Markov decision problem. Also, a model-free reinforcement learning method to solve the coordinate VM allocation problem suggested (Li et al., 2018b). La et al. applied machine learning algorithms for task scheduling in Fog environment with the aim of reducing energy consumption and latency (La et al., 2019). To prove the validity of the proposed approach, two case studies related to user-behavior-driven healthcare monitoring and device-driven adaptive task offloading checked out respectively (La et al., 2019). Three machine learning classifiers including SVM, decision tree, and Gaussian Naive Bayes are trained and tested based on the first case study. Training set accuracy was above 98 percent and the test set was 97.5 percent. According to the second case study, a mixed-integer nonlinear programming optimization applied (La et al., 2019). Tang et al. proposed a new container migration DQL model for mobile tasks with the aim of minimizing delay, power consumption and migration cost. Based on their heuristic, the random action selection in the exploration phase was optimized. Also, DNN training strategy in Q-network was improved (Tang et al., 2019). Gazori et al. proposed double deep Q-learning task scheduling of Fog-based IoT applications with using a target network and experience replay techniques. With the using four separate schedulers, the state and action space dimensions decreased (Gazori et al., 2020). Rahbari et al. proposed a Module Placement method by Classification and regression tree Algorithm (MPCA). The training phase of machine learning algorithms is time-consuming. Therefore, MPCA applied for the training and testing phases and to optimize the MPCA, another algorithm namely MPMCP proposed. The MPMCP results used to select the best Fog devices (Rahbari and Nickray, 2020).


Table 7. Review of Combinatorial Algorithms.

Combinatorial Algorithms
Category	Related papers
Combination of Machine Learning Algorithms and Heuristic	Tang et al., 2019, Gazori et al., 2020, Rahbari and Nickray, 2020, Li et al., 2018b, La et al., 2019
Combination of Evolutionary Algorithms and Heuristic	Guerrero et al., 2019, Skarlat et al., 2017, Wang and Li, 2019, Nguyen et al., 2019b, Jangiti et al., 2019, Jošilo and Dán, 2018, Li et al., 2019a
Combination of Evolutionary Algorithms and Machine Learning Algorithms	Rahbari and Nickray, 2020, Talaat et al., 2020, Li et al., 2019b
Combination of evolutionary algorithms and heuristic.
Combination of evolutionary algorithms and heuristic is one of the categories of the combinatorial algorithm that authors proposed new algorithms or new evolutionary algorithms for achieving more efficient solutions than raw evolutionary algorithms. Skarlat et al. modeled service placement problem for IoT applications based on GA. A gene position in a chromosome represents the service placement on the proposed Fog architecture resources that guarantee the placement of all services. Based on the genes of the chromosome, resource consumption, and response times estimated (Skarlat et al., 2017). Guerrero et al. proposed three evolutionary algorithms based on Fog service placement problem including weighted sum genetic algorithm, non-dominated sorting genetic algorithm II and multiobjective evolutionary algorithm based on decomposition to optimize the network latency, the service spread and the use of the resources. Minimization free resources was the first optimization objective. Efficiency distribution tasks among Fog nodes was the second objective. Also, network latency among service applications was the third objective. Proposed model constraint created a trade-off between resource consumption of Fog devices and resource capacity of Fog nodes. Non-dominated sorting genetic algorithm II outperforms the two other mentioned algorithms in optimization and diversity solution spaces aspects (Guerrero et al., 2019). Wang and Li (2019) proposed hybrid heuristic task scheduling strategy in Fog computing based on a combination of improved PSO (IPSO) and improved ACO (IACO) with the aim of minimizing the delay and energy consumption. IPSO applied to collect the optimal solution and then the optimal solution is the initial of the IACO algorithm as the optimal solution of task scheduling (Wang and Li, 2019). Nguyen et al. proposed a new algorithm namely TCaS to optimized task scheduling problems for bag-of-tasks applications with the aim of reducing makespan time and total costs (Nguyen et al., 2019b). TCaS outperformed other compared methods including bee life algorithm, modified particle swarm optimization, and the simple Round Robin algorithm in both Fog environment and Cloud–Fog system (Nguyen et al., 2019b).

Combination of evolutionary algorithms and machine learning algorithms.
Combination of evolutionary algorithms and machine learning algorithms is one of the categories of the combinatorial algorithm that authors proposed algorithms which try to fix the defects of each other (Siasi et al., 2019, Li et al., 2019b). Talaat et al. presented a load balancing and optimization strategy for dynamic resource allocation based on reinforcement learning and genetic algorithm (Talaat et al., 2020). Li et al. presented a combination of Fuzzy-c-means and particle swarm optimization for resource scheduling in Fog computing (Li et al., 2019b). The explanations of this section can be examined in more details at the bottom of Table 8.


Table 8. Summary of Machine Learning Algorithms in FAP.

Deep Reinforcement Learning Algorithms in FAP
DRL Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
Deep Q-Network	Li et al. (2020a)	Dynamic scheduling of task and load balancing
of servers	IAA DQN
Task scheduling	Average EC, LT	(1) The intelligent adaptive algorithm (IAA)
was designed based on the online learning
framework of RL, which can minimize the
long-term weighted sum cost.
(2) Since the largeness of the state space
information, the DRL method was applied.
Agent: the user device
Environment: the Mobile Fog Computing
network
Mseddi et al. (2019)	Maximizing the number of satisfied user requests
with respect to QoS
requirements	DQN
Resource Allocation	Success ratio	(1) Proposing an online resource allocation
solution, adapted to a dynamic Fog platform.
(2) The resource allocation deep RL based on
container deployment requests was proposed.
Real-World mobility data set was applied
Deep Q-Learning	Tang et al. (2019)	Reducing the cost of power consumption and
delay for container migration	DQLCM
Service placement	EC, MC, DL	(1) Presenting the deep Q-learning based container migration algorithms (DQLCM).
(2) Optimizing random action selection in
exploration and DNN training strategy in
Q-network updated to achieve fast decision
making.
(3) Real-world data driver trace was applied.
Bian et al. (2019)	Achieving ultra-low task latency and multi-resource
fairness among tasks	DRL
Online
Task scheduling	Task Slowdown	By applying dominant resource fairness
and DRL, FairTS an efficient online fair
task scheduling scheme was proposed.
Li et al. (2019c)	Self-adapting in different structures and
topologies of Fog computing for
scheduling	DFS
Task scheduling	Scheduling Time	(1) Presenting DRL model for scheduling crowdsensing tasks in Fog computing.
(2) Deep Reinforcement Fog Scheduling
(DFS) outperform the First in, First out,
reward first greedy, online scheduling,
resource management method with DRL.
Double Deep Q-Learning	Gazori et al. (2020)	Achieving an efficient policy in terms of
time and cost-saving under the resource
and deadline constraints	DDQLS
Task scheduling	EC, RT, DL, WT	At first the task scheduling problem
as MDP modeled.
Then the combination of DQL algorithm
with Double QL, target network, and
experience replay techniques were
applied (DDQLS) for task scheduling
and improving DQN performance.
Eventually four separate schedulers for
each specific group of IoT devices
proposed.
DDPG	Lan et al. (2020)	Minimizing migration cost in terms of delay
and energy consumption	DDPG
Service migration	MC, DL, EC	(1) Proposing a Fog services migration
model and framework in the context
of smart cities, namely Octofog.
(2) To make fast migration decisions,
a deep deterministic policy gradient
(DDPG) was proposed.
(3) Proposed DRL achieves fast conver
gence and better performance than the
baseline function.
Deep Neural Networks Algorithms in FAP
DNN Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
LSTM	Lee and Lee (2020)	Improving the service delay from
the end-users’ perspective	LSTM
Resource Allocation	LT	(1) Presenting a vehicular Fog computing resource
allocation algorithm based on the proposed heuristic
algorithm and from the RL algorithm
(2) Employing an LSTM-based DNN to capture
the mobility pattern of vehicles and predict vehicles’
movement and parking status.
(3) Proposed algorithm effectively offload services
to vehicular Fog nodes over the long term
DNN Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
Recurrent NN	Lee and Lee (2020)	Extracting patterns of resource availability
based on time and place	RNN
Resource Allocation	LT	Integration the RNN into the DNN of proximal
policy optimization algorithm
Classic Machine Learning Algorithms in FAP
RL Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
R-Learning	Farhat et al. (2020)	Decreasing the cloud’s load by utilizing the
maximum available Fogs resources over
different locations	R-Learning
Fog placement	RU	(1) For better utilization of Fog resources and scheduling the available clusters in locations,
the R-learning model proposed.
(2) The proposed model learn the behavior of the requests then predicting the distributions of clusters
over locations at the proper time.
(3) The proposed model was located in the cloud, where it periodically checked the behavior of the
incoming requests and updated its information using R-learning techniques.
Q-Learning	Baek et al. (2019)	(1) Minimizing the processing time and
the overall overloading probability
(2) Finding the optimal offloading decision with
unknown reward and transition functions	Q-Learning
Task offloading	LT, PcT	(1) Presenting Fog dynamic load balancing algorithm for task offloading based on RL
technique.
(2) The proposed algorithm applied Q-learning with
epsilon greedy algorithm to guarantee the optimal
action-selection.
RL	Mai et al. (2018)	(1) Minimizing long-term latency
(2) Optimizing the server selection
function	ES
Task assignment	LT	(1) Presenting a RL model for the real-time
task assignment in Fog network.
(2) For optimizing the server selection function the
evolution strategies (ES) as a learning method for
the RL model was proposed.
SARSA	Alfakih et al. (2020)	Resolving the resource management
problem in the edge server, and making
the optimal offloading decision	OD-SARSA
Task Offloading
Resource allocation	EC, computing
time DL	(1) Presenting a mobile edge computing system
model and formulated it as an optimization problem.
(2) For making the optimal offloading decision,
an offloading decision-based SARSA (OD-SARSA)
using reinforcement learning proposed.
(3) The proposed OD-SARSA outperforms
RL-QL under real-world application.
Unsupervised
Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
K-means	Sharma and Saini (2019b)	Clustering the Fog nodes based on
K-means++ clustering	K-means++
Task scheduling
Load balancing	EC, RT, DL, ScT	The Fog nodes with the least loaded
which are near to the user have
considered the first priority for
task execution.
Maiti et al. (2019)	Optimizing the number of Fog nodes for
deployment to reduce the total latency	K-means
Fog node placement	LT	(1) According to Fog selection problem, for
finding the number of Fog nodes considering
distance as a metric between Fog nodes to
gateways based on K-means clustering applied
(2) Among ten different techniques for initial
centroid selection in k-Means strategy, partition
Mean method gives the minimum delay for Fog
node selection.
Classic Machine Learning Algorithms in FAP
Unsupervised
Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
Hierarchical	Shooshtarian et al. (2019)	(1) Resource pooling, local control, and finding the nearest
Fog node to the IoT
device in order to minimize delay.
(2) Classifying Fog nodes.	Agglomerative
Hierarchical
Application placement	APT	Fog nodes belonging to a specific layer
by Agglomerative Average Linkage
Hierarchical clustering method become grouped.
Fuzzy-c-means	Li et al. (2019b)	Clustering Fog resources	FCAP
Resource scheduling	User satisfaction	Proposing fuzzy-c-means (FCM) for Fog resource
scheduling but the random selection of center points makes the iterative process easily fall into the
local optimal solution. Therefore PSO algorithm
combined with FCM to achieve global optimization.
Supervised
Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
ANN	Guevara et al. (2020)	Discriminating the applications arriving
at the Fog into Classes
of Service (CoS)	ANN
Resource management	Accuracy
Efficiency
Robustness	Utilization of ML classification algorithms include
ANN trained with the Levenberg-Marquardt
backpropagation algorithm and ANN trained with the Scaled conjugate gradient backpropagation algorithm, KNN and SVM for predicting of the CoS
to which the application belongs.
Random NN	Fröhlich and Gelenbe (2020)	Optimization of required parameters
such as QoS between service and client,
equality of clients and usage of resources	RNN, CNM
Service placement	Average RT
Average RU	With combination of decisions provided from
the Random NN (RNN) and the data from the
Cognitive Network Map (CNM) a self-aware
service placement algorithm proposed that
providing an optimal service placement.
SVM	He et al. (2017)	Classification applications	SVM
Resource management	CPT	Approximating the job completion
time based on Logistic regression
and SVM.
KNN	Manukumar and Muthuswamy (2020)	Identifying the nearest Fog nodes to offload	KNN
Resource management	EC, LT	(1) Offloading decision based on
the prediction technology and KNN
algorithms provide the best resource
management for Fog nodes.
(2) Identifying the nearest Fog node
to the user by KNN.
Regression
tree	Rahbari and Nickray (2020)	Selecting the best Fog devices	MPCA
Module placement	EC, RT	(1) Presenting a Module Placement
method by Classification and regression
tree Algorithm (MPCA).
(2) In order to speed up the module
placement, the probability of network’s
resource utilization in the module offloading
(MPMCP) algorithm proposed.
Logistic
regression	Bashir et al. (2019)	Calculating the workload of
each Fog nodes	LR
Resource prediction
and allocation	EC, RT	Logistic regression calculates the load of
individual Fog node and updates
the result to send back to the broker
for the next decision
Supervised Model	Paper	Aim	Algorithm	Performance Metrics	Highlights
Apriori	Liu et al. (2018)	Improving the Apriori algorithm for task
scheduling in Fog computing	I-Apriori
Task scheduling	Average WT
Total TET	(1) According to the I-Apriori algorithm,
a task scheduling model and a novel
task scheduling Fog computing (TSFC)
algorithm were proposed.
(2) By the I-Apriori algorithm, association
rules are generated as an important parameter
of the TSFC task scheduling.
Decision Tree	Alsaffar et al. (2016)	(1) Managing and delegating user request
(2) Optimizing big data distribution in Fog and
Cloud environment	Decision tree
Service Delegation
Resource Allocation	RT, PcT	Presenting a new algorithm that is decision
rules of linearized decision tree based on
services size, completion time and VMs capacity
conditions.
With the aim of allocating resources to meet
service level agreement and QoS also optimizing
big data distribution another algorithm was proposed.
Random Forest	Majeed et al. (2019)	Predicting the time taken to offload
a service using containers in Fog	RFR
Service Offloading	Offloading Time	Utilization of Save and Load offloading
technique with four estimation models,
namely Multivariate Linear Regression,
Polynomial Multivariate, Random forest
Regression (RFR) and Support Vector
Regression are considered.
Then two estimation methods, namely
using a collective model and individual
models with efficient accuracy were proposed.
Combination of Evolutionary (EV) and Machine Learning (ML) Algorithms in FAP
Hybrid	Paper	Aim	Algorithms	Performance Metrics	Highlights
EV + ML	Talaat et al. (2020)	Achieving a low latency	RL and GA
Resource allocation	CPT, WT, TAT
RU, LB	(1) Proposing efficient load balancing and resource
utilization in the healthcare systems.
(2) The proposed Fog layer consists of two modules:
load balancer agent (LBA), and resource allocator (RA).
The LBA is responsible for deciding which Fog server (FS) can process the incoming request.
(3) The RA module is based on the RL algorithm
to achieve a high LB for Fog.
(4) The priority of selecting a specific FS depends
on the value of adaptive weight (AW).
A genetic algorithm (GA) is used to achieve the best
value of AW.
Li et al. (2019b)	Avoiding getting stuck in local minimum	FCM and PSO
Resource scheduling	User satisfaction	Proposing fuzzy-c-means (FCM) for Fog resource
scheduling but the random selection of center points makes the iterative process easily fall
into the local optimal solution.
Therefore PSO algorithm combined with FCM to
achieve global optimization.
The proposed hybrid algorithm has a faster
convergence speed than the Fuzzy-c-means (FCM).
4. Characteristics of AI-based methods in FAP
Although AI-based algorithms have been successful in solving difficult search and optimization problems, they also have weaknesses. In this section, we review the advantages and disadvantages of the methods studied in articles based on FAP.

•
Local optimum A local optimum is the best solution to a problem within a particular neighborhood. This is in contrast to a global optimum, which is the optimal solution among all possible solutions. Stuck in local optimum is one of the weaknesses of most AI-based algorithms. To solve application placement problem, service placement, task scheduling and load balancing and task offloading, evolutionary and machine learning algorithms are listed in Table 3, Table 4, Table 8 respectively. According to the literature reviews, some ways to solve the problem of stucking in the local optimum were presented, which are explained in the following. Zahoor et al. (2018) proposed resource management and load balancing based on ACO and ABC algorithms to find which task should be assigned to which VM. ACO is used in search of new sources of food (VM) based on the best source utilization. ACO algorithm cannot change the obtained pheromone value for the VM in some iterations. So, as a result, an optimal solution is not found due to local optima. To find the best optimal solution, the ABC fitness function steps into ACO to find the global optimum solution. Rafique et al. (2019) proposed bio-inspired hybrid algorithm which is a combination of modified PSO (MPSO) and modified cat swarm optimization (MCSO) for task scheduling and resource allocation in the Fog environment. The MPSO algorithm can help to find the global best and to perform the load balancing. Hybrid MPSO and MCSO were applied to manage resources based on the fitness function. Yasmeen et al. (2018) suggested PSO-SA load balancing algorithm for resource allocation in Fog environment. In the proposed algorithm PSO is used as to find Local best position and global best position. Because of the immaturity of the algorithm, PSO searching for global best is very poor. The performance and searching of the PSO improved with SA. So, the probability of coming out of local optima increase. Li et al. (2019b) proposed a resource scheduling method for Fog computing. The combination of the fuzzy-c-means algorithm and the PSO algorithm with the aim of dividing the resources and reducing the scale of the resource search was applied. Due to the random selection of center points, the fuzzy-c-means clustering algorithm gets stuck in the local optimization. Therefore, the PSO algorithm to achieve the global optimum determined. Mai et al. (2018) suggested a real-time task assignment approach leveraging reinforcement learning with evolution strategies for long-term latency minimization in Fog Computing. The evolution strategies algorithm does not depend on the derivative of the reward function, hence, it is not stuck in the local optima as the back-propagation algorithm which is based on gradients.

•
Search speed and accuracy Search speed and accuracy are not seen in AI-based algorithms at the same time, and some algorithms have high search speed and some do not have but have high accuracy. To take advantage of both speed and accuracy, some authors combined evolutionary algorithms to take advantage of both high speed and high accuracy simultaneously. Wang and Li (2019) proposed a hybrid heuristic task scheduling algorithm for smart production line in the Fog environment include the improved PSO and improved ACO. The PSO algorithm has a fast search speed, but the accuracy is not high, and the ACO algorithm has high precision, but the search speed is low. To combine the advantages of the IPSO algorithm with the IACO algorithm, the fast convergence characteristics of the IPSO algorithm are applied to collect the optimal solution, and then the optimal solution is the initial pheromone distribution of the IACO algorithm. Therefore, the IACO algorithm is used for the optimal solution of task scheduling. Ren et al. (2021) suggested energy-aware approach for resource management with a combination of GA and ACO algorithms in the Fog environment. Due to the high computational costs of genetic algorithms, such as not achieving the optimal solution, the precision and speed of convergence can be optimized by the ACO algorithm.

•
Time-complexity Time complexity of an algorithm quantifies the amount of time taken by an algorithm to run as a function of the input given length size. Boveiri et al. (2019) proposed the Max–Min ant system to properly manipulate the priority values of tasks so that the most optimal task-order can be achieved. The proposed approach compared with five traditional heuristic algorithms based on time-complexity which includes: Highest Level First with Estimated Times, Modified Critical Path, Dynamic Level Scheduling, Earliest Time First, and Insertion Scheduling Heuristic. The time-complexity of the proposed approach was 
 that equal or better than the traditional heuristic methods. Yadav et al. (2019) combining GA and PSO algorithms to solve service placement problem in the Fog environment. PSO has fast convergence, but sometimes the final solution falls in local optima due to the dependency on the position of the local best particle. On the other hand, GA provides poor performance, and it takes more convergence time when the fitness values of the parent chromosomes are low, and the solution space is large. Crossover, mutation and fitness function of each solution calculated based on a selected random population by GA then PSO following the local best position and global best position of the particle, due to the allocation of services on VMs particles. The time complexity of GA-PSO compared with GA and PSO algorithms. GA time complexity related to crossover, mutation operations, and individual generation and PSO time complexity related to position updating, initial velocity setting, calculation of global fitness, calculation of local fitness, position calculation, and update velocity. Therefore, the time complexity of GA-PSO is polynomial. Tang et al. (2019) modeled the container migration strategy based on MDP to host mobile application tasks in containers. For reducing the large MDP spaces and achieving fast decision-making deep reinforcement learning algorithms were applied. The authors proved the DQL based container migration algorithms will converge to the optimal policy and time complexity of the proposed algorithm based on state size, reward calculation, action selection, container list update, user list update, and node list update was polynomial.

•
Convergence Convergence in iterative algorithms occurs when the output gets closer and closer to a specific value and useful results are achieved. In premature convergence, the population for an optimization problem converged too early, resulting in being suboptimal. Butt et al. (2019) improved the PSO algorithm with levy walk, because PSO has premature convergence nature. So, the velocity of particle swarm is updated with levy walk for optimizing response time and processing time for smart societies in the Fog environment. Farhat et al. (2020) proposed a Fog scheduling decision model based on reinforcement R-learning. According to the problem on hand, it does not have one end goal, but reward maximization with the right selections can be reached. Therefore there is no guaranteed convergence to the proposed model. The authors used reinforcement Q-learning based on average reward called R-Learning. The proposed model was located in the Cloud, where it periodically checks the behavior of the incoming requests and updates its information using R-learning techniques. The summary of characteristics of AI-based methods in FAP categorized in Table 9.


Table 9. Summary of Characteristics of AI-based methods in FAP.

Characteristics of AI-based methods in FAP
Characteristics	Paper	Aim	Algorithm	Highlights
Local optimum	Zahoor et al. (2018)	Resource management
and load balancing	ACO + ABC	Although ACO is used in search of new sources of food
(VM) based on best source utilization, it cannot change
the obtained pheromone value for the VM in some
iterations and stuck in the local optimum.
To find the best optimal solution, the ABC fitness function integrated into ACO to find the global
optimum solution.
Rafique et al. (2019)	Task scheduling and
resource allocation	MPSO + MCSO	Improving resource utilization with help of MPSO
Improving the search efficiency with help of MCSO
Yasmeen et al. (2018)	Resource allocation	PSO + SA	PSO can be improved by sampling the Global
best with SA after every iteration Improving the
search of PSO effected to increase the probability
of coming out of local optimum.
Li et al. (2019b)	Resource allocation	Fuzzy-c-means + PSO	Proposing fuzzy-c-means (FCM) for Fog resource
scheduling but the random selection of center points makes the iterative process easily fall into the local
optimal solution. Therefore PSO algorithm combined
with FCM to achieve global optimization.
Search speed and accuracy	Ren et al. (2021)	Resource management	ACO + GA	Precision and speed of GAs convergence can be optimized by the ACO algorithm.
Wang and Li (2019)	Task scheduling	IPSO + IACO	Based on the fast convergence characteristics of the IPSO algorithm the optimal solution collected then the
optimal solution is the initial pheromone distribution of the IACO algorithm for optimal task scheduling.
Time complexity	Boveiri et al. (2019)	Task scheduling	Max–Min ant system	The Max–Min ant system was proposed to properly manipulate the priority values of tasks so that
the most optimal task-order can be achieved.
Yadav et al. (2019)	Service placement	PSO + GA	PSO has fast convergence, but sometimes the final solution falls in local optima
GA provides poor performance, and it takes more convergence time.
The time complexity of GA-PSO compared with GA and PSO is polynomial.
Tang et al. (2019)	Service placement	Deep Q-Learning	The time complexity based on state size, reward calculation, action selection, container list update,
user list update, and node list update was polynomial
according to applied Q-learning for mobile application
tasks placement in the Fog environment.
Convergence	Butt et al. (2019)	VM allocation	IPSO + levy walk	Updating the velocity of particle swarm with levy walk, because of it’s premature convergence
Farhat et al. (2020)	Fog placement	R-Learning	Reinforcement Q-learning based on average reward was applied to guarantee the convergence of proposed
decision model.
5. Security considerations in fog application placement
Application placement requests from accessible IoT devices at the edge of the network can be easily attacked or stolen by malicious users since Fog nodes offer limited security and privacy capabilities. According to security requirements, two types of security controls including software-based (e.g., encryption) and hardware-based (e.g., trusted execution environments). Although the research on the security and privacy issues of Fog computing for IoT applications is still in its early stage, studies have been done in this field, which we will review briefly in the following. For determining the secure placement of an application, one of the most important security techniques is explainable artificial intelligence (XAI) techniques with the ability to explain the results of queries (Forti et al., 2020). XAI can help to recognize the more secure application placement, also consider the level of the security. According to the security requirements of multi-module applications, Forti et al. (2020) proposed a novel model of trust-aware multi-service application deployment namely SecFog, also they proposed a taxonomy of security in Cloud–Edge computing with five subcategories include virtualization, communications, data, physical, and other. Ni et al. (2018) studied several security challenges for IoT applications and introduce techniques to overcome these challenges with four perspective. The first perspective is related to challenges and solutions on real time services that include identity authentication, access control, lightweight protocols design, intrusion detection, resilience to sybil attackers, trust management. The second perspective is related to challenges and solutions on transient storage that involve sensitive data identification and protection, data integrity protection, secure data sharing. The third perspective is related to challenges and solutions on data dissemination that include privacy preserving data aggregation, secure data search, secure content distribution, and privacy-preserving packet forwarding. The last perspective is related to challenges and solutions on decentralized computation that involve verifiable computation, secure aidedcomputation, and secure big data analysis.

Al-Tarawneh (2021) proposed a bio-objective application placement algorithm that formulated as a bi-objective knapsack problem and solved by NSGA-II in Fog computing environment considering applications criticality levels and security requirements such as module’s security requirements, infrastructure security capabilities, and security affinity management.

Ádám Mann (2020) proposed a novel approach based on two types of security controls (software and hardware) in Fog computing environment with mixed-integer quadratic programming that can automatically determine the placement and configuration of complex applications.

Auluck et al. (2019) proposed a scheduling algorithm namely RT-SANE (Real-Time Security Aware scheduling on the Network Edge), that addresses both the privacy/security and real-time performance requirement of application jobs. RT-SANE assigns tags based on proximity to a user or Cloud data center by taking into account network delay and security (trusted, semi-trusted and untrusted). Also submitted jobs get the tag as: private, semi-private, and public. RT-SANE offers a higher success ratio than comparable algorithms, with consideration of security tags.

6. Open challenges and future directions
Although there are several research to address the issue of application deployment, there are still open challenges which are explained in the following that can be suitable for all fields including industry and manufacturing (Yin et al., 2018), health (Lin et al., 2018), and farming.

•
Time management Time is the most important challenge for both service providers and users. Reducing user response time is one of the main reasons for placing applications in the Fog. The time parameter was one of the performance metrics that the authors examined in the articles (Canali and Lancellotti, 2019, Bittencourt et al., 2017, Gazori et al., 2020, Mahmud et al., 2019, Mahmud et al., 2018, Lera et al., 2019, Tran et al., 2019). However, due to limited resources, the QoS decreases when the number of requests increases. Although the proposed algorithms have been able to solve this problem to some extent, it is still a challenge (Mahmud et al., 2018). According to application placement problem, applied techniques for optimizing time performance metrics in the category of deep learning algorithms include DQN, DQL, DDQL, DDPG, LSTM, RNN, QL, RL, SARSA, and in the category of classic machine learning algorithms include K-Means, Random Neural Network, KNN, Regression tree, Logistic regression, Apriori, Decision tree, Random forest, and Branch and bound. In the category of evolutionary algorithms include ant colony optimization, artificial bee colony, bee life algorithm, moth–flame optimization, cuckoo optimization algorithm, firefly algorithm, particle swarm optimization, genetic algorithm, memetic algorithm, differential evolution, tabu search, simulated annealing, and gravitational search algorithm. Using other machine learning algorithms and evolutionary algorithms or combinatorial algorithms that have not yet been evaluated may yield better results than the proposed algorithms in time management.

•
Mobility management Lack of mobility support mechanism in Fog computing can be seen when facing plenty of mobile users with different applications requirement. Therefore migration algorithms and architecture to support mobility tasks with various application requirements are needed. Some articles applied virtual machine migration or container migration. Migration cost is also a challenge. Most of the authors evaluated this problem by using real data in simulators, with Reinforcement learning techniques such as Q-learning and SARSA, and tabu search algorithm in evolutionary approach but it is still considered a challenge in real environments with a large number of requests (Tang et al., 2019).

•
Resource management Resource management is another challenge that the authors face due to the limited resources along with the limited response time to the user in a dynamic environment such as Fog. Resource sharing in the Fog environment is less flexible than the Cloud. Therefore, optimal resource management still needs to be addressed (Mahmud et al., 2020). Based on our literature review the neural network algorithm, the support vector machine algorithm, and the k-nearest neighbor algorithm were applied for resource management.

•
Energy consumption Due to the fact that the application modules are located in the distributed Fog nodes, if provided policies and algorithms are optimized, the idle Fog nodes can be turned off and energy consumption can be saved in conjunction with QoS and QoE. Memory consumption, CPU utilization, and bandwidth usage are an effect on energy consumption and cost (Baccarelli et al., 2017). According to FAP, evolutionary techniques that applied for energy consumption include artificial bee colony, ant colony optimization, bat algorithm, firefly algorithm, particle swarm optimization, genetic algorithm, memetic algorithm, differential evolution, tabu search, and simulated annealing algorithm. Deep learning techniques include DQN, DQL, DDQL, DDPG, SARSA, and classic machine learning algorithms include K-means, KNN, regression tree, logistic regression, and Branch and bound.

•
Security and privacy Fog infrastructure is essential to determine the security as executing the applications because of security threats such as information impairment, identity disclosure, replay, and denial of service attacks. Due to the less control of users over their information in such dynamic computing environments, three types of security including authentication, encryption and data integration are required (Shirazi et al., 2017).

•
Reliability and availability Enhancement the reliability was one of the main reason to emerge the Fog computing. The reliability of Fog computing includes challenges such as the failure of sensors, the absence of coverage from access networks in certain region or the whole network, the failure of the service platform, and the failure of the user’s interface system connection and so on (Madsen et al., 2013). Improving the availability of applications is another challenging in the complex Fog environment. According to service placement problem, one of the proposed heuristic techniques to increase the service availability and the QoS is mapping applications to Fog communities and then transitively placing the services of the applications on the Fog devices’ community (Lera et al., 2019).

•
Emerging Applications on Fog Computing Emerging applications in Fog computing includes image placement and processing in Fog computing, video stream processing, natural language processing, and robotic that explain in the following. Image placement and processing in Fog computing is one of the most popular fields of AI that is used in all fields of science and industry with the aim of distinguishing objects or people from each other and the ability to categorize and differentiate images based on image processing algorithms. The placement of image processing-based applications in Fog computing reduces response time as well as increases Qos. For example, scenarios related to medical applications that require precision in image processing as well as medical data processing speed can be helpful by placing them in Fog environments with efficient scheduling algorithms (Zeng et al., 2016). According to the literature review, deep learning algorithms can be suitable for the image processing field in Fog such as the CNN algorithm and a generative adversarial network. Video streaming refers to video transportation in the real-time. The use of efficient scheduling algorithm for video stream processing in Fog environments can be appropriate. For example, scenarios related to the processing of images received from city traffic, which should be considered the color, location, or the license plate of the car. However, to store this amount of data, Fog, and Cloud interactions must be performed (Hassan and Fareed, 2018). In Chen et al. (2020) authors proposed bitrate selection and radio resource allocation for adaptive video streaming over Fog computing-based radio resource networks based on a multi-agent hierarchy DRL. Also, in Hassan and Ghani (2019) a weighted round-robin scheduling algorithm to schedule the chunk streaming in the Fog environment was applied. Natural language processing is another area of interest in the industry. Sound recognition and processing require the storage of information in Cloud and Fog environments. It can also be important in terms of security due to sound imitation with deep learning methods. For example, scenarios for smart houses and processing and recognizing the homeowner’s voice from strangers should be done with care and speed, which efficient scheduling algorithms for placement natural language processing applications in Fog will be proposed. Deep learning techniques can be useful for this field. Robotics is one of the most usable and important topics in all fields of industry, trade, agriculture, and health. Because robots can process and make decisions with the help of machine learning methods, so storing information and processing it in situations where immediate decisions are needed, Fog environments can be appropriate. Robots also need an environment such as Fog with a quick response time to be able to share data. Each robot is considered as an object that interacts with other robots and other objects based on the IoT infrastructure. Therefore deep learning methods for placement robots tasks in Fog was determined in Tanwani et al., 2019, Gudi et al., 2017 but it needs more works in the future. According to studies and reviews of articles, in future, strategies and scheduling algorithms for application placement problem in Fog computing must be determined based on the type and category of request applications. For example application placement problem in Fog just for robotics, or just for image processing, video stream processing, and audio processing. Therefore the QoS and QoE will be improved.

7. Conclusion
Cloud computing has a great ability to deal with processing, storage, networking and management of resources, but due to a large amount of data produced by internet of thing devices and distance between data centers and users, the intermediate layer between Cloud and IoT, with the name of Fog computing is proposed. By offering Fog computing, new issues and challenges will be introduced. One of the most challenging issues is the application placement problem. According to the literature, most of the research works have a focus on improving the quality of service parameters. Based on our research, components placement algorithms consist of six main categories: AI-based, mathematical model-based, basic algorithms, blockchain-based, Fuzzy-based, and Quantum computing-based. Since we reviewed this article based on FAP with an artificial intelligence approach, AI-based algorithms include evolutionary algorithms, machine learning algorithms, and combinatorial algorithms. Most of the papers combined mathematical modeling and AI-based algorithms whereas heuristics and other algorithms almost were applied equally. In order to achieve application placement in Fog computing environments, placement policies must be satisfied. According to our literature review, most of the evolutionary algorithms applied to solve the FAP problem focused on providing efficient load balancing methods. Most of the machine learning algorithms focused on the reinforcing learning category and used deep learning models in their own heuristics. Also, combining machine learning algorithms with evolutionary algorithms to solve the FAP problem considered. As each of the proposed algorithms have advantages and disadvantages, in review articles, algorithms have been used to cover the weaknesses of each other such as stock in the local optimum, premature convergence, undesirable accuracy, and search speed in order to solve the FAP. Some challenges such as time management, mobility management, resource management, energy consumption, security and privacy, reliability and availability are mentioned as future directions. In this paper we provided a comprehensive explanation of Fog computing environments, then we formulate the FAP and provided review and summary of articles that are related to application placement problem. Also, characteristics of AI-based methods in FAP is presented.

The presented research and classifications are based on the proposed methodology and available research papers. There might be a number of papers or research which missed in this study, so we leave it to the discretion of researchers to how to use the proposed classification in their research.

