Map inference algorithm aims to construct a digital map from other data sources automatically. Due to the labour intensity of traditional map creation and the frequent road change nowadays, map inference is deemed to be a promising solution to automatic map construction and update. However, existing map inference from GPS trajectories suffers from low GPS data quality, which makes the quality of the constructed map unsatisfactory. In this paper, we study the existing map inference algorithms using GPS trajectories. Different from previous surveys, we (1) include the most recent solutions and propose a new categorisation of method; (2) study how different types of GPS errors affect the quality of inference results; (3) evaluate the existing map inference quality measures regarding their ability to identify map quality issues. To achieve these goals, we conduct a comprehensive experimental study on several representative algorithms using both real-world datasets and synthetic datasets, which are generated from our proposed synthetic trajectory generator and artificial map generator. Overall, our study provides insightful observations regarding (1) which inference method performs better in each working scenario, (2) the general data quality requirements for map inference, (3) the direction of future works for quantitative map quality measures.
SECTION 1Introduction
Nowadays, digital maps have been used as the foundation of various map services, such as navigation, vehicle tracking and location-based advertising. Previously, digital maps were constructed by labour-intensive field survey which requires long processing time and huge labour investment. Hence, most of the map data vendors (e.g., TomTom and Google) only focus on constructing and updating maps of urban areas for maximum commercial profit. The recent emergence of Volunteered Geographic Information (VGI) complements maps with the contribution from voluntary users. As a successful example, OpenStreetMap has been the largest free editable map created by VGI. However, since volunteered information may contain inaccurate input or even intended errors, dedicated editors are still necessary to manually validate the map. Moreover, as the road network changes frequently over time, neither field survey nor volunteered information can update the map timely, which motivates the research of automatic map inference (also known as map construction [1]) and map update [2].

Currently, two major resources are being used for automatic map inference: the aerial imagery [3], [4] and GPS trajectory. In general, the map inference from aerial imagery extracts the map layout from static satellite images through image processing, whereas the map inference from GPS trajectories identify the road network by clustering the users’ vehicular traces. Despite their common objective, these two types of methods rely on completely different data sources and methodologies, and they show unique characteristics, respectively. Therefore, several recent works are also proposed which integrate both data sources for better performance [5].

Considering the equal popularity of both map inference types and their significant technical differences, in this paper, we mainly focus on the study of trajectory map inference. Hitherto, several survey papers [6], [7], [8] and a book [1] have been published summarising existing trajectory map inference algorithms from different aspects. In particular, Ahmed et al. [1], [7] present a well-rounded introduction to previous map inference algorithms, together with evaluation measures, experiments and comparison. As the most representative surveys, these works help new researchers quickly dive into this area with some available codes [1]. However, as they mainly focus on delivering the idea of map inference, most of their experiments are conducted through visualisation, aiming to showcase the algorithms’ properties rather than performance. Although some surveys compare the solutions via quantitative measures, they all lack enough candidates [1], [6], [8] and proper reasoning for their measures. Overall, none of the existing work clearly illustrates the advantages of each type of solutions, and there is no research on how GPS data quality affects their performance. As plenty of new solutions [9], [10], [11], [12], [13], [14], [15], [16], [17] have emerged since the last comprehensive survey [1] and some of them [15], [17] violate the previous way of categorisation [7], in this paper, we briefly review the existing map inference methods and propose a new categorisation. More importantly, we discuss the main factors to the map inference quality and address the issues in the current quantitative evaluation system through our experimental comparison on representative algorithms. In general, our contributions over the existing surveys are as follows:

We conduct a comprehensive experimental study on the existing trajectory map inference algorithms. The chosen candidates, including both up-to-date and classical solutions, are more diverse methodologically. Moreover, by introducing datasets with different scales and characteristics and deploy the solutions under the same platform, we are able to evaluate both their effectiveness and efficiency under different input features, which has not been done by previous works. We share our code online1 for future research in this field.

We study the influence of GPS data quality issues on the performance of various inference algorithms. To this end, we propose a synthetic dataset generator to simulate different types of GPS errors. The candidate algorithms are tested on synthetic datasets to reveal the influence of noisy data to the constructed map quality, and we draw conclusions on what types of noisy trajectories should be filtered beforehand to achieve better inference quality.

We discuss the difficulty of map inference evaluation and the weaknesses of current evaluation system. To address the issues of existing quality measures, we first elaborate on the possible map quality issues of constructed maps and propose an artificial map generator, which produces maps with a certain type of errors, to evaluate the effectiveness of the current quantitative measures in identifying different map problems.

The rest of the paper is organised as follows: we introduce some fundamental concepts in Section 2. We then summarise existing inference algorithms and discuss quantitative map evaluation in Sections 3 and 4 respectively. Our experiments and observations are reported in Section 5, followed by a brief conclusion in Section 6.

SECTION 2Preliminaries
In this section, we formally define the input and output of map inference, namely GPS trajectory and map. We also introduce our synthetic trajectory generator to simulate various GPS trajectory errors.

2.1 GPS Trajectory
Nowadays, Global Positioning Systems (GPS) have been vastly integrated into various types of portable devices, including vehicles, mobile phones and other equipment. These devices keep generating a wealthy amount of trajectory data that record vehicle and pedestrian's movement. In general, a trajectory is defined as follows:

Definition 1 (Trajectory).
A trajectory Tr is a sequence of spatial points Tr:p1→p2→…→pn sampled from a continuously moving object. Each point pi consists of a 2-dimensional coordinate ⟨xi,yi⟩∈R2 and a timestamp ti. Points in Tr are chronologically ordered and every two consecutive points pipi+1¯¯¯¯¯¯¯¯¯¯¯¯¯ are connected and form a trajectory segment.

Note that, in some of the map inference solutions [16], [18], the speed (spd) and heading (heading) information are included as point attributes and utilised in the inference process.

In fact, due to the low precision of the GPS devices [19], the trajectory points are usually sampled inaccurately, which becomes the main challenge for trajectory-based applications. Overall, GPS errors mainly consist of two types:

Measurement Error. In a GPS, the location of a device is calculated by its relative distance to multiple satellites. As the number and the stability of satellite connections oscillate from time to time, the sampled trajectory point usually lands to an arbitrary place nearby the actual location, which is assumed to follow the Gaussian distribution [19] in most cases.

Sampling Error. Although an object is moving continuously, its position can only be sampled periodically by the GPS device. Hence, the frequency of GPS position sampling, which is called the sampling rate, is an influential factor to the accuracy of GPS trajectory representation. For example, considering a vehicle runs at a speed less than 50 km/h and is sampled every 30 seconds, the maximum travelled distance between two consecutive samples p1 and p2 is already 417 meters. Therefore, instead of the straight-line representation p1p2¯¯¯¯¯¯¯¯¯, the actual trajectory over the past 30 seconds is missing. Moreover, the sampling rate may vary along a trajectory due to missing samples caused by the loss of the GPS signal, which makes the trajectory quality even worse.

In addition to the GPS errors, another problem of trajectory data, which is trajectory disparity, also affects the performance of map inference process. Note that the roads on the map are travelled in different frequencies. Regarding the map inference problem, a road that is never travelled is impossible to be inferred as it does not appear in the trajectory dataset. Hence, the trajectory disparity makes the rarely travelled road harder to be inferred.

In fact, none of the aforementioned errors occurs solely in practice. Moreover, due to various GPS settings, real-world trajectory datasets usually show different levels of measurement errors, sampling errors and disparity, which makes it hard to evaluate the influence of single error type on the map inference performance, separately. Therefore, we design a synthetic trajectory generator to simulate each type of errors with multiple severity levels to measure its influence, respectively.

2.2 Synthetic Trajectory Generation
To make sure the synthetic dataset follows the same pattern of the actual vehicle movement, instead of generating trajectories randomly, our generator takes the actual road sequence that a vehicle travelled as input to generate a synthetic trajectory. To achieve this, we first conduct a map-matching [20] on a real trajectory dataset to obtain the actual travel route of each trajectory (this step can be skipped if the ground-truth map-matching result is available). Then, for each trajectory Tr and its matching result M(Tr), we perform the following process:

For each point pi∈Tr, we find its matching point M(pi) on M(Tr). M(pi) is regarded as the estimated location of the vehicle at time ti.

For each pair of matching points M(pi),M(pi+1) of two consecutive points pi,pi+1, we find Δt−1 intermediate points along the route between M(pi) and M(pi+1) (Δt=ti+1−ti) which evenly divide the route into Δt pieces. Therefore, each intermediate point represents the estimated location of the vehicle at a certain timestamp.

We collect all points of M(pi) and intermediate points to form a point sequence. The sequence is sorted chronologically and form a trajectory, called primitive trajectory.

Here, the primitive trajectory is the estimated vehicle locations at every moment during the trip. According to the above analysis, map inference algorithms could encounter following types of data quality issues: (1) Inaccurate trajectory point caused by measurement errors. (2) Low sampling rate which makes the shape of a trajectory much different from the actual vehicle movement trace. (3) Trajectory disparity which causes unpopular roads harder to be inferred. To evaluate the impact of these issues on the performance of map inference, our generator produces corresponding synthetic trajectory datasets by manipulating primitive trajectories in certain ways:

To simulate the GPS measurement errors, we follow a bivariate normal distribution with N(0,σ2) on both axes. By varying the standard deviation σ, we are able to generate trajectories with different measurement accuracy. Hence, for each point in primitive trajectory, we randomly choose a new location according to the distribution and finally form a synthetic trajectory.

For sampling errors, we re-sample the primitive trajectory by sampling periodically based on the sampling rate Δt.

As each primitive trajectory is derived from a set of roads, to achieve a certain percentage pct% of road coverage, we incrementally add primitive trajectory that passes new roads until pct% of the total map roads are travelled.

These synthetic datasets will be used in our experiments to evaluate the robustness of the inference algorithms when facing different types of errors.

2.3 Road Network
In general, in the map inference problem, as we only focus on the road layout on the map, we regard the map as a road network defined below.

Definition 2 (Road Network).
A road network (also known as road map) is a directed graph G=(V,E), in which a vertex v=(x,y)∈V represents an intersection or a road end, and an edge e=(u,v,l) is a directed road connecting vertices u and v with a polyline represented by a sequence of spatial points, termed as mini nodes, i.e.: l:u→n1→n2→…→nk→v.

The road network is a highly geographical-based graph, storing actual locations of intersections, shapes of road segments, the length of paths, etc. Apart from the general definition, in map inference, the road network generated by different algorithms may contain various features. Most of the algorithms [21], [22] and evaluation measures [23] are only able to construct/measure planar maps, which require that any two roads traversing each other must generate a vertex. The issue of planar maps is that they fail to represent bridges and tunnels where two roads overlap without connection. In addition, some of the map inference algorithms can only generate undirected maps and are unable to infer features like turning restriction and speed limit, which should be remedied by a post-processing step such as trajectory map-matching [20].

2.4 Map Inference Problem
The current automatic map inference algorithms are mainly built on top of two types of data sources: the aerial imagery and the GPS trajectory. The map inference from aerial imagery tries to identify the roads in the input aerial images using the techniques of image processing and pattern recognition. It has been an active research topic and recent trend refers to deep learning solutions, like Convolutional Neural Network (CNN) and its variations, to generate pixel-level labelling of roads [4], [24] or detecting the road skeletons [25]. The main challenge for the image-based map inference is that many of the roads are partially or completely occluded by tree canopies, the shade of the high buildings, bridges and interchanges. In contrast, the map inference from GPS trajectories does not have the continuity issue, but it faces severer data quality issues. Therefore, some recent works combine both aerial imagery and GPS trajectory data for map inference [5]. One simple but effective solution is to add trajectory points as a feature layer to the existing deep learning model for aerial imagery inference [5]. Meanwhile, due to the real-time feature, the GPS trajectories are also used for map update. However, most of the state-of-the-art map update solutions follow the same pattern [2], [26], which consists of map-matching (align trajectories to map), map inference (infer new roads from trajectories that fail to be matched) and map merge (merge new roads with the previous map). As the current map-matching algorithms [20] have achieved high accuracy, the quality of map update results heavily rely on the performance of map inference algorithm. Hence, the map inference is still the core problem.

On the other hand, the map inference on GPS trajectory has been studied for 20 years and is still a hot topic [13], [15], [27]. To the best of our knowledge, three papers [6], [7], [8] and a book [1] are published surveying the existing methods. Regarding the surveys, Biagioni et al. [6] first reviewed the map inference methods in 2012, the author classifies the existing methods into three categories, namely k-means clustering [28], [29], Kernel Density Estimation (KDE) [21], [30] and trace merging [31], [32], the paper chooses three representative solutions [21], [28], [32] from the categories and compare their inference results through both visualisation and a new quantitative measure proposed in the paper. Results show that the KDE-based methods have overall better accuracy and much lower running time, which is one of the motivations of their follow-up work on KDE method [22]. [1] and [7] combine the k-means and KDE into clustering-based method category. They add another recent work [33] to the trace merging and propose the intersection linking [34] category. They also summarise the existing quantitative measures, including the graph sampling proposed in Biagioni's survey [6], direct Hausdorff distance and path [23]/shortest-path-based [34] distances. Seven representative methods are introduced in detail and compared visually, which is by far the most comprehensive works in surveying the map inference methods. Also, as they share their implementation publicly, it enables the subsequent authors to easily compare their solution with the representatives. However, since they focus more on the visual comparison and the quantitative measures [6], [23], [34] are only conducted to three of the algorithms [22], [33], [34] on one small dataset. There is a lack of evidence to draw any conclusion on those candidates and methodologies. Instead of conducting extensive evaluations, the [8] briefly summarises the main features of existing methods and publishes plenty of datasets, with detailed specifications, for future map inference evaluation. As a great number of new methods [11], [13], [14], [15], [16], [17], [18], [27], [35], [36], [37] and new directions, like parallel processing [9], [36], online map inference [16] and certain map type [38], have been proposed after the last comprehensive survey, it is worth revisiting the existing categorisation and conducting a more comprehensive experimental study on both new and classical methods to comprehensively contrast their performance in more dimensions.

SECTION 3Inference Algorithm Survey
The recent upsurge of map inference solutions introduces new techniques to this field, which forces a review of the current categorisation. We observe that some solutions improve the existing methods by providing new alternative sub-modules [37], [39], while others belong to neither of the existing categories [17]. Therefore, we propose a new categorisation, which consists of three classes: road abstraction, intersection linking and incremental branching. The major difference between these classes is their map inference procedures. Both road abstraction and intersection linking take the entire trajectory dataset as input and construct the map in one shot, whereas the incremental branching starts from an empty map and incrementally expand the map by inserting one or multiple trajectories at a time. Meanwhile, the road abstraction aims to directly extract the map skeleton by finding representative points/edges from the trajectories, while the intersection linking first identifies the intersections and then connects them based on the knowledge from trajectories. In summary, we present most of the existing map inference algorithms in Table 1 based on our classification. In this table, we summarise the solutions and their details in terms of input trajectory feature (location only/heading/speed), trajectory sampling rate, output map type, evaluation method (V = visual, GM = Graph Item Matching, GS = Graph Sampling, PD = Path/shortest-path-based Distance; details in Section 4) and if they are evaluated or compared in other works. Note that, the input trajectory feature does not include those used in pre-processing or post-processing.

TABLE 1 Summary of Map Inference Methods
Table 1- 
Summary of Map Inference Methods
In the following, we will summarise the major differences between these categories, and introduce some representative methods which will be compared in our experiments.

3.1 Road Abstraction
The road abstraction regards the regions where more trajectories passing through to be more likely roads or intersections. Given that trajectory measurement errors are usually modelled by 2D Gaussian distribution, there is a higher probability that the trajectory sample is closer to the road centreline it travels. Therefore, the main process of road abstraction is to find the densest areas on the map and extract a road network from them. Clustering technique, which divides the input points/segments into groups and finds the representative point/segment for each group, is the major technique used in this category. Due to its simple idea, plenty of solutions have been proposed under this category with various types of clustering algorithms. Most of the work from k-means clustering [9], [14], [28], [29], [40] and KDE-based clustering [6], [21], [22], [42] mentioned by previous surveys fall into this category, together with some new solutions [15], [36], [39]. The existing road abstraction methods can be further classified based on their input data types (trajectory point/segment) and clustering methods (k-means/KDE/mean-shift/etc.). In general, the road abstraction method mainly contains the following three steps:

Data Preparation. An input trajectory can be regarded as either a set of points or a set of trajectory segments. For point clustering, besides the point coordinates, the heading of the point is also utilised in most clustering algorithms [14], [16], [36], [39] to distinguish roads with adverse directions and the intersections. For segment clustering, one of the major concerns is that the trajectory segment cannot correctly depict the object's movement trace when the sampling rate is low, which gets even worse when the object makes a turn around intersections. Hence, some line-based methods [43] remove the segments around intersections by their heading changes while others, especially the KDE-based methods [6], [21], [42], filter out such errors when generating the skeleton map.

Clustering. The purpose of the clustering is to find the representative points/segments from the input points/segments so that the final map can be obtained by linking them. K-means is the most widely used algorithm for point-based clustering [9], [14], [28], [29] due to its simplicity and effectiveness. Starting from a set of random seeds on the map, the algorithm iteratively adds GPS points to “closest” clusters, relocates cluster centres, and remove distant points until no more adding or removing happens. In fact, the performance of the k-means clustering is sensitive to the number of initial seeds and their locations, so [14] first identify the straight lines in the map by clustering the trajectory points using DBSCAN algorithm and continuously sample points as seeds alongside the straight lines, which ensures the k-means clusters to be close to the road centreline. Mean-shift clustering works in a similar fashion as k-means but is claimed to be less vulnerable to low sampling trajectories [36], [39]. Most of the line-based clustering utilises the idea of image processing. It first rasterises the map region into a grid whose grid cells correspond to pixels in an image. The trajectory segments are then drawn on the map and each cell receives a count of trajectories passing it. As the trajectory segments may distort around intersections due to low sampling rate, a smoothing process, Kernel Density Estimator [11], [21], [22], [37], [42], is usually applied to reduce the significance of noisy cells and emphasise the road centreline. Finally, the dense area on the map is regarded as roads and intersections. The simplest way of extracting the road areas is to binarise each cell using a global threshold [21]. However, it does not work well as the trajectories are not evenly distributed on the map. Hence, other works improve the thresholding by providing multiple thresholds for different road popularities [22] and road widths [42]. Alternatively, the discrete Morse theory is introduced for better centreline extraction [11], [37] especially for less popular roads. Note that although the KDE-based methods are proved to be effective [13], [14], [15], [40], their output map does not have direction and other map features apart from the road skeleton since only the trajectory locations are preserved after converting the map region into an image.

Road Generation. After the representative points/segments are found, the final step is to connect them and form the output map. For point-based clusters, one simple solution utilises the trajectory continuity and connects clusters with consecutive GPS points from one trajectory [28]. Li et al. [13] further improve this idea by calculating a representative point sequence from trajectories that connect the same sets of clusters as a road. Other works directly create roads without the help of trajectory information. The principal curve method, which creates a representative curve from a set of points, is perfect for this scenario [30], [36]. Qiu et al. [14] assumes that most of the real-world roads are near straight, so it connects the nearby clusters with a similar direction and extends the road until the direction changes. For line-based clustering, the density-based image obtained from KDE methods can be further thinned to extract road centrelines using the techniques like spline fitting [21] and skeletonisation [22]. After the map skeleton is obtained, a scan of the image is needed to identify intersections based on the value of nearby pixels and edges to be obtained subsequently.

Overall, the road abstraction algorithms regard trajectory as a set of points or segments. One advantage is its ability for parallel processing [9] as most of the operations are localised. However, one major problem is the potential connectivity issue. As exemplified in Fig. 1, two parallel roads can be incorrectly connected if the trajectories are broken down into points/segments. Although some effort has been devoted to rectifying such errors using the knowledge from typical intersection design [39] or additional map-matching in post-processing [22], it is still challenging for such methods to infer non-planar features in the map.

Fig. 1. - 
Example of a wrong connection.
Fig. 1.
Example of a wrong connection.

Show All

Three representative methods are selected under this category for our experimental study:

3.1.1 Stanojevic and Abbar 2018 (RA-K-MEANS)
The RA-K-MEANS [16] is the most recent k-means solution with a bunch of optimisations. It regards map inference as a multiple network alignment problem (MNAP), which aims to infer the underlying graph given a set of observable sub-graphs (GPS trajectories). For the k-means clustering, the pair-wise point distance considers both geographical distance and heading difference, and each initial seed is selected along the trajectories with no less than a certain distance away from existing seeds. Moreover, to further reduce the inference of spurious roads, a graph spanner is applied during the road generation to remove roads that are potentially generated by noisy or low-sampling-rate trajectories. Besides, it also provides an online model for stream-based map inference and map update.

3.1.2 Biagioni and Eriksson 2012 (RA-KDE)
The RA-KDE [22] is a typical KDE-based method with a focus to tackle trajectory disparity problem. Instead of setting a global threshold when binarizing the grid density, it proposes a grey-scale multilayer solution so that grids with different densities fall into different density layers. By doing so, roads with fewer visits can be preserved in low-density layers. After smoothing the map by kernel density estimator, the algorithm generates centrelines from each layer using skeletonisation method, and merge them to form a final map. The algorithm also further post-processes the map to merge unnecessary intersections, remove unmatched roads, simplify road shapes and assign road directions. Currently, the RA-KDE [22] is regarded as the representative method in this category. As shown in Table 1, it has been compared the most times with various methods in different categories and performs well in both effectiveness and efficiency.

3.1.3 Zheng and Liu 2017 (RA-TOPIC)
Although being rasterised into grids, the RA-TOPIC [15] does not leverage the KDE method for smoothing and road generation. Instead, it converts map inference into a topic extraction problem in Natural Language Processing (NLP), where a document (trajectory) is built up by a set of words (grid cell) and each word is related to some topics (road segment). It then utilises LDA and pLDA to extract topics (road segments) from documents (trajectories). As a new method inspired by a different research area, we also include this algorithm in our experimental study.

3.2 Incremental Branching
The idea of incremental branching is to incrementally insert new roads to an empty map until all trajectories are examined. Overall, a map can be constructed in two incremental ways:

Trace Merging. The trace merging method incrementally inserts trajectories into the map. For a new trajectory, the algorithm first tries to merge it to existing roads by map-matching or distance measure calculation, such as simple pairwise distance [32], [44] or Fréchet distance [27], [33], [35]. Successfully matched trajectory segments are utilised to adjust road shape by introducing physical attractions [32]. Meanwhile, the unmatched portion either forms a new road from the existing map (partially matched) or creates a completely new road (completely isolated). As one of the early works in this field, Cao et al. [32] merges new trajectories by only considering their segment-based distance and direction difference. Once the merge process is completed, the algorithm defines the physical attraction force between pair-wise points so that the matched roads run towards the newly merged trajectory whereas the unmatched roads run against it. Considering that roads have different lengths in the real world, Buchin et al. [27] proposes a method that predefines multiple road lengths and generate roads with different scales accordingly. This helps to infer small roads that are dominated by nearby main roads.

Map Expanding. The map expanding is a new type of methods initiated by He et al. [17]. Instead of iterating on the trajectories, it starts from a map node. The major process of map expanding is to incrementally infer new roads from the starting node based on the trajectories passing through it. After the current node is visited, the map has branched out and generated multiple new starting nodes, which are the starting points of new iterations. Different from other incremental solutions, since all the trajectories passing the same node are processed once, it is much easier to infer the outgoing directions correctly. Therefore, it performs better when inferring complex map elements, such as complex intersections, non-planar tunnels and interchanges.

Overall, different from road abstraction which treats each trajectory point/segment separately, the incremental branching methods fully utilise the continuity of an entire trajectory so that neighbouring roads that lead to different destinations can be better separated. However, it is hard for such incremental methods to run in parallel. In addition, the scalability of these iterative methods, especially the trace merging, can be really poor as the size of the input dataset increases. In our experimental study, we choose the following two methods as the representative of this category.

3.2.1 Ahmed and Wenk 2012 (IB-TM)
The IB-TM [33] is the only trace merging solution whose performance has been quantitatively evaluated [1]. The algorithm utilises the Fréchet distance to merge a new trajectory with existing roads. It can efficiently extract matched trajectory parts via a maximum distance threshold ϵ, and generate new representative roads using minimum-link paths algorithm. Unmatched portions are inserted into the map as new roads and connected to the matched road to form a new branch and intersection. This method has a theoretical quality guarantee that the inferred roads are well-separated.

3.2.2 He and Bastani 2018 (IB-ME)
The IB-ME [17] is the only candidate for map expanding solutions, and it mainly focuses on high inference precision and non-planar map features. The algorithm first infers partial map correctly and then merges the constructed map portion to another map inferred by other high recall methods [6], [16]. As introduced above, the method starts from an initial map node and grows until covering the entire map region. It can also infer complex regions as it fully utilises the long-term travel information from the trajectories.

3.3 Intersection Linking
The intersection linking approaches emphasise the correct detection of intersections. Once the intersections are inferred, the remaining step is to link intersections using the information from trajectories. Different from the points on roads, trajectories passing intersections usually have different heading or speed, and more importantly, their heading or speed may change significantly during a short period. Therefore, the intersections can be identified based on either trajectory movement characteristics (speed, direction) [18], [34], [41] or point density [46]. The main steps include:

Scan the input trajectory points and extract the point sequences around intersections, which satisfy the heading and speed requirements (for example, heading changes more than 15∘ and average speed under 40km/h [34]).

Cluster the intersection points based on their proximity using k-means [10]/random sampling [41] or based on turn similarity [34], [45] to extract the intersection region.

Link intersections connected directly by trajectories. In addition, since each intersection covers a region instead of a point, the actual type of the intersection (crossing, T-junction, roundabout, etc.) is also considered when connecting the edges inside the intersection region.

As the intersections are usually very complex in real life, a correct inference of intersection, especially its turning pattern, can significantly improve the usefulness of the constructed map. Moreover, this can be conducted concurrently, and the machine learning technique, which has been used in road abstraction methods [30], [39], is also applicable. We consider the following algorithm in our experiments.

3.3.1 Karagiorgou and Pfoser 2017 (IL-TURN)
The IL-TURN [34] is a typical intersection linking approach. Intuitively, a vehicle is making a turn at an intersection when its trajectory sees a significant direction change at a low speed. Hence, this method first calculates the direction change for each trajectory point and finds all points likely to be near an intersection (significant direction change and low speed). The turning points are then clustered according to their proximity and a given maximum intersection radius. One intersection is generated from one cluster, and the intersections are finally linked based on the trajectories connecting them. To avoid large intersections, the algorithm is further improved [18] by sorting turning points according to proximity and adaptively deciding the intersection size. Moreover, in the preprocessing step, it categorises the input trajectories according to their speed to infer three maps for different speed level, ranging from highways to low-level lanes, which are conflated to form a final map.

SECTION 4Quantitative Measure Evaluation
As the performance of map inference algorithms is evaluated by the quality of its constructed map, measuring the map quality is crucial especially when comparing the performance of multiple inference methods. Note that most map inference datasets come with a ground-truth map (usually obtained from public map providers like Google Map and OpenStreetMap) for validation, so the core of the evaluation is to quantify the similarity between the constructed map and the ground-truth. Previously, most of the map inference algorithms demonstrate their performance by visually overlaying their maps with the ground-truth. Despite its simplicity, intuition and usefulness in troubleshooting, visual comparison cannot quantify the map difference, as illustrated in Fig. 2, making it hard to compare the performance of different algorithms. Moreover, many road features, such as road direction, turning restriction and road connectivity, are not displayable. Therefore, there is a strong need for quantitative measures in the map inference field.

Fig. 2. - 
Visually compare two constructed maps, no clear winner.
Fig. 2.
Visually compare two constructed maps, no clear winner.

Show All

However, the design of the quantitative measure is challenging. Intuitively, since the ground-truth map is usually obtainable, the quality of a constructed map should be measured based on its differences to the ground-truth. It is obvious that a map with better quality should be more similar to the ground-truth. However, the definition of similarity is ambiguous. Note that a map is usually represented as a graph, this problem is related to the graph matching problem [47] in graph theory, which is associated with some difficult problems, like subgraph isomorphism (NP-complete), graph edit distance (NP-hard) and network alignment. Moreover, Cheong et al. [48] proved that the problem is still NP-hard even with the geometric information embedded. Therefore, all the existing map quality measures evaluate the map similarity heuristically based on various intuitions, such as the vertex/edge closeness [6] and the navigation correctness [23], [34]. However, since each measure only focuses on one or few map features, there is a lack of discussion that treats the map quality as a compounded problem which is determined by multiple factors. In this section, we will first elaborate on the current map quality issues, introduce the state-of-the-art measures, and then propose our design to experimentally evaluate the existing measures.

4.1 Map Quality Issues
Note that in this section, the map quality issues we refer to are not the general issues in real-world map, instead, we focus on the map errors that (1) can possibly be produced by inference algorithms and (2) may cause quality issues when the map is used in applications such as navigation and location-based services. Hence, we categorise map quality issues as follows:

Topological Error. Topological correctness is crucial for navigation systems. However, it happens quite often that two roads connected in the ground-truth map happen to be disconnected in the constructed map, or vice versa, as exemplified in Fig. 1. Moreover, most inference methods [21], [22]/map quality measures [23] are only able to generate/evaluate planar map, which does not match the real-world scenario where transverse roads do not necessarily generate intersections, such as underpass tunnels and interchanges.

Geographical Error. Since the input trajectories suffer from GPS errors, it is common that the inferred road nodes/edges deviate from their actual locations. These errors can affect the correctness of both navigation applications and location-based queries. Besides, the severity of a geographical error is not only determined by its absolute deviation, but also relative distance which considers the map density of the surrounding area.

Road Loss and Spurious Road. Due to the trajectory disparity [22], many of the roads in ground-truth map are not travelled by any vehicle. Hence, there is no chance for them to be constructed. Also, since the input trajectories contain outliers, many inference algorithms remove the roads constructed from fewer trajectories to avoid generating spurious roads. Therefore, the constructed map usually contains only a subset of roads in the ground-truth map, while the road coverage is an important indicator of algorithm effectiveness. Meanwhile, even with the noise reduction, it is still common to have spurious roads constructed in the map especially around the intersections. Those roads are usually caused by incorrect linking between intersections or inexistent shortcuts. Both road loss and spurious road insertion can affect the navigation and location-based services significantly.

Other Errors. These errors may not affect the quality of map navigation and location-based services considerably, but it can still cause confusion and misunderstanding to the map users. For example, many inference algorithms generate roads and intersections with odd shapes, like the zigzag road pattern occurred frequently in KDE-based method [21] or wrong intersection layout. Besides, it is challenging to infer/measure parallel roads as their distance is usually similar to the GPS error radius. Overall, these errors should also be measured.

4.2 Quantitative Measures
Several quantitative measures have been proposed recently for map comparison, which falls into three categories according to their methodologies: graph item matching, graph sampling and path-based distance.

4.2.1 Graph Item Matching (GM)
In this category, the constructed map G is regarded as a set of nodes V and a set of edges E, and the ground-truth map is G∗=(V∗,E∗). Hence, the quantitative measure can be converted to a set similarity problem and answered using the well-known measures of precision/recall/F-score as long as the match of node (match(v,v∗)) and edge (match(e,e∗)) is properly defined. In fact, match(v,v∗) and match(e,e∗) are defined differently in various papers. We present a basic definition [18] as follows: For match(v,v∗), two points are matched only when their distance is less than a threshold ϵ. Meanwhile, the match(e,e∗) defines that two edges are matched only when both endpoints are matched, respectively. Based on these definitions, the precision/recall/F-score can be evaluated separately for nodes and edges [18] or combined.

Despite its simplicity, the GM also faces several issues: (1) Nodes are not one-to-one matched, which means multiple nodes can be mapped to the same ground-truth node. It can potentially lead to some undetectable connectivity issues. (2) The value of threshold ϵ used for defining node matching may significantly affect the evaluation results. (3) Since the edges are defined by polylines, it is possible that two edges with extremely different shapes may share the same endpoints, which is undetectable in this metric. Although some distance metrics, like Fréchet distance [33] and Hausdorff distance [43], were introduced to further restrict the edge matching to solve the issue (3), it is still hard to measure both the topological and geographical features of the map simultaneously.

4.2.2 Graph Sampling (GS)
This method was first proposed in [6] and adopted in [1], [7], [15], [16], [17], [40]. The main idea is to randomly extract a set of subgraphs from both the constructed and ground-truth maps and compare their similarity. The whole process consists of four steps: (1) Randomly select a set of points on the constructed map as seeds and find the corresponding seed points on the ground-truth map, each of which is the closest point on road to a seed location. (2) Traverse the constructed map starting from each seed point and generate a new point, named as marble, each time a certain distance is passed. Stop the traversal until a given maximum distance is reached. (3) Do the same process for seed points in the ground-truth map, and the generated points are named as holes. (4) Match the marbles with holes to generate the matching ratio. The graph sampling method is able to detect topological errors, especially its variation (TOPO method [16]), as the disconnect edges are not traversed when generating the marbles/holes. Meanwhile, it is also good at evaluating geographical precision through the matching ratio. However, as pointed by Hashemi [8], the performance relies on the number of samples and the traverse distance. It may overestimate the connectivity and incur a huge computational cost if the extracted subgraphs overlap a lot.

4.2.3 Path-Based Distance (PD)
This category [17], [23], [34] assesses the map correctness by its performance of navigation. In the path-based evaluation, the algorithm first picks up a set of source and destination location pairs, which are randomly selected on map [34] or from existing trajectories [17], and projects them on the closest road on both constructed and ground-truth maps. For each pair, the shortest paths on both maps are then obtained and their pair-wise distance is calculated using Discrete Fréchet distance [17], [18], [34] or average vertical distance [18], which measures the largest distance between two polylines. Overall, the map which has less gross pair-wise distance is deemed to be more similar to the ground-truth. This type of methods mainly targets at the topology correctness of the map. The map with high correctness in path-based evaluation can better serve the navigation purpose. However, since the pair-wise distance is usually dominated by the most significant difference along the path, it has weak power to detect the geographical error, spurious roads and other errors. Moreover, since it requires a large number of sampled pairs to evaluate the road coverage, it can be very expensive computationally considering the complexity of the shortest path calculation.

4.3 Measure Evaluation Design
Overall, we think the current study on the quantitative measure is still insufficient: (1) Given that the existing measures are designed for different purposes, no research has been done studying what types of map quality issues each measure can actually identify. The measures are always used by previous works blindly. (2) Some of the map errors, like the road shape error and wrong intersection layout, are not mentioned by previous works. Hence, they may not be detected by any of the existing measures. (3) Evaluation results from some measures, like the path-based evaluation, are not quite informative as the significance of the distance value does not justify the quality of the map without proper reasoning. In this subsection, we will introduce our design of experimental evaluation on existing measures to test their ability in identifying different types of map errors while finding the potential in developing new quantitative measures. Our design mainly relies on a synthetic data tool: the artificial map generator.

The idea of the map generator is to generate a set of maps, each of which contains only one specific type of errors mentioned above that may occur in a constructed map. Note that the map constructed by map inference algorithms usually contains multiple types of map errors, these synthetic maps can help evaluate how the quantitative measures react to a certain type of errors. Given a ground-truth map G∗=(V∗,E∗) and a set of trajectories running on it, the map generator produces an artificial map for each error by modifying the ground-truth map respectively as follows:

4.3.1 Topological Error (TE)
The topological error implies the case that an edge exists at the right location without connecting to the right node. To simulate such error, we randomly select a pct% of roads Ete=e1,e2,…,en from E∗ to be the candidates. For each candidate ei∈Ete, we disconnect one of its endpoints, va for example, and find a new endpoint va′ on ei whose distance to va is
dist(va′,va)=min(ϵ,μei.length),(1)
View SourceRight-click on figure for MathML and additional features.

where ϵ refers to the GPS measurement error threshold, which is used in various map inference and quantitative measures. μ∈(0,1) is a weight that ensures the distance not to be too long compared with the original road length. Then, we set va′ as the new endpoint, add va′ to V∗, remove the adjacency information in va and eventually remove va from V∗ if it is no longer an intersection. By doing so, the map is barely changed geographically, while the roads are disconnected topologically.

4.3.2 Geographical Error (GE)
We generate such error by introducing randomness to the intersections. Here, we first set an error radius r and select a pct% percent of vertices from V∗ as Vge. For each vertex vi∈Vge, we randomly choose a location within error radius as its new position. Then for each edge in E∗ whose endpoint has been drifted, we offset its mini nodes proportionate to the drifted amount to maximally preserve the road shape. Without changing the road connectivity, it is clear that the modified map Gge is topologically isomorphic to G∗.

4.3.3 Road Loss (RL) and Spurious Road (SR)
The introduction of the spurious road (SR) requires the use of trajectories. Following the idea that most of the spurious roads are inferred from some noisy trajectories, we aim to find the noisy trajectories by performing the following two steps: (1) We perform a map-matching algorithm [20] on the trajectory dataset and select the trajectories whose matching result contains breakpoints. (2) For each consecutive breakpoint sequence, we extract the matching roads of its preceding and succeeding points and create a spurious road to connect them directly. We then randomly select a set of spurious roads and insert them to the ground-truth map. The rate of outliers is controlled by the total length of the spurious road inserted. Regarding the road loss (RL) error, we remove a pct% of the roads according to their total length over the total map length.

4.3.4 Other Errors
We simulate the zigzag road shape error (RSE) by interpolating mini nodes to the roads. For each road in ground-truth map, we interpolate a new point p′ for every θ meters along the road. In fact, the actual interpolated mini point p is not at p′. Instead, it is chosen randomly with two constraints: (1) pp′¯¯¯¯¯¯ is perpendicular to the road direction at p′; (2) pp′¯¯¯¯¯¯.length=θ where θ is a distance threshold that is very small to avoid introducing too many geographical errors. Therefore, the severity of the road shape problem is determined by the distance θ, since more interpolated mini points lead to more serrated road shape. For the intersection layout error (ILE), we create the spurious intersections by splitting the existing intersections. Specifically, we select a pct% of vertices Vil from V∗ whose degree is no less than four. For each vi∈Vil, we split it into two points vi1 and vi2 which are symmetric, centred at vi, and satisfy that dist(vi1,vi)=dist(vi2,vi)≤θ. Lastly, the previously connected edges are redirected to the vertex that is closer and vi1 and vi2 are connected to each other eventually.

In Fig. 3, we visualise different types of map errors generated by our artificial map generator. Besides, all the pct% used in aforementioned road-related cases (TE, RL) requires a random selection, which can be achieved in two modes: complete random (CR) and weighted random (WR). Different from the complete randomness, the weighted random assigns a weight to each edge/vertex so that higher weight items are more likely to be selected. Here, the weight for each edge/vertex is calculated by the following steps: (1) We perform map-matching on the trajectory dataset to the ground-truth map, and each trajectory is converted to a sequence of road edges. (2) For each road edge, we count the total number of appearance in the map-matching results as its weight. (3) The weight of each vertex is the sum of all the weights of its adjacent edges. Therefore, the weighted random considers the popularity of road. Such randomness can help test if the measures are sensitive to road importance.

Fig. 3. - 
Various map errors generated by synthetic map generator.
Fig. 3.
Various map errors generated by synthetic map generator.

Show All

SECTION 5Experiments
Our experimental study consists of two main components: (1) Evaluate the ability of the current quantitative measures in identifying various types of map errors; (2) Conduct comprehensive experiments on the representative map inference algorithms and compare their performance under both synthetic and real GPS data.

5.1 Experimental Settings
5.1.1 Datasets
There are a few public datasets available, like the Chicago [6], [7], [11], [14], [15], [16], [18] and Berlin [11], [37] which are widely adopted in existing map inference algorithms. However, they both suffer from severe trajectory disparity issue, as shown in Table 2. They are viable for visualisation but are not suitable in our quantitative experiments. Therefore, the experiments are conducted on the Beijing dataset, which is a commercial dataset collected by our industry collaborator. It contains trajectories by 5,000 taxis in Beijing for 5 days. From the original map Beijing-L, we further extract two sub-areas, namely Beijing-S and Beijing-M, which represent two urban areas with different scales. Table 2 compares these datasets and shows their specifications. In addition to basic information, we also provide three additional statistics for each dataset: (1) map density: the average length of roads (km) in a unit of map area (km2), (2) trajectory density: the average number of trajectory points in a unit of map area (km2), (3) trajectory disparity: the percentage of roads that are never or rarely (≤5 times) visited by trajectories. Overall, compared with Chicago and Berlin, the Beijing datasets contain multiple advantages: (1) The variety of map scale and map/trajectory density enables the test of algorithm's efficiency and scalability. (2) Most of the roads (>63%) in the urban area (Beijing-S and Beijing-M) are travelled by at least one trajectory, which is much higher than Chicago (3.2 percent) and Berlin (21.4 percent). It means that the generated map will have significant less road loss problem. (3) It provides heading and speed information for each trajectory point, which is required by some of our candidate algorithms.

TABLE 2 Comparison of Public and Private Datasets
Table 2- 
Comparison of Public and Private Datasets
5.1.2 Environment
We perform our experiment on a single server, which consists of two Intel(R) Xeon(R) CPU E5-2,630 with 10 cores/20 threads at 2.2 GHz each, 378 GB memory and Ubuntu 16.04. The server has large enough memory to ensure the algorithms can be fully processed in memory. Algorithms run on three languages, namely Python-2.7 (RA-K-MEANS, RA-KDE, RA-TOPIC and IB-ME), Java-1.11 (IB-TM and IL-TURN) and Go-1.12.5 (IB-ME)) due to their reliant on different libraries.

5.2 Evaluation of Measures
Before comparing the map inference algorithms, we first evaluate the existing quantitative measures in identifying map errors discussed in Section 4. Our candidate measures includes graph item matching [34] (GM), graph sampling [6] (GS) and path-based distance [23] (PD). We test them on six types of generated maps (GE, TE, RL, SR, RSE, ILE) with two of them using both complete-random and weighted-random sampling strategies (TE-CR, TE-WR, RL-CR, RL-WR). Tables 3 and 4 show the evaluation results under different error types. Due to the space limit, we only list the F-score for vertex graph item matching (GMV), edge graph item matching (GME) and graph sampling, and we calculate the average Fréchet distance for path-based distance. In general, it is clear that each measure has its weakness in identifying certain types of errors. For instance, it is expected that the vertex-based graph matching is not able to identify the topological error, road loss, spurious roads and road shape errors as the intersections remain unchanged in those maps. However, it is also less sensitive to the cases where the intersections shift slightly (GE), or are duplicated (ILE) since most of those noise does not escape the radius of vertex match and duplicate intersections can be matched to the same ground-truth without penalty. On the other hand, the edge-based graph matching and graph sampling are capable of detecting the topological changes. In particular, both measures decrease considerably when more topological errors (TE) or road removal takes place. Interestingly, the decline becomes less significant when the errors are introduced based on road popularity. The reason is that in the weighted random, we tend to remove less number of roads but with higher importance. However, both GME and GS scores only reflect the reduced number of removals, in other words, these measures do not take into account the importance of different roads.

TABLE 3 Measure Results Under Different Topological Error (TE) and Road Loss (RL) Ratio
Table 3- 
Measure Results Under Different Topological Error (TE) and Road Loss (RL) Ratio
TABLE 4 Measure Results Under Other Error Types
Table 4- 
Measure Results Under Other Error Types
Overall, the path-based measure is underwhelming in most scenarios, except SR and GE, due to multiple reasons: (1) Different from a percentage, an absolute value of distance sometimes cannot measure the difference between two maps, especially when comparing the results between maps with different scale and road density. (2) Since the measure tries to find the matching ground-truth to each path in a constructed map, it can hardly detect the road coverage and connectivity problems, like RL and TE. Instead, it can better detect spurious roads rather than other measures as those roads are usually hard to be matched to ground-truth. (3) As it compares each generated link to all possible links on the map to find the one with minimum Fréchet/Hausdorff distance, the complexity is at the level of O(V3) [23]. Due to the high complexity of Fréchet distance calculation and candidate generation, the measure runs extremely slow even with medium map size.

In general, the graph sampling and edge-based graph item matching have better overall performance on most error types. Compared with graph item matching, the graph sampling is slightly more sensitive to the noise and is very sensitive to low road coverage. However, none of these measures takes into consideration road importance. As an incorrect inference of an arterial road can lead to more serious problems than a missing rural road, the lack of sensitivity to road importance can be a critical problem to map quality evaluation. Moreover, they find a hard time identifying intersection layout errors and are unable to detect road shape changes. Since both errors happen quite often in various inference algorithms [6], [21], it is clear that the current measurement system still requires more attention and further development.

5.3 Evaluation of Inference Algorithms
We evaluate our candidate inference algorithms on Beijing dataset using the above quantitative measures. Note that the parameters used in the algorithms are mostly set to default value unless it is related to the expected GPS measurement error range. As all the algorithms assumes the input is always inaccurate, they always set a threshold for tolerable error radius which is usually between 0 50 meter. In this case, we set it as 20 meter according to our dataset. We conduct the experiments from three perspectives: robustness, scalability and overall performance comparison.

5.3.1 Robustness
The goal of robustness test is to reveal which algorithm is good at handling certain data errors and how they react to those errors in general. Therefore, we generate synthetic trajectory datasets through our generator on Beijing-S map which only contains measurement error, sampling error and trajectory disparity issue, respectively. Note that we do not evaluate RA-K-MEANS and IL-TURN as they requires speed and heading as input, which is not available in synthetic dataset. Fig. 4a shows the inference quality of the candidate algorithms under different GPS measurement accuracy. It is shown that the increase of measurement error does not affect the overall performance significantly until the error exceeds the preset error radius (20 m). The reason is that when a GPS sample exceeds the tolerable error range, it is likely to be treated as a new road element, so its precision drops quickly as the graph sampling measure is sensitive to spurious roads. However, in another experiment we've done, we set the error radius to a higher value (50 m) and found that the overall F-score of most algorithms dropped by a visible amount due to a significant decrease in recall. The combined results show that a proper preset error radius that matches the input is crucial. A strict preset value on a low-quality input can cause low inference accuracy, while a loose preset range guarantees an incomplete map, even with high-quality input. Nowadays, as the accuracy of GPS positioning devices keeps improving, the performance of map inference algorithm can also benefit from it in the future. On the other hand, we also varies the sampling rate while removing the measurement errors entirely. It is clear that the map quality gradually decreases when the sampling rate drops. This happens more seriously to line-based methods, namely RA-KDE and RA-TOPIC, as the lines can no longer represent the road shape when the sampling rate is very low. In terms of the trajectory disparity, we test the algorithms by providing various percentages of the road coverage which contains neither measurement nor sampling error, shown in Fig. 4b. Note that although the road coverage reaches up to 60 percent in our experiment, most of the roads are travelled by only several times since the input trajectory set is chosen by maximising the road coverage while minimising the input size. As shown in the figure, although we can clearly see the improvement of map recall, only less than half of the roads can be inferred, which means that finding the rarely travelled roads is still a challenging task. Many of them are either removed as noise or merged with neighbouring roads. Among all the candidates, the trace merging method has the best detection rate. Since it processes every trajectory individually, it is more likely to find new road segments as long as the trajectory is partially different from the existing roads.

Fig. 4. - 
Summary of experimental results of map inference algorithms.
Fig. 4.
Summary of experimental results of map inference algorithms.

Show All

5.3.2 Scalability
The main objective of the scalability test is to answer three questions: (1) How the quality of the constructed map improves as the size of the input trajectory increases. (2) How the efficiency of algorithms scales with the size of trajectory dataset. (3) How is the map size affects the efficiency of algorithms. Fig. 4c, 4d and 4e answer these questions, respectively. In Fig. 4c, we use graph sampling F-score to evaluate the map quality. Interestingly, not all algorithms’ performance benefits from the increase of the trajectory dataset, in particular, the KDE, k-means and intersection linking methods. It is because although the increase of trajectory size can slightly improve the road coverage, however, due to the poor denoise mechanism, more spurious roads are also introduced, which affect the precision significantly. For example, in KDE method, the increase of input size can lead to more ambiguous road intersections, which can potentially create more incorrect branches after the skeletonisation process. Therefore, increasing input dataset is not always a good idea unless the quality of input is ensured by data preprocessing or a more robust algorithm is chosen. The quality of intersection linking suffers from low input size, especially when the trajectory sampling rate is low where the intersections are hard to be detected. Besides, although there are two algorithms that have very poor F-score, namely RA-TOPIC and IB-ME, their actual performance is not as bad as indicated. The main reason for their poor performance is low recall. Plus, the result from graph sampling measures usually further decrease the score for lower recall solution since most of the seed points from ground-truth cannot find their correspondents on the inferred map. In fact, these two methods can achieve the best accuracy among all solutions, making them the perfect choices for larger input dataset thanks to strict noise control. In terms of efficiency, Fig. 4d shows the scalability of those methods with fixed map size and increasing trajectory input. To our surprise, the trace merging algorithm has the second-best scalability among all candidates, which shows that the cost of the Fréchet distance calculation between every new trajectory and the map has been fully optimised. On the other hand, the topic model method has the worst scalability since the topic extraction algorithms (LDA and pLDA) are all computational-extensive operations which heavily rely on iterations. In contrary, the k-means-based method is very efficient and also scales perfectly. The same applies to Fig. 4e where the map size increases to Beijing-M and Beijing-L with the same or larger trajectory size. Most of the solutions struggle to finish the task within a reasonable time (<5 hours) on even Beijing-M dataset but we can see the K-MEANS methods finish the task on Beijing-L efficiently, not to mention its ability for parallel processing which further accelerates the process. From the results in Fig. 4e, we can clearly see that even with the same input trajectory size, the map size can significantly affect the performance of all algorithms.

5.3.3 Overall Performance
We evaluate the overall performance on 10,000 trajectories in Beijing-S map, shown in Fig. 4f. In general, the classical methods, like KDE and K-means methods, has been largely outperformed by recent solutions. However, there is nothing wrong with the clustering methods. Although using the same rasterization technique, the topic model-based methods achieve much better performance than the KDE method in terms of both accuracy and road coverage, which indicates that the current way of road abstraction from the cluster is still under development. Despite the outstanding efficiency, the accuracy of the K-means method is unsatisfactory. Moreover, since its accuracy does not always improve as the input data grows, its potential for large scale map construction cannot be fully utilised unless some pruning step is introduced. The map expanding method has decent inference accuracy, however, its road coverage is underwhelming. Considering its ability of road feature inference (non-planar map, more accurate road shape), it is an ideal method for map update. Overall, despite its relatively low recall, the topic model-based method has the best accuracy and overall performance among all other methods. Since the idea and solutions of topic model come from another research field, it shows the potential of map inference problem to be solved by the idea from other research areas or through new techniques like machine learning.

SECTION 6Conclusion
In this paper, we present a comprehensive survey and experimental study of existing map inference algorithms. Specifically, we propose a new categorisation method, compare the representative algorithms experimentally and evaluate the existing quantitative measures. Besides, to test the robustness of algorithms and quantitative measures, we introduce a synthetic trajectory generator and an artificial map generator to simulate different trajectory errors and map quality issues, respectively. According to our experiments, we observe that besides their respective weakness, the existing quantitative measures are unable to identify several map issues and do not consider road importance. Regarding the candidate algorithms, the existing algorithms struggle to guarantee performance when the GPS errors exceed their expected threshold, and they still find a hard time identifying roads that are rarely travelled. Moreover, more input trajectories do not always lead to better inference result. Overall, we identify the method that has the best scalability (RA-K-MEANS), the best accuracy (RA-TOPIC), and the best suitability for map update (IB-ME), respectively, and meanwhile point out the potential future research directions.