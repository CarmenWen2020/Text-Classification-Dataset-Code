Keyword search has been widely studied to retrieve relevant substructures from graphs for a given set of keywords. However, existing well-studied approaches aim at finding compact trees/subgraphs containing the keywords, and ignore a critical measure, density, to represent how strongly and stably the keyword nodes are connected in the substructure. In this paper, given a set of keywords Q={w1,w2,…,wl} , we study the problem of finding a cohesive subgraph containing Q with high density and compactness from a graph G . We model the cohesive subgraph based on a carefully chosen k -truss model, and formulate the problem of finding cohesive subgraphs for keyword queries as minimal dense truss search problem, i.e., finding minimal subgraph that maximizes the trussness covering Q . However, unlike k -truss based community search that can be efficiently done based on the local search from a given set of nodes, minimal dense truss search for keyword queries is a nontrivial task as the subset of keyword nodes to be included in the retrieved substructure is previously unknown. To tackle this problem, we first design a novel hybrid KT-Index to keep the keyword and truss information compacly, and then propose an efficient algorithm that carries the search on KT-Index directly to find the dense truss with the maximum trussness Gden without repeated accesses to the original graph. Then, we develop a novel refinement approach to extract minimal dense truss from the dense truss Gden , by checking each node at most once based on the anti-monotonicity property derived from k -truss, together with several optimization strategies including batch based deletion, early-stop based deletion, and local exploration. Moreover, we also extend the proposed method to deal with the top- r search. Extensive experimental studies on real-world networks validated the effectiveness and efficiency of our approaches.
SECTION 1Introduction
Keyword search, as a user-friendly query scheme, has been widely used to retrieve useful information in graph data, such as knowledge graphs, information networks, social networks, etc. Given a query consisting of a number of keywords, the target of keyword search over a graph is to find substructures in the graph relevant to the query keywords.

In recent decades, keyword search has been extensively studied in the literature [1]. Most of the earlier works aim to find minimal connected trees containing the keywords based on a weight function [2], [3], [4]. These trees returned may be compact, but each of them only gives a partial view of the relationships between the keywords. Thus, connected subgraphs covering the keywords were subsequently proposed, such as r-radius subgraph [5], community [6], and r-clique [7]. However, these methods only focus on the compactness of retrieved substructure by evaluating the distance between (keyword) nodes in a connected tree/subgraph, and fail to explore how densely these keywords are connected. In many applications, density is a critical measure to reflect the stability of the relationships between keywords, e.g., forming a team such that the members are stably close with each other so that the whole team can cooperate well [8]. In other words, there are multiple communication paths between any two members so that they cannot be disconnected easily, which implies the high density. There are also some recent works on diversified keyword search [9], [10], [11], but they also neglect the density of retrieved substructures. Two recent works considered density in keyword based community search. However, their target is to maximize the keyword cohesiveness [12] or contextual density that combines the keyword cohesiveness and structural cohesiveness [13], which are inherently different from finding dense subgraph covering query keywords in this paper.

In this paper, for the first time, we study the problem of finding cohesive subgraphs that are highly dense and compact for keyword queries. Various cohesive subgraph models have been proposed in the literature, such as k-core [14], [15], [16], [17], [18], k-truss [19], [20], [21], k-edge connected component [22], [23], to name a few. We choose k-truss, within which each edge is contained in at least (k−2) triangles, to model the substructures for keyword queries due to its good properties as follows [24]. (1) Stable relationship. k-truss is defined based on a higher order graph motif, triangle, rather than primitive vertices/edges, which is a fundamental building block of networks and can ensure us to find strong and stable relationship between keyword nodes in an answer. (2) Bounded diameter. The diameter of a connected k-truss with n vertices is bounded by ⌊2n−2k⌋. This ensures the compactness of the retrieved subgraphs. (3) High density. A connected k-truss is also a (k−1)-core and a (k−1)-edge connected subgraph, i.e., all nodes have degree at least k−1 and remain connected whenever fewer than k−1 edges are removed. This property ensures that the keyword nodes in the retrieved subgraphs are densely connected. We illustrate the differences between k-truss and existing keyword search approaches (e.g., Steiner tree [2], [3], community [6], and r-clique [7]) by the following example.

Fig. 1a shows a co-authorship and citation graph G with 4 authors and 3 papers. The weight of the edge between an author and a paper is the rank of the author in the paper, and the weight of the edge between two papers is their citation frequency. For a query Q={James,Green}, the top-3 connected trees T1, T2, and T3 with weight 3, 4, and 5 are identified respectively by [2], [3] as shown in Fig. 6b. Fig. 1c shows the communities identified by [6], which are multi-centered subgraphs with the distance between a center node and each keyword node no larger than a given threshold (e.g., 3). They are ranked based on the minimum total edge weight from a center node to each keyword node on the corresponding shortest path. The score of community C1 with center node paper1 is 1+2=3. The score of community C2 is 4 as it has two center nodes paper2 and paper3 with total weights 2+3=5 and 1+3=4, respectively. In the r-clique model with diameter no larger than r (e.g., r=3) [7], T1 and T2 are returned, as only Steiner trees of qualified r-cliques are finally extracted. All these approaches return substructures containing James Wilson and John Green as the top-1 answer. However, James Wilson and Jim Green coauthored more papers together with Jack White, which implies a more stable and closer relationship. Based on our truss model, they can be properly discovered in the form of 4-truss (the dashed line area in Fig. 1a).


Fig. 1.
A motivating example.

Show All

1.1 Challenges
To attain highly dense and compact substructures for a keyword query Q, a natural way is to find the subgraph with maximum trussness and minimum size containing Q, which is called as minimum dense truss. However, as we will discuss in Section 2, finding a minimum dense truss containing the query keywords is NP-hard. Moreover, this problem is also APX-hard, which means we cannot find a polynomial-time algorithm that approximates the minimum dense truss search problem within any constant ratio unless P=NP. Thus, in this paper, we study a relaxed version, called minimal dense truss search, i.e., find the subgraph with maximum trussness containing Q such that it does not contain any subgraph with the same trussness containing Q. Note that our model is different from the closest truss model [20] with maximum trussness and minimum diameter, as the diameter of a k-truss with n nodes is bounded by ⌊2n−2k⌋ while a k-truss with minimum diameter may have an arbitrarily large number of nodes. Moreover, closest truss search is NP-hard [20], while minimal dense truss search can be done in polynomial time.

Despite rich studies on related problems such as community detection [24], [25], [26], [27] and community search [19], [21], finding minimal dense truss for a keyword query is a nontrivial task. The main reason is that minimal dense truss search for query keywords is inherently different from these two problems. Community detection is query independent aiming to detect maximal k-truss communities for each k, which can be done by truss decomposition in O(|E|1.5) time [25]. Community search aims to find maximal communities that maximize the trussness and contain a given set of query nodes, which can be done by local search with proper indexes in O(|A|) time (A is the answer) [19], [21]. One recent work [28] studied attributed community search to rank communities based on attribute score, but it also requires the input of a subset of nodes. The main difficulty of minimal dense truss search for a keyword query is that, unlike community search where the query nodes are given, the subset of nodes containing all the keywords to be included in the dense truss to be retrieved is unknown in advance, and therefore we do not know from which nodes to start if we adopt the local search approach in [19], [21]. One possible solution is that, for a query Q={w1,w2,…,wl}, we explore all the combinations of keyword nodes in S=V1×V2×⋯×Vl to find the subgraph with the maximum trussness, where Vi is the node set containing wi. Such search space is inexhaustible for large graphs even when we use the local search method with essentially optimal time O(|A|) in [19], [21], due to a large number of combinations. Even if we have already obtained a truss with the maximum trussness containing Q, verifying the minimality of such truss is also time consuming, because we need to check all of its subgraphs containing Q to make sure that there is no subgraph with the same trussness.

1.2 Contributions
In this paper, we tackle the minimal dense truss search problem for a keyword query Q by dividing it into two subtasks. The first is finding the dense truss Gden with the maximum trussness containing Q. The second is refining Gden to obtain a minimal dense truss H containing Q. For the first subtask, we can either solve it in a bottom-up manner or top-down manner. Due to the limit of space, we only gave a basic solution in the top-down framework in the preliminary version based on KT-Index [29] and did not give thorough analysis and optimization techniques. In this version, we will first give the hardness analysis of the problem studied in this paper. Then we discuss and thoroughly compare the bottom-up framework and top-down framework. Furthermore, we discuss the extension of the proposed method to the top-r search. Moreover, although we only need to check each node at most once based on the anti-monotonicity property of k-truss in the preliminary version [29], the refinement process is still time consuming as we have to do the k-truss verification for each deletion. Thus, we further propose several optimization strategies to accelerate the refinement process, including batch based deletion, early-stop based deletion, and local exploration. We also performed extensive experimental studies on more real-word datasets and parameters and showed that our newly proposed method is faster than our previously proposed method [29] by one order of magnitude. We summarize the substantial improvements as follows.

We study the problem of finding cohesive subgraphs for keyword queries, and formulate it as a carefully chosen k-truss model. To the best of our knowledge, this problem has not been studied in the literature.

We analyze the hardness of the studied problem, and propose two different basic frameworks, namely bottom-up framework and top-down framework with through comparisons.

We design a novel hybrid index KT-Index to keep the keyword information and truss information, which is space and time efficient, and propose a novel top-down algorithm based on KT-Index, which can efficiently find the dense truss with the maximum trussness for a keyword query without repeated accesses to the original graph G.

We develop an efficient refinement algorithm to extract minimal dense truss containing Q from dense truss, with several optimization strategies including batch based deletion, early-stop based deletion, and local exploration to further accelerate the refinement process.

We conducted extensive experimental studies on real and synthetic networks and validated the effectiveness and efficiency of our approach on discovering cohesive substructures for keyword queries.

The rest of the paper is organized as follows. Section 2 gives the problem statement and hardness analysis. Section 3 presents two basic algorithmic frameworks. Section 4 illustrates the improved top-down algorithms based on KT-Index, and a novel algorithm for refining a dense truss to extract the minimal dense truss for a keyword query. Our experimental results are shown in Section 5. Section 6 discusses the related works and Section 7 concludes this paper.

SECTION 2Problem Statement
In this section, we will first describe related notations and definitions, and then analyze the hardness of the minimum dense truss search problem for keywords.

2.1 Notations and Definitions
Given a set of labels Σ, a simple undirected vertex labeled graph is represented as G=(V,E,L), where V is the set of vertices, E⊆V×V is the set of edges, and L is a labeling function which assigns each node a set of labels L(v)⊂Σ. We use V(G) and E(G) to denote the set of vertices and the set of edges of graph G respectively, and use |V(G)| and |E(G)| to denote the number of vertices and number of edges in G respectively. For a vertex v∈V, we denote the set of its neighboring vertices by N(v)={u∈V|(u,v)∈E} and its degree by d(v)=|N(v)|. A triangle △(u,v,w) in G is a substructure such that (u,v),(v,w),(u,w)∈E.

Definition 2.1 (Edge Support).
The support of an edge e=(u,v) in graph G is the number of triangles in which e occurs, defined as supG(e)=|{△(u,v,w)|w∈V(G)}|.

In the following, we use sup(e) and supG(e) interchangeably if the context is clear.

Definition 2.2 (Connected k-Truss).
Given a graph G and an integer k, a connected k-truss is a connected subgraph H⊆G, such that ∀e∈E(H), supH(e)≥k−2.

The above definition implies that in a connected k-truss, the end vertices of each edge have at least k−2 common neighboring vertices in this truss. Thus, the degree of each vertex in a connected k-truss is at least k−1, and a connected k-truss is also a (k−1)-core.

The trussness of a subgraph H⊆G is the minimum support of all the edges in H plus 2, defined as τ(H)=mine∈E(H)supH(e)+2. The trussness of an edge e∈E(G) is the maximum trussness of subgraphs containing e, i.e., τ(e)=maxH⊆G∧e∈E(H)τ(H). The trussness of a vertex v∈V(G) equals to the maximum trussness of its adjacent edges, i.e., τ(v)=maxu∈N(v)τ(u,v).

For example, in Fig. 2, the edge support of (v2,v3) is 3 as it is contained in 3 triangles △(v1,v2,v3), △(v2,v3,v4) and △(v2,v3,v5). Let H1 denote the subgraph induced by vertices {v1,v2,v3,v4}. τ(H1)=4 since the minimum support of edges in H1 is 2. The trussness of edge (v2,v3) is 4 because there is no other subgraph with higher trussness containing (v2,v3). τ(v2)=4 because the maximum trussness of its adjacent edges (v2,v1), (v2,v3), (v2,v4) and (v2,v5) is 4.

Definition 2.3 (Dense Truss Over Keywords).
Given a graph G and a keyword set Q, a dense truss over Q is a connected truss Gden⊆G that maximizes the trussness and contains Q.

Definition 2.4 (Minimum Dense Truss Over Keywords).
Given a graph G and a keyword set Q, the minimum dense truss over keywords Q is a dense truss Gden⊆G containing Q with minimum number of nodes.

Definition 2.5 (Minmal Dense Truss Over Keywords).
Given a graph G and a keyword set Q, the minimal dense truss over Q is a dense truss Gden⊆G containing Q such that any subgraph of Gden is not a dense truss containing Q.

Fig. 2. - 
An example graph $G$G.
Fig. 2.
An example graph G.

Show All

For example, consider a query Q={DB,ML}. H1 and H2 in Fig. 2 are 4-truss and 3-truss containing Q. Clearly, H1 is a dense truss over Q. We also have another 4-truss induced by {v1,v2,v3,v4,v5} containing Q, but it is not minimal. Thus, H1 is the minimal dense truss for Q.

Problem 1 (Minimum Dense Truss Search by Keywords).
Given a graph G and a keyword set Q={w1,w2,…,wl}, find the minimum dense truss containing Q. We refer to it as minimum dense truss search problem when the context is clear.

2.2 Hardness of Minimum Dense Truss Search
We show the NP-hardness of the minimum dense truss search problem by the reduction of maximum clique problem as in [20]. The decision version of the minimum dense truss search problem can be defined as follows.

(k,h)-Truss Problem. Given a graph G, a keyword set Q, integers k and h≥k, test whether G contains a connected k-truss with h nodes covering all the keywords in Q.

Theorem 2.1.
(k,h)-truss problem is NP-hard.

Proof.
We prove this by reducing the well known NP-hard problem, the maximum clique decision problem, to (k,h)-truss problem. Given a graph G and an integer k, the maximum clique decision problem is to check whether G contains a clique of size k. Now we construct an instance of (k,h)-truss problem, consisting of a graph G, parameters k and h=k, and query Q=∅. Next, we show that the instance of the maximum clique decision problem is a YES-instance iff the instance of (k,h)-truss problem is a YES-instance. Clearly, any clique with k nodes is a connected k-truss with size h=k. On the other hand, given a solution H for (k,h)-truss problem. H must contain k nodes since H is a k-truss and h=k, which implies H is a clique.

The above theorem implies the hardness of the minimum dense truss search problem. Next, we further explore whether it can be approximated. For a given constant c≥1 and any instance G, an algorithm can achieve an c-approximation to the minimum dense truss search problem if it outputs a connected k-truss subgraph H such that τ(H) = τ(H∗) and |V(H)|≤c×|V(H∗)| where H∗ is the optimal solution. In the following, we prove that the problem does not admit a polynomial-time algorithm that can achieve any constant approximation ratio unless P=NP. We obtain this result also based on the reduction of the maximum clique decision problem.

Theorem 2.2.
Unless P=NP, there does not exist any polynomial-time algorithm that approximates the minimum dense truss search problem within any constant ratio.

Proof.
We prove this by contradiction. Assume that there exists a polynomial time algorithm A for minimum dense truss search problem with a given k that provides a solution H with an approximation ratio c of the optimal solution H∗. Now we consider the case when Q=∅. Clearly, based on the assumption we have a subgraph H such that τ(H) = τ(H∗) and |V(H)|≤c×|V(H∗)|. Next, we use this approximate solution to solve maximum clique decision problem, i.e., run algorithm A on a given instance G of maximum clique decision problem, with parameters k, h=k, and query Q=∅. We claim that G contains a clique of size k iff A output a solution H with τ(H)=k and |V(H)|=k. To see this, suppose that |V(H)|=k. Then the optimal solution has |V(H∗)|≤|V(H)|=k, which shows H∗ is a clique of size k. On the other hand, suppose that |V(H)|≥k+1. Then we have c×|V(H∗)|≥|V(H)|≥k+1 for any c>1. Thus, we have |V(H∗)|≥k+1. In this case, G cannot contain a clique of size k, because if it did, that clique would be the optimal solution to the minimum dense truss search problem with parameter k and size h=k, which contradicts the optimality of H∗. Thus using algorithm A we can distinguish between the YES and NO instances of the maximum clique decision problem.

The above theorems show that it is not only intractable to obtain a minimum dense truss for a keyword query, but also hard to get its approximate solution in polynomial time. Hence, in the following, we focus on finding the minimal dense truss for keyword queries, which is solvable in polynomial time.

Problem 2 (Minimal Dense Truss Search by Keywords).
Given a graph G and a keyword set Q={w1,w2,…,wl}, find the minimal dense truss containing keywords Q. We refer to it as minimal dense truss search problem when the context is clear.

Note that some applications may require to find top-r minimal dense trusses for keywords, which are ranked by the trussness. For simplicity, we will first consider the top-1 minimal dense truss search for keywords and discuss how to extend it to the top-r version later.

SECTION 3Basic Algorithmic Frameworks
As stated above, finding minimal dense truss for keyword query Q can be naturally divided into two phases. As shown in Algorithm 1, the first is finding the dense truss Gden with maximum trussness containing Q (DenseTrussSearch in line 1), and the second is refining Gden to obtain a minimal dense truss containing Q (FindMinDenseTruss in line 2). In this section, we will first propose two basic dense truss search frameworks for the first phase. The details of the second phase will be introduced later in Section 4.

SECTION Algorithm 1.TwoPhaseFramework
Input: A graph G, and a keyword query Q.

Output: A minimal dense truss H.

Gden←DenseTrussSearch(G,Q) (Algorithm 2/Algorithm 3);

H←FindMinDenseTruss(Gden,Q);

return H;

3.1 Basic Bottom-Up Dense Truss Search
To obtain the dense truss containing keyword query Q, one straightforward method is to explore all the combinations of keyword nodes in S=V1×V2×⋯×Vl. Specifically, for each keyword node set Sj∈S, we obtain a dense truss Gj containing Sj that maximizes the trussness. Then, among all the dense trusses discovered, we return a truss Gden with the largest trussness. Such process is quite time consuming because we need to find the dense truss for |V1|×|V2|×⋯×|V2| sets of nodes.

To find the dense truss Gden as early as possible, we will utilize the upper bound for the trussness of a node subset S, which can be defined as τ′(S)=minv∈Sτ(v).

Lemma 3.1.
Given a graph G and a subset of nodes S⊆ V(G), for any truss H containing S, we have τ(H)≤τ′(S).

This lemma can be easily derived from the trussness definition of a subgraph (H (τ(H)=minv∈V(H)τ(v) in Section 2.1), the upper bound of the trussness for a node set S τ′(S), and S⊆V(H).

The bottom-up dense truss search process is shown in Algorithm 2. Lines 1-8 initialize the variables. From line 9 to line 13, we sequentially check each Sj∈S in descending order of τ′(Sj) to find the dense truss Gj containing Sj. This process stops when the upper bound for the current node subset is no larger than the largest trussness kmax found so far. In line 10, we find the subgraph with the largest trussness containing Q. This can be achieved by truss decomposition, which needs O(|E(Gj)|1.5) time [25], and can even be done in O(|E(Gj)|) time if a proper index is adopted [20].

Algorithm 2. DenseTrussSearch-BottomUp
Input: A graph G, and a keyword query Q.

Output: A dense truss Gden.

compute trussness for all edges and nodes;

for each keyword wi∈Q do

Vi← set of nodes containing wi;

S←V1×V2×⋯×Vl;

for each S∈S do

τ′(S)←minv∈Sτ(v);

sort S in descending order of τ′(S);

kmax←0; j←0;

while j++≤|S|∧kmax<τ′(Sj) do

Gj← find the truss with maximum trussness containing Q;

if kmax<τ(Gj) then

kmax←τ(Gj);

Gden←Gj;

return Gden;

Theorem 3.1.
Algorithm 2 needs O(max{|E|1.5,|V1|×|V2|×⋯×|Vl|×|E|})time.

Proof.
First, the trussness of edges and nodes can be computed by truss decomposition in O(|E|1.5) time [25]. For each Sj, the process DenseTrussSearch can be completed in O(|E(Gj)|) time if the index based method in [20] is adopted. Thus the whole loop needs O(|V1|×|V2|×⋯×|Vl|×|E|} time and the overall time complexity is O(max{|E|1.5,|V1|×|V2|×⋯×|Vl|×|E|}).

Such complexity implies that DenseTrussSearch-BottomUp is impractical for real large graphs even for a small l. Consider the case that l=3 and |Vi|≈103. The complexity is even as large as O(109×|E|).

Note that we can also sort the elements in S by other measures like trussness of Steiner tree induced by each S∈S in [20]. However, such heuristics do not change the stop condition and thus cannot reduce the worst-case complexity. Meanwhile, it also needs extra O(|E|+|V|log|V|) time [30] to approximately compute the Steiner tree for each S∈S.

3.2 Basic Top-Down Dense Truss Search
To avoid enumerating all the combinations of keyword nodes, we propose a top-down framework by starting the search over the truss with the largest trussness kmax in graph G. If it does not contain a connected kmax-truss covering Q, we will gradually decrease kmax until we find one. This process can be accelerated the following property of keyword trussness. Let Vi be the set of nodes containing keyword wi. The upper bound of the keyword trussness is defined as the maximum trussness of nodes in Vi, i.e., τ′(wi)=maxv∈Viτ(v).

Property 3.1.
Given a graph G and a keyword set Q={w1, w2, …,wl}, for any truss H containing Q, we have τ(H)≤min1≤i≤lτ′(wi).

Proof.
For a truss H containing Q, there must exist a node v′i containing wi for each wi∈Q. Obviously, we have τ(H)=minv∈V(H)τ(v)≤min1≤i≤lτ(v′i). Moreover, since τ(v)≤τ′(wi) for any node v∈Vi, we have τ(H)≤min1≤i≤lτ(v′i)≤min1≤i≤lτ′(wi).

Th basic top-down dense truss search process is shown in Algorithm 3. First, we obtain the trussness of all the edges and nodes by truss decomposition [25] (line 1). Then, for each keyword wi∈Q, we compute the node set Vi, and obtain the upper bound of trussness for this keyword by τ′(wi)=maxv∈Viτ(v) (lines 2-4). Based above property, we start searching from kmax-truss where kmax=min1≤i≤lτ′(wi). Specifically, we extract Gkmax={e∈G|τ(e)≥kmax} from G and check each connected component Ci in Gkmax contains all the keywords (lines 6-13). If yes, we return the component containing Q with the smallest size; otherwise, we search (kmax−1)-truss and stop when we find a connected truss Gden containing Q.

Algorithm 3. DenseTrussSearch-TopDown
Input: A graph G, and a keyword query Q.

Output: A dense truss Gden.

compute trussness for all edges and nodes;

for each keyword wi∈Q do

Vi← set of nodes containing wi;

τ′(wi)←maxv∈Vi(v);

Gden←∅;

kmax←min1≤i≤lτ′(wi);

while Gden=∅ do

extract kmax-truss Gkmax={e∈G|τ(e)≥kmax)};

for each connected component Ci in Gkmax do

if Ci contains all keywords in Q then

if |V(Ci)|≤|V(Gden)| then

Gden←Ci;

kmax←kmax−1;

return Gden;

Theorem 3.2.
Algorithm 3 needs O(|E|1.5) time.

Proof.
The complexity of lines 1-4 is bounded by truss decomposition, which is O(|E|1.5) [25]. In lines 6-13, for a kmax-truss, we need O(|E(Gkmax)|) time to compute the connected components and O(|V(Gkmax)|×l) time to check whether each component contains all the l keywords. Since l is usually very small, such process can be done in O(|E(Gkmax|) time. In the worst case, we need to check all the possible values of kmax from min1≤i≤lτ′(wi) to 2. Since the maximum trussness of nodes in graph G is no larger than |E|−−−√ [25], the complexity of lines 6-13 is O(|E|−−−√×|E|), and thus the overall time complexity is O(|E|1.5).

SECTION 4Improved Top-Down Search Algorithm
In this section, we design a novel Keyword-Truss Index (KT-Index) to keep the keywords and trussness information, and propose a highly efficient top-down algorithm to process minimal dense truss search queries.

4.1 KT-Index Design and Construction
In the basic top-down search algorithm, trussness computation for each edge is primitive. Since it is independent with keyword queries, we can complete such computation by truss decomposition [25] offline before any query comes, and then build a hash table to the trussness of each edge.

Another time-consuming part of the basic top-down algorithm is the examination of many k values before a k-truss containing Q with the largest k is found, the time complexity of which is O(|E|1.5). To speed up this process, we design a KT-Index, which includes two parts: truss index and keyword index.

Truss Index. Truss index is a multi-layer structure, where all the connected k-truss are indexed in the kth layer. Suppose that there are pk connected components C1,C2,…,Cpk in the kth layer. We sort all the components in the descending order of their sizes (number of nodes) and assign each component an ID. For each component Ci, we only store the node set V(Ci). Thus, we store the kth layer in the form of list (1,V(C1)),…,(i,V(Ci)),…,(pk,V(Cpk)).

Keyword Index. In the keyword index, we first store an inverted keyword list to keep the node IDs that contain each keyword, i.e., for each wi, we store the keyword node set Vi containing wi. Meanwhile, we record the upper bound of trussness τ′(wi) for each keyword. Moreover, for each keyword, we record the set of IDs of the component CIDk that this keyword occurs in the kth layer in the form of (k,CIDk).

Algorithm 4 shows the process of building KT-Index. First, we obtain the trussness of each edge by truss decomposition (line 1). Then we divide the edges into a number of groups E3,E4,…,Ekmax according to their trussness (lines 3). Next, we build the inverted keyword list by scanning the graph G (line 4). Then for each k from 3 to kmax, we obtain truss Gk in the kth level by deleting edge set Ek−1 from Gk−1. Then we sort the connected components in Gk in ascending order of component size and assign each component an ID (line 7). For each components Ci in Gk, we output (i,V(Ci)) to build the truss index (line 9). We also compute keyword set Wi occurs in Ci and add the component ID to CIDk for each keyword w∈Wi (lines 10-12).

Algorithm 4. BuildKTIndex
Input: A graph G.

Output: KTIndex.

compute τ(e) for each edge e∈E;

kmax=maxe∈Eτ(e);

group edges into E3,…,Ekmax based on τ(e);

build the keyword inverted list;

for k=3 to kmax do

obtain Gk by deleting Ek−1 from Gk−1;

sort the components in Gk and assign CID;

for each connected component Ci in Gk do

output (i,V(Ci)) to build the truss index;

compute keywords Wi contained in Ci;

for each w∈Wi do

add i to CIDk for w;

Theorem 4.1.
KT-Index can be constructed in O(|E|1.5) time and O(m) space by Algroithm 4, and it's size is O(m).

Proof.
The time complexity of lines 1-4 is dominated by the complexity of truss decomposition [25], which is O(|E|1.5). The complexity of the loop in lines 5-12 is O(∑1≤k≤kmax|E(Gk)|). Since each edge e occurs in at most τ(e) layers, we have ∑1≤k≤kmax|E(Gk)|≤∑e∈Gτ(e)≤∑e∈Gsup(e)=3×Ntri, wh`ere Ntri is the number of triangles in G. Since Ntri is bounded by O(α×|E|) where α≤|E|−−−√ is the arboricity of graph G [31], the overall time complexity of Algorithm 4 is O(|E|1.5). For the space complexity, since lines 1-4 need O(|E|) space and lines 5-12 need O(|E(Gk)|) space, the computational space of Algorithm 4 is bounded by O(|E|). For index size, we need O(|E|) space to store edge trussness, and ∑1≤k≤kmax|V(Gk)| space to store the nodes in all the truss layers. Since each node v occurs in at most τ(v) layers and τ(v)≤d(v), we have ∑1≤k≤kmax|V(Gk)|≤∑v∈Vτ(v)≤∑v∈Vd(v)=2×|E|. The size of the keyword index is bounded by O(|V|×navg), where navg is the average number of keywords associated with each node and is usually a small constant. Furthermore, we also keep the set of component keep CIDk in the kth layer for each keyword, which is a usually very small number (at most hundreds for real-world graphs) far away from the number of nodes and edges. Thus, the index size of KT-Index is bounded by O(|E|).

Consider the graph G as shown in Fig. 2. Based on Algorithm 4, we first obtain the trussness of each edge. Since all edges are connected, all the nodes are in one component with trussness 2, as shown in Table 1. We then remove the edges with trussness 2 and obtain two components with trussness 3. The CID of component {v9,v10,v11} is assigned to 1 because it is smaller than the other one. The keyword index is shown in Table 2. For keyword AI, we record the upper bound of its trussness 4, and nodes it occurs in v5 and v6, and the second component of layer 3.

TABLE 1 An Example for Truss Index
Table 1- 
An Example for Truss Index
TABLE 2 An Example for Keyword Index
Table 2- 
An Example for Keyword Index
4.2 The Improved Top-Down Search Algorithm
After KT-Index is constructed, we can directly carry out the minimal dense subgraph search on this index.

The DenseTrussSearch-TopDownKT Algorithm. The search process is shown in Algorithm 5. To avoid the worst case of checking all the value of k, we check each layer of truss index by a binary search, which can be completed in log(kmax) iterations. In the kth layer, we obtain the set of component IDs CC that contains all the keywords (lines 4-5). If CC is empty, we will search layers with trusness smaller than current k; otherwise, we will search layers with trussness larger than current k. After finding the set of component IDs CC that containing all the keywords, we select the smallest component as dense truss Gden. Then we extract the minimal dense truss H containing Q from Gden by function FindMinDenseTruss, which will be detailedly introduced later.

Algorithm 5. DenseTrussSearch-TopDownKT
Input: A graph G, and a keyword query Q.

Output: A dense truss Gden.

kmax←min1≤i≤lτ′(wi); kmin←3;

while kmax>kmin do

k←⌊kmax+kmin2⌋;

SCi←CIDk for each wi∈Q;

CC←∩1≤i≤lSCi;

if CC≠∅ then

kmin←k+1;

else

kmax←k−1;

id←mincid∈CCcid;

Gden← component Cid at the kth layer;

return Gden;

Theorem 4.2.
Algorithm 5 needs O(log|E|−−−√×ncmax) time, where ncmax is the maximum number of components among all the layers in KT-Index.

Proof.
Clearly, the number of iterations based on binary search (lines 2-9) is bounded by O(logkmax). In each iteration, we only need to compute the component ID which contains all the keywords, which needs O(pmax) time, where pmax is the maximum number of components in each layer. Since the maximum trussness in graph G is no larger than |E|−−−√ [25]. The overall time complexity is O(log|E|−−−√×pmax).

Note that in practice, the number of connected components in each layer is far smaller than the number of nodes, which is usually at most hundreds for real-world graphs. Thus our KT-Index based top-down search algorithm can identify Gden efficiently.

Extension to Top-r Search. As stated before, some applications may prefer to find top-r dense subgraphs ranked based on their trussness. From the definition of k-truss, we know that the subgraph contained in a component of k-truss is also contained in a component of (k−1)-truss. Thus, to avoid repeatedly returning dense truss containing the same set of keyword nodes, we require that the minimal dense trusses identified are not overlapped. Therefore, we marked a node if it has already been identified. Then, Algorithm 5 can be easily revised to return the top-r minimal dense trusses. Instead of only returning one component ID with the smallest size in line 11 of Algorithm 5, we return all the IDs in CC. If |CC|≥r, we will extract the minimal truss from the r smallest components in CC and return them as the answer. If |CC|<r, we will extract the minimal truss from all the components in CC and add them to the answer list, update r by r−|CC|, and then check the (k−1)th layer repeatedly until will found r minimal dense trusses from these layers.

4.3 Minimal Dense Truss Extraction
Now, we move to the subtask of extracting minimal dense truss from Gden, as shown in Algorithm . Before getting into the details of function FindMinDenseTruss(Gden,Q), we first discuss the anti-monotonic property of k-truss, to provide essential guidelines for refinement.

Property 4.1.
Given a connected k-truss H, a node v∈V(H) and set of its adjacent edges Ev={(u,v)∈E(H)}, if graph G¬v=(V(H)∖{v},E(H)∖Ev) does not contain a connected k-truss, there does not exist a subgraph H′⊆H such that G′¬v=(V(H′)∖{v},E(H′)∖Ev) contains a connected k-truss.

Proof.
We prove this by contradiction. Assume that ∃H′⊆H such that G′¬v=(V(H′)∖{v},E(H′)∖Ev) contains a connected k-truss H∗. Clearly, H∗⊆G′¬v. Since V(H′)∖{v}⊆V(H)∖{v} and E(H′)∖Ev⊆E(H)∖Ev, we have G′¬v⊆G¬v. Thus we have H∗⊆G¬v which contradicts with the assumption that G¬v does not contain a connected k-truss.

This property shows that when we refine Gden by deleting nodes, each node v in Gden only needs to be checked once. If deleting v will result in a subgraph that contains no connected k-truss containing Q, we will keep v and will not recheck it in the following deletions.

Algorithm FindMinDenseTruss. Based on the above property, we give the process of FindMinDenseTruss in Algorithm 6. The main idea is every time we randomly pick one node v in graph Gden uniformly at random to check whether deleting node v and its adjacent edges will still lead to a connected k-truss H containing Q (lines 4-5). If yes, we update Gden by H (lines 6-7); otherwise, we check the next node. We use set Svis to keep nodes that have been checked to avoid repeated examinations.

Function FindkTruss(G′den,Q,k,S) is used to check the existence of a connected k-truss containing Q after deleting node subset S and their adjacent edges from G′den. First, we use Edel to maintain the set of edges to be deleted from the graph. Then we gradually delete each edge (u,v)∈Edel and check whether it will result in new edges that violate the edge support constraint for a k-truss (lines 15-21). If yes, we will continually add these edges into Edel. Such process stops when Edel=∅. If there is a connected component H containing Q, we will return H as a k-truss; otherwise, we return ∅.

Algorithm 6. FindMinDenseTruss
Input: A dense truss Gden, and a keyword query Q.

Output: A minimal dense truss.

k←τ(Gden); Svis←∅;

while V(Gden)∖Svis≠∅ do

G′den←Gden;

select a node v from V(G′den)∖Svis;

H←FindkTruss(G′den,Q,k,{v});

if H≠∅ then

Gden←H;

Svis←Svis∪{v};

return H;

Procedure FindkTruss(G′den,Q,k,S)

Edel← set of adjacent edges for nodes in S;

for (u,v)∈Edel do

Edel←Edel∖{(u,v)};

Remove (u,v) from G′den;

for w∈N(v)∩N(u) do

sup(v,w)←sup(v,w)−1;

sup(u,w)←sup(u,w)−1;

if sup(v,w)<k−2∧(v,w)∉Edel then

Edel←Edel∪{(v,w)};

if sup(u,w)<k−2∧(u,w)∉Edel then

Edel←Edel∪{(u,w)};

if ∃ connected component H⊆G′den containing Q then

return H;

return ∅;

Theorem 4.3.
The time complexity of Algorithm 6 is O(t×(α−k)×|E(Gden)|) where t≤|V(H)| is the number of iterations, k is the trussness of Gden, and α≤|E(Gden)|−−−−−−−−√) is the arboricity of Gden (minimum number of spanning forests needed to cover all the edges in Gden).

Proof.
First we analyze the complexity of FindkTruss. It is mainly determined by how many times lines 16-21 are executed. The worst case is that if v cannot be delete, then the support of all the edges will be updated to k−3 and deleted. Thus the times of such process is bounded by O(∑e∈E(Gden)(sup(e)−(k−3))). Since ∑e∈E(Gden)=3×Ntri where Ntri is the number of triangles bounded O(α×|E(Gden)|) (α is the arboricity of Gden), we have O(t×(α−k)×|E(Gden)|) where t is the number of iterations of lines 16-21.

We say a node is deletable if deleting it still leads to a connected k-truss containing Q; otherwise, we say it is un-deletable. From the above theorem, we can see that the time complexity of FindMinDenseTruss mainly depends on the number of iterations t and the size of Gden in each iteration as α−k is a constant for a given graph. To reduce the complexity, we need to reduce the number of iterations and delete the deletable nodes as early as possible to reduce the size of the dense truss quickly. In the following, we will introduce some optimization strategies to accelerate this process.

Optimization I: Batch Based Deletion. To reduce the number of iterations, one possible way is to delete the nodes in batch instead of one by one. In fact, if there is a subset S⊆V(Gden) that can be deleted from Gden and the remaining part also contains a connected k-truss covering Q, we can delete all the nodes in S immediately. However, always deleting a large number of nodes each time might result in no k-truss containing Q. Therefore, we increase the deletion size step by step, which means after one successful deletion, we will increase the number of nodes to be deleted. When it meets an unsuccessful removal, we reset the size to 1. By such setting, we can always delete the nodes one by one in the last steps of deletion and make sure that the minimal dense truss is returned.

Optimization II: Eearly-Stop Based Deletion. In addition to the above optimization strategy, we can also accelerate the computation by only find an approximate result of minimal dense truss, i.e., we stop the search if the number of consecutive unsuccessful deletions exceeds a given threshold. In fact, with random deletion, we can output an c-approximation of a minimal dense truss with probability at least 1−δ, if the threshold is set to be log1δ/logc. We omit the proof as it is similar to the proof in [23] of finding minimal Steiner maximum-connected subgraph for a set of query nodes.

Optimization III: Local Exploration. In some cases, Gden can be very large, which may need a large number of deletions to obtain the minimal dense truss. Thus, we can extract a small subgraph G′den from Gden containing the keywords by local exploration. Specifically, we will first construct a Steiner tree T in Gden to connect nodes containing all the keywords. Then we expand T to a subgraph GT in a BFS manner. In the beginning, GT is initialized as T. We iteratively add the adjacent vertices with the largest trussness until |V(GT)| exceeds a threshold t. Then we add all the adjacent edges for each node in GT and check whether GT contains a k-truss G′den that covers all the keywords. If yes, we consider G′den as the new densest subgraph and apply above refinement process to G′den; otherwise, we expand GT until |V(GT)| exceeds 2t. We repeat the above process until a k-truss G′den can be extracted.

SECTION 5Performance Studies
In this section, we will first introduce the setup of the experiments and then discuss the experimental results.

5.1 Experimental Setup
To our best knowledge, there is no existing work on cohesive subgraph search based on k-truss for keyword queries. Thus, we implemented the following versions of our methods to thoroughly evaluate the efficiency and effectiveness of KT-Index, search algorithms, and optimization strategies.

basic. Basic DenseTrussSearch-TopDown in Algorithm 2 with FindMinDenseTruss implemented as Algorithm 6.

KT. DenseTrussSearch-TopDownKT in Algorithm 5 with FindMinDenseTruss implemented as Algorithm 6.

KTb. Algorithm 5 + Algorithm 6 + batch based deletion.

KTs. Algorithm 5 + Algorithm 6 + early-stop based deletion.

KTl. Algorithm 5 + Algorithm 6 + local exploration.

KTbs. Algorithm 5 + Algorithm 6 + batch based deletion + early-stop based deletion.

KTbsl. Algorithm 5 + Algorithm 6 + batch based deletion + early-stop based deletion + local exploration.

All the algorithms were implemented in C++, and all the experiments were conducted on a Linux server with Intel Xeon CPU 2.60 GHz and 128 GB memory.

Datasets. We evaluate the performance of the algorithms on three real-world datasets that have been widely used in previous works on keyword search and attributed community search [6], [11]. (1) DBLP,1 a bibliographic dataset with 2 million nodes and 9.9 million edges. In the dataset, a node denotes an author, and an edge denotes the co-authorship between these two authors. (2) DBpedia,2 a knowledge graph including 5.90 million nodes and 17.6 million edges. Each node represents an entity with a type (e.g.,’animal’, ’architectures’, ’famous places’) from in total 272 types, with a set of attributes (e.g., ’jaguar’, ’Ford’). (3)YAGO3 is also a knowledge graph with 2.64 million nodes and 5.23 million edges, but it is much sparser than DBLP and DBpedia. Note that we did not test another widely used dataset IMDB as it is a tripartite graph with maximum trussness 3. (4) Syn is a synthetic dataset generated by SNAP4 following the Barabaci-Albert (BA) model. It contains five datasets with the same number of nodes (2 million) but a different number of edges (The average out-degree in the model is set to 10, 12, 14, 16, and 18, respectively). The keyword distribution and keyword queries are borrowed from DBLP. Specifically, each node in the synthetic data randomly corresponds to a node in DBLP and borrow the corresponding keywords attached.

Keyword Queries. (1) For DBLP and Syn, the sets of keyword queries used in the evaluation are the same as those in [6], which is shown in Table 3, with their associated keyword frequency KWF. (2) For DBpedia and YAGO, we use 6 query templates consisting of type keywords and value keywords designed in [11], as shown in Table 4. Since each value keyword associates with only one node representing an entity, to generalize the query, we modify the query templates by replacing the value keyword (e.g., american music awards) with one of its corresponding type that contains the most number of entities (e.g., TelevisionShow).

TABLE 3 Keyword Queries for DBLP
Table 3- 
Keyword Queries for DBLP
TABLE 4 Keywords Queries for DBpedia and YAGO
Table 4- 
Keywords Queries for DBpedia and YAGO
Parameters. We test the performance of all the algorithms by varying three parameters, including the number of keywords l, the r value of top-r search, and the keyword frequency KWF. The ranges and default values of these parameters are shown in Table 5. Specifically, for synthetic datasets, we vary its degree d to show how density affects the minimal dense truss search.

TABLE 5 Parameters

5.2 Experiment Results
Exp-1: Index Construction. We start the experiments with the construction of indexes by BuildKTIndex in Algorithm 4. This process is typically performed offline before keyword search is carried out. Once the indexes are built, they will reside in the main memory to efficiently support keyword search in large graphs. We report the space consumed for the overall index structures in memory, and the time spent for index construction in Table 6. It shows that our KT-Index can be constructed within hundreds of seconds efficiently for all the datasets. The size of KT-Index is no more than 2x of the original graph size, which is consistent with the space complexity O(|E|) in our previous theoretical analysis. We omit the datasets in Syn, as they share similar results with DBLP.

Exp-2: Effectiveness and Efficiency on DBLP and Syn. We test the performance of all the algorithms on DBLP by varying parameters l, r, and KWF respectively and Syn by varying the density d.

TABLE 6 Construction Time and Size of Index

The average size of minimal dense trusses for DBLP is reported in Figs. 3a, 3b, and 3c. From Fig. 3a shows that the size increases as the number of keywords increases. It is because a larger substructure is returned to include more keywords. The sizes of the results of all the evaluated algorithms are similar. Fig. 3b shows that the average size of the top-r results remains stable as r increases. It is because the trussness is stable for a small value of r as there may be multiple components at each truss layer. Fig. 3c shows the size of minimal dense trusses for different keyword frequency. For the keywords that are not very frequent (e.g., KWF = 0.003), the keyword nodes will be distributed sparsely in the graph, and a large subgraph is required to include all the keywords. For frequent keywords (e.g., KWF = 0.015), we may only need a very small subgraph to include all the keywords. However, due to different distributions for each keyword query, it does not always decrease for all the cases. The average size of minimal dense trusses for Syn is reported in Fig. 3d, which increases as the density of the graph increase. Note that the size is much smaller compared with the real-world dataset DBLP because the random generated topological structure will destroy the large natural communities that are cohesively connected and topic related in DBLP. Thus the trussness and size of the minimal dense truss are very small.

Fig. 3. - 
Effectiveness and efficiency on DBLP.
Fig. 3.
Effectiveness and efficiency on DBLP.

Show All

Figs. 3e, 3f, and 3g shows the running time on DBLP when varying different parameters. Fig. 3e shows that as l increases, the running times for all the algorithms increase slowly. It is because the time complexity is mainly determined by sizes of graph G and dense truss Gden, and checking more keywords will not cause too much overhead. KT-Index based top-down search algorithm KT is faster than basic without indexes by almost two orders of magnitude. Each of the three optimization techniques can also accelerate computation by 2-5 times. KTbsl based on their combinations is even 10x faster than KT. Fig. 3f shows that as r increases, all the methods need more time to return more results. The increase becomes slow when r is larger because less time is needed to refine truss with smaller trussness. Fig. 3g shows that the running time decreases slowly as the keyword frequency increases because a smaller dense truss Gden will lead to less refinement time. Fig. 3h shows the running time on Syn when varying the density d. The running time of basic algorithm increases along with the increase of density, as it is determined by (O(|E|1.5)). All the KT based algorithms are quite fast because the maximum trussness of Syn is small as dense communities are destroyed in the random graph.

Exp-3: Effectiveness and Efficiency on DBPedia and YAGO. We evaluate the performance on DBpedia and YAGO by the queries in Table 4. Note that we cannot vary l and KWF as keyword query sets are fixed.

The average size of minimal dense truss is reported in Figs. 4a, 4b, 4c, and 4d. Fig. 4a shows that the sizes for all the algorithms are similar, and basic and KT achieve a smaller size as they examine node one by one. The size of the returned subgraphs on DBpedia is not as large as that in DBpedia because DBpedia is sparser than DBLP. Similarly, the retrieved subgraphs for DBpedia are also smaller than that of YAGO in Fig. 4b because of the same reason. Figs. 4c and 4d shows that the size of top-r query on DBpedia and YAGO remains stable as r increases, because there may be multiple components contains the keywords at each truss layer.

Fig. 4. - 
Effectiveness and efficiency on YAGO and DBpedia.
Fig. 4.
Effectiveness and efficiency on YAGO and DBpedia.

Show All

The running time is reported in Figs. 4e, 4f, 4g, and 4h. Fig. 4e shows that basic always needs more time than other algorithms, and KT is faster than basic by 1-2 orders of magnitude. KTbsl is about 10x faster than KT. Fig. 4f has a similar trend as that in Fig. 4e, where KTbsl still performs the best and basic performs the worst, but all the algorithms need less time because YAGO is smaller than DBpedia. Figs. 4g and 4h show the running time when we vary top-r, which also increases along with the increase of r.

Exp-4: Statistics of Trussness and Diameters. We report the trussness and diameter of results for queries given in Tables 3 and 4. We only report the most efficient algorithm KTbsl as other algorithms obtain similar results. Fig. 5 shows that DBLP obtains higher trussness than YAGO and DBPedia because of its high density. Moreover, the trussness increases as query keyword frequency increases, which implies that frequent keywords are more probably to be included in a denser truss. All the diameters of returned results for all the datasets are not larger than 3, which confirms our previous analysis on the tight bound of the diameter of the k-truss.

Fig. 5. - 
Trussness and diameter of the results on DBLP, YAGO and DBpedia.
Fig. 5.
Trussness and diameter of the results on DBLP, YAGO and DBpedia.

Show All

Exp-5: A Case Study on DBLP. We also performed a case study on DBLP to compare the search results of our model and Steiner tree [32]. To find a cohesive subgraph with a stable coauthor relationship, we only consider the edges between authors with at least two coauthored papers. Suppose that an AI company needs to build a team for the task of biometric recognition based on kohonen neural networks, especially for face and periocular facial recognition. For a possible query Q={“biometric”, “recognition”, “face”,”periocular”, “kohonen”}, Fig. 6 shows the minimal dense truss covering Q with trussness 9 we found, where larger nodes represent authors with more publications. In this subgraph, Gerry V. Dozier, Karl Ricanek, and Damon L. Woodard are experts (with more than 50 publications) on biometric recognition, face recognition, and periocular biometric recognition, respectively. Meanwhile, each two of them has coauthored more than ten papers. Joshua Adams and Lasanio Small, the students of Gerry V. Dozier, have published papers on face recognition based on kohonen neural networks, and also have coauthored several papers with Damon L. Woodard. Other persons are students or colleges of Gerry V. Dozier in the biometric recognition research area, and they also have co-authored some papers with other researchers in this subgraph. Fig. 6b shows the Steiner tree found by PrunedDP in [32]. It is contained in a subgraph with the maximum truss value 3. Most of the authors published less than five papers, and their collaborations are very few. Based on the comparison, we can see that our method can return a densely and stably connected subgraph with many publications and coauthor relationships covering Q, while Steiner tree approach can only find a loosely connected structure with very few publications.

Fig. 6. - 
A case study on DBLP.
Fig. 6.
A case study on DBLP.

Show All

SECTION 6Related Work
The related work to this work includes keyword search and community search over graphs.

Keyword Search Over Graphs. Keyword search has been extensively studied in the literature, with query results usually modeled as individual minimal connected trees/graphs containing query keywords [1]. Tree-based methods popularly use Q-SUBTREE to describe a keyword query answer, where the ranking function is usually defined based on Steiner tree-based semantics or distinct root-based semantics. Since finding optimal Steiner tree (top-1 Q-SUBTREE under the Steiner tree-based semantics) is NP-complete, a heuristic algorithm BANKs [2] was proposed to find an approximate solution based on backward search. To find optimal Steiner trees, a parameterized DP algorithm DPBF [33] was proposed where the parameter is determined by the number of Steiner trees. Then, an algorithm producing Steiner trees with polynomial delay was developed [34]. Another method STAR [35] can achieve an O(log(n))-approximation of the optimal Steiner tree in pseudo-polynomial run time. Recently, an improved DP algorithm PrunedDP was proposed [32], based on optimal-tree decomposition and conditional tree merging. BANKS-II [3] and BLINKS [4] were developed to find Q-SUBTREE under distinct root semantics, where the tree weight is the sum of the shortest distance from the root to each keyword node. BANKS-II is a forward search method that starts from the promising root nodes, and BLINKS is an improved algorithm based on a bi-level index through a partitioning graph.

To overcome the drawback that each connected tree only gives a portion of the relationships between query keywords, researchers subsequently proposed new models based on connected subgraphs such as r-radius subgraph [5], community [6], and r-clique [7]. EASE is proposed [5] to find subgraph containing query keywords with a radius no larger than r, based on a ranking function of both structural compactness and textual relevancy. [6] presents a polynomial delay algorithm to generate ranked communities that are multi-centered subgraphs such that the distance between center nodes and each keyword node is no larger than a threshold. [7] prosed a polynomial delay algorithm to approximately find r-cliques with distances between keyword nodes no larger than r. In addition, some other works [9], [10], [11] studied diversified keyword search based on connected trees/subgraphs.

However, the above methods only focus on evaluating the distance between (querying) nodes to ensure the compactness of query results, but none of them consider density. Recently, two approaches start to consider the density for keyword search [12], [13]. However, [13] aims to maximize the contextual density based on the edge density, triangle density, and keyword density, which is inherently different from the truss in this work. Another work [12] aims to maximize the contextual cohesiveness of the k-core for a specific k [12], which is also different from the truss based model studied in this work.

Community Search Based on k-Truss. Community search based on k-truss model aims to find communities that maximize the truss value and contain a given set of query nodes. [19] constructs TCP-Index to support the efficient search of all the k-truss communities containing a given query node. [21] proposed a more compact index EquiTruss to accelerate the computation of k-truss communities for a query node. To avoid the free-rider effect, [20] studied the problem of finding truss with maximum truss value and minimum diameter, and provided an approximate solution. Two recent works [18], [28] studied attributed community search for given nodes and attributes, and proposed different ranking functions regarding the attributes. All these algorithms require a given set of query nodes, which cannot be directly adopted in this paper since the subset of nodes containing keywords to be included in the dense truss is previously unknown.

Moreover, there are also some related works on query independent community detection, which aim to detect maximal k-truss for each k. More information can be find in [25], [26], [27]. Note that above approaches are mainly sequential algorithms, and there is another line of work on the parallel searching over graphs including keyword search [36], [37], community search [38], [39], and other related structure search tasks [40], [41].

SECTION 7Conclusion
In this paper, we study the problem of finding cohesive subgraphs that are highly dense and compact for a given set of keywords. We model the cohesive subgraph based on k-truss model, and formulate the problem of finding cohesive subgraphs as minimal dense truss search problem for keyword queries. We tackle this problem by dividing it into two subtasks. One is finding the dense truss that maximizes the truss value containing keywords, and the other is refining the dense truss to obtain a minimal dense truss containing keywords. To deal with large networks efficiently, we design a novel hybrid graph indexing scheme KT-Index to keep the keyword information and truss information compactly and efficiently, and propose an efficient algorithm which carries search on KT-Index directly to find the dense truss without repeated accesses to the original graph. To extract minimal dense truss, we also develop a novel refinement approach by checking each node at most once based on the anti-monotonicity property of k-truss, and further optimize the refinement by batch based deletion, early-stop based deletion, and local exploration. Extensive experimental studies on real-world graphs show the effectiveness and efficiency of our approaches.