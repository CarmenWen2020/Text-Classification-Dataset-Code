There are a variety of underlying factors influencing what and how people communicate in their daily life. The ability to capture and utilize these factors enables the conversational systems to generate favorable responses and set up amicable connections with users. In this work, we investigate two major factors in response generation, i.e., emotion and intention. To explore the dependency between them, we develop a hierarchical variational model that predicts in sequence the emotion and intention to be conveyed in a response. The response can then be generated word-by-word based on the predictions. We also apply a novel adversarial-augmented inference network to facilitate model training. The experimental results demonstrate the effectiveness of the proposed model as well as the novel adversarial objective. The hypothesis that emotion shapes human communication behavior is also validated.
SECTION 1Introduction
Nowadays, conversational systems have emerged as a new channel for business. They allow enterprises to reach customers everywhere on auxiliary devices or platforms. Because these systems are able to engage with customers in a natural way, they are expected to help improve user experience and build strong connections with users.

With the advancement of neural networks, there has emerged a plethora of work in building such intelligent conversational systems based on the encoder-decoder architecture [1], [2], [3]. However, the responses generated from plain encoder-decoder models are often generic, uninformative, or improper to the conversation context. This indicates a need of additional information in dialog modeling and response generation. Indeed, there are various underlying factors influencing people’s communication in their daily life. The emotion and intention are two essential factors among them.

As studies have shown, it will improve user engagement and satisfaction [4] to endorse conversational agents with emotional intelligence, a critical kind of intelligence in humans. When friends tell us they are unhappy, people often feel more empathy toward them and ask about why [5]. Similar internal states like empathy are major contributors to emotional intelligence and these internal states motivate related behaviors in the communication. Take the two conversations in Fig. 1 for example. The person A invites B for dance and B shows different willingness under certain kinds of emotion. In the upper case, the conversation goes smoothly that two friends are dealt for the dance appointment. While in the lower case, friend A shows empathy towards B and ask what happens, in the perspective of being aware of B’s sadness. This example demonstrates that emotion often guides people’s thoughts, intention, the words, and in consequence, the outcomes of the conversation. Accordingly, an intelligent agent is expected to capture users’ emotions and to respond properly by phrasing its words in a more pleasing way. Previous works along this line that utilize emotion in response generation only utilize emotional information alone and incorporate the emotion vector directly into response decoding using gating mechanism [6], which might be improper as indicated by [7].

Fig. 1. - 
A motivating conversation example. Given the same dance invitation, the kind of emotion that person B is experiencing influences how he/she responses and how the conversation goes. As indicated in the brackets, the following responses are different in the emotion, the intention, and the content. The example is best viewed in color.
Fig. 1.
A motivating conversation example. Given the same dance invitation, the kind of emotion that person B is experiencing influences how he/she responses and how the conversation goes. As indicated in the brackets, the following responses are different in the emotion, the intention, and the content. The example is best viewed in color.

Show All

Motivated by this, we are interested in how emotion influences other underlying factors in conversation. In this paper, we take the particular factor intention to investigate, the other essential one that reflects what people think. In the example above, when A is curious about what happens on B, he/she raises a question rather than insists to tell the invitation details. The intention is almost the same as speech act characterized by [8] and is also known as dialogue act when it is applied in computational linguistics and dialog systems to recognize the speaker’s intention in retrieval-based or task-oriented dialogue systems [9], [10]. However, intentional information has rarely been considered when generating responses in open-domain conversational agents. And we study how emotion and intention influence response generation in a structural way.

We hypothesize that emotion has impact on intention and both of them regulate the response content. We capture the speaker’s intention and emotion with two discrete variables, and adopt a continuous variable representing variability in the content level similar as in [11]. In order to incorporate these variables into response generation models, we propose a novel hierarchical conditional model based on variational encoder-decoder (VED) architectures. VEDs are preferred because they allow modeling underlying factors and bring in diversity when generating responses. In our model, we first encode the input and history utterances, then predict the three variables sequentially by following the assumption that emotion→intention→content, and finally generating a response by sampling the words based on the variables. The hierarchical predicting procedure models the effect of emotion and intention, and encourages the context-level information such as the conversation topics to be directed by them. Moreover, the intention now is dependent on emotion, which will lead to more sensible and emotion-rich conversation. In this way, the content in the responses are expected to be more meaningful according to the whole context. We call the proposed model HINTE standing for response generation with Hierarchical INTention and Emotion prediction. To verify the hierarchical assumption, we implement several variants of the proposed model to realize different relations among the three variables.

To train the proposed hierarchical conditional variational model is non-trivial because of two reasons. The decoder tends to neglect the predicted variables when generating the responses, a.k.a., the vanishing latent variable problem as pointed out by [12]. Even the decoder is aware of the variables, it is still hard to guarantee that the generated responses satisfy the variables. Inspired by [13], we apply a variable-level adversarial learning method to monitor models’ conditional behavior. When the model generates responses that violate the condition, we enforce the model to improve itself by passing a negative signal to it. Specially, we augment the output of the inference network with an extra class to indicate whether the generated response is real or fake. This makes the inference network act as a discriminator, whose output is a signal for the model to generate more natural responses when conditioning on the context as well as certain intention and emotion. It is noteworthy that our adversarial learning is applied on variable-level instead of the generated-response level, and is thus more efficient and effective in monitoring the variable conditioning behavior. We conduct ablation studies to examine the benefits of the variable-level adversarial learning and compare it with two similar approaches [14], [15]. In summary, we highlight our main contributions as follows:

We incorporate the emotion and intention in response generation and propose a hierarchical conditional variational model, which is shown effective in the experiments.

We explore the dependency between emotion and intention in response generation and verify the hypothesis that human emotions shape conversation behavior by comparing several model variants.

We enhance the model with a novel adversarial-augmented inference network and empirically demonstrate its benefit on variable prediction using ablation studies.

We also compare the adversarial-augmented inference network with similar adversarial designs to show its novelty and difference.

SECTION 2Related Work
Our approach generates responses based on the encoder-decoder architecture by hierarchically conditioning on the predicted underlying variables. To regulate the conditional behavior, we propose a novel adversarial learning objective to train the model. In this section, we briefly review related work in this research field.

2.1 Generation-Based Approaches
Due to the massive data and the development of neural networks, researchers have tried to build up chit-chat conversational systems using generation-based approaches. The pioneer work is [16] that first formulates the response generation problem as Statistical Machine Translation (SMT), and reveals the feasibility of using massive Twitter data to build up a generation-based conversational model. Since then, the majority of generation-based models apply the encoder-decoder architecture [17] which allows flexible modeling of user utterance and history utterances. Because history utterances often provide abundant information for conversation modeling, researchers have proposed extensive context-aware conversation models. The simplest way is to combine history utterances with the current one as the whole input using concatenation [18], [19], [20], pooling [19], or weighted combination [21]. A more complicated way is to adopt hierarchical encoders by treating conversations as two-level sequences. [3] proposes a hierarchical encoder-decoder network (HRED) which builds a utterance-level context recurrent neural network (ContextRNN) based on a word-level RNN (EncoderRNN) to summarize the history information in dialogues. [11] extends HRED with a continuous latent variable to allow multi-modality and diversity in generation. Later, [22] improves VHRED with a separate word-level RNN for each dialog speaker, whose hidden states are then combined together to form the high-level dialog context. Based on the dialog context, the latent variable as well as an external label, [22] tries to generate responses that are more controllable.

Similar to [11], [22], our work also builds upon a conditional variational framework and generates responses based on dialog context and latent variables. The major novelty is that our work considers the dependency among the variables, which has been neglected before.

2.2 Diverse and Conditional Generation
Given a user input utterance, there often exists several proper responses. This is called the “one-to-many” problem in dialog response generation, and has been discussed in [23], [24], [25]. The diversity is resulted from a variety of influential factors. Attempts have been made to incorporate interpretable variables. [26] captures personalized communication styles by learning a persona embedding together with the conversation model. [27] introduces latent responding factors to capture the various language mechanisms. [28] endowed chatbots with a pre-defined agent profile obtained using crowdsourcing, and improves the naturalness and coherence of the generated responses. Another line of works attempts to incorporate topic information into chatbots to address the problem. While [29] and [30] injects conversation topics into Seq2Seq models, [31] detects topics as well as topic-specific keywords to design topic-based evaluation metrics.

In this work, we investigate the intention and emotion factors in response generation. Although intention information has been considered before [24], [32], their benefit has only been examined in task-specific dialog systems. Both [24] and [32] relies on the conditional variational framework, while [32] further improves the variable inference using semi-supervised learning and reinforcement learning. As to the emotion factor, [6] simply feeds the emotion information to the response decoder and enforced it to be expressed fully when generation comes to end. Our work differs from theirs in that we focused on open-domain response generation. Most importantly, we take into consideration both the emotion and intention factors, and explore the effect of emotion on intention in response generation.

2.3 Adversarial Approaches in Response Generation
Generative adversarial networks [13] have not shown remarkable progress in text generation as it has in vision field. It is non-trivial to to directly apply GAN in text generation, partially because text generation involves a series of sampling in discrete space, which impedes the gradient to be back-propagated. To tackle the non-differentiability issue, [33] adopts a soft-argmax function to approximate the generator’s output, and the discriminator is asked to score the generator on the sentence-level. [34] proposes a different way to sidestep the discreteness issue. They replace the discrete sampling procedure with an approximate embedding layer. Alternatively, [35] and [14] adopte policy gradient method to reward a generated sentence using the discriminator’s output, which enables gradients passing to the generator. However, this raises a new issue. The discriminator on the sentence-level is only able to give feedback after a full sentence is generated, which means the generator will only receive non-zero reward at the last step of the generation. To remedy the sparse reward issue, researchers have proposed several stepwise rewards, e.g., Monte Carlo Tree Search (MCTS, [36]), to assign credits at each generation step [14], [35]. Despite that these stepwise rewards somehow improved training stability, solely relying on them often affects model performances [37]. Upon this, [38] proposes to reveal discriminator’s hidden states to the generator, and demonstrates a noticable progress in generating long text.

[15] proposes to control the generated text by assessing its expressed attributes using an independent attribute-level discriminator. To address the discreteness issue, they also replace the sampled token with an softmax approximation vector, which is similar to [33]. In this work, we employ the principle of adversarial learning to regularize the dependency of variables in response generation. We augment the inference network with an extra class to indicate the plausibility of the generated responses considering the multiple variables. Our approach can thus be considered as multi-task learning that combines response generation, intention/emotion prediction, and fake response detection.

SECTION 3Background of Variational Methods
We first briefly introduce the background knowledge of the variational Auto-encoders (VAE) and its extension as variational encoder-decoders (VED). VAEs are originally introduced by [39] to encode data X (i.e., sentences) as latent random variables Z and to reconstruct the data based on Z with a generative model pθ(Z,X)=pθ(Z)pθ(X|Z). The likelihood can be computed by:
logpθ(x)≥Ez∼qϕ(z|x)[logpθ(x,z)qϕ(z|x)]=Ez∼qϕ(z|x)[logpθ(x|z)]−KL(qϕ(z|x)||p(z)).
View SourceRight-click on figure for MathML and additional features.

The right hand of the equation is called as the lower bound of the likelihood, where pθ and qϕ are often modeled by neural networks. The second term of the lower bound is the KL-divergence between z’s posterior and prior distributions, and the prior is usually set to standard normal or Gaussian. Therefore, to train VAE is to then to maximize the lower bound.

The most intriguing property of VAEs is the introducing of the latent variables. When applied to sentence modeling, it enables the underlying variables to capture variances in higher-level characteristics (e.g., topic or style) [12]. Inspired by [39], [12] first generates a continuous latent vector z from a multivariate Gaussian prior pθ(z), and then generates the entire sentence based on z by following the conditional distribution pθ(x|z):
pθ(x|z)=Πtpθ(xt|x1,x2,…,xt−1,z).
View Source

Despite its simplicity, VAEs are insufficient when applied to machine translation, text summarization, and dialogue systems. These tasks require model to “transform” source information X to a different target information Y. To this end, VAEs have been extended to variational encoder-decoder (VED) frameworks by building an extra inference network (also called as recognition model) on X, i.e., qϕ(z|y)=qϕ(z|Y(x))=qϕ(z|x).

Different from typical encoder-decoders that encode each x in the dataset X as a single fixed representation in the latent space, VEDs brings in the stochastic component z in the decoder side as pθ(y|x,z). Hence, by sampling different z, the generation procedure will vary a lot according to the same input x. Our approach is based on the VED architecture and is novel in the hierarchical variable prediction, combined with a adversarial-augmented inference network.

SECTION 4The Proposed Framework
To give a whole picture, we first sketch our approach by describing the overall framework and its components in this section, and present the two novelties in the following sections.

The task is to generate responses that are sensitive to the speaker’s underlying intention and emotion. Following previous work [40], [41], we model intention and emotion as two discrete variables zi and ze, which are indexed by the intention and emotion category, respectively. We denote ut as the current input utterance, and ct as the conversation context, i.e., ct={u1,u2,⋯ut}. Our task is to generate the response(s) R given {ct,zti,zte}. For simplicity, we omit the subscripts in the following sections.

4.1 Encoder-Decoder Framework
The basis of our approach is an encoder-decoder framework, which serves as the popular backbone for conversation modeling. The encoder transforms the input utterance into a vector representation, which is then fed into the decoder to generate the response word-by-word [1]. Usually, both the encoder and decoder are Recurrent Neural Networks (RNNs, [42]).

We choose bi-directional Gated Recurrent Unit (GRU, [43]) as our basic recurrent cells due to its advantage on learning long-term dependencies and on representing information from both past and future directions. Bi-directional GRUs are essentially a combination of two GRUs from two directions [44], one from the forward direction whereas the other from the backward direction. By characterizing information from both directions, it can be viewed as a summary of information from past and future directions.

Specifically, given a embedded utterance xt={x1,…,xLx}, the forward/backward GRU hidden state het at time step t is computed based on the the previous hidden state het−1 as:
het=(1−gt)het−1+gth~et,
View SourceRight-click on figure for MathML and additional features.where gt is the update gate which interpolates between het−1 and the current content h~et. Combined with a reset gate rt, these variables are computed as:
gtrth~et=σ(Wgxt+Ughet−1)=σ(Wrxt+Urhet−1)=tanh(Wxt+rt⊙Uhet−1),
View SourceRight-click on figure for MathML and additional features.where ⊙ represents an element-wise multiplication, and Wg,Wr,W,Ug,Ur,U are trained projection matrices. The elements of the gating vectors gt and rt are in [0, 1]. Then, the input utterance is represented by the summary of the hidden states as xc=ϕ(he1,…,heLx). The function ϕ can be average, max, concatenate, and so on. We typically form xc as the concatenation of the last hidden states of each direction.

Once the input utterance is encoded, the decoder generates the response utterance y=y1,…,yLy through another GRU by following p(yt|y<t,x)=softmax(yt−1,hdt,ct), where hdt is the hidden state of the decoder GRU. Typically, the decoder predicts the target word yt by performing a classification over a given vocabulary through the softmax function.

4.2 Overall Framework
To generate responses that are sensitive to dialog history as well as the intention and emotion information, we propose a hierarchical conditional variational network, HINTE, which consists of three parts: (1) History and Utterance Representation; (2) Hierarchical Intention and Emotion Prediction; (3) Conditional Response Generation, as shown in Fig. 2.

Fig. 2. - 
HINTE for variable response generation, where the three variables are shown by different shapes and colors. The lower shaded box gives the overview of the proposed framework, consisting of three main components. Especially for the hierarchical intention and emotion prediction component, we illustrate five representative dependencies among $\mathbf {z}_e$ze, $\mathbf {z}_i$zi and $\mathbf {z}_c$zc: (1) only $\mathbf {z}_e$ze and $\mathbf {z}_c$zc exists independently; (2) all the three latent variables are independent to each other; (3) a two-level prediction: while $\mathbf {z}_c$zc conditions on $\mathbf {z}_e$ze and $\mathbf {z}_i$zi, two discrete variables are independent; (4) a hierarchical prediction that mimics the contradicted hypothesis that emotion is depended on intention; (5) a three-level hierarchical prediction, which is our main assumption as denoted with a star. We omit some dependency in decoder side for simplicity. The figure is best viewed in color.
Fig. 2.
HINTE for variable response generation, where the three variables are shown by different shapes and colors. The lower shaded box gives the overview of the proposed framework, consisting of three main components. Especially for the hierarchical intention and emotion prediction component, we illustrate five representative dependencies among ze, zi and zc: (1) only ze and zc exists independently; (2) all the three latent variables are independent to each other; (3) a two-level prediction: while zc conditions on ze and zi, two discrete variables are independent; (4) a hierarchical prediction that mimics the contradicted hypothesis that emotion is depended on intention; (5) a three-level hierarchical prediction, which is our main assumption as denoted with a star. We omit some dependency in decoder side for simplicity. The figure is best viewed in color.

Show All

The proposed model takes as the input the history utterances word-by-word, and transforms the input using a latent a latent variable encoder-decoder architecture [11], where a word-level EncoderRNN encodes the current utterance and a utterance-level ContextRNN summarizes the dialog histories:
ut=EncoderRNN(x1,…,xt−1)(1)
View Source
ct=ContextRNN(u1,…,ut).(2)
View SourceRight-click on figure for MathML and additional features.In specific, the last hidden state of EncoderRNN is fed to the higher-level ContextRNN:
ct=f(ut−1,ct−1),(3)
View SourceRight-click on figure for MathML and additional features.where ut and ct are the hidden vectors of EncoderRNN and ContextRNN, respectively. Then, ContextRNN updates its internal hidden state until the current utterance is finished. As the conversation goes, the hidden state of ContextRNN stores the history information of what has been conversed, and finally summarizes the information from the history utterances into ct.

As introduced before, a DecoderRNN parametrized by pθ takes as input the history representation and the words generated so far, and emits the next word in a response following:
yt∼pθ(yt|ct,y1,…yt−1).
View Source

To enable more variations in the generation procedure, a latent continuous variable zc is often introduced to capture stochasticity during decoding. Then the generation formula for the DecoderRNN becomes:
yt∼pθ(yt|zc,ct,y1,…yn−1).(4)
View SourceRight-click on figure for MathML and additional features.

As mentioned in Section 3, zc is originally introduced for language modeling and sentence generation [12]. It has no explicit explanation and has been intuitively interpreted as high-level information such as topic, sentiment, style and syntactic features [11], [12]. The ambiguity in zc makes it difficult to be captured precisely. Moreover, if extra influential factors in the dialogue can be captured, it will provide more data for us to narrow down the ambiguity in the response to be generated.

In the light of this, it is insufficient to use zc alone when generating dialog responses. We thus explore two more discrete variables zi and ze, to carry out the intention and emotion information in response generation. All these latent variables are derived from the representations by EncoderRNN and ContextRNN. We investigate the dependency among these variables and develop a hierarchical prediction procedure to infer the latent variables in sequence, which will be described in Section 5.

After prediction, our model utilizes these types of information to generate the responses that are aware of the intention and emotion information. Conditioning on the predicted latent variables zi, ze, zc, as well as previous utterance and generated words, a DecoderRNN parametrized by pθ generates the next response by:
yn∼pθ(yn|zi,ze,zc,ct,y1,…yn−1).(5)
View SourceRight-click on figure for MathML and additional features.

At each time step n, the DecoderRNN generates the next target word tn in the response by:
Pθ(tn|y<n,⋅)=softmax(g(yn−1,dn,sn)),(6)
View Sourcewhere g(⋅) is a non-linear activation, dn is the decoding state for time step n, and sn is a summarization vector of relevant information from the source side provided by ContextRNN as well as the predicted variables.

This enables a hierarchical generation process that first samples the latent variables, and then decodes the response by taking into account the variables. Due to the learning difficulties, we also augment the inference networks with an additional class to discriminate whether the response is consistent with the predicted variables (See Section 6). This not only facilitates the training procedure but also enables HINTE to generate responses that are more natural.

SECTION 5Hierarchical Intention and Emotion Prediction
Our first contribution is the hierarchical variable prediction. Based on the history and current utterance representations, we aim to predict the intention and emotion to be expressed in the following utterance, and utilize them in response generation. The model is required to infer the utterance-level discrete variables as well as context-level continuous variable before generating the corresponding response. Hence, our model comprises both discrete and continuous variables. It is possible to define the model with any combination of these variables in auxiliary hierarchies.

5.1 Hierarchical Model
In multi-level variable models, the discrete factors are often on higher levels in the generation procedure [45]. Moreover, previous work in psychology and communication theory has assumed and empirically shown that intention and emotion are influential for the response content [40], [46]. Therefore, we put the discrete variables in the first-level of the prediction procedure:
zizezc∼p(zi|u1,…ut)∼p(ze|u1,…ut)∼p(zc|zi,ze,u1,…ut).
View Source

Note that there are alternative choices on how to model the relations between intention and emotion. They can be independent to each other as being predicted in parallel. It is also possible that one is dependent on the other and is predicted conditionally. Literature in emotional intelligence has found that emotion often guides one’s thoughts and ultimately influences the outcomes of the conversations [7]. Inspired by it, we assume that emotion puts effect on emotion and adopt a three-level hierarchical predicting procedure in the proposed model:
p(zi,ze,zc|u1,…ut)=p(zc|zi,ze,u1,…ut)p(zi,ze|u1,…ut)=p(zc|zi,ze,ct)p(zi|ze,ct)p(ze|ct).
View SourceRight-click on figure for MathML and additional features.

This is illustrated in Fig. 2 (5), where the two discrete variables and continuous variable form a three-level prediction hierarchy: ze→zi→zc. We verify this assumption by comparing with different model variants in the experiments. The five major variants are illustrated in the upper box in Fig. 2. Among these variants, (1)(2) stands for independent procedures with two or three variables considered, (3) a two-level prediction, and (4)(5) a three-level hierarchical prediction, where (4) is a contradicted version with our main assumption.

Based on the outputs of the generative distributions p(zi) and p(ze), the final intention and emotion classes zi and ze are predicted by sampling from the corresponding distribution.1 The dimension having the largest value will be more probably selected as the predicted class of the corresponding discrete variable. After sampling, we transform the predicted discrete variables into one-hot vectors and concatenate them with the continuous variable vector. The concatenated vector along with the output of ContextRNN are fed into the DecoderRNN. In this way, we generate responses by a hierarchical sampling procedure — sampling latent variables in sequence ze→zi→zc — and decoding responses by conditioning on these three variables.

To predict these three variables, we have three inference networks to approximate the posterior distributions of the three variables. Two are for the discrete variables and are denoted as qiϕ(zi|u1,…ut), qeϕ(ze|u1,…ut). We also denote as qcϕ(zc|zi,ze,u1,…ut) the Gaussian posterior of the continuous variable zc. In practice:
qeϕ(ze|u1,…ut)=Multi(oet)=softmax(Weoet)oet=MLPe(ut,hCt)qiϕ(zi|ze,u1,…ut)=Multi(oit)=softmax(Wioit)oit=MLPi(ut,hCt,ze),
View SourceRight-click on figure for MathML and additional features.where ot are joint representations of the inputs, and Multi() denotes a multi-layer neural network. Note that qϕs are only called during inference by producing samples to compute the gradients. They are not used to predict the variables when generating the responses.

5.2 Variational Bounds
To infer the latent variables, we maximize the variational bounds. For simplicity, we omit the subscript of ct to denote the conversation context as c. And we use zd to denote either zi or ze, and qd for qi or qe. In most cases, the labels for zd are not available, we have X={Wi}Ki=1. To learn the network parameters in the unsupervised manner, for any W=(w1,w2,…wN)∈X, we have the following variational bound:
logp(w1,…,wN)≥∑n=1N−KL(qdϕ||p(zd|c))−KL(qcϕ||p(zc|zd,c))+Eq[logp(wn|zc,zd,c)]:=−Vun.(7)
View SourceRight-click on figure for MathML and additional features.

Due to the high sample variance of the inference networks [32], however, it is often unstable to learn the latent variables based on the aforementioned learning signal. To remedy these issues, we introduce supervised learning to guide the learning of the latent variables. When the ground-truths of zd are available, we have (X,Z)={(Wi,Zi)}Ki=1. For any W=(w1,w2,…wN)∈X and the corresponding Z=(z1d,z2d,…zNd)∈Z, the supervised version of the variational bound is:
logp(W,Z)≥++:∑n=1N−KL(qc||p(zc|zd,c))Eqc[logp(wn|zd,zc,c)]logp(zd|c)=−Vsup.(8)
View Source

Based on the above variational bounds, we define the unsupervised version and the supervised version of the objective as Lsup:=EW,Z∼(X,Z)[Vsup(W,Z)], and Lun:=EW∼X[Vun(W)], respectively.

SECTION 6Adversarial-augmented Variable Inference
To train the model, we maximize the log-likelihood objective. However, this objective alone is not enough to guarantee that the generated responses to be satisfactory. They might look unrealistic to human even if the content is emotional and intentional. For example, the generated words are talking about something painful, while the predicted emotion category is happiness. Such inconsistency might be resulted from the free generation procedure, and the DecoderRNN will not be punished if it generated inconsistent responses according to the predictions. Such situation will be exacerbated when the decoder architecture is autoregressive, i.e., RNNs. As pointed out by [12], RNNs impose strong conditional dependencies between consecutive words. In response, the information from the underlying variables z becomes less impactful during learning.

Even worse, we observe the similar vanishing latent variable problem as in [12], i.e., the DecoderRNN may bypass the information provided by the latent variables during generation, when it has a direct access to the encoder. Theoretically, if qϕ(y|z) is able to perceive X (i.e., the information from the input side), then qϕ(y|z) might be learned almost same as qϕ(y|x). This is because that by considering the input information, the learning procedure will not focus on minimizing the KL-divergence term while maintaining the reconstruction loss, i.e., the first term in the lower bound. On the other hand, the underlying variables would not capture enough information during learning and thus are hard to learn well if not regularized.

These two problems are due to the lack of training on the conditional generation behavior. To mitigate these problems, we employ the idea of adversarial learning [13] to monitor the variable predictions. Intuitively, given a high-quality response, humans are able to deduce its underlying intention and emotion. In other words, the generated response is supposed to be consistent with the predicted intention and emotion.

Motivated by this, we augment the inference networks with an extra output class called “fake” to make them act as discriminators. As illustrated in Fig. 3, we take qi for example and describe its augmentation specifically. The augmentation for the emotion inference network qe is similar. Denoting the space of all possible intention classes as Zi, we define the augmented latent factor z∗i∈Zi∪{F} where {F} represents the generated (fake) sentence. Now we have qi(z∗i|c,w1,…,wn). The objective for the new augmented qi is:
Lqi:=EW,Z∼(X,Z)[∑n=1Nλi(zi)logqiϕ(zi|c,wn)+λi(F)∑n=1Nlogqiϕ(z∗i=F|c,w~n(zi))],(9)
View SourceRight-click on figure for MathML and additional features.where λi are the class weights for tackling unbalanced class labels. After augmentation, the inference networks qi and qe act as “discriminators” and response generation has to make use of their feedbacks. When the variables are classified into the “fake” category, the DecoderRNN (generator) should be punished. To do so, we derive an adversarial loss as:
Vadv(w1,…,wn)=Ezi[∑n=1Nlogqi(zi|w~n(zi),c)],(10)
View Sourceand defined by Ladv:=EW∼X[Vadv(W)].

Fig. 3. - 
The illustration of the inference networks with (bottom) and without (top) augmentation. The color bars represent the weight values predicted for each column in the discrete variable vectors, i.e., intention and emotion. After sampling, the value of the sampled column is set to 1 standing for the selected variable category, whereas others to 0. The figure is best viewed in color.
Fig. 3.
The illustration of the inference networks with (bottom) and without (top) augmentation. The color bars represent the weight values predicted for each column in the discrete variable vectors, i.e., intention and emotion. After sampling, the value of the sampled column is set to 1 standing for the selected variable category, whereas others to 0. The figure is best viewed in color.

Show All

This kind of variable-level adversarial losses from qi and qe are then added to the variational objective to bias the response decoder. The decoder’s objective becomes Lg=Lsup+λadvLadv or Lg=Lun+λadvLadv, where λadv is a weight tuning the constraints of the adversarial learning, and Lsup or Lun is the variational objective as defined in Eqs. (8) and (7). The objective for the continuous encoder qc remains the same. It is trained jointly with the decoder, using normal back-propagation, on both labeled and unlabeled data. Finally, we generate responses w~n(zi,ze) by replacing each argmax(x) word choice with softmax(x/α), where α is the temperature parameter.

Note that the way we employ the idea of adversarial learning is novel. Instead of introducing another independent discriminator, we modify the inference works, i.e., qi and qe, to make them discriminate the imperfection on the variable-level. Compared to previous work that applied adversarial learning on the response-level, the benefits of our design are two-folds: First, qi and qe are capable of detecting the response inconsistency according to the context and the given variables, and thus encourage the response generator to improve upon it. Second, since qi and qe share their encoders (utterance and history representation) with other components, it can be viewed as a regularizer for the representation, which facilitate representation learning implicitly. The proposed method to implement adversarial learning is more effective and efficient because it monitors the conditioning behavior on the variables directly, which is demonstrated by the experimental results in the following section.

SECTION 7Experiments
We conduct three sets of experiments. In the first set, we validate the effectiveness of the proposed model, HINTE, by comparing with four mainstream approaches (Section 7.4). In the second set, we implement nine variants of the proposed approach to verify the hypothesis that intention is dependent on emotion (Section 7.5). Because we apply the adversarial learning when inferring the latent variables, we also run the third set of experiments to investigate its benefits by comparing it with two different adversarial approaches (Section 7.6). Ablation and case studies are conducted in accordance.

7.1 Dataset and Experimental Setup
We examine our proposed approach on a large annotated open-domain dataset, DailyDialog [47], which contains 13,118 multi-turn dialogues that covers common topics in our daily life and are rich in intention and emotion. The dataset is publicly available.2 According to the statistics in Table 1, each conversation lasts about 8 speaker turns. In average, each utterance in the dataset contains 15 tokens.

TABLE 1 Basic Statistics of DailyDialog
Table 1- 
Basic Statistics of DailyDialog
More importantly, the DailyDialog dataset is appealing in that the utterance of each speaker turn is manually labeled with the intention and emotion information. The intention has four classes following the dialog act annotation criteria [48]: inform, question, directive, commissive. The emotion is labeled with seven categories following [41]: anger, disgust, fear, happiness, sadness, surprise, others. These make the dataset suitable for training conversational models.

To the best of our knowledge, DailyDialog is the only dataset applicable for our task to evaluate the proposed hierarchical response generation model. Although other datasets are often used to train conversational models, they lack the annotations for the intention and emotion information.3 We adopt the standard segmentations of Dailydialog dataset as in [47]. The dataset has been randomly separated into training/validation/test sets with 11,118/1,000/1,000 examples. We use a vocabulary size of 25,000 and map all the out-of-vocabulary (OOV) words to a special token UNK. The word embeddings are set to 300-dimension and are initialized with Word2Vec embeddings trained on the Google News Corpus4. During training, the embeddings are normalized after each epoch.

7.2 Compared Models
To validate the effectiveness of HINTE on response generation in chit-chat conversations, we compare with the following models:

Enc2Dec-Attn [49]: It is the attention-based encoder-decoder approach, which is a widely adopted baseline. Both the encoder and decoder are vanilla GRUs. In this model, history utterances are not incorporated. This bare-bones model acts as a baseline to show the performance of encoder-decoder conversational systems.

HRED [3]: This model considers conversation history in a hierarchical way, where a high-level RNN is built upon utterance-level RNN to capture conversation states.

Transformer [50]: It is a state-of-the-art text generation model. We adopt the implementation here.5

VHRED [11]: This is an enhanced version of HRED, which incorporates a continuous variable to encourage diversity in the generated response.

SPHRED [22]: This is another enhanced model of HRED that contains two status RNNs of utterances, each for one speaker. SPHRED generates the next response based on the dialog context, a stochastic latent variable and an inferred or known label (discrete). We adapt it to rely on an extra discrete variable.

For fair comparison, we incorporate the label information during the decoding processes in all compared models. The intention and emotion labels are transformed into one-hot vectors, then concatenated with contextual vectors to feed into the decoders. All the word-level encoders are 1-layer GRU with 512 hidden neurons. And the context-level RNNs in HRED [3] and VHRED [11] are all 1-layer bi-directional GRU of 1,024 hidden units. All the models are implemented by ourselves using TensorFlow [51]. The mini-batch size is set as 128, the learning rate is fixed as 0.0002, and we clip gradients with norms larger than 0.5. Models are trained using Adam optimizer [52]. We tune the parameters on validation set and report the performance on test set.

7.3 Automatic and Human Evaluations
To evaluate our approach and the compared models, we adopt two kinds of automatic evaluation metrics to examine the quality of the generated responses:

BLEU-n [53]: The BLEU scores indicating how much the generated responses is overlapped with the ground-truth response;

Distinct-n [23]: The distinct grams generated in the responses are indicative for the informativeness of the responses. The Dist-1 and Dist-2 scores, for unigrams and bigrams, are the ratios of types to tokens. This kind of diversity measurement is initially proposed to examine the “generic response problem”, which is then widely adopted in following work.

As studied by [54], [55], the automatic BLEU scores do not often correlate well with the human judgments when evaluating conversational models. To better understand the model performances, we also conduct human judgments on 100 random test samples. Each sample contains the input utterance and the response generated by the different models (5 responses in each sample). The samples are distributed to three annotators who have linguistic background. Note that these annotators are unaware of which model the response is from. Following [35], we ask the annotators to rank the generated response considering the following 4 aspects:

Relevance: how likely the generated response is related to the input utterances.

Fluency: measures the readability of the generated responses.

Diversity: whether the generate responses are informative or dull. Low diversity will be given to the generated responses containing repetitive pieces.

Emotion and Intention Appropriateness: whether the intention and emotion expressed in the responses are appropriate according to the certain context.

Note that when the generated responses overlap with each other for a long piece of text, the annotators are allowed to give them the same ranking. The higher rank means the better. We report the experimental results in Table 2.

TABLE 2 Automatic Evaluation and Human Judgment Results
Table 2- 
Automatic Evaluation and Human Judgment Results
7.4 Experimental Results
We first examine the significance of latent variables in conversation modeling. As shown in Table 2, the models in the first block (the first three rows) perform worst than the models in the second block (the last three rows) on the majority of the metrics. Although Transformer even beats VHRED and SPHRED on BLEU-1 and BLEU-2 scores, it obtains very poor Distinct-1 score. It is because that the generated responses from Enc2Dec-Attn and Transformer often contains series of common words like “i don’t”, “thank you you you”, “I like like about”. These common but uninformative words greatly contribute to the high BLEU scores achieved by Transformer. The contradiction between the BLEU scores and human judgments is consistent with the claims from [55], [56] that BLEU-n is not a good metric to evaluate conversational models.

According to Distinct-1 and Diversity metrics, the disappointing performances of Enc2Dec-Attn, HRED and Transformer are strong evidence that they tend to generate “generic” and boring responses [23], [29], e.g, “I don’t know” that are universally relevant to most input utterances. This problem is possibly due to the one-to-many relations between a given input utterance and its possible, multiple proper replies. By utilizing more information like the intention and emotion labels, latent variable models are able to reduce the number of the plausible replies by learning more compact and precise representations for the responses to be generated. As a result, the responses that comply more with the emotion and intention in the input utterance will be more favored. Because Enc2Dec-Attn and HRED only feed the variable information to the decoder without considering them when context modeling, their experimental result empirically supports our research motivation that, it is necessary to model influential latent variables into chit-chat conversation models.

Since all other three models are variational models that introduce latent variables, we then compare them to find which one captures the variables more effectively. By examining the last three rows in Table 2, we can see the differences among VHRED, SPHRED, and HINTE. Although similar in modeling history information, the proposed HINTE differs VHRED and SPHRED in the way it utilizes the intention and emotion information. The compared VHRED and SPHRED simply concatenate the intention and emotion information in parallel, and the roles of the variables are independent. Thus, these two models have difficulties in separating the information from different variables during learning. In contrast, our HINTE utilizes the underlying variables in a hierarchical way to let emotion and intention regulate the content variable.

Overall speaking, HINTE and SPHRED are the best and second best models. They are the only models that utilize the external labels to learn the variable distribution. This proves the necessity of learning signals for training variational conversational models. Variational inferences suffer from high sample variance. During the early stage of model training, the insensible sample will prevent the model from obtaining reliable training signals. The highly unstable training procedure will then lead to poor model performance. As also pointed by [15], [32], it is critical to adopt semi-supervised learning [57] to facilitate variational model training. We thus examine the HINTE performance under different scales of labeled data. We randomly remove different ratios of data labels as unsupervised set, and training HINTE under semi-supervised learning paradigm based on Eqs. (8) and (9). As shown in the last block in Table 2, the model performance degrades as the ratio of labeled data decreases. In addition, the effect of variable labels in terms is more obvious when the ratio of training data is under 20 percent. Although the improvements are limited when more than 20 percent data are available, the performance of HINTE (40 percent) is still comparable to SPHRED trained on the 100 percent labeled data.

Drawing on the highest scores achieved by HINTE, it indicates the effectiveness of its hierarchical process in HINTE in dialog modeling and response generation. In general, the proposed HINTE outperforms the compared models in terms of all metrics. Especially, it is shown that HINTE brings the largest improvement in terms of Diversity and Appropriateness without sacrificing Relevance and Fluency. We will show some case analysis in the next section.

7.5 Hypothesis Validation and Ablation Study
In the second set of experiments, we aim to verify if the novel parts in our model are crucial. There are two novel designs in HINTE: (1) the prediction hierarchy to carry out the dependency of emotion→intention→content; (2) the variable-level adversarial learning objective to facilitate conditional behavior training. We implement three groups of nine model variants and compare them through automatic and human evaluations. They are:

HINTE-EC: only emotion and content variable are taken into consider, and they are independent to each other. It is can be seen as a simplified version of VHRED being compared in the first set of experiments. This setting is illustrated in Fig. 2 (1).

HINTE-IC: a similar setting with HINTE-EC with intention and emotion information being concerned.

HINTE-I: all the three variables, i.e., emotion, intention and content, are independent to each other. It is equivalent to VHRED being compared in the first set of experiments. This setting is illustrated in Fig. 2 (2).

HINTE-E-C: a two-level condition setting with emotion and content being considered. In this setting, emotion directly influence the content.

HINTE-EI-C(S): a two-level version of the proposed approach where content is conditioned on emotion and intention. Meanwhile, the feed-forward layers in the two inference networks of emotion and intention are shared.

HINTE-EI-C(U): a setting similar with HINTE-EI-C(S), only different in the feed-forward layers are unshared. Both of HINTE-C-S and HINTE-C-U are non-hierarchical, where emotion has no effect on intention. They are illustrated in Fig. 2 (3).

HINTE-I-E-C: a hierarchical version where the prediction is proceeded as intention→emotion→content. This is a controversial hypothesis as illustrated in Fig. 2 (4).

HINTE-E-I-C: our primary model comprising the hierarchical prediction as a three-level sampling ze→zi→zc. This mimics the main assumption. Note that the feed=forward layers are also unshared in this setting, and the adversarial loss is ablated. This is illustrated in Fig. 2 (5).

HINTE: a setting adding the adversarial loss to the hierarchical conditional version HINTE-E-I-C, which is our full model as described in the previous section.

The differences in these model variants are summarized in Table 3. We also conduct automatic evaluations on them. As to human judgments, it is difficult for the annotators to rank among nine generated samples. Instead, in this set of experiment, they are required to rate the response in terms of the four aspects. The results are shown in Table 4.

TABLE 3 Description of the Model Variants To Be Compared
Table 3- 
Description of the Model Variants To Be Compared
TABLE 4 Hypothesis Validation Results
Table 4- 
Hypothesis Validation Results
By comparing the first group of models (the first three rows) with other groups, we can see that the three independent models, HINTE-EC, HINTE-IC, HINTE-EIC generate responses that are very poor in terms of Fluency, Diversity and Appropriateness. Although HINTE-EIC performs a little bit better, it still lags far from the models in the conditional and hierarchical groups. The key difference is that the latter two groups of models allow the emotion and intention variables affect the high-level content variable. The results validate that the underlying factors, intention and emotion, are influencing the content in responses and even the communication way of the conversational agents. The improvements can also be resulted from the modeling mechanism on the underlying factors. In addition, considering the difference between the performances of HINTE-EC and HINTE-IC, and comparing them with HINTE-I, we are able to draw inspiration that intention and emotion are two complementary factors.

In the second conditional group (the following three rows), it is noticeable that although HINTE-EI-(S) and HINTE-EI-C(U) enjoy the “same” two-level prediction procedure, the response generated by the model sharing the representations are unfavorable. By both automatic and human evaluation metrics, the conditional model HINTE-EI-(S) performs even worse than the independent model HINTE-EIC. We conjecture that it is notorious to share the feed-forward layers in the inference networks for the emotion and intention variables. This does entangle the representation of these two different variables and confuses the inference networks to make precise predictions. In other words, HINTE-EI-C(U) is better in disentangling the intention and emotion information.

Notably, HINTE-E-I-C and HINTE in the last group are two best models among all the nine variants. They two achieve the best and the second best automatic scores, and are more preferable by human evaluators. We attribute this to the hierarchical hypothesis in these two variants where emotion and intention influence the content in a hierarchical way that emotion shapes intention. This is different from the second group of models whose emotion and intention are in the same-level to control the response generation. The two-level conditional models neglect the emotion’s guidance on the intention, and thus may lose the information from emotion when predicting the intention. It is also intuitive that emotion shapes conversation intention and behaviors. In daily life, we might terminate a conversation if we get angry even though we have prepared something to say. As argued by [7], when experiencing a mood, individuals often come up with particular intentions or thoughts, some of which are regulatory and controlling the information flow, i.e., cutting off experience or stopping conversation. This is also consistent with later work in psychology and communication theory [46], [58].

7.6 Studies For Adversarial-Augmented Variable Inference
By comparing HINTE-E-I-C and HINTE in Table 4, it is shown beneficial to introduce adversarial learning in response generation. As analyzed before, the variable-level adversarial learning facilitates learning effective representation to predict the latent variables. In order to quantitatively measure how greatly the adversarial learning contribute to the predictions, we examine the effect of the coefficient λadv. By tuning its value, we compute the priors (i.e., p(z)) and the posteriors (i.e., q(z|x)) of the emotion and intention variables and compare them with the ground-truth labels. Intuitively, the posterior accuracies will be largely improved due to the observe ration of the input.

The results are illustrated in Fig. 4. The best performance is achieved when λadv is set to 0.4. When the value is too small, the adversarial learning objective does not count. It is also not desired to increase the value too much which might let the gradient from the adversarial learning dominate the whole learning procedure and results in prediction regardless of the conversation pattern.


Fig. 4.
The effect of λadv for variable-level adversarial learning.

Show All

One remarkable thing in Fig. 4 is that while the prior accuracies of the intention variable is almost the ideal value 0.5, the prior accuracies of the emotion are almost the same with its corresponding posteriors. This is resulted from the differences between the distributions of the two variables in the dataset, i.e., the intention and emotion distribution in the DailyDialog. As summarized in [47], the distribution of intention labels are healthily balanced. Hence, the learning on the intention variable is more effective. Comparing the last two ticks, there is a significant improvement of the posteriors accuracies over the priors. On the contrary, the emotion distribution is more heavily imbalanced. From the statistics in [47], it is about 80 percent of utterances are labeled as the category of {Other}, which impedes the learning for other categories. The imbalance problem on the emotion category indicates that it might be improper to categorize the dataset following the the “BigSix Theory” [41], which is initially proposed to account for all primary and universal emotions among human beings. However, it does not mean that these six primary emotions are equally distributed in the daily communication. We leave it as the future work to re-categorize the dataset to handle the imbalance problem.

The second objective of this section is to discern the benefits of the adversarial learning proposed in this work from those in previous work. In this work, we impose the adversarial learning objective through modifying the inference networks, which is assumed to be more effective and efficient. Previously, the idea of adversarial learning have been introduced in text generation in two typical ways:

HINTE-R [14]: In the standard adversarial learning [13], an independent discriminator D is required to judge whether the given text is a true data sample, or a fake sample generated from the generator G. To implement it, we train an independent Convolutional Neural Network (CNN) [59] as the discriminator D, and replace the adversarial loss in HINTE with the CNN prediction output. The response generator G is then trained using the REINFORCE-like objective Lg=∑tD(yt)∗logp(yt|y<t) [60]. In this way, the adversarial learning is applied on the response-level, and we denote this compared model as HINTE-R.

HINTE-C [15]: The second design we compare is initially proposed to control sentiment style in text generation. In [15], an independent discriminator is introduced for each latent discrete variable, and measures how well the generated samples match the desired variables. We denote this variant as HINTE-C. The difference between HINTE-C and our HINTE is that the discriminator in HINTE-C is independent, while the “discriminator” in HINTE is implemented by modifying the inference networks.

Because HINTE-R, HINTE-C and HINTE share the same generator architecture, their difference only lies in the adversarial learning part. For comparison purpose, we also include HINTE-E-I-C without adversarial objective as a barebones model. To evaluate their performances, we report the perplexity (PPL), KL cost, BLEU and Distinct scores, as well as prediction accuracies in Table 6. Ideally, a high-quality response generator should have low PPL, non-trivial KL cost, meanwhile accurately predicting the variables.

TABLE 5 Case Study
Table 5- 
Case Study
TABLE 6 Comparison Results on Different Adversarial Learning Designs
Table 6- 
Comparison Results on Different Adversarial Learning Designs
Obviously, HINTE-R equipped with the response-level standard adversarial learning performs the worst. By comparing it with the barebones model HINTE-E-I-C, adding the response-level adversarial learning drastically degrades the model performances. The reasons are complicated. First, as the reward in HINTE-R is only observed once the generation is complete, it is hard to assign credits when two generated responses share the same prefix. As a result, applying standard response-level adversarial learning will make training even unstable, which explains the worst PPL of HINTE-R. Second, as indicated by the tiny KL cost (almost 0), HINTE-R has great difficulties in capturing latent variables, which is a common issue in training variational model. As pointed out by [12], the collapse of the KL loss is resulted from ignorance on latent variables when generating the responses. The decreased KL cost from HINTE-E-I-C to HINTE-R reveals that, the response-level adversarial learning intensifies the vanishing latent variable problem and accelarates its falling back to conventional language model. The reasons are complicated. In HINTE-R, the reward is given on the response-level regardless of the variables. When the latent variables are overlooked by the response generator, the discriminator will not punish it as long as the generated response is plausible in general semantics. Last but not least, we find the accuracy of the CNN discriminator in HINTE-R is very high, which quickly achieves 0.97 after 2 epochs training. The discriminator is too strong for the generator to fool, which is undesired for the adversarial game to continue [13]. Our results are consistent with previous findings that it is super-easy to tell the response on the whole-text level [34], [38], [61].

The variable-level adversarial learning sidesteps this issue since it is harder to classify the latent variables from the generated responses. Despite the difficulty, both HINTE-C and HINTE achieve satisfying prediction accuracies, as shown in Table 6. Combined with their sensible KL scores, we believe that applying adversarial learning on latent variables is beneficial in learning meaningful representations for latent variables. Although HINTE-C and HINTE achieve comparable performances, they two are different in several ways. In HINTE-C, two independent discriminators, each for one latent variable, are trained simultaneously with the response decoder. As the number of considered latent variables grows, the model parameters increase and the training signals within the GAN game become more variant. We attribute these factors to its slightly higher PPL and smaller KL. In contrast, the “discriminator” in our HINTE is implemented by augmenting the inference networks. qi and qe are not only trained on real utterances with different intention and emotion, but also trained on generated responses. This kind of data augmentation mitigates the over-fitting problem in qi and qe and thus improves estimations for latent variables. The proposed adversarial-augmented inference network is analogous as a expressive powerful and estimation for the posterior distribution [62].

Actually, the prediction accuracies heavily directs the conversation and decides the response content, which are especially important when modeling multi-turn conversations. To illustrate this, we also evaluate HINTE-R and HINTE by manually assessing their generated responses. As shown in Table 5, HINTE-R and HINTE are required to generate multiple consecutive responses given a context. The first column gives the original test context as the input utterances. Given U1, the two models generated responses that are then combined with U1 as the history context for the next turn. The labels in the brackets are the annotated/predicted emotions and intentions. From the first case, the best model HINTE predicts the emotion as happy and expresses its willingness on having food, which encourages the following happy discussion on food choice. Based on the emotion, HINTE also predicts the intention for the last response as commissive. This leads to a pleasant meal agreement. On the contrary, HINTE-R diverges to generate responses (“reservation”) that is often related to restaurant booking. This is because HINTE-R predicts improper intentions directive and commissive which often serves for offering and accepting the help. Similarly, HINTE predicts the variables as (curious, question) which leads to active conversation by caring for the user. These two cases also demonstrate the interpretability of our model.

7.7 Studies for Variable and Word Sampling
There are two technical designs in our approach also influential for response diversity: the sampling method for the latent variables, and the sampling parameter for the word decoding. Instead of stochastically sampling zi and ze, these variables can be deterministically obtained using argmax operation. The other impactful parameter is the temperature α during word decoding. For better understanding, we compare different settings regarding to these two factors.

By comparing the PPL scores in the two sections in Table 7, we can see that models using stochastic sampling (the last two rows) are trained more sufficiently than their deterministic counterparts (the first three rows). Observing that the latter ones often struggled to converge, we hypothesize that the deterministic models will get sharper signals which lead to unstable training procedure. The temperature also counts. The best performance is achieved when we adopt a dynamic strategy. When the training begins, we set the temperature to be large to encourage the model being sensitive and diverse. Gradually we select a lower temperature when more confident predictions are needed.

TABLE 7 Comparison Results on Different Sampling Method and Parameters
Table 7- 
Comparison Results on Different Sampling Method and Parameters
SECTION 8Conclusions and Future Work
We investigate two major underlying factors, i.e., emotion and intention, in open-domain response generation. Unlike existing work that consider them independently, we assume that emotion has impact on intention, and develop a hierarchical conditional variational model, HINTE, to predict them in sequence. To better control the conditional generation behavior, we employ the principle of adversarial learning to regulate the generated response comply with the predicted emotion and intention. Through both automatic and manual evaluations, we demonstrate the effectiveness of the proposed HINTE. By comparing nine variants of it, we validate the hypothesis that emotion influences intention as well as the benefit of adversarial learning. Our framework HINTE is flexible to incorporate various information in response generation. In the future, we plan to apply the proposed framework to explore more influential factors.