Mobile edge computing (MEC) is rising as a key technology for computation-intensive and delay-sensitive applications. Many works have focused on MEC, but most of them only consider unicast scenarios, and ignore multicast issues. The reason is that MEC aiming at personalized computing of users conflicts with multicast which demands the same data stream. This makes MEC and multicast seem inconsistent. However, in fact, there will be lots of services, whose computation process is different but the result may be same (e.g. media push), which can greatly benefit from multicast over MEC and make the combination of multicast and MEC meaningful. In this paper, we first consider challenges and propose multicast-aware resource allocation for MEC, which jointly optimizes computing and caching in multicast scenarios. We formulate the problem by considering user request, network communication, service caching and service computing. But this model is knotty because it is an optimization problem with mixed discrete and continuous variables. Besides its optimization objective is the average value over a long time. Considering the complexity, we first transform the problem into an online optimization, which jointly minimizes the average time delay and energy consumption, by stochastic optimization. Then we separate the discrete variables and continuous variable, and decompose the problem into two subproblems. By solving subproblems, an efficient online algorithm called MA-ECC is proposed. Finally, we compare it with other three baseline methods, and result shows that MA-ECC can effectively reduce service latency while still keeping energy consumption low.

Previous
Next 
Keywords
Mobile edge computing

Multicast

Stochastic optimization

Resource allocation

1. Introduction
Many new computational-demanding services, such as video codec, face detection, etc. are emerging and becoming essential elements in our life. While enriching our daily life, they also causes more consumption of computing, energy and other resources for mobile devices. To address this issue, researchers proposed cloud computing which can effectively reduce the computing pressure of mobile devices by offloading computing services to remote cloud servers (Pan, 2021). However, cloud computing tends to have high service delay because of long transmission from users to cloud servers, and it is hard for the cloud servers to support computing demand of all devices. In this context, mobile edge computing (MEC) (Hai et al., 2020) was proposed to achieve lower service delay by moving computing tasks from the remote servers to the edge base stations which are closer to users.

An important avenue for research in MEC is computing resource allocation in heterogeneous cellular networks (Wang et al., 2017a, Jošilo and Dán, 2019, Saleem et al., 2020, Xiaolong et al., 2019, Guo et al., 2019, Wei et al., 2019). The reason is that unlike the cloud, computing resource of base stations (BSs) is limited, implying that computing resource allocation affects significantly MEC efficiency. In addition, BSs need to cache related databases/libraries before providing edge computing (Shashwat et al., 2020, Coutinho and Boukerche, 2020, Wu et al., 2019, Rainer et al., 2017, Li et al., 2020a). Consequently, resource allocation with joint optimization of computing and caching is of double importance for MEC.

Although some excellent works have focused on computing resource allocation or service caching, they have usually optimized one these aspects only. Moreover, existing works studied computing and caching resource allocation in unicast scenarios, but have not focused on multicast yet. Multicast technology, which effectively utilizes the intrinsic broadcast nature of BS channels, is an efficient way to deliver identical content to satisfy multiple requests (Araniti et al., 2020). At first glance, MEC and multicast seem to be two orthogonal research directions, focusing on personalized processing and same content transmission, respectively. However, we discover that many MEC services can benefit from multicast.

For example, in live video case, the applications analyze packet loss, available bandwidth and other factors to provide appropriate bitrate version for users by video codec. Considering that the number of video versions (e.g. 360P, 720P, 1080p, etc.) is limited, users with similar link qualities will get the same bitrate version (Jiang et al., 2019). Therefore, we can encode at edge base stations and transmit the same version to users with similar link qualities by multicast to improve transmission efficiency, which is an effective combination of MEC and multicast. Another relevant example involves media push. A typical solution is that users with similar interests are allocated to the same group and are pushed the same content (Lu et al., 2018, Desogus et al., 2021). If we can joint MEC and multicast, edge base stations analyze user interests and allocate users with similar interests to the same group, then use multicast to push same contents to users in same group, which will greatly improve transmission efficiency. Extrapolating these examples, note that these services have different computation processes, but may result in the same outcome, which means multicast is of high potential in MEC. Therefore, it is valuable to study the resource allocation with edge computing in multicast scenarios.

The multicast-aware resource allocation with joint optimization of computing and caching faces many challenges. First, computing, caching and multicast are highly coupled and interacting with each other, so they should be addressed jointly. There are two variables in this problem, caching decision which is a zero–one type integer, and computing allocation decision which is a continuous variable. The problem is hard to be solved because of a mixture of discrete variable and continuous variable, which makes some methods such as reinforcement learning inappropriate.


Table 1. Comparison of existing works.

literatures	Service
computing	Service
caching	Communication
method	Long-term
average	Energy
consumption
(Jošilo and Dán, 2019)	Yes	No	Unicast	No	No
(Xiaolong et al., 2019, Guo et al., 2019)	Yes	No	Unicast	No	Yes
(Shashwat et al., 2020)	No	Yes	Unicast	Yes	No
(Coutinho and Boukerche, 2020, Wu et al., 2019)	No	Yes	Unicast	Yes	No
(Rainer et al., 2017, Li et al., 2020a)	No	Yes	Unicast	Yes	Yes
(Wei et al., 2019, Yang et al., 2016)	Yes	Yes	Unicast	Yes	No
(Zhang et al., 2019)	Yes	Yes	Unicast	Yes	Yes
Our MA-ECC	Yes	Yes	Multicast	Yes	Yes
Second, the collaboration between edge base stations and cloud servers should be considered. As we all know, the limited resources of the edge base station make it impractical to provide all services. In order to provide high quality services, cloud servers are needed besides edge base stations. But, different services require different aspects of resources (Wei et al., 2018); for instance face recognition focuses on computing resources, but VR needs more storage space. Therefore, how to coordinate the tasks allocation between edge and cloud is a big challenge.

Third, network variants are highly dynamic and stochastic. We should use long-term average performance to evaluate an algorithm. However, this usually needs future information which is hard to be obtained in dynamic network. So, it is very challenging to optimize long-term average performance.

In this paper, we addresses multicast-aware resource allocation with joint optimization of computing and caching. The Multicast-Aware Caching and Computing algorithm (MA-ECC) is proposed to enable efficient allocation of resources. The main contributions of this paper are as follows:

(1)
We discover the link between edge computing and multicast, and innovatively propose the multicast-aware resource allocation problem, which is formulated as minimization of service latency under energy consumption constraints.

(2)
Due to the lack of future information, we transform original problem into per time-slot optimization. Considering the mixture of discrete variable and continuous variable, the problem is further decomposed into two subproblems: caching decision and computing resource allocation. Then, we solve them by employing implicit enumeration method and Karush–Kuhn–Tucher (KKT) solution, respectively. Finally, a novel efficient algorithm, MA-ECC, is proposed to solve the joint optimization problem.

(3)
Furthermore, we prove the performance of MA-ECC theoretically and design extensive simulation experiments to verify it. Results show that MA-ECC performs well in terms of both service latency and energy consumption.

The paper is organized as follows. The related works are reviewed in Section 2. The system model is introduced in Section 3. We formulate the problem in Section 4. Section 5 decomposes the problem into two subproblem and presents the designed MA-ECC algorithm. Section 6 discusses the simulation results. Finally, Section 7 is the conclusion.

2. Related work
Avoiding long-distance transmission from users to cloud servers, MEC can effectively reduce the service delay and relieve the backhaul link pressure, which is becoming an important computing paradigm. Many scholars have conducted research on MEC. The authors of Wang et al. (2017a) transform the problem into a distributed convex optimization and solve it based on alternating direction method. Jošilo and Dán (2019) designs a decentralized computation offloading algorithm by game theoretical and proves the upper bound of algorithm. In Saleem et al. (2020), authors study the MEC in Device-to-Device scenario. They propose an integrated framework for computation offloading and interference management to optimize service delay. Considering the limited power of mobile devices, (Xiaolong et al., 2019) formulate the computation offloading to a mixed-integer problem and reduced the energy consumption of communication in MEC. In Guo et al. (2019), author propose an energy-efficient computation offloading strategy, which contains three step of computation offloading selection, clock frequency control and transmission power allocation, to shorten the service delay while reducing energy consumption. Considering the stochastic properties of service requests, the authors of Wei et al. (2019) study the stochastic resource allocation strategy by deep reinforcement learning. These works are focus on the computation offloading, but does not give the computing resources allocation scheme for each service.

In terms of edge caching, authors (Shashwat et al., 2020) investigate the content caching problem for the adaptive streaming. The caching management in mobile network scenario is studied in Coutinho and Boukerche (2020). They propose a mathematical framework which considers content request characteristics and content catalogs to reduce delivery delay. Authors of Wu et al. (2019) provide a cooperative video caching mechanism by jointly considering users’ request similarity, users’ movement behavior and users’ demand, which greatly improves quality of experience. In Rainer et al. (2017), authors improve the hit ratio by predicting the popularity of contents. In Li et al. (2020a), authors improve the hit ratio by proposing a cache prefetching strategy. They use Bayesian network theory to select contents. These works mainly focus on content caching scheme and not consider the joint optimization of caching and computation.

To enhance video rate adaptation, a joint optimization of computing and caching is proposed in software-defined networks (Liang et al., 2018). In Yang et al. (2016), authors research a joint caching and computing problem for adaptive bitrate (ABR) delivery, which considers the constraints of both storage space and computing capacity. The most related work is (Zhang et al., 2019). Authors formulate the joint optimization of content caching, computation offloading and computing resource allocation as an mixed integer nonlinear programming, and solve it by generalized benders decomposition method. But there are several differences to our work. First, while unicast scenario is considered in Zhang et al. (2019), we focus on a multicast scenario. Second, while only the computing delay is optimized in Zhang et al. (2019), we optimize the service latency which contains computing delay and transmission time. Third, while the computing tasks are assumed to be divisible in Zhang et al. (2019), we consider they are the smallest processing unit. The comparison of existing works with our work is shown in Table 1.


Table 2. Mathematical notations.

Notation	Explanation
The set of base stations
Storage space of 
Computing capacity (maximum frequency) of base station 
Multicast channel gain of 
Multicast power of 
Noise power of 
Unit energy consumption of 
Effective switched capacitance of 
The set of services
Transmission data size of service 
Storage space requirement of service 
Computing resource requirement of service 
Computation resource allocation vector
Caching resource allocation vector
The limited power of 
Time delay of 
 for transmit service 
Energy consumption of base station 
 for transmit service 
Energy consumption of base station 
 for caching service 
Computation time of 
 for service 
Energy consumption of base station 
 for computing service 
The request to 
 for service 
The actual service volume of  in 
3. System model
This section proposes the system model for multicast-aware joint edge computing and caching resource allocation. The scenario is described first and then the request model, communication model, caching model and computation model are introduced. Table 2 lists the mathematical notations.

3.1. Scenario description
A heterogeneous cellular network containing a MBS and  SBSs is considered, as shown in Fig. 1. Each BS is equipped with computing capabilities and storage space to provide computing services. SBS coverage areas may be joint, but user access is not the scope of this paper. Therefore, we assume users only request to one SBS, as presented in literature Zhou et al. (2017) and Xu et al. (2016). MBS can serve all SBSs and users while the coverage areas of SBS is limited. We denote the set of base stations 
 where MBS is represented by 
 and we denote 
 as the set of SBSs. Each base station 
 is associated with storage space 
 and computing capacity 
 (e.g. the maximum frequency of CPU). The storage space 
 is used to cache services data (e.g. databases/libraries and content) and the computing capability 
 is used for support of diverse computation processes of services. Similar to reality, MBS which is regarded as the cloud servers can store all services data and has strong computing capability (Wang et al., 2017b). Different from MBS, the storage space of SBSs which are edge nodes is limited and can only store part of services.

There are  independent services, expressed by the set . Every service  has three important attributes 
 where 
 is the storage space required for caching service data (e.g. databases/libraries and contents) of , 
 denotes the average computation required to complete service , i.e. the number of CPU cycles, and 
 is the data size of results when the computing of service  is completed. For example, in media pushing case, 
 is the data size of related databases/libraries and content, 
 is the computation required for analyzing user interests, and 
 is the size of media that is recommended to users. Moreover, considering each service is indivisible (i.e. it is difficult to get accurate user interests if divide user’s request record into several parts and analyze them separately), we assume that each logically independent service is the smallest processing unit. For a single service, mobile users first request it from the SBS which they are associated to. The SBS will allocate computing resources to complete the service if it caches the related data. Otherwise, the SBS will offload the requests to MBS and MBS will provide the service.

Without loss of general assumption, the time is slotted (Li et al., 2018), i.e.,  . In each time slot , BSs provide the services which have been requested according to multicast. Due to the difference of storage space and computing resource between MBS and SBSs, for a service, the caching status and allocated computing resource will affect services latency and energy consumption. Therefore, we consider the following multicast-aware edge caching and computing problem with two sub-problems:

1.
Which service to cache? The decision to make is which services data should be cached in SBS due to the limited storage space.

2.
How to allocate computing resources? This refers to how many computing resources are allocated to each service with the limited computing capability of SBS.

In this paper, we optimize the problem by minimizing overall latency of services with the constraints of energy consumption. Next, system models for request, communication, caching and computation are presented in details.

3.2. Request model
A user sends service requests to the associated base station which is dynamic. We formulate the total service request at each time slot in BS 
 as a Poisson process. As for each service, the request frequency conforms to the Zipf distribution. The process of service requests is two-tier as shown in Fig. 2. First, users request service  from the SBS they are associated to. If the SBS stores related data (e.g. database/libraries and contents), it will allocate computing capabilities to process the task and provide related service. Otherwise, the SBS forwards the request to MBS and MBS assigns pre-fixed computing resource (Tan et al., 2018) to it. In other word, for SBS 
, it will forward the requests of service  to MBS if not stores related data. It is worth noting that the service delay of MBS is much longer than the edge computation time because of long distance transmission.

Denote 
 as the caching variable, i.e., 
 if base station 
 stores data of service  at time slot  and 
 otherwise.

The actual volume of service  to 
 is formulated as: (1)
where 
 is the number of requests to 
 for service  at time slot .

For MBS 
, alongside requests from users, it also needs to satisfy the requests that are forwarded from SBSs. Therefore, at time slot , the actual service volume is the sum of the two components. This is formulated as: (2)

3.3. Communication model
Based on multicast communication mechanism, we build the communication model considering transmission time and energy consumption. Assuming that the spectrum between SBSs and MBS is orthogonal. For base station 
, 
 is the multicast channel gain and 
 is the multicast power. Then the multicast data rate of 
 is as follows: (3)
 
where 
 denotes the noise power, and 
 represents the channel bandwidth. In multicast case, we can serve all users through a single multicast stream, which means transmission data is independent of the number of users. Although 
 provides services to 
 users, the data transfer volume is 
 instead of 
. By the way, the data transfer volume is 
 in unicast case. Therefore, for base station 
, the transmission time of service  is: (4)
 
where 
 is the result size of service  after computing. The energy consumption of multicast is represented as follows: (5)

3.4. Caching model
In this subsection, we present the caching model considering storage space constraint and energy consumption. MBS has enough storage space and can cache all services data which means 
. For SBSs, requests for service  can be satisfied locally if SBSs cache related data, reducing transmission time and improving service quality. However, because of the constraint of caching capacity, SBSs cannot simultaneously cache all services data. Therefore, it is important for SBS 
 to decide efficiently which services to store. Moreover, considering the limited storage space, the caching decision of SBS 
 should satisfy the following constraint: (6)

The energy consumption of 
 associated to caching service  is obtained as follows: (7)
where 
 is the unit energy consumption, considered a fixed value.

3.5. Computation model
It is obvious that different computing resource allocation decisions lead to different computation times and energy consumption. Let 
 denote the allocation decision, which means that base station 
 allocates 
 computing resource to complete service  in time slot . Similar to caching, the computing resource allocation decision for SBSs is subject to the limited computing resource: (8)

As mentioned above, the computing process of services is indivisible and the process of service request is two-tier. SBSs will allocate computing resources for services  if they cache related data. Otherwise, MBS assigns computing resource to the service. For service , the computation demand of SBSs in time slot  is presented uniformly as 
, which is different from the calculation method of data transfer volume in the communication model. The reason is that different users have different inputs leading to different computations. Therefore, the computation time 
 of SBS 
 for service  can be expressed as: (9)
 

For MBS, the calculation of computation time is different from SBS because the MBS allocates a pre-fixed computing resource to every request, regardless of the actual service volume. Therefore, the computation time for service  is: (10)
 

The energy that each CPU cycle consumes is 
, where 
 is the energy coefficient relevant to chip architecture (Wang et al., 2016). The energy consumption of 
 for service  is defined as follows: (11)

4. Problem formulation and transformation
In this section, based on the already-introduced system model, we first formulate the multicast-aware joint resource allocation as an optimization problem to minimize service latency while keeping energy consumption low. Because network system is dynamic, our optimization goal is long-term average performance instead of the performance of each time slot. Considering the lack of future information and intractability of the problem, we further transform the problem into an online solvable problem.

4.1. Problem formulation
For each request, the service latency of  consists of two parts: transmission time and computation time. Therefore, the total latency of base station 
 for all requests is: (12)

To simplify the total latency for SBS, we find that 
 because of 
 and 
. Therefore, for SBS, we can replace the quadratic term 
 and obtain the total latency as: (13)

The overall energy consumption is due to multicast consumption, caching consumption and computation consumption. As we all know, base stations provide services only when the related computation is complete. In other word, only the services that are allocated computing resources can be provided and have transmission energy consumption. So the total energy consumption of SBS 
 for all services can be expressed as: (14)
where 
 if  is true, otherwise 
.

The objective of multicast-aware joint resource allocation problem is to minimize overall service latency with limited energy consumption. We formulate this problem as follows:  
  
 
 
(15a) 
 
 
(15b)
(15c)
(15d)
 
(15e)

The first constraint (15a) guarantees that long-term average energy consumption of SBS 
 is limited by power 
. Constraint (15b) ensures the storage space allocated to all services is limited by the caching capacity of SBS. Constraint (15c) indicates the computing capacity of SBS is limited. The fourth constraint (15d) means that we can only allocate computing resource to the services whose related data has been stored in BS. The constraint (15e) is due to the fact that caching variable is binary.

It is intractable to derive the optimal solution of the above problem. The first challenge is lacking of future information. It is difficult and impractical to solve this problem because it requires the request status of users in all time slots. Moreover, the problem is a mixed integer nonlinear programming with discrete variable and continuous variable, which is still challenging even if the request status is known a priori. Therefore, it is imperative to transform this problem into an online solvable problem without the need for predicting future information.

4.2. Problem transformation
In this subsection, we transform the problem (15) into per time-slot optimization which does not require future information. We construct energy queues to satisfy the long-term energy constraint (15a): (16)
where 
. By its dynamic, 
 indicates the backlog of deviation of current energy consumption from the energy constraint.

Lemma 1

If 
 is mean rate stable, our desired average energy consumption constraint (15a) is satisfied. We define the mean rate stable as: (17) 
 
 
where  denotes the expectation.

The proof of Lemma 1 is shown in Appendix A.  □

To represent the “congestion level” in energy queues, we define the energy function as: (18)
 

The energy function represents the status of energy queues. A small  means queues are highly stable, which implies the energy deficit is small. We persistently reduce the value of energy function to stabilize the energy queues and satisfy the energy consumption constraints. In addition, we introduce the drift which is the variation of energy function: (19)

Energy queues become more stable if  is smaller. Therefore, in order to jointly optimize the service latency and queue stability, the drift-plus-penalty is defined as: (20)
where  is a positive parameter to emphasize the significance of service latency. Considering the inequality 
, we further find the upper-bound of energy function as follows: (21)
 
 where 
 
 is a constant and 
.

Therefore, we convert the original problem (15) to minimize the upper-bound which not need future information: (22) 
 

So far, we have overcome the challenge of requiring future information. However, problem (22) is still knotty to get an optimal solution because of non-convex objective and non-linear constraint. Besides, it is a problem with mixture of discrete variable and continuous variable. Thus, we further transform it, as shown in Lemma 2.

Lemma 2

The optimization problem (22) is equivalent to the following problem: (23) 
 
where 
.

The proof of Lemma 2 is shown in Appendix B.  □

We further solve it through iterative optimization, which is described in detail in the next section.

5. Practical solution
This section introduces the MA-ECC algorithm in order to solve the multicast-aware caching and computing problem. MA-ECC determines which services are cached locally and how to allocate computing resources. First the problem is decomposed (23) into two sub-problems: optimization of computing resource allocation for a particular caching status and optimization of storage space allocation. MA-ECC is first described in the context of the two sub-problems, then its performance is analyzed theoretically.

5.1. Optimization of caching decision
This sub-problem concerns the allocation of storage space. The multicast-aware caching and computing problem takes the following form for a given computing resource allocation . (24) 
 

The objective and constraints of problem (24) are linear which means this is a zero–one Type Integer Linear programming. By employing the implicit enumeration method, we can get the optimal caching decision of SBSs. This is briefly described in Algorithm 1.


Download : Download high-res image (359KB)
Download : Download full-size image
5.2. Optimization of computing resource allocation
The computing resource allocation is concerned in this subsection. The optimization problem for a given caching decision  is as follows: (25) 
 

Lemma 3

Problem (25) is a convex problem.

The proof of Lemma 3 is shown as Appendix C.  □

As it is a convex problem, Karush–Kuhn–Tucker (KKT) can solve it. We define Lagrangian functions under inequality constraints: (26)

The optimal solution 
 should satisfy the following conditions: (27)
 
 By solving the equations, we get the optimal computing resource allocation 
 for a given .

5.3. Multicast-aware caching and computing
The optimization solution of the multicast-aware caching and computing resource allocation problem (23) to minimize both the service latency and energy consumption is presented in detail by Algorithm 2. In each time slot , we first use the average computing resource to initialize each service. We solve two sub-problems (24), (25) because a much faster convergence can be achieved by using the solutions of the two sub-problems. Then, alternating iteration continues until convergence. We will get the solution for a given error tolerance . Finally, the energy queues are updated to prepare for the next time slot.


Download : Download high-res image (501KB)
Download : Download full-size image
5.4. Performance analysis
This subsection analyzes theoretically the performance of MA-ECC as shown in Lemma 4.

Lemma 4

By applying MA-ECC, we have following performance guarantees:

(1) The difference between MA-ECC and the optimal algorithm in service latency satisfies: (28) 
 
 
 
where  is a positive constant, 
 is the sum of latency of all BS and 
 is the infimum average latency time achievable by any policy that satisfies constraints.

(2) The energy queue length which is the time-average deviation of energy consumption satisfies: (29) 
 
 
ɛ
ɛ
 
where ɛ and ɛ are constants that satisfy the Slater condition (Neely, 2010). Besides, ɛ and 
ɛ
, where 
 and 
 are finite constants and minimum and maximum bounds for .

Lemma 4 demonstrates that the services latency achieved by the MA-ECC algorithm diverges from the optimal solution with . However, the energy queue length which represents the energy deficit is bound by . There is a tradeoff between services latency and energy consumption by parameter . When parameter  becomes large, the service latency is more emphasized and MA-ECC achieved a better performance with consuming more energy.

5.5. Hypothesis and limitations
MA-ECC has good performance in service delay and energy consumption, but it also has several limitations. First, we assume that SBSs can immediately download the required services data from MBS. Therefore, the download delay of service is not considered in the model. Because, the data transmission of SBSs and MBS is based on backhaul link with high bandwidth, so the download delay is much smaller than the computation time and transmission delay of wireless communication (Li et al., 2020b). In this paper, we ignore the download delay to simplify problem. By the way, our algorithm may be more accurate if we can consider this point in our model.

The second limitation is that we mainly focus on the cooperation between MBS and SBSs, which means SBSs have to offload the service to MBS because of the limitations of caching size and computing capacity. But as the base stations become denser, SBSs can also communicate with each other. It is possible that a SBS offload its service to the neighbor SBSs which are idle. In other word, the SBSs can cooperate with each other in dense network. Therefore, the performance of our algorithm may degrade in dense network, which is also an interest in our future research.

6. Simulation results
In order to evaluate performance, we compare MA-ECC with the following solutions.


Table 3. Parameter settings for simulations.

Parameters	Value
Communicate bandwidth of MBS	2 GB
Communicate bandwidth of SBS	6 GB
BS storage space 
200 GB
Storage space for service , 
[2, 40] GB
Unit energy consumption 
0.04 kWh
SBS computing resource 
100 GHz
Computing resource requirement of service , 
[5, 15] GHz
•
Unicast-optimal resource allocation: To demonstrate the advantages brought by considering multicast in service latency and energy consumption, we remove constraints on energy consumption in algorithm (Zhang et al., 2019), making it the optimal algorithm in unicast. In Zhang et al. (2019), authors constructed an integrated model by jointly considering caching decision and resource allocation, and formulated it as a mixed integer nonlinear programming problem. Then, they design an asymmetric search tree and improve the branch and bound method to solve this problem.

•
Non-cooperative resource allocation: According to user requests in this region, SBS calculates the local popularity of services. We use multicast to transmit data and formulate it as a Knapsack problem whose constraint is the storage space and the goal is to maximize the overall popularity of cached service. Besides, there are no mutual communications between SBSs and we ignore the constraint of energy consumption. Finally, we design a linear programming approach to solve this problem.

•
Delay-optimal resource allocation: Removing the limited energy consumption, we only consider the constraints of storage space and computing capacity. We use exhaustive method to list all caching decisions. Under a specific cache decision, the computing resource allocation is formulated as a convex optimization problem which can be solved by Karush–Kuhn–Tucker (KKT). We can find the global optimal solution by comparing all the results.

6.1. Average delay comparison
Fig. 3 shows the time average delay in different conditions. Specifically, Fig. 3(a) shows the dynamic change of time delay at different time slots. We can find that MA-ECC achieves time average delay approximate to the delay-optimal resource allocation and significantly better than non-cooperative resource allocation or unicast-optimal resource allocation. In no-cooperative resource allocation, BSs individually cache the most demanding services without considering the future information and the cooperation between BSs, which results in a local optimal solution and poor performance in time average delay. In the unicast-optimal resource allocation, BSs have to transmit the service to the user one by one, which leads to higher communication time. Therefore, it has the worst performance in terms of time average delay.

Fig. 3(b) shows the impact of computing capacity on time average delay. We see that the system delay decreases with the increase of SBS computing capacity for all four methods. Obviously, the reason is that as the computing capacity increases, the computation time decreases which influences the time average delay. However, because of the long-term energy consumption constraint, the downward trend of MA-ECC is more gradual than the other three methods, which means when the computing capacity is sufficient, the energy consumption will become the bottleneck for MA-ECC to reduce the system delay.

Fig. 3(c) presents time average delay variation with different storage space. Similar to computing capacity, increasing the storage space of SBSs can reduce the time average delay since more services can be cached in SBSs. However, the effect will gradually weaken, because storage space can affect communication time, but has less impact on computing time due to the limited computing resources.

6.2. Energy consumption comparison
Fig. 4(a) shows the energy consumption of the four algorithms at different time slots. We observe that the energy consumption of MA-ECC fluctuates around the limited power 
 (the black line), while the other three algorithms are far beyond the constraint. As expected, although the delay-optimal algorithm has the lowest time average delay, it consumes two times more energy than MA-ECC. Non-cooperative resource allocation runs out of storage space by caching the most popular service at each time slot, which leads to higher caching energy consumption. Compared with multicast schemes, unicast-optimal algorithm needs more energy to support the transmission of multiple data streams.

Fig. 4, Fig. 4 present the impact of computing capacity and storage space on energy consumption. In Fig. 4(b), we find that the energy consumption of MA-ECC closely follows the constraint in any case, but the other three algorithms overuse energy. Besides, the trend of the other three algorithms is close to the square growth because of Eq. (11). As for storage space, Fig. 4(c) shows that the energy consumption is proportional to storage space. The reason is that more services can be cached and provided by SBSs with the increasement of storage space and resulting in more energy consumption. However, the rate of increase will gradually decrease until reaches zero.

6.3. Impact of  value
Fig. 5(a) illustrates the impact of  on energy queues length which indicates the backlog of deviation of current energy consumption from the energy constraint. We find that the length of energy queues becomes longer as  increases. In other words, the energy deficit increases with . The reason is that the time average delay becomes more important in the optimization problem (23) with increasing  and MA-ECC will achieve a lower system delay at a cost of higher energy deficit. We also observe that the energy queue length is proportional to , which is consistent with the second part of Lemma 4. In order to show more intuitively the impact of energy queue length on network resource allocation, we present the energy queue for  and computing resource usage in Fig. 5(b) at the same time. As the figure shows, SBSs tend to use more computing resources to minimize time average delay when the energy queue length is small (e.g. slot 65, 85). On the contrary, if the energy length is large, SBSs allocate lower computing resources to reduce the energy consumption (e.g. slot 57, 84). Therefore, the energy queue can affect resource allocation to make a tradeoff between service latency and energy consumption.

Fig. 5(c) shows the impact of  on time average delay and energy consumption. It shows that the system delay is inversely proportional to , which is consistent with the first part of Lemma 4. In contrast, energy consumption is roughly proportional to . This can be explained by Eq. (16) and the second part of Lemma 4. In a word, Fig. 5(c) is consistent with Lemma 4 which proves the lemma experimentally.

6.4. Impact of energy constraint
Fig. 6 illustrates the impact of energy consumption constraints 
 on the performance of MA-ECC. As the picture shows, the MA-ECC reduces the time average delay with the increase of energy consumption constraint, because SBSs can allocate more resources to satisfy users’ requests. However, due to the limited resource, the performance gain becomes more gentle when the constraint 
 is large. Besides, we also observe from the right-side of -axis that MA-ECC successfully meets the predetermined energy consumption constraint.

6.5. Convergence of algorithm
In Fig. 7, the convergence of the proposed MA-ECC is evaluated under different initial parameters. We set error tolerance parameter  as 10−2. In order to simplify, we unified the initial parameters of each SBS. Specially, 
 is the limited power of SBSs,  is the storage space of SBSs and  is the computing capacity. The  axis is the iteration number of MA-ECC algorithm and  axis is the objective function value of the optimization problem (23). The pictures shows that although the initial parameters are different, MA-ECC usually achieves convergence within 3 iterations, which means that MA-ECC is efficient in terms of computational complexity.

6.6. Summary of simulation results
In this section, we make lots of experiments to verify the performance of our algorithm MA-ECC. From the results, we can find that MA-ECC has the following advantages. First, in the case of different computing capacity and storage space, MA-ECC all achieve much lower service delay compared with unicast-optimal resource allocation and no-cooperative resource allocation, which close to delay-optimal resource allocation. Second, MA-ECC can always meet the energy consumption constraint of SBS, while other three algorithms greatly exceed this constraint. In other word, MA-ECC has lower energy consumption than the other three algorithms. Third, MA-ECC is more flexible. We can change the weight between services delay and energy consumption by adjusting the  value to adapt to different network scenarios. In time-sensitive network, we can use a large  to reduce service delay, while a small  to reduce energy consumption in energy limited network, which is not available in the other three algorithms. Last but not least, MA-ECC can converge quickly in 3 iterations, and has high usability.

7. Conclusion
In this paper, we studied multicast-aware resource allocation with joint optimization of caching and computing for MEC in a heterogeneous cellular network environment. First, we formulate it as a convex optimization problem. Then, in order to effectively solve the problem, we separate it into two sub-problems, optimization of caching decision and optimization of computing resource allocation. Additionally, we propose an online algorithm MA-ECC as a solution to the overall problem. Theoretical analysis shows our solution not only reduces effectively the time average delay, but also keeps low the energy consumption. The experimental simulation-based performance evaluation shows our proposed solution outperforms three alternative solutions under different system parameters.

Future work will take the mobility of users into account, which contains the analysis of users’ movement trajectory, device access and switch, the cooperation between base stations, and so on. Besides, we will also study the computation offloading on the basis of the original problem and take the download cost into account.