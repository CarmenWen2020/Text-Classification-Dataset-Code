As the scale of datasets used for big data applications expands rapidly, there have been increased efforts to develop faster algorithms. This paper addresses big data summarisation problems using the submodular maximisation approach and proposes an efficient algorithm for maximising general non-negative submodular objective functions subject to k-extendible system constraints. Leveraging a random sampling process and a decreasing threshold strategy, this work proposes an algorithm, named Sample Decreasing Threshold Greedy (SDTG). The proposed algorithm obtains an expected approximation guarantee of 11+ğ‘˜âˆ’ğœ– for maximising monotone submodular functions and of ğ‘˜(1+ğ‘˜)2âˆ’ğœ– in non-monotone cases with expected computational complexity of ğ‘‚(ğ‘›(1+ğ‘˜)ğœ–lnğ‘Ÿğœ–). Here, r is the largest size of feasible solutions, and ğœ–âˆˆ(0,11+ğ‘˜) is an adjustable designing parameter for the trade-off between the approximation ratio and the computational complexity. The performance of the proposed algorithm is validated and compared with that of benchmark algorithms through experiments with a movie recommendation system based on a real database.

Introduction
The research of big data has received extensive attention due to its great significance [1]. Data summarisation, which involves extracting representative information with certain constraints from a large-scale dataset, is one of the compelling directions of big data processing [2]. Typical applications of big data summarisation include personalised recommendation systems [3,4,5,6], exemplar-based clustering [7,8,9], and summarisation of text [10, 11], images [12,13,14], corpus [8, 15], and videos [16, 17], just to name a few.

The unprecedented growth of modern datasets requires efficient and effective techniques to process a mass of data. Computational complexity is one of the grand challenges of big data operations [1]. Fortunately, the quality of data summarisation outcome can be often measured by submodular set functions [11, 12, 14], where the marginal gain value of an element decreases as more elements have already been selected, namely diminishing returns [18]. It is well known that the greedy-related algorithms are efficient and can provide an approximation guarantee for maximising submodular functions [19]. Hence, the big data summarisation problem can be handled as maximising a submodular function based on a large-scale dataset, meanwhile satisfying a certain constraint or a combination of several constraints [2].

This paper addresses big data summarisation problems using the submodular maximisation approach, especially subject to k-extendible system constraints. Note that the k-extendible system constraint is a general type of constraint that has been widely studied. The concept of k-extendible systems was first introduced by Mestre in 2006 [20]. The intersection of k matroids based on the same ground set is always k-extendible [20]. Many types of constraints handled in submodular maximisation problems fall into the k-extendible system constraint, such as the cardinality constraint, partition matroid constraint, and k-matroid constraint.

The issue is that finding the optimal solution of submodular maximisation is NP-hard, and the sizes of datasets tend to increase. NP-hard problems are known to significantly suffer from â€œcurse of dimensionalityâ€, which implies that the complexity of the problem explodes as the problem size increases. Therefore, the trend of increasing sizes of datasets combined with the NP-hardness of the problem urges the development of more computationally efficient optimisation algorithms. The Sample Greedy algorithm (Sample, for short) proposed in [21] is one of the state-of-the-art algorithms for constrained submodular maximisation problems. Specifically, Sample [21] was the fastest algorithm (before this work) for maximising non-monotone submodular functions subject to a k-extendible system constraint.

Inspired by the sampling strategy from [21] and a decreasing threshold idea from [22], this work proposes an algorithm that is even faster than Sample [21]. The proposed algorithm, which is named as Sample Decreasing Threshold Greedy (SDTG), provides an expected approximation guarantee of ğ‘âˆ’ğœ– for maximising monotone submodular functions and of ğ‘(1âˆ’ğ‘)âˆ’ğœ– for non-monotone cases with expected time complexity of only ğ‘‚(ğ‘ğ‘›ğœ–lnğ‘Ÿğœ–), where ğ‘âˆˆ(0,11+ğ‘˜] is the sampling probability and ğœ–âˆˆ(0,ğ‘) is the threshold decreasing parameter. If the sampling probability p is set as 11+ğ‘˜, then SDTG provides the best approximation ratios for both monotone and non-monotone submodular functions which are 11+ğ‘˜âˆ’ğœ– and ğ‘˜(1+ğ‘˜)2âˆ’ğœ–, respectively. Here, ğœ– acts as a design parameter for the trade-off between the approximation ratio and the computational complexity. The proposed algorithm is validated through experiments with a movie recommendation system based on the MovieLens [23] which is a widely used real movie information database. Experimental results demonstrate that the proposed algorithm outperforms benchmark algorithms in terms of both solution quality and computation efficiency. The main contributions of this work are summarised as follows:

This work proposes the current fastest algorithm, SDTG, for maximising non-monotone submodular functions subject to k-extendible system constraints;

Precise mathematical proofs are provided for analysing the theoretical guarantees of the proposed algorithm;

Experiments with a movie recommendation system based on a real database are carried out to reveal the practical performance of SDTG for solving the big data summarisation problem.

The rest part of this work is organised as follows. â€œRelated worksâ€ section investigates related articles for constrained submodular maximisation problems. In â€œPreliminariesâ€ section, some basic knowledge related to the proposed algorithm is presented. â€œAlgorithm and analysisâ€ section demonstrates the proposed algorithm and analyses its theoretical performance in detail. The performance and validity of the theoretical results are then testified through experiments with a movie recommendation system in â€œExperimentsâ€ section. â€œConclusionsâ€ section offers the conclusions of this paper and possible future research directions.

Related works
There have been numerous works recently carried out to develop more efficient constrained submodular maximisation algorithms, and many of them endeavour to increase computational efficiency even by sacrificing some degree of approximation ratio. These works are classified by the types of constraints, and their developments are summarised in the following.

Cardinality constraint
The Sieve-Streaming proposed by Badanidiyuru et al. [12] is the first single-pass streaming algorithm for maximising monotone submodular functions, achieving approximation guarantee of 1/2âˆ’ğœ– with computational complexity of ğ‘‚(ğ‘›ğœ–logğ‘Ÿ). Here, n is the size of the ground set, r is the size of the largest feasible solution. Norouzi-Fard et al. [9] proposed another single-pass algorithm SALSA that improved the approximation guarantee to a value better than 1/2. They also extended their work to a multi-pass algorithm P-PASS that provided the trade-off between the approximation ratio and the number of passes. The Decreasing Threshold Greedy proposed in [22] obtained an approximation ratio of 1âˆ’1/ğ‘’âˆ’ğœ– with time complexity of ğ‘‚(ğ‘›ğœ–logğ‘›ğœ–) for monotone submodular functions. This is the first streaming algorithm whose computational complexity is independent of r. Later, the sampling-based Stochastic Greedy proposed by Mirzasoleiman et al. [24] achieved an expectantly the same approximation ratio with lower time complexity of ğ‘‚(ğ‘›log1ğœ–), compared with the Decreasing Threshold Greedy [22]. The Stochastic Greedy gets orders of magnitudes faster by losing only a bit of approximation ratio compared with other benchmark algorithms. Then Buchbinder et al. [25] extended the Stochastic Greedy to general non-monotone cases and achieved an approximation guarantee of 1/ğ‘’âˆ’ğœ– with computational complexity of ğ‘‚(ğ‘›ğœ–2log1ğœ–). Recently, Breuer et al. [26] proposed an efficient algorithm FAST for the monotone case, using the adaptive sequencing technique. FAST achieves an approximation ratio of 1âˆ’1/ğ‘’âˆ’ğœ–, with ğ‘‚(ğ‘›loglogğ‘Ÿ) queries.

Matroid constraint
The original greedy algorithm (Greedy) [19] provides an approximation ratio of 1/2 with time complexity of O(nr) for monotone submodular maximisation. Nemhauser and Wolsely [27] proved that no algorithm can achieve an approximation ratio better than 1âˆ’1/ğ‘’ with polynomial time complexity. The continuous greedy based on the multilinear extension was utilised to achieve an approximation ratio of 1âˆ’1/ğ‘’ [28]. The measured continuous greedy algorithm developed by Feldman et al. [29] achieved a (1âˆ’1/ğ‘’)-approximation for the monotone case and a 1/e-approximation for the non-monotone case. This is the first algorithm to provide a constant factor of approximation for maximising non-monotone submodular functions subject to a partition matroid constraint. However, the sophisticated continuous algorithms are inherently too time-consuming to be applied directly in the real world [30]. To remedy this, the idea of decreasing threshold [22] was adapted to reduce the computational complexity [31]. Badanidiyuru and Vondrak [22] proposed a new variant of the continuous greedy algorithm and achieved an approximation ratio of 1âˆ’1/ğ‘’âˆ’ğœ– with complexity of ğ‘‚(ğ‘›ğ‘Ÿğœ–4log2ğ‘Ÿğœ–) for monotone submodular functions. Then, a close variant of the Decreasing Threshold Greedy described in [25] provided an approximation ratio of 1/2âˆ’ğœ– with computational complexity of ğ‘‚(ğ‘›ğœ–logğ‘Ÿğœ–) for the monotone case.

k-extendible system constraint
It is known that Greedy [19] achieves a 11+ğ‘˜-approximation for maximising monotone submodular functions subject to a k-extendible system constraint. The Decreasing Threshold Greedy [22] provides a slightly worse approximation guarantee of 11+ğ‘˜+ğœ– but requires lower computational complexity of ğ‘‚(ğ‘›ğœ–2log2ğ‘›ğœ–) than Greedy [19] does for maximising monotone submodular functions. For the non-monotone case, Gupta et al. [32] proposed an algorithm achieving an approximation ratio of ğ‘˜(ğ‘˜+1)(3ğ‘˜+3) with time complexity of O(nrk). Then, the approximation ratio was improved to ğ‘˜(ğ‘˜+1)(2ğ‘˜+1) by an algorithm called FANTOM proposed by Mirzasoleiman et al. [5] with the same complexity. After this, Feldman et al. [21] made a significant breakthrough in terms of both approximation ratio and time complexity. The Sample algorithm proposed in [21] achieved an approximation ratio of ğ‘˜(ğ‘˜+1)2 with complexity of ğ‘‚(ğ‘›+ğ‘›ğ‘Ÿ/ğ‘˜). Experiments based on a movie recommendation system in [21] confirmed that Sample outperformed FANTOM in terms of computational efficiency.

In summary, gradual improvements have been made for solving the constrained submodular maximisation problems recently. However, the rapid expansion in the scale of modern datasets urges persistent developments for faster algorithms. An immediate research question would be whether or not one can develop an algorithm that can further improve the efficiency of maximising general non-negative submodular functions especially subject to k-extendible system constraints.

Preliminaries
This section presents some necessary definitions and basic concepts related to the proposed algorithm. The definitions and concepts can also be found in our previous works [33,34,35].

Definition 1
(Submodularity [21]) A set function ğ‘“:2îˆºâ†’â„ is submodular if, âˆ€ ğ‘‹,ğ‘ŒâŠ†îˆº,

ğ‘“(ğ‘‹)+ğ‘“(ğ‘Œ)â‰¥ğ‘“(ğ‘‹âˆ©ğ‘Œ)+ğ‘“(ğ‘‹âˆªğ‘Œ).
where îˆº is named as â€œground setâ€ which is a finite set containing all elements. Equivalently, âˆ€ ğ´âŠ†ğµâŠ†îˆº and ğ‘¢âˆˆîˆºâˆ’ğµ,

ğ‘“(ğ´âˆª{ğ‘¢})âˆ’ğ‘“(ğ´)â‰¥ğ‘“(ğµâˆª{ğ‘¢})âˆ’ğ‘“(ğµ).
(1)
Definition 2
(Marginal gain value [36] (mgv)) For a set function ğ‘“:2îˆºâ†’â„, a set ğ‘†âŠ†îˆº, and an element ğ‘¢âˆˆîˆº, the marginal gain value of f at S with respect to u is defined as

Î”ğ‘“(ğ‘¢|ğ‘†)â‰ğ‘“(ğ‘†âˆª{ğ‘¢})âˆ’ğ‘“(ğ‘†),
where â‰ means equal by definition. This work denotes the marginal gain value as â€œmgvâ€ for tidiness.

The inequality (1) is known as the diminishing return, which is a crucial property of submodular functions: the mgv of a given element will never increase as more elements have already been selected. One intuitive example for the submodularity is the sensor placement problem: The space coverage increment obtained by adding an extra fire detector to a particular position of a room will never increase as more detectors have already been placed in the room.

Definition 3
(Monotonicity [36]) A set function ğ‘“:2îˆºâ†’â„ is monotone if, âˆ€ğ´âŠ†ğµâŠ†îˆº, ğ‘“(ğ´)â‰¤ğ‘“(ğµ). f is non-monotone if it is not monotone.

The submodular objective functions considered in this paper are normalised (i.e. ğ‘“(âˆ…)=0), non-negative (i.e. ğ‘“(ğ‘†)â‰¥0, âˆ€ğ‘†âŠ†îˆº), and can be either monotone or non-monotone.

Definition 4
(Matroid [22]) A matroid is a pair îˆ¹=(îˆº,îˆµ) where îˆº is the ground set, and îˆµâŠ†2îˆº is a collection of independent sets, satisfying:

âˆ…âˆˆîˆµ;

If ğ´âŠ†ğµ,ğµâˆˆîˆµ, then ğ´âˆˆîˆµ;

If ğ´,ğµâˆˆîˆµ,|ğ´|<|ğµ|, then âˆƒ ğ‘¢âˆˆğµâˆ’ğ´  such  that  ğ´âˆª{ğ‘¢}âˆˆîˆµ.

Specifically, matroid constraints include uniform matroid constraints and partition matroid constraints. The uniform matroid constraint is also called cardinality constraint, which is a special case of matroid constraints where any subset ğ‘†âŠ†îˆº satisfying |ğ‘†|â‰¤ğ‘Ÿ is independent, i.e. ğ‘†âˆˆîˆµ. The partition matroid constraint means that an independent subset S can contain at most a certain number of elements from each of the disjoint partitions of îˆº.

A typical example for the partition matroid constraint is the security camera system: Each camera of the system can only point to one of its admissible directions at a certain moment. The partition matroid constraint is a special case of k-extendible system constraints where k equals to 1. A formal definition of the k-extendible system constraint is given following an auxiliary concept.

Definition 5
(Extension [21]) If an independent set B strictly contains an independent set A, then B is called an extension of A.

Definition 6
(k-extendible system [20]) A k-extendible system is an independence system (îˆº,îˆµ) that for every independent set ğ´âˆˆîˆµ, an extension B of A, and an element ğ‘¢âˆ‰ğ´, ğ´âˆª{ğ‘¢}âˆˆîˆµ, there exists a subset ğ‘‹âŠ†ğµâˆ’ğ´ with |ğ‘‹|â‰¤ğ‘˜ such that (ğµâˆ’ğ‘‹)âˆª{ğ‘¢}âˆˆîˆµ.

Intuitively, if an element u is added into an independent set A of a k-extendible system, it requires at most k other elements to be removed from A in order to keep the set independent [21]. For example, a certain user of a movie recommendation system likes three genres of movies: Action, Adventure, and Sci-Fi. Suppose that this user wants at most one movie from each of these three genres. Note that a movie can belong to multiple genres. Here are four movies with genre information: ğ‘šğ‘£1 (Action), ğ‘šğ‘£2 (Adventure), ğ‘šğ‘£3 (Sci-Fi), and ğ‘šğ‘£4 (Action, Adventure, Sci-Fi). According to the requirement from the user, a recommendation list ğ‘†={ğ‘šğ‘£1,ğ‘šğ‘£2,ğ‘šğ‘£3} is independent, i.e., ğ‘†âˆˆîˆµ; adding ğ‘šğ‘£4 to S will make it dependent. Movies ğ‘šğ‘£1, ğ‘šğ‘£2, and ğ‘šğ‘£3 must be removed from S to keep it independent if ğ‘šğ‘£4 is remained in S. Therefore, the constraint in this example is a 3-extendible system constraint.

The following is an important claim that provides the mathematical foundation for Sample [21] to work well in non-monotone submodular maximisation. Readers are referred to [37] for the proof of Claim 1.

Claim 1
(Due to [37]) Let â„:2îˆºâ†’â„â‰¥0 be a submodular function, and let S be a random subset of îˆº. If each element of S appears with a probability at most p (not necessarily independently), then ğ”¼[â„(ğ‘†)]â‰¥(1âˆ’ğ‘)â„(âˆ…).

Algorithm and analysis
This section describes SDTG in Algorithm 1 and analyses its theoretical performance in detail. Note that the proposed algorithm is based on submodular optimisation like in our previous studies [33,34,35]. Hence the analysis shares some essences of logic in our previous works. An equivalent version of Algorithm 1 is introduced as Algorithm 2 to better analyse SDTG.

Algorithm
This work proposes to leverage the sampling strategy [21] and develop a variant of decreasing threshold idea to design a summarisation algorithm. On the one hand, the random sampling at the beginning of SDTG can help the algorithm to avoid getting trapped in local optima. It can also help to accelerate the algorithm because only a small portion of elements from the ground set is considered. On the other hand, the decreasing threshold can further accelerate the algorithm. Note that Greedy [19] needs to reevaluate all the remaining elements to find the best one during each iteration. In contrast, SDTG searches for a relatively good element whose mgv is no less than the current threshold instead of looking for the best one. Therefore, SDTG does not have to reevaluate all remaining elements every time before selecting an extra element.

Some notations from Algorithm 1 are stated in the following: îˆº is the ground set containing all elements. îˆµ is the collection of all feasible sets (independent); r is the maximum cardinality of feasible sets in îˆµ; p is the sampling probability (uniform distribution); ğœ– is the threshold decreasing parameter determining the decreasing speed of the threshold; S is the solution set containing the selected elements; R is a set containing the remaining sampled elements; ğœƒ is the decreasing threshold.

The structure of Algorithm 1 consists of two phases. The first phase (lines 1â€“4) is sampling where elements are randomly selected from the ground set îˆº with probability p to form a sample set R. The probability distribution of sampling is uniform. The second phase (lines 5â€“22) is selecting where an independent solution set S is selected from R using decreasing threshold greedy. The initial threshold is set as the largest mgv given the empty set and denoted as d (line 5). The terminal threshold is set as ğœ–ğ‘Ÿğ‘‘ (line 6). The reason for choosing this value as the termination condition will be given later in the proof part.

figure a
More details of the second phase are given in the following. One loop of the inner â€œforâ€ loops is named as one iteration. At the beginning of each iteration, SDTG checks independency of ğ‘†âˆª{ğ‘¢}. If it is not independent, then remove element u from R (lines 8â€“9). Otherwise, calculate the mgv of u and compare it with the current threshold ğœƒ. If the mgv of u is greater than or equals to ğœƒ, then add u to S and remove it from R (lines 11â€“13). An element u is named as a qualified element if the mgv of u given S is no less than the current threshold ğœƒ. If the mgv of an element is already less than ğœ–ğ‘Ÿğ‘‘, it will never become greater or equal to ğœ–ğ‘Ÿğ‘‘ in subsequent iterations due to submodularity. Therefore, this element can be removed from R immediately, as stated in lines 15â€“17. Note that each element in R will be evaluated only for one time under one threshold. If the mgv of an element is between ğœ–ğ‘Ÿğ‘‘ and ğœƒ, this element will remain in R for the next outer loop where the threshold will decrease. The remaining elements in R will be reevaluated and their updated mgvs will be compared with a decreased new threshold. The threshold keeps decreasing after all remaining elements in R have been evaluated until reaching the termination condition.

Analysis
To better analyse the theoretical approximation performance of Algorithm 1, this work leverages some analysing techniques that were used in [21]. A few auxiliary variables have been introduced to transform SDTG to an equivalent version, i.e., Algorithm 2.

figure b
In Algorithm 2, variables C, ğ‘†ğ‘, Q, and ğ¾ğ‘ are introduced only for the convenience of analysis and have no effect on the final output S. Therefore, Algorithm 2 and Algorithm 1 are equivalent in terms of solution quality. The rules of these variables are as follows.

C is a set that contains all considered elements that have mgvs greater or equal to the threshold ğœƒ in a certain iteration of Algorithm 2 no matter whether they are added into S or not.

ğ‘†ğ‘ is a set that contains the selected elements at the beginning of the current iteration. At the end of this iteration, ğ‘†=ğ‘†ğ‘âˆª{ğ‘} if c is added into S and Q, otherwise S equals to ğ‘†ğ‘.

Q is a set that bridges the relationship between the solution S and the optimal solution OPT. Q starts at OPT at the beginning of the algorithm and changes over time. Note that, Q is introduced only for analysis and there is no need to know the exact value of Q or OPT. In each iteration, the element added into S is also added into Q. At the same time, a set ğ¾ğ‘ is removed from Q to keep the independence of Q if an element c is added into Q. Note that, if an element c is already in Q and is considered but not added into S at the current iteration, then this element c should be removed from Q.

ğ¾ğ‘ is a set that is introduced to keep Q independent and help Q to remove c that is not added to S. According to the property of k-extendible systems, Algorithm 2 is able to remove a set ğ¾ğ‘âŠ†ğ‘„âˆ’ğ‘† which contains at most k elements from Q if an element is added into the currently independent set Q. In addition, if c is not added to S and ğ‘âˆˆğ‘„ at the beginning of some iteration, then ğ¾ğ‘={ğ‘}.

The theoretical performance of the proposed algorithm SDTG is summarised in Theorem 1.

Theorem 1
SDTG achieves an approximation guarantee of at least 11+ğ‘˜âˆ’ğœ– for maximising monotone submodular functions subject to k-extendible system constraints and of ğ‘˜(1+ğ‘˜)2âˆ’ğœ– for non-monotone cases with computational complexity of ğ‘‚(ğ‘›(1+ğ‘˜)ğœ–lnğ‘Ÿğœ–), where n sis the size of the ground set, r is the largest size of a feasible solution, and ğœ–âˆˆ(0,11+ğ‘˜) is the threshold decreasing parameter.

The computational complexity can be easily proved. Assume that there are in total x number of loops in the outer â€œforâ€ loop of Algorithm 1. Thus,

(1âˆ’ğœ–)ğ‘¥=ğœ–ğ‘Ÿ.
Solving the above equation yields

ğ‘¥=lnğ‘Ÿğœ–ln11âˆ’ğœ–â‰¤1ğœ–lnğ‘Ÿğœ–.
There are expectantly at most ğ‘â‹…ğ‘› function evaluations in each outer loop. Therefore, the time complexity of Algorithm 1 is ğ‘‚(ğ‘ğ‘›ğœ–lnğ‘Ÿğœ–). â—»

The following part of this section analyses the approximation ratios of SDTG in both monotone and non-monotone cases through Algorithm 2.

Lemma 1
ğ‘“(ğ‘†)>11+ğœ–ğ‘“(ğ‘„).

Proof
According to Algorithm 2, at the end of each iteration, the set Q is independent i.e. ğ‘„âˆˆîˆµ. S is a subset of Q, i.e. ğ‘†âŠ†ğ‘„, as every element c that is added to S is also in Q. Therefore, ğ‘†âˆª{ğ‘}âˆˆîˆµ âˆ€ğ‘âˆˆğ‘„âˆ’ğ‘† by the property of independent systems and |ğ‘„âˆ’ğ‘†|â‰¤ğ‘Ÿ. At the termination of Algorithm 2, Î”ğ‘“(ğ‘|ğ‘†)<ğœ–ğ‘Ÿğ‘‘ âˆ€ğ‘âˆˆğ‘„âˆ’ğ‘† and ğ‘“(ğ‘†)â‰¥ğ‘‘. Thus,

âˆ‘ğ‘âˆˆğ‘„âˆ’ğ‘†Î”ğ‘“(ğ‘|ğ‘†)<âˆ‘ğ‘âˆˆğ‘„âˆ’ğ‘†ğœ–ğ‘Ÿğ‘‘â‰¤ğœ–â‹…|ğ‘„âˆ’ğ‘†|ğ‘Ÿğ‘“(ğ‘†)â‰¤ğœ–â‹…ğ‘“(ğ‘†).
Let ğ‘„âˆ’ğ‘†={ğ‘1,ğ‘2,â€¦,ğ‘|ğ‘„âˆ’ğ‘†|}, then

ğ‘“(ğ‘†)=ğ‘“(ğ‘„)âˆ’âˆ‘ğ‘–=1|ğ‘„âˆ’ğ‘†|Î”ğ‘“(ğ‘ğ‘–|ğ‘†âˆª{ğ‘1,â€¦,ğ‘ğ‘–âˆ’1})â‰¥ğ‘“(ğ‘„)âˆ’âˆ‘ğ‘–=1|ğ‘„âˆ’ğ‘†|Î”ğ‘“(ğ‘ğ‘–|ğ‘†)>ğ‘“(ğ‘„)âˆ’ğœ–â‹…ğ‘“(ğ‘†).
(submodularity)
The result is clear by rearranging the above inequality. â—»

Remark 1
Lemma 1 indicates that, at the termination of Algorithm 2, f(S) gets close to f(Q) if ğœ– is small enough. This means that if the mgv of an element is less than ğœ–ğ‘Ÿğ‘‘, then this element can be considered negligible because it has very limited contribution to f(S). This is the reason why the terminal threshold is set as ğœ–ğ‘Ÿğ‘‘.

Lemma 2
ğ”¼[|ğ¾ğ‘¢|]â‰¤ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥ where ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥=max(ğ‘ğ‘˜,1âˆ’ğ‘).

Proof
There are three cases to analyse, depending on whether the current element u is considered at some point of iteration, i.e. ğ‘¢âˆˆğ¶, and whether u is already in Q at the beginning of the iteration in Algorithm 2. Note that the size of ğ¾ğ‘¢ is kept as small as possible.

i.
If ğ‘¢âˆ‰ğ¶ for whole iterations, ğ¾ğ‘¢=âˆ… and thus the expectation is obtained as:

ğ”¼[|ğ¾ğ‘¢|]=0.
ii.
If ğ‘¢âˆˆğ¶ and ğ‘¢âˆˆğ‘„ at the beginning of the iteration, then ğ¾ğ‘¢=âˆ… for ğ‘¢âˆˆîˆºğ‘  and ğ¾ğ‘¢={ğ‘¢} for ğ‘¢âˆ‰îˆºğ‘ . Since u is sampled in îˆºğ‘  with probability p, the expectation is obtained as:

ğ”¼[|ğ¾ğ‘¢|]=ğ‘â‹…|âˆ…|+(1âˆ’ğ‘)|{ğ‘¢}|=1âˆ’ğ‘.
iii.
If ğ‘¢âˆˆğ¶ and ğ‘¢âˆ‰ğ‘„ at the beginning of the iteration, then ğ¾ğ‘¢ contains at most k elements for ğ‘¢âˆˆîˆºğ‘ , and ğ¾ğ‘¢=âˆ… for ğ‘¢âˆ‰îˆºğ‘ . According to the property of k-extendible systems, if Q becomes dependent after adding u, then Q can remove at most k elements to remain independence. If Q is still independent after adding u, then ğ¾ğ‘¢=âˆ…. Therefore,

ğ”¼[|ğ¾ğ‘¢|]â‰¤ğ‘â‹…ğ‘˜+(1âˆ’ğ‘)|âˆ…|=ğ‘ğ‘˜.
In summary, ğ”¼[|ğ¾ğ‘¢|]â‰¤max(ğ‘ğ‘˜,1âˆ’ğ‘). â—»

Lemma 3
ğ”¼[ğ‘“(ğ‘†)]=âˆ‘ğ‘¢âˆˆîˆºğ‘ğ”¼[Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)].

Proof
Let us define a random variable îˆ³ğ‘¢ such that its value is equal to the increase of f(S) when ğ‘¢âˆˆîˆº is considered, i.e.

ğ‘“(ğ‘†)=ğ‘“(âˆ…)+âˆ‘ğ‘¢âˆˆîˆºîˆ³ğ‘¢.
Note that since f is assumed to be normalised, ğ‘“(âˆ…)=0. Given the event îˆ±ğ‘¢ specifying all the decisions made before considering u, the conditional expectation of îˆ³ğ‘¢ is obtained as

ğ”¼[îˆ³ğ‘¢|îˆ±ğ‘¢]=âˆ‘îˆ³ğ‘¢ğ‘ƒ(îˆ³ğ‘¢|îˆ±ğ‘¢)îˆ³ğ‘¢.
Here, if u is sampled, îˆ³ğ‘¢ is equal to Î”ğ‘“(ğ‘¢|ğ‘†â€²ğ‘¢) with the probability of ğ‘ƒ(îˆ³ğ‘¢|îˆ±ğ‘¢)=ğ‘, where ğ‘†â€²ğ‘¢ is defined as ğ‘†ğ‘¢ given the event îˆ±ğ‘¢. Note that if u is sampled but not in C, Î”ğ‘“(ğ‘¢|ğ‘†â€²ğ‘¢) is defined as 0 by convention. Otherwise if u is not sampled, îˆ³ğ‘¢ is zero. Hence, the conditional expectation of îˆ³ğ‘¢ is:

ğ”¼[îˆ³ğ‘¢|îˆ±ğ‘¢]=ğ‘Î”ğ‘“(ğ‘¢|ğ‘†â€²ğ‘¢)=ğ‘ğ”¼[Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)|îˆ±ğ‘¢].
By the law of total expectation, the expectation of îˆ³ğ‘¢ is obtained as:

ğ”¼[îˆ³ğ‘¢]=ğ”¼[ğ”¼[îˆ³ğ‘¢|îˆ±ğ‘¢)]]=âˆ‘îˆ±ğ‘¢ğ‘ƒ(îˆ±ğ‘¢)ğ”¼[îˆ³ğ‘¢|îˆ±ğ‘¢]=ğ‘ğ”¼[Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)].
Hence, the expectation of f(S) is obtained as:

ğ”¼[ğ‘“(ğ‘†)]=âˆ‘ğ‘¢âˆˆîˆºğ‘ğ”¼[Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)].
â—»

Lemma 4
ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğœ–2)ğ‘+ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)].

Proof
In a certain iteration and given the current threshold ğœƒ, if ğ‘¢âˆˆğ¶ it implies that

Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)â‰¥ğœƒ.
(2)
While if an element ğ‘âˆˆğ¾ğ‘¢âˆ’ğ‘† was not selected before this iteration, then

Î”ğ‘“(ğ‘|ğ‘†ğ‘¢)<ğœƒ/(1âˆ’ğœ–).
(3)
Combining Eqs. (2) and (3) yields

Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)>(1âˆ’ğœ–)Î”ğ‘“(ğ‘|ğ‘†ğ‘¢) âˆ€ğ‘âˆˆğ¾ğ‘¢âˆ’ğ‘†.
(4)
Additionally, any element can be removed from Q at most once. In other words, the element that is contained in ğ¾ğ‘¢ at one iteration is always different from those in other iterations when ğ¾ğ‘¢ is not empty. Therefore, the sets {ğ¾ğ‘¢âˆ’ğ‘†}ğ‘¢âˆˆîˆº are disjoint. According to the definition and evolution of Q, Q can be expressed as

ğ‘„=(ğ‘‚ğ‘ƒğ‘‡âˆ’âˆªğ‘¢âˆˆîˆºğ¾ğ‘¢)âˆªğ‘†=(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)âˆ’âˆªğ‘¢âˆˆîˆº(ğ¾ğ‘¢âˆ’ğ‘†).
(5)
Denote îˆº as îˆº={ğ‘¢1,ğ‘¢2,â‹¯,ğ‘¢|îˆº|}. Then we define ğ‘„ğ‘–ğ‘¢ as

ğ‘„ğ‘–ğ‘¢â‰(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)âˆ’âˆªğ‘¢âˆˆîˆºğ‘–(ğ¾ğ‘¢âˆ’ğ‘†)
where îˆºğ‘–={ğ‘¢1,â‹¯,ğ‘¢ğ‘–}. Denote ğ¾ğ‘¢ and ğ‘†ğ‘¢ corresponding to ğ‘¢ğ‘– in the i-th iteration as ğ¾ğ‘–ğ‘¢ and ğ‘†ğ‘–ğ‘¢, respectively. It is clear that ğ‘†ğ‘–ğ‘¢âŠ†ğ‘†âŠ†ğ‘„ğ‘–ğ‘¢. Using Eq. (5), one can have

ğ‘“(ğ‘„)=ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)âˆ’âˆ‘ğ‘–=1|îˆº|Î”ğ‘“(ğ¾ğ‘–ğ‘¢âˆ’ğ‘†|ğ‘„ğ‘–ğ‘¢)â‰¥ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)âˆ’âˆ‘ğ‘–=1|îˆº|âˆ‘ğ‘âˆˆğ¾ğ‘–ğ‘¢âˆ’ğ‘†Î”ğ‘“(ğ‘|ğ‘†ğ‘–ğ‘¢)(submodularity)>ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)âˆ’âˆ‘ğ‘¢âˆˆîˆº|ğ¾ğ‘¢âˆ’ğ‘†|11âˆ’ğœ–Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)(Eq. (4))â‰¥ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)âˆ’âˆ‘ğ‘¢âˆˆîˆº|ğ¾ğ‘¢|11âˆ’ğœ–Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢).
Taking expectation over f(S) yields

ğ”¼[ğ‘“(ğ‘†)]>11+ğœ–ğ”¼[ğ‘“(ğ‘„)]>11+ğœ–ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)]âˆ’1(1+ğœ–)(1âˆ’ğœ–)â‹…ğ”¼[|ğ¾ğ‘¢|]â‹…âˆ‘ğ‘¢âˆˆîˆºğ”¼[Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)]â‰¥11+ğœ–ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)]âˆ’1(1+ğœ–)(1âˆ’ğœ–)â‹…ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥â‹…âˆ‘ğ‘¢âˆˆîˆºğ”¼[Î”ğ‘“(ğ‘¢|ğ‘†ğ‘¢)]=11+ğœ–ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)]âˆ’1(1+ğœ–)(1âˆ’ğœ–)â‹…ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥ğ‘â‹…ğ”¼[ğ‘“(ğ‘†)].(Lemma 1)(Lemma2)(Lemma3)
The result is clear by rearranging the above inequality. â—»

Let us finish the proof of Theorem 1 in the following part of this section.

Proof
(Theorem 1) Recall that, p is the sampling probability and ğ‘âˆˆ(0,1]. Hence

ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥=max(ğ‘ğ‘˜,1âˆ’ğ‘)={1âˆ’ğ‘ğ‘ğ‘˜ for ğ‘âˆˆ(0,11+ğ‘˜] for ğ‘âˆˆ(11+ğ‘˜,1].
It is necessary to analyse the relationship between ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡) and f(OPT) with monotone and non-monotone submodular objective functions, respectively, to get the approximation guarantees for both cases.

If f is monotone, then ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)â‰¥ğ‘“(ğ‘‚ğ‘ƒğ‘‡). According to Lemma 4,

ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğœ–2)ğ‘+ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥â‹…ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)]â‰¥(1âˆ’ğœ–)ğ‘(1âˆ’ğœ–2)ğ‘+ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
When ğ‘âˆˆ(0,11+ğ‘˜], it holds that

ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğœ–2)ğ‘+1âˆ’ğ‘â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)>(ğ‘âˆ’ğœ–)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
When ğ‘âˆˆ(11+ğ‘˜,1], it holds that

ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğœ–2)ğ‘+ğ‘ğ‘˜â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)>(11+ğ‘˜âˆ’ğœ–)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
If f is non-monotone, let us define a new submodular and non-monotone function â„:2îˆºâ†’â„â‰¥0 as â„(ğ‘‹)=ğ‘“(ğ‘‹âˆªğ‘‚ğ‘ƒğ‘‡) âˆ€ğ‘‹âŠ†îˆº. Since S contains each element with probability at most p and according to Claim 1, it is clear that

ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)]=ğ”¼[â„(ğ‘†)]â‰¥(1âˆ’ğ‘)â„(âˆ…)=(1âˆ’ğ‘)ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
(6)
Combining Eq. (6) with Lemma 4 yields

ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğœ–2)ğ‘+ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥â‹…ğ”¼[ğ‘“(ğ‘†âˆªğ‘‚ğ‘ƒğ‘‡)]â‰¥(1âˆ’ğœ–)ğ‘(1âˆ’ğ‘)(1âˆ’ğœ–2)ğ‘+ğ‘ƒğ‘Ÿğ‘šğ‘ğ‘¥â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
When ğ‘âˆˆ(0,11+ğ‘˜], it holds that

ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğ‘)(1âˆ’ğœ–2)ğ‘+1âˆ’ğ‘â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)>[ğ‘(1âˆ’ğ‘)âˆ’ğœ–]â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
When ğ‘âˆˆ(11+ğ‘˜,1], it holds that

ğ”¼[ğ‘“(ğ‘†)]>(1âˆ’ğœ–)ğ‘(1âˆ’ğ‘)(1âˆ’ğœ–2)ğ‘+ğ‘ğ‘˜â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)>(11+ğ‘˜âˆ’ğœ–)(1âˆ’ğ‘)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡).
In summary, if f is monotone, the expected approximation ratios are

ğ”¼[ğ‘“(ğ‘†)]>{(ğ‘âˆ’ğœ–)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)(11+ğ‘˜âˆ’ğœ–)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡) for ğ‘âˆˆ(0,11+ğ‘˜] for ğ‘âˆˆ(11+ğ‘˜,1].
(7)
If f is non-monotone, the expected approximation ratios are

ğ”¼[ğ‘“(ğ‘†)]>{[ğ‘(1âˆ’ğ‘)âˆ’ğœ–]â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)(11+ğ‘˜âˆ’ğœ–)(1âˆ’ğ‘)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡) for ğ‘âˆˆ(0,11+ğ‘˜] for ğ‘âˆˆ(11+ğ‘˜,1].
(8)
Eqs. (7) and (8) show that, for ğ‘âˆˆ(11+ğ‘˜,1], the expected approximation ratio becomes stagnated in the monotone case and decreasing in the non-monotone case. Moreover, the computational complexity increases as the sampling probability gets larger. On the other side, for ğ‘âˆˆ(0,11+ğ‘˜], the sampling probability provides adjustment capability for the trade-off between the approximation ratio and computational complexity. As the probability increases for ğ‘âˆˆ(0,11+ğ‘˜], the expected approximation ratios improve for both monotone and non-monotone cases, but the computational complexity also increases.

Recall that the theoretical time complexity is ğ‘‚(ğ‘ğ‘›ğœ–lnğ‘Ÿğœ–). The impact of ğœ– on the solution quality and time complexity is more desirable than that of p. Therefore, this work fixes the sampling probability as ğ‘=11+ğ‘˜ and leave ğœ– as an adjustable designing parameter for the trade-off of solution quality versus time complexity. According to Eqs. (7) and (8), the best expected approximation ratios can be readily obtained, when ğ‘=11+ğ‘˜, as:

ğ”¼[ğ‘“(ğ‘†)]>{(11+ğ‘˜âˆ’ğœ–)â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡)[ğ‘˜(1+ğ‘˜)2âˆ’ğœ–]â‹…ğ‘“(ğ‘‚ğ‘ƒğ‘‡) ifğ‘“ is  monotone  ifğ‘“ is  non-monotone .
â—»

Experiments
This section testifies the proposed algorithm SDTG through experiments using a real database and compares its performance with that of Greedy [19] and Sample [21]. For a fair comparison, this section uses the basic versions of these algorithms without integrating the Lazy strategy [38]. Note that the performance of Sample and FANTOM [5] has already been compared in [21].

Experimental setup
The database used in the experiments is MovieLens 20M [23]. This database contains 20 million ratings and 465,000 tag applications applied to 27,000 movies by 138,000 users. Movies in the database are classified into 19 genres, such as Action, Comedy, Drama, etc. Besides, each movie is also scored according to the relevance with 1128 genome tags forming 12 million relevance scores in total.

The objective of the movie recommendation system in the experiments is to select a shortlist of movies that are representative yet diverse for users based on their favourite movie genres. The objective function is introduced from [5, 21]. Let îˆº be the set of all movies and G be the set of all movie genres. Denote îˆº(ğ‘”) as the set of all movies that belong to the movie genre ğ‘”âˆˆğº. Denote G(i) as the set of genres that the movie i belongs to. Note that one movie can belong to different genres, hence |ğº(ğ‘–)|â‰¥1. Let ğ‘ ğ‘–ğ‘— represent the similarity between movie i and movie j. Denote ğºğœ‡ as the set of all movie genres that the user ğœ‡ likes, ğºğœ‡âŠ†ğº. The movies that can be considered by the user ğœ‡ is contained in the set îˆºğœ‡=âˆªğ‘”âˆˆğºğœ‡îˆº(ğ‘”). The objective function of movie recommendation for user ğœ‡ is given by

ğ‘“ğœ‡(ğ‘†)=âˆ‘ğ‘–âˆˆğ‘†âˆ‘ğ‘—âˆˆîˆºğœ‡ğ‘ ğ‘–ğ‘—âˆ’ğœ†âˆ‘ğ‘–âˆˆğ‘†âˆ‘ğ‘—âˆˆğ‘†ğ‘ ğ‘–ğ‘—
(9)
where ğœ†âˆˆ[0,1] is the penalty parameter for the similarity between movies within the recommendation list S. The objective function Eq. (9) is non-negative, non-monotone, and submodular. The first term of Eq. (9) reflects the representativeness of the selected movies, and the second term helps to increase diversity. It is desired to achieve high objective function value with low computational complexity.

The similarity value between movie i and movie j can be calculated based on the Euclidean distance of relevance scores

ğ‘ ğ‘–ğ‘—=1âˆ‘ğ‘¡=1ğ‘ğ‘¡(ğ›¾ğ‘–ğ‘¡âˆ’ğ›¾ğ‘—ğ‘¡)2â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾âˆš
where ğ‘ğ‘¡=1128 is the number of all genome tags, ğ›¾ğ‘–ğ‘¡ and ğ›¾ğ‘—ğ‘¡ are the relevance scores in terms of the tag t for movie i and movie j, respectively. The calculation of the similarity map took around 35 days on Cranfield HPCâ€”Delta,Footnote1 using 128 CPUs with parallel computing.

The constraints of the movie recommendation system come from the upper limits of the number of movies in total and in each movie genre. The first constraint is an upper limit m on the total number of movies in the movie recommendation list for the user. The second one is an upper limit ğ‘šğ‘” (named as a genre limit) on the number of movies that belong to the movie genre g. According to [21], the movie recommendation system is subject to a |ğºğœ‡|-extendible system constraint.

In the experiments, suppose that the userâ€™s favourite movie genres are Action, Adventure, and Sci-Fi. Then, the constraint of the movie recommendation system is a 3-extendible system constraint. Movies with ids less than 30,000 are within consideration since not all movies have genome scores in the database. Set the upper limit on the total number of movies as ğ‘š=15, and the genre limit as varying numbers from 1 to 6. Set the sampling probability for Sample and SDTG as ğ‘=0.25, and the threshold decreasing parameter for SDTG as ğœ–=0.2. Set the penalty parameter as ğœ†=0.8. Denoted Max Sample (4) and Max SDTG (4) as the best selections from 4 rounds of Sample and SDTG, respectively. The results of Sample and SDTG are based on 100 rounds of these two algorithms. The running time for these algorithms is measured as the number of objective function evaluations which is independent on the computer conditions. Note that, the experimental results for Sample and SDTG vary somehow each time as the algorithms are related to random sampling.

Results
The performance of SDTG is compared with that of benchmark algorithms in terms of both function values and running time in Fig. 1. It is clear from Fig. 1a that, on average, Sample and SDTG related algorithms outperform Greedy in terms of solution quality. The quality of solutions provided by SDTG is better than that of Sample, although SDTG has a slightly worse theoretical approximation guarantee than Sample does. Overall, Max SDTG (4) achieves the highest function value. Figure 1b shows the number of function evaluations consumed by different algorithms. Four rounds of Sample requires the largest number of function evaluations when ğ‘šğ‘”â‰¥2. Relatively, Greedy requires a bit fewer function evaluations than Max Sample (4) does. But four rounds of SDTG requires significantly fewer evaluations. Overall, Greedy and Sample-related algorithms consume increasing numbers of function evaluations as ğ‘šğ‘” goes up. However, the numbers of function evaluations of the SDTG-related algorithms almost stay constant when ğ‘šğ‘”â‰¥2. When ğ‘šğ‘”=6, four rounds of SDTG is even faster than one round of Sample.

Fig. 1
figure 1
Performance comparison of different algorithms

Full size image
Figure 1c, d illustrate the distribution of function value and running time for 100 rounds of Sample and SDTG algorithms. Recall that, Max Sample (4) and Max SDTG (4) represent the maximum values achieved by four rounds of Sample and SDTG, respectively. And Greedy is a deterministic algorithm. Therefore, these three items do not appear in Fig. 1c, d that are for demonstrating the distribution resulted from random sampling. Overall, the function value distribution of SDTG has similar spreads with Sampleâ€™s, but SDTG achieves higher median values than Sample does. In terms of running time, SDTG has significantly smaller spreads and lower median values than Sample does. The comparison between Sample and SDTG indicates that SDTG not only achieves better function values but also is faster and more reliable.

Figure 1e, f demonstrate the ratio comparison of the solution quality and running time of different algorithms. The performance of Max Sample (4) is set as a baseline for other algorithms in comparison. When ğ‘šğ‘”=2, Max SDTG (4) achieves a significantly better function value but consumes fewer function evaluations than Max Sample (4) does. While ğ‘šğ‘”=5, Max SDTG (4) achieves a much better function value (38.4% higher) and consumes a dramatically smaller number of function evaluations (76.1% fewer). On average, SDTG finds better solutions but only consumes 6.1% of function evaluations compared with Max Sample (4). In both cases, Greedy is the least competitive one among all algorithms because it achieves the worst function values and requires the second largest number of function evaluations. SDTG provides high-quality solutions yet consumes the fewest function evaluations, which is of great advantage when handling large-scale datasets.

Discussion
The reason why Greedy performs poorly in terms of solution quality is that it greedily selects the best element during each iteration heading to bad local optima. On the other side, with the help of the sampling process, Sample and SDTG related algorithms are able to avoid those elements that can get the algorithms trapped in bad local optima. The threshold in SDTG can further help the algorithm to avoid those local optima. This is why SDTG practically outperforms Sample in terms of solution quality. Table 1 explains the reason in detail. According to the definition of the genre limit constraint, at most two movies can be selected from each genre of Adventure, Action, and Sci-Fi when ğ‘šğ‘”=2. The maximum number of movies without violating the aforementioned constraint is six. Greedy only recommends three movies and reaches the upper genre limit. However, Max Sample (4) and Max SDTG (4) are able to recommend five and six movies, respectively, which better fit the objective of the movie recommendation system.

Table 1 Movies recommended by different algorithms, ğ‘šğ‘”=2
Full size table
The reason why Greedy performs poorly in terms of running time is that it has to calculate the mgvs of all remaining elements given the current selection to find the best one. Sample is faster than Greedy because it only considers a small portion of the ground set, although it also needs to evaluate all remaining elements in the sample set. Different from Sample, SDTG can stop evaluating once it finds one qualified element and adds this element to the selection set immediately. This means that SDTG does not have to evaluate all the remaining elements in the sample set in order to select an extra element. Therefore, SDTG consumes fewer function evaluations than Sample does on average. In addition, the running time of Sample is highly dependent on the size of the sample set because it needs to evaluate all elements in the sample set. In contrast, SDTG can usually find a qualified element from the front positions of the sample set and stop evaluating. Therefore, the running time of SDTG is less related to the size of the sample set compared with Sampleâ€™s. This is the reason why the spread of running time distribution of SDTG is smaller than Sampleâ€™s.

Trade-off of solution quality vs. running time
This section also examines the impact of the threshold parameter ğœ– on solution quality and running time. This will help us to choose a desirable value of ğœ– and to have a deeper comprehension of SDTG. The value of ğœ– varies from 0.04 to 0.24 with a step of 0.04. Two cases are checked where ğ‘šğ‘” equals to 2 and 5, respectively. Other settings are as same as previous ones. We run 100 rounds of SDTG and record the function values and the number of function evaluations in each round.

Figure 2 demonstrates the experimental results with varying values of the threshold decreasing parameter. The distributions of function value and running time are illustrated in Fig. 2a, b, respectively. Figure 2a shows that the impact of changing ğœ– on function values is not significant. Function values fluctuate slightly when ğœ–â‰¥0.08. However, the solution quality for both ğ‘šğ‘”=2 and ğ‘šğ‘”=5 is obviously worse when ğœ– equals to 0.04 than that with larger values of ğœ–. This is because the threshold decreases very slowly with an extremely small ğœ–. In this case, the mgv of the element selected by SDTG in each iteration is very close to the largest one. As mentioned before, the decreasing threshold can also help SDTG to avoid local optima. An extremely small ğœ– makes SDTG close to Sample, which weakens the advantage of the decreasing threshold. Figure 2b shows that the median values of running time decrease obviously as ğœ– increases. The spreads of running time also become smaller as ğœ– goes up. The reason is that the threshold decreases faster with a larger ğœ–. When evaluating the mgvs of the remaining elements one by one, SDTG can find a qualified element more quickly with a smaller threshold. The running time of SDTG also becomes less dependent on the size of the sample set.

Fig. 2
figure 2
The effect of ğœ– on function value and running time

Full size image
Conclusions
This paper has presented an efficient algorithm, Sample Decreasing Threshold Greedy (SDTG), to deal with big data summarisation problems. The proposed algorithm achieves an expected approximation ratio of ğ‘˜(1+ğ‘˜)2âˆ’ğœ– for maximising general non-monotone submodular objective functions subject to k-extendible system constraints with only ğ‘‚(ğ‘›(1+ğ‘˜)ğœ–lnğ‘Ÿğœ–) value oracle calls. The performance of SDTG is testified and compared with that of benchmark algorithms through experiments with a movie recommendation system based on a widely-used movie information database. The experimental results indicate that the proposed algorithm has great application potentials in large-scale discrete optimisation problems where the sizes of datasets are enormous such as the applications of machine learning and big data science. We believe that our results are also instrumental for the personalised recommendation systems on internet platforms, like Netflix, YouTube, and Amazon, etc. SDTG can be further accelerated by adapting the Lazy Greedy strategy [38]. A future research direction could also be accelerating the proposed algorithm by combining distributed computing.

Abbreviations
SDTG:
Sample decreasing threshold greedy

mgv :
Marginal gain value

OPT:
Optimal solution

Max Sample (4):
Run 4 rounds of Sample and get the maximum function value

Max SDTG (4):
Run 4 rounds of SDTG and get the maximum function value

