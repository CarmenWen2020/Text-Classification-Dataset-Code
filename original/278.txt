It is essential to comprehend different aspects of performability of a system adopting Moving Target Defence (MTD) techniques. A number of previous works showed significant progress on security effectiveness evaluation for MTD mechanisms. While, a lesser amount of studies considered the impact of running MTD mechanisms on system dependability metrics, exposing a critical missing on the comprehension of pros and cons of MTD mechanisms in terms of security and dependability. In this paper, we present comprehensive modelling and analysis of time-based switch-over MTD strategies complying with IP shuffling techniques deployed in a Software Defined Network (SDN) using stochastic reward net (SRN). To investigate the impact of MTD strategies along with system availability on service performance metrics, we propose performability SRN models for various switch-over MTD strategies. The modelled behaviours of the switch-over MTD strategies are based on the integration of service management policies (drop/accept) with time-based switch-over policies (zero-time, fixed-time, and variable-time waiting policies) Critical performability metrics are comprehensively evaluated, including (i) system availability, downtime minutes, and Capacity-oriented Availability (COA) of a service, (ii) service throughput, (iii) response time of a job, (iv) average utilization of a server, (v) number of lost jobs, and (vi) operational cost (power consumption and business profit loss). The analysis results reveal sophisticated operational system behaviours and the impact of MTD strategies on system performability metrics. This study can help design and plan the development and adoption of MTD strategies in practice regarding the trade-offs between security and performability assurance.


Keywords
Moving 
Target Defence
Software 
Defined 
Network
Performability
Stochastic reward net

1. Introduction
Moving Target Defence (MTD) has recently emerged as a novel paradigm to proactively and adaptively protect systems and networks (Cho et al., 2020a). The main concept of MTD techniques is to introduce a dynamic and endlessly evolving attack surface thus, increasing uncertainty and complexity across different system dimensions for malicious attacks. The static and defenceless natures of modern computing infrastructures unacceptably provide skewed advantages to attackers who can make use of existing vulnerabilities and to penetrate the system to take further malicious actions. MTD comes into play and revolutionizes the defensive technologies in cybersecurity. Falling under the general category of proactive defence strategies, MTD is capable of stopping sophisticated cyber-attacks and preventing an attack before it happens (Sengupta et al., 2020). The dynamic nature of change throughout a system provided by an MTD strategy helps establish a certain level of operational uncertainty that can obviously impede the progress of malicious actions and thus narrow the window of opportunities for cybercriminals. The biggest and most apparent supremacy of MTD is that (i) few false positives can be generated, thus workload can be reduced and system efficiency is enhanced and therefore, the economic burden on the system resources is lessened while substantially securing the system’s cybersecurity regardless of business size; (ii) the real-time randomization mechanisms of MTD strategies cause arduousness to discover an access point and execute a malicious penetration into a target system (Lei et al., 2018); (iii) the uncertainty of MTD techniques help prevent an attack even without prior knowledge of the attack by breaking delivery mechanisms into pieces and thus killing attack chains.

The implementation of MTD strategies. in practice can be performed using various techniques such as (i) changing network topology at a network level, (ii) changing host and OS-level resources, naming and configuration at the host level, or (iii) changing application environment at the application level. In Cho et al. (2020a), Cho et al. introduced an insightful classification of MTD techniques into (i) timeliness-based MTD techniques and (ii) operation-based MTD techniques. Time-based MTD strategies are among popular ones in the category of timeliness-based MTD techniques in which an MTD process to alter an existing attack surface is triggered as soon as a time threshold is violated. The duration between consecutive MTD events is called MTD interval. If MTD interval is a fixed-time value, the MTD mechanism is periodically triggered. While, a variable-time MTD interval indicates that the moments of triggering an MTD process can vary upon a certain set of user-defined conditions is satisfied (for instance, existing requests/services are completely processed, or not). It is a matter of curiosity on how the selection of MTD interval values can help diminish the risks of malicious penetration but not degrade the performance of services. Event-based approach adaptively deploys MTD techniques upon the occurrence of a certain event which is often recognized (or predicted) by a defender as an indication of malicious actions. Hybrid approach employs the above time and event-based MTD strategies to execute MTD mechanisms to obtain proactive and reactive defence. Based on the criteria of “How to move”, Hong and Kim in Hong and Kim (2015) classified operation-based MTD techniques into shuffling, diversity and redundancy. Shuffling MTD techniques are implemented upon the randomization and rearrangement of system configuration (e.g., IP address shuffling), which intentionally causes confusion and uncertainty for malicious actions. Diversity MTD techniques adopt the diverse implementations of system components to secure system resilience in the presence of malicious attacks. And, MTD redundancy techniques aim to secure system dependability (e.g., reliability or availability) by deploying multiple replicas of system/network components thus, offering redundant solutions for the same services if insider threats exist and network nodes or system components are compromised.

Software Defined Network (SDN). enabled by Network Functions Virtualization (NFV) technology has been a dominant computing paradigm in the past few years that possibly decouples the network control and forwarding functions from its physical infrastructure to enable the direct programmability of network control and the abstraction of underlying network infrastructure for applications and network services (Xia et al., 2014). Thanks to the flexibility and programmability, a variety of MTD mechanisms can be easily implemented in the network to secure cybersecurity and system dependability. Different MTD mechanisms have been introduced based on the flexibility and programmability features of SDN such as OpenFlow Random Host Mutation (OF-RHM) (Jafarian et al., 2012b) and Flexible Random Virtual IP Multiplexing (FRVM) (Sharma et al., 2018a) by shuffling virtual IP () of a networked system. Effectiveness Assessment of MTD strategies adopted in a certain networked system has been accomplished in many previous works. Nevertheless, most of the studies presented different security models to explore the effectiveness of MTD strategies in terms of various security metrics. Hong et al. in a number of works (Hong and Kim, 2014, Hong and Kim, 2015) developed a scalable modelling methodology using a security model, namely Hierarchical Attack Representation Models (HARMs) (Hong and Kim, 2013) to evaluate the security effectiveness of MTD techniques in various systems. The main contributions of these works are to assimilate how to evaluate the effectiveness of MTD techniques regarding security metrics (but without considering any performability metrics) and to provide the means for the purposes. The studies in these works developed a novel framework and methodology to assess the security effectiveness of MTD techniques. In Yoon et al., 2020b, Yoon et al., 2020a, Cho et al. presented a security effectiveness assessment of MTD in SDN networks using Attack Graph (AG) in which the author’s proposed two novel assess criticality metrics including role-based criticality (RC) and influence-based criticality (IC) are evaluated. Alavizadeh et al. investigated the security effectiveness of the combination of two MTD techniques including shuffle and redundancy considering two security metrics, system risk and reliability, in Alavizadeh et al. (2020). The works Lei et al., 2018, Sengupta et al., 2020 and Cho et al. (2020b) presented fine-grained metrics for effectiveness assessment of MTD techniques adopted for network security. In regard to effectiveness measurement of MTD techniques, the authors presented a comprehensive categorization of qualitative and quantitative analyses for MTD techniques in which (i) qualitative metrics encompass security and performance considerations of individual defences and ensemble, while (ii) quantitative metrics consists of security metrics, such as Confidentiality, Integrity, and Availability (CIA) metrics, risk metrics, policy conflict metrics, and usability metrics, such as cost metrics and Quality of Service (QoS) metrics.

As investigated in literature, the majority of previous works proposed different MTD techniques and their appropriate modelling for effectiveness assessment with only considerations (and therefore, highlight) on the security assurance and improvement while slightly neglecting the impact on system performance and quality of provided services. Only few recent works explored different aspects of system performance and QoS of a target system adopting specific MTD techniques. In El Mir et al. (2018), El Mir et al. presented a preliminary Markov chain model for performance evaluation of an SDN-enabled cloud data centre adopting virtual machine (VM) migration techniques as an MTD technique in the events of malicious attacks. The authors only considered three operational states including running state (R), vulnerable state (V), and migration state (M). And the assessment metrics are availability, service downtime and downtime cost. In Connell et al. (2018a), Connell et al. presented continuous time Markov chain (CTMC) models for mean response time computation of a virtualized system with multiple VMs adopting wait/drop re-configuration policies during an MTD process under resource limits. Cai et al. in Cai et al. (2016) proposed generalized stochastic Petri net (GSPN) models for performance evaluation of three main typical MTD techniques including (i) software transformation (ST), (ii) dynamic platform techniques (DPT) and (iii) network address shuffling (NAS) deployed in a web server system. Torquato et al. in Torquato et al. (2020) proposed the employment of VM migration as an MTD technique deployed in virtualized systems and then, developed SRN models for the probability of attack success and availability evaluation of the technique. Mendonça et al. in the most recent work Mendonça et al. (2020a) proposed Deterministic and Stochastic Petri Net (DSPN) models for performance-related effectiveness assessment of a time-based MTD strategy adopted on a specific SDN with a single physical server considering the availability of physical subsystems. The above studies are among a few recent works exploring different aspects of the impact of MTD strategies on the performance and quality of service of a target system.

As far as we observed, previous works in literature have contributed rapid progress in effectiveness assessment of MTD techniques adopted in network systems considering security metrics, but lesser progress in terms of performance metrics and quality of provided services. Particularly, none of the previous works considered detailed strategies for provided services and their effectiveness assessment in the progressing of MTD implementation. While very few works considered the impact of both operational availability and the implementation of MTD strategies on system performance. In this paper, we propose comprehensive SRN models for the performance-related effectiveness assessment of a time-based switch-over MTD strategy adopted in an SDN. We explore the impact of different strategies for quality control of provided services in the switch-over MTD technique on various system performance metrics. Furthermore, the proposed MTD strategies can protect an SDN-based network system against network-level threats such as denial of service or information disclosure in STRIDE threat models (Shostack, 2014). A time-based IP shuffling technique provides a time-limited attack surface for an attacker to access to connected web servers and it leads to the increase of attack costs that intruders should waste. For example, Denial-of-Service (DoS) attackers (e.g., SYN flood attack) can occupy only a certain period of time to reconnaissance targets and overwhelm system resources since virtual IP addresses of network targets keep being changed and an MTD adoption can actively help bring DoS migration.

Main contributions.
This paper extends the progressing of the related research area on effectiveness assessment of MTD strategies adopted in network systems through the following key contributions:

(i.)
Proposed a set of comprehensive performability SRN models to capture sophisticated operational behaviours of time-based switch-over MTD strategies to provide a high level of service quality in an SDN. As captured in the models, we investigate the delivery of services from a certain client throughout the network infrastructure all the way to a certain physical SDN server. The implementation of MTD strategies is based on IP shuffling and redundancy techniques of SDN servers and managed by SDN controller, which is captured in a detailed manner in the SDN models. The triggering of MTD processes is controlled by an MTD clock model. The switch-over mechanism of services in the progressing of MTD strategies is also captured in a comprehensive manner in the network-server model while the processing of different types (long/short) of jobs is modelled in server models. Furthermore, we also investigate the impact of operational availability of physical subsystems on system performance by using two-state (up/down) models.

(ii.)
We explored the impact on system performance and service quality of seven time-based MTD strategies along with a switch-over mechanism adopted in an SDN with redundant servers by using proposed SRN models. Based on the combination of job and time management policies, we developed seven performability SRN models capturing complex behaviours of service delivery in the progressing of MTD strategies.

(iii.)
Performed various quantitative analysis experiments for the assessment of performability and service quality provided by an SDN adopting time-based MTD strategies including (i) availability analyses considering operational availability of physical subsystems and COA of service delivery, (ii) performability analyses in regard to various performance metrics including service throughput, meant response time of a server, the average utilization of a server, number of lost jobs in a unit period of time, and (iii) operational cost analyses with respect to operational cost due to power consumption and cost due to profit loss.

Research findings.
Throughout experimental results, we come to draw the following research impacts.

–
Highly frequent execution of MTD strategies may enhance security assurance on one face but apparently cause a severe degradation on performance of the system.

–
Full dropping policy applied for jobs at all locations in the progressing of an MTD strategy guarantees the security efficacy of MTD mechanisms, however, evidently having severely negative impacts on system performance.

–
Waiting policy for the completion of processing jobs in servers in the execution of MTD strategies clearly reduces the impact of dropping policy.

–
Accepting policy for jobs in servers’ service queue and jobs in transit in the network even help diminish the negative impact of the dropping policy and the execution of MTD processes on the system performance. Specifically, the acceptance of jobs in servers’ service queue when performing MTD processes shows a clear improvement in performance metrics while the acceptance of jobs in transit in the network slightly improve, in comparison with the above mentioned full dropping policy.

–
Sensitivity of performability metrics wrt. impacting parameters are, (i) server utilization and service throughput are overly sensitive wrt. job arrival rate and service rate of servers; (ii) service response time manifests the highest sensitivity wrt. service rate while, it is overly sensitive wrt. job arrival rate and the ratio of long/short job types; (iii) the number of lost jobs (thus, operational cost) is overly sensitive wrt. job arrival rate and high repetition of MTD execution.

To the best of our knowledge, this paper presents a comprehensive and complete performability modelling and evaluation of switch-over MTD strategies adopted in an SDN considering a variety of fine-grained operational policies at a very early stage of current research on security and performability efficiency assessment of MTD strategies in networked systems for the first time.

Paper structure.
In Section 2, we present literature review of previous works in relation to this work. System architecture of a specific SDN is presented in Section 3. In this section, we also detail job and time management policies and the formation of different MTD switch-over strategies along with the life-cycle of a job for service delivery in the SDN. The development of performability SRN models is presented in a comprehensive manner in Section 4. The presentation of experiments and analysis results is shown in Section 5. The conclusion of this paper is presented in Section 6.

2. Related work
Moving Target Defence (MTD) provides a state-of-the-art mechanism to thwart the attacker’s reconnaissance by dynamically changing the attack surface of the system. MTD aims to increase uncertainty and/or unpredictability of the system leading to the rise of attack cost that potential adversaries spend more resources and time on the vulnerability of target systems. With the purpose of the complexity of the system configuration, the MTD researchers proposed operation-based MTD techniques (i.e., shuffling, diversity and redundancy) that are categorized by Hong and Kim (2016). Among these MTD techniques, the shuffling technique rearranges or randomizes system and/or network configurations by timeliness-based policies of MTD or event-based and has been proved to play an effective impact on defence mechanisms against the reconnaissance attack (Cho et al., 2020a). As one of shuffling techniques continuing to reassign network configurations, SDN-based network shuffling (Jafarian et al., 2012a) has been proposed to continue to change IP addresses of servers based on DHCP update. FRVM suggests multiple time-variant network shuffling that virtual IP addresses assigned to the real IP addresses of hosts are randomly reassigned and continue to be changed (Sharma et al., 2018b). These network shuffling techniques have benefits to increase the unpredictability of the attack surfaces in terms of network resources and thwart the behaviours of potential attackers over the network. Apart from the other classified MTD techniques (i.e., shuffling and diversity), the main purpose of adapting the redundancy service providing multiple replicas of network systems with the same implementation is to enhance availability and/or reliability of the system for legitimate users against attacks (Cho et al., 2020a). In Yuan et al. (2013), Yuan et al. proposed to use exact replicas among multiple web servers in order to alleviate the impact of potential malware injection attacks. In this paper, we propose a switch-over strategy that provides the secondary server. It is expected to offer higher system reliability and availability than when a primary server only works at MTD adaptation. The second server can deal with the new coming jobs from legitimate clients while a primary server continues to manage current remaining jobs without disconnection with clients when MTD is triggered. This configuration of two servers (i.e., primary and secondary servers) can improve the performance degradation in the system adapting MTD mechanisms.

SRNs can be used to formalize the performability models of the network systems (Trivedi and Bobbio, 2017). The reward rate definitions of SRNs specified by the number of tokens in a place or the rate of transition is computed to evaluate performance measures and availability of the dynamic systems. Mendonça et al. introduced performability modelling and evaluation with DSPN to evaluate the side effects when time-base MTD techniques are deployed on the systems (Mendonça et al., 2020b). They have computed maintenance costs and system degradation caused by the number of requests lost. The authors measured performability and security effectiveness by the proposed models. However, we proposed several strategies (e.g., switch-over) in this work to reduce the probability of dropped jobs caused by network reconfiguration. We designed the analytic models called SRN with the purpose of conducting experiments and analysing performability of the system adapting MTD.

Whilst MTD has security benefits as a proactive defence mechanism, performance degradation is one of the side effects in the systems caused by continuous changes of configuration. Performability analysis in the system adapting MTD has been studied to estimate the system overhead and find optimal system parameters to minimize its drawback and to maximize the security effectiveness of MTD. Leeuwen et al. (2015) represent the cost to resources and performance of an MTD approach which is considered the defensive work factor. Performability models and metrics called Application Performance Monitoring (APM) and Network Performance Monitoring (NPM) have been proposed to estimate the stability of the MTD system based on response time and resource usages. Connell et al. (2018b) describes a quantitative analytic model to estimate resource availability and performance in the system adapting MTD. The reconfiguration limits are proposed as a metric to maximize a utility function and reduce the trade-offs between security and performance. However, these papers did not suggest any alternative countermeasure to reduce performance degradation due to MTD adaptation. In this paper, we will propose job management strategies and policies in order to decrease the performance overhead of SDN-based network systems adapting MTD techniques and evaluate them by modelling SRNs.

3. System architecture
This section presents a SDN-based network utilizing a time-based MTD mechanism. SDN is a programmable network system that can dynamically change network configuration according to security policies. A time-based IP shuffling reassigns virtual IP () address into real IP () address of end-servers that can be updated into Domain Name Server (DNS). Legitimate clients can obtain the valid  from DNS and send requests to enterprise servers. Dynamic IP mutation provides security benefits (e.g., increasing complexity), however, it accordingly enlarges performance overhead due to the unintended disconnection between legitimate clients and enterprise servers.

In order to reduce performance degradation in network systems due to MTD, we proposed a switch-over strategy in Fig. 1 offering the additional server (aka server ) that has the same implementation and functions as server . A server  and a replica () deal with newly incoming requests from clients, in turn, every MTD intervals while its counterpart retains the current connections with legitimate clients and keeps processing remaining jobs in transit or in queues of servers according to predefined policies or rules. SDN controller manages  tables and adds flow entries to change  into  in the connected switches (SW2 and SW2) respectively. The key role of an SDN controller in our proposed system is to update flow tables of the connected switches according to the proposed MTD policies and renew new virtual IP addresses to a DNS server. As a control plane of an SDN system, an SDN controller is required to keep inserting or deleting flow rules in the table of each switch and update the database of a DNS server every MTD interval. It results in the increase of workload in an SDN controller of our proposed system compared to conventional systems. Furthermore, It leads that end-servers can communicate with the legitimate client by only using their own . However, these clients do not realize when the MTD technique is applied until they re-resolve the IP address from DNS server again. TTL, one of DNS attributes can be used of course however, the disconnection between end-servers and clients is not resolved. Therefore, we propose a switch-over strategy in order to minimize connection loss over the network adapting MTD and evaluate in terms of performability in a quantitative manner.



Fig. 1. SDN based network system.

Client types and behaviours.
An enterprise network provides Web-based documents to clients. A client sends an HTTP request for receiving web data by HTTP methods (e.g., GET) and a web server responds to transmit the requested web data fragmented by multiple packets over the network. The established connection between a client and a server should be maintained until receiving the requested data is done. The service time of receiving data depends on the size of requested web data by a client. Since our focus is purely on performability assessment and effectiveness investigation of MTD strategies on system operations rather than security effectiveness, all coming requests (either legitimate or non-legitimate) are assumed to originate from unknown users (either attackers or naive clients).

Job management policies.
During an MTD switch-over process, the reduction of the sojourn time in which a server with an obsolete  is exposed to potentially malicious attacks is a significant matter in the way that the selected MTD switch-over strategy must secure the security effectiveness of the MTD strategy but also not significantly damage the performability of services provided by the SDN. We introduce different job management policies that come along with MTD switch-over strategies to realize the trade-offs between security and performance metrics of the system. It is contrary that abruptly dropping ongoing jobs and finalizing an MTD switch-over process to reduce the sojourn time of exposing servers to malicious attacks apparently provides security assurance but probably degrade the overall performance of the system. It is a matter of curiosity if different management policies for jobs in different places in the network in the progressing of MTD switch-over strategies can offer better security assurance with better or worse performability levels. We employ three types of job policies upon the states of each job including (i) drop () for any job in the network regardless of its place, which is to mean that the jobs can be abruptly dropped as soon as MTD switch-over process is conducted, (ii) waiting () for ongoing jobs in the servers, which indicates the processing of those ongoing jobs in the servers remains until completed during the MTD switch-over process and (iii) accept () for in-transit jobs in the network and not under processing in the servers, which is to imply that the jobs in transition are not dropped and retained for further processing and their transition continues in the network towards a certain server.

Job management policies throughout the network are formed and combined upon job states at difference places during the progressing of MTD switch-over process as shown in Table 1. We consider three states of jobs when transiting in the network including (i) jobs in transit in the network towards a certain server, (ii) jobs in a server’s service queue, and (iii) jobs under processing in a certain server. Particularly, job policies during the progressing of MTD switch-over strategies include:


Table 1. Job management policies in MTD switch-over process.

Policies	Jobs in Transit	Jobs in Servers’ Service Queue	Jobs in servers
DDD	DROP	DROP	DROP
WDD	DROP	DROP	WAIT
WAD	DROP	ACCEPT	WAIT
WAA	ACCEPT	ACCEPT	WAIT
–
: When MTD is triggered, all jobs in all places are dropped forcefully. As all ongoing jobs are discarded, the performance degradation due to MTD adoption is increased but it is expected that MTD’s security benefits are accordingly increased because the connection with a potential attacker is also limited.

–
: When MTD is triggered, all ongoing jobs under processing by server workers are remained to finish while all other jobs in transit and in servers’ service queues are dropped forcefully. Once a client starts receiving web data, it can expect all web data is delivered even an MTD technique is applied to the system.

–
: When MTD is triggered, jobs in servers are awaited for completion, jobs that reside in servers’ service queues are accepted to be processed afterwards but jobs in transit are dropped. It can guaranty the QoS of the web service if the connection is successfully established between clients and a server.

–
: When MTD is triggered, jobs in servers are continuously processed and all other jobs are accepted to be processed until the next MTD interval. It can handle all packets or jobs incoming into the network and web server within an MTD interval and provide the web service with the reduction of performance degradation compared to other job management policies.

MTD waiting time policies. The switch-over of jobs in an MTD process from a certain server to the remaining one is secured by the above-described job management mechanisms and also by the MTD time management policies, which are the two adjusting measures in order to secure security and performability of services in the event of triggering MTD switch-over process. If the job management mechanisms include four job policies (, ,  and ), MTD time management policies are (i) zero waiting time (zero-time), (ii) fixed waiting time (fixed-time) and (iii) variable waiting time (variable-time). The zero-time policy is to mean that jobs are dropped immediately regardless of their states. While, the fixed-time policy implies that the waiting for the completion of jobs in a server is constrained by a time threshold and every MTD switch-over process lasts until the fixed waiting duration expires. When the threshold is violated, existing jobs are abruptly dropped. The variable-time policy indicates the waiting duration for the completion of job processing in servers varies upon the moment that jobs are completely processed. This is to mean that when the processing of all jobs are completely finalized, the MTD switch-over process is finished in accordance. Nevertheless, if the waiting lasts long until the threshold of the waiting duration is violated, this variable-time policy becomes the fixed-time policy in which all jobs are abruptly dropped regardless of their states.

MTD switch-over strategies: The formation of different MTD switch-over strategies is based on the combination of job management mechanisms and the corresponding MTD waiting time policies for the processing of each job as shown in Table 2. Particularly, employing dropping policy for all jobs (or in other words, zero-time policy for MTD waiting duration) we obtain  MTD switch-over strategy. If waiting policy is employed for ongoing jobs in servers and accept or drop policies are applied for other jobs along with fixed-time policy, the MTD switch-over strategies are ,  and . In these strategies, the fixed-time policy is commonly used for adjusting MTD waiting duration while the job management mechanisms are ,  and , respectively. In the same way, if the variable-time policy is applied for observing the MTD waiting time, we can obtain the MTD switch-over strategies ,  and , respectively. We will develop performability models to capture operational behaviours in a comprehensive manner for each of the above MTD switch-over strategies in Section 4.


Table 2. MTD switch-over strategies.

Job	Waiting Time
zero-time	fixed-time	variable-time
DROP	DDD	DDD	n/a	n/a
WDD	n/a	fWDD	vWDD
WAITING	WAD	n/a	fWAD	vWAD
WAA	n/a	fWAA	vWAA
Life-cycle of a job:
As an MTD technique (i.e., IP shuffling) alters the network configuration of systems (i.e., virtual IPs), the ongoing jobs in network components are effected when a time-based MTD is triggered. SDN-based switches play a role in switching jobs (i.g., packets) in transit and in modifying the packet’s source or destination IP address according to the MTD operation while the service queues and worker processes in the host servers manage jobs in progress and serve services to the connected clients. However, IP mutations by MTD adaption can affect all ongoing jobs in transit or in progress over the network system as can be seen in Fig. 2. Without any proposed job management policies (i.e., WDD, WAD, WAA), all remaining jobs over systems will be dropped, which we define this as one of the policies, DDD. Under DDD policy, the ongoing packets in transit will be dropped due to no matched rules with the out-dated vIP while jobs in progress at service queues and service processes are flushed caused by the disconnection between servers and clients. The job loss can accordingly be expected if the number of ongoing jobs is considerably large. Therefore, we suggest other policies (i.e., WDD, WAD and WAA) in order to reduce the performance degradation due to the loss of remaining jobs in transit or in progress. The job management policy, WDD suggests that host systems keep processing the retaining jobs on their workers and jobs in transit and in service queues are dropped. In addition to service processes, the job management policy, WAD suggests that jobs in service queues retain their connection with clients until service workers complete the waiting job. The last job management policy, WAA guarantees to keep processing remaining jobs both in transit and in progress until all jobs are completed or waiting time is expired over the networked systems. WAA can seemingly be expected to better QoS regarding the probability of job completion.

Performability metrics.
To assimilate the effectiveness and impacts of the above-described MTD switch-over strategies, specific performability metrics are employed including (i) operational availability and (ii) Capacity-oriented Availability (COA), (iii) service throughput, (iv) response time, (v) average utilization of a server, (vi) number of lost jobs, (vii) operational cost due to power consumption and profit loss. The details of these performability metrics are presented in Section 5.1.



Fig. 2. Life-cycle of a job: Job processing under the adoption of MTD switch-over strategies at SDN network switches, a server’s service queue and a server’s processing workers.

Operational overhead.
The operational overhead of a target adopting an IP shuffling technique is required to increase abrupt disconnection between legitimate clients and a server an additional server (aka. replica) for the proposed switch-over strategy. Compared to the static system, an MTD technique requires dynamic changes in an attack surface and it brings about the decrease of QoS (e.g., frequent connection loss) while a connected server serves client’s requests. Furthermore, the switch-over strategy for the sake of the performance enhancement requires an extra replica that compulsorily needs more hardware or software resources to handle web services at running.

4. Performability models
This section presents the proposed performability SRN models to evaluate performability of services running on an SDN.

4.1. Overall system model
Performability system model is composed of (i) availability model and (ii) performance model as shown in Fig. 3. The availability model consists of five two-state availability models for modelling failure/recovery behaviours of the SDN’s physical subsystems including SDN controller, DNS server, SDN network devices and SDN servers. Performance model comprises (i) clock model for the implementation of time-based MTD techniques, (ii) network-server model for capturing the transitioning flow of jobs within the network in advance of being allocated to a certain server, and (iii) server  and (iv) server  models for modelling the processing of a job within the servers. Without loss of generality, the initial state of the system starts with all normal states of the physical subsystems represented by tokens in their  places in the availability model including 
, 
, 
, 
, 
 to indicate the initially normal states of SDN controller, DNS server, SDN switches and the servers  and , respectively from the beginning. Furthermore in the performance model, the initial state of the MTD clock is represented by a token in the place 
 indicating the passing of time observed by the clock model. On the other hand, the initial state of the servers  and  is marked by the  tokens residing both in the places 
 and 
 indicating the initial processing capacity of each server. While, the number of tokens initially placed in 
 and 
 is  to represent the capacity of servers’ service queues. The initial placement of  tokens in the places 
 and 
 and  tokens in the place 
 and 
 implies that there is no processing at on the servers in the beginning. At last, one token is initially placed in 
 to indicate the selection of the server  as the primary server to process coming client requests, without loss of generality. Initial transitions can be enabled in the availability model including 
, 
, 
, 
 and 
 to indicate the failure events of the physical subsystems in a stochastic manner. In addition, the transition 
 in the MTD clock model is also enabled to depict the passing of time (note that, the firing of this transition denotes the completion of an MTD interval (). At last, the initial transition 
 is also enabled to represent the stochastic arrival of client requests. To guarantee the correct behaviours and interactions between the sub-models as expected to represent the sophisticated operations in the system when adopting MTD strategies, a number of guard functions is employed as shown in Table 4 to control the movement of tokens in all places so that the overall system model can capture exactly the expected behaviours and operations as described in Section 3. The system model is used to perform simulations and to analyse the performability metrics as described in Section 5.1. In the following, we present the details of behaviours and interactions captured by the system model into separated sub-models.

4.2. Availability models
Availability models of physical subsystems are presented in Fig. 4. The figures Fig. 4(a), Fig. 4(b), and Fig. 4(c) depict the availability modelling of SDN controller (), DNS server (), and SDN network devices (routers/switches) (), while Fig. 4, Fig. 4 display the availability models of server H1 () and server H2 (), respectively. A common technique in availability modelling of a physical system for simplicity and largeness reduction is to use a two-state model as shown in Fig. 4(f). An extension of the availability models can be the consideration of more complicated operational multi-states as shown in (Nguyen et al., 2014). With an assumption that availability dependencies among the SDN subsystems are neglected, failure and recovery behaviours of a certain SDN physical subsystem (denoted as ) can be captured by UP and DOWN states as in Fig. 4(f). A token in the place 
 represents the operational state of the subsystem . On the other hand, when the place 
 has a token, it means that the subsystem  is not working. The timed transitions 
 and 
 capture the state transition in which (i) 
 indicates failure events and (ii) 
 represents successful recovery events. As soon as the running subsystem  experiences an uncertain failure with a failure rate of 
, the timed-transition 
 is enabled and the token in 
 is taken out and deposited in the place 
. When the recovery of the failed subsystem  with a mean time of 
 is completed successfully, the timed transition 
 is fired, the token in 
 is subsequently taken out and returned to 
, which indicates that the subsystem  returns to its initially normal state. The above model description is similarly used for other two-state models represented by Figs. 4(a)–4(e) in the way that  can be replaced by other notations which corresponds to the physical subsystems ( for SDN controller,  for DNS server,  for SDN network devices,  and  for server  and server ), respectively.

4.3. Performance models
4.3.1. Network-server model
Fig. 5 depicts the network-server model for capturing the behaviours of jobs travelling within the SDN network before entering a certain server.

Job arrival.
Particularly, job arrival events are represented by the timed transition 
 with an arrival rate of . When 
 fires, a token is deposited in 
. The presence of tokens in the place 
 indicate the jobs that have arrived at the SDN gateway (GW) which is in turn managed by the SDNs controller. In the first step, the client communicates with the DNS server to lookup a  address of a certain server in the SDN and the  address of a certain physical SDN server to process a job is retrieved from the DNS server. The retrieval of a  address consumes a period of time 
 in average and is represented by the timed-transition 
. When the interaction between a client and the DNS server completes and a server’s  address is assigned, the timed-transition 
 is fired and a certain token in 
 is removed and deposited in 
. In the worst-case scenarios, when a job arrives and awaits the assignment of a server’s  address, a certain physical subsystem among SDN controller, DNS server or SDN gateway may fail at the time, which causes a severe drop of arrived jobs. The immediate transition 
 associated with a guard function 
 is used to capture the above-described drop of arrived jobs due to failures of physical subsystems by removing tokens in 
 when the presence of a token in any of the places 
, 
 or 
 is recognized, which indicates the downstate of the physical subsystems. If a  address of a server is assigned to a job, a token representing the job is present in 
.

vIP retrieval.
In the beginning, since server  is chosen as the initially primary server, arrived jobs are directed to server  by assigning  to the jobs. Nevertheless, in other cases, arrived jobs can be directed to server  with a certain  address. The selection of a server to process arrived jobs is represented by a token in the place 
 or 
 indicating that arrived jobs are directed to server  or , respectively. The presence of a token in 
 enables one or the other of two immediate transitions 
 or 
 in correspondence to the assignment of  or , respectively. The token representing a job which associates with a  () address is taken out from 
 and deposited in 
 (
) in accordance with the corresponding firing of either 
 or 
.


Fig. 5. Network-Server Model.

Establishment of TCP/IP connection.
A job associated with a specific  address ( or ) is then transited to SDN switches. But, the client cannot establish a connection to a physical server due to the absence of routing rules on the SDN switches. At this point, SDN switches communicate with the SDN controller to verify the client’s connection job. The SDN controller sends a packet to a specific server to initiate a connection between the client and the selected server. Also, the SDN controller updates routing rules of SDN switches and a TCP/IP connection between the client and a certain SDN server is established for the in-transit job associated with a  of the selected server. The above-described authentication and establishment process of client–server connection progresses in a mean duration of 
 and is captured by the timed-transition 
 (
). The events that a job associates with a  address , which is represented by a token in 
 (
), enable the timed-transition 
 (
). When the authentication process completes and a client–server connection is established, 
 (
) fires to take out a token from 
 (
) and deposit in 
 (
). The presence of a token in 
 (
) indicates the successful establishment of client–server TCP/IP connection for an in-transit job. In the middle of the verification process and establishment for client–server connection, one or the others among the physical subsystems SDN controller, SDN switches or DNS server can fail. On the other hand, in-transit jobs and client–server connection can be terminated if drop-out MTD strategies (, , or ) are adopted for the in-transit jobs. The dropping of in-transit jobs and client–server connection in these cases are captured by the firing of the immediate transitions 
 (
) and 
 (
) associated with corresponding guard functions 
 (
) and 
 (
) to remove tokens in the places 
 (
) and 
 (
), respectively.

Queuing of in-transit jobs.
When client–server connection has been established (represented by a token in either 
 or 
), the job with a predefined job transits throughout SDN switches associated with routing policies in the direction to a selected server. The jobs are immediately queued into a network queue which is a representation of the holding of jobs at SDN switches. The immediate transitions 
 and 
 model this operation by generating a token into 
 or 
 after removing a token from 
 or 
, respectively. The tokens in the place 
 (
) indicate that in-transit jobs are in travel throughout the SDN switches towards a respective server. The jobs are queued and transited throughout the SDN switches until they reach the SDN switch that connects to the physical server. The timed-transitions 
 (
) model the queuing of in-transit jobs in the network. When these transitions fire, a token is taken out from the places 
 (
) and deposited in 
 (
). The presence of a token in 
 (
) means that the in-transit jobs are in the network queue and are ready for receiving by the server  (), respectively. The entrance of a job in the server is captured by the timed-transitions 
 (
). The firing of these timed-transitions 
 (
) enqueues a job in the network queue into the service queue of the corresponding server  (). Note that the conditions for a job to be enqueued in the service queue of a server are when all physical subsystems (SDN controller, SDN switches and DNS server) and the selected server are operational in order to maintain the client–server connection and the processing of jobs on the server. The guard functions 
 (
) are associated with 
 (
), respectively to verify the satisfaction of the enqueue conditions for a job in the network queue (represented by tokens in 
 (
)). In addition, in the cases that either one of the physical subsystems (SDN controller, SDN switches and DNS server) are in downtime (represented by a token in 
, 
 or 
) or drop-out MTD strategies (,  or ) are applied, the jobs in transit and the jobs in the network queue (represented by tokens in 
 (
) and 
 (
), respectively) are terminated, which is depicted by the firing of the immediate transitions 
 (
) and 
 (
) to take out the tokens in the respective places representing for jobs in transit (
 (
)) or jobs in network queues (
 (
)). Furthermore, the jobs in the network queue (represented by tokens in 
 (
)) can also be blocked and dropped if the respective service queue is full. The status of a full service queue is investigated by the guard functions 
 (
) when looking up the number of the remaining service queue capacity represented by the number of tokens in the places 
 (
) as shown in the server models Fig. 6, respectively.

Job switch-over.
When MTD switch-over strategies are adopted, arriving jobs are directed from one to another physical server among the primary and secondary servers. While, in-transit jobs, jobs in network queue, jobs in service queue and ongoing jobs in servers can be dropped or accepted upon adopted switch-over mechanisms. In the network-server model, the switch-over behaviours of in-transit jobs are captured in a comprehensive manner in relation to the clock models and the server models. When the conditions to trigger an MTD switch-over are satisfied as given by the state of a clock model which corresponds to a switch-over strategy, the immediate transition 
 fires to generate a token in the place 
. Note that, an inhibitor arc connecting 
 and 
 is used to guarantee that there is only one token deposited in 
. The presence of a token in 
 indicates that the SDN is undergoing an MTD switch-over process. Initially, all coming jobs are supposed to be routed to the primary server  by associating  address to the jobs as modelled by the immediate transition 
. When MTD switch-over is triggered, the SDN controller is in charge of updating new  addresses on the DNS server. The process of  alternation on DNS server by SDN controller is assumed to take a mean time of 
. The events of  switch-over of physical servers from server  to server  are modelled by the timed transition 
 while those from server  to server  are captured by the timed transition 
. When 
 fires, a token in 
 is taken out and deposited in 
 indicating that the  of a certain server that a client can see from the SDN has been modified to a new  of another server . It is worth noting that the firing of the timed transition 
 (
) also returns a token to 
 in order to mark the state of ongoing switch-over operations from  of server  () to  of server  (), respectively. On the other hand, an inhibitor arc from 
 (
) to 
 (
) is used to prevent from depositing more than one token in 
 (
) by the time transition 
 (
). When there is a token in each place 
 and 
 (
), the  of the servers  () has been updated to the new one, and thus new coming jobs are directed to the server with the newly assigned  while the jobs in -transit and ongoing jobs on the server with prior  are dropped or accepted upon pre-determined switch-over strategy. The appearance of tokens in 
 (
) satisfy the guard functions 
 (
) which can fire the immediate transitions 
 (
) and disable the remaining one 
 (
) when a token is deposited in 
. As a consequence, arriving jobs are re-routed and switched over from server  (associated with the prior ) through 
 to server  (associated with a newly assigned ) through 
, and vice versa. In this sense, we notice that in the midst of MTD switch-over process associated with waiting strategies, the tokens in network-server model (representing in-transit jobs) which go through 
 can continuously travel towards the server model of server  while newly coming jobs are directed to travel through 
 from the network-server model towards the server model of the server , and vice versa. As time goes on, the MTD clock triggers MTD switch-over strategies when a certain MTD interval expires, the immediate transitions 
 and 
 are alternately enabled and disabled after each MTD interval to direct or block tokens from travelling throughout the network-server model towards the server models of  and , respectively, which also capture the switch-over behaviours of the MTD strategy. As soon as the MTD clock is about to re-initiate counting a new MTD interval represented by a token in the place 
, the immediate transition 
 fires to clear out the tokens in the places 
 (representing the operational state that the server  is selected to process coming jobs), 
 (representing the state that the  to be assigned to a coming job has been updated from the  of the server  to the  of the server ), and 
 (representing an ongoing process of MTD switch-over). At the same time, the immediate transition 
 deposits a token in 
, which indicate that the MTD switch-over process on the server  has completed and the server  has been selected to process coming jobs in the subsequent MTD interval. On the other hand, if 
 fires, it clears out the tokens in 
, 
, and 
, then it deposits a token in 
 as similar to the behaviours of 
. In the cases that the SDN controller or switches encounter with a certain failure, the immediate transition 
 is enabled to remove the only token in 
, meaning that the ongoing MTD switch-over process is aborted immediately after the failures of either SDN controller or SDN switches. Furthermore, if the failure case of DNS server in addition to the failure cases of either SDN controller or SDN switches, the immediate transitions 
 and 
 are enabled to remove tokens in 
 or 
, respectively.

4.3.2. Server models
The server models are shown in Fig. 6 including the model of the primary server  (Fig. 6(a)) and its secondary replica server  (Fig. 6(b)). Since the operational behaviours of the servers are assumed to be not so different to each other, we use a common model for a server  in Fig. 6(c) to describe the operational behaviours of the servers  (Fig. 6(a)) and  (Fig. 6(b)) (which are similar to the server ). The server model of the server  connects to the network-server model through the timed transition 
. That is to say that the server models of the servers  and  connect to the network-server model through the timed transitions 
 and 
, respectively. The timed transition 
 represents the enqueue of in-transit jobs into the service queue of the server . When a job is enqueued into a server’s service queue from the network queues (represented by tokens in 
 or 
 in the network-server model), it would take a mean time of 
 and the condition is that none of the physical subsystems is in downtime period, which is guarded by the guard functions 
 or 
. The timed transition 
 is enabled if there are tokens in both 
 (
/
) in the server model and 
 (
/
) in the network-server model. The number of tokens in 
 represents the remaining capacity of the server ’s service queue while the number of tokens in 
 (
/
) indicates the number of in-transit jobs in the network queue waiting to enter the server ’s service queue. The firing of 
 deposits a token in 
 after taking out a token in each place 
 in the host model and 
 in the network-server model. This indicates that an in-transit job is dequeued from the network queue and then enqueued in the server ’s service queue, and the capacity of server ’s service queue is reduced by one. Therefore, if the capacity of the server ’s service queue is not sufficient (zero tokens in 
), the timed transition 
 is disabled and in-transit jobs are not able to enqueue in the server ’s service queue. When a token appears in 
, it could represent a long or short job, thus it enables the immediate transitions either 
 or 
. Depending on the value of the coverage factors 
/
 of respective long/short job distribution to a server, the immediate transitions 
 or 
 are fired stochastically to model the fact that coming jobs can be long or short jobs in different amounts. When the immediate transition 
 (
) fires, it takes out a token in 
 and another token in 
 and then deposits a token in 
 (
) and another token in 
, respectively. When 
 fires, a long job in the service queue of the server  is immediately dequeued and processed while the firing of 
 indicates that a short job in the service queue is dequeued and processed by the server , which are represented by a token deposited in 
 and 
, respectively. As a job (either long or short job) is retrieved for processing, it occupies a processing resource of the server , and thus, the processing capacity of the server  represented by the number of tokens in 
 is accordingly reduced by one. Also, the dequeue of a job from the service queue returns a token to 
 to release a previously occupied slot in the service queue. In the cases that (i) the server  suddenly experiences an uncertain failure (represented by a token in 
) or (ii) the server  is under an ongoing MTD switch-over strategy in which a policy is imposed to drop enqueued jobs in the service queue of the server , the immediate transition 
 fires to remove tokens in 
 (representing enqueued jobs in the service queue of the server ). The appearance of a token in 
 (
) implies that a long (short) job is being processed by the server . The completion of long (short) jobs is captured by the firing of the timed transitions 
 (
), respectively. And as a sequence, it takes out a token in 
 (
) and deposits a token in 
 to imply that the occupied processing worker is released after the completion of processing a job. In the middle of processing long/short jobs, if an uncertain malfunction happens to a server  causing its downtime period (represented by a token in 
 or 
), the immediate transitions 
 and 
 are enabled to remove all tokens in 
 and 
, respectively and deposit the same amount of tokens in 
, which indicates the drop of ongoing jobs under processing on the server  due to its physical failures. In the cases of undergoing a MTD switch-over process, if a drop policy for ongoing jobs on a server  is triggered by the MTD clock, the immediate transitions 
 and 
 are enabled to take out all tokens in the places 
 and 
, respectively. The number of tokens in 
 are also removed by the immediate transition 
 to imply the termination of the server ’s processing workers for a reset and clean-up. When the MTD clock is reset to tick the time for a new MTD interval, new processing workers are initiated on the server  to fill up the processing capacity of the server , which is represented by the firing of the timed transition 
 to deposit tokens in the place 
 one after another.

4.3.3. MTD Clock models and switch-over strategies
The clock models for drop and waiting MTD strategies under different time policies for MTD interval are shown in Fig. 7. Fig. 7(a) depicts the clock model () for drop strategy (with zero-time policy). Fig. 7, Fig. 7 show the clock models ( and ) for waiting strategies under fixed-time and flexible-time policies, respectively. These clock models can be substituted into the clock sub-model of the overall system model presented in Fig. 3 to form the corresponding system model for a specific case-study in Table 2.

Drop strategy with zero-time policy:
is controlled by  in Fig. 7(a). The initial state of the  model consists of a token in the place 
 to imply that the clock initially and continuously ticks time for MTD switch-over implementation. After an MTD interval that takes a mean time of , an MTD switch-over strategy is triggered, as modelled by the firing of the timed transition 
 to take out the token in 
 and deposit it in 
. The appearance of a token in 
 indicates that the system is under an ongoing MTD switch-over process. But, when the drop strategy is adopted, all jobs including in-transit jobs, jobs in network-queue, jobs in service-queue and jobs in the servers are forcefully aborted. Thus, all tokens representing those jobs which travel throughout the network-server model in Fig. 5 and the server models in Fig. 6 are immediately taken out by corresponding immediate transitions that represent the removal/drop of the tokens. The guard function 
 which associates with the immediate transition 
 looks after the relevant places in network-server model and server models to verify if all tokens representing the travelling jobs are taken out in order to fire the immediate transition 
 to remove a token in 
 and deposit it in 
. At this time, the immediate transition 
 can fire immediately as soon as its associated guard function 
 finds that the token in 
 has been taken out indicating that the MTD switch-over process has been completed. As a subsequence, the token in 
 is removed and deposited in 
 and the  starts ticking for another consecutive MTD interval. In the cases when a physical subsystem among SDN controller, DNS server or SDN switches enters a downtime period due to an uncertain failure, the immediate transitions 
, 
 fires to remove all tokens in the places 
 and 
 while the timed transition 
 is disabled to halt the time ticking of the  if there is a token in 
. When the failed subsystem is recovered, the immediate transition 
 fires to deposit one and only one token in 
. An inhibitor arc what connects 
 to 
 in order to restrict the number of tokens deposited into 
.

Waiting strategy with fixed-time policy:
is controlled by  in Fig. 7(b). Initially, the  also starts ticking with a token in 
. Different from the model of , when an MTD interval expires and the timed transition 
 fires, it takes out the token in 
 and deposits one token in each of the places 
 and 
. The appearance of tokens in these two places imply (i) MTD switch-over has been triggered by the clock and (ii) a waiting strategy is adopted, respectively. In the waiting strategy with fixed-time policy, a fixed time duration of  is used for waiting the completion of jobs. The waiting behaviour is captured by the timed transition 
. The  keeps ticking time until the waiting duration is expired regardless of the operational status of jobs. When the waiting duration expires, 
 is fired to take out the token in 
 and deposit it in 
. The appearance of a token in 
 enables all relevant immediate transitions to drop all tokens in the corresponding places that represent in-transit jobs and jobs in network queues in the network-server model in Fig. 5, jobs in service queue and ongoing jobs in the servers in the server models in Fig. 6. This is to mean that all running jobs in the network or in the servers are forcefully dropped as soon as the waiting duration is expired. The appearance of tokens in two places 
 and 
 allows the immediate transition 
 to fire as soon as its associated guard function 
 confirms the removal of all tokens representing running jobs in the network-server model and in the server models. It is worth noting that in this switch-over strategy, even if there is no job travelling throughout the network to a certain server, the  continuously ticks the time up to the end of a predefined waiting duration. The reset of the  is captured by the immediate transition 
 as similarly as the reset of the . While, in the failure cases of physical subsystems (SDN controller, DNS server or SDN switches), the timed transition 
 is disabled to cause an abrupt stop of the time ticking of the  if there is a token in 
 and the immediate transitions 
, 
, 
 and 
 are fired to remove all tokens in the corresponding places 
, 
, 
 and 
. This indicates the halt of the  due to failures of physical subsystems. The initialization of the  is handled by the immediate transition 
 while the reset of  for ticking consecutive MTD intervals is performed by the immediate transition 
 as similarly as in the  model.

Waiting strategy with variable waiting time policy:
is controlled by  in Fig. 7(c). The running of  is basically similar to that of . However, since we consider the waiting time a flexible value which varies upon the completion of jobs (including in-transit jobs, jobs in network queues, jobs in service queue or ongoing jobs under processing in accordance with an exerted job management mechanism) on a server, the literal waiting time for job completion on a server can be actually less than a fixed waiting time  as in the case of . This means that as soon as all ongoing jobs or jobs on the way to a certain server finish, the  can subsequently end the switch-over process and reset itself for ticking another MTD interval. Nevertheless, even when the maximum Initially, the  begins ticking time for an MTD interval as captured by a token in 
. The expiration of an MTD interval fires the timed transition 
 and deposits a token in each place 
 and 
 to indicate the triggering of MTD switch-over process and also the start of a waiting period for the completion of jobs until an allowed waiting duration is expired, respectively. In the case of expiring the pre-defined waiting time  even when ongoing jobs do not complete yet, the timed transition 
 is fired and the subsequent behaviours of  are identical with those of . On the other hand, if all jobs complete on a server in advance of the expiration of the waiting duration, the guard function 
 which is associated with the immediate transition 
 watches over the number of tokens in corresponding places which represent the ongoing jobs or jobs on the way to a server in the network-server and server models in order to fire the immediate transition 
 when the above-mentioned places are empty of tokens. The firing of 
 indicates the ending of the waiting duration for job completion during the MTD switch-over process under waiting strategies. It removes a token in 
 and deposits a token in 
. The appearance of tokens in two places 
 and 
 enables the immediate transition 
 to fire. The firing of 
 removes two tokens in each place 
 and 
 and deposit a token in 
, which indicates the reset of . The immediate transition 
 is fired once any of the physical SDN subsystems including SDN controller, DNS server or SDN switches encounters with an uncertain failure, which is represented by a token in the corresponding places 
, 
, or 
 in the availability models, respectively.

4.3.4. Dependency modelling
In this section, we explain sophisticated inter-dependencies between the sub-models which are generally mentioned in the descriptions of the sub-models . Basically, the inter-dependencies taken into account in the modelling are (i) dependency of performance models on the availability model and (ii) dependency of network-server model and server models on clock model.

A. Dependency of performance models on availability model:
The failure/recovery of physical subsystems in the SDN are assumed to exert operational dependencies on their performance behaviours in a straightforward manner. Particularly, when the server  goes down, which is represented by a token in 
, ongoing long/short jobs on the server  are abruptly dropped. Thus, the appearance of a token in 
 enables the immediate transitions 
 and 
 to fire and then remove tokens in 
 and 
. In addition, the jobs in the server ’s service queue (represented by tokens in 
) are rejected as well. And, the jobs in the network queue (represented by tokens in 
) are also dropped suddenly due to the fact that they are in communication with the server  to be enqueued in the server’s service queue. Thus, the appearance of a token in 
 also enables the immediate transition 
 and 
 to fire and then take out tokens in the places 
 and 
 indicating the drops of jobs in the service queue and network queue. Similarly, the failure of the server  (depicted by a token in 
) enables the firing of (i) the immediate transitions 
 and 
 to remove tokens in the places 
 and 
, which represents the drop of ongoing jobs on the server , (ii) the immediate transition 
 to remove tokens in the place 
, which indicates the removal of enqueued jobs in the server ’s service queue, and (iii) the immediate transition 
 to take out tokens in the place 
, which depicts the removal of enqueues jobs in the network queue 
.

On the other hand, we assume that an uncertain failure of the physical subsystems including (i) SDN controller, (ii) DNS server and (iii) SDN switches causes an abrupt break of communication and control between a client and the SDN servers which subsequently terminate jobs on the way to a server. The failure of the above subsystems is captured by the appearance of a token in 
 (for SDN controller’s failure), 
 (for DNS server’s failure) and 
 (for SDN switches’ failure), respectively. When this happens, the timed transition 
 is disabled to reject coming requests from the client. At the same time, the immediate transition 
 is enabled to fire and remove tokens in 
, which is to drop arrived jobs. Furthermore, the immediate transition 
 is disabled to prevent depositing a token in 
 in order to prohibit the occurrence of MTD switch-over. The immediate transition 
 is then enabled to fire and remove a token in 
 to halt the ongoing MTD switch-over process (which was represented by a token in 
). Also, the tokens in the places 
 and 
 which represent the updating of  for a certain server on DNS server and the state of waiting for the completion of jobs with obsolete  are removed by the fired immediate transitions 
 and 
, respectively. The abrupt removal of jobs on the way to a certain server due to the sudden failure of one of the above-mentioned physical subsystems is handled by the following immediate transitions (i) 
 and 
 to remove tokens in 
 and 
, respectively, which indicates the drop of jobs with newly assigned ; (ii) 
 and 
 to take out tokens in 
 and 
, respectively, which represents the termination of jobs with verified and authenticated communications between client and corresponding server; (iii) 
 and 
 to drop tokens in 
 and 
, respectively, which depicts the drop of the in-transit jobs in the network to a certain server; and (iv) 
 and 
 to discard tokens in 
 and 
, respectively, which indicates the termination of enqueued jobs in network queues.

The failures of physical subsystems in the SDN also halt the time passing in MTD clocks used for the MTD switch-over strategies due to the termination of jobs and communications in the network. Particularly, as soon as a token is deposited in either 
, 
, or 
, which represents for the failures of SDN controller, DNS server or SDN switches, respectively, several immediate transitions in the clock models in Fig. 7 are designed to handle the clearance of tokens in corresponding places to indicate the halt and reset of MTD clocks. In  (Fig. 7(a)), the immediate transitions 
 and 
 are enabled to fire and remove tokens in the corresponding places 
 and 
, respectively, while the timed transition 
 is disabled to halt the time ticking in the cases of the above-mentioned failures of physical subsystems. When all failed physical subsystems are recovered completely, if there is no token in the places of the  model, the immediate transition 
 is enabled to deposit a token in 
 in order to initiate the time ticking for a new MTD interval. In  (Fig. 7(b)), the failures of the physical subsystems causes the firing of the immediate transitions 
, 
, 
 and 
 to clear out tokens in the corresponding places 
, 
, 
 and 
, respectively, while the halt of time ticking and initialization of  are handled by the time transition 
 and the immediate transition 
 as similarly as those in the  model. In  (Fig. 7(c)), the immediate transitions 
, 
, 
, 
 and 
 are enabled to fire and remove tokens in the corresponding places 
, 
, 
, 
 and 
, respectively. The halt of time ticking and initialization of  are handled by the time transition 
 and the immediate transition 
 as similarly as those in the  and  models.

B. Dependency modelling within performance model in MTD switch-over strategies:

Dependencies captured in the performance model in Fig. 3 are the dependencies among the network-server, server models and a clock model in the events of MTD switch-over occurrence, in order to model different MTD switch-over strategies based on job and time policies. We describe dependencies in different case-studies in correspondence with MTD switch-over strategies and clock models.

(i.)
DDD strategy: In this case, we use  model in Fig. 7(a) as a clock model in the performance model in Fig. 3. When an MTD interval expires, the timed transition 
 is fired to remove a token in 
 and deposit it in 
. The appearance of a token in 
 enables the immediate transition 
 to fire and deposit a token in 
. As soon as a new  is assigned, the timed transitions 
 or 
 are fired to deposit a token in 
 or 
, respectively. The appearance of a token in 
 (
) enables the immediate transitions in the network-server and server models to implement the dropping MTD strategy including (i) 
 (
) to remove tokens in 
 (
) representing jobs with newly assigned  of server  (), (ii) 
 (
) to remove tokens in 
 (
) indicating jobs with an authenticated connection to a certain server, (iii) 
 (
) to remove tokens in 
 (
) depicting in-transit jobs in the network, (iv) 
 (
) to remove tokens in 
 (
) representing enqueued jobs in the network queue, (v) 
 (
) to remove tokens in 
 (
) representing enqueued jobs in the corresponding server’s service queue, (vi) 
/
 (
/
) to remove tokens in 
/
 (
/
), which indicate the removal of ongoing long/short jobs on the server  (), respectively, and (vii) 
 (
) to remove tokens in 
 (
), which indicates the shutdown and reset of processing workers on each server. The above-described removal of tokens from different places in the network-server model and the server model reflects a sharp policy in the drop strategy of jobs for MTD switch-over process. Right after the complete removal of tokens in the relevant places as above-described, the immediate transition 
 is enabled to fire and remove a token in 
, then deposit it in 
. At this time, the above-mentioned immediate transitions in the network-server model and the server model are disabled, while the immediate transition 
 is enabled to fire and take out the tokens in 
, 
 and 
, and then deposit a token in 
 in the case that the current processing server is the server , which represents the switching-over of incoming jobs from server  to server  as soon as a new  is generated to assign to coming jobs. And vice versa, if the current processing server is the server , the immediate transition 
 is fired and remove tokens in the places 
, 
 and 
 and deposit a token in 
, which depicts the switching-over of incoming jobs from server  to server . When the token in 
 disappears, which indicates the completion of the MTD switch-over process for jobs with newly assigned  between the servers, the immediate transition 
 is fired to remove a token in 
 and deposit it in 
 to represent the reset of the  for ticking another MTD interval.

(ii.)
fWDD strategy: The clock model in the performance model Fig. 3 is  model in Fig. 7(b), nevertheless the job policy of the waiting strategy for MTD switch-over process is  in which ongoing jobs in servers are retained until those jobs are completely processed by the servers while in-transit jobs and jobs in the corresponding server’s service queue are abruptly dropped. Because of the chosen  strategy, the dependencies between the  model and the network-server and server models are different from those in the case of  strategy. When the timed transition 
 in the  model is fired, it deposits tokens in the places 
 and 
 to trigger the MTD switch-over process in accordance with  strategy with fixed waiting time policy. The appearance of tokens in 
 and 
 fires the immediate transition 
 to deposit a token in 
. After the assignment of a new , either timed transition 
 or 
 is fired to deposit a token in either 
 or 
, respectively. The appearance of a token either in 
 or 
 immediately enables the immediate transitions 
 (
), 
 (
), 
 (
), 
 (
) and 
 (
) to remove tokens in the places 
 (
), 
 (
), 
 (
), 
 (
) and 
 (
), respectively, which represents the drop of in-transit jobs and jobs in the servers’ service queue. However, the immediate transitions 
/
 (or 
/
) are disabled and thus prohibit them from removing tokens in 
/
 (
/
), which represents the allowance of waiting for the processing of long/short jobs on the servers  or  to complete in the progressing of MTD switch-over process. But when the fixed waiting duration is expired, the timed transition 
 in  model and the immediate transitions 
/
 (or 
/
) are enabled to fire and remove tokens in 
/
 (
/
), which indicates the termination of ongoing long/short jobs in the servers  () if exist due to the expiration of fixed waiting time. After the tokens in 
/
 (
/
) are completely removed, the immediate transition 
 is fired to remove the tokens in 
 and 
 and deposit a token in 
. The remaining behaviours of the performance model which represent the completion of MTD switch-over process and the reset of  are similar to those in the case of the above-described  strategy.

(iii.)
fWAD strategy: In this case, the  in Fig. 7(b) is used for fixed waiting time policy along with the job management policy  in which ongoing jobs are waited for being processed completely and jobs in servers’ service queue are accepted for further processing while in-transit jobs in the network are abruptly dropped. The implementation of dependencies between the  model and the network-server model, server model is similar to that in the case of  strategy. The specific difference is that, when tokens are deposited in 
 and 
 in the  model to trigger the MTD switch-over process with fixed waiting time policy and job management policy of , and a token is deposited in 
 then the timed transitions 
 or 
 are fired to deposit tokens in the corresponding places 
 or 
, the immediate transitions 
 (
), 
 (
), 
 (
) and 
 (
) are enabled to fire and remove tokens in the corresponding places 
 (
), 
 (
), 
 (
) and 
 (
), which depicts the abrupt termination of in-transit jobs in the network. In contrast, the immediate transitions 
 (
) and 
/
 (
/
) are disabled to prevent the removal of tokens in the corresponding places 
 (
) and 
/
 (
/
), which means that the enqueued jobs in the servers’ service queue are retained for further processing while the ongoing long/short jobs in the servers are waited until their processing finishes. Nevertheless, when the fixed waiting time expires, the timed transition 
 in the  model fires to deposit a token in 
. Right after that, the above-mentioned immediate transitions are fired to remove existing tokens in their corresponding places, which represents the drop of all enqueued jobs in service queues and ongoing jobs in the servers due to the expiration of fixed waiting time. After the removal of all tokens in their respective places, which represents the drop of all jobs, the immediate transition 
 (
) are enabled to fire to indicate the completion of MTD switch-over process in the network, and the remaining reset of the  is identical with that in the  strategy.

(iv.)
fWAA strategy: As similar to the  and  strategies, time management policies are performed by the  in Fig. 7(b) while the applied job policy is  in which ongoing jobs in servers are retained for the completion of processing, jobs in servers’ service queue and in-transition jobs are accepted for further processing instead of rejected as in above-described drop strategies. When tokens are deposited (i) in 
 and 
 to represent the triggering of MTD switch-over process and fixed waiting time policy, (ii) in 
 to represent the progressing of MTD switch-over and (iii) in 
 or 
 to represent the assignment of a new  of a certain server to incoming jobs to switch-over the flow of jobs, all tokens in the network-server model and the server model which represent the in-transit jobs, ongoing jobs in servers’ service queue and under processing in servers are not dropped out as before. Particularly, the appearance of a token in 
 (meaning the new  of the server  has been assigned to new incoming jobs), the immediate transition 
 is disabled to block coming jobs with an obsolete  of the server  while the immediate transition 
 is enabled to fire in order to re-direct the coming jobs with newly assigned  of the server . But in the  strategy, all the immediate transitions 
, 
, 
, 
 in the network-server model (Fig. 5) and the immediate transitions 
, 
 in the server model of the server  (Fig. 6(a)) are still disabled to not drop out all tokens in the corresponding places that connect to those immediate transitions. At the same time, incoming jobs with newly assigned  of the server  are re-directed to the server , which is represented by tokens transiting through the immediate transition 
 towards the server model of the server . By this way, we can capture the behaviour in which all jobs with obsolete  of the server  are still remained for further processing in the server  while the new coming jobs with newly assigned  of the server  are re-directed to the server  during the progressing of the MTD switch-over process between the server  to the server . And vice versa, when a token is deposited in 
, the immediate transition 
 is disabled to block incoming jobs with an obsolete  of the server  and the immediate transition 
 is enabled to fire in order to redirect incoming jobs with a newly assigned  of the server , while the immediate transitions 
, 
, 
 and 
 in the network-server model (Fig. 5) and the immediate transitions 
 and 
 in the server model of the server  (Fig. 6(b)) are disabled to not drop out tokens, as similarly as described above. When the fixed duration for job waiting expires, the timed transition 
 in the  model fires to deposit a token in 
. At this time, all the above mentioned immediate transitions are enabled to fire to remove all tokens if exist in the corresponding places. In particular, if the MTD switch-over process is undergoing from the server  to the server , all the immediate transitions 
, 
, 
, 
 in the network-server model (Fig. 5) and the immediate transitions 
, 
 in the server model of the server  (Fig. 6(a)) are enabled to fire and remove tokens in the corresponding places 
, 
, 
 and 
 in the network-server models and the places 
 and 
 in the server model of the server . At this time, the immediate transition 
 in the server  model is also enabled to fire and take out tokens in the corresponding place 
, which represents the reset of processing workers on the server . And vice versa, it is similarly described for the drop-out of jobs (tokens) due to the expiration of fixed waiting time in the case of MTD switch-over process from the server  to the server . Afterwards, the completion of the MTD switch-over process and the reset of the  are equivalently described as those in the above  and  strategies.

(v.)
vWDD strategy: In this case, the time policy is variable waiting time implemented by the  in Fig. 7(c) while the job management policy is  in which ongoing jobs in the servers are retained until their processing completely finishes while in-transit jobs in the network and enqueued jobs in servers’ queue are dropped out. Because the duration of waiting time varies depending on the completion of ongoing jobs in servers, but it is still under a threshold of fixed waiting time, the dependencies between the clock model and the network-server and server models are more complicated compared to those of the fixed-waiting time strategies. Particularly, when tokens are deposited (i) in 
 and 
 to trigger MTD switch-over process with variable waiting time policy, (ii) in 
 to represent the ongoing MTD switch-over process and (iii) in 
 or 
 to indicate the assignment of a new  of a server to incoming jobs, the immediate transitions 
 (
), 
 (
), 
 (
), 
 (
) and 
 (
) are enabled to fire to drop tokens from their corresponding places, which represent the abrupt drop of in-transit jobs in the network and enqueued jobs in the servers’ queue due to MTD switch-over process. At the same time, the immediate transitions 
/
 (or 
/
) are still disabled to not drop tokens in the places 
/
 (or 
/
), respectively, which is to tell that the ongoing jobs in the server  (or ) are retained. Different from fixed-waiting time policy, as soon as the ongoing long/short jobs in the server  (or ) are completely processed, represented as tokens in 
/
 (or 
/
) are taken out by the corresponding timed transitions 
/
 (or 
/
), the immediate transition 
 is fired to take out the token in 
 and deposit in 
. This behaviour implies that the  stops the waiting process right after all jobs in the server has been completely processed. At this time, the immediate transition 
 (or 
) is enabled to fire and remove the tokens in 
 (
), which represents the reset and clean-up of processing workers in the server  (or ). When all jobs are dropped out, the immediate transition 
 in the  model (Fig. 7(c)) is subsequently fired to remove tokens in 
 and 
 and deposit a token in 
. On the other hand, if the processing of ongoing jobs in the server  (or ) is not completed when the threshold of waiting time is violated, the timed transition 
 in the  model is fired to deposit a token in 
 and then the immediate transitions 
/
 (
/
) are fired to remove tokens in the corresponding places 
/
 (or 
/
), which represents the sudden termination of the ongoing long/short jobs in the server  (or ) due to the expiration of waiting time regardless of their processing circumstances. Then, the reset and clean-up of processing workers in the server  () are performed as modelled by the immediate transition 
 (
). When all jobs are terminated, the immediate transition 
 in  model is fired to remove tokens in 
 and 
 and deposit a token in 
. Afterwards, the completion of the MTD switch-over process and the reset of  is captured as similarly as that in the above-described MTD switch-over strategies associated with .

(vi.)
vWAD strategy: The  in Fig. 7(c) is used for time management while the job management policy is  in which in-transit jobs in the network are dropped out but enqueued jobs in servers’ service queue and ongoing jobs in the servers are retained. As similar to the modelling in the above-described  strategy, when tokens are deposited in 
 and 
 in the  model and, 
 and 
 (or 
) in the network-server model in Fig. 5, the immediate transitions 
 (
), 
 (
), 
 (
) and 
 (
) in the network-server model are enabled to fire and take out tokens in the corresponding places 
 (
), 
 (
), 
 (
) and 
 (
), respectively, which represents the abrupt termination of in-transit jobs in the network due to the MTD switch-over process. In contrast, the immediate transitions 
 (
) in the server  (or ) model in Fig. 6(a) (or Fig. 6(b)) are still disabled to not drop out the tokens in the places 
 (or 
), which is to imply that the enqueued jobs in the servers’ service queue are accepted for further processing in the servers. At the same time, the immediate transitions 
/
 (or 
/
) are also disabled to not drop tokens in the corresponding places 
/
 (or 
/
) in the server  (or ) model in Fig. 6(a) (or Fig. 6(b)), respectively, which indicates the holding of ongoing jobs in the servers in the progressing of MTD switch-over process until their processing is completed. When a certain long/short job in a server is completely processed, an enqueued job in the server’s service queue is immediately received by a processing worker in the server, which is represented by the firing of the immediate transitions 
/
 (or 
/
) in the server  (or ) model in Fig. 6(a) (or Fig. 6(b)). The process repeats until all enqueued jobs in the server’s service queue are dequeued and taken over by the processing workers in the server. As soon as the processing of all ongoing jobs in the server  (or ) is finalized (this also means that all previously enqueued jobs in the server’s service queue are dequeued and processed completely), in which all tokens in the places 
, 
 and 
 in the server  model (or 
, 
 and 
 in the server  model) are alternately taken out by the timed transitions 
 and 
 (
 and 
), the immediate transition 
 is enabled to fire and remove a token in 
 to deposit it in 
. This indicates that the  discards the waiting process when the processing of all jobs in the server finishes. Afterwards, the reset and clean-up of the server’s processing workers are handled by the immediate transition 
 (or 
). When tokens representing all jobs and processing workers are cleared out in the server model, the immediate transition 
 is fired to remove tokens in 
 and 
 and deposit a token in 
. Then, the completion of the MTD switch-over process and the reset of  are handled and captured in a similar way to the case of  strategy. Nevertheless, in the case that the waiting for the completion of jobs in the server violates a threshold , the timed transition 
 in the  fires to remove the token in 
 and deposit in 
. Due to this behaviour, the immediate transitions 
, 
 and 
 in the server  model (or 
, 
 and 
 in the server  model) are fired to remove all tokens (if exist) in the places 
, 
 and 
 in the server  model (
, 
 and 
 in the server  model), respectively, which implies the rejection of enqueued jobs in the corresponding server’s service queue and the termination of ongoing jobs in the server itself. At the same time, the immediate transitions 
 (or 
) fires to remove tokens in 
 (or 
), which indicates the clean-up of processing workers in the server. Subsequently, the immediate transition 
 in the  model is fired to remove the token in 
 and deposit it in 
. After all, the ending of MTD switch-over process and the reset of  model are captured as above-described in  strategy.

(vii.)
vWAA strategy: This strategy employs  policy for job management while also applies  for time management. In this case, during the progressing of MTD switch-over process, ongoing jobs in the servers are remained until completely processed while in-transit jobs in the network and enqueued jobs in the server’s service queue are all accepted for further processing. As similarly described in  and  strategies, when tokens are deposited in 
 and 
 in the  model to represent the trigger of MTD switch-over process and the waiting for job completion, while the places 
 and 
 (or 
) in the network-server model consist a token in each place, the immediate transition 
 is disabled to discard incoming jobs with obsolete  of the server  and the immediate transition 
 is enabled to receive jobs with newly assigned  of the server . But due to the selected job management policy , all the immediate transitions 
, 
, 
, 
 in the network-server model are disabled to not drop tokens representing in-transit jobs in the network from the corresponding places of the immediate transitions. Also, in the server model, the immediate transition 
 is still disabled to not discard enqueued jobs in the service queue of the server . And the immediate transitions 
 and 
 are also disabled to not halt ongoing jobs in the server . The disabling of the above-mentioned immediate transitions related to the jobs with obsolete  of the server  implies the implementation of the  strategy in which in-transit jobs in the network and enqueued jobs in the service queue of the server  are accepted for further processing while ongoing jobs in the server  are retained until completed. Thus, the jobs with the obsolete  of the server  in the network and in the service queue are received and processed by the server  one after another when an ongoing job in the server  is completely processed. At the same time, incoming jobs with the obsolete  of the server  are blocked and those with newly assigned  of the server  are switched over through the immediate transition 
 travelling continuously all the way to the server  model. When all the long/short jobs with the obsolete  of the server  are totally processed, which is represented by the removal of all tokens in the places 
, 
, 
 and 
 in the network-server model, and the places 
, 
 and 
 in the server  model by the timed transitions 
 and 
 after travelling all the way from the network-server model to the server model, the immediate transition 
 in the  model fires to remove the token in 
 and deposit in 
. This behaviour of the model captures the halt of the waiting period in the  upon the completion of all jobs with the obsolete  of the server . After the reset of the processing workers in the server  (handled by the immediate transition 
 in the server  model), the immediate transition 
 in the  model is fired to remove tokens in 
 and 
 and deposit a token in 
. In constrast, if the maximum waiting period  expires during the processing of jobs in the server , the timed transition 
 in the  model is fired and all the immediate transitions 
, 
, 
 and 
 in the network-server model, and the immediate transitions 
, 
 and 
 in the server  model are all enabled to fire to immediately remove tokens in their corresponding places, if existed. The modelling of this behaviour captures the abrupt termination of all long/short jobs with an obsolete  of the server  upon the expiration of waiting period which is triggered by the . After that, the immediate transition 
 in the server  model is fired to remove tokens in 
, which represents the reset and clean-up of processing workers in the server . After the total removal of tokens as described above, the immediate transition 
 in the  model is fired to remove tokens in 
 and 
 and deposit a token in 
. Afterwards, the completion of the MTD switch-over process and the reset of the  are modelled and handled by the firing of the immediate transitions 
 in the network-server model and 
 in the  model, respectively. It is here worth noting that the above-desribed modelling is specific for the switching-over of incoming jobs from the obsolete  of the server  to the newly assigned  of the server . The reverse switching of incoming jobs from the obsolete  of the server  to the new  of the server  can be described in the same manner.

5. Experiments and analyses
5.1. Experimental configuration and performability metrics
Default experimental configuration:
The SRN models are implemented by Mercury tool (Maciel et al., 2017) and analysed by using a Discrete Event Simulation (DES) approach that comes along with the tool. The analyses were performed using stationary DES simulation for steady-state analyses by simulating for a long time with the adoption of the method of batch means (Pinheiro et al., 2021). Subsequently, initial transient phases is discarded while the remaining events are divided into batches to obtain point/interval estimates for steady-state statistics (Banks et al., 2010). Ones can implement and analyse the models in other tools such as TimeNET (Zimmermann, 2017) or stochastic petri net package (SPNP) (Ciardo et al., 1989). Various SRN models are developed in accordance with the MTD switch-over strategies as shown in Table 2. To implement the models in Mercury tool, we substitute different clock models as shown in Fig. 7 into the overall system model in Fig. 3 and employ a set of guard functions to capture respective behaviours and dependencies between the sub-models which guarantee the job and time management policies in the above-mentioned MTD switch-over strategies. Default input parameters of the SRN models and their assigned transitions are shown in Table 3. The values of these parameters are based on previous works (Hu et al., 2010, Mendonça et al., 2020a, Nguyen et al., 2014). The values of cost parameters are based on the works Chen et al., 2005, Elnozahy et al., 2003, Nguyen et al., 2017. All experiments and analyses were implemented and performed on a desktop computer with the following main configuration, (i) CPU: Intel Core i7-770K, (ii) RAM: DDRAM4 64 GB.

Guard functions:
To capture sophisticated behaviours and interactions within and between sub-models in the overall system models in Fig. 3, we employ a set of guard functions as shown in Table 4. In this table, we present the firing conditions of each guard function which in turn is associated with a specific immediate/timed transition in the proposed SRN models. The disabling of a transition is performed if its firing conditions are not satisfied. Specification of SRN models that employ a certain guard function is also presented in the table.


Table 3. Default Input parameters.

Parameters	Associated Transition	Description	Values
Mean time to failure of a SDN controller	514.051	h
Mean time to recovery of a SDN controller	0.906	h
Mean time to failure of a DNS server	514.051	h
Mean time to recovery of a DNS server	0.906	h
Mean time to failure of a SDN router	1440	h
Mean time to recovery of a SDN router	0.581	h
, 
Mean time to failure of a physical server	514.051	h
, 
Mean time to recovery of a physical server	0.906	h
, 
Mean time to queue a job to a network queue	0.0077	s
, 
Mean time to queue a job to a service queue of servers	0.01	s
, 
Mean time to initialization of a server’s processing workers	5	s
, 
Mean time to service completion of long jobs	100	s
, 
Mean time to service completion of short jobs	10	s
, 
Mean time to alternate a new vIP in DNS server by SDN controller for a certain physical server during a switch-over process	1.0	s
Mean time to acquire a virtual IP from DNS server by a client	0.5	s
, 
Mean time to vIP verification and TCP/IP Connection establishment by SDN controller	0.1	s
Mean time to a job arrival	15	s
Mean interval of time-based MTD technique	300	s
, 
Coverage factor of long job distribution to a server	50%	
, 
Coverage factor of short job distribution to a server	50%	
n/a	Server queue size	10	
n/a	Server capacity	5	
n/a	Observation period of time	3600	s
n/a	Energy consumption of idle server components per hour	0.0085	kWh
n/a	Energy consumption of a working CPU per hour	0.0227	kWh
n/a	Energy consumption of an idle CPU per hour	0.005	kWh
n/a	Unit cost of power consumption	0.13	USD/kWh
n/a	Unit profit for a short-job processing	0.01	USD
n/a	Unit profit for a long-job processing	0.05	USD
Performability metrics:
To comprehend the behaviours of the SDN under different MTD switch-over strategies, we employed different performability metrics as follows.


Table 4. Guard Functions.

Guard	Trans.	Firing Conditions	Use-cases
—Clock models—
DDD
fWDD, fWAD, fWAA
vWDD, vWAD, vWAA
All
All
DDD, vWDD, vWAD, vWAA
vWDD, vWAD, vWAA
All except DDD
All except DDD
All except DDD
All except DDD
vWDD, vWAD, vWAA
All
All
—Network-server models—
All
All
All
All
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
 	DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
All
All
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
DDD, fWDD, fWAD, vWDD, vWAD
fWAA, vWAA
DDD
All except DDD
All
All
All
All
All
All
All
—Host models—
All
All
DDD, fWDD, vWDD
fWAD, fWAA, vWAD, vWAA
DDD, fWDD, vWDD
fWAD, fWAA, vWAD, vWAA
All
All
All
All
DDD
All except DDD
DDD
All except DDD
DDD
All except DDD
DDD
All except DDD
All
All
All
All
DDD
fWDD, fWAD, fWAA
vWDD, vWAD, vWAA
DDD
fWDD, fWAD, fWAA
vWDD, vWAD, vWAA
All
All
(i.)
Availability (
):

The availability of the SDN is computed by the probability of maintaining the operational and available states of its subsystems at a time, including the availabilities of SDN controller, DNS server, SDN switches and at least one of the SDN servers. The definition of the SDN availability is given by Eq. (1) while the reward function to obtain the availability in the proposed availability model is presented in Eq. (2). (1)
 (2)
 

(ii.)
Capacity-oriented Availability (COA) (
)

COA measures how service is delivered, thereby taking into account not only the states of availability or unavailability but the real effect of these conditions on the delivery of services. The COA calculation considers 
 as the operational processing capacity or the number of resources available at any state 
, while 
 describes the steady-state availability for the 
 state, a set with all available states know as 
 is also considered and, the maximum processing capacity of the system is 
. Thus, we can calculate the COA by Eq. (3) (Maciel et al., 2010). (3)
 

(iii.)
Service throughput:

–
Average throughput of a transition  (Zuberek, 1993, Sahner et al., 1996, Ciardo et al., 1989) in the net  is considered as the average number of new (or completed) firings of the transition in a unit time. Therefore, it is calculated as the multiplication of the probability of possible marking with the rate of the transition in the corresponding marking as in Eq. (4). (4)
Where, 
 is the subset of reachable markings that enable ,  is the probability of a certain marking  in 
, and  is the rate of  in marking .

–
Service throughput of a server 
 is estimated by the total throughput of long and short jobs processed by the server, which is thus the sum of throughput of timed-transitions 
 and 
 representing the processing of corresponding long/short jobs in server models. (5)
Where, 
 and 
 are the average throughput of the server in relation to the processing of long and short jobs, respectively.  is the service capacity of a certain server (or the maximum number of processing workers in a server).

(iv.)
Response time of a server 
:

–
To calculate the response time of a certain server, the Little’s law (Cassandras and Lafortune, 2008) is employed as shown in Eq. (6). (6)
 
Where, 
 is the average number of jobs being received and processed by the corresponding server 
, and 
 is the average throughput of jobs on the server 
 as computed in Eq. (5).

–
The response time of overall SDN is then computed as in Eq. (7). The response time is computed for the SDN by dividing the average number of processed jobs through the SDN (
) by the total throughput of all servers in the SDN (
). (7)
 

(v.)
Average utilization of a server 
:

–
The utilization of a server is calculated by the multiplication of the portion of processed jobs with the total probability of operational states of the server as shown in Eq. (8). (8)
 
Where, 
 is the expected number of jobs being processed on a server 
. 
 is the subset of markings that represents the  state of 
.  is the probability of marking  in which the server 
 is in the state . And,  is the processing capacity of a server which is the total number of processing workers in the server.

(vi.)
Number of lost jobs

–
The number of lost jobs is estimated by measuring the throughput of immediate transitions that represent the dropping or blocking of lost jobs in the SDN in a period of observation time  as shown in Eq. (9). (9)
Where,  is the set of immediate transitions  that blocks or drops an incoming job. 
 is the average throughput of an immediate transition .

(vii.)
Operational cost

–
A cost model is developed to estimate the total cost related to a service execution in the SDN. The cost model consists of two types of cost including (i) cost due to power consumption 
 (or maintenance cost) and (ii) cost due to profit loss 
 (or opportunity cost), estimated in a period of time  as shown in Eq. (10). (10)

–
Cost due to power consumption: relates to CPU utilization of the servers (Chen et al., 2005). The cost consists of the power consumption of the server in an idle state (
) and an extra amount of power consumption due to processing load (
) as shown in Eqs. (11), (12). (11)
 (12)
 
Where 
 is the unit cost of power consumption. 
 is the nominal power consumption of all components in a server (except the processing unit). 
 is the nominal power consumption of the processing unit in a server. 
 is the power consumption of a server in idle state. 
 is the probability of the marking in which the server 
 is in UP state. 
 is the probability of the marking in which the server 
 consists 
 running processing workers while, 
 is the probability of the marking in which the server 
 is in idle state. 
 
 is the utilization of processing workers in the server 
 in the corresponding marking. 
 is the number of servers in the SDN.  is the observation period of time.

–
Cost due to profit loss: relates to the number of lost jobs in the observation period of time . (13)
Where, 
 is the number of lost jobs in the observation period of time  computed for the job type  (,  is the number of job types being served). 
 is the unit profit of processing a corresponding job (type ). And, 
 is the coverage ratio of the job type .  is the set of immediate transitions  that blocks or drops an incoming job. 
 is the throughput of the immediate transition  per time unit.

Reward functions:
Table 5 shows the reward expressions employed to compute the performability metrics of interest in Mercury. The following syntaxes are used to express different elements in the models and during the computation. 
 depicts the number of tokens in the place 
 (e.g., 
 indicates the number of tokens in the place 
). 
 is the mean number of tokens existing in the place 
 (e.g., 
 indicates the mean number of tokens in the place 
).  is the probability in which the statement  is satisfied, (e.g., 
 indicates the probability in which the following conditions are satisfied, including (i) the number of tokens in the place 
 is equal to  and, (ii) the number of tokens in the place 
 is greater than ). At last, 
 depicts the mean throughput of the immediate transition 
, (e.g., 
 indicates the mean throughput of the immediate transition 
). It is worth noting that, to compute the throughput of and the number of jobs passing through an immediate transition, an auxiliary place and its accompanied exponential transition with an infinitesimal delay ( s, compared to other parameters) are associated with the immediate transition in consideration as shown in Fig. 8. Fig. 8(a) shows the additional place 
 and the timed transition 
 associated with the immediate transition 
 to compute its throughput. In the case that the number of jobs passing through an immediate transition is needed to compute taking into account different causes, we can replace the immediate transition in consideration by the other immediate transitions associated with corresponding guard functions to represent the passing of jobs due to a certain cause. Fig. 8(b) shows the use of auxiliary places and timed transitions to compute the number of lost jobs passing the above-mentioned immediate transition 
. Here, we consider three main causes of dropping jobs which are (i) failures of subsystems, (ii) execution of MTD processes (violated threshold) and (iii) insufficient queue size. For that reason, we replace the immediate transition 
 in Fig. 8(a) by three other immediate transitions associated with their corresponding auxiliary places and timed transitions including (i) 
 with 
 and 
, (ii) 
 with 
 and 
, and (iii) 
 with 
 and 
 as depicted in Fig. 8(b). Fig. 8(b) shows an example of using an auxiliary place and a timed transition to compute throughput of the immediate transition 
, while Fig. 8(d) depicts the split of the immediate transition 
 into three other immediate transitions and associated auxiliary places and timed transitions for the computation of the number of lost jobs passing through the immediate transition 
 in Fig. 3.

Fig. 8. Examples of using an auxiliary place and timed transition to compute the throughput of immediate transitions (a) General cases of 
; (b) General cases 
 considering causes of dropping jobs; (c) Example of 
; (d) Example of 
 considering causes.


Table 5. Reward Functions.

Metrics	Reward
Operational Availability	
Mean service throughput	
, where  is the number of tokens in the corresponding places 
 or 
, where  is the number of tokens in the corresponding places 
 or 
Mean utilization of servers	
 
 
Mean response time		
 
No. of lost jobs (per time unit T in seconds)	
Operational cost (per time unit T in seconds)		
 
 
 
 
5.2. Availability analysis
Availability analyses are performed in Mercury tool using both analytical and simulation approaches. To analyse system availability, we disregard performance sub-models in Fig. 3 while remaining the two-state models of physical subsystems in the SDN. The set of two-state models representing the physical failure and recovery of physical subsystems is analysed using an analytical solution in steady-state. While, it is also analysed using DES provided by the Mercury tool with the following main simulation configuration: (i) confidence level: 99%, (ii) maximum relative error: 1%, (iii) batch size: 5000, and (iv) global simulation time:  s ( years, considered as in a steady-state). The availability metrics include (i) system availability (of physical components), (ii) downtime minutes in a day and (iii) COA (of delivered services) as shown in Table 6. As per observed in the analytical results, the SDN of two redundant servers in consideration can reach a level of availability in steady-state at 2 nines while its services’ COA can be obtained at a slightly higher value at 2 nines. Therefore, the system downtime is only a few minutes a day. The analytical analysis provides a reference for the cross-validation of the simulation analysis results obtained by the DES engine in Mercury tool when the model is at a small scale. As seen in the table, the simulation analysis results are very close to the analytical results and the deviation of simulation results obtained by the Mercury tool in comparison to the analytical results are small enough to differentiate. Big-size models can capture sophisticated operational system behaviours but often collide with state-explosion problems. In that regard, the simulation-based approach can provide an appropriate solution for the analysis of big-size models as shown above.


Table 6. Availability Analysis.

Metrics	Analytical	Simulation	Deviation
Availability	0.99607937	0.99606532	[0.99606264, 0.99606799]	−0.0014 %
Downtime (mins/day)	5.64569330	5.66593963	[5.66208663, 5.66979263]	+0.359%
COA	0.99824063	0.99826334	[0.99826200, 0.99826468]	+0.0023%
5.3. Performability analysis
The performability of proposed SRN models for seven MTD strategies is analysed using simulation in Mercury tool. The overall system model in Fig. 3 with both two-state availability models and performance models changes upon the MTD strategy to be assessed by substituting a respective clock model in Fig. 7 and guard functions as defined in Table 4. We performed various analyses including (i) stationary analyses under default parameters, and (ii) sensitivity analyses as a specific parameter varies when all other parameters are fixed, wrt. different performance metrics as defined above.

5.3.1. Stationary analysis
Performability analysis under default parameters:
Table 7 presents the analysis results for each performance metric in seven MTD strategies including, (i) DDD (as a baseline for comparison), (ii) waiting strategies with fixed-time waiting duration (fWDD, fWAD, and fWAA), and (iii) waiting strategies with variable-time waiting duration (vWDD, vWAD and vWAA). To better comprehend the analysis results and to provide better visualization of the numeric results in Table 7, Fig. 9 displays radar charts to represent the analysis results under default parameters. To avoid overlapped and messy graphs, we split the graphs into two charts including (i) Fig. 9(a) presents the comparison of DDD with fixed-time strategies, and (ii) Fig. 9(b) shows the comparison of DDD with variable-time strategies.

As per observed, the implementation of MTD with drop policies for all jobs in transit, in servers’ service queue and in servers’ service processes (i.e., DDD) exposes the worst performability in all aspects in comparison to all other MTD strategies with waiting policies. The MTD strategies with fixed-time waiting policies show slightly better performability as compared to those with variable-time waiting policies, respectively. Furthermore, in the set of fixed-time waiting MTD strategies (or of variable-time waiting MTD strategies), the MTD strategies with waiting policies applied for jobs in servers’ service processes while dropping policies for jobs in transit and jobs in servers’ service queues (i.e., fWDD/vWDD) manifest a better performability than the remaining MTD strategies in the same set (i.e., (fWAD, fWAA) or (vWAD, vWAA)). The acceptance of jobs in servers’ service queue during the execution of an MTD strategy (i.e., fWAD/vWAD) clearly achieves better performability in comparison to the MTD strategies without acceptance of jobs in servers’ service queue and jobs in transit (i.e., fWDD/vWDD), respectively. But, the acceptance or dropping of jobs in transit while accepting jobs in servers’ service queue marginally impact the performability if jobs in servers’ service queue are accepted in the progressing of an MTD strategy. Particularly, the pairs (fWAD and fWAA) and (vWAD and vWAA) expose a little difference in performability.


Table 7. Performance Analysis under Default Parameters.

Metrics	DDD	fWDD	fWAD	fWAA	vWDD	vWAD	vWAA
0.028229	0.031660	0.031983	0.032341	0.031057	0.032016	0.032100
Throughput(jobs/s)	
0.028406	0.031469	0.032075	0.031917	0.031271	0.031983	0.032026
27.811371	34.008947	34.612200	34.782393	33.576205	34.485650	34.395860
Utilization (%)	
27.918614	33.976267	34.506813	34.922269	33.555738	34.465404	34.134334
Response Time (s)	
58.968085	65.923145	72.961275	73.031648	63.099476	67.380552	67.439668
Lost jobs/hour	
35.776482	12.314653	8.044250	7.998715	14.709011	8.676782	8.615680
Operational cost (USD/hour)		0.841755	0.348584	0.220528	0.219036	0.407960	0.241912	0.230553
As per observed the analysis results under default parameters shown in the radar charts in Fig. 9, service availabilities of the SDN in all cases are mostly similar, the marginal difference is due to simulation accuracy. In more detailed, the MTD strategy with all dropping policies (DDD) (which is depicted by the red graph) manifests the lowest values of throughput and utilization of both servers H1 and H2. Due to dropping jobs in the execution of an MTD process, the DDD strategy actually has the best (lowest) response time. But in return, the penalty for dropping jobs at all places of the DDD strategy in the events of MTD processes is the highest regarding the number of lost jobs and the respective operational cost per hour. When comparing the strategies in the same figure, we find that the strategies fWDD and vWDD obtain balanced and reasonable operational metrics in the way that they have marginally lower values of throughput and utilization of servers but clearly better response time compared to the strategies (fWAD, fWAA) and (vWAD, vWAA), respectively. Nevertheless, the penalty for dropping jobs of the (fWDD, vWDD) strategies is still plainly higher regarding the number of lost jobs and operational cost per hour. When comparing the fixed-time and variable-time strategies case by case, we find that (i) all MTD strategies with variable-time policy obtain clearly better (lower values) response time but marginally lower values of throughput and utilization of servers compared to those with fixed-time policy, (ii) variable-time strategies with dropping policies for jobs in servers’ service queue and/or jobs in transit (i.e., vWDD, vWAD) have slightly higher values (i.e., worse) of the number of lost jobs and operational cost per hour in comparison to the corresponding fixed-time strategies (fWDD, fWAD), respectively, while the difference in the performability metrics of the fixed-time and variable-time strategies with accepting policy for all jobs (i.e., fWAA and vWAA) is small.


Fig. 9. Comparative analysis results of performance metrics in all MTD strategies.

To highlight the difference between the MTD strategies in regard to operational cost, we estimated the total cost in a year as shown in Fig. 10. The implementation of an MTD strategy with no consideration of running jobs in the system extremely cost a huge amount of financial spending in a year (at about 7373.78 USD for a two-server system) compared to the remaining MTD strategy with waiting policies. In overall, waiting strategies with fixed-time policies cost less than those with variable-time policies. Because, as we observed, the number of MTD switch-over times between the two servers in the case of variable-time strategies is higher than that in the case of fixed-time strategies and thus, with variable-time policy, more long jobs can be accepted at a time and lost after a time threshold is violated causing a higher penalty. Furthermore, when we apply waiting policy in the execution of an MTD process, the operational cost is reduced significantly compared to the strategy without waiting policy (DDD). While, among the strategies with waiting policy, the accepting policy of jobs in servers’ service queue considerably shrinks the operational cost and the accepting policy of jobs in transit slightly obtains economical gains in operational cost.

5.3.2. Sensitivity analysis
In order to better comprehend the performability characteristics of the system adopting different switch-over MTD mechanisms, we performed a number of sensitivity analyses for the performance metrics in consideration wrt. a variety of impacting parameters including (i) job arrival rate (), (ii) job service rate (of servers) (), (iii) MTD interval (), (iv) servers’ queue size () and (v) ratio of (long/short) job types (
). To reduce the complexity and overlapping issues in plotting graphs, we take graphs representing analysis results of the strategy DDD as a baseline for comparison and split generated graphs into two separate plots, one for the comparison of DDD versus the strategies with fixed-time waiting policy and the other for the comparison of DDD versus the strategies with variable-time waiting policy. As we observed, under default parameters with an equal ratio of long/short jobs, the analysis results of performability metrics of two servers are slightly similar, the difference is marginal. Therefore, we plot only graphs representing the analysis results for one of the two servers (here, server ). And, it is worth noting that the analyses were performed considering the equal ratio of long/short jobs. And, the long/short job types are defined based on the values of mean service time, i.e., a long job takes longer service time while a short job takes shorter service time. Therefore, when performing the sensitivity analyses wrt. the variation of service time, we assume there is only one type of jobs taking the same value of service time to complete. In other analyses, the service time of long/short jobs is as provided in Table 3.

Server utilization:
Sensitivity analysis results of a server’s utilization wrt. the selected parameters are shown in Fig. 11. The detailed description of figures are presented as follows.

Fig. 11, Fig. 11 depict the server utilization wrt. the variation of job arrival time (). When the job arrival rate is high (i.e., mean job arrival time is low), server utilization in all cases is much higher since the servers need to receive and process a higher number of coming jobs at a time. In contrast, when the job arrival rate decreases (i.e., mean job arrival time increases), the utilization of servers rapidly goes down. This is to say that busier data transactions consume more processing powers of the servers. Furthermore, we realize that when dropping jobs at all places in the execution of an MTD process (i.e., DDD strategy), server utilization is significantly lower than that in the other strategies. In a busy situation with a high value of job arrival rate, the MTD strategies (fWDD, vWDD) with waiting policy for jobs in servers and dropping policy for jobs in transit and jobs in servers’ service queue manifest a clearly lower value of server utilization in comparison to the waiting strategies with accepting policy (fWAD, fWAA) and (vWAD, vWAA), respectively. When the system is less busy with longer job arrival time (i.e., lower arrival rate), the server utilization in all strategies with waiting policy is marginally different. The acceptance of jobs in transit in the strategies (fWAA, vWAA) shows a small increase in server utilization metric compared to the strategies (fWAD, vWAD) at all values of job arrival rate, respectively. Whereas, the acceptance of jobs in servers’ service queue in the strategies (fWAD, vWAD) does have a clear impact in increasing the server utilization compared to the strategies (fWDD, vWDD) when the system is busy with high values of job arrival rate. When comparing Fig. 11(a), and Fig. 11(b), the strategies with variable-time waiting policy (vWDD, vWAD, vWAA) show marginally higher values of server utilization in comparison to that in the strategies with fixed-time waiting policy.

Fig. 11, Fig. 11 presents the sensitivity analysis of server utilization wrt. the variation of service time (). In overall, as the servers’ service time gets longer, the server utilization in all strategies rises rapidly because the processing of jobs in servers lasts longer. In consistence with the above sensitivity analysis of server utilization wrt. job arrival time, the MTD strategy DDD with dropping policy for jobs at all places always has the lowest server utilization compared to those strategies with waiting policy. Whereas, the implementation of waiting policy for ongoing jobs in servers in the strategies (fWDD, vWDD) leads to an increase in server utilization compared to that in the DDD strategy. While, when jobs in transit or in servers’ service queue are accepted in the execution of an MTD process in the strategies (fWAD, fWAA) and (vWAD, vWAA), the server utilization clearly rises at a much higher level as the service time increases.

Fig. 11, Fig. 11 depicts the sensitivity of server utilization wrt. the variation of MTD interval (). As per observed in the two figures, when the value of MTD interval increases in the range of low values (0–250] s, the value of server utilization metric vertically rises up. Whereas, in the range of greater values (bigger than 250 s) of the MTD interval, the variation of server utilization is marginal. We also can see that the dropping of jobs at all places in the strategy DDD still pull the values of server utilization while the implementation of waiting policy pushes up the values of server utilization as the MTD interval varies. Whereas the values of server utilization are slightly different in the remaining strategies as the values of MTD intervals changes.

Fig. 11, Fig. 11 show the changes of server utilization wrt. the variation of servers’ service queue size (). When the size of the servers’ service queue increases, the server utilization in all strategies gradually gets higher values, but the difference is marginal. The position of the graph representing the variation of server utilization in the strategy DDD is still the lowest one which tells that the dropping policy of jobs at all places leads to low utilization of servers. The strategies with waiting policy have higher values of server utilization when the servers’ queue size changes, and the waiting strategies with accepting policy for jobs even manifest higher server utilization, but the gaps between the cases are narrow.

Fig. 11, Fig. 11 display the behaviour of the server utilization metric over the changes of the ratio of long/short job types (
). When the number of long jobs coming into the system is higher than the number of short jobs (i.e., the ratio 
 increases), the server utilization metric gradually grows in an approximately proportional manner. The server utilization in the DDD strategy with dropping policy for jobs at all places is still the lowest one at all ratios of long/short jobs. Furthermore, as more short jobs arrive, server utilization in the waiting strategies are slightly similar since the processing of a short job is much shorter. But, when more long jobs come, the accepting policy for jobs in servers’ service queue and jobs in transit does manifest an impact in server utilization in which (i) the strategies fWAA and vWAA with accepting policy for all jobs show the highest server utilization while, (ii) the strategies fWAD and vWAD with acceptance for jobs in servers’ service queue but dropping policy for jobs in transit show slightly lower values of server utilization compared to fWAA and vWAA whereas, (iii) the strategies fWDD and vWDD with only waiting policy for jobs in servers manifest clearly lower values of server utilization compared to the strategies (fWAA, fWAD) and (vWAA, vWAD).

In general as seen throughout the figures, we realize a common tendency in the graphs in which, (i) the dropping policy of jobs at all places in the strategy DDD always manifests the lowest values of server utilization, (ii) the implementation of waiting policy in the remaining MTD strategies significantly leads to higher values of server utilization compared to that in the DDD strategy, (iii) when it starts to accept jobs in servers’ service queue in the strategies (fWAD and vWAD), the values of server utilization are also higher than that in the waiting strategy without acceptance of jobs (i.e., fWDD and vWDD), and (iv) the acceptance of jobs in servers’ service queue and jobs in transit in the waiting strategies (i.e., fWAA and vWAA) has a marginally higher value of server utilization when only accepting jobs in servers’ service queue in the strategies (fWAD and vWAD), respectively. As per observed, the server utilization is highly sensitive with (i) the changes of MTD interval () in the range of low values (i.e., more frequent repetition of MTD execution), (ii) the variation of job arrival time () and service rate (). While the waiting and acceptance policies for jobs clearly have an impact on server utilization when more long jobs arrive.



Fig. 11. Server Utilization () wrt. Impacting Parameters (a),(b): Job arrival (); (c),(d): Service time (); (e),(f): MTD interval (); (g),(h): Server’s service queue size; (i),(j): Job types (
).

Throughput:
The sensitivity behaviour of throughput metric of the overall system wrt. the variation of selected parameters is presented in Fig. 12.

Fig. 12, Fig. 12 presents the sensitivity analysis of service throughput wrt. mean job arrival time (). As per observed, when the system is in busy periods with high arrival rates (i.e., small ), the service throughput in all strategies is obviously high as well whereas, when the arrival time of jobs is bigger, the service throughput also goes down in accordance. Also, the accepting policy in the waiting strategies for jobs either in servers’ service queue or in transit (i.e., fWAD, fWAA or vWAD, vWAA) does have an impact on increasing the service throughput when the job arrival time is small (or the arrival rate is high) as shown by the higher position of the graphs for (fWAD, fWAA) and (vWAD, vWAA) strategies compared to the graph for fWDD and vWDD, respectively when the arrival time is small. The dropping policy of jobs at all places in the strategy DDD also holds the service throughput at the lowest level compared to that in all other waiting strategies.

Fig. 12, Fig. 12 show the sensitivity analysis of service throughput wrt. mean service time (). Clearly shown in the figures, if the service time is small or in other word, job processing in servers is fast with a high service rate, the system can gain higher values of throughput. In contrast, longer processing service causes a rapid sliding on the service throughput as shown by the downward throughput graphs. Here, we also see the impact of the dropping or acceptance policies on the service throughput wrt. the variation of service time. When the processing is fast with low values of service time, dropping jobs in the execution of waiting strategies slightly lower the values of service throughput. Whereas, it clearly pulls the service throughput down if we apply dropping policy for jobs in servers’ service queue in the waiting strategies fWDD and vWDD compared to the other waiting strategies (fWAD, vWAD) and (fWAA, vWAA).

Fig. 12, Fig. 12 display the changes of service throughput wrt. the variation of MTD interval (). As similar to the sensitivity of server utilization wrt. the execution frequency of MTD processes in Fig. 11, Fig. 11, the service throughput is very sensitive to frequent execution of MTD processes. Particularly, the more frequent the execution of MTD processes is, the more rapidly the service throughput falls down, as shown by the vertical part of graphs when MTD interval varies in the range of low values (0–250] s. But, when the MTD processes are performed with lesser occurrences, the service throughput gradually increases with marginal differences. Dropping jobs at all places in MTD processes in the DDD strategy also holds the service throughput down to the lowest level compared to other waiting strategies. While, accepting policy for jobs in the waiting strategies (fWAD, fWAA) and (vWAD, vWAA) manifests a marginal impact in increasing the service throughput compared to each of those strategies, and also a little difference if compared to fWDD and vWDD strategies, respectively.

Fig. 12, Fig. 12 depicts the sensitivity of the service throughput wrt. the variation of the size of the servers’ service queue (). When we increase the queue size , the service throughput slightly increases with marginal differences. Here, the strategy DDD also manifests the lowest service throughput due to dropping policy for jobs at all places while, the waiting strategies (fWDD, vWDD) with dropping policy for jobs in servers’ service queue and jobs in transit expose apparently higher service throughput compared to the DDD strategy but lower than that of the waiting strategies with accepting policy.

Fig. 12, Fig. 12 show the behaviour of service throughput metric wrt. the ratio of (long/short) job types. As per observed in both figures, when the system receives more long jobs, job throughput rapidly goes down. And the more long jobs arrive, the deeper the service throughput falls. Furthermore, the strategy DDD with dropping policy for all jobs also holds the lowest throughput as the ratio of job types varies. While, the waiting strategies (fWDD, vWDD) encounter with an apparent drop in service throughput if most of the jobs arriving in the system are long jobs.

In overall as per observed all over the figures, the service throughput metric is clearly sensitive wrt. (i) job arrival rate () and (ii) MTD interval () in the range of small values (highly frequent execution of MTD processes), in which a small variation in these factors causes an apparently large increase/decrease of the service throughput metric. In addition, the service throughput is relatively sensitive wrt. the change of service time and the ratio of long/short job types, and it is quite sensitive wrt. the increase of long jobs over short jobs in the way that the more long jobs arrive at the system, the more rapidly the service throughput drops. Regarding the impact of the job and time management policies in the execution of MTD processes, the dropping policy for all jobs at all places in the strategy DDD is still the major culprit that drops the overall service throughput to the lowest level in comparison to other waiting strategies. The implementation of waiting policy for the completing of processing jobs in servers apparently pushes the service throughput up to a higher level compared to the strategy DDD with dropping policy for all jobs in the execution of MTD processes. The acceptance of jobs in servers’ service queue does show an impact in increasing the service throughput metric while that of jobs in transit exposes a marginal impact.


Fig. 12. Service throughput (jobs/s) wrt. Impacting Parameters (a),(b): Job arrival (); (c),(d): Service time (); (e),(f): MTD interval (); (g),(h): Server’s service queue size; (i),(j): Job types (
).

Response time:
The sensitivity analyses of response time metric wrt. the variation of impacting parameters are shown in Fig. 13.

Fig. 13, Fig. 13 display the behaviour of response time metric wrt. job arrival time (). When the system is busy with a lot of coming jobs (i.e., high job arrival rate and very small job arrival time), the service response time metric increases in a non-linear fashion due to the increases of waiting time under limited queue sizes. The busier the system is the more dramatic response time increases. In this regard, the dropping, waiting and acceptance policies of jobs clearly impact on the service response time. Particularly, dropping jobs at all places in the strategy DDD keeps the service response time much lower than in other strategies even if the arrival rate becomes high. Clearly shown in the figures, if the waiting policy is used, the overall response time rises a lot when the system is much busier. Especially, when accepting policy is applied for jobs in servers’ service queue, the response time shoots up while the acceptance for jobs in transit does not have a big impact when the job arrival time is small.

Fig. 13, Fig. 13 display the sensitivity analyses of service response time wrt. the variation of service time. It is worth noting that we considered only one type of jobs with the same service time for both servers when performing this analysis. As per observed, when the service time is small in the range (0–50] s (i.e., the processing of jobs is completed quickly), we can see that the response time of provided services in all strategies are marginally different. But when the service time gets longer, the service response time rises rapidly up to very large numbers. The reason is that when the service rate is slow, with the same job arrival rate, more jobs are in waiting queues for processing. Therefore, we observed that the accepting policy for jobs in servers’ service queue and jobs in transit in the strategies (fWAD, fWAA) and (vWAD, vWAA) manifests an apparent impact causing a great increase in response time of services compared to the waiting strategies with dropping policy for jobs at the above-mentioned places (fWDD, vWDD). However, the waiting policy in the strategies (fWDD, fWAD, fWAA) and (vWDD, vWAD, vWAA) also shows a clear impact on increasing service response time compared to the complete dropping strategy DDD.

Fig. 13, Fig. 13 present the dependence of service response time on the variation of MTD interval (). As per observed in detail, the response time of services vertically rises up when the MTD interval increases in a range of small values (0–250] s, in other words, the system experiences a highly frequent execution of switch-over MTD processes. Afterwards, it gradually increases when the MTD interval gets longer. In this case, we see that the waiting and accepting policy in the waiting strategies (fWDD, fWAD, fWAA) and (vWDD, vWAD, vWAA) respectively manifests a slight impact on increasing the response time of services even when the MTD interval changes.

Fig. 13, Fig. 13 depict the variation of service response time wrt. the changes in the size of the servers’ service queue . As the queue size is small (less than 15), the service response time increases clearly when the size increases. This is because the number of lost jobs is higher due to small queue sizes. Additionally, we can also realize the impact of waiting and accepting policy in the waiting strategies on extending the response time of services. If waiting policy in the strategies (fWDD, vWDD) leads to a big gap in response time wrt. the lower one in the strategy DDD, the accepting policy in the waiting strategies (fWAD, fWAA) and (vWAD, vWAA) even causes a bigger gap compared to the graphs representing response time in the strategies (fWDD, vWDD).

Fig. 13, Fig. 13 show the sensitivity of service response time wrt. the ratio of long/short jobs. Clearly shown in the figures, as more jobs arriving at the system are of long jobs, the response time of services in all strategies rapidly soars up to very large values. And, the waiting and accepting policy for jobs in the waiting strategies also causes a clear increase of service response time. Comparing the two figures, we find that if the system receives many long jobs over few short jobs, the implementation of switch-over MTD strategies with fixed-time waiting policy causes a higher increase of service response time compared to those MTD strategies with variable-time waiting policy.

Overall, we realize throughout the figures that the response time of services is very much sensitive wrt. (i) service rate (), (ii) ratio of long/short jobs (
), and (iii) job arrival time and MTD interval in the range of small values. Also, as mentioned earlier, the waiting and accepting policies in the waiting strategies alternately cause an apparent increase of response time compared to each other and to the complete dropping policy in the strategy DDD.

Number of lost jobs:
Fig. 14, Fig. 14 display the variation of 
 over any change of job arrival time (). When the arrival time decreases in a range of small values (less than 15 s) that is, the system is very busy with high arrival rates and a huge number of jobs arrives at a time, the number of lost jobs 
 soars up to very large values. Nonetheless, when the system is less busy, the arrival time of jobs gets longer, the number of lost jobs decreases with marginal differences. When comparing the two figures, we find that the waiting strategies with fixed-time waiting policy lose slightly more jobs than those with variable-time waiting policy. This is because fixed-time waiting policy allows more jobs to arrive until a fixed time threshold is violated for another consecutive MTD interval, and thus more jobs could be dropped right after the threshold. Furthermore, we can see that the position of the blue graph representing the strategy DDD with complete dropping policy for all jobs at all places is now the highest in the figures. This is to say that the dropping policy in the strategy DDD causes even more job loss compared to other strategies. And, the waiting and accepting policies in the waiting strategies alternately reduce the loss of jobs as shown by the graphs at a lower level in the figures which represent the waiting strategies.

Fig. 14, Fig. 14 show the sensitivity analyses of the number of lost jobs 
 wrt. service time of servers (). As the processing of jobs in servers is performed quickly with low values of service time, we can see that 
 in the waiting strategies is very low, but in the case of the strategy DDD, 
 is much higher. This is to say that the dropping policy causes a negative impact when the service rate is high. Furthermore, when the service time gets longer, the total number of lost jobs in all strategies rapidly rises to a very high level. Even though the strategy DDD with dropping policy for jobs at all places still behaves as the worst-case while the waiting strategies with dropping policy for jobs both in servers’ service queue and in transit (fWDD, vWDD) lose more jobs as the service time increases in the range of higher values, and the waiting strategies with accepting policy (fWAD, fWAA) and (vWAD, vWAA) have a slightly lower number of lost jobs 
.

Fig. 14, Fig. 14 show the variation of the number of lost jobs 
 wrt. MTD interval (). As seen in the figures, when the system undergoes highly frequent executions of MTD processes, the number of lost jobs 
 is vertically shoot up in all strategies. Specifically, the strategy DDD with dropping policy for jobs at all places loses the highest number of jobs compared to the other waiting strategies when MTD processes are executed repeatedly at a very high rate. When the execution of MTD processes repeats at a slower pace, the number of lost jobs 
 in all cases is reduced vastly, and changes with the marginal difference if the MTD interval is long enough. This is because the servers can complete the processing of more jobs relative to the total arrived jobs in each MTD interval.

Fig. 14, Fig. 14 show the sensitivity analysis of the number of lost jobs per hour 
 wrt. the size of servers’ service queue. When the size is small, the number of lost jobs slightly increases but when we increase the queue size, the number of jobs changes marginally. This is because under the default parameters (e.g., job arrival rate  or service rate ), the queue size that is bigger than 10 is actually sufficient for the processing of jobs in servers. In addition, we also clearly see that the dropping policy in the strategy DDD behaves like the worst culprit to job loss as shown by the highest blue graph in the figures. While, waiting policy in the strategies fWDD and vWDD can reduce the number of lost jobs and the waiting and accepting policies in the waiting strategies (fWAD, fWAA) and (vWAD, vWAA) can reduce even more job loss.


Fig. 14. Total number of lost jobs per hour (
) wrt. Impacting Parameters (a),(b): Job arrival (); (c),(d): Service time (); (e),(f): MTD interval (); (g),(h): Server’s service queue size (); (i),(j): Job types (
).

Fig. 14, Fig. 14 display the sensitivity of the number of lost jobs 
 wrt. the ratio of long/short job types (
). We realize that as more short jobs arrive, the waiting strategies expose the lowest 
 but the strategy DDD still behaves as the worst case with the highest 
. And, the gap between these strategies in terms of 
 becomes even worse when the number of long jobs increases relative to the number of short jobs (i.e., 
 increases). In this scenario, the gap between the waiting strategy with dropping policy for all jobs (fWDD, vWDD) and the remaining waiting strategies also increases as more long jobs arrive.

In general, the number of lost jobs per hour (
) is highly sensitive with the variation of (i) job arrival time (in the range of small values), (ii) MTD interval () (also in the range of small values, i.e., more frequent MTD execution). While the metric is slightly sensitive wrt. service rate . Furthermore, the dropping policy is still the major culprit to the higher number of lost jobs while waiting and accepting policy in the waiting strategies alternately reduce the loss of jobs in the execution of MTD processes.

Operational cost:
The sensitivity of operational cost () considering maintenance cost and business profit cost in a year (USD/year) is shown as in Fig. 15. Since the computation of operational cost metric  relates to the number of lost jobs 
, the sensitivity behaviours of operational cost metric  and the number of lost jobs 
 with respect to the selected impacting parameters are very much similar as shown by the similar graphs in Fig. 14, Fig. 14 when comparing their respective subfigures. For this reason, ones may refer to the above-presented explanation of the sensitivity analysis of the number of lost jobs 
 for a comprehensive and similar description of the sensitivity of operational cost wrt. impacting parameters.


Fig. 15. Operational Cost (USD/year) wrt. Impacting Parameters (a),(b): Job arrival time (); (c),(d): Service time (); (e),(f): MTD interval (); (g),(h): server’s service queue size (); (i),(j): Job types (
).

Causes of job loss:
The investigation of culprits for job loss is shown in Fig. 16. It is a matter of curiosity what causes and their portion contributes to the total loss of jobs. Therefore, we performed analyses of job loss wrt. the ratio of long/short job types to understand the causes of job loss and compute the number of lost (dropped) jobs when adopting each of the switch-over MTD strategies in consideration regarding (i) the execution of MTD processes (
) (jobs are dropped during MTD processes depending on the job management policy of the MTD strategy or jobs are dropped when a time threshold is violated), (ii) the failures of physical subsystems (
) (ongoing jobs are dropped when a physical subsystem goes down, e.g., ongoing jobs in a server immediately vanish if the server fails), (iii) insufficient queue size of servers and network devices (
) and (iv) the ratio of long/short job types (
) (jobs can be discarded if a queue is full).

As per presented throughout the figures we realize that, under the observed period of time, the number of lost jobs due to physical failures of subsystems (
) changes with marginal differences in different MTD strategies and under the different ratio of long/short jobs. The portion of lost jobs due to this culprit of subsystem failures is also the least in the above-mentioned causes. Furthermore, we also can see a common tendency in all cases in which when the ratio of long/short jobs increases (i.e., more long jobs arrive at the system over short jobs), the portion of lost jobs due to (i) the execution of MTD processes (
) (as shown by the blue bars) and (ii) insufficient queue size (
) (as shown by the red bars) also increases rapidly. When the number of short jobs arriving at the system is higher (in some cases, even slightly lower) than the number of long jobs, the major portion of job loss is due to the execution of MTD processes while in some other cases, the main culprit of job loss is the insufficiency of the queue when most of the arrived jobs are of the long type. Particularly, in the strategy DDD as depicted in Fig. 16(a), we find that the major culprit of job loss is apparently the dropping policy for jobs at all places in the execution of MTD processes as shown by the high blue bars. Also, when comparing the figures, the complete dropping policy in the strategy DDD even causes the highest portion of job loss as compared to other strategies. The impact of dropping policy is still serious in the strategies (fWDD, vWDD) with waiting policy for ongoing jobs in servers and dropping policy for jobs in servers’ service queue and jobs in transit. But in these cases, when most of the arrived jobs are long jobs, the insufficiency in size of servers’ queue and network devices’ queue also causes a large portion of job loss. Nonetheless, in the cases of the strategies (fWAD, fWAA) with fixed-time waiting policy and accepting policy for jobs in servers’ service queue or jobs in transit, the insufficient queue size for holding more jobs when accepting jobs in MTD processes is the main culprit causing a large portion of job loss and an even larger portion if compared to the cause of lost jobs due to the execution of MTD processes in the above-mentioned cases. While, in the strategies (vWAD, vWAA) with variable-time waiting policy along with accepting policy for jobs in servers’ service queue and jobs in transit, the portions of job loss due to insufficient queue size and the execution of MTD processes are marginally different when most of the arrived jobs are of the long type.

5.4. Discussions
Client classification.
Without the loss of generality, all coming requests are assumed to arrive at the SDN network from clients without distinguishment or classification. From performability perspectives, legit or non-legit requests are not taken into account while job types are necessary to consider in which two types of jobs (long/short) are elaborated in modelling without any job priority. To this end, the impacts of job types are assimilated in the events of MTD execution since our focus in this work is the implementation and expected impacts of different MTD strategies on performability metrics of a SDN network. We found a world of possibilities for the extension of this work in the course to pursuing a unified framework and methodology for the simultaneous assessment of security and performability effectiveness of MTD techniques. The consistent elaboration and unification of client classification, job types along with different MTD strategies are challenging but essential to unify the security and performability effectiveness assessment of MTD techniques.

Resource availability and capacity.
The Eqs. (3), (11) (or more specifically, Eq. (12)) implicitly relate to each other in some aspects. Particularly, both COA and the power consumption of the servers in idle states 
 (as involved in the equations) are computed upon the probability of the resources residing in available () states. Therefore, the values of COA and 
 proportionally relates to each other. Nevertheless, if COA represents the resource capability to provide sufficient service availability as required in QoS agreements regarding service availability requirements, the operational cost due to power consumption as considered in Eq. (11) and Eq. (12) is more about performance requirements in which the total consumed power of resources actually varies not only upon the nominal availability of the resources but also the actual operations and workloads throughout a specific time frame. In particular, the power consumption under workload relates to CPU utilization of the servers in which the number of processing workers (
) in each server at a time needs to elaborate in the computation of total power consumption. It is worth noting that the probability of the markings in which a server 
 contains 
 processing workers (
, where  is the processing capacity of the server) is computed by the performance model and thus, is constrainted by the probability of the server being available computed by the availability model. In this sense, the total consumed power cost in Eq. (11) does consist the nature of resource availability COA in its calculation partially reflected in the idle power consumption. However, it does not imply specific relations between the total consumed power cost and the resource availability. In deed, the resource availability proportionally affects the nominal consumed power (in idle states), while extra power consumption cost which relates to actual operations and depends on adopted MTD strategies is introduced in the total consumed power cost in Eq. (11) (or more specifically, Eq. (12)). Therefore, the total consumed power cost varies dominantly upon the actual performance of the system. One may investigate the resource availability impacts on the power consumption cost when the total number of resources varies (for instance, the number of clusters in Eucalyptus-based private cloud Melo et al., 2017), which is out of the scopes of this study. We find a broad research avenue regarding the investigation on the relationship between availability metrics and performance metrics. We believe there is a need in future work for the comprehension on the impact of resource availability and capacity on the performance and security metrics along with the current studies on the effectiveness and impact of MTD techniques.

System of systems.
This work focused on fine-grained modelling and analysis of switch-over MTD strategies adopting various management policies for services and the execution of MTD processes in networked systems. Therefore, the proposed performability models are specific and comprehensive for a two-node server system in which a node is a primary server and another one is a redundant replica of the primary node for the implementation of service switching techniques in the execution of MTD processes. In this work, the system is considered as a twin-server system while in larger systems adopting switch-over MTD strategies, one may consider the system as a system of multiple twin-server systems and thus, the proposed models and modelling methodology can be extended in future works for modelling such a system of systems using hierarchical modelling approach or interactive modelling approach as presented in Ataie et al., 2017, Entezari-Maleki et al., 2017 and Ghosh et al. (2010).

Performability metrics and parameterization.
This work presented comprehensive analyses of substantial performability metrics including (i) availability metrics such as availability of physical subsystems, downtime minutes in a day, or COA, (ii) performance metrics such as service throughput, server utilization, service response time and the number of lost jobs per hour, and (iii) financial metrics (operational cost) such as cost due to power consumption and cost due to profit loss. Sensitivity analyses were performed in consideration of various impacting parameters such as (i) job arrival rate , (ii) service rate , (iii) MTD interval , (iv) queue size of servers  and (v) ratio of long/short job types 
. To comprehend different aspects and behaviours of the system adopting MTD techniques, future extensions can consider additional performability metrics of interest as well as parameterization as shown in (Ghosh et al., 2010, Raei and Yazdani, 2017).

Additional MTD techniques. This work showed a comprehensive study on the adoption of switch-over MTD strategies in networked systems using SRN models and simulation for analyses. The MTD strategies in this work are performed by the IP shuffling technique as the core mechanism for the sake of MTD and the switch-over and redundancy techniques as the key solution to maintain a high level of performability along with a variety of policies for service management and MTD triggering mechanisms. We realize an open research avenue in the future for the modelling and analysis of different MTD techniques along with different MTD triggering mechanisms, such as diversity MTD techniques with event-based triggering mechanisms as discussed in Cho et al. (2020a). In addition, a realistic test-bed development and its parameterization is a necessary endeavour to provide practical perspectives on the implementation of MTD techniques in a networked system in consideration of security efficiency and performability assurance.

Operational cost trade-offs.
In the cases without job policies, proposed MTD strategies are not adopted and thus, the traffic pattern of loads is different, which can be considered as a normal traffic under possible security attacks. Particularly, the power consumption cost in Eqs. (11), (12) varies mostly upon the load pattern while the probability of operational states (e.g., the probability that a certain server 
 contains 
 processing workers 
 (
,  is the processing capacity of each server)) varies in a different manner. On the other hand, since the adoption of MTD policies requires IP address shuffling and job switch-over strategies, the job loss due to MTD implementation could be apparently higher than it could in the case without MTD policies. Thus, the profit loss due to job drop under the adoption of MTD strategies could be much higher compared to the profit loss due to system failures or malfunctions without MTD policies. But, the profit loss due to security attacks is often unacceptable and unnegotiable. For instance, the privacy leaks could cause severe legal problems and damage the enterprise reputation. Therefore, in regards of operational cost, it is critical to not consider the trade-offs for the adoption of MTD techniques or not. In this regard, we find a broad avenue to unify the effectiveness assessment of MTD techniques in networked systems considering the trade-offs between both security and performability effectiveness in an unique assessment framework.

6. Conclusion
In this paper, we presented comprehensive performability modelling and analysis of an SDN system adopting switch-over MTD strategies. The chosen techniques for security efficiency in the execution of MTD processes are IP shuffling and server redundancy along with switch-over mechanisms for performability assurance. The triggering MTD mechanism is the time-based approach. While, various service management policies are proposed in the execution and progressing of MTD processes to maintain an expected level of performability measures, which form seven switch-over MTD strategies including (i) DDD strategy with dropping and zero-time waiting policies () for jobs at all places, (ii) (fWDD, fWAD, fWAA) and (vWDD, vWAD, vWAA) strategies with fixed-time and variable-time waiting policies ( and ) for ongoing jobs in servers, respectively and corresponding accepting () and dropping () policies for jobs in servers’ service queue and jobs in transit. In accordance with the considered MTD strategies in this work, we proposed different comprehensive performability SRN models and performed detailed simulations and analyses for the evaluation of performability metrics. Specifically, availability and performance metrics of the system were analysed under default parameters while sensitivity analyses of performability metrics were conducted with regard to various significant parameters including job arrival rate, service rate, MTD interval, service queue size of servers, a ratio of long/short job types. Performability metrics of interest include (i) availability and downtime minutes in a day of a physical system, and COA of services for availability analyses, and (ii) service throughput, server utilization, service response time, number of lost jobs per hour and operational cost for performance analyses. The analysis results revealed a comprehension of the impact and thus trade-offs for the implementation of MTD strategies on the performability metrics and operational behaviours of the system, particularly (i) while complete dropping policy for jobs at all places can secure security efficiency of MTD mechanisms, the policy apparently incurs negative impacts on system performance, (ii) waiting policy for the completion of processing jobs in servers in the execution of MTD strategies can help reduce the impact of dropping policy, and (iii) accepting policy for jobs in servers’ service queue and jobs in transit in the network even help diminish the negative impact of the dropping policy and the execution of MTD processes on the system performance. The findings of this study can help develop a comprehensive master plan for the adoption of MTD strategies in practical networked systems for security and performability assurance.