Both software-defined networking and big data have gained approval and preferences from both industry and academia. These two important realms have conventionally been addressed independently in wireless cellular networks. The discussion taken into consideration in this study was to analyze the wireless cellular technologies with the contrast of efficient and enhanced spectral densities at a reduced cost. To accomplish the goal of this study, Welch's method has been used as the core subject. With the aid of previous research and classical techniques, this study has identified that the spectral densities can be enhanced at reduced costs with the help of the power spectral estimation methods. The Welch method gives the result on power spectrum estimation. By reducing the effect of noise, the Welch method is used to calculate the power spectral density of a signal. When data length is increased, Welch's method is considered the best as a conclusion to this paper because excellent results are yielded by it in the area of power spectral density estimation.

Introduction
Big data enjoys a wide range of acclimation in both industry and academia. Its data sets are so complex and massive that conventional data processing methods and management tools are inappropriate to deal with it [1]. Big data is popularly denoted by “5Vs”: variety, velocity, volume, integrity, and value. In today’s world, the data is being generated exponentially, mainly from social networking websites, scientific research, and the internet of things (IoT) [2]. According to the recent report of an international data corporation (IDC), the global volume of data will increase from 33 zeta-bytes to 175 zeta-bytes by 2025 [3].

Big data applications would not be possible regardless of the underlying networking support because of their extreme complexity and large volume, specifically for near-real-time or real-time applications [4]. Recently, software-defined networking (SDN) has drawn much attention from researchers as a new paradigm in networking [5]. The core processes of SDN are to detach the control plane from the forwarding plane, instill the competence to program the network, and break vertical integration [6]. Logical centralization of feedback control is allowed by SDN, and decisions are made by the network brain operating with a global network viewpoint that eases optimization of network [7].

In SDN, data plane aspects become programmable packet and highly efficient forwarding devices, while the control plane features are reflected by a single entity: the controller [8]. It is much easier to develop and apply applications in SDN as compared to conventional networks. Additionally, it is feasible to enforce consistent network policies with the global exploration of SDN [9]. SDN reflects a major paradigm shift in the development of networks and introduces a new dimension of networking infrastructure.

In most previous studies, Big data and SDN have been addressed independently [10]. Nevertheless, SDN as an essential networking paradigm will have substantial effects on big data applications. Specifically, big data acquisition, storage, processing, and transmission are facilitated via several better characteristics such as logically centralized control, ability to program the network, global view of the network, and separation of the control and data planes [11]. For instance, big data is often processed in cloud data centers. SDN-based data centers show better performance by dynamically assigning resources in data centers to different big data applications to fulfill the legal service agreements of these big data applications in contrast with the conventional data centers [12].

Big data will have a substantial effect on the design and operation of SDN. In particular, the logically centralized controller in SDN can obtain big data from all different layers such as physical and application layers with arbitrary granularity with the global view of the network [13]. The network becomes so complex that conventional approaches are inappropriate to design and optimize such networks even though sharing information can enhance network performance in different layers [14]. Providentially, big data analytics can assist the design and operation of SDN and leverage analytical methods for obtaining viewpoints from data to guide decisions. For instance, it is easier for the controller to perform traffic engineering to enhance the performance of SDN with big traffic data analytics [15, 16].

Therefore, this study aims to discuss the fundamental characteristics and the new patterns of big data and SDN from the perspective of Quality of Service (QoS) management. It further presents the SDN features that may help solve different prevailing issues with big data applications such as data delivery, joint optimization, scheduling issues, cloud data centers, and scientific big data architectures. It has been observed that SDN can manage the network efficiently to enhance the performance of big data applications. Moreover, big data can benefit SDN by including cross-layer design, defeating security attacks, traffic engineering, inter-data-center networks, and SDN-based Intra networks [17]. In addition, several open issues are discussed that should be addressed concerning big data and SDN in future studies.

The interrelationship between big data and SDN in QoS management has not been well-addressed in previous studies [18, 19]. In particular, the unique applications of big data and unique features of SDN pose challenges beyond the existing work. It is assumed that the initial steps taken here should enhance the understanding of big data applications and SDN, facilitate maximum use of the advantages of SDN to enhance the big data applications, and ensure the effective working of SDN with big data. Previous surveys that formally explained the edge paradigm and its associated challenges, issues, and advantages and were published between 2015 and 2020 were included in the study to explore how effectively big data and SDN have been accepted in QoS management. The main observation throughout each survey and its associated primary theme, such as QoS management, were selected after reviewing the content of the papers. This review also indicated that the big data applications are still in their preliminary stages. The QoS management community requires additional time to comprehend how to use its advantages to provide feasible services to end-user clients. Following the current developments in the field of Big Data, contributions of the study are important as it would help in integrating further developments in the field of Big Data and cellular networks.

The use of intelligent devices is increasing with the increase in population. Communication, computing, and storage required by these smart devices require robustness and reliability to prevent them from deployment. Therefore, mobile devices were introduced to overcome these challenges. However, mobile devices have shown the issue of limited size and power consumption. Mobile devices had to be more capable of storing data and had needed ambient intelligence and information. This lead to more power consumption and faced issues regarding thermal management. This issue was resolved somehow after implementing the wireless LANs with fixed internet to support wireless mobile internet, which provides the same quality of service as fixed internet.

It was then needed to set wireless LANs as per the requirement of all the issues mentioned above. Wireless LANs evolution is a solution to the problems of 3G and enhanced the quality of the services. To increase the bandwidth and decrease the cost of the resources. Later came the advanced technologies such as; 4G and 5G to flourish the concept of good quality service at reduced rates. Furthermore, the researchers carried different researches related to the enhancement of spectral densities in wireless cellular communications. They introduced different approaches like an adaptive antenna and the A-SDMA approach, which alone can enhance spectral density, reduce power consumption, and drastically Radio Frequency pollution in cellular communication networks. The major goals of this approach are to get better coverage, increased capacity, reduced expenses in the upcoming world of technology. A lot of work is in progress on the smart antenna. Once nanotechnology antenna arrays are developed, it will be possible to incorporate smart antennas at handheld systems.

The study suggested using smart antennas to enhance the quality of wireless communication over time. Without being mechanically changed, the radiation pattern and the smart antennas with intelligence can be varied. The signals can be processed digitally, as the system uses a processor or DSP, and the performance with good reduction of signal interference and a high data rate transmission. It allowed many users to be connected as it gets rid of interference within the same cell simultaneously with the aid of the same frequencies. To where the most users are connected, it can also show the adaptation of the frequency allocation. The spectral efficiency of the cell could be multiplied at least ten times with the adaptive beamforming. Different researchers also suggested the enhancement of spectral density at a reduced cost. Also, the estimation of the spectral density and its methods were marked as the core points behind this study—Welch’s method for the estimation of spectral density, considered to be the milestone.

The rest of the sections are organized as follows: Section II presents an overview of big data and SDN; Section III shows the benefits of SDN on big data application; Section IV provides discussion on quality of signals and wireless communications; Section V presents the case study for resolving issues concerned with the quality of signals and wireless cellular networks, Section VI presents the discussion and Section VII presents the overall conclusion of this study.

Overview of big data and SDN
Big data has become a prominent subject of interest in recent decades as it is entirely related to the ability to store and process data sets. In recent years, new technologies have been developed for storing and processing huge datasets to enhance data capability [20]. The new domains, thus developed, are linked with the sources of big data such as scientific research, business, and networking [16]. Big data can be advantageously used in many applications in different domains such as healthcare, scientific research, IoT, and enterprise. Accordingly, Big data projects have been initiated by almost all the predominant firms such as Facebook, Microsoft, Oracle, Amazon, and Google. In the United States, several federal agencies such as the National Science Foundation, the National Institutes of Health, the National Science Foundation, and the Defense Advanced Research Projects Agency have made a great deal of investment in Big Data research [21]. However, Big Data research encounters several challenges such as data processing models, distributed storage, analytics platforms, underlying networking support, data staging, data security, and privacy [22].

SDN is considered one of the predominant means to revolutionize the cyber world with appropriate network management to increase the volume of data of different applications over the internet [23]. OpenFlow is considered the initial standardized protocol in SDN, and it is also identified as the enabler of SDN. At Stanford University, the ideas and work of OpenFlow were presented using the term SDN. This term refers to a network architecture where the forwarding link is managed by a remote-control plane decoupled from the preceding state in the data plane [24]. Real applications have followed additional SDN protocol standards. These days, the term SDN is not confined to any one integration, and it is used to represent a general platform. The definition of SDN as proposed by the open networking foundation is as follows: “In the SDN architecture, the control and data planes are decoupled, network intelligence and state are logically centralized, and the underlying network infrastructure is abstracted from the applications [6].”

Generally, SDN can be classified into three streams in its reference model: control layer, application layer, and infrastructure layer. In the SDN architecture, different applications are involved in the application layer [3]. The application layer communicates with the SDN control plane about the network status and its specific requirements with the help of the northbound application programming interfaces. In the control layer, the SDN control plane is considered the primary element of the SDN model, which controls the overall network [5]. Several SDN controllers have been designed, including Floodlight, OpenDaylight, Trema, Ryu, POX, Beacon, Onix, and Contrail. In recent years, SDN is being used for designing data center network architectures to accomplish better performance with low energy consumption and complexity [6]. SDN can fundamentally allocate resources for enhancing application performance by collecting the traffic data. In addition, the capabilities of SDN for application-aware-networking are leveraged in data center applications along with network architectures [9]. SDN-based data centers can help Big data applications by dynamically assigning resources based on service level agreements as it is often processed in data centers.

Benefits of SDN on big data application
Big data is often processed in cloud data centers. It is essential to efficiently allocate and manage resources of the cloud data centers for fulfilling the service level agreements of different big data applications since the resource equipment dynamically changes in cloud data centers concerning big data applications [10]. The service level agreement of a big data application is the accord settled between users and a big data service provider. It refers to the features of the offered big data service, including level objectives, anticipated quality of service (QoS), and penalties if the big data service provider11 does not fulfil these objectives.

Rate of failure, trust, negotiation time, maintenance time, cost estimation, amount of data processed, amount of data emitted, data quality of input and output, security, processing time, response time, data persistence time, data movement latency, and data losses are included as factors for service level agreements [12]. The technological pattern of cloud computing puts forth stress on data center providers for creating additional flexible services with better security and performance. The storage and networking infrastructure is delivered as a service and automated by service level agreement made with SDN-enabled data centers [1]. The cloud platform is constructed based on the data centers from the viewpoint of infrastructure, which can be termed cloud data centers. This infrastructure is hosted by cloud service providers for big data applications. Previously, an SDN-based OpenFlow network was proposed with combined input and cross-point queued switches for scheduling different big data application packets [14].

A controller maintains a bandwidth that offers a table for different big data applications and sends it to the combined input and cross-point queued switches. Afterward, the packet scheduling preferences are decided by the switches based on the bandwidth provisioning table from the controller. Different big data applications in cloud data centers reduce the resource allocation frequency and the power consumption [7]. The application-driven control plane is decoupled with SDN, allowing photonic devices’ dynamic and flexible runtime configuration for supporting complicated traffic patterns. SDN-enabled tropical transport architecture is presented for handling the bursting data in big data applications with the deployment of SDN [8]. A core transport node is abstracted into a programmable architecture for leveraging the OpenFlow protocol for control. It is observed that flexibility and programmability can help data delivery for big data applications with a prototype description.

Quality of signals and wireless communications
The evolution of Wireless LANs provided the same service and quality as the fixed networks. It was beyond the problems and limitations of 3G. Still, the goal was also to increase the services and quality provided by the wireless communications to get the increased bandwidth and reduce the cost. 6G technology was introduced for the integration of satellites to get global coverage. Communications were considered horizontal, including cordless, short-range wireless connectivity, and wired systems.

4G mobile systems use horizontal communication, which involves the systems mentioned above to provide such platforms that complement each other to create radio environments in the best possible way. The 5th wireless communication helps set the world-wide wireless web (WWWW) concept defined as a perfect real wireless world. 4G technologies provide a base to the 5G technologies. Two main problems need to be addressed while working with this kind of processing. (1) Freedom of movement exists from one technology to another, and (2) it gives a wider coverage. Proceeding to the next generation (6G) wireless networks of mobile communication, 6G shall integrate the satellites for global coverage. The union of the four systems is accomplished by the 7G Technology, the 7th generation for space roaming.

The four GPS systems available will be united in the 7G wireless mobile networks to get space roaming for 6G systems [25]. On the other hand, using the technology with its added application of the advanced cellular networks will be an essential task to make resources highly feasible to use. The incredible success of wireless communication has been observed in the last 45 years. It has been predicted that in the future, the annual data traffic will grow by 38%. Developing traffic in cellular networks requires some vital factors are required. These factors include the architecture of the cellular network and increased network throughput. The following three remedies have been suggested to solve this problem: Higher Cell density, More Spectrum, and Higher spectral efficiency [25].

In a broadband wireless communication system of modern times, Orthogonal Frequency-division Multiplexing called OFDM is the technique devised to execute this kind of communication. OFDM has been adopted by the IEEE 802.11a, i.e., wireless standards. On WLAN, different curves of Power Spectral density are used by the OFDM. The waveform of OFDM analyzes different block sizes and various modulation techniques in frequency-domain and their responses. Quadrature phase-shift keying (QPSK), 64 Quadrature Amplitude Modulation (QAM), 16 QAM, and Binary Phase Shift Keying (BPSK) are some of the techniques that define the modulation. For 2048 block-size, − 32.5, − 17, − 22.5, and − 32.5 are the spectral densities of the previously mentioned modulation techniques. With the increase in levels of modulation, power spectral density (PSD) also increases. It depends on which modulation technique is being used as the PSD depends on these techniques. As the modulation levels increase, PSD gets strong.

According to Wang et al. [29], circular overlaps are used to destroy the effective properties of the windowing function. The comprehensive windowing function is illustrated from the magnitude of the DFT. This function assists in reducing the variation when modifications are applied to solve the issues [26]. These problems adhere through the use of circular segments window, which is appropriately illustrated using different windowing functions. It has been deemed that the implementation of circular segments in the windowing function will not lose its effective aspects for the better monitoring of spectral densities [27].

An analytical expression has been found possibly from the variance analysis, whereas the window's resolution is shown effectively using extensive simulations. By considering the contra analysis of wireless cellular technologies, it has been observed that the enhanced estimator of the spectral density function anticipates the equivalent fluctuation in the spectral density [28]. The reason behind this anticipation is found in the affective aspects of the windowing function. The modification of spectrum estimator using welch method has been applied to identify the spectral densities [29]. Power spectrum estimation methods have been successful in accomplishing the enhanced spectral density at reduced cost [30]. This perception is accomplished for the variance reduction and reflected through the biasness of the Welch power spectrum estimation.

A monotonically reduced function is comprehensively observed using the variance of the modified power spectrum estimation using the welch method, where numerous overlapping sub-records and overlapping fractions are decreased. Numerous studies have revealed the enhancement of spectral density by using the Hamming window [31,32,33]. The modifications implemented with hamming window significantly improve the spectral density of wireless cellular technologies at a reduced cost [34]. The identification of power spectrum estimation is reflected through different shadings such as light gray curve and dark gray curve, which reveals the overlapping of spectral density under the Welch method. It has been indicated that significant correspondence is shown between the welch method's spectrum estimation and overlapping spectral density [35]. Furthermore, the overlapping of spectral density is adhered to for the circular overlapping, whereas the business of welch spectrum density is reflected using the equivalent magnitude [36].

Prior studies have focused on the improvement of spectral density using the anticipated expression of variance [37,38,39]. It has been identified from the outcomes that the modified power spectrum estimation was effective in computing the circular overlapping. In contradiction to this statement, this study has implemented a welch method to analyze wireless cellular networks to investigate the enhancement of spectral density at a reduced cost [40]. The variance of the welch method has significantly dominated the enhancement of spectral density. It has been found that the correlation between spectral density and bandwidth reduction is illustrated by augmenting the frequency of overlapping results [41]. On the contrary, the estimation of the welch method has been revealed from the variance of unequal data weighting, implying a covariance among the weighted sub-records and a windowing function [42].

Past researches have shown a monotonic reduction in the variance of enhanced power spectrum estimation, which instigates additional systematic flaws [43]. The enhanced spectral density using the welch method for wireless cellular technologies is based optimally on the extent of spectrum estimation. The effective properties of traditional welch spectral density have been modified through the enhanced power spectrum estimation [44]. The overall processing algorithm cannot be modified by using the effective properties of the Welch method [45].

The implementation of the welch method has been vital in enhancing the power spectral density estimation. Furthermore, speech recognition and speech compression have been estimated by using spectral deduction. Several different types of noise have been used to estimate the actual recording of speech signal interference. It has been identified that the noise of vacuum cleaners and blenders is heavily associated with speech signal [46]. By considering this interference, the approximation of white noise is revealed from the white band noise characters.

On the contrary, a drilling machine and a ford transit have been used in past researches, showing the interference of speech signal [47]. These approaches have been examined based on their narrow-band noise characters. The signal-to-noise ratio has been determined for the estimation of quality segments as well as to ensure that the actual environment [48] made the recordings. In addition, this estimation has ensured that speech signal was acquired without the distortion of any interference [49].

The signal power is being examined from the ratio of speech signal segment with the power of interference. The proposed modified welch method has been used to enhance the spectral density and determine the noisy speech signal of wireless cellular networks at compressed bandwidth. To compare this approach, researchers have shown the enhancement of spectral density by using the spectral subtraction approach and Welch method [50,51,52]. Moreover, prior research has also applied the RASTA method for improving spectral density. These approaches have been vital in identifying the values of signal-to-noise ratio [53]. The anticipated enhancement in the signal-to-noise ratio has been revealed from the wideband character interference compared to the RASTA method and the original spectral subtraction. The dependency of signal noise has been additionally observed from the narrow-band character noise [54].

Case study
This study suggested the use of smart antennas to enhance the quality of wireless communication over time. Without being mechanically changed, the radiation pattern and the smart antennas with intelligence can be varied. The periodic signals can be processed digitally as the system uses a digital signal processor and performs with good reduction of signal interference and with a high data rate transmission. Allowing many users to be connected, the narrow beams get rid of interference within the same cell simultaneously with the aid of the same frequencies. It can also show the adaptation of the frequency allocation. With the force of the adaptive beam, the spectral efficiency of the cell could be multiplied at least ten times [55].

In order to collect the data, different data bases and research articles were considered such as IEEE, IJSRET, MathWorks and Google scholar etc. In order to collect appropriate data, main keywords were searched which were found to be included in the study and were found to be supporting the fact that has been discussed in the study. Few of the keywords which were selected were; wireless cellular communications, spectral density, estimation of PSD, Welch’s method and many more. The study has been formulated on the basis of relevant studies and the published articles which were used as the resource pack by the researcher of this study. Moreover, the articles that have been selected in the study were found to be authentic to implement experimental analysis of the study. Furthermore, the selected studies will be thoroughly assessed for the quality of the content that has been included in the selected research and was then further assessed on the various scales.

The researchers have collected the data in a way to attain the objective and the motive for the research. In the beginning, investigator have done paper work, listed down all the queries and points which they wanted to know. Because gaining quality data from individuals or groups without any misunderstanding is mandatory. Before doing this study; the researchers had many confusions related to the topic but once they had done that, concerns and confusions were minimized to zero level. Selection of the signal processing professional’s has done according to their achievements and experiences. The sampling of data impacts overall evaluation by providing understanding and useful experimental method in addition to Welch’s method to assess the change and to observe the reasons as well as results behind the process.

Methods
The spectral density illustrates time series in a frequency domain directly proportional to the time-domain auto-covariance representation. The auto-covariance is carrying similar information and the spectral density of the signal essentially, but their representations are entirely different.

The spectral density and the auto-covariance have a relationship which is illustrated below:

Υ(h)=∫−1/21/2𝑒2×𝜋𝑖𝑤ℎf(w)dw
(1)
and

F(w)=∑ℎ=−∞ℎ=∞Υ(ℎ)𝑒−2𝜋𝑗𝑤ℎ
(2)
Population spectral density is estimated by the rough sample of a periodogram which is called a raw periodogram. For the Periodogram, only the fundamental harmonic frequencies, which are discrete, are used. Therefore, the estimate is “rough”. While over a continuum of frequencies, the spectral density is defined. With the aid of moving averages center, spectral density estimation is smothered, and this can be considered the one achievable improvisation. Using tapering methods, smoothing can be done additionally, which is used for weighing the ends of the series (in time) less than the center of the data. Below are the two main methods for estimating the Spectral Density:

Estimation of the spectral density (non-parametric) (smoothing method)
For the smothering of a periodogram, a classical method that is being used as a name that sounds fancy and hence, difficult to pronounce. With a few possible modifications, its mere procedure is to average the moving at the center. The Daniell kernel uses the m parameter, which defines a centered moving average for a time series. Generally, this will create a value at time t, which is smothered by taking the average values between times t − m and t + m.

Estimation of the spectral density (parametric)
The non-parametric method in the spectral density is the smoothing method for the estimation of a spectral density. The time series process has not been used by this method which is underlying because no parametric model is made for the time series process. Alternatively, the parametric method is the one that is mainly used for this purpose. This will emphasize the most appropriate method, known as the Auto-regressive model, for plotting the spectral density of that model for the series. Before a spectral analysis, the parametric method produces a series that is detrended. At a low frequency, such dominant spectral density is caused by a trend that the other trends cannot be seen.

Power spectrum estimation using Welch method
In Power Spectral Estimation, a good resolution is achieved by using data samples optimized in size. By using the rectangular and hamming window approach, Power Spectrum estimation can be acquired, using the Welch method for variable data length, which has been evaluated in this paper. Welch method uses the non-parametric approach, which includes a periodogram. Because of the implementation, which is achievable by using the fast Fourier Transform, is a very beneficial way for Welch's method. Including the periodogram technique, the Welch method can provide a fair resolution resolution if the selection of the data length samples is optimal. To simulate and design Power spectrum efficiency, MATLAB provides the aid for both the Hamming window and the Rectangular window. Among other windows like Blackman, Hanning, and Barlett window, Hamming and Rectangular window techniques yield better results.

To reduce the variance of a periodogram, a method used is called the Barlett method. Moreover, the Blackman method is used to reduce the estimator variance, which is sent by samples of correlation. Modification of Barlett method is used by Welch’s method through which it is allowed to overlap the portion of the series that contribute to each Periodogram. An improvement on the Periodogram is also done by Welch’s method. The finite length of a signal is used to estimate the auto-correlation method is the spectrum estimation method which reduces noise in the estimated power spectra and where the signal to noise ratio is high, in exchange for frequency resolution deduction. The Welch method in this paper, with different windows in window methods, gives the power spectrum estimation result. With reducing the effect of noise, the Welch method is used to calculate the power spectral density of a signal. When data length is increased, Welch's method is considered the best as a conclusion to this paper because excellent results are yielded by it on the area of power spectral density estimation.

Welch programming
To generate a signal for the pwelch estimation, consider Ts  =  1e−6, where t is supposed to be t  =  (0: Tsamp: 222*Tsamp), where Tsamp is the sampling period. Fs the frequency of the signal is Fs  =  440.55 (constructed to show some scallop loss), the amplitude of the signal is A  =  0.8 (signal magnitude in V); Total integrated noise in Vrms, i.e., (voltage root mean square) is denoted by Vn  =  1/300; Input signal is:

Vin  =  0.8*sin [2π (440.55)]  +  randn [size (t)]*Vn;

The output in bitstreams is taken as bout  =  ones [size (t)], i.e., the output is returned as the scalar 1 with the same numeric type, complexity (real or complex) which is equal to the size of t. Qin is taken as 0, regin  =  Vin (1), and regout is taken as zero. If qin is greater than equals zero; qout is equaled to 1. Otherwise, qout is a negative numeric value i.e., − 1. Now, a variable bout (k) has a value of qout. In addition to it, qin is replaced by regin. Where regin  =  Vin (k) − qout + qin. K is the range; k  =  0, 1,……., n.

Now to calculate an 8-times averaged spectrum with pwelch, where n is the averaging factor of vector x, nx  =  max [size (bout)]; where nais taken as 8. W is the window, which uses blackmanharris MATLAB function and is hence represented as w  =  blackmanharris [floor (nx/na)]. The parameters that are passed in pwelch function will be bout, w, 0, [], 1/Tsamp and therefore, is given as [Pxx, f]  =  welch (bout, w, 0, [], 1/Tsamp);

Now, fbin  =  1/Tsim which is equal to fbin  =  1/NTsamp. Here Tsimis the simulation or measurement time and Tsamp is the sampling period. In order to calculate the spectrum parameters, fbin = f(2) − f(1); Coherent gain is CG that is, CG  =  sum (w)/(nx/na); and Noise gain is NG, that is NG  =  sum (w. ^2)/(nx/na);

Now, to calculate the indices of the signal, harmonics, band edge, Indices of signal are written as;

isig  =  round (fig/fbin)  +  1; while the indices of 3rd harmonic signal will be ih3  =  round (3*fsig/bin)  +  1; and the indices of 5th harmonic signal is shown as ih5  =  round (5*fsig/bin); and the indices of the bandwidth were ibw  =  round(2500/fbin)  +  1.

Moreover, for plotting and marking the above signal, loglog function is used, loglog plots the column of Y versus their index if Y contains real numbers. Here, it is taken as loglog (f, Pxx), hold on is used to hold the window of the plotted graph. A variable itmp is taken and some operations are performed such as itmp  =  (isig − 5: isig + 5)’; plot [f (itmp), Pxx(itmp), ‘r’]; itmp = (ih3 − 4: ih3 + 4)’; plot [f (itmp), Pxx (itmp), ‘r’]; itmp  =  (ih5 − 4: ih5 + 4’; plot [f (itmp), Pxx (itmp), ‘r’];

And also, plot [f (ibw:end), Pxx (ibw:end), ‘g’]; and hold off is used at the end, a  =  axis (); a (1) = f(1); a (2) = f (end); axis (a);

Also, given the labelling as (‘frequency [Hz]’); ylabel (‘Power Density [V^2/Hz]’);

Finally, a few calculations are presented now. For measuring the signal magnitude srmt is the variable is taken, which is the division of asig with sqrt;

Theoretical values are presented as, srms is now a square root of the sum of (Pxx (isig-5: isig  + 5)*fbin), signal spectrum integrated is shown by the variable srmsp which is the square root of [Pxx (isig)*NG*fbin/CG^2], maximum read off spectrum is denoted by a variable which is scl that is scallop loss scl  =  20*log 10 (srmt/srmsp).

Findings
Different researchers have also suggested the enhancement of spectral density at a reduced cost. Also, the estimation of the spectral density and its methods were marked as the core points of this study. Welch’s method for the estimation of spectral density is considered to be a milestone. Welch’s method has been employed using MATLAB programming to reduce the spectral density consumption of wireless cellular technologies. Hamming and rectangular windows have been used to reveal the results of spectral density further. The spectral densities have been computed by applying different loads in the MATLAB Periodogram.

The frequencies obtained for spectral density analysis have shown effective and significant results regarding wireless cellular technologies. These results have been comprehensively supported by results of the past studies that showed the enhancement and efficacy of spectral density using Welch’s method. To analyze spectral density, different values were undertaken for the comparison of windowing function on power spectral density estimation. The utilization of filter transfer function has proved the appropriate reflection of goodness of fit in order to obtain spectral density. The signal power is also another aspect, which is used to identify the enhancement of spectral density. In this regard, power spectral density integration should be comparatively equal to the variance of the comprehensive power. To compute the entire spectral values, Parseval’s theorem was used by considering the integration of the power spectrum. It has been notified that differences in the numerical computation are the outcomes of estimating the variance of comprehensive power spectrum density.

The accurate working of code has been provided to focus on the better results of Periodogram and spectral densities. The validation of code and influence of different lengths and windows have been reflected from the experimental data. The spectrum shape is revealed in the form of harmonic tones and a low-pass frequency filter from the results. The association of MATLAB periodogram increases the generation of pure tones flow along with the number of blades and frequencies. The window length effect has been shown to compute the influence of diverse window lengths and types.

A turbo-machinery has been used for the generation of power spectral density with different window lengths. In Fig. 1, harmonic tones and broadband frequency are shown, apparently generating spectral density. It is revealed from Fig. 1 that the bottom plot is closely associated with the first tone. The representation of tones appeared on account of the better capability of different windows. Generally, an impulse function is used to notify the window tones.

Fig. 1
figure 1
Estimation of Power Spectral Density with different window length

Full size image
On the contrary, the illustration of sampling frequency is represented as a sine function because of practical restrictions. In addition, a superior approximation is revealed from the sine function that leads to different window lengths. Considering this approach, it has been explored that the anticipation of tone frequencies leads to a crucial dilemma because window length is directly based on the modification of the values.

The programmable source has been shown in Fig. 2 for the spectral analysis at 30 Hz and full load. The harmonics of spectral density have been represented, which illustrates a higher magnitude for a full load. Figure 2 depicts that the harmonics for the power spectral analysis are illustrated based on equivalent frequency. In addition, the magnitude of the spectral density has been measured from the harmonic tones of the Periodogram. It has been represented from the results that there is no apparent occurrence of superimposed harmonics as compared to the first harmonic tone. The figures have shown that the representation of spectral density cannot be illustrated easily at low frequency. Thereby, the detection of the spectral density should be based on higher frequency and harmonics.

Fig. 2
figure 2
Power Spectral Density at full load and at 30 Hz

Full size image
From Fig. 3, the programmable source for the spectral density has been identified, monitored at 40 Hz. The harmonics of spectral density have been represented, which illustrates a higher magnitude for a full load. The frequency of harmonics in the Periodogram is higher as compared to the frequency used in Fig. 3. The appearance of harmonic magnitude is represented through the spectral analysis periodogram. Figure 4 distinguishably shows lower harmonics between the spectral densities at full load.

Fig. 3
figure 3
Power Spectral Density at full load and at 40 Hz

Full size image
Fig. 4
figure 4
Power Spectral Density at full load and at 60 Hz

Full size image
A distinguishable comparison has been shown for the spectral densities at 60 Hz. Figure 4 represents the magnitude of harmonics for spectral densities. The harmonics reflected from the figures have shown a better indication of the spectral densities. Figure 5 depicts a higher magnitude for 80 Hz. The inclusion of more harmonics in these figures has shown a better indication of spectral densities. The results show a higher magnitude for the spectral densities from the MATLAB periodogram.

Fig. 5
figure 5
Power Spectral Density at full load and at 80 Hz

Full size image
Discussion
The applicability of wireless cellular technologies in enhancing spectral density by using the cellular infrastructure has been considered. The accessibility of cell radii is indicated in the bandwidth of cellular infrastructure. The fraction of inactive users and the density of access points have initiated the augmentation of the achievable rate. The extensive usage of cellular technologies has focused on the individual's perception to revise cellular rates to access the services easily. Thereby, spectrum allocation can be technically advanced with the implementation of simple allocation schemes [56].

The accessibility of managed infrastructure can be revealed from the optimistic rates, which are accounted for channel impairments. These impairments are directly associated with the mobility and large-scale fading of cellular technologies. Numerous applications are accessible for the enhancement of spectral density and to assume the shared use of cellular infrastructure. On the other hand, the minimal extent of individual rates focuses on the low accessibility of spectral density [57]. Broadcasting services are further focused on accomplishing anticipated enhancement in the spectral density by acknowledging the demands of cellular technologies. By considering the use of coding schemes and modulation, it has been reflected that system design can be simplified by enhancing spectral density. The minimization in associated interference and transmit power are further enabled through different bandwidths.

Further researches have discussed the relationship between spectral efficiency and cellular networks [58,59,60]. These relationships have adhered to energy efficiency analysis, which reveals the usage of default parameters to enhance spectral density. These studies have comprehensively focused on the comparison of cellular grid networks as well as random cellular networks for analyzing the efficiency of power spectrum density. The path loss exponent and cellular network density are focused on comparing grid cellular networks and spectrum efficiency. The results have shown the illustration of PVT cellular network in the form of the hexagonal cellular network. By considering the results, the efficiency of the spatial spectrum is augmented comprehensively through cellular grid networks. In addition, the corresponded values of random cellular networks are compared to the grid cellular networks to enhance the efficiency of spectral density. These results have been affirmed in which the core focus was on the transmission of spectral density between random cellular networks and girded cellular networks [61].

The efficiency of spectral density is indicated from the cellular network spectrum density on the fixed transmission bandwidth. The likelihood estimation of cellular networks is increased due to the escalated arrival rate. On the contrary, the reduction between the grid cellular networks and spatial spectrum efficiency with the potential increase of arrival call. Different thresholds have been used to enhance the efficiency of spatial density and the association of call arrival rate with spectrum efficiency in cellular technologies. The efficiency of spectral density is decreased when the call arrival rate is fixed in the cellular technologies [62].

The applicability of realistic channel models has allowed cellular technologies to investigate the spectral density enhancement at reduced costs. These channels have accurately demonstrated the usage of appropriate and indispensable methods for analyzing the enhancement of spectral density [63]. Among these channels, high-mobility channels and MIMO channels have been significant in measuring the efficiency of cellular technologies. On the contrary, restrictions have been found for implementing MIMO channels as numerous antennas are adhered to to illustrate the cluster observations. Cellular technologies have specifically dominated through the implementation of MIMO channels, which categorize the cellular network assumptions. The non-stationary and spherical-wave front assumption demonstrates the efficacy of spectral density. The classification of cellular technologies is categorized from these existing channels, and, therefore, the enhancement of spectral density is attributed through these channels significantly [64].

Welch’s method has been effective in indicating the significance of spectral density in wireless cellular technologies. Cellular technologies have been the main focus in the current era due to their resources and varied demand. A large service provider can provide an incentive to the cellular users in creating in-depth incorporation of base stations and demand for more spectrums. Based on the above discussion, it can be said that wireless cellular technologies should be a focus on using different parameter techniques and the enhancement of spectral density.

Conclusion
By using MATLAB Periodogram, results have shown that spectral densities can be improved with the aid of spectral estimation methods. Better resolution and variance have been shown for the spectral densities by applying different loads. Thereby, it has been concluded that the effective implementation of the Welch method provides enhanced spectral densities for cellular technologies at a reduced cost. Moreover, it has been indicated that the Welch method compared with the Bartlet window provides significant spectral densities. If the number of samples is augmented, the entire results regarding power spectral densities can effectively reduce the effect of noise and work.

The algorithms used in the study are operated in the frequency domain, focusing on computing the samples by applying sine waveform in the frequency domain. The coherence level of spectral density is escalated when the quality of the estimate expands as the size of the data. The Blackman Tuckey test should be utilized instead of the Welch method when data size is smaller; however, the Welch method can provide significant results when the data size is expanded. The depiction of power spectrum estimation is observed from the peaks of different windows. SDN has been studied for wireless mobile networks and wired networks, including cellular networks, vehicle networks, and sensor networks. SDN-enabled wireless mobile networks will bring promising features such as reduced management and operational costs of heterogeneous technologies, increased accountability and service differentiation, easier deployment of multi-vendor infrastructures, efficient operation of multi-vendor infrastructures, and continuous and transparent improvement of network operations. With the rapid development of wireless mobile networks, additional data are now collected from mobile networks and devices. Therefore, additional research should be conducted to study SDN’s advantages in wireless mobile networks for big data applications. Wireless services can be beneficial at different locations by granting spectrum to be incorporated with major modifications. This incorporation can significantly expand the demands of the user towards wireless cellular technologies. The independence of the provision of wireless services can be a major outcome of the expansion of spectrum technologies and ownership. By considering low entry barriers, the instigation of diverse offering sets can aid in the development of assorted cellular technologies.

Spectrum techniques should be considered for the allocation of diverse applications in the cellular technologies market by the user demand. Efforts should be made to prepare the grounds that shall assist in the better development of wireless cellular technologies. Furthermore, the enhancement of spectral densities should be focused in these efforts. In the context of current operational features, a significant barrier has been notified that obstructs the effective execution of the flows. Future studies should focus on implementing wavelet transform coefficients for the enhancement of spectral densities. This approach can be effective in mitigating the variance of spectral power estimation for different noises. The enhancement of speech signal can be used from the consistent estimation of the spectral subtraction method. By considering this approach, the power estimation of the spectral signal of speech recognition can be mitigated through the lower variance of power spectral density. The by-product of the current method of spectral subtraction method can be effective in exploring the speech signal of the spectrum. Furthermore, single-channel methods of speech improvement can be used to threshold the wavelet transform coefficients and anticipate power spectral density.

Abbreviations
IDC:
International data corporation

IoT:
Internet of things

OFDM:
Orthogonal frequency-division multiplexing

QoS:
Quality of service

SDN:
Software-defined networking

WWWW:
World-wide wireless web

PSD:
Power spectral density