The social media technologies are open to users who are intended in creating a community and publishing their opinions of recent incidents. The participants of the online social networking sites remain ignorant of the criticality of disclosing personal data to the public audience. The private data of users are at high risk leading to many adverse effects like cyberbullying, identity theft, and job loss. This research work aims to define the user entities or data like phone number, email address, family details, health-related information as user’s sensitive private data (SPD) in a social media platform. The proposed system, Tweet-Scan-Post (TSP), is mainly focused on identifying the presence of SPD in user’s posts under personal, professional, and health domains. The TSP framework is built based on the standards and privacy regulations established by social networking sites and organizations like NIST, DHS, GDPR. The proposed approach of TSP addresses the prevailing challenges in determining the presence of sensitive PII, user privacy within the bounds of confidentiality and trustworthiness. A novel layered classification approach with various state-of-art machine learning models is used by the TSP framework to classify tweets as sensitive and insensitive. The findings of TSP systems include 201 Sensitive Privacy Keywords using a boosting strategy, sensitivity scaling that measures the degree of sensitivity allied with a tweet. The experimental results revealed that personal tweets were highly related to mother and children, professional tweets with apology, and health tweets with concern over the father’s health condition.

Access provided by University of Auckland Library

Introduction
The online social networks (OSN) like Twitter, Facebook, Instagram, YouTube have grown tremendously with the user-generated content (UGC) like messages, photographs, and videos shared by a user for self-expression and self-actualization [39, 51]. Twitter is one of the widely used social media for sharing personal, professional, political information among various communities. The growing population in many developed and developing countries like the USA with 59.35 million, Japan with 45.75 million, the UK with 16.7 million, and India with 11.45 million active Twitter accounts in January 2020 show the wide range of audience and its extensive usability amongst the citizens [54]. Twitter has also become the central hub of real-time stories with breaking news. It is not a surprise that the public reports crimes and keeps the officials informed about them through OSN. The growing user population and usage of OSN have drastically increased over the years, which involves the risk of sharing information to a large community of audience. The audience for any post shared by an OSN user is not well defined and limited. The user cannot control the reach of the shared information which leads to several vulnerabilities without the awareness of the user. Therefore, every tweet and retweet reveal a certain degree of sensitive information which the user is ignorant about. Such information revealing activities are classified into primary and secondary information leaks. The primary information leaks refer to disclosing one’s private information, and the secondary information leaks refer to the act of exhibiting other’s private information [24, 30].

Context
Many embarrassing and adverse effects of personal and profession-oriented incidents get reported on social media. The recent action of Kotak Mahindra Bank Ltd., firing out its manager who posted a derogatory comment on a rape victim [55], is one such incident. The comment given by the ex-manager can be categorized under the direct attack and direct criticism kind of regrets [40]. According to research [56], by the age of two, 90% of the children seem to have their presence in social media. Similarly, a non-profit organization, Child Rescue Coalition, has identified 100 hashtags that could put a child at risk. In both the above-mentioned cases, the users are highly ignorant of the potential threats and criticality involved in sharing personal information or opinion of oneself and others in OSN. An in-depth analysis of this personal information will reveal sensitive data about an individual. The extensive growth of the Internet has increased the scope of information security and privacy laws in OSN thereby invoking the necessity to understand and learn the vulnerabilities of the shared information.

The National Institute of Standards and Technology (NIST) of the USA [29], the European Union’s (EU) General Data Protection Regulation (GDPR) [32], and the Department of Homeland Security (DHS) [58] have introduced the Personally Identifiable Information (PII) or Sensitive Personal Information (SPI) for differentiating individuals based on their identity. The data which require a higher level of protection are claimed in an additional section in GDPR called Sensitive Personal Data (SPD) that includes information related to biometric, genetic, and health. Technically, PII links an individual to a unique identity which will help any analyst or offender to map the individual with other identifiers like educational, financial, medical, and employment information. However, any statement or tweet without PII can also reveal sensitive information about an individual. The regulations framed by the EU state that ‘processing personal data are allowed only in special cases with legal obligations’. They also state that ‘if the SPD is not protected, it will create a significant risk in the individual’s right and freedom’ [57].

Terminologies
The most significant terminologies related to this research work are briefed below for better readability.

Cyber-keywords—The keywords that are most frequently used by social media users to communicate in the cyber-space/digital environment. These keywords are determined from the results of the Google search engine for research by [29] with the context of privacy, confidentiality, and universality. For instance, words like ‘home’, ‘family’, ‘investment’, ‘salary’, ‘drug use’, ‘blood group’ are derived as significant privacy query terms from Google search results. In context with the TSP system, users generally choose a wide range of words to express themselves in OSN. To reduce the outliers or irrelevant data during data collection, the keywords from [29] are used as query terms and termed as ‘cyber keywords’.

Sensitive Personal Data (SPD)—Any potential information that refers to an individual in real life or virtual environment with a sense of privacy leak, probable personal information leak, and data disclosure which are termed as Sensitive Personal Data by GDPR. This research work identifies and analyses the SPD in the collected data by applying various theories and computational models.

Sensitive Privacy Keywords (SPKs)—A set of keywords are extracted from the dataset by applying a computational method for SPD analysis. These keywords are the co-occurring and supportive keywords that are present in the user post and help users to reveal sensitive information or personally incriminating information about self and others.

Rules of Sensitivity and Contextuality (RSC)—Generally, all the data collected with cyber-keywords as query terms will not be sensitive/contain sensitive information. There are possibilities of having insensitive information/non-private information in data instances which must be identified before feeding it to a computational model. Thus, to train and test the collected data through various machine learning models, the dataset has to be labelled as ‘sensitive’ and ‘insensitive’. To understand the importance and user views on privacy and personal data preferences and induce it in the learning process, the RSC is brought into focus with diverse content and contextual parameters.

Problem statement
The self-disclosures of user’s personal, professional, and health-related information happen in any social media post. This leads to personal data leaks and privacy threats. Self-disclosures and privacy threat in a post can be assessed by a user when they are aware of the flow, focused attention, interaction, perceived control, privacy awareness, privacy concerns [47], privacy invasion experience, privacy risk [27], and tie strength that a post possesses [2, 28]. Yet there is no tool or standard approach to discover the presence of SPD in a user post and alert users on the potentiality or vulnerability of losing their private data.

Objective
The objective of the proposed Tweet-Scan-Post (TSP) system is to help users to protect their sensitive information while presenting opinions in OSN without revealing SPDs. This research work aims to identify whether a post is sensitive or not and the degree of sensitivity associated with a post in three domains using content and contextual features. The TSP system focuses on learning the user preferences for sensitivity from the existing data which would contribute to building an online tool that can alert users about the potential vulnerability before posting on social media.

TSP system
The TSP system is a framework that will generate computational models for predicting sensitive information present in personal (tweets that contain personal and family-related information), professional (tweets that contain occupational, financial status and business-oriented information), and health-related (tweets that contain disease-related information, psychological status) social media posts. The main contribution of the TSP system is that it considers both content and contextual features besides the private data protection standards recommended by international organizations. It experimented with state-of-the-art machine learning models, ensemble models, layered classification approach with a reinforced feature set to determine an optimal classifier for each tweet domain. The TSP system also delivers the scale of sensitivity (SoS) as a simplistic visual feature for the users to easily understand the sensitivity in a user post. The SoS is a numerical score on the degree of sensitivity associated with a tweet that is derived based on the combination of SPD values, SPK, and cyber-keywords. All the results and research observations extracted from the TSP system will be encompassed to build a tool that will let users evaluate their text content for sensitivity before posting it on social media.

Research contributions
The proposed research work focuses on answering the following research questions while building the TSP system.

RQ1: What is user post sensitivity? How are sensitive PII determined theoretically and practically?
The authors conceptually coined a definition for ‘user post sensitivity’ which will help in determining the presence of sensitive information in a user’s post. The theoretical implications of determining the sensitive PII were supported by the standards and regulations established by various organizations like NIST, EU-GDPR, DHS, privacy policies of various social networking sites. Besides, the authors also comprised observations from various theories like the Subjective Collective-Privacy (CP) theory [33], Uses and Gratification Theory (UGT) [39, 59], cognitive process flows, social perspectives [48], and Regret Theory [15]. According to this research work, we follow a sequential, two-factor approach to practically determine the sensitivity in a tweet. Initially, the sensitivity is determined by a knowledge expert who evaluates the post from the user’s context in three domains, namely personal, professional, and health perspectives. Next, the content in the user post is computationally evaluated by the presence of cyber-keyword and its corresponding SPD values. In-case of more than one cyber-keyword present in a tweet, a combinational significance for cyber-keywords is predicted for the sensitivity based on SPD values and SPKs. The authors claim the observations and computational models from this research to introduce a novel scale of sensitivity (SoS) that will practically help in automating the prediction of sensitivity in a tweet.

The authors define the sensitivity in a user’s post as ‘real-time experiences sought from the reflexive actions of the audience and self when presenting a PII to public and handling regrets psychologically, financially and physically. The sensitivity is directly related to the degree of privacy leaks, privacy regrets, privacy concerns and risk that the user decides for various PII and SPD and its corresponding personalized values disclosed’.

RQ2: How to discover the presence of potentially sensitive PII under personal, professional, and health categories in social media short texts without pattern matching?
The language structure of a social media post, context, and information shared by users varies drastically and is almost unique. Thus, it is not possible to extract sensitive data or identify the presence of sensitive information through simple pattern matching algorithms. The authors comprised the sensitivity parameters emphasized by various regulatory bodies, social and psychological theories that identify the potential sensitivity present in a message. The TSP system proposed Rules of Sensitivity and Contextuality (RSC), a novel rule set for determining the tweet sensitivity in three domains, namely personal, professional, and health tweet categories. The detailed ruleset is presented in Sect. 4.2 for each tweet category.

RQ3: What are the supporting keywords along with cyber-keywords that help in revealing sensitive PII?
The supporting keywords that co-occur while presenting SPD are identified by extracting an individual set of SPK for personal, professional, and health tweet categories. It is extracted by employing the LogitBoost classifier on the user post with sensitive information. Section 5.2 explains the process of extracting SPK, and Sect. 6.1 presents the 3 unique vocabulary sets of SPKs in each tweet category.

RQ4: Is it possible to apply keyword featurization in predicting tweets with sensitive PII?
The most important implication of the TSP system is to leverage the textual features to predict sensitivity without human intervention. Therefore, the authors decided to experiment with the SPK as a significant feature in disclosing SPD. The SPK under each tweet category was applied as a feature set in training the classifiers to predict the sensitive tweets. Section 5.3 briefly describes the application of SPK in tweet classification, and Sect. 6.2 evaluates the prediction of sensitive and insensitive tweets through various metrics.

RQ5: How to measure the sensitivity in self-disclosure through the PIIs and SPD revealed in social media short texts?
The sensitivity of self-disclosures is measured by a proposed metric called SoS. Section 6.3.1 prescribes the sensitivity scale that is traced based on prediction results with the significance of SPK, cyber-keywords, non-SPK, and non-SPK ∩ cyber-keywords.

Outline
Section 2 of this paper discusses various research works that were carried out related to social media data—text classification, and potential threats reported, self-disclosures assessed and predicted. The gap existing in SPI classification and its major challenges are discussed in Sect. 3. Section 4 elaborates about the dataset preparation, rules for defining sensitive and insensitive tweets by framing RSC and annotation process. The methodologies used for tweet pre-processing, sensitive keyword identification, and classification of tweets are presented in Sect. 5. The results obtained and inference of the research work carried out based on the proposed method are discussed in Sect. 6. Section 7 briefs the conclusion of the research work, limitations, and its future scope.

Related work
Social media data can be classified with a variety of features derived from geographical data, textual data, and other semantic features available in a post. The following sections will include an overview of the research work performed on social media text classification and privacy leaks in OSN. This will assist readers in comprehending how the OSN can formally lead to privacy leaks due to self-disclosures which result in regrets.

Trust and regrets in twitter
A privacy trust model with three independent and two dependent variables was proposed by [13]. A survey of users aged 18 to 30 years old was conducted by presenting a set of questions about Internet privacy concerns, trust, knowledge sharing [24], and building new connections in OSN. According to the observations derived from this model, users are more comfortable with creating online relationships without trust, which is the most desired aspect in face-to-face interactions. Various techniques like NLP, ontology, and machine learning algorithms are used to address different problems in detecting privacy-related knowledge from unstructured texts [37, 40]. The research identified problems in defining the user's perspective, domain specificity, context-dependency, privacy awareness, and data interdependencies in social media messages. The users who communicate through fictional audiences were asked questions like ‘Whom do you tweet to?’ and ‘Whom do you anticipate viewing your tweet?’ The audience evolved differently depending on the message, the time of the tweet, the subject, and the user's community. Social media users are anxious about the audience, such as parents and employers [31]. There were various sources of regrets admitted by users through interviews, user diaries, and online polls. It included posts about religion, sex, money, and personal problems that were shared while under the influence of drugs [6, 40]. Soft privacy has also been established in studies with organizations such as trusted third-party (TTP) agents, which users rely on to ensure their privacy and protect them from Internet privacy threats [35].

Self-disclosures and private data in social media
Many researchers and the layman accepted the risk in self-disclosures and its corresponding privacy losses [3, 42]. The Subjective Collective-Privacy theory states that an online social network with privacy-related behavioural environment is a ‘noisy society’ where the users constantly produce information flow through which certain potential people gain access to one’s information. Thus, even if the information is present online publicly, it is not always under threat unless it reaches potential individuals. In the meantime, the authors also stated that the posts in the newsfeed with easier access to private information led to privacy intrusion. Therefore, as per the definition stated in [33], the Subjective CP theory concludes that ‘self-disclosure is not equivalent with a privacy loss, because only a few intended people are assumed to read one’s posts, despite the (semi-)public nature of the information. Likewise, self-disclosure is subjective to privacy intrusion and security through obscurity where there is no actual control of personal information, but the raw data is transformed into knowledge, understood and internalized by an intelligent agent’.

The Subjective CP theory was also supported by the UGT of communication by emphasizing the usage of media for building interpersonal communication and focuses on the users and audience activities [59]. According to UGT defined in [39], ‘There is nothing as absolute truth. Human needs and gratification can be classified into affective (emotional) needs, cognitive (mental and intellectual) needs, social integrative (socialize) needs, personal integrative (self-esteem and respect) needs, and tension-free (relax and relieve stress) needs. Not every user is interested in all the data that are shared by another user. Not all users who share data are victims of social media. The users are creating connections in the society to retain their obtained gratification by extending their motives in awareness, sharing personal identity, integrity and recreating social mutual interactions’.

Many patients share their health records on social media through participatory health enabling technologies like patient portals, web-based platforms, mobile health (mHealth), media sharing platforms, crowdsourcing, and medical avatars by enabling the public to access their private information and increase the risk of de-identification and commercialization [19]. The diverse effects of collecting PII directly or indirectly can extend its impacts over a business, stalking a person, theft, and criminal activities.

Table 1 presents a list of supporting research work related to tweet content classification with their research datasets and Table 2 detailed information about the type of features and techniques used for tweet content classification.

Table 1 Related works on Twitter Data Classification
Full size table
Table 2 List of various techniques and features used for Twitter Data Classification
Full size table
Gap analysis
The proposed research work handled the following gaps and limitations in existing research works.

Gap 1
The research work carried out concerning privacy in social network messages is dealt with human intervention. The problem lies in contextually annotating messages manually either through third-party service providers like Amazon Mechanical Turk (AMT) or crowdsourcing. The proposed method used AMT for tweet annotation thereby complying with the requirement of dataset standardization and universal acceptability.

Gap 2
The existing system [29] manually identified only 53 cyber-keywords as critical keywords for analysing the presence of private information in tweets. Therefore, the mere presence of these keywords will not help in determining the sensitivity. The most frequently used keyword and contextually related keywords are required to determine the sensitivity of a tweet which are fulfilled by discovering the SPKs in each tweet domain.

Gap 3
The data collected for analysis posed a bigger challenge for prediction due to its imbalanced class distribution [23, 37, 53]. It is assumed that the sensitive information disclosed was significantly lower than the insensitive information shared by users. Instead of concentrating on the overall accuracy of the classifier, it is necessary to discover which classifier will correctly identify a higher percentage of true positiveness.

Gap 4
The online social media users are unaware of the criticality in presenting PII-related data to the public. The TSP system provides a SoS, which could be used as a lookup by naïve users when posting a message on social media to avoid the red-alert state.

Gap 5
The wide reachability of messages to an unlimited and unintended audience [27] is the greatest difficulty for preserving user’s sensitive information in the bounds of trustworthiness [8] and confidentiality. This gap is addressed by building a publicly available online tool based on the research findings of the TSP system.

Dataset preparation
As discussed earlier, the TSP system is focused on analysing sensitive information disclosure. There are 200,200,000,000 tweets posted per year. According to a statistical report produced by Gemalto, the global breach database identified 2,200,000,000 data breaches due to identity theft in various social media [60]. The overall probability of data breaches due to self-disclosure of PII in twitter is expected to be minimal. Yet, the effects of self-disclosures in a user’s life will be severe when faced with financial, psychological, and physical aspects. The TSP system aimed to work on context-specific data and thus used real-time tweets from Twitter for analysing sensitive self-disclosures. So, the authors prepared a new dataset that was based on context-specific query terms (here, the cyber-keywords) for a particular time and prepared it for training and testing the classifiers. The overall process involved in collecting and labelling tweets is presented in Fig. 1.

Fig. 1
figure 1
The dataset preparation process for TSP system

Full size image
The process of collecting real-time tweets is discussed in Sect. 4.1. The rules on which the tweets are labelled as sensitive and insensitive tweets for applying models are explained in Sect. 4.2.1. Section 4.2.2 presents the tweet annotation process in which the collected tweets were labelled through crowdsourcing services to achieve a diverse dataset.

Tweet collection
The real-time Twitter data were extracted using the Twitter Streaming API with a wide range of retrieval options. The Twitter Streaming API offers various extraction options for tweets in which hashtags, date, timeframe, username, words, location can be a query term. The TSP system used a set of 53 domain-specific cyber-keywords listed by [29] based on user activities in the Google search engine and their privacy levels. Additionally, the tweet collection had a timeframe parameter in which the authors considered tweets that were posted from 1 October 2017 to 30 November 2017. Table 3 presents the 53 domain-specific cyber-keywords in three tweet domains, namely personal, professional, and health.

Table 3 The list of 53 cyber-keywords in each domain and 21 cyber-keywords (in bold) present in tweets after applying constraints for selecting tweets for sensitivity analysis
Full size table
The 53 cyber-keywords were categorized into personal, professional, and health because many studies and surveys reflected the fact of user-facing privacy issues, mental instability or depression, social embarrassments because of revealing private information. In addition to this, organizations like NIST and GDPR also state that sensitive information disclosures happen in the form of personal life, professional life, and the health of a user. Thus, the authors ensure that using those bench-marked 53 cyber-keywords will reduce ambiguity and build relevant datasets in personal, professional, and health tweet domains, which are prone to highly private information disclosure.

Finally, 800,841 tweets were collected based on the above-mentioned constraints. The collected tweets were filtered by adhering to a set of 8 constraints to derive a valuable set of tweets. Figure 2 explains the depreciation in tweet counts when applying the 8 constraints over the extracted tweets. It was found that only 21 cyber-keywords (marked ‘bold’ in Table 3) were contributing 2414 valuable tweets with the private information of users that are suitable for sensitivity analysis. The TSP system performs all modelling and analysis with this static data and will accumulate more dynamic data once it is hosted as an online tool in the future.

Fig. 2
figure 2
The dataset preparation process for the TSP system by applying various constraints for sensitive tweet prediction

Full size image
Labelling data for sensitivity analysis
The collected tweets should be labelled to further apply them over a machine learning model and data analysis. The main objective of the TSP system is to identify the presence of sensitive data through the Sensitive Tweet Classification process which requires training and testing the data through state-of-the--art machine learning algorithms. According to the requirement of the TSP system, the tweets must be labelled as either sensitive or insensitive. To perform the task of labelling, the annotators must be selected and given well-defined rules referring to the scenarios to determine whether a tweet is sensitive or insensitive. Section 4.2.1 presents the novel RSC prepared for the annotators to apply it on tweets and decide on the sensitivity. Section 4.2.2 briefs the process of presenting the dataset to the crowdsourcing platform and selection annotators, evaluating the labelled dataset for the TSP system.

Rules of sensitivity and contextuality (RSC)
The RSC were derived from the user’s self-disclosure behaviour and its impact on their life, subjective to the SPD disclosed. To understand and decide on what to mark sensitive and insensitive, the authors preferred the subjective CP theory of self-disclosure in trust and privacy [33]. It follows the cognitive process flow through which an individual responds to a particular event or act by understanding, applying, and evaluating a particular task or event with the obtained knowledge or previous experiences. Since the choices and preference on factors like sensitivity, privacy, and self-disclosure vary with user and audience, the RSC will be a baseline that defines boundaries for sensitive and insensitive content. The data collected by the TSP system are not user-specific and thereby contain a wide range of users differing in age, location, gender, and profession. The user behaviour monitoring and follow-ups on their life events and decisions after posting self-incriminating information are not practically feasible. Therefore, the annotators were advised to follow RSC, their cognitive process flows, and Subjective CP theory thereby placing their personal experience, Internet exposure, and knowledge, perception, or idea over a particular SPD disclosure.

RSC for personal Information
Cyber-keywords—children, spouse, house, home, marriage, family, nation, car, chat, hobby, location, mobile phone, my photo, phone book, religion, shopping, travel, call record, race, identification, and party.

Sensitive personal content

Pronoun with user mention, interrogative context

Pronoun with time/date/place

Criticism with unpleasant opinion towards a person/community/political party/leader/religious beliefs/personalized URLs

Insensitive personal content

Pronoun with greeting

Pronoun with product reviews

Pronoun with entertainment-related information

Pronoun with national or world level crisis

Pronoun with URLs

RSC for professional information
Cyber-keywords—bank account, phone number, password, job, email, salary, fingerprint, online records, stock, insurance, criminal records, position, credit card records, company address, IP, passport, booking hotel, affiliation, investment, chat, address book, credit score, MSN, property, driver license.

Sensitive professional content

Pronoun with a user mention

Pronoun with unpleasant work experience, client/customer information

Criticism with unpleasant opinion towards manager, organization, clients, society, women, and children

Violation of resource sharing norms

Insensitive professional content

Pronoun with organization’s news, business ideas, wishes, team activities.

Employment news

Training and certifications

Social media profiles

RSC for health information
Cyber-keywords—disease, drug, age, height, weight, birth, blood group.

Sensitive health content

Pronouns with user mentions, clinical experiences, and effects of diseases.

Criticism with an unpleasant opinion about a hospital, doctor, or diseased person

False vulnerability of a disease

Depression, stress, and pessimistic mindset revealing content.

Insensitive health content

Pronouns with childbirth-related content, positive check-up reviews, health habits.

Refer a physician.

User mentions or pronouns with health care challenges.

Regional health issues

Tweet annotation
The most critical phase of the TSP system is labelling the dataset. It requires plenty of time and expertise in identifying tweets as sensitive or insensitive. The training and testing results are dependent on this manual annotation of tweets as sensitive or insensitive. The manual tweet annotation process was done by Amazon Mechanical Turk (AMT), a third-party service provider that provides a crowdsourcing platform [34] allowing a set of workers to undertake the human intelligent tasks posted by a requestor with a specific requirement. The authors defined the requirements clearly which depicted the goal of identifying SPD in the tweet with a dedicated RSC under each tweet category.

The workers were also instructed to be aware of the context and content present in the tweet and consider it as one of the factors in marking the tweet as sensitive or insensitive. For instance, any information about a famous person or celebrity or an event might not be sensitive unless it reflects any disrespectful comment or opinion that might lead to regrets or social imbalance. The tweets with pronouns like I, me, my, he, his, she, her, we, will directly denote the presence of self-descriptive data either about the Twitter user or real-time entity associated with the Twitter user. Therefore, during the annotation process, the tweets with pronouns and cyber-keywords might be annotated as sensitive tweets. Similarly, any tweet without an SPD value relatable to any cyber-keyword, but with a pronoun, will not be treated as a sensitive tweet. Therefore, the annotation process purely depends on the AMT worker’s ability in understanding the social perspective [48] and applying cognitive process flows.

The following information bulletin in addition to the RSC was submitted to the AMT workers to provide basic insights on PII and cyber-keywords:

‘Task Description—We have a list of tweets extracted from Twitter. The workers are expected to classify the tweets as sensitive or insensitive tweets based on the presence of personal data in the tweet. (Personal data—unique identity of a person, community, organization).

The Personally Identifiable Information (PII) or Sensitive Personal Information (SPI) can be any unique identifier that can help differentiate individuals. Some of the PII are full name, location data, face, fingerprint, handwriting, an online identifier, an identifier that expresses an individual’s physical, physiological, mental, cultural, genetic, commercial, or social identity such as email address, social security number, home address, passport number, vehicle registration number, telephone number, digital identity, driver’s license number, date of birth, birthplace. Subjective information like judgments, opinions, religious or ideological impressions, and professional data like IP addresses, membership in a union was also declared to be personal data.

We have defined the following list of cyber-keywords as a contributing factor in revealing the above-mentioned SPI—address book, affiliation, age, bank account, birth, blood type, booking hotel, call record, car, chat, children, company address, credit card, credit score, criminal record, disease, driver license, drug use, email address, family, fingerprint, height, hobby, home, house, identification, insurance, investment, marriage, mobile phone, MSN, my photo, accident, allergy, ambulance, death, diagnosis, hospital, immunity, infection, medical, nursing, mental, surgery, therapy, treatment, vaccine, nation, online record, party, passport, password, phone book, phone number, position, property, race, religion, salary, shopping, spouse, stock, travel, weight’.

To maintain balance in selecting the better worker for the task of annotation from AMT, the authors also looked for certain criteria like the worker should use social media or the Internet for a minimum of 1 h; should be aware of the Internet jargons; should be fluent in the English language; and should be an expert level worker in AMT. The authors approved results from 153 AMT workers on annotating the TSP dataset based on turnaround time, annotated tweet count, and comments. The labelling resulted in 75% of insensitive tweets and 25% of sensitive tweets in the TSP dataset. This labelled data will be further considered for training and testing the state-of-the-art models in identifying sensitive information. Tables 14 and 15 list a set of sample tweet instances that are marked as sensitive and insensitive by AMT workers.

Method
The labelled dataset of the TSP system will experiment on the state-of-the-art models under three categories, namely personal, professional, and health domains. A set of pre-processing rules were defined and applied to make it suitable for text classification. This will help in extracting valuable features for training the classifiers to learn the properties of sensitive data in social media posts. The state-of-the-art algorithms, namely SVM, NB, and GBM, are applied to the pre-processed tweets for sensitivity detection.

During the process of tweet classification, tweets with SPD are identified as sensitive tweets, whereas others are classified as insensitive tweets. The insensitive tweets were further considered for layered classification by introducing SPKs as an additional checker for determining the sensitivity. The results of layered classification revealed that there were substantially more sensitive tweets than had been found during the manual tweet classification phase. The overall architecture of the TSP system as a framework for tweet classification is presented in Fig. 3.

Fig. 3
figure 3
Architecture of the proposed TSP system for tweet classification and SPK identification

Full size image
LogitBoost method was adopted for defining SPKs which plays a vital role in detecting sensitive tweets. The ensemble approach has opted for sensitive data identification so that the performance of the classifiers is improved by combining multiple weak learners [26]. The LogitBoost is a boosting algorithm that follows the AdaBoost framework and logistic regression has been selected for identifying the sensitive privacy keywords from the bag-of-words model based on a threshold set on the probability values [38]. The GBM yields a prediction model that works like a decision tree by iteratively combining the results of weak learners. Both tweet classification and SPK identification were evaluated with the boosting strategy as it reduces the inaccuracies. It focuses on defining the decision edge by reweighting instances of training and testing datasets. The TSP system identified the NB classifier as the optimal classifier as it outperformed for sensitive tweet classification.

The three steps involved in the classification of the tweets are tweet pre-processing, SPK identification, and tweet classification using the above-mentioned algorithms and are described in the following sections.

Tweet pre-processing
The text messages posted by users in OSN cannot be directly used to derive features for a machine learning model due to the presence of noisy and unstructured contents like slang, abbreviations, hashtags, user mentions, non-English characters, and emoticons. As an initial step of pre-processing the tweets, it was recommended that the standards of formal text content with proper context, English grammar, and spelling are checked [6, 22]. The authors formulated a ruleset with 11 conditional formattings and applied it over the tweets to have a better measure for classification. The pre-processed tweets are then obtained by applying the ruleset mentioned in Algorithm 1 and are stored in the tweet repository which was analysed for generating sensitive keywords.

figure d
The tweets are pipelined for tokenization to extract the individual linguistic features, generally words and special components like emoticons, numerical values, URLs, etc. The process of tokenization allows filtering the important linguistic features of a tweet by removing special characters used for punctuations, unwanted spaces, and new line characters, stop-words, non-English words. Certain prominent textual data with SPIs will be replaced with a common word to reduce the sparseness in textual features [23]. For instance, if the user has mentioned a particular date in a tweet, it will be replaced with ‘at_date’. Similarly, if there is a phone number disclosed in a tweet, it will be replaced by ‘at_tele’. Other complications in cleaning tweets lie in handling the user mentions, hashtags, and typographical errors which are done with regular expressions, TwitterNER, and word embeddings and segmentation [14].

Sensitive privacy keywords identification
The most important research question of TSP is RQ3 which deals with identifying supportive keywords that reveal sensitive PII. This is achieved by identifying SPKs for each tweet category in TSP. The pre-processed tweets are retrieved from the tweet repository based on the tweet category. A term-document matrix is generated from the pre-processed tweet which will give a collection of unique bag of words (BoW) for the tweets in each category. The BoW model is a very naive approach to represent the textual content irrespective of the order in which they occur. The frequency of each word that appears is counted and will be used as a feature to train the classifiers and can also relate the keyword’s significance in each tweet category with a certain degree of relevance. Equation 1 represents the collection of bag of words used in TSP for short texts.

fBOW(Tweetc[n])=Keywordsc[m]
(1)
where C defines the tweet categories as personal, professional, and health.

fBOW defines the bag-of-words generation function for a tweet category. n denotes the number of tweets in each tweet category. m denotes the number of identified keywords in each tweet category.

For instance, the two tweets, {‘I can’t believe this family picture is missing me’, ‘Mom come pick me up, I went camping with my family and now my friends are bullying me’} can be represented in the BoW model as {‘and’, ‘are’, ‘believe’, ‘bullying’, ‘camping’, ‘cant’, ‘come’, ‘family’, ‘friends’, ‘I’, ‘is’, ‘me’, ‘missing’, ‘Mom’, ‘my’, ‘now’, ‘pick’, ‘picture’, ‘this’, ‘up’, ‘went’, ‘with’}. From this form of representation, a tweet will be transformed into a collection of words or a vocabulary set containing all unique words in it. To handle the sparsity and less significant words by occurrence and relevance, few rules were already introduced in the pre-processing phase to generate a desirable feature set for the classifiers.

The TSP system emphasizes the usage of the LogitBoost classifier for extracting SPKs because it works based on the regression function for prediction. The significance of the keywords was computed by adopting the ensemble method LogitBoost, which is a combination of the machine learning algorithm and computational learning. This algorithm is a statistical framework adapting AdaBoost methodology and the cost function of logistic regression to derive the classification results. The probability values resulting from the classification for tweets denote the likelihood of the corresponding tweet in a specific category. The probability values are determined using AdaBoost by computing the weighted average. The LogitBoost classifier initially computes normalized class sampling probability and then tries to normalize the imbalanced class during classification [21]. This property of the LogitBoost classifier will help in reducing the error rate in predicting minority class, say here, predicting sensitive tweets.

Initially, the probability for each tweet in each tweet domain is set to pi. The weight wi,k for each word in the tweet domain was estimated using the bag-of-words model for a short text generated from Eq. 2 as shown below.

BoW,\;wi,k=pi,k(1−pi,k)\;
(2)
where wi,k denotes the weight for tweet i in the BoW list. i ranges from 1 to N denoting the tweet in the tweet domain list. k ranges from 1 to K referring to the classes.

The sensitivity regression function for calculating probability estimates for each tweet i is given by Eq. 3. The regression function is led by weight quantile γ = 0.1 which acts as a threshold trimmer for class associated with the tweet i. This regression function has significance on the social media short texts because it derived features from the bag-of-words model generated from tweets.

Fi,k=\;Fi,k+\;γk−1k\;(fi,k−\;1K\;∑K−1k=0fi.k)
(3)
The probability estimators calculated by the linear regression with the least-square estimator are applied for computing the boosting function Fi,k as shown in Eq. 3.

pi,k=exp(Fi,k)∑K−1k=0exp(Fi,k)
(4)
The boosting function for each tweet in the list was considered recursively for refining the probability or likelihood value of a tweet pi,k in the overall tweets as given in Eq. 4. Thus, the obtained probability values for tweet features in each tweet category will assist in setting a threshold value based on which a set of keywords was defined to be sensitive. The vocabulary set for SPKs was identified by considering the tweet features that had their probability values exceeding the threshold value. The identified SPKs are the supporting keywords required for the analysis of sensitive self-disclosures focused on RQ3.

Tweet classification
The sensitive tweet classification in TSP System is performed at three stages as shown in Fig. 4. The first level of tweet classification is performed manually in the tweet annotation stage based on the user context of revealing private information, the presence of SPD, and annotator’s domain knowledge by applying RSC on the raw tweets. The previous works related to privacy information detection used supervised machine learning algorithms and textual features using the BoW model, TF-IDF, and POS tagging mechanisms [16]. The TSP system adapts the classifier based on the discussion placed in Sect. 2. The authors were keen on choosing the classifier depending on the results influenced by the bag-of-words model for short texts and the performance rate of the supervised (SVM, NB) and semi-supervised (GBM) classifiers. The second level is the application of state-of-the-art classifiers over the labelled tweets. The proposed system considers SVM, NB, and GBM classifiers for sensitive tweet classification.

Fig. 4
figure 4
The three levels of sensitive tweet classification in the TSP system

Full size image
Finally, the third stage of tweet classification involves the process of re-evaluating the insensitive tweets predicted during the second level with the optimal classifier in combination with SPKs for its sensitivity. Since the TSP system identified NB as the best performing classifier in level 2, it was further used in the third level of classification.

The TSP system focuses on identifying the SPKs to intensively classify the sensitive tweets. The layered classification is performed recursively with the insensitive tweets by manually reclassifying with the context and identified SPKs. This will be the reinforcement factor of the TSP system to accurately predict the sensitive tweets and overcome the challenges of the underfitting effect. The TSP system showed a remarkable increase in the identification of sensitive tweets when SPKs are considered for classification. This proved that the proposed system efficiently identified many vulnerable tweets. The authors clearly state that the aim of using classifiers in the TSP system is not to identify the tweet category such as personal, professional, or health-related tweets but to identify the presence of sensitive information in the tweet.

Some of the tweets posted by users will have the combination of two or more keywords with cross-categories which are even more sensitive to disclose in public. This research also explored such keywords and termed them as ‘inter-domain fuzzy keywords’. The classification results of all three categories of tweets are discussed in the following section of this paper. The layered classification results have many observations for analysing the sensitivity of a tweet. A scale of sensitivity is determined by combining the analytical values obtained for several SPKs, non-SPKs but cyber-keywords and non-SPKs.

Results and discussion
The existing privacy detection mechanisms are designed out for a particular event, location, or user community, whereas the TSP system is user-independent and context-specific. This clarifies the inappropriateness in comparing the TSP system with other existing research works due to varying datasets. The proposed TSP system’s sensitivity detection mechanism could not be compared with [31, 50] because they could only deal with the art of detection of privacy revealing tweets. The TSP investigates both sensitivity and privacy revealing information in a message. Another rationality of TSP is its independence from user profile data and social network structures as described in [4] because TSP is purely based on textual content the user posts on SNS. Many research works require human intervention in deciding the sensitivity of the message, with a team of knowledgeable judges in privacy theories [17, 46] or users of the post or Google’s search engine data [29]. The TSP system concentrates on domain-specific data extracted based on well-established cyber-keywords by Privacy Information Security Classification (PISC) model [29] to eliminate randomness and irrelevant content for analysis. Most of the existing privacy analysis research works concentrate on an individual user’s experience and preferences for determining the privacy context. The TSP computes privacy in terms of sensitivity by applying the cognitive process flows and computational models that are independent of the individual users.

Sensitive privacy keywords (SPK) of the TSP data
The LogitBoost method was applied to the BoW generated from the pre-processed tweets. The authors extracted certain keywords from the sensitive tweets identified by the LogitBoost model as critical or privacy revealing words called SPK by their significance through the observed probability values. For the personal tweets, the BoW generated was 3440, whereas the professional and health tweets produced 1495 and 1529 words, respectively. Figure 4 summarizes the classification results of the LogitBoost model for three categories of tweets from which the SPKs were extracted. It shows that an average of 26% of the tweets is sensitive (see Fig. 5) and 3% of the bag-of-words were extracted to form the SPK vocabulary set (see Fig. 6).

Fig. 5
figure 5
Classification results of LogitBoost algorithm for three categories of tweets, namely personal tweets, professional tweets, and health-related tweets

Full size image
Fig. 6
figure 6
Overall percentage of bag of words obtained for three categories of tweets and their corresponding SPKs

Full size image
The sensitivity of the tweets in TSP is calculated based on SPKs generated probability value obtained for each tweet during the classification by LogitBoost algorithm as described in Eq. (4). The tweet having a probability estimate greater than 0.50 is sensitive and that with a lower value is insensitive. The threshold is set to 0.50 because the probability values represent the possibility of maximizing correct prediction and minimizing errors.

The probability values achieved after applying LogitBoost classifier were found to vary with 0.11, 0.5, 0.88, 0.98, 0.99, and 1.0. Thus, for setting up a threshold value for extracting sensitive keywords, the notable difference in the probability value 0.5 is selected. While selecting tweets for identifying SPKs, those tweets which were classified to be sensitive by the LogitBoost classifier are considered to achieve a minimum error and maximum likelihood [38].

The sensitive tweets identified by the LogitBoost approach and the keywords with probability value higher than the threshold from the bag of words were compared. If a word is present in the sensitive tweet and has a probability value higher than the threshold, it is labelled as an SPK. The TSP followed this approach for all three categories of tweets, and a vocabulary set consisting of 201 keywords was built thereby answering the research question RQ3. Some tweets were identified to be sensitive without the presence of SPKs. In such cases, the cyber-keyword that was used during the tweet streaming process for that tweet is considered as sensitive information and added to the SPK list.

Table 4 displays the identified SPKs for each category with the coinciding 23 cyber-keywords depicted in bold italics, and the ‘inter-domain fuzzy keywords’ are highlighted in bold font style. As mentioned earlier, 21 cyber-keywords were used for extracting tweets. Apart from the 21 cyber-keywords taken for analysis which is highlighted in Table 4, the SPK vocabulary set built by TSP bench-marked two cyber-keywords, namely salary and company. For the personal tweets category, there were about 3440 bag of words generated from the tweet and the sensitive words were 70. Similarly, for the professional tweet category, there were 61 sensitive keywords among the 1595 words generated by the bag-of-words model. The health tweets were found to have 70 sensitive keywords from a set of 1529 words from the bag-of-words model.

Table 4 Sensitive privacy keywords identified by LogitBoost algorithm for tweet categories
Full size table
On analysing the sensitive keywords in Table 4, it was found that TSP identified certain keywords that are common for more than one category. Such keywords were identified to be inter-domain fuzzy privacy words (see Table 2). For instance, the keyword ‘contact’ is present in both the professional and health category; ‘child’, ‘family’, and ‘save’ keywords are present in both the personal and health category. On further analysing the obtained SPK, it was found that child, marriage, spouse, family, house, address, phone, number, job, bank, account, password, email, address, age, fingerprint, blood type, home, birth, nation, weight, salary, and company were in common with the 53 cyber-keywords [29]. This implies the proposed method of identifying SPKs in TSP is efficient as it coincides with the bench-marked cyber-keywords which could be further used for automatic tweet analysis.

Ensemble classifier vs. other classifiers performance for TSP data
The manual classification of tweets for the dataset preparation for TSP resulted in a well-versed set of sensitive and insensitive tweets. There were about 313 sensitive and 1129 insensitive tweets for the personal tweet category, 159 sensitive tweets and 339 insensitive tweets in the professional category, and 135 sensitive tweets, and 341 insensitive tweets in the health category.

Sensitivity classification
The optimal feature selection in the TSP system is achieved when the sparse feature set of a social media text is reduced by building the feature set using a BoW model. The most popular feature selection technique used for text classification is the frequency approach of BoW [25]. The important features are extracted, depending on the occurrence of a keyword in the tweet domain. The less occurring feature is ignored, which leads to the selection of only significant features for sensitivity prediction. This resulted in a great reduction in the feature vector dimensions for tweets as shown in Table 5. The reduced feature set is considered for predicting the sensitivity of a tweet.

Table 5 The feature reduction for optimal classification results of the tweets
Full size table
The results of classifiers showed a varied proportion of sensitive and insensitive tweets when compared to that of the actual classification (AC). The actual classification identified 21% of personal tweets, 31% of professional tweets, and 28% of health tweets as sensitive. The predicted classification (PC) results for various classifiers are briefed as follows. The SVM classifier identified 16% of personal tweets, 30% of professional tweets, and 15% of health tweets as sensitive, which is very low when compared to the AC. The NB classifier predicted 24% of personal tweets, 33% of professional tweets, and 29% of health tweets as sensitive. The GBM classifier found only 14% of personal tweets, 11% of professional tweets, and 11% of health tweets to be sensitive. From the classification results, the NB classifier predicted more sensitive tweets when compared to the other classifiers. According to the classification results in Fig. 7, a greater number of sensitive tweets are from the professional domain, which shows that people in social media are vulnerable to lose their professional information that is necessary to be confidential.

Fig. 7
figure 7
Classification results of machine learning algorithms like SVM, NB, and GBM for personal tweets, professional tweets, and health tweets

Full size image
The GBM classifier worked out well with personal and health-related tweets, showing better performance when compared to professional tweet domains. The class distribution for each tweet was performed with three interaction depths and trees with 50, 100, and 150 nodes as term vectors, where the weights for each tweet were set by the classifier. The weights that were set for the tweet given below are 0.05 for the professional tweet and 0.5 for the health tweet. These weights vary depending upon the class distribution for each tweet and tweet category. The GBM classifier failed against NB for professional and health categories because of the underfitting effect with a smaller number of data instances, whereas it performed appreciably well with that of the personal tweets. This misclassification in boosting method using decision trees was due to the complexity in handling sparse data as shown in Table 6. Table 7 describes an overview of tweet classification including the pre-processing stage, identification of SPKs in the tweets, and corresponding cyber-keyword. The classifier results are presented to show how the actual classification (AC) resulted for tweet sensitivity and the predicted class (PC) results varied. In the classification results, I denote the insensitive and S denotes the sensitive class.

Table 6 Tweet category and sample tweet instances that were misclassified by ensemble classifier—GBM algorithm
Full size table
Table 7 Sample tweets that were misclassified by the machine learning algorithms for three categories of tweets
Full size table
Evaluation metrics
Precision denotes the fraction of correctly classified sensitive tweets among all samples of tweets identified as sensitive. A greater value of precision implies a smaller number of misclassified test samples. The recall is the fraction of correctly classified sensitive tweets among all the actual sensitive tweets. The greater the value of recall, the higher would be the percentage of actual sensitive tweets in the classified sensitive tweets. The ROC curve is plotted for values of true positive rate and false positive rate obtained by a classifier. The imbalanced classes in the dataset are a challenging factor that makes the identification of sensitive tweets to be critical. The cross-validation method was adopted for estimating the generalized performance of the classifiers. The dataset was recursively split into test and train sets, and the classifier’s accuracy is recorded in Table 8.

Table 8 Summary of test instances covered and results obtained in classification of tweets to identify sensitivity using various classifiers
Full size table
The performance of the classifiers is evaluated with other significant measures like precision, recall, and ROC curve because the accuracy metric is not suitable in the prediction of the performance of a classifier in an imbalanced class. The state-of-the-art classifiers were applied for various train–test splits ranging from 95–5 to 50–50, and the performance was recorded. As mentioned earlier, the optimal classification results were achievable when the train–test split was 80–20 of the tweet datasets. The precision–recall was plotted to observe the retrieval rate of sensitive tweets by the classifier as shown in Fig. 8.

Fig. 8
figure 8
Classification results of SVM, NB, and GBM classifiers for various tweet domains

Full size image
The personal tweets classified by the NB classifier achieved better recall value. The performance of the NB classifier was better than SVM and GBM when evaluated with the ROC metric as shown in Fig. 9. The NB classifier predicted the sensitive tweets correctly in the professional category. The curve extends to the top left corner of the vector space denoting the optimal characteristics. The area under the ROC curve was 0.74, comparatively higher than all other classifiers. The performance of the SVM classifier was better than NB and GBM, but it failed in identifying sensitive tweets. The confusion matrix result analysis surprisingly discovered that there was no true negative (insensitive tweets identified to be insensitive) instances identified by the classifier.

Fig. 9
figure 9
ROC curve obtained for state-of-the-art algorithms for personal, professional, and health tweets

Full size image
Though the area under the ROC curve and the precision–recall curve for SVM were better than the other two classifiers, the authors had to ignore the SVM classifier and consider only the NB and GBM for further analysis. The SVM classifier identified sensitive tweets to be sensitive (true positive) and insensitive (false negative). Therefore, considering the SVM classifier will lead to a poor system, marking all insensitive tweets to be sensitive. The GBM classifier predicted a greater number of insensitive tweets (true negatives) than the NB classifier. The selection of the best classifier for layered prediction is determined by the precision and recall values. The NB had higher average precision and recall values than GBM (see Table 8). Thus, the authors selected the NB classifier for the layered classification approach.

Layered classification with SPKs of TSP
From the experimental results observed from the classification proposed by TSP, it is evident that the NB algorithm performs better for tweet classification. Therefore, the tweets that are predicted to be insensitive by the NB classifier are taken and analysed for the presence of SPKs. Any insensitive tweet that is discovered to have one or more SPKs with some personal information is marked sensitive. This imposes the application of the keyword factorization approach in predicting sensitive PII which answers the research question RQ4. The results of classifying tweets that were annotated based on the SPKs using NB classifier are presented in Table 9.

Table 9 The layered classification results for the insensitive tweets extracted by the NB classifier
Full size table
The layered classification proposed by the TSP system resulted in a wide variety of analytical observative. By following this layered classification approach, a significant increase and decrease of sensitive and insensitive tweets, respectively, can be noted as depicted in Fig. 10 for all personal, professional, and health tweet categories, respectively.

Fig. 10
figure 10
The variation observed in the number of sensitive tweets and insensitive tweets during the layered classification with SPKs and the manual annotation performed for personal tweets

Full size image
Table 10 presents the statistical data on the variation of sensitive tweets predicted before and after considering SPKs. It is well proven that the SPKs are almost present in 34% of the personal tweets, 76% of professional tweets, and 67% of the health tweets. This shows the fact that people are more concerned about sharing their professional status among their friends and online communities. The next level of analysis was done for finding out the maximum number of SPKs that a tweet was composed with. The personal tweets were detected to have a maximum of 6 SPKs in a tweet, whereas the professional category had a maximum of 7 SPKs and the health category had a maximum of 8 SPKs in a tweet.

Table 10 Statistical depiction of the initial and layered classification results achieved after considering the presence of SPKs
Full size table
On analysing the prediction results of layered classification, it is anticipated that many insensitive tweets were found to be sensitive by the classifier. A sample set of insensitive tweets that were discovered to be sensitive by performing layered classification is presented in Table 11 for all three tweet categories. The recursive classification is performed only once after identifying SPKs because the possibility of predicting the tweet sensitivity is maximal when the contextual annotation rules are applied during the initial stage. The sensitive tweets that were missed during the initial classification, i.e. the insensitive tweets of the classifier, are reviewed during the layered classification process. Thus, the concept of the one-time imposition of contextual rules and layered classification with SPKs will evolve an appreciable degree of accuracy in predicting the sensitive tweets.

Table 11 Insensitive tweets from NB classifier considered for layered classification predicted as sensitive
Full size table
Logically, the NB classifier is expected to yield better results after layered classification with SPKs. The personal tweets accounted for higher than professional and health tweets. This was the key factor for achieving appreciable results in layered classification. The performance of the classifier had the impact of the underfitting effect which occurred when the number of training instances got declined during the extraction of the insensitive tweets from the manually classified tweets. Therefore, it is evident that the TSP system will perform well for professional and health categories if the number of tweets is increased. This also helps in building the most appropriate SPK vocabulary for each tweet category. The number of sensitive tweets identified in layered classification in professional was higher than that of the personal and health category. On that account, it can be concluded that in both state-of-the-art classification and layered classification, the number of sensitive tweets is predicted in a professional tweet category. The number of layered classifications applied in the TSP system was determined by considering the saturation point where the model shows zero deviation in prediction of the sensitive and insensitive tweets.

Scale of sensitivity
The layered classification result infers a very novel insight of predicting a tweet’s sensitivity based on the number of SPKs and the cyber-keyword occurrences. Table 12 defines the various terms that were used to determine the degree of sensitivity associated with a tweet based on the observations of the layered classification. Table 13 shows the observed pattern of the number of SPK and non-SPK cyber-keyword and non-SPK that could be present in a sensitive and insensitive tweet. The results presented here are specific for the tweets that are collected under three categories for a specific timeframe. The observation concludes that to enhance the tweet classification, it is mandatory to have a large tweet repository with SPKs. The TSP system anticipated that the presence of SPKs is the key factor in disclosing sensitive information highlighting the rationality of dependency between self-disclosures with keywords.

Table 12 The notations used for determining the scale of sensitivity of a tweet
Full size table
Table 13 Scale of sensitivity extracted based on the presence of SPKs, cyber-keywords, and non-cyber-keywords in a tweet
Full size table
The statistical data for recognizing the scale of sensitivity for a tweet in the dataset considered by TSP are presented in Tables 13, 14, 15. The occurrence of SPKs in each tweet is marked after annotating tweets with SPKs for sensitivity. The scale of sensitivity in TSP is determined for all three tweet categories. This scale of sensitivity is defined based on the dataset taken for analysis because as the tweet repository is updated with more recent tweets, the SPKs and the non-SPKs are expected to vary. The scale of sensitivity will help the users in identifying the sensitive tweet before posting it online by being aware of SPKs and PII.

Table 14 Sample sensitive tweets annotated based on the contextual rules for Sensitivity
Full size table
Table 15 Sample insensitive tweets annotated based on the contextual rules for insensitivity
Full size table
The research question RQ5 is addressed here by measuring the sensitivity based on the observed scaling factors. The authors come up with an automatic sensitivity identification model that helps in the task of automatically identifying sensitive content in a user’s post. The TSP system discussed in this research work is the base work for building the automatic sensitivity identification model through which the user’s posts are trained and tested recursively to make it suitable for addressing a wide range of privacy leaks and issues. The authors are working on the prototype of the TSP system which will be publicly available as a tool for identifying user tweets with SPI to make sure the users are ensured with their safety online. A sample GUI planned for the TSP system is shown in Fig. 11.

Fig. 11
figure 11
The template of proposed TSP as a tool for analysing the sensitivity of a tweet

Full size image
The TSP system has a tweet alert indicator that will assist users in determining the sensitivity of the information shared in the post. The tweet composed by the user is taken for analysis to identify the cyber-keywords present in it and the related historical data for that cyber-keyword is loaded for sensitivity analysis. The sensitive data present in the tweet are examined using SPKs and SPD values, and its degree of sensitivity will be presented through the proposed sensitivity scale. The historical data for all the cyber-keywords are collected from Twitter and stored in a big data environment which will be frequently updated with the recent posts on Twitter. The historical data along with the user’s tweets posted in the TSP system will be used to train the classifier to predict the sensitivity of the tweet.

Conclusively, the TSP system advises the user to be aware of the SPKs and PIIs while posting online messages. It also highlights the users the necessity of evaluating the post with the scale of sensitivity to identify the sensitive content before posting it online. The authors insist on ‘Though it is a pleasure to gain public’s attention and appreciation, it is equally important to have safe and secure social networking life to avoid regrets’.

Conclusion
In this paper, the author has presented a model for tweet sensitivity analysis. Twitter has now enhanced the tweeting experience by increasing the number of characters from 140 to 280 per tweet. The extensive use of social media has created a privacy threat that many users are ignorant of which may lead to red-alert situations. The proposed Tweet-Scan-Post System contributes five major findings and five research questions in the sensitivity analysis. First, the TSP system formulated a mathematical representation for extracting keywords using a bag-of-words model for short text messages that are gathered from social media. Second, a set of well-defined contextual rules for annotating tweets as sensitive and insensitive are formulated. Third, a set of inter-domain fuzzy privacy keywords, namely ‘contact’, ‘save’, ‘family’, ‘child’, was identified. As the name implies, the keywords were present in multiple tweet categories that were taken for analysis. Fourth, a vocabulary set of 201 SPKs are identified by TSP. The number of cyber-keywords taken for the streaming tweet was 21, whereas the SPKs identified by TSP had 23 cyber-keywords including all those 21 cyber-keywords and two cyber-keywords, namely ‘company’ and ‘salary’. This strongly implies that the proposed approach in TSP performs well in identifying privacy keywords. The vocabulary set of TSP has been further enhanced for tweet sensitivity prediction by replacing the manual assumption of cyber-keywords with SPKs. The layered classification approach proposed by the TSP predicted a higher proportion of sensitive tweets than those identified during the manual annotation process. Fifth, a scale of sensitivity has been presented for tweets based on the statistical occurrences of the SPKs, cyber-keywords, and the non-SPKs. However, being dataset dependent, this scale presents a simple approach for the layman user to understand the sensitivity of the tweet before posting it online.

Some behavioural facts of the Twitter users are observed from the SPKs revealed interesting information on the tweeting content and the user’s concern. The number of personal tweets was related to the mother and children. The professional tweets were related to the company and apology for any activity. The health tweets were concerned with the father. From the tweets streamed for analysis, it can be inferred that the personal tweets ranged higher when compared to the professional and health categories. This shows that the tweeters are unaware of the vulnerability and ignorantly presented their personal information to the virtual world where the data are kept open for cyber-criminals. The NB classification used in the proposed model outperformed two categories of tweets, namely personal and health-related tweets. The overall accuracy for sensitive tweet identification was 75.24% that is higher than other classifiers. Analysis of the sensitive tweets without considering the SPKs shows that an average of 25% (approximately about 600 tweets from the dataset) is highly sensitive and is composed with privacy revealing information and PII. But, in the layered classification approach with SPKs, 35% (approximately about 870 tweets from the dataset) of the tweets were found to be composed of sensitive information. Though the count may seem to be comparatively low, it would range up to a significantly larger value when scaled up to the actual UGC.

Limitations and future work
The authors conclude that the TSP system can be improved in the aspect of dataset dependency which has an impact on SPK identification, number of tweets in each category, number of levels in recursive classification. The presence of PII and user-specific data is a direct vulnerability or threat that a user might encounter shortly in the future. The identification of sensitive content in a post is challenging because of the large volume and variety of data generated by users in OSN. Therefore, the prototype developed based on this research work will be presented to the naïve users in the form of a mobile application. The future work would be on generating a relationship graph between the identified SPKs and group them under various topics. Thus, it is necessary to have a red alert while composing tweets or messages in online social media to avoid regrets and threats in both personal and professional life.