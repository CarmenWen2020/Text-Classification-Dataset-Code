Item-based filtering technique is a collaborative filtering algorithm for recommendations. Correlation-based similarity measures such as cosine similarity, Pearson correlation, and its variants have inherent limitations on sparse datasets because items may not have enough ratings for predictions. In addition, traditional similarity measures mainly focus on the orientations of the rating vectors, not magnitude, and as a result two rating vectors with different magnitudes but oriented in the same direction, can be exactly similar. Another aspect is that on a set of items, similar users’ may have different rating pattern. In addition, to calculate the similarity between items, ratings of all co-rated users are considered; however, a judicious approach is to consider the similarity between users as a weight to find the similar neighbors of a target item. To mitigate these issues, a modified Bhattacharyya coefficient is proposed in this paper. The proposed similarity measure is used to calculate user–user similarity, which in turn is used as a weight in item-based collaborative filtering. The experimental analysis on the collected MovieLens datasets shows a significant improvement of item-based collaborative filtering, when user–user similarity calculated by the proposed modified similarity measure is used as a weight.

Access provided by University of Auckland Library

Introduction
Our society has entered the era of big data with the advent of internet and its applications in various domains [1]. The volume, velocity, and variety of data produced on a daily basis lead to excessive information, which is commonly known as information overload. Recommender system (RS) is used as an information retrieval tool in different domains (such as e-government, e-library, e-tourism, and e-commerce) to address the problem of information overloading. Several techniques such as content-based filtering, collaborative filtering (CF), and hybrid filtering are used to recommend items to active user. CF, which was first suggested by Goldberg in 1992, is the most popular and commonly used techniques in various RSs [2]. In fact, CF techniques produced the highest volume of research papers collected from established journals in the 2013–2014 period [3]. CF can be categorized into two types: model-based and memory-based. The model-based techniques employ the use of ML and data mining for generating recommendations, while the memory-based technique uses the user rating data to compute the similarity between users and/or items. Model-based CF were introduced to overcome the cons of memory-based CF; for instance, its limitation on sparse datasets is one of the most fundamental problems and limited research has addressed this issue.

Model-based approaches although lucrative come with its own set of implementational challenges. ML approaches are preferred when there is need to decrypt a black-box setting, i.e., when the unknown mapping function that generates a known input and output is to be recognized. However, in case of rating-based RSs one is provided with a rating and is aware of the function, whose basic ideology is as simple as “I like what my friends like.” Hence, memory-based approaches with their fundamental limitation in sparse dataset resolved shall be highly beneficial to this scenario since the complexity of the RSs is minimal. Further, ML approaches would require extensive feature collection and dimension reduction. In case of limited datasets, a representative cluster may turn out to be an outlier and fail to truly represent the population. Further, the benchmark data on which model-based methods are trained on often differ from real-world settings, thus leading to a performance degradation. These arguments direct the motivation of research toward memory-based CF. Moreover, the simplicity of implementation, minimal content requirement, and ability to handle cold starts and to scale well with correlated items are other contributing factors that add to the advantages.

The existing memory-based CF technique can be classified into user-based and item-based CF. The concept of user-based CF is to find users who share appreciation in a group. If the same or almost the same rated items is common between two users, then users may have similar taste. These users create a community or a neighborhood. Intrinsic and extrinsic are the two methods, utilized for rating collection [4]. These collected ratings are used in the form of matrix of size m×n, where m represents a set of users, i.e., U = {u1, u2, u3,..., um}, and n shows a set of items, i.e., I = {i1, i2, i3,..., in} that are rated by user set U.

More precisely, the basic principle behind user-based CF is that users with similar preferences in the past may have similar preferences in the future. Consequently, the most critical aspect of CF for enhancing recommendation quality is to find the nearest neighbors. The similarity method therefore has a significant impact in the performance of CF. Various similarity measures (SMs) are used to find the nearest neighbors or similar users of a target user [1, 3]. The respective ratings and similarity values of nearest neighbors are used to predict the taste of the target user on different items. Top-N recommendation list is generated based on the above philosophy [3, 5].

User-based CF faced some major limitations such as scalability, cold start, and sparsity [6, 7]. The number of customers in any E-commerce site is increasing rapidly as compared to items and due to this, computing similarities between each pair of user became quite expensive . Item-based CF, which is introduced by members of GroupLens Research Group [8], is a more feasible approach for item recommendation. The basic assumption of item-based CF is that user prefers similar items that he or she liked in the past. Item-based CF utilizes the similarity values of items for predicting the target item [9]. The item-based CF has many advantages over user-based CF. Firstly, items are relatively static and very less in numbers, compared to the number of users, so similarity can be computed offline and can be accessed when needed [10]. Secondly, it provides more accurate recommendation than user-based CF [8, 11, 12].

However, like user-based CF, the performance of item-based CF may be disrupted due to several reasons. The following issues may result in inaccurate prediction in item-based RS. Firstly, item–item similarity for some pair of items cannot be computed, if there is no co-rated items in the dataset. Secondly, item-based CF gives equal weight to all the co-rated users. However, rating of two similar user on a randomly chosen item may vary, in spite of impressive similarity between them, due to the fact that the randomly chosen item might have negligible or very small impact on the average rating taken over n rated items, i.e., it may be an outlier. This may happen in four cases:

Biased rating by one user or both users; the ideal conditions of rating might have been violated.

The particular item reflects two very different emotional/psychological involvement of the persons with the product.

The taste of two users on the particular item may be different and

One user may be stringent and other may be lenient in rating that item [13].

Therefore, a more judicious approach is that the similarity between a target user and each co-rated users should be considered in finding similar neighbors of the target item. Thirdly, traditional similarity functions such as cosine similarity and its variants are a measure of orientation, not magnitude. Two vectors with different magnitude but exactly the same orientation can have cosine similarity value of one. The above circumstances may lead to the disruption of prediction accuracy in CF.

The purpose of this paper is to examine the behavior of different SMs at different rating patterns of users. To alleviate the above-mentioned issues, we propose a new similarity function using the modified Bhattacharyya coefficient. The efficiency of the proposed similarity function is measured on the collected MovieLens datasets, and the comparative results of this paper are divided as: (i) The experimental analysis reveals that item-based CF with user–user similarity as weight is a better choice than user-based CF with item–item similarity as weight, (ii) user–user similarity computed using the modified Bhattacharyya coefficient results in improved accuracy in item-based CF, as compared to the weight calculated using traditional SMs, and (iii) the proposed similarity function using the modified Bhattacharyya coefficient attains more prediction accuracy than some recently used similarity measures in CF-based RS.

The remainder of the article is structured as follows. Section 2 elaborates the background and related work. In Sect. 3, limitations of various similarity measures are discussed. Section 4 highlights the motivation of the proposed work. The proposed recommender system is portrayed in Sect. 5. Experimental analysis is discussed in Sect. s6, and finally, Sect. s7 concludes our paper.

Background and related work
RS can be defined as a decision-making strategy which aims to provide the most relevant and accurate chunk of information to the user according to their preferences and taste by filtering from a huge pool of information. It assists the user to handle the information overload problem by providing them personalized and customized content, and services. Additionally, in the complex information environment, recommender engine discovers the data pattern in the dataset that could connect the user to their needs. Over the last two decades, recommenders have evolved from manual to automated engines, and their use has grown significantly in a variety of applications, resulting in the development of a diverse set of algorithms. Content-based and CF are the most commonly used approaches in RS [14]. The basic intuition of the content-based RS is that "the recommendation of the target item depends on it’s properties which are highly similar to the previously favored items by the target user". The fundamental steps involved in the content-based RS are: (i) finding the attributes of an item that may be recommended to the target user, (ii) making a profile of the user that portrays the sort of items that the user likes, (iii) contrasting the properties of the item with the user’s profile, to figure out what item needs to be recommended. Content-based filtering applies on the attributes of the item, whereas CF uses the user’s behavior also with the attributes of the item.

Memory-based CF utilizes the user-to-user and item-to-item correlations, based on the rating in order to predict the rating of the target user for the recommendation. The basic steps in memory-based CF for recommendation are: (i) creation of a user’s profile from rating, (ii) selection of neighbors of a target user by utilizing similarity function, (iii) rating prediction of the target item, and (iv) recommendation of the Top-N items to the target user.

Haifeng Liu et al. have explored the major drawbacks of traditional SMs in CF, namely [15]: (i) ignoring the proportions of common ratings lead to lower accuracy, (ii) under Jaccard’s similarity, it would be difficult to discern between different users the absolute value of the rating, because it considers only a proportion of the common ratings, (iii) two users with similar ratings might not have the same predicted rating for the target item, and (iv) two users with distinct rating patterns may be similar on the predicted rating of a target item. In order to mitigate these limitations, they have proposed a novel SM which is composed of three factors of similarity, i.e., proximity, impact, and popularity. The proximity factor not only measures the absolute difference between the two ratings, but also determines whether or not these ratings are in agreement and, in case of disagreement, also gives a penalty to the ratings. The impact factor shows the preferred or non-preferred nature of an item toward the user. Popularity denotes how common is the rating pattern of two users. If the difference between the average of two users’ rating and the average of total user’s rating is maximum, then these ratings of the two users may increase the accuracy of similarity values between the two users.

Sarik Ghazarian et al. have proposed a group recommender system that can solve the sparsity problem in memory-based CF [16]. Support vector machine learning model is applied in finding items’ similarity in the proposed method. The two conceptions of similar and dissimilar users are as follows: (i) The two users are said to be similar if they have nearly the same rating pattern on the similar items, and (ii) if the two users rate two different items, then they are said to be dissimilar users.

Some hardware constraints may impede the scalability and processing efficiency of item-based CF because of the growing number of items and users. Chenyang Li and Kejing He have proposed an optimized MapReduce for item-based CF algorithm to minimize the scalability issue in item-based CF [17]. User’s rating frequency provides a reasonable empirical factor in the calculation of similarity value between items. Hence, they have also introduced an argument, named as the inverse user frequency that means the users who have lower rating frequency than the users who have higher rating frequency should be more involved in the calculation of item–item similarity. Their proposed algorithm divides the large-scale datasets into small jobs, and then, these small jobs are executed independently to reduce the execution overhead and to ensure better performance.

Cold-start problem is another significant issue in memory-based CF, and hence, Andre Luiz Vizine Pereira and Eduardo Raul Hruschka have presented a hybrid recommender system based on simultaneous co-clustering and learning that combines the CF with demographic information [18]. The advantage of their proposed system is that it can provide recommendation where no rating is available for the new user. To deal with the sparsity problem and to improve the accuracy of the CF-based system, Qusai Shambour et al. have used the Euclidean distance and cosine similarity as the SMs for making more personalized RS [19].

CF-based RS uses the entire rating database, resulting in poor scalability when more users and items are added to the database. To minimize this issue, Efthalia Karydi and Konstantinos G. Margaritis have constructed two parallel variants of the CF method which include benefits related to efficiency and the capacity to dynamically update data [20]. The first version is built in parallel using the OpenMP API, and its efficiency is assessed on a multi-core system. The second variant is a hybrid technique that utilizes both OpenMP and MPI which is tested in both homogeneous and heterogeneous clusters.

Zhongya Wang et al. have developed a CUDA-enabled parallel CF method that uses an efficient data partitioning scheme to speed up the execution [21].

In a survey of parallel and distributed collaborative filtering, Efthalia Karydi and Konstantinos Margaritis revealed that no memory-based methods have been built on distributed memory environment, and only one has been established in a shared memory framework [22]. Many parallel and distributed collaborative filtering algorithms have recently been developed, particularly in the use of graphics processing units and other platforms. It would be excellent to use a multilayer heterogeneous method that utilizes several machines to efficiently process large amounts of data and then combine a number of techniques.

With the distribution of bipartite material, Christos Sardianos et al. have presented a method for enhancing the effectiveness of CF algorithms that perform in a parallel configuration [23].

User’s rating information plays an important role in the memory-based CF. The privacy of this information provides more efficient and accurate recommendation. In that direction, Dongsheng Li et al. have introduced an efficient privacy-preserving item based CF that can protect user privacy during online recommendation process [24]. Here, item similarities have been computed using the proposed un-synchronized secure multi-party computation protocol that preserves the privacy of the item similarity computation.

In the existing literature, some multi-criteria item-based CF techniques have been introduced to mitigate the limitations of the traditional single-criterion rating-based algorithm. Alper Bilge and Cihan Kaleli have discussed about a multi-criteria item-based CF framework [25]. In this paper, the authors have followed two steps in the calculation of similarity between items. In the first step, the similarity between items have been computed according to each criterion. The second step involves estimating the average of the similarity between each criterion. Pearson correlation, adjusted cosine similarity, Euclidean distance, Manhattan distance, and Chebyshev distance are the SMs used in this paper. Gediminas Adomavicius and YoungOk Kwon have explained the two new approaches, i.e., the similarity-based approach and the aggregation function-based approach for improving the multi-criteria rating information in recommender systems [26].

Table 1 shows the notations used in the equations of popular traditional SMs.

Table 1 Notations used in SMs
Full size table
The computation equations of SMs are:

Cosine Similarity [8]

CSim(u,v)=∑i∈I(Ru,i)(Rv,i)∑i∈I(Ru,i)2−−−−−−−−−√2∑i∈I(Rv,i)2−−−−−−−−−√2
(1)
Adjusted Cosine Similarity [8]:

ACSim(u,v)=∑i∈I(Ru,i−Ri¯)(Rv,i−Ri¯)∑i∈I(Ru,i−Ri¯)2−−−−−−−−−−−−−−√2∑i∈I(Rv,i−Ri¯)2−−−−−−−−−−−−−√2
(2)
Euclidean Distance [27]:

EDSim(u,v)=11+∑i∈I(Ru,i−Rv,i)2−−−−−−−−−−−−−−√2
(3)
Pearson Correlation [8]:

PCSim(u,v)=∑i∈I(Ru,i−Ru¯)(Rv,i−Rv¯)∑i∈I(Ru,i−Ru¯)2−−−−−−−−−−−−−−√2∑i∈I(Rv,i−Rv¯)2−−−−−−−−−−−−−−√2
(4)
Spearman Correlation [28][29]:

SCSim(u,v)=∑i∈I(ku,i−ku¯)(kv,i−kv¯)∑i∈I(ku,i−ku¯)2−−−−−−−−−−−−−√2∑i∈I(kv,i−kv¯)2−−−−−−−−−−−−−√2
(5)
For item-based CF, the equations of SMs can be derived by mutually exchanging u with i and v with j [3]. These SMs do not utilize the similarity value of a target item and other item in the computation of user similarity. Hence, K. Choi and Y. Suh [27] have proposed a new SM that outperforms the traditional SMs in the selection of neighbors for each target item.

Sparsity is a major issue in CF-based RS. Various SMs are unable to compute accurate top-k similar neighbor in a sparse scenario. Therefore, Patra et al. have provided a new SM using Bhattacharyya coefficient (BC) that outperforms the prevalent SMs. The computational equation 6 shows the SM using BC. In this equation, Jacc(u,v) represents the Jaccard similarity between users. BC(i,j) computes the similarity on item i and item j using BC . loc(rui,rvj) denotes the local similarity between users with respect to item i and item j.

Similarity using modified Bhattacharyya coefficient [30]:

BCSim(u,v)=Jacc(u,v)+∑i∈Iu∑j∈IvBC(i,j)loc(rui,rvj)
(6)
The mathematical formula of BC(i,j) and loc(rui,rvj) is:

BC(i,j)=∑h=1mpih¯pjh¯−−−−−√
(7)
loc(rui,rvi)=(rui−rmed)(rvi−rmed)∑k∈Iu(ruk−rmed)2−−−−−−−−−−−−−−−√∑k∈Iv(rvk−rmed)2−−−−−−−−−−−−−−−√
(8)
Here, m identifies the number of bins. pih¯ shows the ratio between the number of users rated the item i with rating value ’h’ and the total number of users rated the item i. rmed is the median of the rating scale, Iu shows the set of items rated by the user u, and ruk denotes the rating value of user u on item k.

A parallel CF-based RS on extending the vector (PCF-EV) is presented by Hongyi Su et al. to overcome the scalability issue [31]. To begin, the eigenvector is fairly extended to obtain the expand-vector using the expand-vector model. The expand-vectors are then used to illustrate a set of similarity evaluations. Then, the k-nearest item is determined, and the computation results are used to make more reliable recommendations to the target user. On the basis of this, additional optimization allows it to be successfully deployed to the parallel computing architecture.

Limitations of similarity measures
Similarity computation method plays a significant role in the prediction accuracy of CF-based RS. There is a plethora of work that exists in the literature to improve the performance of CF. However, existing SMs are not suitable in the following cases (i) when co-rated items are few or zero, and (ii) ratings of two items follow some specific patterns. The following cases are used to explain the limitations of existing SMs.

Case 1: Suppose the rating vectors of 3 items and 4 users are I1=(1,2,1,2), I2=(2,4,2,4), and I3=(0.5,1,0.5,1).

In Table 2, except ED, other SMs stand testimony to the fact that two items are exactly similar in spite of their different rating patterns.

Case 2: Suppose the rating vectors of two items pair are [I1=(1,2), I2=(1,2)], and [I1=(1,2,1,1),I3=(1,3,1,1)] for two and four users, respectively.

In Table 3, I1 and I2 have two and I1 and I3 have four co-rated users, respectively. The varying lengths of rating vectors notwithstanding PC and SC compute the same similarity value in both conditions. On the contrary, in condition 1, ACS is unable to compute similarity. Thus, in such circumstances, the prediction accuracy of CF may be disrupted.

Case 3: Suppose, the rating vectors of three items for four users are I1=(1,1,1,1), I2=(1,1,1,1), and I3=(3,3,3,3).

Table 4 illustrates that except ED, all SMs have some computational issues on flat rating vectors. The rating vectors of I2 and I3 are opposite to each other, but CS computes the same similarity value in both the conditions 1 and 2. ACS, PC, and SC are unable to calculate the similarity value in both conditions.

Case 4: Suppose the rating vectors of two item pair for four users are [I1=(1,5,5,1), I2=(5,1,1,5)], and [I1=(1,1,5,5), I3=(5,5,1,1)]. In Table 5, both item pairs have four co-rated users. The circumstantial evidence helps us to draw the conclusion that both items I2 and I3 have a rating value of 5 when item I1 has a rating value of 1, and vice versa. In addition to this, only CS and ED compute the positive similarity value (greater than minimum similarity value) when the rating vectors of items are opposite to each other. In such a case, it won’t be incorrect to conclude that CS and ED may provide inaccurate rating prediction in CF-based RS.

Case 5: Suppose the rating vectors of three items for single user are I1=(1), I2=(3), and I3=(5).

In Table 6, only ED computes the different similarity values in both the conditions. Similarity values cannot be computed using PC and SC. Using CS, we can misinterpret that items I2 and I3 are equally similar to I1. Items I2 and I3 are found to be most dissimilar to I1 according to ACS value.

Case 6: Suppose the rating vectors of two items pair are [I1=(1,5,1,3), I2=(5,1,3,1)], and [I1=(1,5), I3=(5,1)] for four and two users, respectively.

From Table 7, a number of co-rated users for item pairs (I1, I3) and (I1, I2) are four and two, respectively. In both the conditions, CS and ED provide positive similarity value (means greater than minimum similarity value) where the rating vectors of each pair are opposite to each other. Furthermore, ACS and PC have the same similarity value in both the conditions. These nature of SMs may degrade the rating prediction accuracy in CF.

Case 7: Suppose the rating vectors of three items for four users are I1=(?,1,?,2), I2=(2,?,?,?), and I3=(?,?,1,?). Here, ? denotes that a user did not rate the particular item. Table 8 shows all SMs are unable to compute the similarity between items. In such a scenario, using CS, ACS, ED, PC, and SC the rating prediction accuracy of CF may decrease significantly.

Table 2 Equal-Ratio problem [32]
Full size table
Table 3 Unequal-Length problem [32]
Full size table
Table 4 Flat-Value problem [32]
Full size table
Table 5 Opposite-Value [32]
Full size table
Table 6 Single-Value [32]
Full size table
Table 7 Cross-Value problem [32]
Full size table
Table 8 Sparsity problem when no co-rated items exist [30]
Full size table
The above situations highlight the fact that no single SM is suitable to compute the similarity between items in CF. Another key drawback of traditional SMs is that they give equal weightage to all co-rated users to find similar neighbors.

To attain more rating prediction accuracy, K. Choi and Y. Suh have introduced a new similarity function that adopts the similarity value of the target item and other items as a weight for a user-based CF. The experimental results of K. Choi and Y. Suh have indicated that user-based CF using Pearson correlation obtains more recommendation accuracy than other SMs when item similarity value is used as a weight in the computation of user–user similarity. Although their proposed SM considers the aspect of CF-based RS that two similar users may have different opinions on a set of items, their proposed SM fails in some rating patterns of users as shown in Table 9.

Table 9 Proposed SM of K. Choi and Y. Suh at various issues
Full size table
Table 9 highlights the similarity values of users at different target item. In spite of computing similarity at each target item, the proposed SM of K. Choi and Y. Suh is unable to resolve many problems such as Unequal-Length, Flat-Value, Single-Value, and sparsity (when no co-rated users exist).

In this direction, to mitigate the above-mentioned issues, Z. Tan et al. have suggested a new SM. The proposed algorithm is based on physical resonance phenomenon [32]. Although the resonance similarity overcomes most of the above-discussed issues, major concern still exists in their proposed approach. (i) In reality, different applications have a different percentage of sparse data [3, 30, 33]. However, the comparative analysis of their proposed approach at different sparsity levels has not been discussed. (ii) The efficiency of CF algorithms is justified by various statistical metrics such as MAE, RMSE, precision, recall, F1-measure, t test, and confidence [27, 30, 33]. But, Z. Tan et al. have used only MAE in their comparative results. (iii) Another important aspect, i.e., on a set of items, similar users may have different rating patterns, is not addressed in their proposed approach. (iv) The ratings of all co-rated items are considered in their proposed approach, and as a result, it may also suffer from performance issues [30].

Motivation
Sparsity is a major concern in item-based CF, as correlation-based SMs such as cosine similarity, Pearson correlation, and its variants fail to calculate the similarity between some items. In statistics, the Bhattacharyya distance measures the similarity of two probability distribution. It is closely related to the Bhattacharyya coefficient. Bhattacharyya coefficient named after Anil Kumar Bhattacharyya, a statistician, can be a suitable similarity measure in sparse dataset, because it does not consider co-rated items and is a measure of magnitude, not orientation. Instead, the Bhattacharyya coefficient computes the relative closeness between two statistical samples [34, 35]. Table 10 shows the similarity value of items using BC on different rating patterns.

Table 10 Similarity value by BC
Full size table
It may well be concluded from Table 10 that BC is the most suitable SM for a sparse dataset, though it fails to resolve some of the issues such as Equal-Ratio, Opposite-Value, Single-Value, and Cross-validation problems.

Although many SMs are found in the literature to enhance the rating prediction accuracy in CF, but, throughout the above discussion, we can observe that no single SM can overcome all the mentioned issues. Table 11 represents the brief description of various SMs for different aspects of CF-based RS.

In Table 11, ✓ identifies that the SM can resolve the issue. × denotes that the SM is unable to resolve the issue. And, ∗ notifies that the SM can resolve some issues of rating patterns, and others cannot be resolved.

Table 11 Performance of various SMs at different rating patterns
Full size table
However, similar users may have different opinions on some items [27]. For example, suppose that u1, u2, and u3 are the three users, and their rating vectors on six items are u1=(5,1,1,5,5,?), u2=(5,5,5,5,5,1), u3=(1,1,1,1,1,1). Here, ’?’ denotes that user u1 does not rate the item six. Rating vectors clearly show that users u1 and u2 are the most similar. However, their taste on second and third items are totally different (opposite).

Inspired by the above observations, the rating prediction accuracy of item-based CF can be improved (i) if user–user similarity is used as a weight to find similar items, and (ii) BC and modified BCSim are utilized to satisfy the varied taste of similar users.

Proposed recommender system
The proposed RS is divided into four modules, namely (i) data collection, (ii) data processing, (iii) rating prediction, and (iv) Top-N recommendation as presented in Fig. 1. Data collection comprises the methods that collect the users’ feedback on the target item. These collected feedbacks are converted into user–item rating matrix for further CF-based recommendations. In the next step of the proposed RS, this user–item matrix is used to find the similarity value using proposed SM.

Fig. 1
figure 1
Proposed Recommender System based on Item-based Collaborative Filtering

Full size image
Proposed similarity function to find similar items of a target item for a target user
This section gives the detailed information of proposed SM that uses the similarity value of the similar user in finding the top-k nearest items of a target item. The computational equations of modified BC, i.e., proposed SM, are shown in Table 12.

Table 12 Proposed similarity measure
Full size table
In Table 12, CF_BI_BU denotes item similarity using BCSim weighted by user similarity using BCSim for target user u and target item i. U and I represent the set of users and items, respectively. Jacc(i,j) shows the Jaccard similarity between items. BC(u,v) finds the similarity between users u and v using BC. locmod(riu,rjv) denotes the local similarity between items i and j with respect to user u and user v. m identifies the number of bins. puh¯ shows the ratio between the number of items rated by user u and the number of items rated by user u with rating value h. rmed is the median of the rating scale, Ui demonstrates the set of users who rate the item i, and rik denotes the rating value of item i by user k.

The advantages of CF_BI_BU can be illustrated in Table 13, where similarity of item I1 and I2 is computed on different rating patterns for different target users. Instead, Table 12 is utilized in the formation of Table 13 as discussed in the following steps.

In Equal-Ratio problem for target user 1:

figure a
=[1∗2.4{(1−3)(1−3)+(1−3)(2−3)+(2−3)(1−3)+(2−3)(2−3)}+(0.5∗1.16){(1−3)(2−3)+(1−3)(4−3)+(2−3)(2−3)+(2−3)(4−3)}+(1∗2.4){(1−3)(1−3)+(1−3)(2−3)+(2−3)(1−3)+(2−3)(2−3)}+(0.5∗1.16){(1−3)(2−3)+(1−3)(4−3)+(2−3)(2−3)+(2−3)(4−3)}]/{10−−√∗4–√)}={2∗2.4∗(4+2+2+1)+1.16(2−2+1−1)}/40−−√=41.2/40−−√=6.51 And,∑u,v∈UBCSim(u,v)=BCSim(1,1)+BCSim(1,2)+BCSim(1,3)+BCSim(1,4)=2.4+1.16+2.4+1.16=7.12SimU1(I1,I2)=Jacc(I1,I2)+(6.51/7.12)=1+0.91=1.91
Table 13 Similarity value by CF_BI_BU
Full size table
In Equal-Ratio problem for target user 2:

figure b
=[0.5∗1.16{(2−3)(1−3)+(2−3)(2−3)+(4−3)(1−3)+(4−3)(2−3)}+(1∗1.5){(2−3)(2−3)+(2−3)(4−3)+(4−3)(2−3)+(4−3)(4−3)}+(0.5∗1.16){(2−3)(1−3)+(2−3)(2−3)+(4−3)(1−3)+(4−3)(2−3)}+(1∗1.5){(2−3)(2−3)+(2−3)(4−3)+(4−3)(2−3)+(4−3)(4−3)}]/{10∗4−−−−−√}={1.16∗(2+1−2−1)+3(1−1−1+1)}/40−−√=0/40−−√=0 And,∑u,v∈UBCSim(u,v)=BCSim(2,1)+BCSim(2,2)+BCSim(2,3)+BCSim(2,4)=1.16+1.5+1.16+1.5=5.32SimU2(I1,I2)=Jacc(I1,I2)+(0/5.32)=1+0=1.0.
Similarly, we can compute the desired similarity value for each rating patterns.

In Table 13, in most of the cases, CF_BI_BU resolves the illustrated issues. In reality, the user–item rating dataset may be highly sparse and non-co-rated. In such scenario, from Table 13, we can notice that CF_BI_BU computes different similarity values for each rating pattern.

Rating prediction of target items for the target user
After calculating similarity values, the prediction approach has been used in the rating prediction of the target item [42,43,44]. Firstly, all the similarity between target item and other items are calculated, and then, Top-k similar items with highest similarity values are selected as the closest similar item of the target item. In the last step of prediction approach, the aggregation function is used to predict the rating of target user on the target item. The equation of prediction approach becomes as follows:

ru,i^=ri¯+∑kj=1Simu(i,j)(ru,j−rj¯)∑kj=1|Simu(i,j)|
(9)
Here, ru,i^ shows the predicted rating of target item i for target user u and k is the number of the closest similar items of the target item. Simu(i,j) identifies the similarity between target item i and other item j for target user u. After determining all the predicted rating of target items, a list of Top-N item is selected and recommended to the target users.

Proposed algorithm
A detailed process for rating prediction using the proposed SM is given in Algorithm 1 using notations as discussed in Table 14.

Table 14 Notations
Full size table
figure c
Time complexity of the proposed algorithm
The proposed algorithm is divided into four steps. First step calculates the similarity between users. The similarity value between two users is used as the weighing factor to find the item similarity value of target users in step 2. All item–item similarity values are arranged in descending order in step 3. And the final step utilizes the outputs of the previous steps as an input in the prediction of rating of the item for the target user. Lines 4 to 7 take O(m), O(m), O(n), O(n) time, respectively, in execution [45]. Therefore, the time complexity of step 1 is O(m2n2). Similarly, step 2 takes O(m2n2) time complexity due to O(n), O(n), O(m), and O(m) from lines 9 to 12, respectively. In step 3, sorting technique is applied to arrange the item similarity value. Therefore, it has various complexity for different cases. Lines 14 to 16 take Ω(mn), θ(mnlogn), and O(mn2) as best, average, and worst case execution time, respectively. And in the final step, the execution time from line 18 to 22 is O(m), O(n), O(1), O(k), and O(1), respectively. Hence, the time complexity to execute the step 4 is O(mnk). Here, k is the total number of predicted ratings. Table 15 shows the total time complexity of the CF_BI_BU.

Table 15 Time complexity of CF_BI_BU
Full size table
Illustrative example
In this section, we provide an illustrative example using the modified traditional SMs (under proposed idea, i.e., utilization of user similarity as a weight in an item-based CF) as well as using the proposed SM (CF_BI_BU). Table 16 shows the notations used in the modified traditional SMs, and the equations of modified traditional SMs are represented in Table 17.

Table 16 Notations used in the modified traditional similarity measures
Full size table
Table 17 Modified traditional similarity measures
Full size table
Here, Ri,v, and Ri,v show the rating value of items i and j rated by user v. Rj¯, ki¯, and kj¯ represent the average rating of item j, average rank of the item i, and average rank of the item j, respectively. k(i,v), and k(j,v) show the rank of the rating of items i and j rated by user v.

Table 18 shows the rating information of nine users and eleven items, where Tu and Ti are the target user and item, respectively. Table 19 depicts the similarity between target user and other user using the traditional SMs.

Table 18 User–item rating information
Full size table
Table 19 Similarity between target user and other user
Full size table
Calculation for the similarity between target item and other item
CSimTu(Ti-I1) = AB√2∗C√2

where A, B, and C are the symbols used in the proposed SMs as shown in Table 12.

A = (0.726*0.5*2) + (0.788*1*2.5) + (0.803*3.5*3) + (0.826*3.5*4.5) + (0.743*4*5) + (0.588*2*0.5) + (0.818*2.5*1) + (0.858*1.5*3).

A ≈ 45.504.

B =(0.852∗0.5)2 + (0.887∗1)2 + (0.896∗3.5)2 + (0.909∗3.5)2 + (0.862∗4)2 + (0.767∗2)2 + (0.904∗2.5)2 + (0.926∗1.5)2.

B ≈ 42.221.

C =(0.852∗2)2 + (0.887∗2.5)2 + (0.896∗3)2 + (0.909∗4.5)2 + (0.862∗5)2 + (0.767∗0.5)2 + (0.904∗1)2 + (0.926∗3)2. C ≈ 59.059.

CSimTu(Ti-I1)=45.50442.221√2∗59.059√2≈ 0.912.

Similarly, the similarity value of target item and other item is calculated using the traditional SMs and the proposed SMs, respectively, as shown in Table 20. Based on these similarity values using the SMs, Table 21 shows the ranking of similar items for Ti.

Calculation of rating prediction of the target item for the target user
rTu,Ti^ using CSimTu(Ti-I1) = rTi¯ + XY

where rTi¯ = 2.6875

X = 0.912*(1-2.313) + 0.982*(2-2.75) + 0.985*(2-2.938) + 0.934*(2.5-2.5) + 0.950*(5-2.563) ≈− 0.543

Y = 0.912 + 0.982 + 0.985 + 0.934 + 0.950 ≈ 4.763

rTu,Ti^ = 2.6875 + −0.5434.763 ≈ 2.57.

The predicted rating of the target item is calculated using the proposed SMs in Table 22. We consider only the Top-5 similar items in the rating prediction.

Table 20 Similarity between target item and other item
Full size table
Table 21 Ranking of similar items for the target item
Full size table
Table 22 Predicted rating of target item
Full size table
Experiments
This section explains the effectiveness of the proposed SMs in item-based CF and is divided into two subsections, i.e., (i) experimental setup and (ii) comparative analysis.

Experimental setup
The experiments of the proposed SM are tested on the MovieLens datasets. Table 23 shows the details of collected datasets.

Table 23 Details of the collected datasets
Full size table
To demonstrate the performance of proposed SMs in different sparse datasets, the collected datasets are further divided into subsets. These subsets are created by randomly removing 10%, 20%, and 30% of ratings from Datasets 1 and 2, and 10%, 30%, and 50% of ratings from Dataset 3, respectively [3, 46,47,48]. Brief details of these subsets are listed in Table 24.

Table 24 Used subsets in the experiments
Full size table
Furthermore, in this paper, these deleted ratings are predicted by various CF algorithms and different accuracy/performance metrics have been used in the comparative analysis. These metrics are MAE, RMSE, precision, recall, F1-measure, and accuracy. The equations of these metrics are [3, 7, 46,47,48]:

MAE=∑Ni=1|pi−qi^|N
(10)
RMSE=∑Ni=1(pi−qi^)2N−−−−−−−−−−−−√
(11)
From equations 10 and 11, the predicted and actual rating of item i is represented by pi and qi^, respectively. N denotes the total number of predicted items in the dataset.

Precision=#tp#tp+#fp
(12)
Recall=#tp#tp+#fn
(13)
F1−Measure=2∗Precision∗RecallPrecision+Recall
(14)
Accuracy=#tp+#tn#tp+#tn+#fp+#fn
(15)
The ratings above 3 are addressed to be a high rating (recommended), and less than 3 is a low rating (not recommended) to determine the precision, recall, F1-measure, and accuracy. Symbol # denotes the ’number of’. The classification of the possible results, i.e., tp, fn, fp, and tn, is calculated using Table 25 [7, 46, 47].

Table 25 Classification of the potential outcomes used in performance metrics
Full size table
Comparative analysis
Comparative results of this section can be divided into four parts.

K. Choi and Y. Suh have proved that Pearson correlation, using item–item similarity as a weight in a user-based CF, attains more accuracy than other algorithms. Therefore, to measure the effectiveness of the proposed idea, the SM using Pearson correlation is compared with the CF algorithm proposed by K. Choi and Y. Suh, where user similarity using Pearson correlation is calculated by item similarity using Pearson correlation ((CF_P_P)) [27].

To find the most accurate SM, this paper compares item-based CF with users similarity as weight calculated using cosine similarity, Pearson correlation, its variants, and modified Bhattacharyya coefficient (CF_CI_CU, CF_AI_AU, CF_EI_EU, CF_PI_PU, CF_SI_SU, and CF_BI_BU).

This work demonstrates a comparison between the most accurate SM calculated in the previous part, and some recently used SMs in CF-based RS (A CF algorithm for density enrichment using Pearson correlation (CFDR_PC), and CF algorithm using improved triangle similarity (CF_ITR)).

Lastly, the comparison of complexities has been discussed among CF_P_P, CF_CI_CU, CF_AI_AU, CF_EI_EU, CF_PI_PU, CF_SI_SU, CF_BI_BU, CFDR_PC, and CF_ITR.

Comparison of CF_PI_PU and CF_P_P
Figures 2, 3, 4, 5, 6, 7, 8, 9, 10 represent the comparison between CF_PI_PU and CF_P_P on the basis of various performance metrics in different datasets. From the observations, we collect results on different values of k in top-k neighbors.

Fig. 2
figure 2
Comparison of CF_PI_PU and CF_P_P based on MAE values at Dataset1

Full size image
Figures  2, 3, 4, 5, 6, 7 serve as significant evidence to choose the accurate SM between CF_PI_PU and CF_P_P. We can notice that CF_PI_PU attains less prediction errors than CF_P_P for datasets1 and 2 at different values of k-nearest neighbors. In dataset3, for less sparse subset, i.e., ML7, CF_PI_PU fails to outperform CF_P_P, but, for more sparse subsets, i.e., ML8 and ML9, it outperforms CF_P_P in terms of less prediction error at various values of k-nearest neighbors.

Fig. 3
figure 3
Comparison of CF_PI_PU and CF_P_P based on MAE values at Dataset 2

Full size image
Fig. 4
figure 4
Comparison of CF_PI_PU and CF_P_P based on MAE values at Dataset 3

Full size image
Fig. 5
figure 5
Comparison of CF_PI_PU and CF_P_P based on RMSE values at Dataset 1

Full size image
Fig. 6
figure 6
Comparison of CF_PI_PU and CF_P_P based on RMSE values at Dataset 2

Full size image
Fig. 7
figure 7
Comparison of CF_PI_PU and CF_P_P based on RMSE values at Dataset 3

Full size image
Fig. 8
figure 8
Comparison of CF_PI_PU and CF_P_P based on precision, recall, F1-measure, and accuracy at Dataset 1

Full size image
Fig. 9
figure 9
Comparison of CF_PI_PU and CF_P_P based on precision, recall, F1-measure, and accuracy at Dataset 2

Full size image
Fig. 10
figure 10
Comparison of CF_PI_PU and CF_P_P based on precision, recall, F1-measure, and accuracy at Dataset 3

Full size image
Figures 8, 9, 10 demonstrate the comparison between CF_PI_PU and CF_P_P on the basis of precision, recall, F1-measure, and accuracy. It is observed that CF_PI_PU has higher values of mentioned performance metrics than the CF_P_P in Datasets 1 and 2 at various sparsity. In Dataset 3, CF_PI_PU has low precision, recall, F1-measure, and accuracy at 10% sparsity than CF_P_P , but higher precision, recall, F1-measure, and accuracy at 30% and 50% sparsity.

From all three datasets, recommendation accuracy goes in favor of CF_PI_PU. Hence, CF_PI_PU is better SM than CF_P_P, and utilization of user–user similarity as a weight in an item-based CF is a judicious approach.

Comparison of proposed similarity function using traditional similarity measures
To evaluate the performance of proposed SM under different traditional SMs, this section demonstrates the comparative analysis based on MAE, RMSE, precision, recall, F1-measure, and accuracy. In the comparative analysis, we compute all performance metrics at various k values (i.e., 50, 100, 150, 200, 250, and 300) in Top-k neighbors. The performance of CF_BI_BU is found to be relatively better than others with respect to MAE values as shown in Figs. 11, 12, 13.

Fig. 11
figure 11
Comparison based on MAE values at Dataset 1

Full size image
Fig. 12
figure 12
Comparison based on MAE values at Dataset 2

Full size image
Fig. 13
figure 13
Comparison based on MAE values at Dataset 3

Full size image
Fig. 14
figure 14
Comparison based on RMSE values at Dataset 1

Full size image
Fig. 15
figure 15
Comparison based on RMSE values at Dataset 2

Full size image
Fig. 16
figure 16
Comparison based on RMSE values at Dataset 3

Full size image
Fig. 17
figure 17
Comparison among CF_CI_CU, CF_AI_AU, CF_EI_EU, CF_PI_PU, CF_SI_SU, and CF_BI_BU at Dataset 1

Full size image
Fig. 18
figure 18
Comparison among CF_CI_CU, CF_AI_AU, CF_EI_EU, CF_PI_PU, CF_SI_SU, and CF_BI_BU at Dataset 2

Full size image
Fig. 19
figure 19
Comparison among CF_CI_CU, CF_AI_AU, CF_EI_EU, CF_PI_PU, CF_SI_SU, and CF_BI_BU at Dataset 3

Full size image
In Figs. 14, 15, 16, CF_BI_BU demonstrates comparatively low RMSE values than the other approaches for all neighbors at all datasets. Figures 17, 18, 19 highlight the comparison among CF_CI_CU, CF_AI_AU, CF_EI_EU, CF_PI_PU, CF_SI_SU, and CF_BI_BU on the basis of precision, recall, F1-measure, and accuracy. It is evident that CF_BI_BU attains better prediction accuracy than others in all datasets and recommendation accuracy further goes in favor of CF_BI_BU. Hence, CF_BI_BU outperforms other similarity functions.

Fig. 20
figure 20
Comparison based on MAE values at Dataset 1

Full size image
Fig. 21
figure 21
Comparison based on MAE values at Dataset 2

Full size image
Fig. 22
figure 22
Comparison based on MAE values at Dataset 3

Full size image
Fig. 23
figure 23
Comparison based on RMSE values at Dataset 1

Full size image
Fig. 24
figure 24
Comparison based on RMSE values at Dataset 2

Full size image
Fig. 25
figure 25
Comparison based on RMSE values at Dataset 3

Full size image
Fig. 26
figure 26
Comparison among CF_BI_BU, CFDR_PC, and CF_ITR at Dataset 1

Full size image
Fig. 27
figure 27
Comparison among CF_BI_BU, CFDR_PC, and CF_ITR at Dataset 2

Full size image
Fig. 28
figure 28
Comparison among CF_BI_BU, CFDR_PC, and CF_ITR at Dataset 3

Full size image
Comparison of CF_BI_BU, CFDR_PC, and CF_ITR
Figures 20, 21, 22, 23, 24, 25, 26, 27, 28 represent the comparison among CF_BI_BU, CFDR_PC, and CF_ITR based on various accuracy metrics at different datasets. From Figs. 20, 21, 22, 23, 24, 25, we notice that in most of the cases, CF_BI_BU has low MAE and low RMSE value as compared to CFDR_PC, and CF_ITR. Figures 26, 27, 28 depict the comparison based on precision, recall, F1-measure, and accuracy at three datasets. Here, CF_BI_BU attains more precision, recall, F1-measure and accuracy than other recently used SMs for all datasets.

Complexity comparison
Table 26 shows the comparison among various CF algorithms based on their computational complexity. Here, m and n denote the total numbers of users and items, respectively.

Table 26 Complexity comparison
Full size table
From Table 26, we observe that CF_BI_BU takes more execution time than other algorithms due to its high complexity.

Hence, through the comparative analysis with various sparse datasets, we can rightly conclude that the CF_BI_BU performs better than other CF algorithms in spite of getting high complexity. However, various e-commerce websites adopt various cloud offerings like Amazon SageMaker, which utilizes libraries for performing the computation on parallel GPU instances. Common cloud offerings for techniques like MapReduce can also be employed to achieve the required parallelism in methods. Therefore, the proposed approach can be implemented in parallel to resolve the scalability issue.

Conclusions
Classical memory-based recommender systems were outmoded by model-based systems in the first place due to their inability to handle sparse datasets and due to inherent drawbacks of traditional similarity measures. Owing to the simplicity, serendipitous nature, and interpretability of memory-based recommendation systems, addressing their key blockers will make them the most attractive approach and open tremendous scope for promising strides. In this paper, the proposed similarity function mitigates the issue related to the sparsity of datasets and factors in different magnitudes of rating vectors. The proposed function first computes the similarity between two users, and then, it utilizes the weight of each user in the calculation of similarity between a target item and other items. The experimental results show that this function outperforms various modified similarity measures and the well-known user similarity function by K. Choi and Y. Suh, in terms of lower MAE and RMSE values and higher precision, recall, F1-measure, and accuracy over MovieLens and Film trust datasets.

The future work may aim to address the chronic cold-start problem, i.e., recommending without a historical record and finding a new similarity measure beyond direction orientation. Furthermore, future work will be focused on parallel and distributed collaborative filtering algorithms to mitigate the scalability issue and to reduce the complexity of the proposed approach.