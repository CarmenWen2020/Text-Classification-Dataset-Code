Shapelet is a discriminative subsequence of time series. An advanced shapelet-based method is to embed shapelet into the accurate and fast random forest. However, there are several limitations. First, random shapelet forest requires a large training cost for split threshold searching. Second, a single shapelet provides limited information for only one branch of the decision tree, resulting in insufficient accuracy. Third, the randomized ensemble decreases comprehensibility. For that, this paper presents Random Pairwise Shapelets Forest (RPSF). RPSF combines a pair of shapelets from different classes to construct random forest. It omits threshold searching to be more efficient, includes more information about each node of the forest to be more effective. Moreover, a discriminability measure, Decomposed Mean Decrease Impurity, is proposed to identify the influential region for each class. Extensive experiments show that RPSF is competitive compared with other methods, while it improves the training speed of shapelet-based forest.

Access provided by University of Auckland Library

Introduction
Time series is being produced every day and everywhere in real world, such as ECG recordings, financial data, industrial observations, etc. Time series classification (TSC) is an important subject in the field of data mining. Unlike general classification tasks, it takes attribute order into account. Recent studies have shown that the 1NN with Dynamic Time Warping (DTW) remains among the most competitive classification approaches [11, 47, 48]. However, this method has drawbacks of high classification time complexity and lacks of interpretability.

Shapelet is the most discriminant, phase independent subsequence in time series [45]. It is interpretable and fast in the classification stage. Since random forest can achieve good performance through integrating a series of modest classifiers [7], the shapelet-based random forest has attracted significant attention and research effort recently. For example, Karlsson et al. [23] introduced a random shapelet forest. It selects both training instances and shapelet candidates randomly. In order to identify important features, a contribution metric Mean Decrease Impurity (MDI) was proposed [21]. Random shapelet forest has also been extended to multivariate time series forest, applied successfully to ECG classification [20] and early classification problem [22]. In addition, Deng et al. [10] introduced a combination of entropy and distance measure to evaluate the node split in the forest. Cetin et al. [8] proposed a shapelet discovery technique that allows efficient candidate evaluation in multivariate time series forest.

However, some limitations exist in the shapelet forest. First, a single shapelet often cannot provide enough information to distinguish different classes. Second, a time-consuming split threshold searching is needed to evaluate candidate shapelet. Third, randomization and ensemble lead to interpretation declining easily.

Fig. 1
figure 1
Left Classic shapelet tree; right Pairwise shapelets tree

Full size image
For these challenges above, this paper proposes a comparison-based ensemble algorithm that combines a pair of shapelets in decision tree node, called Random Pairwise Shapelets Forest (RPSF).Footnote1 Figure 1 compares classic shapelet tree structure with the proposed base model in a simple binary classification task.Footnote2 In the left sub-figure, ‘like’ or not is measured by the distance between instance D and shapelet S. However, the pairwise shapelets tree (as shown in the right sub-figure) asks whether instance D is closer to shapelet S1 or shapelet S2. It is much easier for human beings to give feedback when we do not have enough domain knowledge about the representation of time series data or the distances between data points [14].

RPSF provides more information by combining a pair of shapelets from different classes, which enhances the diversity of ensemble model. In addition, we present an effective metric for identifying influential data series regions (or subsequences) for a specific class. Our main contributions are as follows.

The proposed pairwise shapelets tree extracts discriminant features from two different classes, and each tree node is split according to subsequence distances between instances and the two shapelets. This idea sharpens the contrast between the different two classes. Recent studies also explain the effectiveness and efficiency of comparison-based random forest framework theoretically and practically [14, 36].

RPSF no longer needs to find the split threshold, which saves computing resources. This is especially true when introducing entropy early pruning to speed up [45] (constantly evaluating shapelet under limited information and abandoning apparent inadequate candidates in advance).

The proposed importance measure, Decomposed Mean Decrease Impurity (DMDI), could highlight which parts of the time series contributed the most to a certain class. Figure 2 shows results of MDI and DMDI on ECGFiveDays dataset, both of them point to similar subsequences (the left sub-figure and the class1 of the right sub-figure), while the DMDI indicates additional discriminant interval (the class2 of the right sub-figure) for the other class. This result seems to be in line with the medical conclusion in [33].

Fig. 2
figure 2
Left Mean Decrease Impurity (MDI); right Decomposed Mean Decrease Impurity (DMDI). The right one indicates important features for both classes of ECGFiveDays dataset

Full size image
The remainder of our paper is organized by the following. In the next section, we will discuss about related works. Required preliminaries are described in Sect. 3. Section 4 presents RPSF algorithm in detail. The DMDI method is explained in Sect. 5. In Sect. 6, the experimental setup and results from the empirical investigation are discussed. Finally, main contributions are summarized and future work is discussed in Sect. 7.

Related work
According to the different characteristics of TSC algorithms, we group them as shapelet-based, interval-based, dictionary-based, similarity-based and deep learning methods.

Shapelet-based TSC methods focus on local features that are interpretable and discriminative. They could be divided into two large categories. The first category integrates shapelet selection within the process of constructing decision tree(s). Except for the shapelet-based random forest discussed above, researchers also proposed several single tree-based algorithms, such as the logical-shapelets [32], Symbolic Aggregate approXimation (SAX) representation for fast shapelet discovery [33] and random-shapelet that extracts shapelet to build decision tree randomly [34]. In order to reduce the high time complexity of shapelet discovery, methods based on heuristic gradient decent [13], numerical optimization [16], and local fisher discriminant analysis [50] were introduced to learn discriminative features efficiently.

The second category disconnects the process of discovering shapelets from the classifier by adopting shapelets transformation. For example, Lines et al. [30] proposed the first method that maps the original time series into another data space, where discriminatory features can be detected easily. Then an alternative was presented to reduce similarities of selected shapelets [46], and a speed-up method was introduced to deal with multi-class TSC problems [6]. This idea has also been applied to ensemble classifiers successfully [2].

Interval-based TSC algorithms build classifiers by selecting one or more contiguous subsets of time series data points, or employing the summary measures of intervals. For instance, Time Series Forest (TSF) [10] summaries statistics of each interval as features, then builds random forests based on them. Both Time Series Bag of Features (TSBF) [5] and Learned Pattern Similarity (LPS) [4] extended the original TSF by introducing bag of features or changing the previous decision trees to regression ones.

Dictionary-based methods involve frequency counts of recurring patterns for classification. Bag-of-patterns (BOP) representation [28] is a dictionary classifier that employs SAX to form count histograms. SAX and Vector Space Model (SAXVSM) [39] is an extension of BOP that includes the vector space model commonly used in information retrieval. Classic Fourier coefficients that combined with the BOP model are considered as the state-of-the-art algorithm for TSC [37, 38].

Different from previous introduced three types of methods, similarity-based methods deal with the whole series instead. DTW is a primary sequence alignment method, and there exist several ways to improve it. Traditionally, we can add constraints to prevent the matching path from being too distorted [17, 35], try to increase the quality of alignment by including global/local weights [19, 47], first-order derivatives [24], local shape features [52], and correction factors [3]. Apart from these methods for sequence alignment, researchers also proposed other measures like Time Warping Edit (TWE) [31], Move-Split-Merge (MSM) [42], and so on.

Convolutional neural networks (CNN) that play an important role in the computer vision community has also been widely considered for TSC problems recently. For example, Time LeNet (t-LeNet) was presented first to apply CNN on time series [26]. Then, a multi-scale CNN (MCNN) is proposed to train CNN based on extracted subsequences [9]. Moreover, classic methods like multi-layer perceptron (MLP), fully convolutional neural network (FCN), and residual network (ResNet) are successfully applied on time series [44]. Zhao et al. [51] proposed the Time-CNN that employs mean squared error for adapting the characteristics of time series. Other neural networks include the time warping invariant Echo State Network [43] that directly uses the original time series for classification, and an encoder algorithm combining attention layers [40]. A more detailed review could be found in [12].

Definition and notation
In this section, some relevant definitions of this study will be introduced. Table 1 summarizes the notations of this paper, and we expand on the definitions below.

Table 1 Symbol table
Full size table
Suppose we have a set of n time series, D={T1,T2,…,Tn}, where each time series has m ordered real-valued observations and a class value c, Ti={ti1,ti2,…,tim,ci}. The objective is to construct a function that maps the observations of a time series to a possible class value. Note that, we assume that all time series have the same length (and with fixed time intervals) for simplicity and computational consideration.

Definition 1
Time series subsequence and shapelet.

A time series subsequence Si,q={ti,ti+1,…,ti+q−1} is a continuous subsequence of T starting at position i with length q, where 1≤i≤m−q+1. Notice that data points t1,t2,…,tm are arranged by temporal order with fixed time intervals. Time series subsequence could be considered as the local properties of a time series, while shapelet is one of the most discriminative subsequences.

Definition 2
Distance and subsequence distance.

For two given time series X and Y of the same length m, normally their differences are measured by the length-normalized Euclidean distance (As shown in Eq. 1). Note that, both X and Y must be z-normalized to make meaningful comparisons, and to avoid scale and offset variance.

dist(X,Y)=1m∑mi=1(xi−yi)2−−−−−−−−−−−−−−−√.
(1)
For the pairwise shapelets tree ST, it is required to calculate the similarity between a short subsequence and a much longer time series. For that, the shorter one must slide against the longer one to achieve the best possible alignment. The subsequence distance is defined as:

subdist(X,Y)=min(dist(X,Y|X|)),
(2)
where Y|X| represents subsequence of Y with length |X|, and what the function subdist() achieved is the minimum distance between two time series.

Definition 3
Shapelets pair.

A pair of shapelets is a tuple (S1,S2), where both S1 and S2 are shapelets. A shapelets pair divides the dataset D into two disjoint subsets D1={X:X∈D,subdist(S1,X)≤subdist(S2,X)}, and D2={X:X∈D,subdist(S1,X)>subdist(S2,X)}. Shapelets pairs are used as tree nodes to construct decision trees and the random forest in this paper.

Definition 4
Entropy.

Assume that we have a dataset D of N time series from |c| different classes, every class ci has ni (n1+n2+⋯+n|c|=N) labeled instances in the dataset. The entropy of D is

E(D)=−∑|c|i=1niNlog(niN).
(3)
Definition 5
Information gain.

The information gain of a shapelets pair (S1,S2) is

I(S1,S2)(D)=E(D)−|D1||D|E(D1)−|D2||D|E(D2).
(4)
Although other quality measures are available, information gain is preferred to evaluate the discriminative power of each shapelets pair.

Definition 6
Separation gap.

The separation gap of a shapelets pair (S1,S2) is

G(S1,S2)=1|D|∑i|subdist(S1,Di)−subdist(S2,Di)||S1|+|S2|−−−−−−−−√.
(5)
It represents the average of differences between the subsequence distance of the left side of a tree node and that of the right side.

Note that, when we compare two pairs of shapelets, the one has greater information gain is selected. If their information gains are equal, the one has the maximum separation gap is chosen. If their separation gaps are also the same, we choose the relatively shorter one. However, if their lengths are equal, the one that appeared earlier is the answer. In other words, we break ties by maximizing the separation gap and minimizing the length of the shapelets pairs.

Random pairwise shapelets forest
RPSF is an ensemble model built by multiple pairwise shapelet-based trees, we will provide a detailed elaboration to the proposed algorithm in this section.

Intuition for pairwise shapelets
The shapelet-based decision tree makes prediction according to the subsequence distance between shapelet S and instance D. If D is similar to S (the subsequence distance is less than the split threshold) from a specific class, it is assigned to that class, or to other classes. However, similarity with features (shapelet) from only one class cannot accurately characterize discriminative information in the data. Just as each branch of a traditional decision tree indicates the corresponding split attribute value, it is meaningful to identify the intuition of each branch of the shapelet-based tree. Under this notion, we propose the idea of combining a pair of shapelets from different classes to construct a decision tree, so that ‘like and not like’ becomes ‘like S1 or like S2’ (as shown in Fig. 1). A decision can be made according to distances to the two shapelets in the pair rather than distance to a single one and a threshold. It improves the accuracy of the classifier due to the additional information. Besides, the diversity of the ensemble model can be enhanced since a pairwise combination has more possible candidates than single ones. In addition, the pairwise-based method has an advantage in terms of training time. The split threshold searching, which is time-consuming, is omitted because of the combination. This is especially true with the introduce of entropy early pruning, where the previously calculated distance information can be reused, but the split threshold, which is avoided by RPSF, must be recalculated each time.

Proposed algorithm
RPSF trains a set of trees by considering several parameters: the shapelet length interval [l, u], the number of decision trees p, and the number of candidate shapelets pairs in tree node r. For the construction of each pairwise shapelets decision tree, |D| time series are sampled using the traditional Bootstrap approach. The main steps to learn the RPSF can be summarized as follows.

Initially, |D| sampled instances are extracted from the training set D randomly.

Shapelets are extracted randomly from two random different classes r times to form the candidate shapelets pairs S. The lower bound length is l, while the upper is u.

Estimate the best shapelets pair (S1, S2) as a split node according to information gain and separation gap, and it divides the original set into two parts, D1 and D2 separately.

Recursive steps 2 and 3 until a random pairwise shapelets tree is built.

Iterate steps 1 to 4 until p pairwise shapelets trees are built to construct a random forest.

figure f
Algorithms 1 - 4 describe the constructing process in detail. Algorithm 1 provides a brief overview of creating a random pairwise shapelets forest R. First, bootstrap sample is employed to pick instances from the training set D (line 2). Then, a random pairwise shapelets tree STi is built based on sampled Di and the corresponding parameters (line 3, as shown in Algorithm 2). This process iterates until the number of needed trees is satisfied (lines 1–5).

figure g
Algorithm 2 shows the process of building each pairwise shapelets tree. At the beginning, the creation of leaf nodes is determined according to the purity of data (if entropy < 0.1 or not) (lines 1–3). Then subsequences are extracted randomly for r times from two random classes to form a candidate set. To be more clear, we first select two random different classes, then two lengths and starting points are randomly chosen to form a pair of shapelets (lines 4–7). After that, we assess candidates and find the best pair (line 8, details in Algorithm 3 and 4). The best pair (S1,S2) splits the dataset D to two subsets D1 and D2. The distances between a training instance Di and (S1,S2) are named as d1, d2. If d1 is less than or equal to d2, it means that Di is closer to S1, and it is added to D1, otherwise, added to D2 (line 9). Finally, the algorithm recursively calls itself on D1 and D2 to construct subtrees (lines 10–11).

The number of candidate shapelets in a dataset consisting of n instances of length m and possible shapelet candidate lengths interval [l, u] is equal to

r=(∑i=lum−i+1)∗n∗percentage.
(6)
where percentage means that a part of the candidates are sampled to build trees. For our method, the two shapelets must come from different classes, and the number of class labels |c| and its corresponding instances vary a lot for different dataset. Here we assume that the number of instance for each class is the same, which will be n/|c|. Indeed, we have  combinations. The number of possible candidate pairwise shapelets for each node should be

	(7)
It is clear that Eq. 7 cannot provide a stable value for experiment. When compared with gRSF, Eq. 6 is adopt for simplicity and fairness. Moreover, ignoring the subsequence distance consumption, the time complexity for each pairwise shapelets tree is O(nrlogn), where logn is the average depth of the decision tree. When p trees are built, the time complexity of RPSF will be O(pnrlogn).

figure h
figure i
As shown in Algorithms 3 and 4, information gain and separation gap are typically used when shapelet assessment is needed. For a normalized shapelets pair (S1,S2) (Algorithm 3, line 3), we try to split training data by calculating the subsequence distance between training instance and (S1,S2) separately, and assigning each instance to its closer side (Algorithm 4, lines 2–10, similar with splitting process in the previous paragraph). When this process completed, information gain and separation gap can then be calculated to measure its quality (Algorithm 4, lines 11–12). A pair with greater information gain and separation gap is considered preferentially (Algorithm 3, lines 7–8). Entropy early pruning is also introduced in this process to abandon apparently inadequate candidates [45].

After training, each internal tree node consists of a shapelets pair (S1,S2) and the left, right subtree. The leaf node records the class value. To classify a test instance T, we begin from the root node. If the distance between T and S1 is less than that of T and S2, the left subtree is recursively used. Otherwise, the right one is traversed. The process repeatedly runs until it reaches a leaf node and gets a prediction. The final result is obtained by the majority voting of p trees. Indeed, the time complexity of the test process is O(plogn), where p is the ensemble size, logn represents the average depth of the decision trees.

Decomposed mean decrease impurity
This method evaluates the importance of each time series attribute for each class and considers those with higher scores to contribute more for classification. Existing MDI provides only a global score, which is determined by its tree structure [8]. On the contrary, the proposed pairwise format allows us to identify discriminative regions of different classes.

We decompose the information gain of each node according to shapelet’s contribution (Eq. 9), then add it to attributes that form the shapelet. For shapelets pair (S1,S2), if the dataset attracted by shapelet S1 causes greater entropy reduction (Eq. 10), it is assumed that S1 contributes more than S2. The contribution of shapelet for different classes should be accumulated, respectively. Based on the above idea, we define the Decomposed Mean Decrease Impurity (DMDI).

Given a pairwise shapelet forest R={ST1,ST2,…,STp}, where ST is a pairwise shapelet tree. Each node of the tree corresponds to a shapelets pair (S1,S2). Given a training set D with series length m, for time series attribute k and class c, DMDI(k, c) is defined as follows.

DMDI(k,c)=∑p(∑node(k∈S1∧class(S1)=c)CV(node,S1)+∑node(k∈S2∧class(S2)=c)CV(node,S2))
(8)
where CV is the contribution value of one shapelet. It is obtained from the decomposition of the total information gain of the node. Let the input dataset to a node be D0, the datasets obtained by dividing the D0 are D1, D2, then

CV(node,Si)=ER(node,Si)ER(node,S1)+ER(node,S2)∗I(S1,S2)(D0)
(9)
where I(S1,S2)(D0) is the information gain of the tree node, and

ER(node,Si)={E(D0)−E(Di),0,ifE(D0)>E(Di);otherwise.
(10)
where E(D) is the entropy of D, i equals to 1 or 2, ER(node,Si) is the entropy reduction caused by a shapelet. We cannot guarantee that ER is positive. It is set to zero in a negative case. If the two terms in the denominator are both zero, the node is discarded.

For every class, DMDI searches all nodes that embed a shapelet from it, decomposes the information gain of these nodes, and adds the contribution of shapelet to attributes forming it. Eventually, we recognize which attributes in the sequence contribute more for a particular class.

Experiment and evaluation
In this part, we first describe the datasets used to conduct our experiments, and then outline the parameter setting, before evaluating the performance of the proposed RPSF algorithm in terms of accuracy and time consumption.Footnote3

Datasets and parameter settings
Experiments are conducted on UCR/UEA datasetsFootnote4 that are widely used in studies on a 3.40 GHz Intel Core i7-6700 PC machine with 16 Gigabytes main memory. In order to build the forest and due to the computational reason, we discard datasets that cannot finish 10 times running in 120 hours. In addition, the predefined splits are employed for experiments. The RPSF model is built on bootstrapped training set, and its accuracy is recorded on the test set. For the proposed RPSF, there are three factors that strongly determine its efficiency and effectiveness, the number of pairwise shapelets trees p, the minimum and maximum length of shapelets (represented by l and u separately), and the number of random candidate shapelets pairs r for each split node. Note that, for the parameter validation, five datasets with comparatively larger test instances are chosen. We tried to select parameters based on the out-of-bag (OOB) error rate in the beginning. However, the OOB error rates we got are mostly equal to 0, no matter how we vary the ensemble size, the length of shapelets or the percentage of shapelets pairs. To illustrate the effect of parameters better, we evaluate them on the sampled training set, and report the error/accuracy on the test set directly.

Fig. 3
figure 3
Accuracy of RPSF when the number of classifiers p varies from 10 to 100

Full size image
We initially studied the impact of the number of integrated models p on the classification accuracy, increasing from 10 to 100. As shown in Fig. 3, the minimum and maximum length ratio (compared with the whole length m) is set to 0.25 and 0.67 independently, and r is set to 1% of all candidate shapelets.

It is widely accepted that the ensemble averaging reduces the variance of base models and improves the generalization behavior. Figure 3 is in accordance with this theory, and all the accuracy curves show an upward trend or fluctuate in a small range with the rise of p. However, since the time consumed increases linearly, we need to find a trade-off between accuracy and computation. It is visible that the improvement of accuracy after p=50 is not obvious (e.g., datasets TwoLeadECG and Symbols), p=50 is set as the real experimental parameter for the following experimentations thus accordingly.

Fig. 4
figure 4
Accuracy of RPSF when the shapelet length interval varies

Full size image
For the shapelet lengths l and u, we fix the interval to 30% of the time series length, that is, (u−l)/m=0.3, and the average of these lengths (e.g., (l+u)/2m) keep changing from 0.15 to 0.85 when sliding the window. Note that the 30% length interval is relatively small, which makes the fluctuation of accuracy more sensitive to the sliding window. r is set to 1% of all candidate shapelets, and p=50 for this analysis.

The experimental results are shown in Fig. 4. The curves present several different trends. For datasets that are similar globally, and small local dissimilarities exist among different classes (e.g., CBF, Symbols, and MoteStrain), their accuracies decrease at first, and then climb up. The performance of TwoLeadECG keeps decreasing with the rise of average length, indicating that its two classes could be easily distinguished by local features. For dataset FacesUCR, it is lower at both ends and higher in the middle, meaning that relative long or short searching space cannot guarantee acceptable accuracy. Indeed, getting the optimal parameters of length depends on different personalities of datasets.

Fig. 5
figure 5
Accuracy of RPSF when the number of selected shapelets for splitting varies from 0.2 to 3 (in percentage)

Full size image
For the following experiment, we increase the number of candidate shapelets from 0.2% to 3% of the total extracted ones, observing the classification accuracy under different conditions. The ratio of shapelet interval is set as [0.25, 0.67], and the number of pairwise shapelets trees is set to 50.

The number of pairwise shapelets r represents the randomness of the ensemble model. The smaller the r, the greater the randomness of the model RPSF. If only one pair of shapelets is extracted, the algorithm is completely random. If all possible shapelet pairs are considered, the model is totally deterministic. Figure 5 depicts the experimental results. Accuracy curves show that our model is robust to the number of shapelets. The reason may lie in that the random strategy avoids over-fitting, and the ensemble improves generalization.

In a nutshell and for simplicity, shapelet length interval of gRSF and RPSF are set to 25% to 67% of the total length of corresponding time series, which covers a larger range and is a relatively safe value. The number of decision trees is set to 50. r is set to 1% of the possible candidate shapelets. Besides, the results are achieved on an average of ten runs.

Predictive performance
In this section, we demonstrate that RPSF is competitive in terms of classification accuracy contrast to state-of-the-art algorithms. First, the proposed method is compared with other local feature-based methods. Second, comparisons with other distance-based (global similarity) approaches are presented. Last but not least, RPSF is compared with other ensemble and deep learning alternatives.

Compared with shapelet-based/dictionary-based/interval-based benchmark classifiers
Several benchmark algorithms, from shapelet-based or dictionary-based to interval-based ones, are used for comparisons in this section. For example, FastShapelet (FS) refers to the decision tree algorithm proposed in [33] where getting the approximate shapelet quickly through SAX representation [27]. Learning time-series shapelets (LTS) is an algorithm proposed in [13] that searches shapelet by using optimization approach. BOP [28] and SAXVSM [39] are considered as the dictionary-based benchmarks. For forest-based classifiers, gRSF is the state-of-the-art shapelet-based random forest [23]. Interval-based classifiers, like TSF [10], TSBF [5] and LPS [4], also ensemble decision or regression trees for classification.

Fig. 6
figure 6
Accuracy comparison between RPSF and other shapelet/dictionary/interval-based classifiers

Full size image
Fig. 7
figure 7
Critical difference diagram for the average ranking comparison among RPSF and other shapelet/feature-based single/ensemble classifiers

Full size image
Figure 6 depicts the accuracy comparison peer-to-peer visually and areas below the diagonal line indicate that RPSF is better. W/D/L and the numerical numbers below represent the number of Win/Draw/Loss between the two compared methods. More details are shown in Table 2.Footnote5 It is clear that our method shows outstanding performance. For the single shapelet/dictionary-based methods, RPSF beats FS, LTS, BOP and SAXVSM on 50, 31, 49, 44 out of 59 datasets, respectively. As we can see from the lower triangular area of Fig. 6, points far away from the diagonal line indicate that RPSF shows overwhelming superiority on these datasets. For example, it is 20.8% higher than the LTS on the OliveOil dataset, and 20.7% higher on the Wine dataset. When compared our method with shapelet/interval-based ensemble classifiers, it beats the gRSF on 40 out of 55 datasets and outperforms other interval-based forests on more than one half of the tested datasets.

Table 2 Classification accuracy of RPSF compared to shapelet-based methods and other random forests
Full size table
Figure 7 gives the critical differences diagram for the accuracy of individual algorithms (α=0.05). RPSF is definitely the one with the lowest (best) ranking. It is also significantly better than FS, BoP, and SAXVSM. The data are not sufficient to conclude whether LTS, LPS, TSBF, gRSF, and TSF perform the same as RPSF or SAXVSM, and similarly, whether SAXVSM is equivalent to FS and BoP or to the better five methods.

Compared with distance-based benchmark classifiers
The nearest neighbor classifier based on Euclidean distance (ED) is a widely-used benchmark whose performance can be improved by DTW. In order to improve the similarity measure, lots of advanced approaches are proposed. For example, Derivative Dynamic Time Warping (DDTW) [25], globally Weighted Dynamic Time Warping (WDTW) [19], Complexity-invariant DTW (CID) [3], Locally Weighted DTW (LWDTW) [47], shape Dynamic Time Warping (shapeDTW) [52], etc. Moreover, researchers also try to import other elastic distance measures to time series, the successful ones include the Time Warp Edit distance (TWE) [31], Longest Common Subsequence (LCSS) [18], and the Move-Split-Merge metric (MSM) [42].

Fig. 8
figure 8
Accuracy comparison between RPSF and other distance-based classifiers

Full size image
Fig. 9
figure 9
Critical difference diagram for the average ranking comparison among RPSF and other distance-based classifiers

Full size image
For these comparisons, the results of LWDTW and shapeDTW are obtained from the original paper, others are picked up from [1] for simplicity. As shown in Fig. 8, our method is obviously superior to the nearest neighbor classifier on the vast majority of datasets. Especially for the sub-figure of RPSF vs. shapeDTW, there are three points apparently far away from the diagonal line, meaning that RPSF is 24.4%, 20.3%, and 20.2% higher than the alternative on datasets Ham, InsectWingbeatSound and Wine, respectively.

For the critical difference of the average ranking (as shown in Fig. 9), the proposed approach again achieved the first place among 11 classifiers. Figure 9 also indicates that RPSF performs significantly better than ED, DDTW, and DTW. The main advantage of distance-based methods lies in its effectiveness and efficiency. However, our RPSF is not only accurate, it can also be sped up easily using parallel/multi-core computing, details will be discussed in Sect. 6.3.

Compared with other ensemble benchmark classifiers
Ensemble classifiers combine multiple classification algorithms to obtain better predictive performance. For time series, apart from the forest-based methods introduced previously, other benchmark ones include the Collective of Transformation-based Ensembles (COTE) [2], Bag of Symbolic Fourier Approximation Symbols (BOSS) [37], Elastic Ensemble (EE) [29], and the Shapelet Transformation (ST) [15] combined with random forest (with 500 trees), rotation forest (with 50 trees) and other basic classifiers like SVM, Naive bayes etc.

Fig. 10
figure 10
Accuracy comparison between RPSF and other ensemble classifiers

Full size image
Fig. 11
figure 11
Critical difference diagram for the average ranking comparison among RPSF and other ensemble classifiers

Full size image
As shown in Figs. 10 and 11, although our method is worse than COTE, it is competitive with ST, BOSS, and EE. In addition, RPSF just consists of 50 pairwise shapelets trees, it is far less than the number of classifiers contained in ST (more than 500 ones) and BOSS (normally equals to m−10). COTE involves classifiers constructed in the time, frequency, change, and shapelet transformation domains, while our method only involves time domain. EE combines multiple advanced distance measures discussed in last section (such as LCSS, TWE, MSM, WDTW, and so on).

Compared with deep learning benchmark classifiers
Deep neural networks are considered widely in recent years to perform time series classification. We tried to compare RPSF with the nine deep learning benchmark classifiers mentioned in [12]. They are MLP, FCN, ResNet [44], Encoder [40], MCNN [9], t-LeNet [26], Multi Channel Deep Convolutional Neural Network (MCDCNN) [53] , Time-CNN [51], and Time Warping Invariant Echo State Network (TWIESN) [43]. As shown in Fig. 12, it is clear that, except FCN and ResNet, our method beats other deep learning classifiers on at least three-quarters of the total datasets.

Fig. 12
figure 12
Accuracy comparison between RPSF and deep learning classifiers

Full size image
Fig. 13
figure 13
Critical difference diagram for the average ranking comparison among RPSF and deep learning classifiers

Full size image
The analysis in Fig. 13 reveals that RPSF performs significantly better than Time-CNN, MLP, TWIESN, MCDCNN, MCNN, and t-LeNet. The data are not sufficient to conclude whether RPSF performs the same as Encoder or to the better two methods FCN and ResNet.

Computational performance
In this section, the time scalability of RPSF is analyzed at first, then we will describe the significant increase in time performance due to the omission of split searching. Note that RPSF approach is easy to parallelize, several times of further acceleration can be achieved using parallel computing.

Time scalability
There are two factors that affect the time scalability of RPSF, the number of instances in the training set N, and the length of time series m. First, datasets Wafer and StarLightCurves that consist of 1000 training instances are employed. Second, datasets Mallat and BeetleFly with relatively larger number of attributes are selected. N and m are sampled randomly, and the sampling rate varies from 30% to 100%. Figures 14 and 15 show their wall clock time separately. It is easy to find that RPSF increases approximately linearly with the inflation of N and quadratically with m. These help us to make sure that the proposed algorithm has strong practicability.

Fig. 14
figure 14
Time scalability with respect to the training size

Full size image
Fig. 15
figure 15
Time scalability with respect to the length of time series

Full size image
Fig. 16
figure 16
Relative time consumption of FS, LTS, and gRSF compared with RPSF

Full size image
Versus other algorithms
We compare RPSF with other shapelet-based time series classification algorithms in terms of training time. Figure 16 shows boxplots of the relative time consumption using RPSF as benchmark to make it more intuitive. The dashed bold line indicates the time consumption of RPSF. FS is faster than other methods, which is the major advantage of this approach. RPSF is significantly better than LTS on the vast majority of datasets. It even appears tens of times faster on some datasets. It is also noticeable that gRSF is slower than RPSF on almost all datasets. This result verifies our idea of omitting the calculation of the split threshold for time saving. In the next part, we will discuss it further.

Stage analysis
This part divides RPSF and gRSF into two main stages and analyzes the time consumption of them. We will show that eliminating split threshold indeed saves computation resources.

The decision tree of RPSF combines a pair of shapelets while gRSF is based on a single one. In terms of time, the main difference is that while assessing candidates, on the one hand, RPSF needs to calculate subsequence distances between two shapelets and all training instances, which is twice as much as that of single shapelet-based method; on the other hand, in the process of evaluating a single shapelet, a split threshold needs to be found. This is avoided by RPSF. Note that with entropy early pruning [45], threshold searching will be executed multiple times during candidate assessment, while subsequence distance will only be calculated once since its information can be reused. This expands the advantage of RPSF. A toy example is shown in Fig. 17.

Fig. 17
figure 17
Split point searching for single candidate shapelet and pairwise shapelets (a toy example)

Full size image
As shown in Fig. 17a, for each candidate shapelet, subsequence distance between each instance and S is calculated and mapped on an orderline. Then every possible split point between each two objects is tested to find the optimal one (as indicated by the dashed vertical lines). After testing all the candidates, we pick the one achieving the best utility as the split node of decision tree.

For the pairwise shapelets (S1, S2), each instance should be compared with each shapelet in the pair. However, all the instances are divided into two clusters naturally (as shown in Fig. 17b). If it is closer to S1, it belongs to the left part, otherwise the right. Indeed, we do not have to find the optimal split point for the pairwise shapelets.

Table 3 depicts the average running time in different stages and the average depth on several datasets. Although the depth of RPSF is either equal to or slightly greater than that of gRSF, the total training time is significantly smaller. On relatively small datasets, such as Coffee and FaceFour, the distance computation of RPSF consumes approximately twice as much as that of the gRSF. However, the time consumption of information gain on RPSF is obviously less than gRSF, and there is no doubt that RPSF is generally more efficient than gRSF, especially on relatively larger datasets (such as InsectWingbeatSound, Beef, SyntheticControl and Wine).

Table 3 Average depths and running time (in seconds) in different stages of gRSF and RPSF
Full size table
Case study
As discussed in Sect. 5, the DMDI provides an importance score for identifying influential time series regions. We briefly show the profit of DMDI on the ECGFiveDays dataset previously. More detailed synthetic and real-world examples will be included to demonstrate the usefulness of our proposed method in this section.

BME
The first row of Fig.18 shows the profile of some time series of Begin, Middle, and End classes of the synthetic dataset BME. For the time series of Begin class, the small bells arising at the initial period. For the time series of End class, the small bells arising at the final period, while only large up bells exist for the Middle class. The second row of Fig. 18 presents the DMDI values for each class. We can see that the learned scores succeed to localize the discriminative periods of the ground truth by achieving relatively higher scores during the beginning (ending) parts of the Begin (End) class. For the Middle class, the highest DMDI score appears in the middle parts, indicating the difference that large up or down bells arising in other classes.

Fig. 18
figure 18
DMDI for BME dataset

Full size image
GunPoint
GunPoint is a dataset that has been studied extensively in literature. The 150-length dataset describes the action curves of actors with or without a gun when making a motion (as shown in Fig. 19). The DMDI measure applied on this dataset is shown in the second part of Fig. 19. It is clear that the importance scores of the two classes arrive at their highest value near time stamps 100–120, and the score of Gun reaches a local peak among the indexes 40–60. These results are similar to the outcome of [45, 49].

Fig. 19
figure 19
DMDI for GunPoint dataset

Full size image
ArrowHead
ArrowHead is a multi-class dataset with 251 attributes. It can be divided into three classes according to their place, age, and the race belonged: Avonlea, Clovis, and Mix. Figure 20 briefly depicts these outline series on the top three sub-figures, while our DMDI scores on the bottom three. According to the importance score, the most significant area to distinguish Clovis with others lies near time stamp 125, and the other two locate at 160 and 90 separately.

Fig. 20
figure 20
DMDI for ArrowHead dataset

Full size image
Conclusion and future work
In this paper, we present an effective and efficient random forest combining shapelets from different classes randomly. The model diversity and classification accuracy are enhanced by including more information in a node. Due to the fact that pairwise shapelets do not have to search the split threshold, the time consumption is optimized. In addition, a novel importance measure DMDI is proposed to evaluate the contribution of each attribute to identify a certain class. Extensive experiments and case studies show that our method outperforms state-of-the-art random shapelet forest. Although the random combination presented is powerful, it is still relatively time-consuming. Trying to include a more sophisticated combination to further enhance the performance of random forest will be the focus of future work.