Most existing algorithms of anomaly detection are suitable for static data where all data are available during detection but are incapable of handling dynamic data streams. In this study, we proposed an improved iLOF (incremental local outlier factor) algorithm based on the landmark window model, which provides an efficient method for anomaly detection in data streams and outperforms conventional methods. What is more, data windows as updating units are introduced to reduce the false alarm rate, and multiple tests are taken here to identify candidate anomalies and real anomalies. The improved iLOF shows its obvious advantage with its false positive rate. Furthermore, the proposed algorithm instantly deletes data points of identified real anomalies. We analyzed the performance of the improved algorithm and the sensitivity of certain parameters via empirical experiments using synthetic and real data sets. The experimental results demonstrate that the proposed improved algorithm achieved better performance on the higher detection rate and the lower false alarm rate compared with the original iLOF algorithm and its improvements.

Access provided by University of Auckland Library

Introduction
In data mining, anomaly detection is increasingly important. Unlike other data mining techniques, the purpose of anomaly detection is to identify rare events that are inconsistent with the usual pattern in a dataset. These rare events, often called outliers or anomalies, occur at low frequencies ranging from around 5% to < 0.01% depending on the context [31]. The effects of anomalies are often threatening in certain applications. Detecting anomalies quickly has a positive effect on maintaining safety and preventing risks, so compared with the general situation, outliers need more attention and anomaly detection is important. Moreover, anomaly detection has been extensively used in fields such as network intrusion [13], fraudulent transactions [39], and medical anomaly detection [9].

Anomaly detection methods are categorized into supervised and unsupervised learnings. To learn general characteristics of normal points, supervised methods require pre-labeled training data [45], and they have two inherent limitations [31]: pre-labeled data are not easy to obtain and detecting new outlier types is difficult. In reality, anomalies often do not have a uniform pattern and, in a constantly changing data stream, even normal behaviors may change. Therefore, the model obtained from the pre-labeled training samples possibly fails. However, unsupervised learning methods can overcome these limitations because they do not require pre-labeled data and detect outliers that are considerably different from normal data by measuring distance, similarity, and density between samples. Among unsupervised anomaly detection techniques, the local outlier factor (LOF) algorithm is popular and extensively used [7], and the application of the algorithm has yielded results in various fields [25, 30]. Furthermore, many researchers proposed improvements on it to improve its accuracy and computational efficiency.

However, most anomaly detection methods apply to static data sets which have stored all data records before detection, although in reality a lot of data are obtained in data streams. Streaming data, time series data and sequential data are all temporal data, and temporal outlier analysis examines both point outliers and consecutive outliers in the behavior of the data across time [4, 15]. However, most anomaly detection techniques for time series and sequential data are static models using given data sets [1, 14], and simply applying models periodically with windows, which affects the efficiency [33]. Data streams are constantly and rapidly changing with the arrival of new data over very short time, and continuous flowing may lead to unlimited data scale [15], e.g., in video surveillance, new video and image information is constantly generated over time [29]. Therefore, static and inefficient methods are not suitable for anomaly detection in data streams. Instead, anomaly detection for data streams needs real-time and online analysis in a dynamic and complex environment. These requirements and characteristics increase the difficulty of anomaly detection techniques and are a challenge for research. Pokrajac et al. [31] firstly proposed the incremental LOF (iLOF) algorithm suitable for data streams, which considered the local influence of new insertion data points. Several researchers improved efficiency or accuracy of the algorithm [19, 34], but still ignored some problems such as high rate of false positives and losing old information.

To enhance the performance of the algorithm, this study proposes an improved iLOF with the landmark window model (LWM). The proposed method maintains the incremental algorithm’s high computational efficiency and improves the accuracy of anomaly detection in data streams by increasing the rate of true positive (TP) and decreasing FP rate. The innovation of the improved method includes: (1) introducing the landmark window and using basic windows as updating units rather than a single data point, which helps to identify abnormal patterns and new normal patterns, thus reducing the FP rate; (2) performing multiple tests and using an adaptive threshold to identify outliers and differentiating “candidate anomalies” and “real anomalies” to avoid misinterpretation of points near window edges and sparse points of new normal behavior; and (3) instantly deleting identified abnormal points to prevent them from clustering and causing interference. Experiment results show that compared with original methods, the improved algorithm has better performance on anomaly detection for data streams.

The remainder of this paper is organized as follows. We discussed related works in Sect. 2 and introduced the LOF algorithm and the incremental LOF (iLOF) algorithm in Sect. 3. In Sect. 4, our improved algorithms were discussed in detail with analysis. In Sect. 5, we conducted experimental studies using simulated and real-life data and compared the results of our algorithm with the original algorithm. Finally, conclusion and future work are summarized in Sect. 6.

Related work
Anomaly detection techniques are categorized into four groups: (1) statistical; (2) cluster-based; (3) model-based; and (4) distance-based methods. In terms of statistical approaches [5, 40], the random distribution of data sets is necessary to build a probability model; however, this is difficult to achieve in reality. Using unsupervised learning, cluster-based methods classify points far from normal clusters and very small clusters as anomalies [12, 17, 41]. Some studies integrated several clustering methods to identify outliers [35]. The model-based methods primarily build a model for normal points using either supervised or unsupervised learning, which is then used to predict whether a data point belongs to the normal category. For example, to identify outliers in large multivariate data, Hawkins et al. [16] used an iterative neural network model. Note that distance-based methods, which do not need to know the distribution of data sets, are simple and intuitive. They detect outliers based on full-dimensional distances among points [45]. These methods are divided into “global methods” and “local methods,” and local methods are known as density-based methods. Knorr and Ng [20] were the first to define the distance-based global outlier. Aggarwal and Yu [2] used the distance-based method to mine abnormal points of high-dimensional sparse data set by learning the behavior of data set projections. Ahn et al. [3] proposed the distance-based outlier detection for high dimension and low sample size data motivated by asymptotic properties of high-dimensional distance measures. Despite the advantages of distance-based global methods, they fail to detect outliers in non-homogeneous densities. However, density-based methods can be used in such situation.

The local outlier factor (LOF) algorithm proposed by Breunig et al. [7] is an important and widely used density-based method. It assigns the Local Outlier Factor (LOF), a measure of being an outlier, to each data in a static environment and identifies anomalies. Because the LOF technique achieves good detection accuracy in non-homogeneous densities without assumptions about the underlying distribution of data sets, it has become a popular approach and many researchers have worked on improving the technique. Liu et al. [26] proposed a fast detection algorithm for top-n local outliers based on density and then designed multi-granularity pruning by combining index structure and multiple LOF boundary values, which improved the algorithm’s speed. Furthermore, multiple variants of the LOF algorithm have been proposed. Tang et al. [38] changed the calculation method of k-nearest neighbors and proposed an anomaly factor based on connectivity, which improved detection accuracy. To reflect the probability of a point being an outlier, Kriegel et al. [22] used the mean of the sum of distance squares between a point and its k-nearest neighbors to represent the local density and assigned an outlier score of [0,1] to each point. Yu et al. [42] compared the relationship between a point and its neighbors, as well as the relationship between neighbors rather than comparing the relative density between points and detected local anomalies in the classified space. Sun and Chawla [37] provided a measure of spatial local outliers, which can identify spatial local outliers. Zhang et al. [44] used the mean distance of a sample point to its k-nearest neighbors to represent its local density. Schubert et al. [36] proposed the simplified-LOF method using k-distance to replace the reachability distance; the obvious limitation of it is that the result is strongly dependent on k. Furthermore, Liu and Deng [27] extended local anomaly detection to uncertain data represented by probability density.

However, the LOF algorithm and its improved methods are primarily applicable to static data sets. Many environments generate complex and dynamically changing data streams that have a large amount of data; researchers cannot obtain the entire data set before detection. Although static LOF algorithm can be applied to data streams by certain techniques, they all have some disadvantages. Pokrajac et al. [31] improved the LOF algorithm and proposed an incremental LOF (iLOF) algorithm for data streams. This algorithm only focuses on k-nearest neighbors, reachability distances, and LOF values affected by the new incoming point or old deleted points; the algorithm does not need to consider all existing points in the data set. The incremental method saves the computational cost and realizes the dynamic update of the existing data information. Compared to static method, it achieves improved results in the anomaly detection for data streams. Summarizing and clustering old data, Salehi et al. [34] improved memory efficiency based on the iLOF algorithm and enhanced the ability to process large amounts of data. However, because they detect every single point once it enters the data set, the iLOF algorithm and its improvement have a relatively high false-positive rate. Furthermore, normal patterns change in data streams. If each changed point is detected as soon as it reaches the data set, it is possible to misidentify the new normal points as outliers. To solve this problem, Karimian et al. [19] introduced a sliding window and reduced the number of normal points determined as abnormal points. However, the limitation is that some old points are deleted, which results in the problem of distinguishing new from old behaviors. This may reduce the accuracy rate of anomaly detection for newly entering points [34]. Moreover, the sliding window ignores the problem of the points at the end of the window, which is similar to the problem of detecting a single newly entering point. Furthermore, the rate of false positive is high when new pattern points are sparsely inserted. To solve these problems, we proposed the improved incremental LOF based on a landmark window model in this paper.

Background on LOF and iLOF
Before describing our improved algorithm framework, we demonstrated the original LOF algorithm for detecting local outliers in static data sets and the incremental LOF algorithm (iLOF) for detecting outliers in data streams.

LOF algorithm
The original LOF algorithm is an anomaly detection method based on local density. It computes the value of local outlier factor (LOF) for each point in the data set to show its degree of being an outlier. Data points with high LOF have local densities that are lesser compared to their neighborhood and typically represent stronger outliers. In contrast, the local density of normal points is usually high and their LOF values are low.

The LOF values are computed for all data points as per the following definitions assuming that data set is D and p is a data sample in it.

k-nearest neighbors (kNN): ∀k∈N∗, k-nearest neighbors of a data point p are the nearest k samples of p. Nk(p) is the set of k—nearest neighbors of p.

k-distance (k−dist(p)): ∀k∈N∗, k-distance of p is the distance from p to its kth nearest neighbor. ∀q∈Nk(p), dist(p, q) is the distance between point p and q, dist(p,q)≤k−dist(p).

Reachability distance (reach-dist): ∀o∈D, compute the reachability distance for p with respect to o as follows:

reach−dist(p,o) = max{k−dist(o),d(p,o)}
(1)
where d(p,o) is Euclidean distance from p to o. From reach-dist(p,o), we can deduce that if p is k-nearest neighbors of o (∀p∈Nk(o)), the reachability distance for p with respect to o is the k-distance of o. Otherwise, it is the distance between two points.

Local reachability density of a data point p (lrd(p)):

lrd(p) = (1k∑o∈Nk(p)reach−dist(p,o))−1
(2)
From the definition, the lrd of any point in the data set is the inverse of the mean of reachability distance to its k-nearest neighbors. The smaller mean then represents higher local reachability density.

Local outlier factor of a data point p (LOF(p)):

LOF(p) = 1k∑o∈Nk(p)lrd(o)lrd(p)
(3)
The LOF value of p is the average ratio of the lrd of all its k-nearest neighbors to its own lrd. The larger LOF value is, the farther the local reachability density of p differs from its k neighbors; thus, p is in a low-density region, and it is more likely to be an anomaly.

The LOF algorithm has two main advantages: (i) only the local density rather than all data needs to be considered when calculating the local outlier factor of each point, and (ii) this method does not require the data set’s distribution. The LOF algorithm is a static detection method, and all data must be available when using it; however, data streams are dynamic with a lot of new data constantly entering the data set. To apply static method to data streams, “supervised” LOF and “iterated” LOF are two primary approaches [31]. The “supervised” LOF uses data of a time period as the training set to calculate the k-distance of each sample point, the reachability distance and reachability density respect to its k-nearest neighbors. When new data come into the data set, this approach uses reach-dist and lrd from the training set to compute their LOF values. The apparent problem is that all information is not updated; therefore, the LOF values of new points may be inaccurate and new normal behaviors are possibly identified as outliers. In “iterated” LOF, the static LOF algorithm is reapplied every time a new data record is inserted into the data set. This approach solves the problem of the “supervised” LOF, but it is computationally expensive. The incremental LOF algorithm (iLOF) was introduced to overcome the above-mentioned limitations.

iLOF algorithm
The incremental LOF (iLOF) algorithm is used to detect anomalies in dynamic data streams. For the first time, it introduced the idea of increment to the LOF algorithm, which provided equivalent detection performance as the static LOF algorithm and considerably improved the computing efficiency. The iLOF algorithm only considers and updates k-nearest neighbors, reachability distances, and LOF values affected by the new incoming points or old deleted points, instead of all points in the data set, which can save the computational costs. The time complexity of the algorithm is O(NlogN).

The main idea of the iLOF algorithm is that when new points are inserted or old points are deleted, information such as the k-nearest neighbors, k-distance and reachability density of only affected data points need to be updated rather than all data in the data set. The iLOF algorithm includes insertion and deletion algorithms. In the insertion part, the algorithm performs two steps: computing reach-dist, lrd, and LOF of the inserted new point and updating k-distances, reach-dist, lrd and LOF for affected existing points. Let T=[t0,tn] be a continuous interval of time, and let pt∈RD denote a data vector inserted at time t where D is the number of data dimensions. Algorithm 1 shows the pseudo-code of the insertion algorithm of the iLOF algorithm.

figure e
The deletion algorithm is similar to the insertion one. The primary purpose of the deletion algorithm is to delete old and outdated data from the data set and update information such as k-distance and reachability density of affected data points.

Improved iLOF_LWM: iLOF algorithm with the landmark window model
Although the iLOF algorithm is a good method to detect anomalies in data streams, it still has some limitations like misidentifying normal patterns and missing some outliers. To solve these problems, we presented an improved iLOF based on the landmark window model (iLOF_LWM). The proposed method uses landmark window data and confirms outliers by multiple tests and finally deletes real anomalies. Sections 4.2–4.4 explain the positive effects of inserting basic windows, confirming outliers by the adaptive threshold and multiple tests, and deleting real abnormal points. Three parts of the model complement each other and jointly improve the proposed algorithm’s performance.

Problem definition
Before explanation, some preliminary concepts are presented as follows.

Definition 1
Data Stream–A data stream DS = x1, x2,…,xn is an ordered unbounded sequence of data objects that arrive in a timely order. Object xi= (x1i, x2i,…,xmi) is then characterized by a set of m attributes.

Definition 2
Basic Window and Landmark Window–A basic window w consists of some data points arriving continuously within a certain time, i.e., w = {xi, xi+1,…,xj}(0<i≤j), and its length, |w|, is the number of data points in it. A landmark window W comprises many continuous neighboring basic windows, i.e., W = {w1, w2, …, wi, …, wj,…}, where w1 is the original basic window. The current length of a landmark window continually changes along with new data arriving. With the arrival of new data, the start position of the landmark window does not change, and the end position will continue to slide in units of the basic window.

Definition 3
An Adaptive Threshold–Real-time detection for data streams requires judgment whenever a new data point or a small data set flows in, so a threshold is needed to distinguish normal points from the abnormal ones. To adapt to dynamic changes of the data stream, we introduced an adaptive threshold, θ, and defined it as the sum of the mean value and three times standard deviation of LOF of existing points in the data set at a certain time. Therefore, θ is constantly updated as new points enter and real outliers are deleted.

Definition 4
Number of Times Recorded as Outliers and the Distinction Cut-off—Whenever the LOF value of a newly entered point is greater than the threshold, instead of judging it as an anomaly immediately, we recorded the number of “abnormal” times, μ. Every time the LOF value of a point is higher than θ, the point’s μ value increases by 1. In addition, the cut-off denoted as tf is used to distinguish candidate anomalies and real anomalies. In order to make multiple judgments, we set tf of iLOF_LWM greater than one.

Definition 5
Candidate Anomaly and Real Anomaly—A point is a candidate anomaly if its μ value is less than the cut-off, i.e., μ<tf. Otherwise, it is a real anomaly, i.e., μ≥tf.

Based on the landmark window model, the overall idea of iLOF_LWM is as follows.

With the entry of the data stream, the basic window is defined, and the new basic window data rather than every single point are used as the operation object of the insertion part in iLOF. As basic windows enter, the landmark window continues to grow, and the LOF values that require updation are changed after computing. Next, LOF values of all data in the current data set are tested. The points with the LOF value not greater than the adaptive threshold are considered as normal points, and others are divided into two categories. As new data are constantly flowing into the original data set, the LOF values of data change continuously. The points with the number of times recorded as outliers (μ) less than the cut-off are considered as “candidate anomalies,” and those with μ value equal to or greater than the cut-off are considered as “real anomalies.” Finally, real anomalies are removed from the data set. Figure 1 shows a schematic of the proposed scheme based on the landmark window model and marks the improvements in gray.

Fig. 1
figure 1
Block diagram of proposed scheme: The improved iLOF based on the landmark window model

Full size image
Implementing a landmark window
In the iLOF algorithm, whenever a new data point enters, the information of the data set is updated. The LOF values of points affected by the new data point change and the LOF value of every new data point is recorded. Identifying every data point as soon as it comes into the data set may lead to the problem of distinguishing between new data behaviors and outliers. Because of the dynamic nature of data streams, data behaviors may change with the time. At the start of a new pattern, the LOF values of new points may be higher than those of the original points, because data with the new pattern are different from the original data set. However, with more data flowing in, data points of the new behavior will become denser and the LOF values of the points entering at the beginning of the new pattern will significantly decrease. In the iLOF algorithm, the points of the new behavior that first entered will be concerned due to high LOF; hence, they may be considered as outliers and raise the false alarm. Implementing a landmark window and using basic windows as updating units can solve this problem. A landmark window comprises many basic windows, and every basic window includes an equal number of data points [28, 43]. The proposed algorithm with the landmark window model detects points in the data set after computing all data in the new basic window.

Let DS={x1,x2,x3,...,xn,xn+1,xn+2...} be a data stream where xi(i=1,2,...) is the ith point in DS described by p attributes. Data points in basic windows with length of m are then denoted as {x1,x2,...,xm},{xm+1,xm+2,...,x2m},.... Let {x1,x2,...,xt} denote the points in the data set at time t and new samples xt+1,xt+2,... continue to flow in over time. The improved algorithm requires that the LOF values of all points, i.e., {x1,x2,...,xt,xt+1,...,xt+m}, in the data set should be analyzed after calculating the data of the newly inserted window, i.e., {xt+1,xt+2,...,xt+m}.

The following example using synthetic data shows the change of LOF values after data continuously flow into the data set and the function of inserting basic windows. The data set considers 500 records generated from Gaussian distribution N1(μ1,Σ1) and 500 records with Gaussian distribution N2(μ2,Σ2) where

μ1= (1,1), Σ1=(0.1000.1).

μ2=(−1,−1), Σ2=(0.5000.5).

We firstly inserted data from N1(μ1,Σ1) distribution and then the stream distribution changes to N2(μ2,Σ2). The iLOF algorithm with k = 20 is used to calculate LOF values of the points in the data set when the 501st, 510th, 550th and 600th points are inserted. The results are shown in Fig. 2.

Fig. 2
figure 2
Dynamical changes of LOF

Full size image
Figure 2 shows that when the 501st point with different distribution started to enter the data set, its LOF was high (LOF(501) = 5.28). Thus, it may be considered as an outlier at this time; however, with arrival of more new data, the number of samples near the 501st point increased and its LOF value decreased. After setting a basic window with 50 data points, the algorithm computed the newly inserted 501st to 550th points and then yielded LOF(501) = 1.0285. Therefore, the data point 501 is not detected as an outlier. The result is shown in Fig. 3.

Fig. 3
figure 3
The influence of window data

Full size image
Multiple tests for outliers
The insertion of basic window data may still result in detecting normal values as outliers for two main reasons. First, the sample points of the new behavior are exactly at the end of a window, which is equivalent to observing the LOF value of the new pattern as soon as it enters the data set. Second, the entry of points describing the new pattern may not be concentrated. If there are few points of the new behavior in the same window and they do not form a dense cluster, their LOF values will remain high. Therefore, to address this problem, the improved model in this study sets an adaptive threshold and offers multiple tests for suspicious outliers.

The method of multiple tests for outliers in the landmark window model assigns μ, a number of times recorded as an outlier to each data point. Let {x1,x2,...,xt} denote the points in the data set at time t and μi(i=1,2,...t) be the number of times that xi(i=1,2,...t) is recorded as an outlier. The original value of μ for every point is zero. If the LOF value of xj(xj∈{x1,...,xt+m}) is higher than the adaptive threshold after the subsequent basic window data {xt+km+1,xt+km+2,...,xt+(k+1)m}(k=0,1,...) enter over time, μj of this point will increase by 1. The adaptive threshold is updated automatically as the data set changes, and its calculation method is shown in Definition 3. In addition, by comparing the values of μ and the preset cut-off, tf, candidate anomalies and real anomalies are distinguished. Note that the value of the cut-off should not be considerably large. Recording points as candidate outliers for too many times is not suitable for the rapid and real-time detection of anomalies in the data stream and prevents the timely deletion of true anomalies from the data set, which results in distortion of information.

The adaptive threshold and multiple tests for LOF values help to correctly detect anomalies and reduce the false positive rate. Here, synthetic data are used as an example for analysis. The synthetic data comprise a mixture of three different two-dimensional Gaussian distributions, i.e., N1(μ1,Σ1), N2(μ2,Σ2) and N3(μ3,Σ3), where N1(μ1,Σ1) and N2(μ2,Σ2) are normal points with 500 samples in each distribution and N3(μ3,Σ3) is outlier distribution with 50 samples. We set the k nearest neighbors parameter k = 30, the length of the basic window |w| = 50, and the initial training set contains 150 points. Figures 4 and 5 show the results of a single test and multiple tests for outliers under the fixed and adaptive thresholds, respectively. The fixed threshold is the sum of the mean and three times standard deviation of LOF values of points in the training set. One test for outliers means a point is declared as a real outlier once its LOF value exceeds the threshold. In Figs. 4 and 5, blue dots are normal points in the data set, green triangles are abnormal points in the data set, and red crosses are points detected as anomalies by the algorithm.

Fig. 4
figure 4
The result of fixed threshold

Full size image
Fig. 5
figure 5
The result of adaptive threshold

Full size image
Figures 4a and 5a are the results of declaring outliers when the LOF values of the sample points are larger than the threshold for the first time. Figures 4b and 5b are the results of the improved algorithm with the landmark window model, which identify the real outliers after the points are recorded as the outliers 3 times. Many normal points are detected as anomalies from Figs. 4a and 5a, and this is significantly improved in Figs. 4b and 5b. In the anomaly detection, normal points are considered as negative events and anomalies are considered as positive events. The results show that under the fixed threshold, the number of false positive samples generated by only one test for the abnormal points is 541 (FP = 541), and the number generated by multiple tests is 27 (FP = 27). Under the adaptive threshold, the numbers of false positive samples for one test and multiple tests are 132 and 12, respectively. Therefore, multiple tests help in reducing the number of misinterpretations. Furthermore, compared with the fixed threshold, the adaptive threshold also helps to reduce the FP rate obviously and keeps a relatively high true positive (TP) rate.

Compared with the static method, the improved iLOF algorithm has an increment thought and remains a certain computational efficiency, while compared with the original iLOF algorithm, testing possible outliers more than once inevitably increases the computational cost. Taking the synthetic data in this section as an example, we found that the improved method with multiple tests took only 3.42% longer than the original iLOF algorithm.Footnote1 However, the results of the original iLOF with a fixed threshold showed that TP was 19 and FP was 31. Therefore, although the computing time increases slightly, the improved algorithm reduces the number of false positive samples and increases the number of true positive samples (TP = 39, FP = 12). The increase in the computational burden of the improved algorithm is limited. On the one hand, in the deletion part of the improved method, the k-nearest neighbors of the deleted points are not calculated again and the information of them is not updated, which effectively reduces the computational cost. On the other hand, the introduction of basic window data avoids misjudgment and deletion for many new pattern points, which reduces unnecessary and time-consuming operations. Furthermore, with the development of computer hardware and technology in the future, computing efficiency will be further optimized and improved.

Deleting real anomalies
Unlike deleting obsolete data in the iLOF algorithm, the improved algorithm based on the landmark window model proposed in this study only deletes the real anomalies after multiple tests. The deletion of old data leads to difficulties in distinguishing new points from old points in the data set. Furthermore, it may cause information loss and a lack of points to calculate new data, which results in wrong judgment [34]. When outliers in the data stream are relatively concentrated, dense outliers possibly form small clusters, thereby reducing their LOF values and making it difficult to correctly detect them. There are two main methods to solve this problem. First, the basic window size should be appropriate. Large windows may contain clusters of abnormal points. Second, real outliers should be removed timely from the data set. Deleting real anomalies prevents outliers from clustering over time and interfering with the classification of new normal points. Therefore, it can improve the accuracy of anomaly detection.

When deleting the real anomalies discussed in Sect. 4.3, this study adopts the deletion technique used by Karimian et al. [19] rather than the “deletion” part of the iLOF algorithm. The difference between them is that in iLOF, the information of data points affected by deletion is updated, which increases the computational cost, while the algorithm in [19] does not consider the information updating. In this study, when deleting real anomalies, iLOF_LWM only removes them from the data set and does not recalculate the k-nearest neighbors, reachable distance, and the LOF value of affected points. Therefore, the main effect of deletion is to restrict the k-nearest neighbors of newly entered points to normal points and candidate anomalies.

Further experiments were performed with the synthetic data in Sect. 4.3 to analyze the effect of deleting or not deleting real outliers on the results. Figure 6 shows the result of introducing the same window and multiple tests as shown in Fig. 5b without deleting the real anomalies. In Fig. 6, the number of normal points detected as abnormal, i.e., the number of false positive (FP) cases, and the number of anomalies that are not detected, i.e., the number of false negative (FN) cases, both increased. There are 50 true abnormal points in the data set and FN = 42. However, in the improved algorithm iLOF_LWM shown in Fig. 5b, FN = 11.

Fig. 6
figure 6
The result of detection without deleting real outliers

Full size image
To summarize the contents of the above four sections, the pseudocode of the improved iLOF algorithm with the landmark window model (iLOF_LWM) is shown in Algorithm 2.

figure f
Experimental results
In this section, experiments of the proposed algorithm iLOF_LWM are performed on several synthetic data sets and real-life data sets. We compared the results with those of iLOF and its’ improvement, I-incLOF and MiLOF and analyzed the impact of different window sizes and different numbers of tests on our improved algorithm. All programs are implemented using Python 3.6. In Sect. 5.1, we introduced the eight data sets and the metrics used to evaluate empirical results. Among the eight data sets, two are synthetic data sets that were randomly generated by a computer, and six are real-life data sets collected in the real world. Sections 5.2 and 5.3 show the experimental results of the synthetic and the real data, respectively.

Data sets and metrics for evaluation
Table 1 summarizes the number of samples, attributes, categories of normal instances, and the proportion of anomalies of all experimental data sets. All data sets have numerical attributes.

Table 1 Characteristics of data sets
Full size table

Synthetic Data sets The Synthetic-A comprises four types of four-dimensional data generated by the clustering data generator in Python. Two of them represent normal data points, each containing 1500 samples, while the other two represent two groups of outliers, containing 20 and 30 samples, respectively. In the second synthetic data set (Synthetic-B), we generated 4-modal mixture of two-dimensional Gaussian distributions and ten scattered outliers. The four groups of Gaussian distribution data are denoted as N1(μ1,Σ1), N2(μ2,Σ2), N3(μ3,Σ3), and N4(μ4,Σ4), respectively, where

μ1 = (1,1), μ2 = ( - 1, - 1), Σ1 = Σ2 = (0.1000.1),

μ3 = (0,2), Σ3 = (0.05000.05), μ4 = (1.5, - 1), Σ4 = (0.03000.03).

There are 1500 data records generated from Gaussian distribution N1(μ1,Σ1) and N2(μ2,Σ2), respectively, which are normal instances. Two clusters of outliers generated from N3(μ3,Σ3) and N4(μ4,Σ4) contain 20 and 30 data records, respectively. We randomly inserted N3, N4, and ten scattered outliers into the normal data sets and then obtained the synthetic data set B.


Motion TrajectoryFootnote2 This data set was also used in [31, 34] to evaluate the results of their algorithms. This motion trajectory data set was collected using infrared surveillance videos and obtained by motion detection and tracking algorithm [23]. The data set comprises 238 data records, containing two outliers. All data are described by three features after principal component analysis.


UCI Data sets Pedestrian [6], Yeast, Gas sensors [18], KDD Cup 1999 and Forest Cover are all real-life data sets chosen from the UCI machine learning repository [11].

The Pedestrian and the Yeast data sets contain many classes, and we chose some of them for anomaly detection in the experiments. In the Pedestrian, we selected the two classes with the largest number as normal samples and the one with the least number as abnormal samples, and randomly inserted anomalies into normal points. In addition, the position coordinates were selected as data attributes. The Yeast contains 1484 sample points of 10 classes. Similarly, three classes, CYT, NUC, and MIT, with the most sample points were selected as normal points, whereas three classes with the least samples were selected as anomalies and 60% samples of the two classes among them were removed to reduce the proportion of outliers.

The Gas Sensors dataset has 100 recordings of home activity stimuli from a gas sensor at a total of 919,438 sample points with 11 attributes. In the experiments, 11,594 samples were selected for the experiment with one type of stimulus as the normal points and a few another type of stimulus as outliers, and sensors’ data, temperature, and humidity were considered as data attributes.

KDD Cup 1999Footnote3 is a huge data set related to network traffic and intrusion, which has also been used in the literature [24, 34]. The 10% subset data contain 494,021 records in five classes, four intrusion types and one normal type. When performing experiments on the data set, we only randomly selected part of the data and 18 continuous numerical attributes, and only the rare intrusion type (R2L) in the original data set was chosen as anomalies. The final modified data set contains 2000 samples with 19 anomalies.

The Forest Cover dataset available at the UCI KDD ArchiveFootnote4 was also used by [8, 21, 34]. This dataset is for the prediction of forest cover type based on cartographic variables and has 7 classes and 581,012 samples. Like other literature [10, 32], we selected some data in the two categories of Cottonwood/Willow and Krummholz and used 10 quantitative attributes to characterize them. The new dataset contains 4918 samples of Cottonwood/Willow class and 82 samples of Krummholz class.

The indicators of the evaluation used in this study are TP, FP, TN, FN, anomaly detection rate, and false alarm rate. TP is the number of positive cases correctly predicted, namely, the number of true positive cases. It represents how many positive cases are considered as positive cases by the algorithm. FP is the number of false positive cases, representing those positive cases predicted as negative cases by the algorithm. Similarly, TN and FN are true negative and false negative cases, respectively. The main purpose of anomaly detection is to find the anomalies, so anomalies need more attention. Therefore, anomalies are usually considered as positive samples.

The anomaly detection rate refers to the ratio of the number of outliers correctly detected (TP) to the number of total actual anomalies. This rate demonstrates how many points of true anomalies are detected. Therefore, a higher anomaly detection rate indicates better performance. The false alarm rate is the ratio of the number of FP cases to the number of total points judged as anomalies by the algorithm. It indicates how many points of all detected anomalies are wrongly detected; therefore, the lower false alarm rate is better. The two metrics are defined in Eqs. (4) and (5).

Anomaly Detection Rate = TPTP+FN
(4)
False Alarm Rate = FPTP+FP.
(5)
Table 2 summarizes the meanings of different parameters and indicators used in the experiments.

Table 2 Parameters and indicators
Full size table
The results of synthetic data
This section presents the anomaly detection rate and the false alarm rate of two synthetic data sets computed using iLOF_LWM and compares them with the results of the original iLOF algorithm. Moreover, considering the Synthetic-B as an example, sensitivity analysis is conducted on the window size and the cut-off of distinguishing candidate and real outliers of the improved algorithm.

Tables 3 and 4 show the empirical results of synthetic data sets A and B, respectively, which summarize the indicators of the improved iLOF algorithm with different window sizes and different cut-off values. In the experiments of data sets A and B, the values of k are 50 and 30, respectively.

Table 3 Experiment results of Synthetic-A
Full size table
Table 4 Experiment results of Synthetic-B
Full size table
As per Tables 3 and 4, the results of multiple tests (tf = 2 and tf = 3) are better than those of a single test (tf = 1). On the Synthetic-A data, an appropriate increase in the number of tests with window sizes of 150 and 200 can significantly reduce the false alarm rate and detect all true anomalies. Similarly, on the Synthetic-B data, compared with the single test under different window sizes, implementing multiple tests and distinguishing candidate and real anomalies reduced the false alarm rates obviously. Although the anomaly detection rates decreased slightly, they were still at ≥ 0.8.

In addition, we compared the results of the proposed algorithm iLOF_LWM with those of iterative LOF and original iLOF on synthetic datasets. For iterative LOF and original iLOF, we set fixed thresholds and adaptive thresholds, and the calculation of them is the same as that of iLOF_LWM. The value of the fixed threshold is always equal to the threshold value of the initial small training dataset, while the adaptive threshold is constantly adjusted with the entry of new data points. The experiment results are shown in Table 5.

Table 5 Comparison of different algorithms on two synthetic data sets
Full size table
From Table 5, it can be observed that the performance of original iLOF and iterative static LOF is the same. The introduction of the adaptive threshold reduced both the false alarm rate and the anomaly detection rate of original iLOF and iterative LOF. However, iLOF_LWM algorithm with a window size of 150 and tf value of 3 maintained the high anomaly detection rate and greatly reduced the false alarm rate, which achieved better results than the two original algorithms with the fixed or adaptive threshold. Therefore, the improved iLOF algorithm based on the landmark window model can detect most of the actual anomalies and has a relatively low false alarm rate, achieving an ideal performance in the anomaly detection for data streams.

Taking the Synthetic-B as an example, we further analyzed the influence of different cut-off values of the improved algorithm on the anomaly detection rate and the false alarm rate under a constant window size, as well as the influence of different window sizes on the results under a specific cut-off value of the proposed model.

Figure 7 shows the changes in anomaly detection and false alarm rates of iLOF_LWM, where outliers were identified by a varying number of tests for window sizes of 30, 50, 100, 150, and 250, respectively. Except the window size of 250, the multiple tests with appropriate test numbers are better than the single test method. Although the anomaly detection rate of multiple tests method slightly decreases, the false alarm rate decreases significantly. Comparing different cut-off values of the improved algorithm, the anomaly detection rate generally decreases with increase in the cut-off value, particularly when the window size is 250. With increase in tf value, the false alarm rate first drops sharply and then remains unchanged or increases. Changes of the evaluation metrics show that keeping increasing recording times does not improve performance for certain window sizes. Recording points as candidate anomalies for too many times may lead to certain outliers remaining in the data set rather than being deleted in time. Furthermore, it is not beneficial for quick and real-time detection of anomalies in the dynamic and evolving data streams.

Fig. 7
figure 7
The indicator results of different cut-off values under a specific window size

Full size image
Figure 8 shows the influence of different window sizes on the anomaly detection and false alarm rates in the improved algorithm with window data. For a certain cut-off value for distinguishing candidate and real anomalies, the anomaly detection rate generally decreases with the increase in the window size, and it drops more obviously when tf values are relatively large (tf ≥ 4). In addition, the false alarm rate of multiple tests decreases or shows a “u” shape change with the increase in the window size. Therefore, a moderate window size helps to avoid the misinterpretation of new normal behaviors as anomalies, but large windows may lead to outliers clustering with high density and smaller local outlier factors. This prevents the correct detection and the deletion of true outliers; moreover, anomalies remaining in the data set will interfere with anomalies detection. Furthermore, a large basic window weakens the benefits of the improved algorithm in timely and fast judgment.

Fig. 8
figure 8
The indicator results of different window sizes under a specific cut-off

Full size image
The results of real data
This section uses data sets collected in the real world for empirical research. The first real data set is motion trajectory [31, 34], which reflects the movement of an object in the surveillance video. Timely detection of abnormal patterns in surveillance videos is important for preventing illegal behaviors. There are 238 data points in this data set, among which the 224th and 236th samples are outliers. Due to the small amount of data in the data set, we directly observed the change of the LOF value of each data point as new data points flowed in. The improved algorithm iLOF_LWM was applied to detect anomalies with k = 30, w = 10 and tf = 2. The results are shown in Fig. 9.

Fig. 9
figure 9
Anomaly detection results of motion trajectory

Full size image
The four subgraphs in Fig. 9 show the local outlier factor (LOF) value of each point after the 200th point, the 224th point, the 236th point, and the 238th point enter the data set, respectively. The dotted lines in the figure are the adaptive thresholds updated with the data set changing. The LOF values of the 224th and 236th sample points are significantly higher than other points and exceed the threshold. This behavior is consistent with the fact that these two points are abnormal events. Furthermore, the LOF values of the two points that are higher than the threshold were observed as the data points entered the data set; hence, the improved algorithm detected the anomalies in real-time.

I-incLOF in [19] and MiLOF in [34] are state-of-the-art improvements of the original iLOF from different aspects and achieve better anomaly detection for data streams. Therefore, we compared the anomaly detection rate and the false alarm rate of the improved algorithm iLOF_LWM with those of iLOF, I-incLOF and MiLOF algorithms on the rest five data sets except the Motion Trajectory. In addition, the computational efficiency of different algorithms is compared on each data set.

Anomaly detection for data streams requires the comparison of LOF of newly entered data points and the threshold in real time to output anomalies rather than finding the points with high LOF after all data are calculated. The threshold was not described in detail in the literature [19, 31, 34]. In order to achieve real-time detection, we set thresholds for the algorithms iLOF, I-incLOF and MiLOF, and they were divided into fixed thresholds and adaptive thresholds like the synthetic data experiments. The detection results of different algorithms on each data set are shown in Figs. 10 and 11.

Fig. 10
figure 10
Experiment results of algorithms with fixed threshold

Full size image
Fig. 11
figure 11
Experiment results of algorithms with adaptive threshold

Full size image
Figure 10 shows the anomaly detection and false alarm rates of all algorithms on different data sets when fixed thresholds were set for iLOF, I-incLOF and MiLOF, while Fig. 11 shows the detection metric results when adaptive thresholds were set for the compared algorithms. As for LOF_LWM, except for the Yeast data set, the results of the other four data sets are good, with a high anomaly detection rate at an average of 0.94 and a low false alarm rate at an average of 0.51. The results on the Yeast dataset are relatively ordinary because categories regarded as normal points and anomalies may not be significantly different. However, compared to other algorithms with fixed thresholds, iLOF_LWM has the best results on each data set. Although the anomaly detection rates of the improved algorithm on some data sets are slightly lower than those of other algorithms, its false alarm rates are greatly reduced. Similarly, when the thresholds of other algorithms are variable, iLOF_LWM has the highest anomaly detection rate and the low false alarm rate compared with other algorithms except the results of the original iLOF algorithm on the KDD dataset. The average results of each algorithm on all data sets are summarized in Table 6. Compared with the fixed threshold, the adaptive threshold reduces both false alarm rates and anomaly detection rates. Moreover, the proposed algorithm iLOF_LWM has better performance in anomaly detection for data streams than the original iLOF algorithm and its improved algorithms.

Table 6 Experiment results on real data
Full size table
In addition, the time costs of different algorithms were compared in each data set. Since the computing speed of the algorithm is affected by the computer hardware, we compared the relative time of different algorithms. Regarding the improved algorithm iLOF_LWM as the baseline, the time of it on each data set was set to one unit, and the relative value of computing efficiency of other algorithms was obtained through the ratio of the absolute time of other algorithms to that of iLOF_LWM. The comparison results of computing costs are shown in Fig. 12.

Fig. 12
figure 12
Computation time

Full size image
Analyzing Fig. 12, it can be observed that in the Pedestrian and Yeast small data sets, the time cost of iLOF_LWM is less than that of iLOF and MiLOF, and for large data sets Gas Sensors, iLOF_LWM takes longer. Moreover, in the datasets KDD and Forest Cover, the computing time of the improved algorithm proposed in this paper is comparable to that of the original iLOF. In relatively small data sets, the deletion of real outliers in the improved algorithm reduces the amount of data in the dataset during the operation and helps to reduce time costs, but multiple tests also affect computational efficiency especially in the large data set. However, although the time cost increases, iLOF_LWM has considerably better anomaly detection and false alarm rates.

Conclusion
The iLOF algorithm provides a good method for the anomaly detection of data streams. This study proposes the landmark window model to improve the iLOF algorithm and get better performance. The introduction of basic data windows helps the algorithm to distinguish abnormal points from the normal points of new patterns; hence, it reduces the false positive rate. This is supplemented by the adaptive threshold and multiple tests for anomalies, which divides points with large LOF values into candidate anomalies and real anomalies. This method further reduces the false positive rate of anomaly detection. Identified anomalies are deleted from the data set instantly, which effectively reduces the interference of outliers to new data and decreases the false negative rate of results. The three improvements complement each other and affect the overall detection performance of the algorithm. The low false positive rate provides the foundation for the correct deletion of anomalies, and the timely deletion of real anomalies helps the algorithm to more accurately detect new outliers. Although compared with the original iLOF algorithm, the improved method increases the computational complexity to a certain extent in large data sets, this problem will be improved with the development of computer hardware and further optimization of the algorithm in the future.

Empirical experiments of the proposed algorithm were studied with synthetic and real data sets. The results show that compared with other algorithms with fixed thresholds or adaptive thresholds, iLOF_LWM improves the effect of the real-time anomaly detection for data streams based on two metrics. The proposed iLOF_LWM has significantly better performance than the original incremental algorithm and static algorithm in the synthetic data sets. In the real data sets, the average anomaly detection rate of iLOF_LWM is 40.32% higher than that of iLOF, and the average false alarm rate is 25.33% lower. Moreover, compared with the improved incremental algorithms I-incLOF and MiLOF, the average anomaly detection rate of iLOF_LWM is increased by 6.10% and 55.36%, respectively, and the average false alarm rate is reduced by 32.53% and 20.57%, respectively. Therefore, the improved iLOF algorithm with the landmark window model generally performs better on the detection rate and the false alarm rate in data sets. Furthermore, the false alarm rate generally changes in “u” shape as the cut-off value and the window size increase, while the anomaly detection rate generally decreases. Therefore, the number of times of candidate anomaly recordings and the window size should be appropriate. They are not the bigger the better. Moreover, a large window size and cut-off value will threaten the efficiency of the incremental algorithm.

In future research, the influence of time can be considered. Although old data should not be directly deleted, its impact may be different from that of newly entered data. Furthermore, the setting of the threshold requires knowledge of relevant fields. It can be adaptively generated by pruning or sorting in further study. Some adaptive optimization methods can also be used to automatically select the window size by comparing the detection performance. Moreover, with the increase in the amount of data, keeping all points other than identified anomalies in the data set causes a high computational burden and memory requirements. Therefore, some appropriate methods, such as clustering and merging the features of historical data, can be adopted to improve memory efficiency and reduce computation time.