Equivalence structure (ES) extraction enables us to determine correspondence relations within a dataset or between multiple datasets. Applications of ES extraction include the analysis of time series data, preprocessing of imitation learning, and preprocessing of transfer learning. Currently, pairwise incremental search (PIS) is the fastest method to extract ESs; however, a combinatorial explosion can occur when employing this method. In this paper, we show that combinatorial explosion is a problem that occurs in the PIS, and we propose a new method where this problem does not occur. We evaluate the proposed method via experiments; the results show that our proposed method is 39 times faster than the PIS for synthetic datasets where a 20-dimensional ES exists. For the experiment using video datasets, the proposed method enabled us to obtain a 29-dimensional ES, whereas the PIS did not because the memory usage reached its limit when the number of dimensions was 9. In this experiment, the total processing time for our proposed method up to 29 dimensions was 6.3 times shorter than that for PIS up to even 8 dimensions.

Access provided by University of Auckland Library

Introduction
Equivalence structure (ES) extraction can help determine correspondence relations between two multidimensional sequences [9]. An ES is a set of tuples that indicates multidimensional sequences that can be considered equivalent. The applications of ES extraction include the analysis of time series data, preprocessing of imitation learning [3, 12, 14, 17], and preprocessing of transfer learning [7, 13, 15, 19]. As an example of the preprocessing of imitation learning, if the correspondence relation between the dimensions of the student and those of the teacher is known, imitation learning can be performed more efficiently. As preprocessing of transfer learning, it is useful to determine a correspondence relation between the dimensions of the source domain and those of the target domain. In transfer learning, when the representation of the dimensions is compressed by a deep neural network etc., the representation can be entangled (owing to the redundancy of a deep neural network), and therefore, correspondence relations can be found more effectively by using a disentanglement method [2, 5, 6]. Disentanglement technology has been being studied for time series data [16].

Motif discovery is a technique similar to ES extraction [1, 4, 18]. Although some motif discovery techniques can extract similar subsequences from two multidimensional sequences, the correspondence between each dimension of the two multidimensional sequences must be known. The ES extraction determines the correspondence between each dimension itself.

The existing methods for ES extraction include the brute-force search (BFS), incremental search (IS) [8, 10], and pairwise incremental search (PIS) [9] exist. Because a combinatorial explosion of the number of comparisons occurs in BFS, IS was proposed to obtain K-dimensional ESs based on (K−1)-dimensional ESs and suppress the combinatorial explosion. However, an ES obtained by IS may be a subset of another ES, and it takes a long time to remove such a subset. Therefore, PIS was proposed where ESs are decomposed into pairs called equivalent pairs (EPs), which are obtained instead of ESs. Although PIS is considerably faster than IS, the combinatorial explosion remains a problem when the number of dimensions of EPs is high.

In this paper, we show that a combinatorial explosion remains a problem even in the procedure of PIS, and we propose a new method where the combinatorial explosion does not occur. In particular, a large number of unnecessary EPs are found in the procedure of PIS, and it causes a combinatorial explosion; therefore, we propose a new method where the problem does not occur. In addition, we evaluate our proposed method by conducting three experiments.

This paper is organized as follows. In Sect. 2, we describe ES extraction. In Sect. 3, we describe the existing methods. In Sect. 4, we discuss the problem in the procedure of PIS, and we present the proposed method. Then, we evaluate the proposed method via three experiments in Sect. 5. Finally, we offer conclusions and discuss future works in Sect. 6.

Equivalence structure extraction
The ES extraction enables us to determine correspondence relations within a dataset or between multiple datasets [9]. In this paper, we consider only ES extraction that determines corresponding relations between two datasets. Therefore, the input of ES extraction is two datasets and the output is a set of ESs.

A K-dimensional ES is a set of K-tuples that indicate K-dimensional sequences. Here, we consider only the case where K is an integer greater than one. The elements of a K-tuple are K IDs for K sequences. A K-dimensional ES indicates K-dimensional sequences that are equivalent. The standard for equivalence is determined based on the subsequences of the K-dimensional sequences. Figure 1 shows an example of a three-dimensional ES.

Fig. 1
figure 1
Illustration of ES extraction

Full size image
In the example, a three-dimensional sequence specified by three-tuple ⟨A1, A2, A3⟩ and a three-dimensional sequence specified by three-tuple ⟨B4, B2, B1⟩ are considered equivalent because one subsequence of the former sequence is very similar to one subsequence of the latter one. Further, one subsequence each of sequences A1, A2, and A3 are very similar to one subsequence each of B1, B2, and B4, respectively. However, none of the subsequences of the three-dimensional sequence specified by ⟨A1, A2, A3⟩, and the three-dimensional sequence specified by ⟨B1, B2, B4⟩ are similar, and the two three-dimensional sequences are not considered equivalent. Thus, comparisons between one-dimensional sequences are not sufficient, and that between subsequences of K-dimensional sequences is required when determining the K-dimensional ES.

A standard for equivalence
The ES extraction requires a standard that multidimensional sequences are equivalent. In this study, the standard for equivalence described below is used; however, it may be better to use a different standard depending on the application.

First, we consider a dataset {xxA1,...,xxAN1} that has N1 sequences and the lengths are all T1, and a dataset {xxB1,...,xxBN2} that has N2 sequences and the lengths are all T2. Here, we call the two datasets as dataset A and dataset B. A subsequence is described as

zz(t)k≡=(z(t,1)k,...,z(t,τ)k)tr(x(t)k,...,x(t+τ−1)k)tr−1τ∑t′=1τx(t+t′−1)k
(1)
where k denotes an ID for a sequence, t∈{1,...,T1−τ+1} if k∈{A1,...,AN1}, t∈{1,...,T2−τ+1} if k∈{B1,...,BN2}, τ denotes the length of a subsequence, the symbol ≡ denotes is equal by definition to, and aatr denotes the transposition of a vector aa.

We use the similarity function

s(vv1,vv2)=1β(∑t=1T1−τ+1w(t)vv1h(t)vv1,vv2+∑t=1T2−τ+1w(t)vv2h(t)vv2,vv1)
(2)
where

β≡∑t=1T1−τ+1w(t)vv1+∑t=1T2−τ+1w(t)vv2,
(3)
w(t)vvi≡1τ∑t′=1τ∑k=1K{z(t,t′)vi,k}2−−−−−−−−−−⎷,
(4)
h(t)vvi,vvi′≡h(θMSV−MSV(t)vvi,vvi′),
(5)
MSV(t)vvi,vvi′≡min(MSV(t,t′)vvi,vvi′|t′∈{1,...,Ti′−τ+1}),
(6)
MSV(t,t′)vvi,vvi′≡1τK∑k=1K∣∣z(t)vi,k−z(t′)vi′,k∣∣2,
(7)
i∈{1,2},i′∈{1,2}∖{i}, and vv1≡⟨v1,1,...,v1,K⟩ specifies a K-dimensional sequence composed of K sequences in dataset A, and vv2≡⟨v2,1,...,v2,K⟩ specifies a K-dimensional sequence composed of K sequences in dataset B. MSV(t,t′)vvi,vvi′ in Eq. (7) is the mean-square value (MSV); MSV(t)vvi,vvi′ in Eq. (6) is the minimum MSV when comparing the subsequence of the K-dimensional sequence specified by vvi starting at t with all subsequences of the K-dimensional sequence specified by vvi′. The value of h in Eq. (5) is the Heaviside step function, and h(t)vv1,vv2 in Eq. (5) is 1 if MSV(t)vv1,vv2<θMSV and 0 otherwise. Further, θMSV is a threshold that should be adjusted depending on the application. w(t)vv1 in Eq. (4) indicates the weight of the subsequence of the K-dimensional sequence specified by v1; the larger the variance of the subsequence, the larger is the value. When h(t)vv1,vv2 is 1 in a place where the weight is large, it is more likely to be regarded as equivalent. The value s(vv1,vv2) is in the interval [0, 1]. Here, the sequences specified by vv1 and vv2 are regarded as equivalent if the value of s(vv1,vv2) is greater than the threshold θs. In this standard, it is necessary to set the length τ of a subsequence, the thresholds θMSV and θs. Here, the MSV is used to compare the subsequences as in Eq. (7); however, it may be better to use a different calculation such as dynamic time warping [1, 11]. Note that we define the similarity function s(vv(K)1,vv(K)2) instead of the dissimilarity function d(vv(K)1,vv(K)2) unlike the previous study [9], but the functionality is the same because d(vv(K)1,vv(K)2)=1−s(vv(K)1,vv(K)2).

Properties of the similarity function
Even if vv1 and vv2 in Eq. (2) are transposed, the value of s(vv1,vv2) is the same; however, for simplicity, we consider only the case where the tuple of the first argument of s is a tuple to specify a multidimensional sequence of dataset A, and the tuple of the second argument is used to specify that of dataset B. Then, the similarity function s(vv1,vv2) has the symmetries

s(vv(K)1,vv(K)2)=s(⟨v1,p1,...,v1,pK⟩,⟨v2,p1,...,v2,pK⟩)
(8)
where

vv(K)1=⟨v1,1,...,v1,K⟩,   vv(K)2=⟨v2,1,...,v2,K⟩,   ⟨p1,...,pK⟩∈P(K),
(9)
and P(K) denotes the set of all K-permutations of {1,...,K}. Therefore, if the elements of vv1 and vv2 are replaced similarly and simultaneously, the value of s will be the same.

Existing methods
The BFS, IS [8, 10], and PIS [9] are the existing methods for ES extraction.

Brute-force search
In the BFS, all K-dimensional sequences are compared to obtain K-dimensional ESs. When searching K-dimensional ESs between two datasets, the number of calculations of the similarity function is NAPKNBPK, where the number of sequences for dataset A is NA, that for dataset B is NB, and NPK is the number of K-permutations of {1,...,N}. Considering the similarity properties described in Sect. 2.1.1, the number of calculations of the similarity function can be reduced to NAPKNBPKK! (=NACKNBPK =NAPKNBCK) where NCK is the number of K-combinations of {1,...,N}. However, even if the number of the calculations is reduced, the combinatorial explosion remains a problem.

Incremental search
The IS was proposed because the combinatorial explosion of the number of calculations of the similarity function occurs in the BFS [10]. In IS, K-dimensional ESs are searched from the candidates generated using (K−1)-dimensional ESs. Figure 2 shows a conceptual diagram of IS. Algorithm 1 shows the procedure of IS. We omit the details of how to generate candidates in Step 5; these details (method and validity) are provided in [8]. An ES obtained by IS can be a subset of another ES, and such a subset needs to be removed. Therefore, it requires a considerable amount of time to determine whether an ES is a subset of another ES and to then delete it. Figure 3 shows an example where such subsets exist. In the figure, ES 1 is an ES with four tuples, and ES 2 is a subset of ES 1 and must be deleted. ES 3 is the same as ES 2 when the first and third elements of all tuples in ES 3 are transposed. Therefore, ES 1 and ES 3 may appear to be different at first glance; however, ES 3 needs to be removed.

Fig. 2
figure 2
Conceptual diagram of IS. A circle, rounded square, and dotted rounded square represent a tuple, an ES, and a candidate for an ES, respectively

Full size image
figure c
Fig. 3
figure 3
Example of subsets of ESs

Full size image
Pairwise incremental search
The PIS was proposed to overcome the problem in IS: ESs can be subsets of other ESs. In PIS, an ES is split into pairs [9]. Figure 4 shows a conceptual diagram of PIS. A pair obtained by decomposing an ES is called an equivalent pair (EP). For example, ES {⟨A1, A2⟩, ⟨B1, B2⟩, ⟨B4, B3⟩} is decomposed into two EPs {⟨A1, A2⟩, ⟨B1, B2⟩}, and {⟨A1, A2⟩, ⟨B1, B2⟩}. Since an EP is a pair, it can be represented as a two-tuple whose elements are tuples; however, for convenience, it is represented as a set here. In the procedure of the PIS, the problem of subsets of ESs does not occur because the number of elements of an EP is always two. Further, ESs can be built based on EPs if necessary.

Fig. 4
figure 4
Conceptual diagram of pairwise incremental search. A circle and rounded square represent a tuple and an ES, respectively

Full size image
Algorithm 2 shows the procedure of PIS. Here, the processes in Steps 2, 5, 6, and 7 can be calculated in parallel, and therefore, they were processed in parallel in the following experiments.

figure d
The simplest method to generate candidates in Step 5 is to connect a connectable ID to a tuple in a (K−1)-dimensional ES. For example, IDs connectable to tuple ⟨A1,A2⟩ are A3,...,ANA, and we consider ⟨A1,A2,A3⟩, ...,⟨A1,A2,ANA⟩. However, we use a more efficient approach to generate candidates, as described below.

Candidate generation
A candidate E˜(K)r,rr for a K-dimensional EP is generated using

E˜(K)r,rr==g′(E(K−1)r,rr){⟨v∗1,...,v∗K−1,i⟩∣∣∣ ⋀k∈{1,...,K−1}v∗k≠i,⋀k∈{1,...,K−1}⟨v∗k,i⟩∈E(2)rk,⟨v∗1,...,v∗K−1⟩∈E(K−1)r}
(10)
where E(K−1)r denotes a (K−1)-dimensional EP, rr∈{⟨r1,...,rK−1⟩ |  r1,...,rK−1∈{1,...,R∗(2)}}. For example, when searching for three-dimensional EPs, if E(2)1={⟨A1,A2⟩,⟨B4,B5⟩}, E(2)2={⟨A1,A3⟩,⟨B4,B6⟩}, E(2)3={⟨A2,A3⟩,⟨B5,B6⟩}, E(2)4={⟨A1,A2⟩,⟨B5,B6⟩} exist, r=1, and rr=⟨2,3⟩, Then, E˜(K)r,rr={⟨A1,A2,A3⟩, ⟨B4,B5,B6⟩}. In addition, if r=1, rr=⟨4,3⟩, then E˜(K)r,rr={⟨A1,A2,A3⟩}. The maximum number of elements of E˜(K)r,rr is 2, and when the number is 1 or 0, it is indeed excluded from the candidates.

Fig. 5
figure 5
Non-derivative EP and its derivative EPs

Full size image
It has been proven that candidate generation enables us to obtain all EPs that are the same as all EPs obtained by BFS under the following assumption [9]:

Assumption 1
∀k∈{1,...,K}∃q{k}∈{1,...,R∗(K−1)}:: ∀r∈{1,...,R∗(K)}:  drop(E(K)r,k)=E(K−1)q{k}
(11)
where E(K)1,...,e(K)R∗(K) are the K-dimensional EPs, and E(K−1)1, ...,  E(K−1)R∗(K−1) are the (K−1)-dimensional EPs.

For example, when {⟨A1,A2,A3⟩,⟨B4,B5,B6⟩} is an EP, {⟨A1,A2⟩,⟨B4,B5⟩}, {⟨A1,A3⟩,⟨B4,B6⟩}, {⟨A2,A3⟩,⟨B5,B6⟩} are all EPs under the assumption. The assumption is considered to hold to a certain extent, but the extent to which it holds depends on the standard for equivalence, noises in data, and so on.

A problem with PIS and our proposed method
Derivative EPs
Although PIS is faster than IS, derivative EP (DEP) exists and a combinatorial explosion can occur. If a K-dimensional EP exists and Assumption 1 holds, then {⟨vc1,...,vck⟩ | vv(K)∈E∗(K)c′} are all EPs where ⟨c1,...,ck⟩∈C(K)k, C(K)k denotes the set of all k combinations of {1,...,K}, and k∈{2,...,K−1}. Here, EPs that can be expressed in this manner are called derivative EPs (DEPs), and the other EPs are called non-derivative EPs (NDEPs). This means that if Assumption 1 holds and a K-dimensional NDEP exists, then, the number of its DEPs is ∑K−1k=2 KCk where  KCk is the number of k-combinations of {1,...,K}. Therefore, the combinatorial explosion occurs when there exist high-dimensional EPs. Figure 5 shows an example where an NDEP and its DEPs exist. In the figure, there exits NDEP {⟨A1, A2, A3, A4, A5 ⟩, ⟨B6, B7, B8, B9, B10 ⟩} and its DEPs such as {⟨A1, A2, A3, A4⟩, ⟨B6, B7, B8, B9 ⟩} and {⟨A2, A3, A5 ⟩, ⟨B7, B8, B10 ⟩}. In this case, the number of DEPs is ∑K−1k=2 KCk where K=5, and the number of calculations of similarities is the same number as that of DEPs. Therefore, the number of calculations of similarities rapidly increases along with the increase in the number K of dimensions of an NDEP.

Pairwise dimension-first search
As described in Sect. 4.1, the combinatorial explosion of the number of DEPs occurs in the procedure of PIS when high-dimensional EPs exist. Therefore, we propose a search method where a combinatorial explosion does not occur.

In our proposed method, two-dimensional EPs are obtained in the same manner as that in PIS, and candidates for three-dimensional EPs are generated. Next, in PIS, all three-dimensional EPs are obtained; however, in our proposed method, not all EPs are obtained and candidates for four-dimensional EPs are generated; four-dimensional EPs are obtained before obtaining the other three-dimensional EPs. Then, an EP with a large number of dimensions is preferentially searched. Thus, we call our proposed method pairwise dimension-first search (PDFS). Figure 6 shows the processing flows of PIS and PDFS.

Fig. 6
figure 6
Processing flows of PIS and PDFS where an NDEP exists and npara=1

Full size image
Algorithm 3 shows the algorithm of PDFS. For the candidate generation in Step 7, we can use function g provided in Eq. (10) as done in PIS. In addition, the processes in Steps 1, 2, 5, and 7 can be calculated in parallel, and therefore, they were processed in parallel in the following experiments. If the npara in Step 4 is 1, the number of calculations of the similarity function should be the smallest. However, the total processing time can be faster when the npara is greater than 1 because Steps 5 and 7 can be processed in parallel. In Step 4, the determination of whether a candidate is derivative is based on the EPs obtained at that time.

figure e
In the example shown in Fig. 6b, all two-dimensional EPs are obtained, and all candidates for three-dimensional EPs are generated in Steps 1 and 2 of PDFS in the same way as PIS. In Step 4 of PDFS, {⟨A1, A2, A3⟩, ⟨B6, B7, B8⟩} is selected as a nonderivative candidate. Then, the similarity s(⟨A1, A2, A3⟩, ⟨B6, B7, B8⟩) is calculated, and EP {⟨A1, A2, A3⟩, ⟨B6, B7, B8⟩} is obtained in Step 5. In Step 7, candidates {⟨A1, A2, A3, A4⟩, ⟨B6, B7, B8, B9⟩} and {⟨A1, A2, A3, A5⟩, ⟨B6, B7, B8, B5⟩} are generated using the EP {⟨A1, A2, A3⟩, ⟨B6, B7, B8⟩}. Go back to Step 4, {⟨A1, A2, A3, A4⟩, ⟨B6, B7, B8, B9⟩} is selected as a nonderivative candidate. Then, the similarity s(⟨A1, A2, A3, A4⟩, ⟨B6, B7, B8, B9⟩) is calculated, and EP {⟨A1, A2, A3, A4⟩, ⟨B6, B7, B8, B9⟩} is obtained in Step 5. In Step 7, {⟨A1, A2, A3, A4, A5⟩, ⟨B6, B7, B8, B9, B5⟩} is generated as a candidate using the EP {⟨A1, A2, A3, A4⟩, ⟨B6, B7, B8, B9⟩}. Go back to Step 4, {⟨A1, A2, A3, A4, A5⟩, ⟨B6, B7, B8, B9, B5⟩} is selected as a nonderivative candidate. Then, the similarity s(⟨A1, A2, A3, A4, A5⟩, ⟨B6, B7, B8, B9, B5⟩) is calculated, and EP {⟨A1, A2, A3, A4, A5⟩, ⟨B6, B7, B8, B9, B5⟩} is obtained in Step 5. In Step 7, no candidate is generated using the EP {⟨A1, A2, A3, A4, A5⟩, ⟨B6, B7, B8, B9, B5⟩}. Go back to Step 4, nonderivative candidates are searched from candidates such as {⟨A1, A2, A4⟩, ⟨B6, B7, B9⟩} and {⟨A1, A2, A5⟩, ⟨B6, B7, B5⟩}, but none of the candidates are nonderivative candidates. Therefore, the similarities of the candidates are not calculated. In addition, sets {⟨A1, A2, A4, A5⟩, ⟨B6, B7, B9, B5⟩}, {⟨A1, A3, A4, A5⟩, ⟨B6, B8, B9, B5⟩}, and {⟨A2, A3, A4, A5⟩, ⟨B7, B8, B9, B5⟩} shown in Fig. 6b do not become even candidates and the calculations of the similarities can be skipped, while the similarities of all pairs shown in Fig. 6a are calculated in the procedure of PIS.

Number of calculations of similarity function in PIS and PDFS
First, we consider the case where Assumption 1 holds and a K-dimensional NDEP exists; we refer to this as case 1. Then, the number of DEPs obtained by PIS is ∑K−1k=2 KCk. In addition, because all two-dimensional sequences are compared, the number of calculations of the similarity function in PIS is

NA(NA−1)NB(NB−1)/2+∑k=3K KCk
(12)
where the number of sequences for dataset A is NA and that for dataset B is NB. The first term of Eq. (12) is the number of calculations of similarities when obtaining two-dimensional EPs. The number of calculations of similarities when obtaining k-dimensional EPs is  KCk where k∈{3,...,K−1}. Because the number of K-dimensional EPs is one, which is an NDEP, the number of calculations of similarities when obtaining K-dimensional EPs is one, which is  KCK. Therefore, the total number of calculations of similarities for PIS is Eq. (12).

When npara in Step 4 of Algorithm 3 is 1, the number of calculations of the similarity function in PDFS in case 1 is

NA(NA−1)NB(NB−1)/2+K−2
(13)
as seen in Fig. 6. As is the case with PIS, the first term of Eq. (13) is the number of calculations of similarities when obtaining two-dimensional EPs. In the procedure of PDFS, not all three-dimensional EPs are obtained, but four-dimensional EPs are searched right after obtaining a three-dimensional EP. Therefore, the number of calculations of similarities when obtaining three-dimensional EPs is one. Similarly, the number of calculations of similarities when obtaining k-dimensional EPs is one where k∈{3,...,K}. Consequently, the total number of calculations of similarities for PDFS is Eq. (13).

Next, we consider the case where Assumption 1 holds, the maximum number of dimensions of NDEPs is Kmax, the number of each K-dimensional NDEPs is MK, and an ID for a sequence does not appear in NDEPs or appears only once. Here, we refer to this as case 2. The number of calculations of the similarity function in PIS is then

NA(NA−1)NB(NB−1)/2+∑K=3KmaxMK(∑k=3K KCk).
(14)
The number of calculations of the similarity function in PDFS is

NA(NA−1)NB(NB−1)/2+∑K=3KmaxMK(K−2).
(15)
Thus, the combinatorial explosion occurs in the PIS even when only one K-dimensional NDEP exists and K is large; however, it does not occur in the procedure of PDFS even if multiple NDEPs exist. Tables 1 and 2 summarize the numbers of calculations of the similarity function in BFS, PIS, and PDFS for cases 1 and 2.

Table 1 Number of calculations of the similarity function in case 1, where a K-dimensional EP exits
Full size table
Table 2 Number of calculations of the similarity function in case 2, where MK K-dimensional EPs exist
Full size table
Experiments
We conducted three experiments to evaluate PDFS. For the experiments, we used a system with an Intel(R) Core(TM) i9-9900X CPU (10 cores) @ 3.50 GHz and 32.0 GB RAM; we used MATLAB R2019b as the programming language. Further, we used Parallel Computing Toolbox version 7.1 in the MATLAB R2019b to perform parallel computing. The optimum number of npara in Step 4 of Algorithm 3 may differ depending on the data and computer used; however, for this study, we set this value to 10, which is the same as the number of CPU cores.

Synthetic datasets
We conducted the first experiment using two synthetic datasets. We made the two datasets where a 20-dimensional EP obviously exists. Figure 7 shows the two datasets, which we call synthetic datasets A and B.

Fig. 7
figure 7
Synthetic datasets. Black points denote values of 1; white points denote values of 0

Full size image
Synthetic dataset A has 40 sequences and the IDs are A1,..., A40. Synthetic dataset B has 20 sequences and the IDs are B1,..., B20. The length of a sequence in synthetic dataset A is 90, and that in B is 80. A pattern appears from t=20 in sequences whose IDs are A1,..., A20; the same pattern appears from t=40 in sequences whose IDs are A40,..., A21. In addition, the same pattern appears from t=30 in synthetic dataset B; however, the order of the sequences is out of order.

We normalized all sequences such that the means and standard deviations would be 0 and 1, respectively. We used the similarity function s described in Sect. 2.1 to determine whether the two multidimensional sequences were equivalent. We set the length τ of the subsequences and the threshold θMSV of MSV to 20 and 0.01, respectively, and two multidimensional sequences were determined equivalent if the value of s was greater than 0.99.

Table 3 shows the processing times for PIS and PDFS. Processing times for PIS and PDFS were 58 min 18 s and 1 min 29 s, respectively, which means that PDFS was 39 times faster than PIS. The processing times required to obtain two-dimensional EPs were 1 min 24 s for both methods; the processing times to obtain EPs with three or more dimensions were 56 min 53 s for PIS and 5 s for PDFS, thereby indicating PDFS was 648 times faster when the number K of dimensions was greater than two. Since EPs with different numbers of dimensions may be searched in parallel in PDFS, only the total processing time to obtain EPs with three or more dimensions was measured. Although it is possible to measure the processing time to obtain EPs in each dimension in PDFS, adding the processing times to obtain EPs in each dimension does not yield the total processing time in general. In PIS, adding the processing times to obtain EPs in each dimension yields the total processing time.

Table 3 Processing times for synthetic datasets (min:sec). K is the number of dimensions
Full size table
Figure 8 shows the numbers of comparisons of sequences in each dimension K of EPs and the numbers of EPs obtained in PIS and PDFS. When K=2, the number of comparisons for PIS and that for PDFS were the same; however, when K=3 to 19, the number of comparisons for PIS was significantly higher, and a combinatorial explosion occurred in PIS; however, it did not occur in PDFS. When K=20, the number of comparisons was two for both methods. The number of two-dimensional EPs obtained by PDFS was the same as that by PIS; however, the number of 3- to 19-dimensional EPs obtained by PDFS was significantly smaller than that by PIS, and the number of 20-dimensional EPs was two for both methods. Of the EPs obtained, there were only two NDEPs in 20 dimensions, and the number of NDEPs obtained by PIS and that by PDFS were the same. One of the reasons why the number of comparisons for PIS and that for PDFS were the same when K=20 is that comparisons to obtain NDEPs in PDFS cannot be skipped, unlike comparisons to obtain DEPs. The number of DEPs obtained by PIS was the same as that by PDFS when K=2; however, the number of DEPs obtained by PIS was significantly higher than that by PDFS when K≥3. When K=10, the number of DEPs obtained by PIS was 369500, which was the highest; however, the number of DEPs in PDFS was 20. The number of DEPs obtained by PDFS was always dozens when K=3 or more. The number of DEPs obtained by PDFS will change if the parameter npara is changed.

Fig. 8
figure 8
Numbers of comparisons and EPs for synthetic datasets

Full size image
The maximum number of dimensions of the obtained EPs was 20, and 20-dimensional EPs obtained by PDFS were exactly like those obtained by PIS. Table 4 lists the 20-dimensional EPs. Based on the arrangements of the sequences in Fig. 7, E(20)1 and E(20)2 in Table 4, it seems that the correspondence relation was successfully identified; however, ES extraction does not enable us to find similar patterns themselves. If such patterns are necessary, we can use motif discovery methods after finding dimensions corresponding between two datasets.

Table 4 Highest-dimensional EPs obtained by PIS for synthetic datasets
Full size table
Motion capture datasets
Using two motion capture datasets, we conducted the same experiment as reported in a previous study [9] (data, preprocessing, and parameter values were the same). The only difference was the computer used and the version of MATLAB. We obtained the datasets (07_01.c3d, 07_02.c3d) from CMU Graphics Lab Motion Capture Database. Here, we call the two datasets mocap dataset A and B. Each dataset has 41 sequences; however, because there are sequences similar to other sequences, these sequences were merged before ES extraction. After merging sequences, the number of sequences in mocap dataset A was 22, and that in mocap dataset B was 18. Next, the original length of the sequences in mocap dataset A is 316 and that in mocap dataset B is 329; however, using simple moving average and downsampling as preprocessing, the length for mocap dataset A was 52, and that for mocap dataset B was 54. As in the previous study [9], we set the length τ of subsequences and the threshold θMSV of MSV to 20 and 0.06, respectively, as used in the similarity function s described in Sect. 2.1; the sequences were equivalent if the value of s was less than 0.05.

Table 5 shows the processing times for PIS and PDFS. They were 1 min 3 s and 39 s, respectively, which means that PDFS was 1.6 times faster. The processing times to obtain two-dimensional EPs were almost the same for both methods; however, the processing times to obtain EPs with three or more dimensions were 1 min 0 s for PIS and 36 s for PDFS, which means that PDFS was 1.7 times faster. Since EPs with different numbers of dimensions may be searched in parallel, we measured only the processing time to obtain EPs with three or more dimensions in the procedure of PDFS. Figure 9 shows the numbers of comparisons of sequences in each dimension K of EPs and the numbers of EPs obtained in PIS and PDFS.

Table 5 Processing times for mocap datasets (min:sec)
Full size table
Figure 9 shows the numbers of comparisons of sequences in each dimension K of EPs and the numbers of EPs obtained in PIS and PDFS. When K=2, the number of comparisons for PIS and that for PDFS were the same; however, when K=3–14, the number of comparisons for PIS was higher. When K=15, the number of comparisons for PIS and that for PIS were the same.

Fig. 9
figure 9
Numbers of comparisons and EPs for mocap datasets

Full size image
As shown in Fig. 9b, the number of two-dimensional EPs obtained by PDFS was the same as that by PIS; however, the number of 3- to 14-dimensional EPs obtained by PDFS was significantly smaller than that by PIS. The number of 15-dimensional EPs was 6 for both PDFS and PIS.

In the experiment using synthetic datasets, the number of NDEPs obtained by PIS was the same as that by PDFS; however, in this experiment, more NDEPs were obtained by PIS as shown in 9c. For example, when K=14, the number of NDEPs obtained by PIS was 31, and that obtained by PDFS was 29. Thus, for examining NDEPs obtained only by PIS, it was found that not all DEPs were obtained. For example, EP {⟨A6, A7, A8, A9, A10, A12, A14, A15, A16, A18, A19, A20, A21, A22⟩, ⟨B6, B9, B3, B11, B5, B16, B12, B15, B10, B1, B17, B2, B18, B8⟩} were obtained only by PIS, and some of the DEPs such as {⟨A7, A9, A10⟩, ⟨B9, B11, B5⟩}, {⟨A7, A14, A16⟩, ⟨B9, B12, B10⟩}, and {⟨A9, A10, A14⟩, ⟨B11, B5, B12⟩} were not obtained even when using PIS. If Assumption 1 always holds, then all DEPs should be obtained by PIS, but this is not the case. We believe that this is more likely to occur in noisy datasets. Further, we consider that it is not necessary to obtain all NDEPs, and it is sufficient to obtain useful NDEPs. Currently, there is no standard to evaluate the usefulness of an NDEP, and here, we consider that an EP with more dimensions is more useful.

The maximum dimension of EPs obtained was 15, and 15-dimensional EPs obtained by PDFS were the same as those obtained by PIS. Table 6 shows the 15-dimensional EPs. Figure 10 shows 15-dimensional EP E(15)4 drawn in the original three-dimensional space. From the results shown in Fig. 10, we consider that quality correspondence relations were successfully determined.

Table 6 Highest-dimensional EPs obtained by PIS or PDFS for mocap datasets
Full size table
Fig. 10
figure 10
15-dimensional EP E(15)4 drawn in the original three-dimensional space. Circle markers represent sequences for IDs A1,..., A22, B1,..., B18. Cross markers represent sequences that were merged in the preprocessing. Solid lines represent the correspondence relation

Full size image
Video datasets
Using two movie datasets, we conducted an experiment to determine the correspondence relations between the two movies. In this experiment, we used two movies (one was embedded in the other video), and we verified whether the embedded video could be found by ES extraction. One application of this experiment is to search for illegally uploaded videos. Embedding an illegally uploaded video to another video makes finding the illegally uploaded video very difficult. However, even if such embedding is performed, we consider that, by using ES extraction, it is possible to discover whether the target movie is embedded. Because we attempted to compare PIS and PDFS, we did not use a method specific to this problem. There are probably many ways to specialize it to this problem. For example, using information on which sequences are adjacent can help improve speed; however, this information was not used in this experiment.

We used two videos from Videvo. The titles of the two videos are Beetle in Slow Motion CC-BY NatureClip, and Car Journey Time-Lapse at Night CC-BY NatureClip. Here, we refer to them as videos 1 and 2, respectively. Figure 11 shows one frame for each video.

Fig. 11
figure 11
Videos

Full size image
Here, we embedded video 1 in video 2 and verified whether the embedded video could be identified. The process for embedding video 1 in video 2 and creating two datasets is shown below.

1.
The frame size (width × height) of video 1 is 1280 × 720; we resized it to 6 × 5 (Fig. 12a).

2.
Let video 1 be a dataset of 30 sequences. Here, we call this dataset video dataset A.

3.
The frame size (width × height) of video 2 is 1280 × 720; we resized it to 10 × 10 (Fig. 12b).

4.
We rotated video 1 by 90 degree and embedded it in video 2 as shown in Fig. 12c; we played video 1 after 5 s as shown in Fig. 12d.

5.
Let video 2 be a dataset of 100 sequences. Here, we call this dataset video dataset B.

Fig. 12
figure 12
Video datasets

Full size image
As preprocessing for ES extraction, we normalized each sequence such that the mean and standard deviation would be 0 and 1, respectively. Next, we set n to six and used the n-point simple moving average for each sequence. We selected the value of n such that the mean squared error between sequences before and after the moving average was 0.01 or less in all sequences in video dataset A. Then, we down-sampled each sequence by n. Because the original frame per sec (FPS) was 24, the FPS after this processing was 4.

As in the other experiments, we used the similarity function s described in Sect. 2.1 to determine whether the two multidimensional sequences were equivalent. We set the length τ of the subsequences and the threshold θMSV of MSV to 20 and 0.1, respectively, and two multidimensional sequences were determined equivalent if the value of s was greater than 0.5.

Table 7 summarizes the processing times for PIS and PDFS. When searching for nine-dimensional EPs in PIS, memory usage reached its limit, and therefore, the process ended when K=9. The processing time up to K=8 was 448 min 46 s. The memory was not out of memory in the procedure of PDFS, and the processing time up to K=29 was 84 min 21 s, which means that the total processing time for PDFS was 6.3 times faster than the processing time for PIS up to K=8. The processing times to obtain two-dimensional EPs were about 84 min for both methods. In PDFS, the processing time from K=3–29 was 22 s, and the processing time from K=3–8 in PIS was 532 min 43 s, which means that the processing time from K=3–29 in PDFS was 1203 times faster than that from K=3–8 in PIS.

Table 7 Processing times for video datasets (min:sec)
Full size table
Figure 13 shows the numbers of comparisons of sequences in each dimension K of EPs and the numbers of EPs obtained in PIS and PDFS. Since PIS ends processing in the middle, the figures show the numbers of NDEPs and DEPs obtained only by PDFS. When K=2, the number of comparisons for PIS and that for PDFS were the same; however, a combinatorial explosion occurred in PIS when K>2. The number of comparisons for PDFS did not exceed 100 when K was greater than three. In addition, the number of EPs obtained by PIS increased explosively, and that by PDFS did not exceed 100. The number of NDEPs obtained by PDFS was 0 to 3 when K=2,...,29. The total number of the NDEPs was 11, and the maximum number of dimensions of NDEPs was 29. Figure 14 shows the 29-dimensional EP obtained by PDFS. Video dataset A has 30 sequences of video 1, and the 30 sequences were embedded in video dataset B. As shown in Fig. 14, 29 out of 30 sequences of video 1 were successfully found in video dataset B. We determined that sequences were equivalent if the value of s was less than 0.5 in this experiment. The 30-dimensional EP might be obtained by increasing the value to more than 0.5; however, in that case, extra EPs may be obtained, which can lead to a slow process. In addition, the larger the size of the images, the more accurate the distinctiveness may be. In order to handle a larger size of images, it will be necessary to use more powerful computers or a faster method to obtain two-dimensional EPs.

Fig. 13
figure 13
Numbers of comparisons and EPs for video datasets

Full size image
Fig. 14
figure 14
29-dimensional EP obtained by PDFS. Lines represent the correspondence relation

Full size image
Conclusion
In this paper, we showed that PIS—the fastest of the existing methods—does indeed have a problem in that the number of unnecessary EPs causes a combinatorial explosion. Further, we proposed a new method, PDFS, which can avoid any combinatorial explosion. In the experiment using synthetic datasets, the processing times for PIS and PDFS were 58 min 18 s and 1 min 29 s, respectively, and thus, PDFS was 39 times faster than PIS. The maximum number of dimensions of the obtained EPs was 20, and two 20-dimensional EPs obtained by PDFS were exactly the same as those obtained by PIS. In the experiment using motion capture datasets, the processing times for PIS and PDFS were 1 min 3 s and 39 s, respectively; thus, PDFS was 1.6 times faster than PIS. The maximum number of dimensions of the obtained EPs was 15, and six 15-dimensional EPs obtained by PDFS were exactly the same as those obtained by PIS. In the experiment using video datasets, the process of PIS was terminated because memory usage reached its limit while searching for nine-dimensional EPs. The memory was not insufficient for PDFS; further, PDFS enabled us to obtain a 29-dimensional EP that implied a quality correspondence relation between two video datasets. The processing time for PDFS up to 29 dimensions was 84 min 21 s, and that for PIS up to 8 dimensions was 532 min 43. This means the total processing time for PDFS was 6.3 times shorter than that for PIS even up to 8 dimensions. In addition, the processing time for PDFS from 3–29 dimensions was 22 s, and the processing time for PIS from 3–8 dimensions was 448 min 46 s. This means the processing time for PDFS from 3–29 dimensions was 1203 times faster than that for PIS from 3–8 dimensions.

In the future, we will propose a faster method to obtain all two-dimensional EPs because it usually takes a considerable amount of time to obtain all two-dimensional EPs even when using PDFS. In addition, we plan to conduct more practical application experiments such as the analysis of time series data, preprocessing of imitation learning and preprocessing of transfer learning as described in Sect. 1. Moreover, because there has been no standard to evaluate the usefulness of an EP, such a standard will be useful. If we have such standard to evaluate the usefulness of an EP, then a similarity function can be improved.