Fog computing (FC) designates a decentralized computing structure placed among the devices that produce data and cloud. Such flexible structure empowers users to place resources to increase performance. However, limited resources and low delay services obstruct the application of new virtualization technologies in the task scheduling and resource management of fog computing. Scheduling and load balancing (LB) in the cloud computing have been widely studied. However, countless efforts in LB have been proposed in the fog architectures. This presents some enticing challenges to solve the problem of how tasks are routed between different physical devices between fog nodes and cloud. Within fog, due to its mass and heterogeneity of devices, the scheduling is very difficult. There are still few studies that have been conducted. LB is a very interesting and important study area in FC as it aims to achieve high resource utilization. There are various challenges in LB such as security and fault tolerance. The main objective of this paper is to introduce an effective dynamic load balancing technique (EDLB) using convolutional neural network and modified particle swarm optimization, which is composed of three main modules, namely: (i) fog resource monitor (FRM), (ii) CNN-based classifier (CBC), and (iii) optimized dynamic scheduler (ODS). The main purpose of EDLB is to achieve LB in FC environment via dynamic real-time scheduling algorithm. This paper studies the FC architecture for Healthcare system applications. The FRM is responsible for monitoring each server resource and save the server's data into table called fog resources table. The CNN-based classifier (CBC) is responsible for classifying each fog server to suitable or not suitable. The optimized dynamic scheduler (ODS) is responsible for assigning the incoming process to the most appropriate server. Comparing EDLB with other previous LB algorithms, it reduces the response time and achieves high resource utilization. Hence, it is an efficient way to ensure the continuous service. Accordingly, EDLB is simple and efficient in real-time systems in fog computing such as in the case of healthcare system. Although several methods in LB for FC have been introduced, they have many limitations. EDLB overcomes these limitations and achieves high performance in various scenarios. It achieved better makespan, average resource utilization and load balancing level as compared to previously mentioned LB algorithms.

Access provided by University of Auckland Library

Introduction
With the exponential growth of the Internet of things (IoT)-related wearable technology [1], a growing amount of data is being distributed over the Internet. The Internet in the future will become the IoT. This has arisen with ubiquitous networking features (anything, anywhere, and anytime). Triggers, sensors, or artifacts contain objects such as smart watch, smart car, smart pen, smart chair, and smart bag. The Internet of things makes it easy to turn something into a smart computer called Smart X. In order to accomplish complicated and challenging tasks without human intervention, these clever things engage with each other. The smart devices usually consume a high computation power, bandwidth, and storage. Hence, IoT services and applications need to be backed up by huge servers which are mostly deployed in the cloud. The cloud is a series of computers typically operated by a single company. Cloud computing (CC) has evolved exponentially in recent years. CC can be described as a paradigm of distributed computing which allows user to benefit from the applications and the services that exist on servers far from his location [2]. CC is an acceptable way to store, distribute, and manage online sites, tools, apps, and data through the implementation of the "Pay-Per-Use Concept" [3]. It isolates resources and services from customers in order to facilitate the operation of applications [4]. CC provides many services such as applications through Internet (Google Docs), computing through Internet (Amazon EC3), storage and backup through Internet. Data centers consume lots of power due to the wide use of cloud services. Cloud services are classified as three types, namely Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS), respectively [5]. SaaS is a Software that is installed at remote servers provided to user as a service [6] 7]. Example of SaaS is Google Docs, Spreadsheets, a bank application (Multi-tenancy). PaaS allows developers to build SW applications using tools provided by the provider [8, 9]. Developers can code, test, and build an application on remote platform (OS, Database…). Example of PaaS is building a Web application remotely, so, you do not need to install PHP, Web servers, or MySql server. IaaS is also known as HW as a service (pay per use). IaaS provides virtualized computing resources over the Internet [10]. It provides hardware, storage, servers, data center space, and HW components. Example of IaaS is platform virtualization.

Cloud services and applications suffer from unacceptable latency while sending data to end devices and receiving it from them because data centers of clouds are located near to the core of the network. Therefore, cloud is not suitable for real-time applications such as real-time monitoring. Besides this, some IoT applications usually require geo-distribution, mobility support, and location awareness. In addition, the cloud is centralized and there is no location awareness in it. In general, CC is considered a potential solution to deliver low-cost services and software to consumers. Nevertheless, as “Fog” to be close to the user, many cloud providers and apps would be at the edge of the network. Fog computing (FC) has the same features of CC (virtualization, network, processing, and computing) and made by Cisco. These features are provided near to things to solve the problem of high delay and is specialized for sensitive applications like healthcare [11]. Cisco said that there will be around 25 billion of things, objects, and actuators by 2020. These things generate an enormous number of messages. Governments and societies benefit from these messages to improve the quality-of-life of end users [12]. In 2012, Cisco Systems adopted the word “FC” to simplify the deployment of networks at the edge of the network, satisfy latency criteria, and gain location-awareness. Latency is the interval between the input into a device and the desired output. To illustrate the relation between IoT, big data, cloud, and fog as depicted in Fig. 1, IoT produces big data which needs CC. Big data should be maintained by the data centers provided by the cloud and processed by huge power provided by cloud servers. FC is not an option to CC, but an expansion of this [13] is the usage of tools from devices at the edge. However, the choice between cloud and fog is not a choice. They form a reciprocal interdependent series. Coordination between devices may depend on the cloud in a fog. It is more fitting to run specific apps in fog when others are in the cloud. So Cisco expands CC across mobile devices and the cloud by adding an intermediate fog layer.

Fig. 1
figure 1
Big data-IoT-cloud-fog relationship

Full size image
Figure 2 shows a three-layer mobile-fog-cloud hierarchy. This figure illustrates how different collections of devices will use FC to connect with the cloud. One or more clients or edge devices can describe fog networks as an infrastructure that employs storage, communication, and management. Fog is a virtualized platform that offers resources for storing, processing, and networking between the cloud and the network edge [14].

Fig. 2
figure 2
End devices-fog-cloud architecture

Full size image
FC overcomes several challenges by the following: (i) Reduction of data movement: Resulting in reduced congestion since data can be processed locally in the fog and smart devices also saves network bandwidth. (ii) Elimination of bottlenecks resulting from centralized computing systems. (iii) Minimize data latency: Hence, it is suitable for real-time interaction and time-sensitive applications. (iv) Location awareness: Custom services can be provided to the user based on his location. (v) Improved security of encrypted data as it stays closer to the end user.

Despite all advantages of FC, fog still faces some challenges such as: (i) FC is still new and lacks a standardization such as lack of suitable real-time scheduling algorithm. (ii) It suffers from security issues (data theft attack, man-in-the-middle attack, and lack of trust). (iii) The cost of connectivity. Healthcare system can be understood as an arrangement of parts and their interconnections that come together to concern with people’s health. Some health systems are failing to deliver care, and some are collapsing under the pressure of inefficient service provision. The main contributions of this research are to achieve load balancing in fog environment via dynamic real-time scheduling. This paper studies the FC architecture for healthcare system applications. The originality of this paper is concentrated in introducing a proposed effective dynamic load balancing technique (EDLB), which is composed of three main modules, namely: (i) fog resource monitor (FRM), (ii) CNN-based classifier (CBC), and (iii) optimized dynamic scheduler (ODS). Comparing EDLB with other previous LB algorithms, it reduces the response time and achieves high resource utilization. Hence, it is an efficient way to ensure the continuous service. Accordingly, EDLB is simple and powerful in real-time systems in fog computing such as in the healthcare system. Although several methods in LB for FC have been introduced, they have many limitations. EDLB overcomes these limitations and achieves high performance in various scenarios.

The rest of paper is organized as follows: Sect. 2 gives a background for some basic concepts. Section 3 introduces the frequently used LB algorithms generally, and the recent previous efforts in the area of dynamic task scheduling algorithms. Section 4 introduces a proposed effective dynamic load balancing technique (EDLB) based on convolutional neural network and modified PSO with more details about each contribution. Section 5 introduces the evaluation results and discussion. Our conclusion is discussed in Sect. 6.

Background and basic concepts
In this section, several concepts present in the area of load balancing (LB), dynamic task scheduling (DTS), deep learning (DL), deep neural network (DNN), convolutional neural network (CNN), and particle swarm optimization (PSO).

Load balancing (LB)
Load balancing (LB) is a vital research issue in distributed computing. It is mandatory to achieve high performance in distributed environment. There are many approaches and techniques that must be considered for proper LB [15, 16]. In many of these approaches, the load is transferred from the overloaded node to the other under-loaded one [17, 18]. Load balancer is a network device that is used in distributed system to enhance the response time and utilization of resources and to prevent the single point of failure. Thus, the LB improves the overall system as it ensures availability and reliability. But if the LB is not done in a proper way then we have faced a very big issue in networking. The LB is classified to static and dynamic. Static LB [19, 20] is achieved by collecting main data about each server. Dynamic LB [21, 22] frequently monitors any updates in the system load and adapt it accordingly.

Dynamic task scheduling (DTS)
Scheduling is a situation of equilibrium in which activities are organized in accordance with the particular criteria and the specific algorithm. The purpose of scheduling algorithms is to minimize the task's execution time. Task scheduling algorithms are divided into two groups, static and dynamic. Dynamic task scheduling (DTS) is an important issue that is regarded in many fields of computing such as cloud and fog to improve the performance. Hence, many researchers have presented many research works in this issue.

Deep learning (DL)
Deep learning (DL) (also referred to as deep organized learning or hierarchical learning) is part of a larger family of artificial neural network-based machine learning methods [23]. DL is a digital machine that mimics the brain's network of neurons. It is a branch of machine learning and since it makes use of deep neural networks [24, 25], it is called deep learning and it can be supervised. DL architectures such as deep neural networks, deep belief networks, recurrent neural networks, and convolutional neural networks have been implemented to fields such as classification, object detection, and speech recognition [26]. Unlike the traditional learning algorithms, the performance of DL algorithm increases with the increase of the amount of data as shown in Fig. 3.

Fig. 3
figure 3
Why deep learning

Full size image
Deep neural network (DNN)
A deep neural network (DNN) is a multilayered artificial neural network (ANN) between input and output layers [27]. DNN is constructed with connected a set of layers which are: (i) input layer, (ii) output layer, and (iii) hidden layers (all layers in between). In order to transform the input into the output, the DNN finds the right mathematical manipulation, whether it is a linear relationship or a nonlinear relationship. The term deep means that the network connects neurons in more than two layers. Without predefined information expressly coded by the programmers, DNN will learn automatically.

The network passes through the layers, measuring each output's likelihood. "Any mathematical manipulation as such is called a layer and, as shown in Fig. 4, complex DNNs have several layers, thus the term "deep" networks [28].

Fig. 4
figure 4
DNN architecture

Full size image
Usually, DNNs are feed-forward networks in which data flows without looping back from the input layer to the output layer. The DNN initially generates a map of simulated neurons and assigns relations between them to arbitrary numerical values, or “weights.” Weights and inputs are multiplied and an output of 0–1 is returned. If the network did not correctly identify a certain pattern, an algorithm would change the weights [29]. That way, before it chooses the best mathematical manipulation to completely process the data, the algorithm may make those parameters more influential. In DNN, each layer, i.e., the hierarchy of knowledge, reflects a deeper level of knowledge. A four-layer neural network can acquire more complex features than those of two layers.

Convolutional neural networks (CNNs)
A convolutional neural network (ConvNet/CNN) [30] is a DL algorithm that can take an input image, attach value to various aspects/objects in the image (learnable weights and biases) and be able to discern one from the other. As compared to other classification algorithms, the preprocessing required in a ConvNet is much smaller. Although filters are hand-engineered in rudimentary systems, ConvNets have the potential to learn these filters/characteristics with adequate preparation. The architecture of a ConvNet is similar to that of neurons' connectivity pattern in the human brain and was influenced by the visual cortex organization. Individual neurons respond only in a small area of the visual field known as the receptive field to stimulus. A collection of such fields' overlaps to cover the entire visual area. CNN is a particular kind of neural network feed-forward with convolution layers and pooling operations [31]. It can catch global and local characteristics and dramatically boost performance and accuracy. This works well with grid-like topology in the retrieval of details.

Particle swarm optimization (PSO)
Recently, particle swarm optimization (PSO) is a global optimization model that has gained weight as it is easy to be applied in complex multidimensional and unsupervised problems that cannot be solved using traditional algorithms [32]. PSO optimizes a problem by repeatedly improving a candidate solution respecting a specific quality measure. The greater the number of elements of the squadron and the smaller the search area, the easier the solution is found and faster [33]. The PSO algorithm consists of three steps: (i) Evaluate fitness of each particle. (ii) Update individual and global bests. (iii) Update velocity and position of each particle. These steps are repeated until some stopping condition is met.

Related work
This section introduces the previous contributions in the area of task scheduling algorithms generally and in the area of task scheduling algorithms for in CC and FC. In the last years, many researchers are working on different issues to solve the FC challenges. Itrat [34] proposed a novel service broker scheme and compared it with two LB algorithms, which are throttled, and RR. In [35], the authors have studied the LB issue using RR and SJF. Authors in [36] discussed many issues in FC such as scalability, adaptability, and connection between end devices and fog servers. In [37], authors deal with LB on FC. Authors use PSO algorithm to minimize the load of requests on fog. In [38], authors proposed LB algorithm to find the priority for the incoming request and save it in a priority table. Authors in [39] tried to achieve the quality of service (QoS) via LB on cloud by considering set of heterogeneous data centers. In [40], authors proposed a LB technique, which is bio-inspired to minimize the task completion time and communication delay time. It assigns the task to the server according to its demand.

In several optimization problems, PSO is used to make the best solution simpler and quicker to discover. It has already been implemented. Khatir et al. [41] used PSO, based on the inverse problem, to predict the position and magnitude of damage of a steel cantilever beam and a two-dimensional frame. Wei et al. [42] employed an improved PSO to detect the damage of different structures (a frame, beam, and a truss) with a high accuracy. Shabbir et al. [43], Shao et al. [44], Qiing et al. [45], Pau et al. [46], Mangiatordi et al. [47], and other researchers also successfully used PSO to deal with other optimization problems. Authors in [48] introduced a hybrid task scheduling algorithm that applies the round robin (RR) and shortest job first (SJF) algorithms. Authors in [49] suggested an expanded particle swarm optimization (EPSO) algorithm with an additional gradient approach to simplify the problem of work scheduling in cloud–fog conditions. The ACO algorithm revokes the long paths [50].

Casavant [51] presented a scheduling approach in distributed systems. The classification presented in [51] includes static and dynamic, local and global, cooperative and noncooperative, and distributed and non-distributed scheduling. This presented a complete and effective classification approach. However, this taxonomy is not suitable to the current distributed systems. Kwok [52] presented a survey on static scheduling algorithms. Authors in [52] surveyed the description and classification of 27 scheduling algorithms. There have been a number of proposed scheduling strategies for CC to enhance the task completion time and improve the resource utilization [53]. The most popular task scheduling algorithms are: MIN–MIN algorithm [54], MAX–MIN algorithm [54], PMM algorithm, MET algorithm [55], MCT algorithm [55], and genetic algorithm (GA).

The MET (Minimum Execution Time) is defined as the minimum time taken by the processor to execute each task assigned to it. The MET does not consider the processor ready time. The MCT (Minimum Completion Time) algorithm is defined as the minimum time taken by the processor to complete each task assigned to it. It is unable to assign some tasks to the fastest processor. The MIN–MIN and the MCT algorithms are based on the minimum completion time. The MCT algorithm considers only one task at a time. But the MIN–MIN algorithm considers all tasks that are not scheduled. Firstly, the MIN–MIN algorithm determines the completion time of all unassigned processes firstly. Then it continuously chooses the process with the least completion time and allocates it to the processor that can decrease its completion time.

The MAX–MIN algorithm is similar to the MIN–MIN algorithm. It also firstly determines the least completion time (LCT). Then it chooses the process with the greatest LCT value and allocates it to the processor with the least completion time. The PMM (Priority MIN–MIN) algorithm is an enhancement of the MIN–MIN algorithm. It gives a priority to each process by calculating the standard deviation of it on each processor.

The previous scheduling algorithms have been applied successfully in CC. However, they are not suitable for large scheduling problems. To enhance the performance of the scheduling problem, researchers have proposed several algorithms to schedule tasks effectively and hence achieve the load balancing. The most common previous proposed scheduling algorithms which achieved good results in FC are shown in Table 1. It summarizes these algorithms highlighting their strength and weakness.

Table 1 Related task scheduling algorithms for fog computing and cloud computing
Full size table
Problem definition and plan of solution
Although there are many existing task scheduling algorithms, they have many limitations such as (i) they does not consider the task's requirements such as the priority of the task and the number of tasks. (ii) Most of them does not consider the response time and waiting time reduction. The proposed load balancing technique tries to solve the previously mentioned problems through the following contributions: (i) standardizing and normalizing the resource attributes. (ii) Combining CNN with PSO to divide the resources and reduce the scale of the resource search. (iii) Achieving a low latency. (iv) Achieving load balancing in fog layer. The methodology of each contribution and solution is shown in the next section in details. More explanation for the drawbacks of the previous algorithms and the proposed solution is shown in Table 2.

Table 2 More explanation for the drawbacks of the previous algorithms and the proposed solution
Full size table
The main contribution of this paper is to propose a load balancing technique which takes into consideration the how to determine your fog server requirements and how to define the incoming process requirements. It is important to determine: (i) how many CPUs per server are required for the incoming process, (ii) how much RAM, and (iii) how much storage does the process need. It is easy to calculate the size of the incoming process. If the process is running on a physical server, you can look at the overall size of the process as well as the anticipated traffic. It is also important to know how to determine the computing power (CPU and RAM).

The effective load balancing technique using CNN and PSO
FC in healthcare system needs a standardization and a suitable real-time scheduling algorithm which can determine the criticality of data and how much the incoming request is important. It is an extremely important issue to achieve LB between the fog nodes to optimize resource utilization while increasing throughput and decreasing response time. The most significant benefit of “IoT in healthcare” is that it lowers maintenance expenses, which leads to an increase in the possibility of receiving care. Figure 5 depicts the overall architecture of an Internet of things-based healthcare system. The three stages of automation in IoT-based healthcare include data collection via sensors, analytics based on the collected data, and decision making based on the obtained data.

Fig. 5
figure 5
Smart healthcare system architecture

Full size image
The proposed effective load balancing (EDLB) technique using CNN is shown in Fig. 6. A healthcare system is one of the most relevant applications related to IoT goals. Many variables should be taken into account in healthcare systems, such as time, data protection, and precision. In all time, the healthcare infrastructure should be efficient and accessible. The main goals of the EDLB are: (i) standardizing and normalizing the resource attributes. (ii) Combining CNN with PSO to divide the resources and reduce the scale of the resource search. (iii) Achieving a low latency. (iv) Achieving load balancing in fog layer. The proposed effective dynamic load balancing technique (EDLB) consists of three main modules which are: (i) fog resource monitor (FRM), (ii) CNN-based classifier (CBC), and (iii) optimized dynamic scheduler (ODS).

Fig. 6
figure 6
Fog computing task scheduling process

Full size image
Fog resource monitor (FRM)
The FRM is responsible for monitoring each server resource and save the server's data into table called Fog Resources Table (FRT) as shown in Table 3. The FRT is located at the FRM server. The FRM server is one server from the fog servers.

Table 3 Fog resources table (FRT)
Full size table
Each fog server is classified as suitable or not suitable according to set of rules based on three main features which are: (i) storage (STR), (ii) computing (CMT), and (iii) RAM. The steps to assign the status to each server are:

i.
Calculate the average storage (AVG_STR).

ii.
Calculate the average computing (AVG_CMT).

iii.
Calculate the average RAM size (AVG_RAM).

iv.
Apply set of rules such as; (a) If STR ≥ AVG_STR then STR = 1, Else if STR < AVG_STR then STR = 0. (b) If CMT ≥ AVG_CMT then CMT = 1, Else if CMT < AVG_CMT then CMT = 0. (C) If RAM ≥ AVG_RAM then RAM = 1, Else if RAM < AVG_RAM then RAM = 0. These three features (STR, CMT, and RAM) will be the input for CNN. CNN is trained using the three input parameters which are: STR, CMT, and RAM. Then PNN will be tested to assign each FS a status which is suitable or not suitable. The overall steps of training and testing CNN are illustrated in the next section.

CNN-based classifier (CBC)
The CNN-based classifier (CBC) is responsible for classifying each fog server to suitable or not suitable. The classification process is done using CNN as shown in Fig. 7.

Fig. 7
figure 7
The CBC steps

Full size image
Problem description
Given a specific fog server, it is required to identify possible features for the server. Each server is labeled as "suitable" or "not suitable" according to its features stored in the FRT which are: (i) storage, (ii) computing, and (iii) RAM. The steps of CBC are: (i) the first step is to collect and clean the data. We sampled around 20 servers. Each server can have three possible labels ["Storage," "Computing," and "RAM"]. (ii) The second step is to encode the labels in a format that can be utilized by the CNN, we create a three-dimensional vector such that there is a "1" if a label is present in the server data and "0" if a label is absent. The three learned features are storage (STR), computing (CMT), and RAM. They are calculated as follows: (a) Calculate the average storage (AVG_STR). (b) Calculate the average computing (AVG_CMT). (c) Calculate the average ram (AVG_RAM). (d) If STR ≥ AVG_STR then STR = 1, Else if STR < AVG_STR then STR = 0. (e) If CMT ≥ AVG_CMT then CMT = 1, Else if CMT < AVG_CMT then CMT = 0. (f) If RAM ≥ AVG_RAM then RAM = 1, Else if RAM < AVG_RAM then RAM = 0.). (iii) Train the CNN with the training set {STR, CMT, RAM}. (iv) Test the CNN in the real time, for example: Tags: [suitable, not suitable], Tag Vector: [0,1,1]. The server is labeled as "not suitable." It is only labeled as "suitable" in case the Tag vector is equal to [1,1,1]. The suitable servers with their data are stored in Fog Suitable Table (FST), which is located at the FRM server as shown in Table 4.

Table 4 Fog suitable table (FST)
Full size table
figure a
Training and testing the CNN with the features of the fog servers in the FRT is better than training with the required features of the incoming process. In case of training and testing the CNN with the features of the fog servers, load balancing will be occurred as it selects the most suitable server, which has enough storage and processing. While, in case of matchmaking as in [64], it selects the most suitable server for the incoming process. The selected server in [64] may be with small storage capability and when this process assigned to it, it will become overloaded. This issue is not found in EDLB.

Illustrative example
Consider five servers as shown in Table 5 and incoming process P1 with requirements {STR = 4, CMP = 4, RAM = 3}. In case of [64], FS1 will be selected; however, there is another suitable server with larger storage. After assigning P1 to FS1, it will be overloaded. In case of EDLB, FS3 will be selected. After assigning P1 to FS3, it is still balanced.

Table 5 Servers' capabilities
Full size table
Optimized dynamic scheduler (ODS)
The optimized dynamic scheduler (ODS) is responsible for assigning the incoming process to the most appropriate server. The scheduling process is done using ODS as shown in Fig. 8 and Algorithm 2. ODS selects the most appropriate server between the available suitable servers from the FRT based on the modified particle swarm optimization (MPSO) algorithm. The steps of ODS are as follows:

(i)
Assign gbest = Vi, where gbest is the global best solution and Vi is an initial value.

(ii)
Assign BS = S0, where BS is the best server which is the most appropriate to the incoming process and S0 is an initial value.

(iii)
For each solution {available suitable server (Si) at FRT}, calculate the fitness value (FVi) using fuzzy logic via the three parameters stored in FST which are STR, CMT, and RAM.

(iv)
If FVi > gbest then (gbest = FVi and BS = Si).

(v)
Assign the incoming process to BS.

Fig. 8
figure 8
Optimized dynamic scheduler (ODS)

Full size image
figure b
Implementation and evaluation
This section performs a comparative experiment between EDLB and the previously mentioned LB algorithms to validate the EDLB's efficiency (WRR, GA, and BLA).

Used dataset
Table 6 shows a simulated dataset consisting of 200 servers that will be used in this paper as a typical example to help understand the discrepancies between EDLB and the previous LB algorithms listed.

Table 6 Considered available servers dataset
Full size table
Consider Table 7, which represents a simulated dataset consisting of 150 incoming tasks that will be used as common example throughout this paper to better understand the differences between EDLB and previous listed LB algorithms.

Table 7 Considered incoming tasks dataset
Full size table
Performance metrics
EDLB performance compared with the previously mentioned LB algorithms by considering the metrics shown in Table 8.

Table 8 Performance metrics to evaluate the proposed EDLB scheme
Full size table
The makespan is defined as the total time needed to complete all tasks. The formula for calculating the makespan is shown in Eq. (1).

Makespan=Max(CT(ti))
(1)
where CT is the time at which task ti completes its execution. CT is calculated using (2) and TAT is calculated using (3)

CT(ti)=AT(ti)+TAT(ti)
(2)
TAT(ti)=WT(ti)+BT(ti)
(3)
where TAT: is the turnaround time, WT: is the waiting time, AT: is the arrival time, and BT: is the burst time. ARU can be calculated as in (4) and LBL can be calculated as in (5).

ARU=(BS+OL)FSs×100%
(4)
LBL=BSFSs×100%
(5)
where BS: is the number of balanced FSs, OL: is the number of overloaded FSs, and FSs: is the number of all available fog servers. The total cost for a set of tasks at a specific time can be calculated as in (6).

Total cost=∑i=0nCP(ti)+CM(ti)+CB(ti)
(6)
where CP: is the processing cost (i.e., CPU usage cost per time), CM is the cost of memory usage, CB is the cost of bandwidth usage, and n is the number of the tasks at a specific time.

With GA, BLA, and WRR, the EDLB algorithm was compared. The values of makespan are shown in Table 9 and Fig. 9, respectively. Table 10 and Fig. 10 display the values of ARU. The LBL values are shown in Table 11 and in Fig. 11. The values of the net cost are shown in Table 12 and Fig. 12.

Table 9 Makespan analysis (in ms)
Full size table
Fig. 9
figure 9
Makespan for EDLB versus previous LB algorithms

Full size image
Table 10 ARU analysis (%)
Full size table
Fig. 10
figure 10
ARU for EDLB versus previous LB algorithms

Full size image
Table 11 LBL analysis (%)
Full size table
Fig. 11
figure 11
LBL for EDLB versus previous LB algorithms

Full size image
Table 12 Total cost
Full size table
Fig. 12
figure 12
Total cost for EDLB versus previous LB algorithms

Full size image
Figure 9 shows that as opposed to previous LB algorithms, the EDLB algorithm provides lower Makespan. Figures 10 and 11 reveal that as the higher ARU and higher LBL were obtained, the EDLB algorithm yielded improved performance relative to previous LB algorithms. All of the above results have also shown that, relative to GA, BLA, and WRR, the EDLB algorithm performs better for makespan, ARU, and LBL. Comparing the proposed algorithm with the state-of-the-art algorithms, the experimental results revealed that the power consumption of the algorithm can be decreased and the number of migrations reduced. Also a certain cost should be paid for the bandwidth, memory usage, and processing. From Fig. 12, it is obvious that the total cost was significantly less in the EDLB method than that in previous algorithms. EDLB has taken into consideration many factors to achieve these results. EDLB has combined CNN with PSO to divide the resources and reduce the scale of the resource search which leads to efficient resource utilization. CNN is a good choice for achieving high accuracy on resource management tasks. There is another advantage of using CNN where there is no need of feature extraction. Another reason for EDLB to achieve such acceptable performance is using MPSO. MPSP used fuzzy logic to calculate the fitness value (FVi) using via the three parameters stored in FST and assign the incoming process to the BS. Fuzzy is fast and accurate in determining the fitness value.

Conclusions and future work
In this paper, an effective dynamic load balancing technique (EDLB) using convolutional neural network and modified particle swarm optimization (MPSO) was proposed. EDLB is composed of three main modules, namely: (i) fog resource monitor (FRM), (ii) CNN-based classifier (CBC), and (iii) optimized dynamic scheduler (ODS). The main purpose of EDLB is to achieve LB in FC environment via dynamic real-time scheduling algorithm. This paper studies the FC architecture for healthcare system applications. The FRM is responsible for monitoring each server resource and saves the server's data into table called fog resources table (FRT). The CNN-based classifier (CBC) is responsible for classifying each fog server to suitable or not suitable. The optimized dynamic scheduler (ODS) is responsible for assigning the incoming process to the most appropriate server. Comparing EDLB with other previous LB algorithms, it reduces the response time and achieves high resource utilization. Hence, it is an efficient way to ensure the continuous service. Accordingly, in fog computing, real-time systems such as the healthcare system, EDLB is easy and efficient. Although several methods in LB for FC have been introduced, they have many limitations. EDLB overcomes these limitations and achieves high performance in various scenarios. It achieved better makespan, average resource utilization, and load balancing level as compared to previously mentioned LB algorithms. A real-time task failure with EDLB may occur due to an unexpectedly heavy demand on the server hosting that task. To address this problem, the system should reschedule a crucial work to a new server when an unexpected abrupt load is observed on a server that hosts a real-time task. This, however, necessitates pausing the task and storing its current state. Furthermore, if no open servers are available to host this work, the rescheduling procedure will take a long time, and there will be numerous migrations, which will impact system performance. We want to tackle this problem correctly in the future so that clients can have a better quality of experience (QoE) and quality of service (QoS).