Developing effective and efficient data stream classifiers is challenging for the machine learning community because of the dynamic nature of data streams. As a result, many data stream learning algorithms have been proposed during the past decades and achieve great success in various fields. This paper aims to explore a specific type of challenge in learning evolving data streams, called concept evolution (emergence of novel classes). Concept evolution indicates that the underlying patterns evolve over time, and new patterns (classes) may emerge at any time in streaming data. Therefore, data stream classifiers with emerging class detection have received increasing attention in recent years due to the practical values in many real-world applications. In this article, we provide a comprehensive overview of the existing works in this line of research. We discuss and analyze various aspects of the proposed algorithms for data stream classification with concept evolution detection and adaptation. Additionally, we discuss the potential application areas in which these techniques can be used. We also provide a detailed overview of evaluation measures and datasets used in these studies. Finally, we describe the current research challenges and future directions for data stream classification with novel class detection.

Access provided by University of Auckland Library

Introduction
Data stream mining covers many tasks, like frequency counting, clustering, time-series analysis and classification. Among all these tasks, the data stream classification has been the most focused and significant research area over the past decade [17, 89, 122, 165]. As a result, several algorithms have been proposed and gained considerable attention from the industry as well [20, 37, 46, 56, 74, 83, 100, 131]. Data stream classification slightly differs from traditional static data classification task. Data stream classifiers continuously receive data sequentially at a very high speed, while in a static setting, all the data is available at once to train a classifier. Additionally, while dealing with the massive amount of online data, the data stream classifiers must work with limited time and memory.

Moreover, the nature of the data stream is non-stationary, which means that the data distribution with time evolves. This phenomenon is known as the concept drift [55, 68, 73, 88]. Due to concept drift, the classifier trained from previous data can become obsolete/ ineffective for incoming data. Therefore, concept-drifting learning algorithms must be adaptive to evolving concepts. A variety of concept-drift learning methods have been proposed over the past decades [18, 23, 66, 72, 136, 137].

Another important challenge for learning algorithms in data streams is the concept evolution (emergence of novel classes) [1, 95, 114, 145, 153, 168]. For traditional classification tasks, the number of classes is predefined, and a classifier is constructed to classify the test data in these known classes. In many real-world data stream applications, however, the concept of underlying problems can evolve over time. Specifically, new patterns (classes) can emerge at any time during the streaming data. For illustration, consider the intrusion detection system as an example. Firstly, we train a classifier from certain types of known attacks (classes). This classifier only recognizes the attacks on which it was trained previously and cannot identify a new kind of attack (class) when it appears. Novel class identification is also crucial in the case where an important class is underrepresented in the initial phase of training [41, 43, 51, 123, 124, 141, 166, 170]. Figure 1 provides a simple example for illustration. At the start (see Fig. 1a), we have initial training data with two classes, and a classifier is first trained based on the initial data. Over time, we can see that a concept drift happens (Fig. 1b). Additionally, some data points associated with the novel class are evolving (see Fig. 1c). Here, the black filled points are outliers, data points in the dashed circle are drifting points, and green filled data points indicate the data points with a new class (i.e., concept evolution). Thus, a significant challenge is to distinguish between the actual emerging class from drift in the existing classes or a noise.

Fig. 1
figure 1
The challenges of data stream classification in the presence of concept drift, concept evolution and outliers. Blue and red dots are existing classes, green dots are novel class, and black dots are outliers

Full size image
Data stream classification with emerging class identification refers to learning algorithms that can detect and learn new classes. This becomes an important research challenge because of its practical significance in many applications such as text mining [80, 148], intrusion detection [128], fraud detection [151], power distribution networks [93], activity recognition [1, 115], bioinformatics [141], fault diagnosis [166] and runoff simulation [157, 163]. The novel class detection system allows us to significantly reduce human efforts that would otherwise be needed to fix incorrect classifications due to unidentified emerging classes manually. Additionally, the system can learn or discover novel patterns that we did not initially anticipate.

In academic literature, concept evolution is considered from two viewpoints, i.e., concept evolution adaptation and novel class identification and adaptation. The former task is concerned with how to adapt new classes from the data stream to maintain an efficient classification model without explicitly detecting the novel class [52, 53, 81, 92, 101, 114, 119, 145, 168, 172]. But recent research is more concerned with how to detect possible new classes and provide automatic assistance in data labeling.

Learning evolving data stream is a hot research topic, and many survey papers [68, 74, 100, 122] have been published in the literature over the past years. These survey papers provide theoretical foundations and insights into both the established and the state-of-the-art learning algorithms. However, these surveys do not cover the concept evolution learning algorithms. In 2015, a survey paper related to novelty detection [61] was published. However, this survey paper provides an overview of only 12 research papers. Since then, several new state-of-the-art algorithms have been proposed. Therefore, it is necessary to integrate and evaluate these algorithms to provide the most recent research trends on data stream classification with novel class detection, which is one of the primary focus of this research.

The main contributions of the paper are summarized as follows.

Provide a comprehensive review of different state-of-the-art algorithms for data stream classification with novel class detection in the literature.

Provide deep insight into the existing works and analyzes the strength and weaknesses of each algorithm.

Provide a taxonomy of literature on novel class detection with respect to different aspects.

Provide an experimental comparison between different algorithms.

Provide a discussion on the potential application areas in which these techniques can be used.

Provide a list and description of available benchmark datasets and provide a discussion on evaluation measures that are used for performance comparison.

Provide a summary of the available software tools for data stream mining, especially the link of source codes of different novel class detecting algorithms, is also provided.

We also highlight the significant research challenges that need to be addressed in the coming years. We hope that this survey will provide inspiration and a roadmap for the development of new methods in this research area.

The remaining paper is organized as follows. Section 2 provides some fundamental concepts related to data stream. Section 3 presents the categorization of proposed algorithms from different aspects. The review of the proposed algorithms is presented in Sect. 4. Section 5 discusses the limitations of the reviewed algorithms. Section 6 presents evaluation measures and used in different algorithms. Section 7 presents the empirical study. Section 8 presents the application areas, datasets used in different algorithms, and some open-source tools for mining streaming data. The paper ends with Sect. 9 with concluding remarks and future research directions.

Preliminaries
Notion and notations
Definition 1
(Data stream) A data stream is a potential infinite sequence of data items, which are continuously arrive at a rapid speed. Mathematically, let us define a data stream as D={(xt,yt)}∞1. Here, pair (xt,yt) is a data item arrived at a time stamp t, xt∈Rn is a n-dimensional feature vector and yt∈Y={c1,c2,…,ck} is the ground truth, i.e., a class label (if available) associated with the data item.

Definition 2
(Concept drift) Concept drift occurs when a source that generates data changes over time. Formally, let’s take St (data distribution) as sources generating instance xt at the time point t. A concept drift occurs when two instances x0 and x1, with the timestamps t0 and t1, are generated from different sources, i.e., St0≠St1. According to [68], this change can take different types of forms; that is, it may be due to a change in the characteristics of the input data (i.e., P(x)) or a change in the relationship between the input data and the target labels (i.e., P(y|x)). Mathematically, concept drift between two timestamps t0 and t1 can be defined as follows.

∃X:Pt0(x,y)≠Pt1(x,y).
(1)
Here, Pt represents the joint distribution between the feature vector x and class label y at time t. According to [149], the changes in the data may be due to a change in the posterior probabilities of the classes P(y|x) or to a change in the distribution of the class P(y) or change in feature space P(x). Change in the feature space P(x) is known as virtual drift, which may or may not affect the decision boundary. Also, it important to note that a change of P(y|x) (with or without a change of P(x)) is considered a real concept drift, because a change in P(y|x) affects the decision boundary [68].

Definition 3
(Anomaly, outlier and novelty detection) An anomaly is usually defined as an irregularity, or a noisy event in the normal data [5, 40, 129]. The task of anomaly detection is to find unexpected or abnormal behaviors (patterns) in normal data. In the literature, other names given to these patterns are contaminants, peculiarities, surprises, exceptions, outliers, anomalies [28, 38, 40]. Aggarwal et al. [3] describe outlier as a data item that can be regarded as an irregularity, a noise, or an abnormality. In contrast, an anomaly is considered as a particular type of outlier that needs the attention of a specialist. According to [39], outliers can be contenders for abnormal data, which can severely affect systems. Examples of outliers are a human fault, changes in the environment, instrumentation malfunction and malicious events.

Anomaly and outlier detection is often used in the literature as a synonym of novelty detection [21, 42]. Novelty detection referred to the task of detecting data items that significantly different from the data that is available in the training set [102, 103]. For [67], novelty or novel concepts (patterns) are cohesive groups of data items whose characteristics largely differ from normal data, while outliers are simply sparse independent data items without representing any new concepts. Mostly, novelty detection problem is taken as a one-class classification [21, 130]. In this, a classifier is trained from only one class data representing the normal or positive class, and the task is to distinguish between normal and abnormal data (i.e., binary classification).

Definition 4
(Concept evolution) Let Y={c1,c2,…,ck} be a set of classes from a training set on which a classifier is trained. This dataset represents the known concepts about the underlying problem and the classes in the set Y are called known or existing classes. During the streaming data, a new class appears that is not present in the set Y. That is, a class c appears at the time t if c∉Y. Such a class is called an emerging class. This phenomenon is called concept evolution [107, 109]. It is also important to note that the class c remains a new class until examples belonging to the class c are labeled and incorporated in the classifier. As an example, Fig. 2 depicts the concept evolution in image classification in data stream.

Fig. 2
figure 2
Illustration of concept evolution. Initially, we have two classes and over time two more classes emerge during the stream

Full size image
Problem formalization
Data stream classifiers with emerging class detection usually work in two phases: warm-up and online phase [61].

Fig. 3
figure 3
The workflow of data stream classification with emerging class detection. Initially, in the warm-up, a model is learned from training data. In the online phase, the learned model perform three tasks, namely: (i) novel class identification, (ii) classification of the existing or known classes and (iii) updating the model with the latest data and incorporate newly detected classes into the model

Full size image
Warm-up phase
In this phase, a model (f:X→Y) is first learned with some initial training dataset, i.e., X=Dinit={(xi,yi)}m1. Here, xi∈Rn is an n-dimensional feature vector, yi∈Y={c1,c2,…,ck} is associated class labels.

Online phase
In this phase, model f learned in the warm-up phase is used both for classification and emerging class identification simultaneously. In the online phase, the learned model has to perform three tasks, namely: (i) novel class identification, (ii) classification of the existing or known classes and (iii) updating the model with the latest data and incorporate newly detected classes into the model [116].

In general, for incoming instances in the streaming data, the current decision model first filters the instances to determine whether they are likely to belong to the existing classes or potential emerging pattern. If the instances are likely to belong to the existing classes, their class labels are predicted by the model. Otherwise, the instances are marked as potential emerging class instances and stored in a buffer. Afterward, the buffer is periodically examined for a novel class. If a novel class is found it is incorporated in the model by expanding the label set Y={c1,c2,…,ck,ck+1}. So that it can correctly classify the future instances belonging to this new class. In evolving data streams, an important aspect is to keep the learning model up-to-date with the latest data to cope with concept drift and implement forgetting mechanisms to remove the outdated concepts from the model. The overall workflow of stream classifiers with novel class detection is depicted in Fig. 3.

Taxonomy of proposed approaches
Taxonomy to categorize novel class detection approaches for data streams can be based on several criteria [61]. The focus of this study is to analyze different aspects of data stream classifiers with emerging class identification. Therefore, grouping or categorization can be made according to the following criteria. Figure 4 shows the categorization of proposed algorithms from different aspects.

Number of classes considered: One-class/Multi-class

Number of classifiers used: Single/Ensemble

Type of learning used in online phase: Unsupervised/ Semi-supervised/ Supervised

Classifier construction: Cluster-based/Model-based

Number of labels associated with data: Single/Multi-label

Other relevant aspects

Handling outliers

Handling recurring contexts

Handling feature evolution

Number of novel classes detected: One/Multiple

Forgetting mechanism.

One or multi-class classification
Several proposed approaches work within the framework of one-class classification [10, 79, 90, 133, 142,143,144, 146]. In these approaches, a classifier is trained from only one class data representing normal or positive class and the task is to distinguish between normal and abnormal data. The output of these classifiers is binary, i.e., all the test instances are classified as normal by the model if they represent the normal class. Otherwise, the instances are marked as unknown or abnormal. A group of cohesive unknown instances is then declared as a novelty or new class, while other approaches proposed in [1, 2, 7, 7,8,9, 16, 29, 44, 48, 49, 58, 64, 65, 70, 71, 75,76,77, 84, 85, 104,105,111, 117, 120, 125, 126, 138, 155, 156, 160,161,162, 167] are multi-class classifiers. In these approaches, a classifier is trained with a dataset that has multiple classes. The learned classifiers are then able to distinguish between multiple classes of data and detect the appearance of new classes.

Single or ensemble classifiers
The second aspect of categorization is number of classifiers used to build a learning model. Several approaches [7, 30, 44, 49, 60, 63, 71, 79, 85, 116, 131, 142,143,144, 155, 156, 161] build a single learning model which is incrementally update during the stream progress, while techniques proposed in [2, 8, 9, 33, 58, 64, 65, 70, 75,76,77, 84, 104,105,106,107,108,109,110, 120, 125, 126, 138, 160] use ensemble of classifiers to build the learning model.

Type of learning used in online phase
Another important aspect of categorization to be considered is the type of learning used in the online phase. Therefore, based on this, approaches in this area can be categorized as unsupervised, semi-supervised and supervised. Unsupervised methods proposed in [7, 30, 33, 44, 60, 63, 70, 71, 79, 85, 116, 118, 131, 142,143,144, 155, 156, 171, 173] are based on the assumption that class labels for training data are available only in initial model construction in the warm-up phase and no external feedback (class labels) is available after that. These methods update the model using unlabeled instances. In semi-supervised methods [1, 29, 75,76,77, 110, 120, 167], the classification model is updated with partially labeled data, while supervised methods [2, 7,8,9, 16, 48, 49, 58, 64, 65, 84, 104,105,106,107,108,109, 111, 117, 125, 126, 138, 155, 156, 160,161,162] assume that the class labels for all incoming streaming data will be accessible after a delay and classification model is updated with the true class labels.

Fig. 4
figure 4
Taxonomy of novel class detection algorithms from different aspects

Full size image
Classifier construction
In the literature, different approaches use different types of techniques to construct the learning model. Therefore, based on the classifier construction, these approaches can be divided into two types: clustering-based [2, 7, 9, 44, 58, 60, 63, 65, 71, 79, 85, 104,105,106,107,108,109, 116, 125, 131, 142,143,144, 155, 156] and model-based [30, 64, 65, 90, 116, 118, 125,126,127, 133, 146, 167, 171, 173] learning algorithms.

Number of labels associated with data
Traditional supervised learning tasks consist of creating a classifier from a set of data, with each example of the dataset being associated with a single class (label) from a set of classes. In learning environments with multiple labels, an example can be associated with different labels [32, 164]. In recent years, research into multi-label learning has received increasing attention due to its applied significance in many applications such as tag recommendation [86], bioinformatics [112], text mining [150], information retrieval [158]. Given its importance, some algorithms [85, 118, 171, 173, 174] are also proposed to identify emerging labels in the field of multi-label learning.

Other relevant aspects
Similarly, some other important aspects are also needed to consider when developing new algorithms. These aspects are not addressed by all approaches. These include handling outliers, recurring context identification, feature evolution and detecting one or more-than-one novel class(es).

Outliers
Outliers are sparse and isolated data items that have significantly different characteristics from normal data [40]. The learning algorithm needs to handle outliers because the presence of outliers can severely degrade the classifier performance as these outliers can be viewed as novel class or change in the existing classes due to concept drift.

Recurring contexts
Recurring contexts are the concepts that were learned in the past by the learning algorithm and may reappear in the future [6, 87]. It is a special type of concept drift. Therefore, if a concept recurs, it is imperative to identify it as an old concept instead of considering it as a new concept. Because learning an old concept again for each reappearance would be a waste of time and effort for already learned concepts. To solve this problem, some techniques [8, 9, 60, 63, 105], save obsolete concepts instead of discarding them. The saved concepts are then analyzed for possible recurring context identification to ensure good classification performance in a cost-effective manner.

Feature evolution
Feature evolution is also a major problem in dynamic data streams. Traditional learning algorithms work with the fixed-size feature set, where the classifiers and test instances have similar feature space, however, new features may appear in data streams (such as text streams), and some old features may disappear during the streaming of data. Emerging class identification in feature evolving data streams is not a trivial task. Few works [2, 106, 125,126,127] have been proposed to solve this problem.

Forgetting mechanism
In dynamic data streams, the distribution of data can change over time. Learning algorithms must adapt to changing concepts with the latest data. Some algorithms also implement a forget mechanism to remove outdated concepts from the model that have been learned previously to make the model inline with the recent trends in the data.

Number of novel classes detected
Several techniques from the literature identify emerging pattern(s) as one class, i.e., they assume that only one class may appear at a time in the stream, while other approaches [60, 63, 107, 108] consider that multiple novel classes can emerge simultaneously over time. Thus they can identify multiple class at the same time.

Review of proposed algorithms
The taxonomy we follow here, which categorizes the stream classifiers with emerging class identification, is based on the construction of learning models. In the literature, different approaches use different types of techniques to construct the learning model. Therefore, based on the classifier construction, these approaches can be divided into two types: clustering-based and model-based learning algorithms. In the following sections, we briefly discuss each algorithm. Figure 5 shows the categorization of proposed approaches based on classifier construction.

Fig. 5
figure 5
Categorization of proposed approaches based on the classifier construction

Full size image
Clustering-based learning algorithms
The clustering-based learning algorithms are well-known methods of novel class recognition. The main idea of these algorithms is to create decision boundaries for learning models by applying some clustering algorithms (such as k-means or DBSCAN) to represent normal or known concepts (classes). A hypersphere represents every cluster of the model in the feature space by its center and radius. All test instances located within the hypersphere are classified as belonging to the normal concept. In comparison, instances residing outside of hyperspheres are marked as outliers (probable new class instances) and temporarily stored in a buffer for further analysis. Due to concept drift, the buffer may contain instances belonging to normal concepts or actual outliers. As a result, different algorithms apply different strategies to separate novel class instances from known class examples and outliers. Finally, a new class is declared if a group of cohesive outliers (with similar characteristics) is found. Figure 6 depicts the working of cluster-based algorithms. Approaches in this field can be further categorized into single or ensemble classifiers.

Fig. 6
figure 6
Working diagram of cluster-based algorithms. Here, we have two classes (blue and green) and their corresponding cluster boundaries. Test instances (+) that fall inside the cluster boundaries are classified as an existing class instance. Similarly, other instances falling outside are further classified as outliers, drift in the existing classes and novel pattern

Full size image
Clustering-based single classifiers
In these classifiers, a single cluster-based learning model is built which is incrementally update during the stream progress.

Early algorithms like [79, 142,143,144] work under the framework of one-class classification. Spinosa et al. [142,143,144] proposed a technique called OLINDDA. Initially, OLINDDA created a learning model by clustering the training data of a single class into k clusters. Afterward, incoming stream instance which is outside the cluster boundaries is stored in a buffer. For novel class detection, the instances in the buffer are first divided into k clusters. Any new cluster that meets the conditions for cohesiveness and representativeness is considered a valid cluster. Cohesion (like cluster density) is used to measure the degree of likeness between instances of a cluster, while representativeness is a minimum of instances that belong to a cluster. Once the valid clusters are identified, OLINDDA then creates a macro-hypersphere that is defined by the center and radius. The center of the macro-hypersphere is the center of all clusters of the normal model, and the radius is determined by the distance between the center of the macro-hypersphere and the farthest cluster centroid. For all validated clusters, if their centers are in a macro-hypersphere, they are considered an extension of the normal model. Otherwise, they are considered novelties. All valid clusters are then added to the learning model.

Hayat et al. [79] proposed a technique called DETECTNOD. It is also a single class classification model. In this technique, however, after creating clusters, each cluster is subdivided into sub-clusters. For every sub-cluster, total instances are set to the same number by using interpolation. To further reduce memory usage, the DCT is applied to each sub-cluster and only a few DCT coefficients approximating the original data are retained. For each incoming stream instance, the closest sub-cluster closest in the model is selected and an unknown score is calculated. Which is the difference between DCT coefficients before and after merging the instance with the closest sub-cluster. Instances for which the score is greater than a threshold are marked as unknown and moved to a buffer. For emerging class identification, instances in the buffer are clustered, the number of instances is set to the same value by interpolation, and the DCT is applied to each cluster. The similarity between the candidate clusters and their closest sub-clusters in the model is then calculated. If the similarity is lesser than a threshold, the cluster is identified as a novel, otherwise, it is considered as an extension in the normal concepts. To avoid increasing the memory usage, sub-clusters that are not used for a long time are replaced by new clusters.

Faria et al. [60, 63] proposed a technique called MINAS for classifying multiple classes. In this scheme, the initial set of training dataset is first divided into subsets, each subset containing the instances of a single class. Then, the data in each subset are clustered and a summary of each cluster, such as the center point, the radius and the label, indicating each class to which it belongs is stored in micro-cluster. Each instance that falls within the micro-cluster boundary receives the label of the nearest cluster, while instances falling outside are clustered and clusters with fewer instances than the given threshold are discarded. New clusters that are near (based on distance) to the existing micro-clusters considered concept drift in known classes and receives the labels of their closest micro-clusters in the model. Otherwise, the new clusters are declared as a novel class. Each valid cluster is then added to the current model. After a specified period, the micro-clusters that do not receive a sample are removed from the model and stored in a sleeping memory. Similarly, the work presented in [85] is an extension of MINAS algorithm and proposed a multi-label learning algorithm for streaming data. Another technique similar to MINAS is also proposed in [71].

An extension of the MINAS algorithm [63] is proposed in [44], called FuzzND. This method uses the Fuzzy C-Means (FCM) clustering algorithm to create a set of supervised fuzzy micro-clusters (SFMiC) defined in [45]. For each incoming instance, the membership value is calculated for all micro-clusters in the current model. Membership values for each class micro-clusters are added and stored as a class compatibility value. Instances with maximum class compatibility higher than a threshold are classified as existing class instances, while others are stored in a buffer. To discover novel class, the buffered instances are first clustered with FCM. A fuzzy silhouette coefficient [35] is then calculated for each new cluster. New clusters whose silhouette coefficient is less than zero or whose number of samples is smaller than a certain threshold value are discarded, but their samples remain in memory. For all new valid clusters, a fuzzy cluster similarity [154] between new clusters and all existing clusters in the model is calculated. If the similarity is greater than a predefined threshold, the new clusters are tagged with the label of maximum similarity cluster. Otherwise, the clusters are declared a new class. FuzzND deletes the clusters that have not been updated for some time and removes old instances from the buffer.

CluMC [155] and McStream [156] algorithms are based on DenStream [36] clustering algorithm and maintain the summary of the data stream in two types of micro-clusters: outlier and potential micro-clusters. Initially, several p-micro-clusters are created according to DenStream and the class label to each p-micro-cluster is assigned based on the majority class of this cluster while outlier-buffer is empty. Test instances falling inside labeled p-micro-clusters get their labels. During the online data maintenance, if the test instance is added into an o-micro-cluster and its weight becomes greater than or equal to a given threshold value, then the cluster is inserted in the potential buffer. Afterward, the DBSCAN [59] algorithm is applied to the entire potential-buffer. If the new p-micro-cluster is density-reachable from other labeled micro-clusters, it is considered an extension of the known concept and gets the label from the nearest micro-cluster. Otherwise, it is considered to belong to a new class. Finally, the weights of all micro-clusters will gradually decrease if no example is added. After a specific period, each micro-cluster, if its weight is below the given threshold, is removed from the buffer.

The framework proposed in [131] maintains two windows containing the instances of the previous batch and the new batch. First, a change detection algorithm E-CUSUM [11], is applied to combined data from two windows. If a significant change is detected, the data of the current batch are divided into k and k+1 number of clusters by the k-means clustering algorithm. Here, k is the number of known classes of the last batch. The resulting clustering outputs are then inputted to a silhouette function defined in [159]. The silhouette function computes a coefficient value for each instance by means of the within and between cluster dissimilarity. Then, the sum of the coefficients for all the instances achieved by each partition is compared, and the cluster partition for which the sum of the silhouette coefficients is larger is considered as the actual number of clusters. All the instances of current batch centroids receive the label of the closest pair of centroids in the previous batch. If the number of clusters in the previous batch is less than the current number of clusters, this means that one or more clusters are left unpaired. Unpaired clusters are then assigned an unknown label. On the other hand, if no substantial change is detected, instances of the current batch are classified.

The technique proposed in [162] called SVSCLASS keeps the decision boundaries in the kernel space for each class in the stream. For each class, a set of spheres is created and managed using SVDD (description of the supporting vector domain) [147]. For each sphere, information like support vectors, bounded support vectors, a center, a radius and a maximum distance between the bound support vectors and the center of the sphere are stored. The instances which lie inside the spheres of the existing classes are given the class labels of that spheres. All other instances outside the spheres are first clustered by SVC (support vector cluster) [22], and then a neighborhood graph is created to recognize new class instances, as described in [160]. Finally, after obtaining the labeled block, the current classifier is updated by shrinking, enlarging, or creating new spheres.

Similar to SVSCLASS [162] algorithm, the work proposed in [161] called ONCLAD keeps a set of support vectors (boundary list) for each class observed. These support vectors are extracted by using the General Support Vector Representation Machine (GSVRM) [34]. Whenever a new test block arrives, some instances are generated for each existing class using their boundaries. Then, an extended version of the agglomerative fuzzy k-means algorithm [94] is used to divide the generated instances and newly arrived instances into clusters. Clusters with most instances generated from a single class are termed as known clusters and unlabeled instances in those clusters are assigned the label with the majority class. For clusters where most instances are unlabeled, they are declared as new if the number of instances in this cluster is higher than a particular threshold value. Clusters containing very few instances and semi-known clusters, the outcomes of the agglomerative method are examined in the reverse direction, where the cluster is merged with other clusters. The current decision model is updated upon receipt of the actual labels by modifying the support vector lists.

Similarly, another micro-clusters-based k-NN method is proposed in [49], called EMC. In this technique, after creating a set of clusters, summary information such as the linear sum, the sum squared, the covariance matrix of each cluster is stored in micro-clusters. EMC uses an error-based method described in [137], and the decay function to learn the importance of each micro-cluster over time. This allows EMC to dynamically maintain micro-clusters by inserting new ones or delete obsolete micro-clusters. This technique uses the local density method with the Local Outlier Factor (LOF) [31] algorithm to discover a novel class. For this, some instances for each class in the current model are generated using the mean and covariance matrix stored in each micro-cluster. Outlier instances with a local density similar to their neighbors in known classes are declared as the existing class instances, while remaining outlier instances are declared as new class instances if the total number of instances is greater than the given threshold.

Clustering-based ensemble classifiers
Ensembles classifiers are naturally suitable and can easily be used in a streaming data environment. Because the construction of the ensemble is modular, a new component can easily be added to the ensemble [74]. They also have the capability to modify an existing member of the classifiers or change the weights of each classifier during the voting combination. The cluster-based ensemble classifier is divided into the chunk-based ensemble and a class-based ensemble.

Chunk-based ensemble In these approaches, the data stream is processed chunk by chunk. During the warm-up phase, the first L labeled chunks are used to create an ensemble of classifiers, that is, E={C1,…,CL}. Here, E is an ensemble and Ci are individual cluster-based classifiers. Only one classifier Ci is trained on each chunk. In the online phase, the ensemble is continuously updated by adding new classifiers and removing outdated ones. Figure 7 depicts the working of chunk-based ensemble classifiers.

Fig. 7
figure 7
Chunk-based ensemble training and update procedure

Full size image
Masud et al. proposed MineClass [109] and ECSMiner [104] ensemble classifiers where each classifier Ci is a cluster-based k-NN classifier. After creating clusters with the k-means clustering algorithm, summary information (called pseudo-points) for each cluster is stored. Test instances falling inside the decision boundary of the ensemble are classified by taking the majority of the votes in the ensemble. For all outliers instances, a measure defined in Eq. (2) (called q-silhouette coefficient or q-NSC) is calculated.

q-NSC(x)=DCmin,q(x)−DCout,q(x)max{DCmin,q(x),DCout,q(x)}.
(2)
Here, DCout,q(x), DCmin,q(x) is the average distance between an outlier x and its q-closest outliers and existing class instances, respectively (see Fig. 8 for illustration). According to the definition, an instance with a positive value of q-NSC means that x is closer to its outliers and away from an existing class. The q-NSC measure is calculated for each outlier and for each classifier in the ensemble. A novel class is declared if the number of outliers for which the value of q-NSC is positive is greater than a given threshold value. The work presented in [16], called ENCD, is based on MineClass [109] and uses an extra condition for creating a new classifier. In the MineClass, a new model is trained only after the most recent data block is completed. But in [16] whenever a new class is identified during the test chunk and a flag is set, a new classifier is trained and added in the ensemble. This algorithm does not wait for the test chunk to be completed to create a new classifier.

Fig. 8
figure 8
Illustration of q-NSC for q=5. Here, DCmin,q(x)=min(DC1,q(x),DC2,q(x))

Full size image
The techniques proposed in DECSMiner [106] and SNODSOC [2] also use the same strategy to build a cluster-based ensemble classifier as described in MineClass [109]. Additionally, these strategies provide a mechanism to handle feature evolution in the data streams. These techniques use two methods for feature extraction and selection: predictive and informative feature selection. In predictive feature selection, the feature set for incoming examples is predicted in a supervised way (e.g., using information gain) from the previously labeled examples, while in informative feature selection, a test chunk is used to select the feature set in an unsupervised way (e.g., highest frequency features). Finally, the authors proposed a homogeneous feature space conversion method (called “lossless homogenization”) in which the classifier and the test data convert their features sets to the union of their sets before classification.

Similar, another family of MineClass [109] algorithm is presented in [107, 108] under the name MCM. In these techniques, various improvements have been proposed with respect to the existing algorithm. For example, in MineClass, the decision boundary of each classifier is fixed, while in MCM, a dynamic slack space outside the decision boundary of each classifier is defined to improve the outlier detection. For novel class identification, MCM proposes a new technique based on discrete Gini Coefficient. In [107], for all instances that are outside the slack space, the measure q-NSC defined in Eq. (2) is computed. If the value of q-NSC for an instance is negative, this instance is considered an existing class instance and is removed from the buffer. Then, an another measure called N-score(x) defined in Eq. (3) is computed for each instance with a positive score for q-NSC.

N-score(x)=1−W(x)1−minWq-NSC(x)
(3)
where W(x)=er−d and r is the radius of the cluster closest to the instance x, d is the distance between x and the center of the nearest cluster, and minW is the minimum weight between all outliers with q-NSC positive value. To identify new class instances, the values of N-score(x) are discretized into n intervals. The cumulative distribution function (CDF) of N-score(x) and the discrete Gini coefficient are then calculated. A threshold is then determined to separate the new class instances. If the value of the Gini coefficient is greater than n−13n, all instances of the buffer are declared as new class instances. On the other hand, if the Gini coefficient is zero, all instances classified as the existing class instances. Finally, if the Gini coefficient is between [0, n−13n], the instances of the first interval are deleted, and the remaining instances are declared as belonging to a new class. MCM can identify multiple new classes at the same time by creating a graph of instances marked as new, and then searching for connected components in the graph, where each connected component represents a new, separate class, while in [108], after detecting and saving outlier in the buffer, the instances of the buffer are clustered using k-means to speed up the calculation of the q-NSC value. Subsequently, summary information (called O-pseudo point h) such as center point (h.u), Cluster size (W(h)) and radius is stored for each cluster. The q-NSC for an O-pseudo-point is calculated as follows.

q-NSC(h)=DCmin,q(h)−DCout,q(h)max{DCmin,q(h),DCout,q(h)}.
(4)
Here, DCmin,q(h) is the minimum weighted average distance from O-pseudopoint h to q nearest pseudopoint of the existing class e. Which is given by:

DC,q(h)=∑m1W(ei)D(h,ei)∑m1W(ei)
(5)
where D(h,ei) is centroid to centroid distance. Similarly, the mean distance DCout,q(h) from h to other O-pseudopoint is given by:

DCcout,q(h)=W(h)h.u+∑r−11W(hi)D(h,hi)W(h)+∑r−11W(hi).
(6)
Finally, the N-score defined in Eq. (3) is computed for all O-pseudo-points having a positive value. Then using the Gini coefficient and constructing a graph, multiple novel classes are identified. In addition, this algorithm also adopted the technique proposed in DECSMiner [106] to handle feature evolution in the data streams.

An extension of MCM [107] algorithm is proposed in [58] which introduces a technique to reduces the risk of false alarms from [107]. To further purify, the declared novel class instances are clustered using k-means, and the value of the number of clusters is chosen in a way to overestimate the actual number of clusters. After creating clusters, the density (ratio between the number of instances in the cluster and the average distance between them) of each cluster is measured. The cluster with low density or whose instances are below the given threshold value is eliminated. Similarly, another version of MineClass [109] and MCM [107] is also presented in DTNC [111]. In this paper, the authors proposed that using Very Fast Decision Tree (VFDT) [54] as base learners and k-prototypes++ as the clustering algorithm significantly improves the performance of MineClass. k-prototypes++ is a combination of two methods: K-means++ [15] and K-prototypes [82].

The work proposed in SCANR [105] consists of two ensembles, a primary and an auxiliary ensemble. The primary ensemble is created in the same way as described in MineClass [109], while the auxiliary ensemble is created for each class by creating a set of clusters and storing the clusters summaries. The auxiliary ensemble is maintained to remember each class in the data stream. Test instance falling inside the primary ensemble boundaries are classified by taking the majority voting among the classifiers. Test instances outside the primary ensemble boundaries are sent to the auxiliary ensemble for outlier detection. If the auxiliary ensemble declares the instances as outliers, then the technique of MineClass [109] algorithm is adapted to identify the novel class. Otherwise, the auxiliary ensemble considers them as the existing class instances.

In addition to the supervised algorithms, some techniques such as [69, 75,76,77, 110, 169] use semi-supervised learning algorithms to build the classification model.

The technique presented in [110] called ActMiner extends MineClass [109] and proposes an active learning-based semi-supervised algorithm. During the classification, ActMiner selects the most uncertain (weakly classified) instances and requests the user to provide actual labels for them. The measurement of uncertainty is based on two factors. A test instance is considered the most uncertain if it is declared an outlier or if the ratio between the majority votes and the total votes is lower than a certain threshold value called the minimum majority threshold.

Other techniques SCDMiner [75], SAND [76] and ECHO [77] use a similar method as described in ECSMiner [104]. ECSMiner maintains an ensemble of classifiers on data blocks with a fixed size, while these approaches maintain a dynamic window, which stores the classifier’s confidence score behind predicting the label of a test instance. This window, with the confidence scores, is then used to detect a change in the confidence of the classifier over time. If a significant change in the classifier’s confidence is detected, a change point is determined in the current window. Data after the change point is kept while old data is removed and the size of the window is reduced. The true labels for the instances of the current window where the classifier showed weak confidence in the prediction are requested from the user. For the rest of the instances, predicted labels are used as final labels and include them in the training data. If the change is not significant, the current ensemble is kept unchanged, and the window size continues to grow.

The work proposed by Mustafa et at. [120] trains a Denoising Autoencoder (DAE) by computing the weights (W and b) to extract deep abstract features before training a classification model. The learned weights are kept unchanged and used to transform the original input features of incoming instances to abstract features. Afterward, a classification model similar to ECSMiner [104] is trained for emerging class identification. A change detection method is also proposed to determine the chunk boundaries dynamically.

The work presented in [70] creates two clustering-based ensembles and integrates them into the MINAS algorithm [63]. Two clustering ensembles are referred to as homogeneous clustering (HoCluS) and heterogeneous clustering (HeCluS) for data Streams. The former ensemble is created by varying the Clustream [4] algorithm parameters to generate different cluster partitions for training data. The later ensemble is created using different clustering algorithms to generate multiple cluster partitions.

Class-based ensemble In the class-based ensemble algorithms, the training data is split into disjoint sets so that each set contains the instances of a single class. A classifier for each class is then created by clustering the data belonging to a single class and saving the summaries of each cluster. For each class, an ensemble of such classifiers is maintained and regularly updated with new data by training new per class classifiers and replacing them in the corresponding ensemble. Figure 9 illustrates the training and update procedure of class-based ensemble classifiers.

Fig. 9
figure 9
Class-based ensemble training and update procedure

Full size image
The technique proposed by Alkateeb et al. called CLAM [8, 9] is a per class ensemble algorithm and uses a k-means clustering algorithm to create a set of clusters for each class. Test instances outside the cluster boundaries for each class ensemble are analyzed for novel classes as described in ECSMiner [104]. To classify an instance, the distance between the instance and clusters of each per class ensemble is measured. The ensemble of class with minimum distance is declared as the class of the instance. Finally, the ensemble is updated upon receipt of a new labeled block by creating new per class classifiers and replacing them with the existing classifiers in the ensemble. In the CLAM algorithm, a per class ensemble is created on different data blocks while in another technique [84], each class ensemble is created on the same data by varying the seed parameters of the k-means algorithm which diversifies each classifier in the ensemble. In this algorithm, after receiving the labels of the most recent block, per class clusters are produced on instances that have been wrongly predicted by the classifier. For each newly created cluster, if the cluster center lies inside the existing cluster, they are merged. Otherwise, it is replaced with the cluster in the corresponding class ensemble that has the worst prediction performance on the latest block.

Similarly, LOCE [160] also maintains a set of cluster-based classifiers (called local classifiers) for each class. The output of these local classifiers is aggregated by a global classifier. Finally, all the outputs of the global classifiers are then aggregated to make the final prediction. Test instances for which the final prediction value is greater than a certain threshold are classified with the class label of the ensemble that generates the maximum value. For the detection of novel classes, a group of instances with low prediction values are first divided into clusters. A novelty score is then calculated for each cluster and clusters with positive scores are isolated from the other clusters. A neighborhood graph is then constructed with cluster centers (non-isolated and isolated) and their nearest centers in the existing ensemble. If an isolated cluster center is liked to a non-isolated cluster center or existing cluster center in the ensemble is removed. A novel class is declared if the instances in the isolated cluster are higher than a threshold.

Table 1 Clustering-based learning algorithms
Full size table
The technique proposed by Siahroudi et al. [138] creates and maintains an ensemble of combined kernels for each class. Each combined kernel consists of a static and a dynamic kernel. Only one static kernel is created for each class and is shared with the other combined kernels in the ensemble of the same class but can have a different weight, while for every upcoming block, a new dynamic kernel is created and combined with the static kernel. This newly created combined kernel is then replaced by an existing combined kernel that has not been used for a long time. Each combined kernel stores two values, namely the center of the corresponding class and a confidence distance. For each instance of the upcoming block, a new feature vector is first extracted, then a distance between the instance and all other classes is calculated. If the distance is lower than the reliability distance of the closest class, the instance receives the label from the nearest class. All other instances whose distance is higher than the class reliability are first clustered. Clusters whose size is larger than a given threshold value are identified as new class instances. Finally, the remaining instances are marked as outliers of the existing classes and classified using the minimum distance between the instance and all existing classes.

Another class-based ensemble approach is proposed by Abdallah et al. [1]. In this method, clusters are formed in two steps. The initial training data is first divided into separate classes, and then clusters are created for each class. In the second step, the clusters created in the first step are divided into smaller sub-clusters by applying the EM algorithm. Each sub-cluster represents a different pattern within the cluster. All new concepts (clusters) that are outside of all existing clusters and continuously move away from all existing clusters are declared as new class clusters. A forgetting mechanism is also implemented to remove old clusters (concepts) that are no longer compatible with recent concepts. To reduce labeling costs, the authors also proposed an active learning method. Finally, the summary of cluster-based algorithms is given in Table 1.

Similarly, the work presented in [33] extends iNNE [19] algorithm and creates a per class instance-based ensemble classifier. Each instance in the ensemble represents an isolation hypersphere defined by its radius. The radius of the hypersphere is determined by the distance between the instance and its nearest neighbor of the same class. For every test instance, if the distance between its nearest neighbor in each class ensemble is greater than a certain threshold it is declared new: otherwise, the nearest class is assigned as its label.

Model-based learning algorithms
Unlike clustering-based techniques, model-based learning techniques focus on finding a model for classification and detecting new classes. Here, different traditional learning models are adopted by different techniques and these models can be divided into the following categories.

Hierarchy-based ensemble algorithms

Decision tree-based algorithms

Graph-based algorithms

Sketch-based algorithms

Support Vector Machine (SVM) and Neural Network (NN) based algorithms.

Hierarchy-based ensemble algorithms
Parker et al. [125, 126] proposed a hierarchy of ensemble classifiers called HSMiner and SluiceBox, respectively. These methods built a hierarchy of ensemble classifiers. At the lowest level of the hierarchy, there is a base classifier for each attribute, and at a higher level, a per class ensemble is assigned. To classify an instance, it is passed down the hierarchy of ensemble and each base classifier at the bottom of the hierarchy cast a weighted vote in a continuous range [−1,+1]. The top tier ensemble then aggregates the votes into a final score. In HSMiner, two methods are proposed for emerging class identification. The first method is naïve and considers each instance as an emerging class whose final score is lower than a given threshold, whereas in the second method, a new single-class classifier is trained using instances with a “new” tag. Now, this new classifier is used to vote for every instance of the block. Instances whose final vote is above the threshold value are marked as “new.” This process is repeated several times, and ultimately, instances marked as “new” are considered as new class instances and the remaining instances from the existing classes, while SluiceBox uses clustering to detect new classes described in [109]. Similarly, another technique based on the SluiceBox algorithm is presented in [127], called SluiceBoxAM (AnyMeans). SluiceBoxAM can discover clusters with non-spherical shapes and can also be used with other classifiers, for example, with leveraging bagging [26]. The architecture of the hierarchy-based ensemble classifiers is shown in Fig. 10.

Fig. 10
figure 10
Hierarchy-based ensemble classifier architecture

Full size image
Decision tree-based algorithms
The technique presented by Farid et al. [64] is based on a decision tree classifier. After creating the decision tree from the training dataset, the instances of each leaf node are clustered. A threshold value is then calculated, which is a ratio between the total number of instances in the leaf node and the total number of instances in the training set. For each test instance, if its addition to the leaf node increases the threshold value and outside all clusters of the leaf node, it is considered an emerging class instance. An extension of this work is proposed in [65], which creates an ensemble of three decision trees (DT). In this algorithm, first, a naive Bayes classifier is used to weight the initial training instances with the highest posterior probability. After weighing the instances, the first DT is built using selection and replacement techniques in the weighted training set, while the other two DTs are built using the highest weighted instances, which is calculated based on their prediction accuracy of the first DT. Weight is also associated with each DT based on the accuracy of its predictions on the training set. If a test instance is outside of all clusters corresponding to the leaf nodes of all the trees it reaches, it is considered an outlier and placed in the buffer. In addition, a new flag is set to 1. Otherwise, weighted majority voting is used by the ensemble to classify the instance. When the value of the new flag is 1 and the ratio of the incoming instances classified by a leaf node increases or decreases relative to the previously calculated threshold value, the instances are considered as new class instances. When a labeled data block is available, a new DT classifier is formed and replaced by the low-precision DT.

The method proposed in [116], called SENCForest, is based on an unsupervised anomaly detector iForest (isolationForest) [97]. An iForest is an ensemble of randomly generated decision trees using a subsample randomly selected in the training dataset. After building an iForest, a threshold called path length is used to divide the data space into two regions, normal and anomaly regions. The path length is the average number of edges traversed by the training examples from the root node to a leaf node. Training instances where the path length is less than the threshold define the normal region. The anomaly region is again subdivided into two regions, the anomaly of known classes and the outlying region (see Fig. 11 for illustration). Test instances that fall inside the outlying region are considered instances of new classes and stored in a buffer. After the construction of the new class detector, the class labels of the known classes are recorded in the normal and anomaly sub-region of known classes. Each test instance that falls inside the normal or anomaly sub-region of known classes is classified by taking majority class labels in that region. In the proposed technique, the model is updated in two ways. First, the current model is updated by growing a new subtree in an existing tree if the number of instances in the leaf node exceeds a certain limit. Otherwise, the statistics of the leaf node are updated; that is, the frequency of each class is updated to include the new class. In the second method, if the number of classes that a SENCForest can handle reaches a pre-defined threshold, a new SENCForest is trained and added to the model.

Fig. 11
figure 11
Illustration of normal and anomaly regions defined in [116]

Full size image
The technique proposed in [171, 173] called MuENL is a multi-label classification algorithm with emerging label detection. For classification, MuENL trains a linear classifier for each label. To provide a better performance, they use label correlations among multi-labels where a pairwise label ranking loss is minimized. For novel label detection, MuENL extends iForest [97] algorithm with clustering to identify new labels. Instances that are outside the clusters in leaf nodes are placed in a buffer. When the buffer reaches a pre-defined limit, both classifier and detector are updated.

Similarly, another multi-label classification algorithm is proposed in [118] called NL-Forest. The framework of NL-Forest consists of two models: an instance-based model (I-F) and a label-based model (L-F). The former is created for the entire training set, while the latter is created for each label that is present in the data. Both models are created using random decision trees like iForest [97]. This algorithm can detect two types of emerging labels, namely an absolutely new label or a partially new label. For absolutely new label detection, the same technique is used as described in [116], while for partially new label detection, the test instance is first passed to the I-F, where the probabilities of the known labels are generated as a label vector. The vector is then arranged in descending order of known labels. Depending on the order of the labels, the test instance is then passed on to L-F, where the height of the test instance is measured from each sub-forest in L-F. If the average height of the instance is less than a threshold value, it is considered new. Finally, both models are updated when a group of novel labels is found.

Ting et al. [146] proposed an ensemble of half-space trees (HS) for one-class classification. An HS tree is a complete binary tree in which all leaf nodes are at the same depth. It works by maintaining two consecutive windows of data; one is called the reference window, and the other containing the most recent instances. During the initial learning, an ensemble of HS trees is induced by learning the mass profile (i.e., the number of instances reaching the tree nodes) of the data in the reference window (called mass r). For each instance of the incoming block, it is passed down to the hierarchy of each HS tree of the ensemble, and an accumulated score called anomaly score is computed. If this anomaly score is higher than a threshold value, the instance is considered anomalous. Otherwise, it is considered as belonging to the normal class. From every new recent window, a new mass profile is computed that replaces the old profile in the reference window.

Graph-based algorithms
In graph-based models [29, 30], a graph topology G (see Fig. 12) is built with instances as nodes and edges serving as a connection between different nodes. This graph is regularly updated by creating new nodes and connections between nodes as new data arrives. Each node of the graph represents the center of a hypersphere defined by its radius. All these hyperspheres cover the feature space and used to identify emerging classes as well as classify incoming instances as the existing classes. In [29], after receiving a block of instances, first, the instances are separated into two sets. The ones locating inside the hyperspheres as insiders and the ones which fall outside as outsiders. Meanwhile, a graph G^ is also constructed from the recent block. Then, for each instance, x in the new block, an average distance of x from its nearest nodes in G, and G^ is computed. Based on these values, a probability score of each instance x is calculated as follows.

P(N|x)=dExdEx+dNx
(7)
P(E|x)=dExdEx+dNx.
(8)
Fig. 12
figure 12
Left: synthetic data. Right: graph topology G [29]

Full size image
Here, dEx, dNx are the means distances from G and G^. If x belongs to a novel class then P(N|x) will be greater than P(E|x)). Afterward, an iterative procedure is adapted to refine further the set of insiders and outsiders, which may contain false positive or false negative instances. Insiders are then classified by nearest label nodes. It also requests for true class labels of weakly classified instances, while the technique proposed in [30] also provides an adaptation mechanism to cope with local changes in the feature space where the data distribution is changed. Additionally, an adaptive forgetting mechanism is also implemented to identify and remove irrelevant or obsolete nodes from the graph. Finally, a probabilistic evolutionary mechanism creates new neurons when it is necessary to represent data in new areas of the feature space. A test instance is considered a novel instance if the distance between the instance and its nearest node in the graph is greater than the average length of the current set of edges in the graph.

Sketch-based algorithms
The techniques presented in [117, 167] are based on the matrix sketching technique described in [96]. A sketch of a matrix is a small matrix that approximates the very large original matrix. The calculations on the sketch matrix can be performed without much loss of precision. These algorithms exploit the matrix sketching method and create two low-dimensional matrices (called Global and Local) sketches for streaming data. The “Global Sketch” (GS) is created on the entire training set, while “The Local Sketch” (LS) is created for each class in the data. Figure 13 illustrates the process of building both sketches.

For each incoming instance x, a similarity between x and each row of matrix GS is measured by taking the indoor product. If the similarity exceeds a threshold value, the instance is flagged as a potential emerging class instance and placed in a buffer. Otherwise, LS is used to classify the instance into one of the known classes. For this, the inner product between x and each local matrix sketching LSi for each class is calculated. When the buffer reaches a predefined limit, first, the instances in the buffer are sorted in ascending order based on the similarity values. Afterward, the list is subdivided into two sub-lists by searching a split point. The best split point between the two sub-lists is searched according to the following criteria.

τ=argminτ|σ(Vleft)−σ(Vright)|.
(9)
Here, is σ(.) is a standard deviation and τ is the best point. τ is the point that minimizes the standard deviation between the two sub-lists. After that, the GS and the LS are updated, and the buffer is reset. However, in [167], before building the sketches, a neural network is trained only with the initial training set for extracting features for each instance. Then with the extract features, the local and global sketches are built, while during online learning, the weights of the neural network are fixed. All the incoming data are first processed through the neural network, which extracts the features for each instance and then fed into the next module. It also used CFS (clustering by fast search) [132] algorithm to find multiple novel classes.

Fig. 13
figure 13
Global and local matrix sketching to approximate very large original matrix [117]

Full size image
Table 2 Model-based learning algorithms
Full size table
SVM and NN based algorithms
Krawczyk et al. [90] proposed a one-class classification algorithm based on WOCSVM (One-class weighted support vector machine) [24]. WOCSVM is based on OCSVM [134] and assigns a weight to each instance in the training data. These weights are used to minimize hypersphere volume, but still contain all the training data. After creating an initial WOCSVM classifier, incoming instances are classified as normal if they fall into the hypersphere. Otherwise, the instances are declared as a novel pattern. In this algorithm, two approaches are proposed to implement the forgetting mechanism. In the first approach, instance weights are decreased gradually over time, and instances with a weight of 0 are discarded. In the second approach, all instances of the old block are deleted when a new data block is received without considering the initial importance of the weights.

The work proposed by Rusiecki et al. [133] is also a one-class classification algorithm. This technique is based on a neural network (NN) and trains two autoregressive feedforward NN. To train the first NN, a robust learning technique is used that tries to minimize the error by reducing the influence of outliers on the training set. The second NN is trained using the traditional back-propagation technique that minimizes the least-squares error. These NNs are trained on a window with a predefined length that contains the most recent instances and moves in discrete periods. According to the authors, updating the NN for every incoming instance is computationally expressive. Therefore, a network is trained only once for a given period. When data of a predefined length is collected, it is then used to update the weights of the network. Because not all instances are used to train the NN, another parameter is also used that defines the distance between two windows. For each test instance, a response is calculated for both NNs. If the difference between the output of these two networks is below a certain threshold value, the instance is considered a normal class instance. Otherwise, the instance is marked as a novelty. The threshold used to separate novelties from normal data is calculated as follows.

Tr=k∗std(|ymse(xi)−ylmls(xi)|).
(10)
Here, ymse is the output of traditional NN and ylmls is the output of robust NN, std is the standard difference, and k is a user-defined constant.

The work presented in [152] is a CNN-based Prototype Ensemble (CPE). In this technique, a deep neural network is used to extract a set of prototypes (latent class distribution) for each class in the training set. For each incoming instance, the original input features are transformed into a representation of learned features via the network. The prototype closest to the test instance is then searched. If the instance is close to the existing prototype, it is labeled with the nearest prototype. Otherwise, it is placed in a buffer. When the buffer size reaches a predefined limit, the true class labels of the buffer instances are requested from the user. After obtaining the actual class labels, the prototypes of the new class were extracted and added to the model. The network parameters are also updated. At last, the summary of model-based algorithms is presented in Table 2.

Discussion
Although many exciting algorithms for the identification of novel classes in data streams have been proposed, the use of these algorithms in many real-world applications is not feasible due to various limitations. Many problems and challenges are still present and need to be adequately addressed for the development of efficient and effective learning algorithms.

The main limitation of cluster-based approaches is that they use a distance-based heuristic to identify new classes and drift in the existing classes. Defining an optimal distance threshold is a difficult task and depends on the data dynamics. Similarly, the majority of the techniques [8, 9, 49, 58, 60, 63, 71, 75,76,77, 79, 84, 104,105,106,107,108,109, 120, 125, 131, 142,143,144, 160] presented use the k-means clustering algorithm to create the model that requires predefined value of the input parameter (number of clusters). The main assumption of these algorithms is that the underlying data distribution can be represented by hyperspheres. The main drawback is that a fixed number of clusters cannot accurately capture the underlying data distribution, especially data with a non-Gaussian distribution [91]. Another potential problem with cluster-based techniques is that they usually do not produce good results with complex real-world high-dimensional data.

Most approaches [2, 7, 7,8,9, 16, 30, 44, 48, 49, 58, 60, 63,64,65, 71, 75,76,77, 79, 84, 104,105,109, 111, 116,117,118, 120, 125, 126, 131, 138, 142,143,144, 155, 155, 156, 156, 160,161,162, 171, 173] assume that the emerging pattern(s) are geometrically far from the existing classes in the feature space. This assumption is not realistic in many applications, where the class boundaries are very close to each other. Thus, these approaches cannot handle the classes with complex distribution that can lead to a high degradation in classification performance.

An important problem is related to ensemble-based approaches [8, 9, 49, 104, 107,108,109] that process the data stream in fixed-size chunks. Determining the size of the chunk is a non-trivial task and the performance of these algorithms mainly depends on chunk size. Few techniques use a change detection algorithm to dynamically determine the size of chunk. However, change detection using limited labeled data is also a non-trivial task [175].

Another limitation is related to supervised algorithms [2, 7,8,9, 16, 48, 49, 58, 64, 65, 84, 104,105,106,107,108,109, 111, 117, 125, 126, 138, 155, 156, 160,161,162] which need a complete set of labeled data to update / refine their models to deal with concept drift. However, labeling fast and continuous streaming data is impossible in many real-world applications [50]. In contrast, several other algorithms [7, 30, 33, 44, 60, 63, 70, 71, 79, 116, 118, 131, 142,143,144, 155, 156, 171, 173] assume a full set of labels only in the offline phase to induce a model. Afterward, in the online phase, they constantly update their models with unlabeled data. Thus, unsupervised algorithms are not suitable for real concept drift where the target label given the input data (P(y|x)) changes without change in the distribution of the data (P(x)). Similarly, to reduce dependence on fully labeled data, some techniques [75,76,77, 120] are based on an active learning framework and ask the user to provide labels for limited unlabeled data. These techniques then use limited labeled data along with classifiers own predicted labeled data to update the model. However, the cumulative error can increase if the data is wrongly predicted.

In a dynamic streaming environment, the evolution of features (appearance and disappearance of features) is also a critical problem. Most existing approaches can work with a fixed set of features and apply a new class detection procedure. Few algorithms address this problem, for example, [125,126,127] has proposed a set of hierarchical classifiers and created a separate classifier for each entity. However, such decomposition increases complexity and may not be suitable in scenarios where the attributes are correlated or irrelevant.

Some algorithms, such as [33, 64, 65, 90, 116, 133, 146], consider any change to be an evolution of the concept in the data. In these techniques, any instance, if not explained by the classifier, is considered a change without checking the cohesiveness between the examples of the new pattern(s). In dynamic streaming data, the existing concepts are constantly changing; therefore, it is essential to distinguish between the actual novel pattern from drift in the existing patterns or the presence of outlier or noise. Similarly, another important problem is determining when to execute the new class detection procedure. In some techniques [49, 138, 162], a new class detection procedure is performed each time a new block of data is received, while other techniques [29, 60, 63, 70, 79, 104, 142,143,144] define a fixed time interval or a fixed-size buffer to perform the detection procedure. Here, the main problem is the static values defined by the user for the execution of the detection procedure, the automatic definition of these parameters is still an open problem.

Evaluation measures
In static data learning algorithms, several well-known methods (such as leave-one-out, cross-over validation) are available to evaluate the performance of different algorithms. However, these standard methodologies are not suitable/applicable in data streams due to the dynamic or evolving nature of the data stream. For data stream classification algorithms, two methods for performance evaluation are often used: prequential and hold-out. The prequential method is also known as the test-then-train method, where each instance is first used to test and then update the classifier. Finally, the accumulated accuracy is calculated for all instances. In the hold-out method, the data stream is divided into training and test sets. Here, the learning model created on the training sets is tested at regular intervals with the test set.

However, little consideration has been given to the performance evaluation methods for stream classifiers with emerging class detection. Some algorithms have used different static data evaluation methods, while in others, new ad hoc methods have been developed to evaluate performance.

Algorithms presented in [7,8,9, 16, 49, 64, 65, 71, 75,76,77, 84, 104,105,111, 120, 125,126,127, 138, 142,143,144, 160,161,162] use the following metrics to evaluate their performance.

Mnew=FnNc×100
(11)
Fnew=FpN−Nc×100
(12)
Error=Fn+Fp+FeN×100.
(13)
Here, Fp indicates the total number of the existing class examples that were wrongly identified as a new class (false positive). Fn represents the total number of examples of emerging classes that are wrongly classified in the existing classes (false negative). Fe is the total number of the existing class examples that have been incorrectly classified, except for Fp. Nc is the total number of examples of emerging classes, and N is the total number of examples in the stream. The measures Mnew represent the percentage of examples of emerging classes that are misclassified as the existing classes. Fnew is the percentage of the existing class examples that are misclassified as an emerging class, and Error is the total misclassification percentage.

Similarly, some other methods [10, 10, 29, 30, 33, 44, 58, 70, 75, 77, 90, 106,107,108, 116, 117, 126, 131, 146, 167] also use AUC (area under the curves), ROC curves, Precision, Recall, Accuracy and F-measure [139] to evaluate their performance. Accuracy and F-measure is given by the following equations.

Accuracy=An+AoN×100
(14)
where An is total number of emerging class examples identified correctly, Ao is total number of known class examples classified correctly and N is the total examples.

F-measure=2×P×RP+R×100.
(15)
Here, P is precision and R is recall.

The evaluation strategy adopted by [44, 60, 63, 70] is based on the incremental confusion matrix as described in [62], which grows incrementally whenever a new example is classified. The confusion matrix is composed of rows and columns representing unknown examples, existing classes and novel patterns. In this method, novel patterns may be considered as an extension of known class or have no association with the known class, i.e., representing a completely new class. It is important to indicate that a new class can be represented by several novelty patterns, or a complete novelty pattern represents a class. In addition, a separate measure is used to evaluate unknown examples, which are given by the following equation.

UnkR=1#C(∑i=1#C#Unki#Exci).
(16)
Here, #Exci is the total number of class Ci examples, #Unki indicates total the number of class Ci examples identified as unknown, and #C is the total number of classes.

Empirical study
In this section, we present the empirical study conducted on six algorithms, namely EMC [49], MINAS [63] ECSMiser [104], CLAM [9], ECHO [77], SAND [76] and SENCForest [116]. EMC and MINAS are cluster-based single classifiers. ECSMiser, ECHO and SAND are cluster-based ensemble classifiers, while CLAM is a class-based ensemble and SENCForest is a decision tree-based ensemble classifier. For all algorithms, the default parameters setting given in the corresponding papers are followed. We have selected two synthetic and five real-world datasets to evaluate the performance of these algorithms. Datasets include SynC, SynRBF, KddCup, ForestCoverType (FCT), IoTbotnet attack (IoT), HAR and Shuttle. The detail of each dataset is given in Table 4. SynC contains two classes with concept drift but no novel class. All the other datasets are arranged to have new classes appear over time as described in [49]. For the KddCup dataset, ten largest classes are selected. For the initial training phase, three classes are used, and the remaining seven classes appear randomly with an extended period of three classes until all classes are finished. For the FCT dataset, we normalize the dataset and arrange it in the manner that at least two and three classes appear in any block and new class appears randomly in some blocks as described in [104, 160]. Similarly, for IoT, Shuttle, HAR and RBF, initial training data contains 4, 2, 3 and 2 classes, respectively, and the remaining classes appear during the stream with known classes data. Shuttle and HAR have 58,000, 10,299 instances, respectively, while for all the other datasets, we have used 100K instances.

Table 3 False positive (Fnew) and false negative (Mnew) rates (%) of all algorithms on different datasets
Full size table
Fig. 14
figure 14
Accuracy achieved by all algorithms on different datasets

Full size image
Fig. 15
figure 15
Accumulative average accuracy over the streams of different datasets

Full size image
For performance evaluation, we the measures Accuracy, Mnew, and Fnew defined in Eqs. (14), (11), and (12), respectively. Table 3 and Fig. 14 report the results achieved by all algorithms. For Table 3, we can see that for simple datasets such as Shuttle and SynRBG, all the algorithms achieve good classification performance. In contrast, for more complex datasets, the obtained results by all algorithms are not satisfactory. Especially , for a high-dimensional dataset like HAR, novel class identification by all algorithms is very poor. For the results, we can see that the performance of unsupervised algorithms like MINAS and SENCForest are significantly degraded on the SynC dataset. This dataset simulates the evolving concepts by changing the position and orientation of a hyperplane smoothly or suddenly in two-dimensional space. Thus simulate a gradual and abrupt concept drift. Because these methods update their predictive model using unlabeled data (without external feedback), they are unable to cope with the concept drift problem.

Applications, datasets and open-source software
Applications
Modern real-world applications and devices (such as sensors) generate an enormous amount of data every day. Various data mining algorithms have been developed to extract useful information from this data continuously. Because streaming data is dynamic, it is necessary that the learning algorithm is adoptive (retort to changes) in order to handle evolving concepts and to be able to learn new concepts. Among many applications in the real world, some of the significant applications in the literature include video surveillance, text extraction, intrusion detection, fraud detection, power distribution networks, activity recognition, fault diagnosis in machines. Algorithms proposed for classification and novel class detection in the literature have used several real applications data to compare the performance of their algorithms.

Intrusion detection
Most of the algorithms presented in the literature used network intrusion detection datasets (such as KDDcup99 and packages) for comparison purposes. The task of intrusion detection is to recognize unauthorized network traffic from normal traffic data. In this application, a learning model is first formed based on a set of initial learning data with normal and attacked data. In online learning, the model then classifies known attacks and identifies new types of emerging attacks. This dataset is used in algorithms such as [8, 9, 16, 16, 49, 58, 63,64,65, 84, 104,105,106,107, 109,110,111, 116, 117, 125,126,127, 138, 143, 144, 160,161,162, 167, 167].

Text mining
It is another application, and different algorithms used a set of real-world text dataset (like twitter stream) for comparison purposes. Stream classifiers such as [106,107,108, 125] are first created with predefined topics, after which these classifiers can discover emerging topics during the text streaming and incorporate them in the classifier.

Forest cover type detection
The forest cover dataset is a well-known dataset. This dataset is often used to assess algorithm performance. This dataset contains a set of geospatial features that describe a type of forest. Algorithms such as [8, 9, 30, 49, 63, 71, 75,76,77, 84, 104,105,106,107,108,109,110,111, 116, 117, 120, 125,126,127, 138, 146, 160,161,162, 167, 167] are initially trained with a set of known forest cover types and later these classifiers can be used to detect new forest cover types.

Human activity recognition
Similarly, human activity recognition is another important application. Activity recognition refers to the analysis of human behavior (normal or abnormal) in real-time. In this application, the main task of the learning algorithms is recognizing and learning evolving activities (concepts) in the stream. For example, identify new normal activities like “Driving” that are not available during the training phase of the classifier or discover abnormal activities like “Sudden fall.” Algorithms such as [1, 49, 75,76,77, 81, 120, 127] have used real-world datasets to recognize and identify new activities.

Datasets and open-source software
Table 4 Description and characteristics of datasets used in different algorithms
Full size table
Several real-world and synthetic datasets are selected by various algorithms to evaluate their performance. A brief description and characteristics of all datasets that are used in different algorithms are presented in Table 4. These datasets are available on the following websites/repositories and can be downloaded.

UCI Machine Learning Repository:Footnote1 is a large collection of datasets that can be used for different types of machine learning tasks, like pattern recognition, classification, clustering, in a wide range of application domains. Datasets like KDDcup99, Forest cover type, Shuttle, PAMAP2 and HAR are available at this repository.

Similarly, some other concept drift datasets are available at the following websites. SEA and Weather datasets,Footnote2 Forest cover type and Electricity datasets,Footnote3 Spam,Footnote4 Power Supply.Footnote5

In addition to these dataset collection repositories, some authors have developed codes to generate synthetic datasets that can be used to evaluate the performance of the proposed algorithms.

Kuncheva et al. [121] have developed a framework based on Matlab (Concept Drift Generator)Footnote6 to generate drifting synthetic data streams.

Similarly, the frameworkFootnote7 of Minku et al. [113] can also generate synthetic data streams.

Other useful data and software can be downloaded from the following links.Footnote8,Footnote9,Footnote10,Footnote11

Some open-source codes and software frameworks are also available to the research community for the development of new algorithms. Moreover, many authors have provided the software implementations and data of their algorithm used in the publication. Different algorithm’s code and data publicly available are given in the following links.

Massive Online Analysis (MOA)Footnote12 [25]: is a Java-based open-source framework, that provides the implementation of many state-of-the-art algorithms for data stream mining. It includes clustering, classification, active learning and concept drifting stream generating models.

Scalable Advanced Massive Online AnalysisFootnote13 [47]: is a Java-based distributed algorithm collection for mining big data streams.

In addition to these open-source frameworks, some authors made their code available to the public.

SAND [76] https://github.com/ahaque-utd/SAND

ECHO [77] https://github.com/ahaque-utd/ECHO

MINAS [60, 63] http://www.facom.ufu.br/~elaine/MINAS

SENCForest [116] http://www.lamda.nju.edu.cn/files/SENCForest.zip

EMC [49] https://github.com/SalahuddinSwati/EMC

MuENL [171, 173] http://www.lamda.nju.edu.cn/code_MuENL.ashx

CPE [152] https://github.com/Vitvicky/

Summary and future research directions
In this study, we provide a review of data stream classification algorithms with emerging class detection. We offer a deep insight into the various state-of-the-art algorithms for novel class detection in the literature and analyzes the strength and weaknesses of each algorithm. Although several practical algorithms have been proposed, there are still several challenges preset in the existing algorithms that limit their applicability in many applications. Many problems remain open research questions that need to be resolved. Here, we provide a brief overview of possible research directions that seem useful and require further investigation.

Novel class detection with multiple types of features
Currently, most techniques developed to identify novel classes use only numeric attributes. Therefore, there is a need for algorithms that can work with other types of attributes, such as categorical, ordinal, or other data structures.

Novel class detection in high-dimensional data
High-dimensional data is a crucial issue that needs to address. Most of the existing algorithms are cluster-based methods and use distance-based measures to identify novel patterns, which is not a proven method for high-dimensional data streams.

Novel class detection and label scarcity
The availability of labeled data is also the biggest and most important issue that needs to be adequately considered. Most algorithms in the literature make an unrealistic assumption about the availability of labeled data. They assume that the ground truth for all data is available after some delay, which can be used to update learning models regularly. However, this assumption is far from the truth. It is impossible and unrealistic to provide labels for continuously arriving data streams. It is, therefore, necessary to have algorithms that can create and update their learning models with limited labeled data to reduce labeling costs and still provides an acceptable classification and a new class identification performance.

Novel class detection in feature evolving data stream
Only a few algorithms considered the problem of feature evolution. Most of the algorithms work with a fixed set of features. But in dynamic data streams, features may also evolve over time, where new features may be augmented while some old features vanished. Therefore, how to detect emerging patterns in feature evolving stream is an interesting research problem.

Multi-label learning with emerging new labels
In traditional learning tasks, one instance is associated with only one class (label), while in multi-label learning environments, an instance may be associated with multiple concepts (labels). It is also an exciting area, and only a few algorithms are developed for multi-label data streams learning with emerging new labels.

New evaluation measures for emerging class identification
To evaluate the performance of the algorithms, different algorithms have adopted different static data evaluation methods. However, these evaluation measures are not sufficient for streaming data due to the large volume of data, sequential arrival of data and dynamic data distribution. Therefore, the development of new measures to evaluate algorithm performance remains an open issue.

Recurring context with novel class identification
Various works presented in the literature implement forgetting mechanisms to eliminate outdated concepts. In these algorithms, every time a new pattern appears, it is considered a new concept. However, only a few techniques provide a mechanism to retain old concepts. When these concepts reappear, they are considered old concepts instead of declaring them as new concepts. It also a potential research area that can be further explored.

Parameter-free or less parameters algorithms
The majority of algorithms rely on various user-defined parameters, such as the number of clusters, the number of classifiers, the size of the block or window, threshold for emerging pattern identification and so on. The performance of these algorithms depends largely on these parameters and must be turned according to the dataset. Therefore, it is necessary to develop parameters free algorithms or algorithms that use less parameter for better prediction performance across diverse datasets.

Outlier handling with emerging patterns identification
Because data streams are dynamic, and existing concepts can change gradually or abruptly. In these scenarios, the handling of noise or outliers is a significant problem, and new robust algorithms are needed to identify emerging patterns from noisy data.