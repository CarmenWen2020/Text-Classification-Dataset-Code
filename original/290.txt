This study attempts to solve the placement and chaining problem of 5G User Plane Functions (UPFs) in a Multi-access Edge Computing (MEC) ecosystem. The problem is formalized as a multi-objective Integer Linear Programming (ILP) model targeted at optimizing provisioning costs and quality of service. Our model takes into account several aspects of the system such as UPF-specific considerations, the Service Function Chain (SFC) requests topology (single and multiple branches), Virtual Network Function (VNF) order constraints, service demands, and physical network capacities. Since the formulated problem is NP-hard, two heuristic solutions are devised to enhance solution efficiency. Specifically, an algorithm called Priority and Cautious-UPF Placement and Chaining (PC-UPC) and a simulated annealing (SA) meta-heuristic are proposed. Through extensive simulation experiments, we evaluated the performance of the proposed solutions. The results revealed that our solutions outperformed the baselines (i.e., two greedy-based heuristics and a variant of the classical SA) and that we had obtained nearly optimal solutions with significant reductions in running time. Moreover, the PC-UPC algorithm can effectively avoid SFC rejections and improve provisioning costs by considering session requirements, current network conditions, and the effects of VNF mapping decisions. Additionally, the proposed SA approach incorporates several mechanisms (e.g., variable Markov chain length and restart–stop) that allow the improvement of not only the quality of the solutions but also their computation time.

Keywords
5G
User 
Plane Function
Service Function Chaining
ILP
Simulated annealing


1. Introduction
5G and beyond networks are expected to support diverse use cases and services with different requirements and characteristics. Among those requirements, user-experienced data rate (0.1–1 Gbps), connection density (millions of devices per 
), and end-to-end (E2E) latency (less than 1 ms) are the three most fundamental ones (Liu and Jiang, 2016). To achieve such goals in a cost-effective manner, radical transformations and optimization in several aspects of the system are required. In a nutshell, the envisioned system must be flexible, scalable, adaptable, secure, programmable, and above all feasible to deploy. In this vein, technologies such as Network Function Virtualization (NFV), Software-Defined Networking (SDN), and Multi-access Edge Computing (MEC), to name just a few, have been defined as key enablers (5G Americas, 2017, Blanco et al., 2017).

SDN and NFV (Yousaf et al., 2017) allow for flexible and cost-effective networks. Specifically, SDN provides network programmability by decoupling the control and user planes, whereas NFV (Mijumbi et al., 2016) enables the implementation of network functions as software instances (i.e., Virtual Network Functions, VNFs) that can be instantiated on-demand on commodity hardware at the most suitable locations. Additionally, MEC (Hu et al., 2015, Kiran et al., 2020) brings computing, storage, and networking resources closer to users, reducing network response time and backhaul traffic and enhancing security. Therefore, the combination of these technologies allows the optimization of network resources through the virtualization, disaggregation, and placement of network functions at the network edge.

Specifically, by placing User Plane Functions (UPFs) (3GPP, 2020a, Jun et al., 2020) and applications at the network edge, service latency and bandwidth requirements can be met since the length of the routing path is significantly reduced. UPFs represent the evolution of traditional Serving Gateway (SGW) and Packet Gateway (PGW) toward 5G networks under the concept of control and user plane separation (CUPS). However, unlike traditional networks where a Packet Data Unit (PDU) session is served by a unique PGW and SGW, in 5G networks, a PDU session can be assigned to multiple UPFs simultaneously. The reason for this is that 5G standards allow UPFs to be divided into different functional roles (microservices) that can be chained together and steered as required.

However, the placement and chaining of UPFs in a MEC ecosystem is challenging due to numerous aspects and involved trade-offs. While deployment applications and network functions (e.g., UPFs) to the network edge often leads to reduced latency as well as improved reliability, throughput, and fault tolerance, it still comes at the expense of increased costs since this approach implies a higher number of deployed instances. Besides, in edge-based systems where the number of embedded computational nodes is in the order of thousands, the cost is generally much higher than in traditional cloud services (Chalapathi et al., 2021). By contrast, expenditures could be reduced by minimizing the number of deployed UPFs or consolidating multiple instances on the same edge node, but this is at the risk of deteriorating the quality of the services (QoS) or failing to meet their requirements. Thus, a fair trade-off between meeting 5G services stringent demands and their associated costs needs to be found. Moreover, the placement of network functions at the network edge is challenging not only because of its limited resources but also due to the high number of possible locations that add to the problem complexity. Another major challenge that arises is the existence of different types of UPFs with diverse and specific requirements that need to be chained in a specific order and by accounting for their inter-dependency. Thus, we tackle the problem of determining the optimal placement and chaining of UPFs, at the network edge, so that 5G service requirements are satisfied while minimizing expenditures. In this regard, the main contributions of this paper can be summarized as follows:

•
The UPF Placement and Chaining (UPC) problem is formalized as an Integer Linear Programming (ILP) model aimed at optimizing network operator expenditures and the QoS. Moreover, the proposed model considers several aspects such as resource capacity, service latency, UPF-specific requirements, and the order of VNFs in the Service Function Chains (SFCs).

•
Since the UPC problem is NP-hard, two solutions are provided to solve it in polynomial time. Specifically, a heuristic and a meta-heuristic called Priority and Cautious UPC (PC-UPC) and Simulated Annealing-based (SA) UPC (SA-UPC), respectively, are developed.

•
The proposed heuristic avoids the rejections of SFC requests (SFCRs) by prioritizing the mapping of the most demanding services and considering the effects of mapping decisions on the current and next stages.

•
The proposed SA incorporates several strategies (e.g., restart–stop and variable Markov chain length; VMCL) that significantly improve its efficiency and effectiveness compared with classical SA (CSA) approaches.

•
The performance of the proposed solutions is evaluated through extensive simulations. The obtained results validate that the proposed heuristics can achieve an average cost close to the optimal cost in a considerably shorter time when the number of PDU session requests is small.

The remainder of the paper is organized as follows. Section 2 presents an overview of related work. Section 3 provides the mathematical formulation of the problem, and Section 4 describes the proposed heuristic and meta-heuristic solutions. Next, Section 5 discusses the simulation results, and finally, Section 6 concludes this work and outlines future studies.

2. Related work
This section provides a literature review of preliminary research work related to the UPF and SFC placement (SFCP) problems with single and multiple branches. It underlines their strengths and limitations as well as solution approaches. Moreover, the review pays special attention to studies that apply SA in their solutions. We adopted SA as a solution approach due to its efficiency and flexibility for solving combinatorial optimization problems (e.g., the facility location problem) compared with other algorithms such as branch-and-bound and greedy (Fischer et al., 2019).

2.1. 5G UPFs placement and chaining
Peters and Khan, 2018, Peters and Khan, 2019 propose the concept of anticipatory user plane management for reducing the effects of handover procedures. In this regard, predictions of individual user behavior are used to decide whether to insert intermediate UPFs (I-UPFs) in the session data path. Additionally, in Peters and Khan (2019), a simplified model overview is introduced to optimize the I-UPF placement. Leyva-Pupo et al., 2019a, Leyva-Pupo et al., 2019b address the placement problem of anchor UPFs (A-UPFs). Their main objective is to optimize deployment and operational expenditures while satisfying 5G service requirements. To this end, two ILP models are presented in Leyva-Pupo et al. (2019a) whereas in Leyva-Pupo et al. (2019b) a mathematical model along with an algorithm is provided.

In Ge et al. (2019), introduce a framework for determining the optimal set of UPFs that traffic flows should traverse. To this end, different flow categories and SFC templates are defined for identifying the set of UPFs in a flow path. Nonetheless, no solution is presented for addressing the UPF placement problem. Subramanya et al. (2020) tackle the problem of joint user association and SFCP in a hierarchical MEC ecosystem. Two solutions, an ILP and a heuristic, are proposed for determining the optimal location of the VNFs while minimizing E2E service delay. Moreover, the researchers apply machine learning models to predict the required number of UPFs based on traffic demands. Nevertheless, no placement constraints associated with UPFs are considered since they assume that the SFCs are composed of only one type of UPF.

2.2. Single-branch SFC placement
The authors in Papagianni et al. (2018) and Oljira et al. (2017) tackle the SFC mapping problem in LTE networks through optimization models. In Papagianni et al. (2018), propose a MILP model aimed at reducing deployment- and bandwidth-associated costs through VNF sharing. However, the E2E latency requirement is overlooked. By contrast, Oljira et al. (2017) present a fine-grained delay model that includes the effects of virtualization overhead. This model’s main objective is to minimize the combination of several cost components subject to resource capacity limitations, VNF placement constraints, flow conservation, and latency requirements. Mouaci et al. (2020) attempt to solve the VNF placement and routing problem. To this end, a path-based MILP model is introduced with the main objective of optimizing VNF deployment and node opening costs. The model considers several constraints such as anti-affinity, VNF order, routing, and latency. Nevertheless, the link capacity limitation is ignored.

Optimization models are characterized by scalability limitations. Hence, they are usually used to solve small-scale problems or as a benchmark for assessing the performance of heuristic-based solutions. This combined approach has been widely used by many research works (Alleg et al., 2017, Song et al., 2017, Wang et al., 2019b, Allybokus et al., 2018, Li et al., 2019) in the field of SFCP. Alleg et al. (2017) formalize the SFC placement and chaining problem as an ILP and propose a degree-based heuristic. These solutions are aimed at minimizing E2E delay and resource allocation costs. The model embraces constraints related to node and link capacity, VNF mapping, E2E delay, and flow conservation. Song et al. (2017) study the resource-efficient VNF placement problem to minimize computing and communication resources. An ILP model and a heuristic based on the hidden Markov model are provided. In Wang et al. (2019b), the main objective is to optimize VNF instance and link utilization in a cloud data center environment. In Song et al., 2017, Wang et al., 2019b, several aspects are taken into consideration, such as resource capacity, VNF order dependency, and flow conservation; however, the E2E service latency requirement is overlooked.

Allybokus et al. (2018) formulate the problem as a MILP that encompasses several constraints such as service delay, VNF order, anti-affinity, and resource limitations. Their main aim is to optimize routing and VNF deployment costs. Moreover, a heuristic algorithm that combines the linear relaxation of the problem with a greedy approach is developed. Likewise, Li et al. (2019) propose a greedy-based heuristic. It studies the SFCP problem in a hierarchical MEC ecosystem to minimize the total cost associated with substrate resources subject to capacity and propagation delay restrictions. A common limitation of the aforementioned works is that they have only considered single-branch SFCRs.

2.3. Multiple-branch SFC placement
Luizelli et al., 2015, Luizelli et al., 2017 approach the VNF placement and chaining (VNFPC) as an optimization problem combined with heuristic solutions. Their main objective is to minimize the number of VNFs mapped on the infrastructure subject to limitations of physical resources, VNF mapping, E2E delay, and flow conservation rules. To overcome the scalability limitations of the models, a binary search heuristic is proposed in Luizelli et al. (2015), whereas in Luizelli et al. (2017) an algorithm based on a variable neighborhood search meta-heuristic is introduced. They consider VNF sharing and the existence of different SFC topologies.

The goal in Wang et al. (2019c) is to optimize the VNF deployment and link costs subject to resources, delay, and traffic routing constraints. Moreover, aspects such as traffic splitting into multiple branches as well as multiple ingress/egress nodes are taken into account. Similarly, Leivadeas et al. (2019) adopt a path-splitting approach to address the SFC mapping in a MEC-Cloud infrastructure to minimize E2E communication delays and deployment costs. To solve the problem, a Mixed-Integer Programming (MIP) model and a Tabu Search algorithm are developed. The MIP formulation accounts for aspects related to resource capacity, flow conservation, and VNF mapping. Nevertheless, the definition of constraints for ensuring the correct order of VNFs in the chain is omitted. Jalalitabar et al. (2019) address the branching SFC embedding and routing problem. To this end, they define a set of policies that had to be accounted for, such as VNF dependency, branching, and anti-affinity. Additionally, they propose an algorithm to optimize node and link utilization. Nonetheless, the service latency requirement is omitted from the solution.

In Alhussein et al. (2020), tackle multicast service orchestration for single and multiple services. They deal with the optimization of two conflicting objectives (i.e., VNF deployment and link provisioning costs) subject to node capacity and flow conservation constraints. However, E2E latency requirements are not considered and the problem is solved under the assumption that VNFs cannot be shared among multiple SFCRs. Since the problem is proven to be NP-hard, low complexity heuristics are proposed to find efficient solutions. Ren et al. (2019) propose the use of the service function tree to embed SFC for multicast tasks. An ILP model and a heuristic are provided to optimize deployment and routing costs. They solve the problem subject to node capacity, flow conservation, and multicast flow constraints. However, no restrictions regarding either link capacity or E2E delay are included.

2.4. SA in the VNF and SFC placement
Li and Qian (2015) formulate the VNF placement problem as an ILP and propose an SA algorithm to solve it. Likewise, Cheng et al. (2015) formulate the service chain instantiation as an ILP problem and rely on SA to determine its solution. Liu et al. (2017) address the middlebox placement problem in order to optimize SFC performance (i.e., the E2E delay and bandwidth consumption). To overcome the complexity of the problem a greedy and a SA solution are proposed. Similarly, in Fischer et al. (2019), a heuristic called affinity-based SA is proposed to address the delay-aware SFC embedding problem. The proposed solutions can not only outperform several greedy approaches (i.e., Liu et al., 2017, Fischer et al., 2019) but can also obtain near-optimal results. Nonetheless, they are based on CSA approaches with none or minor modifications e.g., neighborhood solution generator).

Contrary to the aforementioned works, which have considered only one type of UPF in the session data path or overlooked UPF requirements in their solutions, our problem formulation specifically deals with UPFs’ main roles (refer to Section 3.1), characteristics, and specificities. To this end, PDU sessions are modeled as SFCRs, which may have different topologies (single and multiple branches). However, when working with SFC is crucial to consider VNFs order and inter-dependency. For instance, I-UPF should be placed before A-UPFs, in the uplink direction, while A-UPFs terminate connections at the data network (DN) end. Furthermore, 5G services characterize by stringent latency and bandwidth requirements that are more difficult to meet with increasing SFC lengths as processing and propagation delays also increase. Another important requirement is the anti-affinity constraint which not only enhances the robustness of the UPF placement but also allows to reach multiple networks within the same PDU session through the multi-home functionality. The latter is essential for the deployment of MEC scenarios and local area data network (Jun et al., 2020). Thereby, our mathematical model takes a wide range of constraints related to both the UPF and SFC placement problems into account. These restrictions range from latency and capacity limitations to VNF order, anti-affinity, and VNF sharing. Moreover, to overcome the scalability limitation of the model, we propose two heuristic-based solutions: a heuristic-specific and SA variant. The latter introduces several modifications that significantly enhance the performance.

3. Optimal UPF placement and chaining
This section begins by giving a brief background about 5G UPFs and presents the used notation and models for the system and SFCRs. Then, we describe and formulate the UPF placement and chaining problem as an ILP model.

3.1. 5G user plane functions
The 5G user plane is compounded by UPFs, which are in charge of processing PDUs between the access network (AN) and the data network. UPFs may perform different functionalities such as an external PDU session point of interconnection to DN, and an anchor point for intra-/inter-radio access technologies’ mobility. They are also responsible for packet inspection, routing and forwarding, traffic steering and usage reporting, lawful interception, and QoS handling (e.g., data rate enforcement). Not all of these functionalities are required to be supported by a single UPF instance, and they can be selected and tailored as required either during or after the establishment of a session. To perform these functionalities, they rely on the Session Management Functions (SMFs) in the control plane. The SMFs are also responsible for selecting and managing the UPFs associated with a PDU session.

Regarding UPFs’ functionalities, four main roles can be defined: PDU Session Anchor (PSA), I-UPF, Uplink Classifier (UL-CL), and Branching Point (BP). PSAs, also called A-UPFs, terminate the PDU session at the DN end and are responsible for IP anchoring. The I-UPFs forward traffic between the AN and the PSA. This type of UPF can be used to guarantee the continuity of the service either when the user moves in a wide range network or due to transport network limitations.

Similarly, UL-CLs and BPs may be inserted in the data path between the AN and PSAs. However, unlike the former, these functionalities allow a single PDU session to be served by multiple PSAs connected to the same DN to support session and service continuity (SSC) mode 3 and selective traffic routing. The latter is especially useful for edge computing scenarios where services are hosted closer to the users. These functionalities are not mutually exclusive. Specifically, UPFs acting as UL-CLs or BPs may also support the PSAs’ functionality. Moreover, a single UPF entity can have different roles for one or various PDU sessions (Rommer et al., 2019). Additionally, according to their location in the data path, two types can be defined: terminated UPFs (T-UPFs) and intermediate UPFs. The first category is compounded by PSAs, whereas the second one embraces all those UPFs that connect with the AN and other UPFs or just with other UPFs. Notably, UPFs that support BP and UL-CL functionalities are classified as I-UPFs with multi-homing functionality (MI-UPF), but not all I-UPFs are UL-CL or BPs.

To comply with 3GPP specifications for 5G    networks (3GPP, 2020a, 3GPP, 2020b), the following aspects must be considered when orchestrating PDU sessions: (1) At least one UPF is required to act as a PSA; (2) all UPFs acting as PSAs must terminate the data path with the DN; (3) more than one I-UPF (e.g., UL-CL and BP) may be inserted in the path but only one connects with the AN via the N3 interface, except for session continuity during UL-CL/BP relocation (3GPP, 2020a); (4) if a UL-CL or BP functionality is inserted in the data path of a PDU session, then multiple PSAs are assigned to this session; and (5) the use of UL-CL and BP is independent of the SSC mode and is mostly linked to QoS metrics or network policy rules.

According to the previous considerations, we assumed that PDU sessions can have different characteristics (e.g., number and type of UPFs as well as topology), which may vary according to several aspects such as requested service type and network conditions. In this paper, we consider three basic topologies for PDU session flows by considering the aforementioned main UPF roles and requirements. These topologies may be combined or extended to include other UPF roles and create more complex structures. Fig. 1 depicts these topologies in the uplink direction.

3.2. System model and notation
The 5G network is modeled as a directed graph G(N, E, U), where N, E, and U represent the set of network nodes, edges, and users with active PDU sessions, respectively. The set of network nodes is formed by VNF candidate locations (
), aggregation points (
) and access nodes (
). Moreover, we include the set of paths in the network () as well as the set of paths between a specific pair of nodes (
), where 
. Each path  is identified by its endpoints (n,m) and an ID (h) to distinguish different paths between the same pair of nodes. The parameter 
 indicates whether a physical link (u,v) belongs to a path p or not. The candidate nodes are characterized by a processing capacity (
) while the physical links are characterized by the bandwidth capacity (
) and latency (
). The latter includes propagation and processing delay of the transmission nodes (e.g., APs).

Different types of VNFs can be deployed. The set of all the available VNF types is represented by  where  denotes a specific type (e.g., t=1: A-UPF, t=2: MI-UPF, and t=3: I-UPF). Each VNF type is associated with a processing capacity (
), a processing delay (
), and a maximum number of instances that can be deployed (
). A list of notations related to physical and virtual networks is provided in Table 1.

The set of active PDU sessions is denoted by S and the PDU sessions are modeled as SFCRs. The properties of an SFCR  are represented by a ten-tuple 
, where 
, 
 and 
 denote the user ID to which the data session is associated, its access node, and set of requested VNF instances, respectively. To simplify the model, we define the access node (source) of an SFCR as VNFs of type  and extend the set of requested VNFs to include it, 
. Furthermore, each PDU session is characterized by a processing capacity demand (
), a required bandwidth (
), and a maximum E2E delay (
). Additionally, parameters 
, 
, 
 and 
 specify the number of branches in an SFCR, the type of each VNF, as well as their order and presence in each branch, respectively. Please note that, unlike other related studies, our model does not include the destination nodes of an SFCR, since we assume that they are DNs co-located with the A-UPFs, and therefore, their location before the UPF placement is unknown. Table 2 summarizes the SFCR’s notation.


Table 1. Physical and virtual networks notation.

Notation	Description
Sets
Set of all nodes
Set of access nodes
Set of candidate locations (e.g., MEC servers)
Set of aggregation points
Set of physical links
Set of paths between all network nodes
Set of paths between nodes n and m, ()
Set of all types of available VNFs
Parameters and indicators
Resource capacity at candidate location 
Resource capacity of VNF of type 
Bandwidth capacity of link (u,v)
Latency associated to link (u,v)
Latency associated to path 
Processing delay of VNF of type 
Maximum number of instances of type 
1 if path  is mapped to physical link (u,v)
1 if node  supports VNFs of type t

Table 2. Sets, parameters and indicators related to SFCRs.

Notation	Description
Set of active users
Set of PDU sessions (SFCRs)
User ID of PDU session 
Access node (
) of SFCR s
Set of VNFs forming SFCR s
Number of VNFs of type t in SFCR s
Computing resources required by SFCR 
Bandwidth capacity required by SFCR s
E2E latency requirement of SFCR s
Number of A-UPFs (branches) in SFCR s
1 if VNF 
 in SFCR  is of type 
1 if VNF f goes just before VNF g in branch 
 of SFCR 
1 if VNF f is present in branch 
 of SFCR 
3.3. Problem formulation
5G services are characterized by stringent requirements such as high data rates and capacity, huge connection density, and very low latency, which in some cases is less than 1 ms. To cope with such demands, not only is an increase in the number and capabilities of UPFs required but also their placement must be closer to the users at the network edge. Thus, the network response time can be enhanced since the E2E service delay and link load are reduced. Moreover, unlike traditional LTE networks, where a service session is assigned to a unique PDW and SGW, in 5G networks, a single PDU session can be served by several UPFs simultaneously. This situation implies a significant increase in the number of deployed UPFs which translates into higher expenditures for network operators. Furthermore, some of the UPFs’ main functions are traffic steering and packet routing and forwarding. Thus, the optimization of the flow data path is of the utmost importance for reducing service latency as well as the transmission cost.

The UPC problem can be defined as follows: Given a physical network infrastructure and a set of PDU session requests, it is necessary to determine the optimal number and location of the UPFs as well as their routing paths so that the overall cost and QoS are optimized. Moreover, session requirements such as VNF order and latency must be ensured while considering physical network limitations, such as available resources and topology. A description of the decision variables used for the problem formulation is provided in Table 3.

Additionally, to simplify the problem, a set of assumptions were made: (1) the use of either UL-CL or BP functionality is linked to the PDU session type (e.g., IPv4 or IPv6) which is out of this paper’s scope; hence, both types of UPFs were treated interchangeably as MI-UPF; (2) the 3GPP in its technical specifications does not restrict the maximum number of UPFs for a given PDU session; nevertheless, the number of I-UPFs serving a PDU session was limited to one to avoid extra signaling between SMFs and UPFs and reduce resource utilization in the user plane; (3) a UPF instance has an equal and identical role for all its assigned PDU sessions; and (4) the links propagation delay is constant and proportional to their length.


Table 3. Decision variables.

Notation	Description
1 if candidate node 
 is open
1 if instance i of VNF type  is deployed on node 
1 if VNF  of SFCR  is mapped to instance i of VNF type t located at node n
1 if VNF  in branch  of SFCR  is mapped to instance i of VNF type t located at node n
1 if path  is used to route traffic between VNFs f and g in branch  of SFCR s
The main objective of the UPC problem is to minimize provisioning costs and service response time. To this end, three cost components were considered: node activation, number of deployed VNF instances (i.e., UPFs), and routing cost. Note that the latter has been expressed in terms of the propagation delay since this allows the optimization of more than one objective at the same time (i.e., routing cost and response time). (1)
(2)
(3)

The constraints associated with the UPC problem were grouped into five categories: capacity, VNF, SFC, UPF, and QoS (i.e., E2E delay) constraints.

Capacity constraints: Expressions (4), (5), (6) represent the resource limitation in the candidate nodes, VNF instances, and physical links, respectively. The processing capacity occupied by the VNF instances deployed on a MEC server cannot exceed its physical resource capabilities; see (4). Similarly, constraints (5), (6) express that VNF instances and links must have sufficient capacity to handle the required capabilities of their assigned PDU sessions. (4)
(5)
(6)

VNF constraints: Inequality (7) expresses the maximum number of VNF instances of a given type that can be deployed. This can be determined according to the number of available licenses or resources. Moreover, constraint (8) ensures that each instance 
 of a VNF type t is deployed on one node at most. Additionally, expression (9) guarantees that the instances of each VNF type are deployed only on those nodes that support such type and are open whereas inequality (10) forces a node to be closed if it has not deployed any VNF instance. (7)
(8)
(9)
(10)

SFC constraints: Constraints (11)–(17) mainly specify, the number and type of VNFs assigned to the SFCRs. Constraint (11) enforces each VNF 
, requested by a PDU session, to be mapped to one VNF instance whereas inequality (12) restricts its assignment to those locations where there are VNF instances of the requested type deployed. Likewise, (13) avoids instantiating empty VNFs by ensuring that the launched instances have assigned service requests. Expression (14) guarantees that each SFCR is assigned to at least its minimum number of required VNF instances of a given type. Additionally, constraint (15) expresses that if a VNF 
 in an SFC is mapped to a VNF instance, then this is because this VNF service has been requested by at least one of its branches. Likewise, inequality (16) ensures that a VNF instance can serve a branch of an SFCR only if it has been mapped on a network. Moreover, inequality (17) ensures that all the branches of the SFCs are served only by their requested VNFs. (11)
(12)
(13)
(14)
(15)
(16)
(17)
(18)
 (19)

Expressions (18), (19) are path-related constraints. Inequality (18) guarantees the order among VNFs forming the branches of an SFCR by enforcing the existence of a path between two consecutive VNFs in the required direction. Additionally, constraint (19) enforces the assignment of the VNFs forming an SFCR to those nodes through which its traffic passes through. Furthermore, it avoids loops in the traffic flow between two consecutive VNFs by preventing them from using more than one data path for their communication. Note that this constraint is non-linear since it implies the product of two binary variables. The latter can be better appreciated if we add a binary variable 
 which takes value 1 if 
 and 0 otherwise. Consequently, expression (19) can be linearized by introducing a new binary variable 
 such that: 

UPF constraints: Inequality (20) defines the anti-affinity constraint for VNFs that serve the same PDU session. Specifically, it expresses that VNFs of the same type serving a PDU session must be instantiated on different nodes. Additionally, expression (21) restricts the deployment of I-UPFs with no multi-homing functionality and A-UPFs to different locations since the former are inserted in a data path to overcome PSA limitations. (20)
(21)

E2E delay constraint: Expression (22) ensures that the E2E data plane delay of a PDU session, in the Round-Trip-Time (RTT), does not exceed its service latency requirement. It was expressed in terms of the processing time of VNFs in the branches and the propagation delay between them. (22)

Since the formalization of the UPC problem resulted in a multi-objective model with conflicting objectives, we adopted a weighted sum method to transform it into a single-objective model. The relative importance of the cost components in the objective function was specified by adding a set of weight factors: ,  and , such that . Note that to avoid the predominance of one term over the others, it is necessary to normalize their magnitudes. Thus, the mathematical model that describes the UPC problem can be summarized as follows: (23)

The UPC problem is a specific variant of the VNFPC problem which has been proven to be an NP-hard problem (Alhussein et al., 2020, Ghaznavi et al., 2016, Luizelli et al., 2017, Li et al., 2019). Thus, the UPC problem is also NP-Hard. In this context, the design of heuristic algorithms is required for obtaining efficient solutions to the problem for large-scale networks.

4. Proposed solutions
To solve the UPC problem in polynomial time, we propose two heuristics. Specifically, we develop an algorithm that provides efficient SFC mapping by applying priority classification of session requests and cautiously mapping their VNFs. We call this approach Priority and Cautious UPC (PC-UPC). Our second solution is an SA-based approach that incorporates several strategies to enhance its performance. The following subsections explain our proposed solutions in detail.

4.1. Priority and cautious UPC
Algorithm 1 provides a general overview of the proposed PC-UPC heuristic. It takes as its input a set of SFCRs and the substrate network topology (e.g., nodes, physical links, and paths) along with their requirements and capabilities, respectively. The algorithm begins by determining the candidates that could host the VNFs associated with each SFCR as well as the SFCRs that could be attended by each server in terms of latency requirements (line: 2). The former provides information for determining whether an SFCR is in a critical stage, whereas the latter helps to decide in which server it is more convenient to instantiate a virtual UPF. Specifically, an SFCR is classified as critical if it has a number of edge nodes (ENs) equal to or lower than the minimum required to map its VNFs (line: 3). Afterward, the SFCRs are sorted according to the established criteria (line: 4). In this case, they are ordered in terms of criticism level, service latency requirements (ascending), number of VNFs forming the service chain (descending), number of available candidates, and closeness between their access nodes. In this way, the more demanding PDU sessions have more possibilities of being mapped. Once the SFCR order has been established, the mapping process starts by selecting the most demanding SFCR and calling the SFCR-mapping procedure (lines: 6–7).

Procedure 1 is in charge of determining the best location and routing paths for the VNFs forming the selected SFCR. To provide more effective VNF mapping as well as to avoid SFCR rejection, a VNF mapping decision is made by taking into account its effects not only in the current stage but also in the next stage. Specifically, the procedure analyzes how the placement decision of a given VNF affects other VNFs that directly depend on it (the next VNFs in the branches). In this way, dead-ends in the SFC mapping and reassignment procedures can be avoided. To keep the SFCR-mapping procedure simple as well as to reduce its execution time, we only consider the impact of the VNF mapping decision in the current and next stages. Nonetheless, it could be extended to include more stages.

The first step of the SFCR-mapping procedure is initializing the output variables by setting the mapping indicator as successful and creating an empty set to store the SFCR mapping information (i.e., VNFs’ location and path; line: 1). Next, it proceeds to map the VNFs by iterating through each VNF in the set of VNFs (
) (line: 2). This set contains the VNFs sorted by their order of appearance in the SFCR branches. Before proceeding to analyze the mapping options for a given VNF, whether this VNF has not been mapped yet is first verified (line: 3). This step is required, since a VNF may have been previously mapped as a result of the look-ahead process. In the case of an unmapped VNF, the best mapping cost is set to a large value (i.e., infinite), and the VNF source nodes, the next VNFs in the chain (if any), and possible candidates are determined. This step is made for each branch in the chain since a VNF can have different source nodes, destination VNFs as well as candidates for each one (lines: 5–8).

The candidates are determined by taking into account the source node and the available propagation delay budget in each branch. Next, candidates that are common to all the branches are selected and their feasibility and mapping cost are determined (lines: 9–10). A candidate is classified as unfeasible if any of the placement constraints formulated in Section 3 are violated. In the case of a feasible candidate, the mapping cost of f is calculated according to (23). Additionally, the fraction of unassigned sessions remaining is also considered when the selection of a candidate involves the creation of a new instance. In this way, UPFs can be created in those candidates that can attend a greater number of SFCRs. As a result of this step, the shortest virtual path with enough available bandwidth to support the requested traffic flow is also obtained. Then, the feasible candidates are selected and sorted in ascending order according to the estimated VNF mapping cost (lines: 11–12).

For each feasible candidate (lines: 13–37), the mapping of f will be simulated if its estimated cost is lower than the current best cost (
). This condition helps to reduce the solution running time by instantaneously discarding worse candidates. Moreover, if the selected VNF is not the last one in the chain, the look-ahead process takes place (lines: 17–34). Otherwise, the first candidate in the set of feasible candidates is selected as the best one for the mapping of the VNF f, the placement and SFCR mapping are updated, and the SFCR-mapping process is ended (lines: 35–37).

The look-ahead process starts by sorting the next VNFs that directly depend on the currently selected VNF (f). These VNFs are sorted by their propagation latency budget and criticism level although other criteria may be used. For each next VNF (nf), its candidates are determined and evaluated according to their feasibility and mapping cost. If feasible candidates exist for the mapping of nf, the one with the lowest cost is selected and the mapping of nf is simulated in the candidate by reserving the required resources (lines: 23–26). Additionally, the deployment cost is updated by considering the expected cost of the next VNF. In case of no feasible candidate for the next VNFs, the current candidate 
  is discarded by setting its cost to infinite (lines: 28–29). The latter avoids selecting candidates that at future steps may lead to unmapped VNFs. Once the look-ahead process for a given candidate has finished, its mapping cost is compared with the current best one to determine if we are in the presence of a better candidate. If this is the case, the best cost and candidate are updated. Moreover, when f is the penultimate VNF in a chain, the best simulated mapping configuration is also saved to avoid the mapping process of the next VNFs.

Once all the candidates have been analyzed, the one with the lowest mapping cost is selected and the placement configuration is updated with the best SFCR mapping configuration. When no feasible candidate is found, the mapping process is interrupted and marked as failed. Otherwise, the mapping process continues until no VNF is left unmapped.

According to the output of the SFCR-mapping procedure, an SFCR is either classified as mapped or rejected in Algorithm 1. When an SFCR is successfully mapped, the network and infrastructure resources must be updated. Moreover, whether any changes have occurred in the candidates set is verified (lines: 11–12). In that case, the subset of available candidates for each SFCR is updated, and therefore, the SFCRs must be reordered. Finally, the set of SFCRs is also updated by removing the currently selected SFC regardless of its mapping result (line: 16).

4.2. Simulated annealing-based UPC
SA is a local search meta-heuristic that allows escaping from local optima through hill-climbing moves (Gendreau et al., 2010). Basically, it accepts worse moves in the hope of finding a global optimum, and the probability of accepting such moves decreases with the temperature. SA-based solutions are characterized by having a wide variety of parameters such as initial and final temperature, temperature length, cooling schedule, and acceptance criterion, which need to be specified and tuned according to the problem. In the following subsections, we provide a detailed description of the main components of the proposed solution with an emphasis on aspects such as neighborhood function, the Markov chain length (MCL) parameter, restart strategy, and termination condition. Moreover, the procedure of the proposed SA is described through a flowchart.

4.2.1. SA components
Initial solution, acceptance criterion, and cooling schedule: Our proposed SA approach can accept any initial solution (e.g., random or heuristic-specific) as long as it is feasible. In other words, it must satisfy the UPF placement constraints specified in Section 3. For the acceptance criterion and cooling schedule, the Metropolis condition and geometric scheduling were adopted (Kirkpatrick et al., 1983). Although other approaches can be used, we prefer these due to their popularity and simplicity. Due to the wide variety of studies addressing the performance of both parameters, we focused on the improvement of other aspects of the solution (i.e., the neighborhood solution, MCL, and restart solution).

Neighbor solution (NS): Most studies related to SA use only one approach to generate NSs, which mainly introduce small changes to the current solution. However, we believe that by combining different strategies, the efficiency of SA can be significantly improved. Thus, unlike the former, we propose two approaches (i.e., NS_ST and NS_3T) that combine intensification with diversification. In this manner, we can not only better explore the solution space, but also prevent the algorithm from being trapped in local optima.

The proposed methods encompass three different strategies for making changes to the current solution. The first one aims to exploit the current solution by introducing small changes. Specifically, it randomly selects an SFCR from the PDU sessions set and maps it into the network. Mapping of the selected SFCR can either be random or follow the criteria of cost optimization in Section 3. In this case, the generated solution will differ from the current solution in the mapping of one SFC. However, this may involve changes to other system parameters, such as the number of open servers and VNF instances. Following this criterion, a subset of neighboring solutions of a pre-established size can be generated.

The second and third variants re-map all the SFCRs associated with a randomly selected VNF instance and candidate server, respectively. The mapping of selected SFCRs is done following the criteria of cost reduction (best cost) only. The main reason for this is to avoid overlay deteriorating the quality of the current solution given the presence of a greater number of selected sessions. The objective of these two approaches is to introduce higher modifications in the current solution to better explore the solution space and help to escape from local optima. In all the strategies, SFCR mapping is performed by verifying placement constraints and considering only their near candidates (i.e., those that satisfy service latency requirements). In this way, only feasible solutions are generated. By taking these types of changes into account, the following two methods are proposed:

•
NS_3T: The set of neighboring solutions is generated by always considering the three previous approaches. Specifically, a neighbor solution (or a set of solutions for changes of type 1) is generated for each type of change.

•
NS_ST: Unlike the previous method, this method selects the types of changes to be used according to the quality of the generated solutions and temperature values. Initially, it starts by considering the three types of changes until a more effective solution is found. Once such a solution is detected, only neighboring solutions of the first type are generated. The decision to switch back to a diversification strategy is made after finishing all the iterations at a certain temperature with probability 
. The probability of using diversification is a function of the fraction of remaining temperatures (
) and the best solution ratio updates at each temperature (Q). Specifically, if 
 is greater than Q and lower than 
, then the diversification strategy is applied. Notably, there is a higher probability of diversification at the beginning of the algorithms since both 
 and Q decrease with the temperature.

Once all the neighbor solutions have been generated according to the specified method, their associated cost is determined, and the one with the best (lowest) cost is selected as the neighbor solution.

Markov Chain Length: The MCL, also called temperature length (
), defines the number of iterations for a given temperature value. To ensure a thorough exploration of a given solution, a large MCL is recommended. However, this implies longer execution times. To avoid long Markov chains, cooling schedule strategies with small decrements in the temperature may be adopted (Atiqullah and Rao, 2001). The use of a fixed temperature length during the whole simulation time is a common approach. Nevertheless, for large-scale optimization problems, this may not be the most suitable strategy (Wang et al., 2019a). In this regard, studies such as (Martinez-Rios and Frausto-Solis, 2012, Martinez-Rios and Frausto-Solis, 2008, Tian et al., 2019, Wang et al., 2019a) have proposed different strategies for variable MCL. In Martinez-Rios and Frausto-Solis, 2012, Martinez-Rios and Frausto-Solis, 2008, the length of the MC is varied inversely to the temperature update. In Tian et al. (2019), the higher the temperature, the longer the length of the MC, whereas in Wang et al. (2019a), a higher MCL in intermediate temperatures is recommended.

As in the aforementioned studies, we adopt a VMCL approach. However, unlike those that vary the length of the Markov chain with the temperature value, our strategy adapts it according to the quality of the generated solutions. Our strategy takes two values for the MCL and switches between them. Specifically, a lower value (
) is selected when no better solution is found at a temperature; otherwise, a maximum value (
) is adopted. Another procedure could be to gradually increase or decrease this parameter using adjusting factors or an ordered list of values. Nonetheless, we prefer the former for its simplicity and also to accelerate the algorithm execution time. In both cases, the MCL is adjusted at the end of a temperature length, if required. This strategy allows for greater exploitation of effective solutions as well as reductions in computation time.

Restart strategy: Restart strategies are a popular diversification technique to escape strong local optima and increase the probability of finding a global optimum. Two aspects associated with this mechanism are the restart conditions and the restart point. Our SA solution restarts if the current best solution has not been improved for a fixed number of consecutive temperatures (restart period, 
). The restart point requires the specification of the current solution and temperature. For the latter, many approaches can be followed such as reestablishing the initial temperature, multiplying the current temperature by a factor greater than 1, or using the temperature value that the system had when the current best solution was found. Nonetheless, our proposed strategy does not allow any of the aforementioned re-heating methods to reduce the probability of accepting worse solutions as well as the computation time.

For the restart solution, studies such as (Addou et al., 2019, Yamada et al., 1994) select the current best solution. However, a drawback to this approach is that it may end up restarting to the same point of the solution space if no update of the best solution is applied during the restart period. Thus, it may restart to the local optimum from which one is trying to escape. By contrast, some papers prefer to generate random solutions (Lin and Vincent, 2015) or combine different strategies (Nakakuki and Sadeh, 1994). Our proposed strategy for selecting the restart solution is more in line with the latter approach since different methods may be used to generate the restart solution. This is done by randomly choosing between a set of possible solutions (e.g., the initial solution, current solution, and best solution) and constructing a new restart point from it. For the latter, we randomly select some open servers and reassign their assigned SFCR following the criteria of the best cost.

Once a new restart point has been generated, we must ensure that it is located in a different region of the solution space to escape from a current local optimum, in the case of being trapped in one. Moreover, we verify that the selected restart point has not been used before to promote diversification during the restarts. For the former, we keep a record of neighboring solutions generated during the restart period and verify whether the new solution is an outlier in this set. To determine if we are in the presence of an outlier, the z-score formula is used. Thus, we can compare how far the restart solution cost is from the mean cost of the neighboring solutions. To verify the diversification condition, we defined a Tabu list in which the costs of the selected restart solutions are stored. The length of this list is conditioned by the stop condition (i.e., number of permissible restarts). A new restart solution will be accepted only if it has not been previously used as a restart point and it significantly differs from the ones recently visited during the restart period. Notably, that the acceptance criterion of the restart point is based on the cost (objective function) of the solutions instead of the placement configuration since this is much simpler to analyze.

Termination condition: This indicates when the SA algorithm should end. Our proposed solution has two stopping conditions. The first criterion is the one used by the CSA; that is, it stops analyzing neighbor solutions when a certain temperature value is reached. The second condition is to terminate when a fixed number of restarts has been performed. Thus, our SA will stop executing when one of the aforementioned conditions is satisfied.

4.3. SA-UPC procedure
Fig. 2 depicts the flowchart of the proposed SA-UPC. Our solution starts by generating (or reading) the initial solution and evaluating its cost according to (23). Subsequently, the current and the best solutions (
 and 
), as well as their costs (
 and 
), are initialized with the initial solution parameters (configuration and cost). Moreover, the initial temperature value () and length of the Markov chain (
) must be set. Given that initially, the probability of improving the current best solution as well as of accepting worst solutions is high, the 
 parameter is started at its minimum value. Additionally, a neighboring solution strategy needs to be specified.

At each iteration in the inner loop, a set of neighbor solutions is generated according to the selected criteria. For each solution, the UPF placement requirements are verified and it is accepted only if those constraints are satisfied. Otherwise, a new one must be generated. Next, their costs are determined and the one with the lowest value is selected. Then, the costs of the neighbor and current solutions are compared (
). If the neighbor solution is better than the current state, the latter is updated, and whether this also outperforms the current best solution is verified. If this is the case, the placement configuration of the best solution and its associated cost are replaced by the ones of the neighbor solution. Moreover, if the NS_ST method has been selected, only neighbor solutions of type 1 will be generated during the next iterations until otherwise specified. Furthermore, it is indicated to set the MCL to its maximum value at the next temperature iteration. In this way, greater exploitation of the solution space can be achieved. By contrast, if the neighbor solution is worse than the current one, it will be accepted as the current solution with probability 
Fig. 2. Flowchart of the proposed SA-UPC.

Once all the iterations in the inner loop have been performed, the restart counter is updated. The latter increases when there is no update of the best solution during the current temperature length; otherwise, it resets. The algorithm restarts if no better solution is found during a restart period. As a result of this process, the current solution is modified, the MCL is increased and the NS_ST method, if selected, adopts a diversification phase. Finally, the stopping condition is verified. If this is satisfied, the algorithm terminates and returns the best solution found thus far. Otherwise, it proceeds to update the current temperature value, the MCL, and the neighborhood strategy if the NS_ST method is used. The MC length is set to its minimum value when there is no best solution improvement.

5. Performance evaluation
5.1. Simulation setup
For the simulations, a network topology representing a 5G medium-scale scenario was generated (see Fig. 3). In this scenario, the gNBs are connected through APs, and MEC servers are co-located along with the APs. The ENs have a service area with a radius of 1 km and the gNB inter-site distances are 500 m and 200 m for gNBs located in urban and dense urban areas (Alliance, 2018), respectively. Bidirectional links are represented as two individual links, one in each direction. Furthermore, it was assumed that the gNBs and the link among gNBs and APs have enough resources to support their associated users and their traffic. Additionally, the bandwidth between MEC servers was set to 10 Gbps (Chen and Liao, 2019).

For the service demand, three types of SFC were considered. Each SFCR corresponds to an active PDU session formed by one to three UPFs. The PDU sessions’ service latency requirement, processing demand, and bandwidth were randomly generated according to the parameters specified in Table 4. The number of active PDU sessions was varied in the interval of [10–400]. The simulation parameters for the UPC model and proposed heuristic are summarized in Table 4.

Fig. 3. 5G access network topology.

The UPC model was implemented using the Python-based package Pyomo (Hart et al., 2017) and Gurobi (Gurobi Optimization, 2021) as its underlying solver, whereas the PC-UPC and SA-UPC algorithms were coded in the Python programming language. For each experiment, we ran the solutions 15 times, which enabled us to present simulation results with confidence intervals of 95%. The simulations were performed on a workstation with a 3.30 GHz Intel Core-i9 processor and 64 GB of RAM.


Table 4. Simulation parameters for the UPC.

Network Topology
Number of gNBs	121
Number of ENs	13
Number of links	174
Number of shortest paths	1742
Scenario dimensions	5  5 km
PDU Sessions
Number of PDU sessions	[10-400]
Bandwidth requirement	[1 Mbps, 10 Mbps, 20 Mbps]
Processing demand	[0.1 CPU, 0.2 CPU]
Latency requirement	[0.9 ms, 1 ms]
Propagation and Processing Delays
RTT delay in the RAN (
)	500 μ
Processing time of UPFs (
)	50 μ
Processing time of DN (
)	100 μ
Processing time of AP (
)	5 μ
Propagation delay in optical links	5 μ
Other parameters
Links capacity	10 Gbps
MEC server capacity	16 vCPU
UPF processing capacity	2 vCPU
UPF types	1:A-UPF, 2:MI-UPF, 3:I-UPF
Number of VNF instance per type	[1: 72, 2: 16, 3: 16]
Weight factors	, , 
5.2. PC-UPC performance evaluation
To evaluate the effectiveness of the proposed heuristic, we compared its behavior with two benchmarks in terms of the total cost, the number of reassigned VNFs, and execution time. These baseline solutions were greedy-based heuristics called Greedy (GH) and Sorted Greedy (SGH). Both solutions assign SFCRs to those VNF instances and servers that offer the lowest cost (i.e., minimize the objective function (23)). Additionally, SGH orders the SFCRs by following the same criteria as our proposed algorithm. Moreover, to avoid SFCR rejections and guarantee similar comparison conditions, we included a VNF reassignment procedure. This procedure takes one step back into the mapping process when a VNF service request cannot be mapped due to the absence of feasible candidates. Specifically, the previous VNF in the chain is reassigned to a different candidate (the next best location) if any. This process repeats until successful mapping of the current VNF has been achieved or no feasible candidate remains to be screened for the previous VNF.

Fig. 4 summarizes the gathered results. As a general observation, the analyzed metrics can be seen to increase with the number of PDU sessions. This figure, also reveals that our proposed heuristic outperformed the benchmarks. It not only had the best cost behavior but also the lowest execution time and fewer reassignments. Concretely, the PC-UPC was able to map all the SFCRs without reassigning any VNF. Noteworthily, had it not been for the reassignment procedure, the baselines would have ended up rejecting the reassigned PDU sessions. Furthermore, higher cost reductions as well as fewer VNF reassignments were achieved when accounting for SFC requirements along with current network conditions (i.e., PC-UPC and SGH). Consequently, these results showcase the importance of using the look-ahead and priority sorting processes during the mapping of SFCRs.

5.3. SA-UPC performance evaluation
The main objective of this subsection is to assess the performance of the proposed SA. Since our solution introduces several modifications w.r.t to the CSA, we ran various experiments by gradually introducing each of the changes. Doing so allowed us to investigate their advantages in greater depth. First, we evaluated the proposed neighborhood methods when a non-restart–stop mechanism was used for a fixed MCL (FMCL) of 20 iterations. Next, we studied the effects of our restart–stop strategy by comparing it with a classical restart approach in which the current best solution is always used as the restart point. Finally, we analyzed the performance of the variable MCL strategy versus a fixed approach. For the tests, the initial and final temperature values were set to 100 and 0.01, respectively, and geometric scheduling with a cooling factor () of 0.9 was used.

5.3.1. Initial solution and neighborhood methods
Fig. 5, Fig. 6 summarize the simulation results, in terms of cost and execution time, for the proposed NS approaches (i.e., NS_3T and NS_ST). Their performance was compared with a traditional method (NS_T1) that introduces small modifications to the current solution (only changes of type one). For changes of type one, a neighborhood set with a size of five samples was used. Moreover, we investigated their behavior when different approaches were applied to determine the initial solution (IS). Specifically, two types of initial solutions were considered: the first was generated by randomly mapping the SFCRs in candidates that comply with UPF placement restrictions, whereas the second solution was the proposed PC-UPC heuristic.

From Fig. 5 we can observe that NS_3T and NS_ST always had the best performance, achieving significant cost reductions compared with NS_T1. This was more noteworthy when the initial solution was of poor quality (see Fig. 5(a)). In this case, the proposed methods were able to improve the initial solution by at least 60%, whereas NS_T1 only provided a cost reduction of up to 37% in the best case scenario (i.e., S = 50). Moreover, both NS_3T and NS_ST provided similar results regardless of the quality of the initial solution. By contrast, the final cost obtained by NS_T1 was highly dependent on the initial solution quality since it was unable to achieve significant improvements. The latter is depicted in Fig. 5(b), where the cost of the initial and final solutions for NS_T1 can be observed not to differ significantly.


Fig. 5. SA-UPC placement cost for different NS methods.

Fig. 6. SA-UPC execution time for different NS methods.

Regarding the methods’ effects on the SA running time (see Fig. 6), the NS_T1 method had the lowest impact with values around four and two times smaller than NS_3T and NS_T1, respectively. This behavior was anticipated since the proposed methods introduce more transformations to generate the neighbor solutions. Concerning the effects of the initial solution on this metric, we can appreciate that the execution time of NS_T1 was similar for both types of initial solutions since it did not depend on the quality of the generated solutions. This was not the case for NS_ST and NS_3T, which experienced an increment when the proposed heuristic was used as the initial state. This is because more sessions had to be re-mapped since the servers and VNFs had more sessions assigned as their number was smaller. Moreover, NS_ST performed more diversification processes in an attempt to find improved solutions given the fewer updates of the best solution. Furthermore, the simulation time of NS_ST remained much lower at all times than the one obtained by NS_3T with a difference of at least 1.6 times for both types of initial solutions. Therefore, NS_TS can provide similar costs to NS_3T at a lower execution time by adapting the neighborhood search to the quality of the generated solutions and temperature values.

The obtained results demonstrate that NS methods that combine exploration with the exploitation of the solution space provide superior results compared with the traditional methods. Nonetheless, this is at the expense of higher execution times.

5.3.2. Restart–stop criteria
This subsection evaluates the performance of the proposed restart (PR) method against a classical restart (CR) approach in which the current best solution is always used as the restart point. Moreover, it analyzes the effects of different stop periods on the quality of the final solution and execution time of the SA. These experiments were realized with an FMCL of 20 iterations per temperature value and a random initial solution. Moreover, the proposed restart approach generates the restart point based on the current best solution by completely reassigning the PDU sessions allocated to a maximum of two servers selected at random.

Fig. 7, Fig. 7 illustrate the SA output cost for a restart period of three temperatures and a stop condition of three and five restarts, respectively. From both figures, it can be appreciated that the proposed restart approach, represented by striped bars, always provides solutions with lower costs than the baseline (bars without stripes), regardless of the NS method. Moreover, w.r.t. the effects of more restarts in the stopping condition, slight improvements in the proposed NS methods were noted for both the classical and proposed restart approaches. These observations were more noticeable for the NS_T1 method, which depends on the restart solution to incorporate diversification and thus for improving the exploration of the solution space. In this regard, we stress that, unlike the PR, the CR was unable to enhance the output solution for NS_T1 despite the increment in the number of restarts. The latter provides evidence that a classical restart may be unable to help the algorithm escape from local optima, thus rendering it inefficient.

Fig. 8 depicts the running time for both restart strategies. In this respect, the proposed restart mechanism required a higher execution time than the baseline. However, except for the NS_3T method with 150 PDU sessions, this difference was not highly significant. The main cause of this behavior is that most of the time, the proposed restart enabled improvement of the current best solution, which in turn delayed the occurrence of restarts and subsequently of the stopping condition. Additionally, the execution time tended to increase with the increment of the stop period, as was to be expected.


Fig. 7. Obtained cost for different restart–stop periods.

By comparing the behavior of the SA with and without the proposed restart–stop strategy, we noticed that not only was the initial solution significantly improved (compare Fig. 5(a) against Fig. 7(a)) but also the computing time of the SA was too (refer to Fig. 6, Fig. 8). Specifically, for the NS_ST, NS_T1, and NS_3T methods, the restart–stop with 
 and 
 resulted in reductions in the execution time of at least 50%, 65%, and 70%, respectively. Likewise, for 
 and 
, the SA algorithm was more than 40%, 50%, and 65% faster. Moreover, the difference between the running time of NS_3T and NS_ST was significantly reduced. The aforementioned results demonstrate the effectiveness of the proposed restart–stop approach, not only in increasing the probability of finding better solutions but also in reducing the SA running time.


Fig. 8. Execution time for different restart–stop periods.

5.3.3. VMCL strategy
The effects of the VMCL strategy were assessed under different conditions for the proposed NS methods. In particular, its behavior was tested for SA with and without restart–stop against an FMCL approach and using a random solution as the initial state. For the experiments, different values for the upper and lower bound of the Markov chain were considered. To facilitate the analysis of the results, these approaches were divided into two groups according to the MCL values, as shown in Table 5.

The impact of different MCL approaches on the cost of the SA final solution is depicted in Fig. 9. By examining this figure closely, we can appreciate that, in general, no significant improvements in the quality of the output solutions were obtained despite the number of inner iterations increasing (e.g., FMCL_20 vs. FMCL_40). Additionally, for both the NS_3T and NS_ST methods, the VMCL strategy provided similar or better costs than its fixed analogous. This was more remarkable for the second group of MCL variants where the length of the chain was greater. The exception to this behavior was VMCL_1020 which in general had worse performance than FMCL_20. The reason behind this is that VMCL_1020 performed poorer scans of the solution space since it realized fewer iterations.


Table 5. MCL values considered in the experiments.

Group	Approach	MCL	Notation
Variable	10 & 20	VMCL_1020
I	Variable	10 & 30	VMCL_1030
Fixed	20	FMCL_20
Variable	20 & 40	VMCL_2040
II	Variable	20 & 50	VMCL_2050
Fixed	40	FMCL_40
Fig. 10 illustrates the effects of the MCL on the running time of the SA for different numbers of PDU sessions. As was expected, this metric increased with the temperature length. However, the proposed VMCL solutions managed to maintain slower paces than their corresponding fixed variants. The latter was most notable for greater MCL values (i.e. group II) or when using SA without restart–stop.


Fig. 9. SA output cost for different MCL strategies with and without restart–stop.

5.4. UPC performance evaluation
In this subsection, we evaluate the performance of the proposed solutions according to the following metrics: overall cost, execution time, number of open servers, number of UPFs, and average E2E delay. We also compare the SA-UPC with a variant of the CSA, which generates neighbor solutions by only introducing changes of type one. Moreover, this baseline (CSA_T1) always used the best current solution as the restart point and had an FMCL of 20 iterations per temperature value. By contrast, SA-UPC adopted the proposed restart method and a VMCL (i.e., VMCL_1030). Additionally, a restart period of three temperatures and a stopping condition of three restarts were considered. The proposed heuristic was used as the initial state for all the variants of SA. Please note that for the ILP model, simulation results are presented for up to 100 active PDU sessions since it was unable to solve the problem for higher numbers of sessions within a reasonable time.

5.4.1. Overall cost
Fig. 11 represents the average total cost for the proposed solutions and the baseline for different values of PDU session requests. From this figure, we can observe that the total cost increased with the number of active PDU sessions since more servers and VNF instances must be activated to cope with service demands. The minimum costs were always provided by the ILP and the proposed variants of the SA-UPC (i.e., SA-UPC_3T and SA-UPC_ST). Notably, this solution provides almost identical results to the mathematical model when using either of the proposed NS methods. In fact, the NS_ST method was able to obtain similar results to NS_3T when an initial solution with acceptable quality was used in combination with the proposed restart–stop strategy. By contrast, the PC-UPC had the worst performance since it was used as the initial solution for all the SA variants. However, in the worst-case scenario, its difference from the optimal was at most 22%.

Additionally, the SA-UPC was able of improving the initial solution by approximately 2.3% and 17% whereas the baseline only provided a cost reduction of 8.5% in the best-case scenario. The improvement achieved by this method was null or scarce most of the time (i.e., less than 3%). In the cases where the proposed SA had poor performance, with results similar to the CSA, the proposed heuristic (initial state of the SA) obtained results close to the optimal (S = 40) or the minimum number of VNF and open servers (S = 300 and 400) needed to meet the required services demand. Thus, the only possibility for improvement in those cases was in terms of latency, which had the least importance in the objective function.


Fig. 11. Total cost vs. different numbers of SFCs.

5.4.2. Running time
In addition, we measured the average running time required for each solution to solve the UPC problem. As Fig. 12 reveals, a significant difference existed between the running time of the ILP model and the heuristic-based solutions. The execution time of the former grew exponentially with the number of active PDU sessions. Moreover, for numbers of sessions higher than 100, the ILP model was unable to obtain the optimal solution due to the huge number of feasible solutions. By contrast, the heuristic-based solutions’ running time increased linearly with the number of SFCRs. In this regard, the best computing time was provided by the PC-UPC heuristic which was able to solve the problem within a couple of seconds (i.e., less than 10 s) with an average optimality gap below 13.5%.

Regarding the performance of the proposed SA compared to the baseline, the CSA_T1 was on average 2.8 and 5.5 times faster than SA-UPC_ST and SA-UPC_3T, respectively. However, this speed was at the expense of a poor quality improvement for the initial solution.

Fig. 12. Running time vs. different numbers of SFCs.

5.4.3. Other metrics
Finally, we offer a glimpse of other aspects of the generated solutions by representing the behavior of each term in the objective function (23), see Fig. 13.

Figs. 13(a) and  13(b) depict the average number of active servers and instantiated UPFs, respectively. The first observation here is that the PC-UPC heuristic was able to provide solutions that differ from the optimal, at most, in the activation of one server or VNF instance, but not both simultaneously. Moreover, the SA-UPC approach was the one that most closely resembled the performance of the mathematical model. The latter also applies to the average E2E delay parameter (see Fig. 13(c)), where both solutions behaved quite alike. In this regard, it is worth mentioning that our proposed SA obtained lower average latency values than the baseline even in cases where it had fewer open servers or VNF instances.

Fig. 13. Performance of each term in the objective function vs. different numbers of PDU sessions.

The presented ILP formulation for the UPC problem becomes computationally intractable as the size of the involved sets increases (e.g., the number of SFCRs, VNF types, and ENs). As evidenced by the conducted experiments, its computational time grew exponentially with the number of PDU sessions until the point of being unable to determine a solution when the number of SFCRs was higher than 100, in a medium-size 5G topology compounded by 13 ENs. Moreover, as the UPC problem difficulty increases, does its execution time and the required computational resources. To overcome these limitations, we have presented heuristic and metaheuristic-based solutions. They introduce various mechanisms that notably enhance their performance. Our simulation results showcased that these solutions are feasible and efficient approaches to tackle the problem. Specifically, they provide near-optimal results in significantly less time in addition to outperforming some existent benchmarks. Thereby, our proposed strategies provide the necessary flexibility and efficiency to meet 5G service stringent requirements (e.g., latency and device density) and reduce their deployment and operational costs. Furthermore, these approaches can help network operators and service providers efficiently plan and deploy their services and network functions, as well as study and analyze the behavior of different parameters.

6. Conclusion
In this study, we investigated the 5G UPC problem. The problem was formulated as a multi-objective ILP model aimed at minimizing expenditures associated with PDU session provisioning and the enhancement of QoS (i.e., network response time). The model is bounded by stringent service latency requirements and physical network capabilities (e.g., links bandwidth and node processing capacity). Moreover, it encompasses several constraints such as UPF-specific, VNF order, and routing path.

Since the problem was demonstrated to be NP-hard, a specific heuristic (PC-UPC) along with an SA solution (SA-UPC) was provided to solve it in polynomial time. Simulation results revealed that the proposed solutions not only outperformed the benchmarks but also obtained near-optimal results, when the problem scale was small, in significantly less time. Specifically, the PC-UPC algorithm was able to solve the problem within a couple of seconds with an average optimality gap of around 13.5%. By contrast, the proposed variants of SA allowed for results almost identical to the optimal results but at the expense of higher running times. Moreover, through extensive simulations, we demonstrated that the proposed modifications improved the performance of the SA algorithm, thus, enabling it to provide high-quality outputs regardless of the initial solution.

For future work, we will adapt our proposed solutions for the UPC to a dynamic environment in which the numbers of PDU sessions and user positions vary over time. Specifically, our primary goal is to design reconfiguration strategies (mathematical models and heuristics) and scheduling mechanisms to determine the optimal time to reconfigure according to different criteria. Furthermore, we will also intend to investigate the incorporation of reliability approaches (backup VNFs and paths) to enhance the robustness of the placement and chaining solution.