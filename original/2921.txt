This thematic synthesis aims to analyze the qualitative evidence provided by earlier empirical studies to achieve a comprehensive and up-to-date understanding of the factors influencing students’ online learning experiences through the lens of the Community of Inquiry framework. Following a three-stage procedure specified by Thomas and Harden (2008), we started with 3641 potential studies and then (1) coded all studies meeting inclusion criteria (n = 35); (2) developed descriptive themes based on the codes; and (3) generated analytical themes based on the descriptive themes. The results revealed ten descriptive themes that can be grouped into three overarching categories (i.e., course design, instructor actions, and student actions) that are related to the Community of Inquiry framework. Analytical themes included accountability, being real, and supporting learning process. These conceptual insights provide both theoretical and practical implications as well as directions for future research.

Keywords
Community of inquiry
Teaching presence
Cognitive presence
Social presence
Online learning
Thematic synthesis

1. Introduction
It is not uncommon for online learners to report that online courses offer flexibility and convenience, provide the opportunity to work at a preferred pace, allow increased access to diverse courses, and present affordable educational opportunities (Davidson-Shivers, Rasmussen, & Lowenthal, 2018). Although institutions have been increasing online course offerings due to benefits for institutions, instructors, and students, providing students satisfying online learning experiences still remains a major concern (Davidson-Shivers et al., 2018; Lee & Martin, 2017) due to reasons including the need for “higher-level self-directed learning skills and greater difficulties in enabling effective human interactions” (Xu & Xu, 2019, p. 26). In this respect, the Community of Inquiry (CoI) framework (Garrison, Anderson, & Archer, 2000) provides both theoretical and methodological guidance for designing and facilitating meaningful online learning experiences and evaluating online learning effectiveness (e.g., Arbaugh, 2013; Richardson et al., 2012), which aligns with such claims as “a more in-depth analysis requires a lens that illuminates the complexities of online learning” (Richardson et al., 2012, p. 98).

As a result, the CoI framework has been quite influential on online education research and practice (e.g., Kozan & Caskurlu, 2018). Yet, only a few studies have synthesized the previous findings related to the CoI framework (e.g., Befus, 2016; Caskurlu, Maeda, Richardson, & Lv, 2020; De Gagne & Walters, 2009; Richardson, Maeda, Lv, & Caskurlu, 2017). Most of these were quantitative in nature with only; Befus (2016) is the only qualitative synthesis thematically synthesizing previous CoI research regarding the nature, focus, and context of each study. Specifically, Befus (2016) explores how the seminal CoI work by Garrison et al. (2000) had been applied in previous research by using each study as a unit of analysis. Befus (2016) identified (a) 24 basic themes (e.g., describe online learning environments and factors, adopt CoI content analysis protocol, adopt CoI concepts as a treatment in a quasi-experimental study to determine the effect on student learning, and to validate or modify CoI model); (b) 11 organizing themes (e.g., describe, define, analyze, and critique); and (c) four global themes (i.e., describe, measure variables, research treatment, and validate/extend). In other words, Befus (2016) synthesized the relevant research by focusing on their different characteristics. Accordingly, there is a need for a more interpretive, comprehensive, and updated synthesis on earlier qualitative research with a focus on the factors that are informed by the CoI framework and that impact the quality of students’ online learning experiences. To this end, the current synthesis provides a more interpretive synthesis of the previous qualitative study findings.

1.1. The CoI framework and student outcomes
Garrison et al. (2000) proposed the CoI framework to “illustrate the multifaceted components of teaching and learning in a text-based environment” (Anderson, Rourke, Garrison, & Archer, 2001, p. 3). The focus of the CoI framework is to create deep and meaningful online learning experiences through (a) social presence (SP): “the ability of participants to identify with the community (e.g., course of study), communicate purposefully in a trusting environment, and develop interpersonal relationships by way of projecting their individual personalities” (Garrison, 2009, p. 352); (b) cognitive presence (CP): “the extent to which the participants in any particular configuration of a community of inquiry are able to construct meaning through sustained communication” (Garrison et al., 2000, p. 89); and (c) teaching presence (TP): “the design, facilitation, and direction of cognitive and social processes for the purpose of realizing personally meaningful and educationally worthwhile learning outcomes” (Anderson et al., 2001, p. 5).

More specifically, SP consists of (a) affective expression or expressing feelings related to a given learning experience; (b) open communication that is “reciprocal and respectful exchanges”; and (c) group cohesion referring to “activities that build and sustain a sense of group commitment” (Garrison et al., 2000, p. 89). Likewise, CP has been operationalized through the four phases of the Practical Inquiry Model (Garrison, Anderson, & Archer, 2001): (a) triggering events involve “recognizing the problem”; (b) exploration covers “information exchange, discussion of ambiguities”; (c) integration includes “connecting ideas, create solutions”; and (d) resolution gets learners to “vicariously apply new ideas, critically assess solutions” and choosing the best one (Garrison et al., 2000, p. 102). Finally, TP is comprised of three subparts: (a) design and organization is designing “the process, structure, evaluation and interaction” and “providing guidelines and tips and modeling”; (b) facilitating discourse is enhancing reflective and sustained communication and learners’ “interest, motivation, and engagement” in addition to evaluating these efforts; and (c) direct instruction is providing students subject matter expert knowledge and leadership to attain learning goals (Anderson et al., 2001, p. 5-6-7).

Given their definitions above, it is no surprise that the CoI elements are related to student outcomes in online education: the CoI presences, for instance, are related to student outcomes ranging from satisfaction to actual learning in online education (e.g., Richardson et al., 2017; Richardson & Swan, 2003; Swan & Shih, 2005). Earlier research suggested that CoI-related factors (e.g., course design, facilitation) influence online learning experiences from different perspectives including sense of belonging (e.g., Borup, West, & Graham, 2012; Kupczynski, Ice, Wisenmayer, & McCluskey, 2010; Shea, Swan, Li, and Pickett, 2005). Arguing that meaningful technology integration can enhance group interaction thereby supporting knowledge building, sense of belonging, and sense of involvement, there is also research addressing the use of technology to support communities of inquiry in online environments with the guidance and support of the following CoI-related factors: course design, facilitation, and direct instruction (e.g., Borup et al., 2012; Huss & Eastep, 2013, p. 2014; Ice, Curtis, Phillips, & Wells, 2007; Miller, Hahs-Vaughn, & Zygouris-Coe, 2014; Pinsk, Curran, Poirier, & Coulson, 2014). Despite the studies referring to the relationships between CoI elements and student outcomes in online education, there is a lack of synthesis providing a comprehensive recent summary that can inform both future research and practice.

Specifically, the quantitative meta-analytic work we previously conducted (i.e., Caskurlu, Maeda, Richardson, & Lv, 2020; Richardson et al., 2017) yielded a positive relationship between the CoI presences and student outcomes in fully online courses. However, due to the lack of sufficient information reported in the quantitative studies included in the meta-analyses, it was not possible to explore whether course design and instructors' actions would serve as moderators affecting the relationship between the CoI presences and perceived student outcomes. Our review of CoI studies also revealed that course design- and instructor action-related factors are mainly reported as qualitative evidence. Therefore, this qualitative synthesis study aims to complement and add the depth of contextual understanding to the knowledge generated by the earlier quantitative findings by accumulating the qualitative evidence for the factors that influence students' online learning experiences as they relate to the CoI framework. Specifically, the present thematic synthesis: (a) presents qualitative insights into the relationships between CoI elements and student outcomes in online learning, a link supported by previous research (e.g., Akyol & Garrison, 2011; Caskurlu, Maeda, Richardson, & Lv, 2020; Miller et al., 2014; Richardson et al., 2017); and (b) translates main findings from primary studies into broader themes and more comprehensive descriptions, thereby also providing strong insights into practice. In other words, this study is a qualitative synthesis that aims “to integrate themes and insights gained from individual qualitative research into a higher-order synthesis that promotes broad understandings” of students' online learning experiences (Scruggs, Mastropieri, & McDuffie, 2007, p. 395) while examining the following research question: What are the factors influencing students’ learning experiences in fully online courses as informed by the CoI framework?

2. Methodology
This study utilized thematic synthesis that is a specific type of qualitative synthesis and different from other narrative reviews because it explicitly treats reported qualitative findings as data for analysis, and identifies prominent or recurrent themes (Thomas & Harden, 2008). We chose thematic synthesis mainly due to our exploratory purpose: it allowed us to explore the students’ online learning experiences by integrating primary study findings thus going beyond each study. Thomas and Harden (2008) proposed three steps for thematic synthesis: (a) line-by-line coding; (b) developing descriptive themes using the first coding; and (c) generating analytical themes based on the descriptive themes. Descriptive and analytical themes are different in that descriptive themes represent the original studies while analytical themes bring new interpretative insights (Barnett-Page & Thomas, 2009; Thomas & Harden, 2008).

2.1. Search procedure
We identified studies through electronic search engines such as Google Scholar, and electronic databases (e.g., EBSCHO, ERIC, PsycINFO, ProQuest Dissertations & Theses) and used criterion sampling to ensure the retrieved studies were relevant. Search terms included “community of inquiry”, “online”, “higher education”, “qualitative”, and “learning experience”. To identify additional studies, we also hand searched the following journals: The Internet and Higher Education, British Journal of Educational Technology, Online Learning, Computers & Education, Distance Education, American Journal of Distance Education, and The International Review of Research in Open and Distributed Learning. We also searched book chapters through the university library website and included the available book chapters. Finally, we used snowball sampling by reviewing the references of identified studies to detect more studies.

2.2. Inclusion and exclusion criteria
We included peer-reviewed journal articles, dissertations and theses, and book chapters that (a) were published within the last 12 years (January 2007–August 2019) to cover the most recent and up-to-date insights; (b) used the CoI framework; (c) covered students' fully online learning experiences in higher education; (d) provided qualitative evidence including verbatim evidence from the participant's voice/grounded data; and (e) were published in English. We also included mixed method studies when qualitative data were reported. Our electronic and manual search produced a total of 3641 potential studies; however, inclusion and exclusion criteria led to an ultimate total of 35 studies (see Fig. 1). Some literature on qualitative synthesis methodology suggests including 10 studies as an optimal in qualitative synthesis as “overly large sample sizes tend to impede deep analysis and, therefore, threaten the interpretive validity of findings” (Sandelowski, Docherty, & Emden, 1997, p. 368).

Fig. 1
Download : Download high-res image (256KB)
Download : Download full-size image
Fig. 1. Search procedure.

2.3. Critical appraisal of the included studies
There is no consensus on how the results of a critical appraisal should be presented in a synthesis (e.g., Carroll and Booth, 2015) despite the general consensus that quality appraisal should be part of a synthesis process assessing trustworthiness and relevance. For example, even though some researchers suggest excluding poor quality studies to enhance quality (e.g., Atkins et al., 2008), others argue that excluding studies with low methodological quality might lose some important qualitative evidence (e.g., Campbell et al., 2011). Furthermore, some researchers argued that due to the potential lack of information provided in primary studies, reviewers may not have sufficient information to evaluate quality (Carroll, Booth, & Lloyd-Jones, 2012; Dixon-Woods et al., 2006). Finally, there is no threshold for excluding or including a study based on critical appraisal results (Heyvaert, Hannes, & Onghena, 2017). Therefore, we developed and used a critical appraisal checklist with seven items considered as essential in qualitative research to describe reporting practices of the included studies, and to examine the credibility of synthesis findings in addition to a sensitivity analysis. Specifically, we used the critical appraisal (Appendix B) to review primary studies by focusing on what was reported or not, thereby descriptively evaluating the reporting quality.

2.4. Data extraction and synthesis of results
This synthesis followed three steps: line-by-line coding of primary study findings, developing descriptive themes, and generating analytical themes. First, all primary studies were imported to the QSR's NVivo (11) software for qualitative data analysis. Then, we coded study findings line-by-line, with the unit of analysis being phrase level. If a phrase represented more than one code, multiple codes were assigned to it.

We conducted three coding cycles: (1) the initial coding schema aligning with the CoI indicators (e.g., Anderson et al., 2001; Garrison et al., 2001; Rourke, Anderson, Garrison, & Archer, 2001) was created inductively through five sample studies; (2) the first author coded all primary studies individually. As the researcher continued coding, reading and rereading the studies, new codes were added as necessary. Next, the first and second authors discussed the codes with example quotes and revised the coding schema. In the revised version, three initial themes (i.e., course design, instructor actions, and student actions) became overarching categories, and initial descriptive themes (e.g., sense of belonging, supporting sense of community) were created inductively by grouping and organizing the codes; and (3) the first author coded all the studies based on the revised coding schema with the descriptive themes. A second researcher coded five randomly selected studies to validate data extraction and coding. Finally, we created the analytical themes (i.e., accountability, being real, and supporting student learning process) based on the identified descriptive themes.

2.5. Trustworthiness and reliability
To establish trustworthiness and reliability, we employed several strategies. First, the first author coded all studies individually, and the second author coded five randomly selected ones including one dissertation and four journal articles. Initial inter-coder reliability was 97% and all disagreements were resolved through consensus. Second, study search, coding, and synthesis processes were explained in as much detail as possible. Third, verbatim evidence was used to support the inferences made. Fourth, primary characteristics of the reviewed studies were provided to enhance dependability. Fifth, we employed a sensitivity analysis by using the critical appraisal checklist to increase credibility: the first and fourth author appraised all 35 studies individually and compared their codes. The initial agreement was 73%, and full agreement was achieved by resolving all disagreements. Lastly, the sensitivity analysis showed that removing low quality studies did not change the overall themes and factors.

Furthermore, trustworthiness and reliability were improved since the researchers were reflexive about their position regarding the process of qualitative synthesis (Suri & Clark, 2011): We approached this study from a collaborative constructivist approach since it is the foundation of the CoI framework. According to this approach, “constructing knowledge is situated in discourse by way of advancing personal meaning and adding to shared understanding” (Garrison, 2013, p. 4). Thus, knowledge construction is a joint activity of all participants in a learning community (Garrison, 2013). Accordingly, we sought to identify the factors influencing students’ online learning experiences in relation to course design, instructor, and peers. Of note, we are also experienced online instructors and course developers, and have experience with the use of the CoI framework for conducting research, designing, and evaluating online courses. Therefore, our professional experience provided informed decisions regarding online learning, course design, and facilitation especially in relation to the CoI framework.

3. Results
3.1. Characteristics of primary studies
Thirty-five qualitative and mixed method studies were included in this synthesis (see Appendix A for study characteristics). Of these, 18 were qualitative, 15 were mixed-methods studies, and two did not specify their research design. The qualitative studies used different research designs: 14 qualitative studies conducted case study (n = 1 phenomenological, n = 1 cross-case, n = 2 multiple case study, n = 1 descriptive case study, n = 1 pragmatic case study, and n = 8 did not specify their case study type), two phenomenological studies, and two did not specify their qualitative research method. Further, of the mixed-methods studies, three were sequential explanatory, two were explanatory, one was sequential, one was action research, one was concurrent, one was convergent parallel design, one was comparative approach, and five studies did not specify their research design.

The main data source among the primary studies was interview (i.e., semi-structured, open, and ethnographic: n = 27) followed by focus group (n = 5), open-ended questions (n = 9), participant reflection (n = 1), and end of course evaluation comments (n = 1). The studies explicitly reporting qualitative data analysis methods employed content analysis (n = 5), thematic analysis (n = 6), constant comparisons (n = 3), cross-case analysis (n = 3), cross-study analysis (n = 1), textual analysis (n = 1), and phenomenological approach (n = 1). Lastly, a total of 2875 participants participated in the qualitative phases with sample sizes ranging from four to 1085.

3.2. Descriptive themes
This thematic synthesis revealed 10 descriptive themes that can be presented under the following CoI-related overarching categories: course design, instructor actions, and student actions.

3.2.1. Course design
This category focuses on the following course design-related items that primary study participants emphasized as influencing their online learning experiences: learning resources, learning activities, collaboration and working in small groups, supporting interaction, supporting sense of community, and clarity in course design and expectations.

3.2.1.1. Learning resources
Primary study participants perceived course content and learning materials as important contributors to their learning experiences (e.g., Archibald, 2011; Bokhari, 2016; Snyder, 2014; Theissen, 2015; Wojenski, 2014). Students emphasized that they feel more engaged to participate when the subject and course content encourage them to search and seek more information (Bokhari, 2016; Snyder, 2014). For instance, a participant noted that “It just starts at the very beginning and goes through and then kind of keeps it in really centralized to something that were experiencing right now … The content kept me totally engaged. I'm excited about the next chapter” (Snyder, 2014, p. 60).

When it comes to learning materials, students mentioned that having different types of learning materials in various delivery modes (e.g., readings, video lectures, PowerPoint slides) helped them to maintain their motivation, perceive different perspectives, and supported their learning (Archibald, 2011; Finley, 2016; Huss & Eastep, 2013; Mills et al., 2016; Snyder, 2014; Steele, Robertson, & Mandernach, 2017; Wojenski, 2014). For example, a participant mentioned that having different types of resources helped them understand the subject better: “I felt that the articles, Pinterest, and YouTube helped me understand the subject matter and did a good job of giving thorough explanation” (Wojenski, 2014, p. 84). In contrast, in a case lacking such a variety, one participant from Huss and Eastep's (2013) study stated: “the only technology used was regular PowerPoints and links to resources. It was a very boring class.” (p. 9).

3.2.1.2. Learning activities
Learning activities in online courses also impacted primary study participants’ learning process and experience. Specifically, students regarded learning activities as “the most rewarding aspect” of a satisfying learning experience when they are relevant to the real world and their work (Mills et al., 2016, p. 38). Such activities not only help them to link their learning to their lives and workplaces, but also to better understand class concepts (Archibald, 2011; Bokhari, 2016; Snyder, 2014; Thiessen, 2015; Williams-Shakespeare, 2018). To illustrate, one participant indicated:

I would always prefer to be able to do activities or assignments that are real-life based rather than based on the information in the text. I like to learn the material in the text and then apply it to my life. This makes writing about the material easier and I feel that I understand the concept better when I can see how it is used in the real world (Thiessen, 2015, p. 104).

Finally, participants considered learning activities enjoyable, motivating, and helpful for their learning when the new learning experience takes their previous learning into account rather than repeating what they already know (Bokhari, 2016). For instance, a participant from Bokhari (2016) reported an unsatisfying experience because she did not feel the class took into account her prior learning. Likewise, another participant reported: “Actually, I did study English courses before I started my college learning. So it was like a repetition for me in terms of my grammar and in term[s] of my understanding to some words and sentences, and I did not improve in my speaking or listening” (Bokhari, 2016, p. 81).

3.2.1.3. Collaboration and working in small groups
Primary study participants also perceived collaborating with others and working in small groups in learning activities as valuable since such experiences encourage them to be “involve[d] more in the work and produce more precious output” (Bokhari, 2016, p. 71). Students also preferred having small group discussions rather than whole group discussions as they helped them to “focus and follow up each other's work closely” (Dzubinski, 2014, p. 102). However, working in small groups or collaborating with others may not always be functional due to student learning preferences, disagreements among group members, communication issues among group members because of technology and students' unresponsiveness, and lack of contribution to group projects (Alanazi, 2017; Archibald, 2011; Brakhage, 2015; Huss & Eastep, 2013; Robinson, 2013; Theissen, 2015; Townsend, 2015; Williams-Shakespeare, 2018; Wojenski, 2014).

Students also preferred to have individual learning activities that support their self-directed learning (Archibald, 2011; Bokhari, 2016; Lambert & Fisher, 2013; McDonald, 2013; Snyder, 2014; Townsend, 2015; Wojenski, 2014). For instance, one participant from the Lambert and Fisher (2013) study stated: “I've felt empowered in this class, especially with the website assignment. Essentially we were the teacher or ultimate authority within our own site and academic discipline.” (p. 11).

3.2.1.4. Supporting interaction
Primary study participants found that interaction in online classes is helpful and important as it keeps them engaged, encourages them to seek different opinions and to share their perspectives, and fosters their learning through information exchange, reading others' posts and reflecting on their learning (Archibald, 2011; Bokhari, 2016; Borup et al., 2012; Catron, 2012; Makos, 2017; Tolu, 2010; Wojenski, 2014). For example, one participant shared: “It was interesting to see what we had agreed on and the points we had seen differently. This helped me to focus on and rethink my ideas as I looked at the work from a slightly different angle” (Robinson, 2013, p. 303). Interaction also helped students exchange their ideas, which encouraged them to think critically and to reflect on their learning thereby forming their understanding of concepts (Archibald, 2011; Bokhari, 2016; Makos, 2017; Mills et al., 2016; Robinson, 2013; Snyder (2014). For instance, one participant said: “Listening, sharing, and reading others' ideas enabled students to understand concepts and to realize what you don't know … it was probably more about that inﬂuential stuff, that I didn't realize what I didn't know. That was probably the best thing I got out of it” (Mills et al., 2016, p. 37).

Although students participating in class “demonstrated more cognitive presence, felt more socially connected, and experienced a more positive intervention experience” (Wojenski, 2014, p. 90), exceptions were reported in Capra (2014), Theissen (2015), and Williams-Shakespeare (2018). Some students did not find interaction in online classes so important for their learning, and the main reasons were (a) learning preferences; (b) quality of interaction and responses; and (c) timeliness of student responses. For example, one participant shared an unwillingness to depend on others:

My online learning experience is negative in that it has too much interaction with other students. I don't know how much interaction you need with other people but I know that I just want to be given my assignments and be able to get them done without having to depend on others for my grade, whether that's through a group project or waiting for someone to post on a discussion board (Theissen, 2015, p. 75).

Similarly, a student from Capra (2014) did not enjoy class discussions because “There is about 30 kids in the class by the end of the post they all are pretty repetitive (p. 112). This shows that students expect to have “courteous and professional debate of issues, and contributing fresh new perspectives” in online discussions (Brakhage, 2015, p. 120). Providing a discussion rubric targeting quality could encourage students to provide meaningful responses (Brakhage, 2015; Theissen, 2015).

Moreover, some students suggested that the effectiveness of text-based interaction is enhanced when incorporated into synchronous sessions that (a) provide humanness, just-in-time interaction and immediate feedback; (b) improve student's learning; (c) make the course content clearer and easy to understand; and (d) help students express themselves (Borup et al., 2012; Brakhage, 2015; Catron, 2012; Clark, Strudler, & Grove, 2015; Finley, 2016; McDonald, 2013; Mills et al., 2016; Robinson, 2013; Wheeler, 2015; Williams-Shakespeare, 2018; Wojenski, 2014).

3.2.1.5. Supporting sense of community
Primary study participants valued the sense of community in online courses since it creates a welcoming learning climate, increases their confidence to interact with others, feels being part of the community, and perceives others as real (Borup et al., 2012; Kgatla, 2016; Lewis, 2019). The synthesis of primary studies showed that students value ice-breaker activities asking students to introduce themselves along with a picture foster sense of community (Dzubinski, 2014; Lambert & Fisher, 2013; Makos, 2017; Scialdone, 2014; Snyder, 2014; Williams-Shakespeare, 2018; Wojenski, 2014). Sense of community can be also supported through content-related interactions (Brakhage, 2015; Finley, 2016; Kgatla, 2016; Snyder, 2014) as it allows students “to know each other by working together and commenting on peers learning activities/assignments which were submitted in the discussion forums” (Kgatla, 2016, p. 82). To illustrate, one participant said: “Really, the discussion board is the only place where I really feel connected to the other students” (Snyder, 2014, p. 52).

Further, feeling a “sense of ‘self’ within the context of the asynchronous learning environment” was crucial for having a sense of community (Pinsk, Curran, Poirier, & Coulson, 2014) as it helps to perceive peers and instructors as real and to feel being in a real class (Christen, Kelly, Fall, & Snyder, 2015; Dzubinski, 2014; Lambert & Fisher, 2013; Pinsk et al., 2014; Scialdone, 2014). One strategy fostering the “sense of self” feeling in online courses could be including video lectures (Steele et al., 2017) and video-communication (Borup et al., 2012; Clark et al., 2015; Finley, 2016; Huss & Eastep, 2013; Jones, 2018; Pinks et al., 2014; Stermer, 2018). Some students shared that since video-communication includes visual cues, it helps them humanize the instructor and other students in the class thereby perceiving them as real (Borup et al., 2012; Clark et al., 2015; Pinks et al., 2014). For example, one participant mentioned:

I could actually talk to students and the professor. It was absolutely worth the time and effort. You spend so much time in the classes feeling alone and isolated and I actually felt like I was part of this class, especially when I watched the other students’ videos (Pinks et al., 2014, p. 272).

Even though most students agreed that video communication helps them learn more about their instructor and peers compared to text-based communication, some students indicated that it cannot replace the emotional expressions in a face-to-face class (Borup et al., 2012; Catron, 2012). Students mentioned time as a barrier to using video communication in discussions since “It takes at least twice as long to make a video post because you have to know what you're going to say before you start recording.” (Pinsk et al., 2014, pp. 270–271). Furthermore, some students reported that video-communication helped them develop the sense of community; however, it was difficult to track others' comments or responses (Borup et al., 2012). Students preferred synchronous video-communication, which makes it easier to track other comments and responses (Borup et al., 2012) as well as helping students be part of a community, feel less isolated, get to know others, and build a relationship with the instructor (McDonald, 2013).

3.2.1.6. Clarity in course design and expectations
The synthesis of primary studies showed that “regardless of learner level and context, the need for presentation of clear, concise objectives, instructions and general participation guidelines should be a cornerstone of online course development” (Kupczynski, Ice, Wiesenmayer, & McCluskey, 2010, p. 32). Clarity-related elements were easy navigation, clear assignment instructions and expectations, grading, participation, and established time parameters (Alanazi, 2017; Archibald, 2011; Brakhage, 2015; Dzubinski, 2014; Finley, 2016; Huss & Eastep, 2013; Jones, 2018; Kupczynski et al., 2010; Lambert & Fisher, 2013; Lazarevic, 2011; Lewis, 2019; Mills et al., 2016; Townsend, 2015; Wheeler, 2015). Hence, students found it helpful when there was a detailed syllabus including assignments and a week-by-week schedule (Finley, 2016; Huss & Eastep, 2013; Kupczynski, 2010; Lazarevic, 2011; Wheeler, 2015). One student expressed: “I was really frustrated in this class [course name omitted]. We had assignments that were really confusing. There were several things we needed to do but there weren't any guides that gave us details” (Kupczynski, 2010, p. 31). Lastly, providing clear expectations (e.g., posting videos explaining what to do in a particular week) that would help students keep pace was also useful for some (Alanazi, 2017; Finley, 2016). As one student shared:

One of the best tools that I've seen used more and more in the last year, year and a half - has been some form of a webcast, or podcast, or an audio lecture where you can actually pull up the instructor and they'll demonstrate what they're expecting for the week, and I found that extremely beneficial as I work through some of the more difficult materials (p. 120–121).

3.2.2. Instructor actions
This category included three descriptive themes that increase student satisfaction. Specifically, students are more likely to be satisfied with their learning experiences when their instructors (a) are active and interactive in the course; (b) provide timely, constructive, and detailed feedback; and (c) are present in the course.

3.2.2.1. Being active and interactive
The review of primary studies showed that instructor's support and active participation in an online course is essential for engaging and meaningful interaction (Bokhari, 2016; Brakhage, 2015; Capra, 2014; Catron, 2012; Finley, 2016; Huss & Eastep, 2013; McDonald, 2013; Wheeler, 2015). This finding is not surprising given that students reported “best learning experiences when the teacher” was an active participant in discussions as a co-learner (Brakhage, 2015, p. 122). Similarly, students appreciated their instructor's active involvement in online discussions when the instructor asked exploratory questions (Bokhari, 2016; Borup et al., 2012; Finley, 2016; Townsend, 2015). Students reported that it does not only encourage them to participate in class, but it also helps them “drill down” their ideas (Kupzynski et al., 2010, p. 30) and makes them think outside of the box (Finley, 2016).

Another way to encourage student interaction in online environments is to provide subject matter expert knowledge clarifying student misunderstandings or questions, and prompting responses and additional resources (Finley, 2016; Kupzynski et al., 2010; Snyder, 2014; Stermer, 2018). For example, one student indicated “… There are a couples of teachers that put a little of more time, to explain things. Then even if the student asks the question a million times they'll still answer it but then send a link to like that video and say, "Look this is where you can find this, but let me explain it in different in terms."” (Finley, 2016, pp. 124–125). Finally, students reported satisfaction and better learning when their instructors provided their own perspectives and insights (Archibald, 2011; Synder, 2014; Thiessen, 2015) as it helped them participate in the course and relate that experience to their own life.

Students also expect their instructors to create a positive climate to support interaction by incorporating etiquette strategies (Brakhage, 2015; Dzubinski, 2014; Lambert & Fisher, 2013; Townsend, 2015). For instance, one participant explained: “I would try to make sure the instructors know about online etiquette. I've come across a number of instructors who have made me unhappy because their response comes off with a rude vibe” (Brakhage, 2015, p. 159). It also helps instructors set communication guidelines for “handling disagreements during online discussions” (Lambert & Fisher, 2013, p. 24). Accordingly, some students thought that “It is the responsibility of the teacher to provide adequate topic related discussion material to support useful dialog and effective learning experiences” (Brakhage, 2015, p. 121). However, it is important to note here that some other students reported that instructor involvement may not be necessary: “I don't think the instructor needs to be there to get people to think critically. I think it's all in the assignment” (Townsend, 2015, p. 86).

3.2.2.2. Providing feedback
Feedback was as another important factor that supports students’ learning and provides satisfaction (Archibald, 2011; Berry, 2017; Bokhari, 2016; Catron, 2012; Finley, 2016; Ice, Kupczynski, Wiesenmayer, & Phillips, 2008; Jones, 2018; Kgatla, 2016; Kupczynski, 2010; Mills et al., 2016; Snyder, 2014; Steele et al., 2017; Thiessen, 2015; Townsend, 2015; Wheeler, 2015; Williams-Shakespeare, 2018). For instance, one student reported: “I struggled with writing my final year portfolio because there was no constructive feedback on all my written assignments” (Kgatla, 2016, p. 95). When instructor feedback is detailed and constructive, it helps students construct knowledge and improve their skills by providing direction on how the student is doing, what s/he did wrong, and what s/he further needs to do (Archibald, 2011; Berry, 2017; Bokhari, 2016; Catron, 2012; Finley, 2016; Ice et al., 2008; Jones, 2018; Kgatla, 2016; Kupczynski, 2010; Mills et al., 2016; Snyder, 2014; Thiessen, 2015; Townsend, 2015; Wheeler, 2015).

Students also expect to receive timely feedback on their assignments explaining how they are doing and to refine their assignments (Brakhage, 2015; Huss & Eastep, 2013; Kgatla, 2016; Lambert & Fisher, 2013; Mills et al., 2016; Thiessen, 2015; Townsend, 2015). For example, one study participant stated: “My professor was very disorganized and would not give feedback before another assignment was due so you had no idea if you were supposed to complete the assignment the same or if you were supposed to be doing something different” (Thiessen, 2015, p. 80–81). Moreover, students were also satisfied with video feedback (Berry, 2017). In other words, students reported that video feedback made their instructor's comments easy to understand and enhanced instructor presence (Berry, 2017). Lastly, students expected to receive group feedback along with individual feedback to see the big picture (Dzubinski, 2014; Ice et al., 2008).

3.2.2.3. Being present
Instructor presence was another instructor-related factor contributing to students’ online learning experiences. Reviewing primary studies led to a number of factors that enhance instructor immediacy in online courses. One factor was being accessible and available when students have questions or need instructor input (Alanazi, 2017; Dzubinski, 2014; Finley, 2016; Huss & Eastep, 2013; Lambert & Fisher, 2013; Lewis, 2019; Mills et al., 2016; Snyder, 2014; Steele et al., 2017; Stermer, 2018; Theissen, 2015) as it is “what made this online learning experience all the better” (Theissen, 2015, p. 93).

Another relevant factor was showing caring behaviors by asking how they are doing and if they need any help with understanding the course materials (Berry, 2017; Christen et al., 2015; Dzubinski, 2014; Finley, 2016) through e-mails, weekly announcements, and discussion forums where students can share their difficulties and learning experiences (Berry, 2017; Stermer, 2018). Students also reported that such caring behaviors helped to create a positive learning climate, and implied that their instructor cared about them and their learning.

Instructor self-disclosure through sharing personal experiences, a personal photo, and video communication strengthened their online learning experience was also a factor impacting instructor immediacy (Borup et al., 2012; Christen et al., 2015; Townsend, 2015). Students reported that it “could help students perceive their instructors as real people rather than merely an electronic persona” (Christen et al., 2015, p. 39). To illustrate, one participant claimed: “It was just like being in a classroom, so you saw him and he gave similar examples. He shared things about his family … he shared those personal experiences, and so you felt like you knew him more” (Borup et al., 2012, p. 199). Finally, including video lectures in online classes also helps students perceive their instructors real as “Factors such as seeing the instructor's facial expressions, hearing the instructor's voice, or the instructor sharing expertise contributed to this sense of connection.” (Steele et al., 2017, p. 86).

3.2.3. Student actions
This overarching category consists of students' actions and behaviors that turned out to be crucial for primary study participants' online learning. Specifically, students' active involvement in course discussions in a timely manner and being responsive to their peers’ inquiries through meaningful responses are essential for their online learning experiences (Alanazi, 2017; Bokhari, 2016; Borup et al., 2012; Lewis, 2019; Makos, 2017; Mills et al., 2016; Snyder, 2014; Townsend, 2015).

Students’ contribution to collaborative learning activities was also an important factor impacting online learning experiences (Alanazi, 2017; Brakhage, 2015; Thiessesn, 2015). One student stated: “we had a student that barely participated and it made the project very difficult. This student did not participate in the discussions online and did not get their portion of their work turned in to everyone on time” (Thiessen, 2015, p. 73). Finally, students expect meaningful feedback from their peers too (Dzubinki, 2014; Makos, 2017; Williams-Shakespeare, 2018), which includes corrective stuff and affirmation as well as approval (Dzubinki, 2014; Makos, 2017).

3.3. Analytical themes
The 10 descriptive themes above were aggregated into three analytical themes as part of the current synthesis: (a) accountability (e.g., clear course structure, clear instructions and expectations, checking for understanding); (b) supporting learning process (e.g. setting a positive climate, self-disclosure, using welcoming tone); and (c) being real (e.g., collaborative learning activities, answering student's comments, students active involvement in discussion, providing individual support). Fig. 2 presents the analytical themes and descriptive themes.

Fig. 2
Download : Download high-res image (190KB)
Download : Download full-size image
Fig. 2. Analytical themes.

3.3.1. Accountability
This thematic synthesis showed that accountability plays a significant role in online learning. A further review of descriptive themes revealed that accountability pertains to course design, instructors, and peers. Course design accountability comprises being explicit, clear, and transparent in course design, organization, and facilitation. This accountability can be achieved by weekly course introductions, informing students about important due dates and time frames, providing clear instructions and expectations on participation, and selecting manageable content and learning activities.

Another crucial accountability element is the facilitating discourse responsibility of instructors to clarify course expectations and student understanding. Likewise, instructor accountability includes being accessible and responsive to students' questions regarding course expectations and/or content-related questions. Students also value instructors' active involvement in class discussions by checking student understanding, providing subject-matter expert knowledge to clarify student misunderstandings and/or resolve any disagreements, assessing the efficacy of student inquiry, and providing detailed and timely feedback to help students diagnose their misunderstandings. Finally, students' accountability includes active participation and being responsive to their peers’ inquiries/questions and helping them clarify their course or content-related questions.

3.3.2. Supporting learning process
Course design, instructor, and peers are accountable to the extent they support the learning process and promote learning outcomes. The results revealed that students reported satisfaction when they construct their own knowledge through (a) interaction (content-related and social); (b) comprehension and reflection; and (c) active participation in collaborative and cooperative activities. To that end, course content and learning activities should be designed in a way that encourages students to reflect on their learning through interaction, information exchange, and collaboration with their peers. Furthermore, while students valued interaction and working together with others, they reported more satisfaction when their autonomy is also encouraged. In this respect, they suggested including different forms of learning ranging from individual to collaborative. Furthermore, to support both student autonomy and learning process, learning activities should align with students’ learning goals, be relevant to the real-world, and provide opportunities for application in professional practice. Likewise, learning materials are important: students expect accessible and comprehensive learning materials that are delivered in various formats so that they can integrate different information types, and search more information. Finally, providing flexibility to work in a self-paced manner within a given time frame is important for student learning because they would have more time to think and reflect on their learning.

Furthermore, instructor involvement in the course is important to facilitate and provide discourse direction. Students want responsibility for their learning besides instructors' scaffolding and guidance. Students expect their instructors to actively participate in not only the course but also their individual learning experiences. Accordingly, instructors can actively participate in the discussions where they check for understanding, answer student questions, confirm student understanding, and facilitate discussions to ensure students are on the task. Further, instructors can promote critical thinking and higher-order thinking skills by asking exploratory questions, sharing their own perspectives, providing prompting responses, giving detailed, timely, and constructive feedback, and being responsive to student questions. Finally, students also expect their peers to support their learning process and autonomy. Peer-related expectations include active participation, meaningful responses to peers' inquiries, participation in group work, and being responsive to other students’ inquiries.

3.3.3. Being real
Being real is an essential contributor to the sense of community in online classes, which is critical for student learning and satisfaction. The sense of community is supported by course design, in addition to instructors' and peers’ actions. This thematic synthesis showed that self-disclosure and using visual cues (e.g., video communication) were important to reduce sense of isolation, and help students get to know each other thereby encouraging social and content-related interaction. Example activities increasing interaction included ice-breaker activities that help students get to know each other, holding synchronous hours, and learning activities that encourage students for content-related interaction.

Instructor-related factors included being active and responsive, creating a positive climate to support interaction, using visual clues (e.g., video feedback, video announcement), being accessible and available to students, checking with students individually, and self-disclosure. Further, student-related factors were active participation, being responsive to other students’ inquiries, and self-disclosure. All these factors contribute to and encourage the analytical theme of being real in online learning in such a way that it promotes student outcomes.

3.4. Critical appraisal results and credibility of findings
The current results (Appendix B) showed that reporting quality varied greatly: qualitative research method information was missing in 20 studies and 23 reported no rationale for their chosen qualitative method. The latter was mainly observed in mixed-methods studies. The choice of data analysis method and the rationale for it were also missing in 13 studies. Moreover, 20 studies did not explicitly reveal any methods applied to enhance the quality of data sources. However, 27 studies reported what was applied to enhance the credibility, dependability, and trustworthiness. Finally, we found that the amount of information provided was varied across publication and study types. Unsurprisingly, we observed that dissertations provided more information than journal articles possibly due to the formatting and reporting requirements of journals.

As a result, we identified three studies as low quality since they missed some information that is essential for transparency and credibility in qualitative research. The results of a sensitivity analysis showed that removing those low quality studies from the synthesis did not change the overall themes thus establishing the credibility of the present findings.

4. Discussion
This study synthesized the qualitative study findings pertaining to the factors impacting students’ online learning experiences in relation to the CoI framework and revealed three analytical themes, accountability, supporting learning process and being real, that are essential for quality online education. The present synthesis also showed that course design, instructor actions, and student actions, which are crucial for the CoI presences, address these analytical themes. Specifically, aligning with previous research (e.g., Capra, 2014; Garrison, 2007; Garrison & Cleveland-Innes, 2005; Shea & Bidjerano, 2010), the current results showed that designing and developing meaningful online learning experiences is a shared responsibility of course designers (if different from instructors) during development, and of instructors and students during a course. That is, results revealed that deep and meaningful online learning occurs as a result of (a) online course structure; (b) guidance, modeling, and scaffolding by the instructor; and (c) collaborative work among active and supportive participants in learning communities.

From a teaching presence (TP) perspective, results highlighted especially the importance of course design and facilitation, which complies with earlier studies suggesting that they support social and cognitive interaction, help create a welcoming environment, and encourage students in collaborative activities (e.g., Akyol & Garrison, 2011; Garrison, 2007, 2009; Garrison & Cleveland-Innes, 2005; Shea, Li, Swan, & Pickett, 2005). Further, especially being real, which is at the core of social presence (SP), turned out to be an important analytical theme that is necessary to establish relationships, create the sense of community, and build a safe and welcoming environment where students share their perspectives and seek others’ perspectives. Similarly, Garrison (2007) claimed that SP is crucial “to create the conditions for inquiry and quality interaction (reflective and threaded discussions) in order to collaboratively achieve worthwhile educational goals” (p. 64).

The analytical theme supporting learning process is closely related to cognitive presence (CP) and results indicated that strong TP is critical to “move students through to resolution” through course design and facilitating discourse (Garrison, 2007, p. 66). Importantly, results also supported the distribution of TP between instructors and students (Garrison et al., 2000). For instance, course design and facilitation turned out to be their common responsibility especially during course delivery. Also, aligning with earlier quantitative syntheses (e.g., Richardson et al., 2017), results demonstrated that indicators of all three presences were essential thereby pointing to their validity. All these findings and implications also comply with the close interrelationships between TP, CP and SP (e.g., Kozan & Richardson, 2014), and the role of TP in coordinating SP and CP (e.g., Garrison & Akyol, 2013).

The results also showed that students value online learning experiences when they support student autonomy through individualization and personalization. This point suggests that learners favor controlling the pace of their learning or CP in an online learning experience where there are already sufficient TP and SP thus supporting a strong sense of community. In other words, even though online learners may want to be challenged by well-designed and facilitated online learning experiences, they also want to control them by processing at their own pace within a given time frame. Consequently, it is “important for students to monitor and regulate their learning in a community of inquiry” (Akyol & Garrison, 2011, p. 189). All these insights may add to the conceptualizations of TP, SP and CP in that the role and extent of learner autonomy or self-paced learning in online education become more salient.

Methodologically speaking, we both synthesized the primary study findings and reviewed the transparency of their reporting practice since insufficient information may make it difficult to check credibility and validity (Campbell et al., 2011; Hannes & Macaitis, 2012; Heyveart et al., 2017). To this end, the critical appraisal results showed that most studies reported essential information needed to evaluate reporting transparency (e.g., clear research purpose and/or questions, setting for data collection, data collection and analysis procedure). However, there was some missing information across studies. First, the type of qualitative research method used and the rationale for selecting a research design were missing, which made it harder to evaluate how researchers designed their study and how they “explored their research questions and aims” (Tong, Sainsbury, & Craig, 2007, p. 351). Second, although most studies provided detailed information about their data analysis process, a limited number explicitly stated their data analysis method and its corresponding rationale. This may not be very problematic though as “rigorous analysis is marked by transparency regarding the process of sorting, choosing, and organizing the data” (Tracy, 2010, p. 841). Finally, even though most studies applied methods to enhance credibility and dependability (e.g., inter-coder reliability, member check, thick descriptions), most did not report any methods to promote data collection quality.

Finally, the missing information above may make it more challenging to evaluate the reliability and validity of especially data collection, methodology and data analysis when they may not be inferred from the information provided. Consequently, whether they are inferable or not, presenting relevant information explicitly would make it more transparent and easier to handle for especially those readers who are not research literate, which also aligns with claims for transparency (e.g., Tong, Flemming, McInnes, Oliver, & Craig, 2012).

4.1. Limitations and suggestions for further research
The current results should be read carefully since the data are limited to the studies reported in English thereby potentially missing more diverse perspectives. The focus on student perspectives might also limit the insights gained to one perspective thereby asking for multiple similar data collections from different stakeholders including instructors. Consequently, future research might synthesize qualitative evidence regarding instructor's perceptions about how applying the CoI framework for course design and facilitation influences learning.

Further, we also need future studies to examine the degree to which the factors originating from this thematic synthesis would impact the relationship between TP, CP and SP and student online learning outcomes (e.g., satisfaction perceived learning). Finally, this study provided an accumulative understanding of how qualitative research contributes to our understanding of student online learning experiences from the perspective of the CoI framework, which can be enriched by future mixed-methods synthesis of the studies in which both qualitative and quantitative evidence are explored, to provide a more holistic view based on both qualitative and quantitative evidence.

5. Conclusions
The current thematic synthesis revealed 10 descriptive themes listed under overarching categories: course design, instructor actions and student actions. Next, the 10 descriptive themes were aggregated into three analytical themes: accountability, being real, and supporting learning process. These analytical themes strongly suggest that successful online education has a multidimensional nature and that designing, developing, and implementing meaningful online learning experiences is the responsibility of course designers, instructors, and students. Accordingly, taking all these stakeholders’ insights into account during different phases of online education, from course design to evaluation, would be reasonable. Interestingly, these findings also strongly suggested that these factors, which are important for student online learning experiences, are interpretable by the CoI framework thus providing awareness into its predictive power. Given that this synthesis is the first of its kind within the scope of the CoI framework in relation to student online learning experiences, similar future research focusing on the CoI framework and other theoretical perspectives would provide further conceptual and theoretical insights and expand our understanding of successful online learning.

Additionally, the results of this thematic synthesis produced collective evidence across the included studies about the factors influencing students' online learning experiences. This synthesis also informed us of what students value in their online learning experiences, why certain factors are important, and what may need to be adapted for more satisfying online learning experiences. Therefore, this thematic synthesis provided researchers, course designers, instructors, and students with (a) research-based evidence for the factors related to student expectations and needs; (b) tips for how to design online courses to provide a satisfying and effective learning experience; (c) tips for how to participate in online courses to be accountable for their learning as well as that of their peers; and (d) new conceptual insights into learners' level of involvement in an online learning community and its management. For instance, students can contribute to the success of an online learning experience through active participation, which can be used by instructors to evaluate each student's performance. Course designers and instructors can use these tips (e.g., clear structure, expectations and feedback, checking for understanding, collaboration, interaction) in course design and facilitation while researchers can use them to enhance theoretical or conceptual understandings and online learning interventions in their research. Overall, these insights would foster building inclusive, sustainable, and quality online education where students are welcomed, accepted, and respected by providing explicit implications for practice.

Regarding research, this study will hopefully take attention to reporting practices and improving research design and findings in qualitative research. After all, more rigorous research design and transparent reporting is needed, and there is no agreed standard for judging the quality of qualitative research, which may make it challenging for novice researchers to conduct methodologically sound qualitative research (Noble & Smith, 2015). To this end, in addition to being used for appraising qualitative studies, we hope that the critical appraisal checklist used in this synthesis guides researchers to plan and report more rigorous qualitative research studies. Finally, given that qualitative synthesis is an emerging method (Tong et al., 2012), and there is a limited number of qualitative syntheses on the CoI framework and online learning, this thematic synthesis would also serve future educational qualitative synthesis research that would address its limitations.
