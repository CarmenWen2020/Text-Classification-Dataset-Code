Against the backdrop of preparing students for a digitalized future, supporting pre-service teachers' development of technological pedagogical content knowledge (TPACK) has become paramount in pre-service teacher education. Whether and how pre-service teachers' acquisition of TPACK could be supported is still an open question, as previous research predominantly relied on correlational data and/or self-report assessments. Based on previous research, we developed subject-specific versions of a TPACK-module to support the acquisition of TPACK. Further purpose of the TPACK-module was to enhance technology-related motivation, as motivational orientations have been documented to be crucial for technology integration. We evaluated the effectiveness of the module by means of a quasi-experimental field study. Pre-service teachers (N = 208), enrolled in five subjects, attended regular semester courses on subject-matter pedagogies. In half of the courses, we randomly implemented subject-specific TPACK-modules (duration: three weeks), in which pre-service teachers were taught in using technology for subject-matter teaching, whereas the control condition attended the regular courses without the TPACK-module. We found that pre-service teachers in the courses with the TPACK-modules acquired more TPACK than those in the control courses without the TPACK-modules. Significant effects were also obtained for pre-service teachers' technology-related self-efficacy and their perceived support for technology integration. The effectiveness of the TPACK-modules could be explained by the obtained support for technology integration. The findings highlight the central need of adequate support for pre-service teachers’ development of technology-related professional knowledge and motivation in teacher education programs.

Previous
Next 
Keywords
Professional knowledge

Technology integration

TPACK

Teacher education

1. Introduction
Against the background of digitalization, integrating technology into teaching is paramount for teachers to prepare students for a digitalized future. As a consequence, teachers are required to integrate technology into their teaching to support students’ learning (Siddiq, Scherer, & Tondeur, 2016). Despite the potential of integrating technology for teaching, however, research has demonstrated that in many educational systems teachers rarely adopt technology into teaching (Fraillon, Ainley, Schulz, Friedman, & Duckworth, 2020).

Therefore, it is generally argued that pre-service teachers should acquire subject-specific professional knowledge regarding technology integration to be able to support their future students' learning. The professional knowledge related to a successful subject-specific integration of technology is commonly subsumed under the concept of technological pedagogical content knowledge (cf. TPACK, Mishra & Koehler, 2007). Likewise, pre-service teachers should develop adequate motivational orientations (e.g., self-efficacy, utility to adopt educational technology, teaching enthusiasm, see Backfisch, Lachner, Hische, Loose, & Scheiter, 2020; Kunter et al., 2013), as motivation is essential for persistence and performance. To date, only few empirical examples of interventions exist which tackle pre-service teachers' acquisition of TPACK and technology-related motivation by means of (quasi-)experimental research, which allow to draw conclusions regarding the effectiveness of such interventions (for scarce exceptions see Alayyar, Fisser, & Voogt, 2012; Kramarski & Michalsky, 2010; Rienties, Lewis, O'Dowd, Rets, & Rogaten, 2020). However, a large proportion of these quasi-experimental interventions often focused on professional knowledge for technology integration in a domain-general manner (i.e. TPK), and often ignored the subject-specific knowledge component of technology integration (i.e., TPACK), as identified by several systematic reviews (Tseng, Chai, Tan, & Park, 2020; Voogt, Fisser, Pareja Roblin, Tondeur, & van Braak, 2013). TPACK, however, is often regarded as essential to integrate technology into subject-specific teaching in a meaningful manner (Mishra & Koehler, 2007). Against the background of lacking available quasi-experimental evidence on subject-specific TPACK-interventions, we conducted a quasi-experimental study in which we compared effects of a TPACK-intervention to a control intervention, which did not contain the TPACK-intervention. The TPACK intervention followed general principles of teacher education (e.g., approximation of practice, see Grossman, Hammerness, & McDonald, 2009) and specific evidence-based guidelines for pre-service teacher education regarding technology integration (Synthesis of Qualitative Data (SQD) model, see Tondeur, Aesaert, Prestridge, & Consuegra, 2018; Tondeur et al., 2012). Moreover, the intervention was adapted to five subjects and, therefore, comprised domain-specific aspects of technology-integration into subject-specific teaching.

1.1. Pre-service teachers’ professional knowledge to integrate educational technology
TPACK is a ubiquitous conceptual framework to describe teachers' professional knowledge regarding technology integration (Mishra & Koehler, 2007). TPACK is based on general conceptualizations by Shulman (1986) who proposed three knowledge components for professional teaching (see also Baumert et al., 2010; Hill et al., 2008; Kunter et al., 2013): a) Content knowledge (CK) is regarded as teachers' subject-specific knowledge related to the content to be taught; b) pedagogical knowledge (PK) is operationalized as generic instructional knowledge to design effective learning environments (Voss, Kunter, & Baumert, 2011) and refers to domain-general instructional strategies that should support students' learning (Baumert et al., 2010; Voss et al., 2011); and c) pedagogical content knowledge (PCK) is the knowledge about content-specific teaching strategies and students' (mis-)conceptions, which helps teachers adapt content knowledge to students’ potential prerequisites and provide adequate representations (Baumert et al., 2010; Hill et al., 2008; Shulman, 1986).

In their TPACK framework, Mishra and Koehler (2007) added another knowledge component, technological knowledge (TK), which refers to teachers' professional knowledge regarding technologies, such as digital tools and infrastructure. Due to the addition of technological knowledge, three additional “t-intersections” have emerged (Scherer, Tondeur, & Siddiq, 2017), which are commonly associated with teachers' technology integration: Technological content knowledge (TCK) comprises knowledge about how to use technology in different content-specific areas; technological pedagogical knowledge (TPK) refers to teachers' generic knowledge of technology integration to support students’ learning and is not bound to specific contents (Koehler & Mishra, 2009; Scherer et al., 2017); and technological pedagogical content knowledge (TPACK) specifically refers to content-specific teaching strategies in the context of technology integration (Koehler & Mishra, 2009). For successful technology integration, Koehler and Mishra (2009) have emphasized the central role of TPK and TPACK. Whereas TPK should help teachers apply their knowledge about teaching with technology in a generic manner, TPACK should particularly enable teachers to integrate educational technology for content-specific teaching strategies (Koehler & Mishra, 2009).

However, to date only limited empirical evidence is available on the cognitive structure of TPACK, as previous studies predominantly relied on assessing professional knowledge by means of self-reports instead of using test-based instruments (e.g., Archambault & Barnett, 2010; Lin, Tsai, Chai, & Lee, 2013; Scherer et al., 2017; see Akyuz, 2018 for exceptions). Contrarily, self-reported knowledge may rather reflect teachers' confidence to integrate technology, and thus may constitute proxies of teachers' technology-related self-efficacy beliefs instead of objective measures of professional knowledge (Backfisch et al., 2020; Brantley-Dias & Ertmer, 2013; Cheng & Xie, 2018; Lachner, Backfisch, & Stürmer, 2019; Scherer et al., 2017; Willermark, 2018). Furthermore, although self-assessments have been shown to correlate with direct measures of TPACK to a limited extent (see Schmid, Brianza, & Petko, 2021), they may largely depend on the participant's skills to accurately assess his or her own knowledge (see Prinz, Golke, & Wittwer, 2020, for a general overview between self-assessments and test-based assessments). The development of test-based assessments for TPACK, however, is just at the beginning (see Drummond & Sweeney, 2017, for a scarce example of measuring TPACK using a test-based instrument) given that most previous studies have relied on self-reported knowledge (Koehler, Shin, & Mishra, 2012; Willermark, 2018).

1.2. Technology-related motivation
Besides the acquisition of TPACK, enhancing technology-related motivation is discussed to be critical for successful technology-integration, as adopting technologies requires teachers to deliberately change their teaching practices (see bib_Backfisch_et_al_2021aBackfisch, Lachner, Stürmer, & Scheiter, 2021; Hussain et al., 2018). The research landscape of technology-related motivation is rooted in different conceptual frameworks, such as technology-acceptance models (TAM, see Scherer, Siddiq, & Tondeur, 2019; Teo, 2011) or expectancy-value models (Backfisch et al., 2020; Eccles & Wigfield, 2002), which highlight the role of self-efficacy and perceived utility (cf. Usefulness, see bib_Backfisch_et_al_2021bBackfisch, Scherer, Siddiq, Lachner, & Scheiter, 2021, for an empirical comparison). For instance, Scherer et al. (2019) synthesized the findings from 114 survey studies which used TAM as a theoretical framework and examined the correlation between teacher motivation (i.e., perceived utility, technology-related self-efficacy) and their intention to use technologies and the self-reported frequency of using technologies for teaching. The authors found that self-efficacy and perceived utility predicted teachers’ intention to use technology and the frequency of technology-integration.

Relatedly, Backfisch et al. (2020) more closely investigated the quality of technology-integration, by applying a lesson-plan scenario. The authors required mathematics teachers (N = 94) differing in their teaching expertise (i.e., pre-service teachers, trainee teachers, and in-service teachers) to answer a test measuring their professional knowledge regarding the basic components of TPACK (i.e., CK, PCK, TK), and report their motivation to integrate technology (i.e., self-efficacy, utility value). Furthermore, the teachers generated a lesson plan to teach the Pythagorean theorem with educational technology. The authors found that teachers having higher levels of expertise (i.e., trainee teachers, in-service teachers) provided lesson plans in which technology was used to better enhance teaching quality, than the ones by novice teachers (i.e., pre-service teachers, 
 = 0.16). The quality of the lesson plans was mainly associated with teachers’ perceived utility (see also bib_Backfisch_et_al_2021aBackfisch, Lachner, et al., 2021, for a longitudinal replication), suggesting that teacher motivation played a distinct role in technology integration.

1.3. Approaches to support pre-service teachers’ development of TPACK and technology-related motivation
The previous findings highlight the central role of TPACK as well as technology-related motivation for technology integration and suggest that particularly pre-service teachers may require assistance during the course of teacher education. Research on teacher education has provided several design principles on how interventions should be designed to foster pre-service teachers' development of TPACK (Hofer & Grandgenett, 2012). Based on general intervention models of teacher education (e.g., Grossman et al., 2009; Korthagen, Loughran, & Russell, 2006), in their systematic review, Tondeur et al. (2012) developed a conceptual framework called the SQD (Synthesis of Qualitative Evidence) model which proposes six key features to foster pre-service teachers’ acquisition of TPACK. From a motivational perspective, these features are regarded as enhancing pre-service teacher motivation (Howard, Tondeur, Ma, & Yang, 2021), such as their self-efficacy or their enthusiasm to teach with technology (i.e., technology-related teaching enthusiasm, see also Kunter et al., 2013; Lauermann & König, 2016, for related discussions on general teaching enthusiasm).

In initial phases of skill acquisition, the use of role models (feature 1) should help pre-service teachers acquire initial TPACK by observing good-practice examples in which effective strategies of technology integration are modeled (Howard et al., 2021; Wekerle & Kollar, 2021). The use of such models should further reduce the initial demands of technology integration, as pre-service teachers can observe prototypical practices of technology integration and help them develop transferable and flexible knowledge structures (Wekerle & Kollar, 2021).

Furthermore, Tondeur et al. (2012) highlighted the role of guided practice, in which pre-service teachers learn how to use educational technology for their teaching. Ideally, such practices should be followed by the principle of approximation of practice (i.e., increasing practice experiences combined with decreasing instructional support, see Grossman et al., 2009) to provide pre-service teachers with learning opportunities that are proximal to their current level of professional development. Therefore, the enactment of design-based practices is highlighted (feature 2: instructional design), such as lesson planning (e.g., Backfisch et al., 2020; Kramarski & Michalsky, 2010), which should be continuously supplemented with more practice-oriented authentic experiences (feature 3). For instance, micro-teachings (Grossman et al., 2009) can help pre-service teachers practice parts of the teaching process in a live role-play, which allows them to capture and continuously repeat distinct teaching sequences in a decomposed setting. Collaboration is regarded as another key feature in the development of TPACK (feature 4), as pre-service teachers can discuss successful or less successful ways of integrating technology and build up a community of practice (Howard et al., 2021; Little, 2002).

Throughout these learning opportunities, pre-service teachers are required to critically reflect upon the role of educational technologies and their professional development (feature 5) to further engage in a process of continuous learning. The final key feature (feature 6) involves the use of formative feedback on students' design-based practices (Kleinknecht & Gröschner, 2016), which is regarded to be effective in supporting pre-service teachers’ TPACK.

Research on evaluating the design features of the SQD-model has gained considerable interest in the last decade. For instance, Tondeur et al. (2018) followed a survey design to examine relationships between the subjective availability of the SQD-features and professional skill development and found medium to large relations between pre-service teachers' perceptions of the availability of the SQD-key features and their self-reported TPACK (see Baran, Bilici, Sari, & Tondeur, 2019; Howard et al., 2021, for similar findings). In a follow-up mixed method study, Tondeur, Scherer, Siddiq, and Baran (2020) replicated the quantitative findings and conducted qualitative interviews with a select group of pre-service teachers. These interviews revealed that the availability of role models was subjectively important for students' skill development. However, it has to be noted that correlational surveys do not allow to draw conclusions about the role of the availability of such design features on pre-service teachers' TPACK, as correlation commonly does not imply causation. Against this background, Hsu and Lin (2020) implemented a four-week training module based on the SQD-features and measured self-reported TPACK-gains from pre-to posttest. Overall, they found gains of TPACK, as a first hint of the effectiveness of the intervention. Moreover, these gains were related to the perceived availability of the SQD-features (i.e., reflection). However, the absence of a control group and test-based measurements in this study makes it difficult to gauge whether these gains resulted due to the intervention or due to alternative explanations such as mere maturation. An exception regarding the experimental investigation of technology-related interventions with test-based instruments is the study by Kramarski and Michalsky (2010). Kramarski and Michalsky randomly assigned pre-service teachers to two versions of a semester course. The main aim of the courses was to foster domain-general technological pedagogical knowledge (TPK, see Lachner et al., 2019) in the specific context of hypermedia environments. In both courses, pre-service teachers received instruction on how to implement hypermedia environments to foster students’ learning processes and were engaged in collaborative design tasks to deepen their previously acquired TPK. However, in the intervention course, pre-service teachers received additional metacognitive support to critically reflect upon the learning content. The authors demonstrated that the pre-service teachers in the intervention course outperformed the pre-service teachers in the control course in their acquisition of TPK. The amount of reflection was substantially correlated with the acquisition of TPK. The findings by Kramarski and Michalsky (2010) provide important evidence on the role of reflection phases for the development of TPK. However, it must be noted that the experimental study only comprised the acquisition of TPK (in the context of hypermedia instruction) and only one specific type of support feature, namely reflection.

1.4. The present study: fostering pre-service teachers’ acquisition of TPACK and motivation
The primary goal of the present article was to investigate whether short three-week TPACK-modules, implemented and adapted in regular subject-specific university pre-service teacher education courses, can enhance pre-service teachers' acquisition of TPACK and technology-related motivation. The TPACK-modules were based on the SQD-model and general principles of teacher education (Grossman et al., 2009). Following a quasi-experimental approach, the TPACK-modules were compared to control courses which did not include the TPACK-modules. We collected pre-service teachers' technology-related professional knowledge by means of objective knowledge tests. In addition to test-based TPACK-assessments, we also assessed TPK (Lachner et al., 2019), as well as motivational variables (perceived utility, self-efficacy, teaching enthusiasm) to portray a broad picture of pre-service teachers’ skill development. Furthermore, we additionally collected assessments of perceived support regarding technology integration (Tondeur et al., 2018) as a potential explanatory variable for why the TPACK-modules were effective (see also Hsu & Lin, 2020). We tested the following hypotheses which were pre-registered on https://aspredicted.org/(see https://aspredicted.org/j8ii3.pdf):

1)
Pre-service teachers in the TPACK-intervention outperform pre-service teachers in the control condition in the knowledge tests (TPK, TPACK).

2)
Pre-service teachers in the TPACK-intervention show higher levels of technology-related motivation (self-efficacy, utility-value, teaching enthusiasm) than pre-service teachers in the control condition.

3)
Pre-service teachers in the TPACK-intervention report higher levels of subjective support than pre-service teachers in the control courses.

Additionally, as an exploratory analysis, we examined whether the effectiveness of the TPACK-module could be explained by the perceived subjective support during the intervention by means of multilevel mediation analysis.

2. Method
2.1. Study site and participants
The quasi-experimental study was implemented in the pre-service teacher education program of a southwestern German university (27,000 students, 4000 pre-service teachers) with a special emphasis on secondary education. In the teacher education program (consecutive Bachelor/Master program), pre-service teachers choose two subjects (in total 25 subjects) and attend content-specific courses (CK, PCK), as well as pedagogy courses (PK). The study was embedded in the Bachelor program with a strong focus on content knowledge and pedagogical content knowledge. For the study, five subject-matter pedagogy experts agreed to participate in the study (biology, mathematics, teaching English as a foreign language, German, philosophy). For each subject, we aimed to recruit two parallel courses (same topic and teacher) per semester term, ideally resulting in 20 courses (5 subjects by 2 cohorts by 2 courses); one of the courses served as the experimental condition and the other as a control condition (see Fig. 1 for an overview).

Fig. 1
Download : Download high-res image (319KB)
Download : Download full-size image
Fig. 1. Design of the current study. The design of the study had a nested data structure, as students were nested within the TPACK-intervention versus the control condition within five different subjects (EFL, biology, math, philosophy, and German) across two student cohorts (winter-term, summer-term).

To ensure test power, we computed an a-priori power simulation study. This simulation study would allow to empirically investigate whether the intended sample size and number of courses would be sufficient to detect an effect of our intervention. We could not base our effect size estimates on prior research, as the previous studies were either correlational, based on self-report data, or constituted generic TPK-interventions. Therefore, we followed the rule of thumb definition by Hattie (1992) and opted for detecting medium effect sizes at least (d = 0.50). We tested for a multilevel-model (see Fig. 1), in which pre-service teachers (n = 12) were nested within subjects (k = 5) and cohorts (j = 2) and ran 1000 simulations. Based on an alpha-level of α = .05, we would achieve excellent test power of 1-β = 93% to find an effect of the experimental condition with the estimated number of courses and students. However, the actual sample size of pre-service teachers was N = 208 which fell below the intended level. We were not able to recruit a control course in biology due to restricted availability of courses during the COVID-19-pandemic. Therefore, we re-ran a power simulation, a-priori to the data analysis. To account for potential differences among cohorts due to the pandemic, we decided to control for the cohort as a further randomized factor in the model. Power was still excellent, 1-β = 91% and above the conventional level of 80%.

The recruited pre-service teachers were on average 22.67 (SD = 2.55) years old and in the end of their Bachelor program, in their 6th semester (SD = 2.44). The number of participating pre-service teachers slightly varied across the five subjects (29 < n < 53).

2.2. Design
The study was realized as a quasi-experimental field study in which courses were randomly assigned to experimental conditions: Regular course + TPACK-module (N = 88 pre-service teachers) versus a regular-course only, as a business-as-usual control condition (N = 120 pre-service teachers). As we had a nested data structure (pre-service teachers nested within subjects nested within cohorts), we applied a three-level random coefficient model to take the multi-level structure into account. As dependent variables, we used pre-service teachers' technology-related motivation (i.e., self-efficacy, perceived utility, enthusiasm to teach with technology) and pre-service teachers’ test performance (TPK, TPACK). Further dependent variables encompassed the perceived subjective support for technology integration during our intervention. We controlled for cohort and subject by modeling random factors.

2.2.1. Design of the TPACK-module
The TPACK-module was based on the SQD-model (Tondeur et al., 2012), as well as general principles of teacher education (Grossman et al., 2009) and was implemented in regular courses in five subject-matter pedagogies (biology, mathematics, teaching English as a foreign language, German, philosophy). The module was held by trained certified subject-matter experts, which also developed the TPACK-modules. The module lasted three weeks. The structure (but not the subject-specific content) of the module was identical across subjects. The materials of the TPACK-modules were implemented as Open Educational Resources and can be seen https://vitruv.uni-tuebingen.de/ilias3/goto.php?target=cat_6596.

Overall, the TPACK-module considered reflection, collaboration and feedback as recurring design features of the SQD-model during the entire module. The three single sessions emphasized different SQD-features (i.e., role models, design practices, authentic experiences) with increasing approximation of practice.

In session 1, the pre-service teachers were introduced to subject-specific principles of technology integration via an online learning module (see Fig. 2). In that module, they received direct instruction on how technology can be integrated to improve teaching quality. For each subject, we focused on subject-specific methods of technology integration and provided the pre-service teachers with two content-specific videos which modeled good-practice examples of technology integration in the particular discipline (e.g., the use of virtual experiments to foster students’ scientific reasoning in biology, see Fig. 3 for further examples). In those videos, two experts provided conceptual information on the distinct potential of the portrayed technologies from the perspectives of subject-matter pedagogies and educational technology. To increase student reflection, we asked the students to self-explain the instructed concepts. Overall, session 1 aimed at providing role models for students (Tondeur et al., 2012).

Fig. 2
Download : Download high-res image (1MB)
Download : Download full-size image
Fig. 2. Translated example page of the online module as preparation for the first face-to-face session.

Fig. 3
Download : Download high-res image (1MB)
Download : Download full-size image
Fig. 3. Translated good-practice example in the online module.

In session 2, pre-service teachers enacted a collaborative design task in small groups. In this design task, they developed a subject-specific lesson plan in which they adopted educational technology (see also Harris, Grandgenett, & Hofer, 2010, pp. 3833–3840). To enhance pre-service teachers' reflection during lesson planning, we used the scheme by Backfisch et al. (2020) which contained a specific set of prompts. To further support pre-service teachers’ planning and reflection activities, they received formative feedback from the course instructors. Subsequently, the pre-service teachers revised their lesson plans accordingly. Session 2, therefore, mainly emphasized the role of design-based practices (Tondeur et al., 2012).

In session three, the resulting teaching sequences were held collaboratively in micro-teachings. As such, the pre-service teachers were engaged in authentic teaching experiences. Furthermore, the micro-teachings were video-taped. As a final homework assignment, pre-service teachers provided peer-feedback on one randomly chosen micro-teaching session to further engage their reflection. For that purpose, the pre-service teachers had at hand an annotation tool within the online learning environment which allowed to provide specific comments and feedback on distinct sequences of the assigned micro-teaching (see Fig. 4 for an example). To scaffold the peer-feedback process, the pre-service teachers additionally had at hand a set of prompts. These prompts were validated in a previous pilot study. For cohort 2, the procedure was identical except for the fact that the micro-teachings were held online due to the COVID-19 pandemic. Across the two cohorts, all the pre-service teachers were engaged in the same learning and teaching activities.

Fig. 4
Download : Download high-res image (948KB)
Download : Download full-size image
Fig. 4. Translated screenshot of the peer-feedback environment.

In contrast to the students in the TPACK-modules, students in the control conditions received further instruction from the subject-pedagogy experts (i.e., PCK). The control instructors confirmed that they had realized the courses as they usually would. As indicated by post-hoc analyses of the study curricula and reports by the corresponding instructors, teaching TPACK was not the explicit goal of the courses, although, it could naturally occur during regular teaching. However, as expected, explicitly teaching TPACK occurred very rarely. Only one subject explicitly dealt with a subject-specific technology (i.e., Geogebra). The main focus of this presentation was on the technical functions but not on pedagogical functions of Geogebra. Additionally, the duration of the presentations was very short (<10 min) and therefore negligible. As such, we can conclude that TPACK was rarely taught in the control courses. At the same time, the control courses were also comprised of a high degree of student-centered teaching methods particularly in the last third of the courses (e.g., collaborative design-based practices, reflection) in which the TPACK-modules were implemented in the experimental condition. For instance, students also accomplished lesson planning activities or designed learning materials, however, without the explicit intention to integrate technology. In summary, we implemented our intervention in subject-pedagogy courses and compared them to a business-as-usual-condition across five subjects, which helps to test whether the TPACK-module was more effective than current educational practice to prepare students for their future technology integration.

2.3. Measures
2.3.1. Motivational pre- and post-assessments
We measured technology-related self-efficacy, perceived utility value, and enthusiasm to teach with technology at pre- and posttest.

2.3.1.1. Technology-related self-efficacy
To assess teachers' technology-related self-efficacy beliefs, we used an adapted questionnaire by Schmidt et al. (2009) comprising five items which were translated into German by Backfisch et al. (2020). Pre-service teachers had to estimate whether they would be able to adopt various educational technologies to advance student learning in their specific subject (e.g., “I can use educational technology to increase the learning success of students”; “I can use educational technology to optimize the methods in my lesson.“; pre: Cronbach's α = .72; post: Cronbach's α = .66). We used a four-point Likert scale ranging from 1 (strongly disagree) to 4 (strongly agree).

2.3.1.2. Technology-related utility-value
To measure pre-service teachers' perceived utility-value regarding educational technologies, we used a scale by Backfisch et al. (2020, originally developed by van Braak, Tondeur, & Valcke, 2004) comprising four items (e.g., “I believe that a progressive introduction of technology into education responds to our society's changing needs”; “I highly value the introduction of technology in the classroom.“, pre: Cronbach's α = .76; post: Cronbach's α = .76). The items were answered on a four-point Likert scale ranging from 1 (strongly disagree) to 4 (strongly agree).

2.3.1.3. Technology-related teaching enthusiasm
We assessed pre-service teachers' prospective teaching enthusiasm with technology, as teaching enthusiasm has been demonstrated to be a strong predictor for teaching quality (see Kunter et al., 2013). Therefore, we used the scale by Bleschke, Ehmke, and Senkbeil (2001), comprising five items (e.g., “I will use educational technology in my future teaching”; “In my future teaching, I will search for possibilities to effectively integrate technology”, pre: Cronbach's α = .79; post: Cronbach's α = .78). Again, the questions were answered on a four-point Likert scale ranging from 1 (strongly disagree) to 4 (strongly agree).

2.3.2. Knowledge assessments
2.3.2.1. Technology-related prior knowledge
We measured pre-service teachers' prior knowledge about concepts and principles related to the domain of educational technology. We administered the conceptual TPK-scale by Lachner et al. (2019) comprising different potentials of educational technology (eight items). We particularly decided to assess TPK as the availability of TPK is often considered to be a crucial prerequisite for acquiring TPACK (Lachner et al., 2019; Mishra & Koehler, 2007). Furthermore, we wanted to avoid redundancies between pre- and posttest assessments and not administer the identical questionnaire, as part of the intervention effects could have been attributed to re-testing (see Rowland, 2014, for general meta-analytic findings of the testing effect). For each correct solution per item stem, the participants received one point resulting in a maximum score of 32 points (Cronbach's α = .64).

2.3.2.2. TPK-posttest
To measure pre-service teachers' acquisition of generic technological pedagogical knowledge, we used the situational TPK-test by Lachner et al. (2019). The TPK-posttest contained text-based vignettes which required the pre-service teachers to judge the general appropriateness of educational technology across subjects (e.g., “students create a wiki”) for distinct teaching situations (e.g., “for prior knowledge activation”). Consequently, the pre-service teachers had to apply their technological knowledge (e.g., knowledge about the functions of wikis) to distinct teaching situations (e.g., activating prior knowledge). The TPK-posttest comprised 12 items (Cronbach's α = .69); 1 point could be achieved per correct answer, resulting in a maximum score of 96 points.

2.3.2.3. TPACK-posttest
To measure pre-service teachers' subject-specific knowledge about technology integration (TPACK), we developed subject-specific TPACK-tests, which were based on classical test theory (see 10.17605/OSF.IO/3EN2H for the entire test documentation). To heighten the construct validity of our instruments, the TPACK tests were constructed by an interdisciplinary research team consisting of experts in the participating subject-pedagogies, educational technology, and methodology. To receive a comprehensive set of items, which represented a broad spectrum of the particular subject, we selected representative problems on the basis of the current federal curriculum for secondary education of the particular subject. Additionally, during the design of the test items, we followed a comparative approach and continuously inspected the comparability of the test versions across subjects. Based on Krauss et al. (2008), in each item, the pre-service teachers were provided with a short text-based vignette in which a subject-specific teaching problem was stated (e.g., mathematics: “Correctly multiplying fractions causes little difficulty for most students. At the same time, however, they find it difficult to understand that multiplying two rational numbers can result in a smaller number in terms of absolute value. How could you use educational technologies as a teacher to prevent these misconceptions? Give reasons for your answer, please.“; EFL: “The students in class 7a have troubles understanding when to use the simple past and when to use the present perfect. How could you use educational technologies as a teacher in the classroom to help the students overcome their difficulties? Give reasons for your answer, please.“, see anonymized link for the entire test items). Additionally, the participants had to provide an answer whether and how educational technology could help to solve the subject specific teaching problem and to justify their answer. As such, the pre-service teachers would need to apply their pedagogical content knowledge (PCK) and relate it to their technological knowledge (TK) to successfully solve the items. Each test had eight open-ended items. For each item, pre-service teachers could receive three points, resulting in an overall score of 24 points (see Appendix A, for the scoring rubric and examples). Twenty percent of the answers were rated by two subject-matter pedagogy experts. Inter-rater-reliability was good for each test version (ICC > .92). Additionally, internal consistency was good (range of Cronbach's α: .72 - .77, except for one TEFL: α = .54, however, see Stadler, Sailer, & Fischer, 2021, for a critical discussion for using Cronbach's α for knowledge assessments).

2.3.3. Perceived support during the courses for technology integration (SQD)
To assess the perceived support for technology integration, we used the SQD-questionnaire by Tondeur et al. (2018). The questionnaire consisted of 22 items (e.g., “In the course, I saw good examples of ICT practice that inspired me to use ICT applications in the classroom myself.“; “During the course, I received a great deal of help developing ICT-rich lessons.“) The items were answered on a four-point Likert scale ranging from 1 (strongly disagree) to 4 (strongly agree). The internal consistency of the questionnaire was excellent, Cronbach's α = .97.

2.4. Procedure
Before the module started, we obtained approval by our local ethics committee. The courses were randomly assigned to the TPACK-module or the control condition. At the beginning of the semester, the pre-service teachers provided written consent to participate in the study. Afterwards, they provided their demographic data and answered the pretest comprising the three motivation scales and the prior knowledge test. After a period of regular teaching in the subject pedagogies, the TPACK-modules were implemented in the last third of the semester. The pre-service teachers in the experimental condition participated in the TPACK-modules. The control condition continued with their regular course instruction without the TPACK-module (business-as-usual condition). The courses were held by certified subject-pedagogy teacher educators. All the teacher educators had ample experience in the context of teacher education and held a teaching certificate for the taught subjects. Particularly, the teacher educators in the TPACK-intervention were explicitly trained to teach the particular modules to ensure implementation fidelity (see also 2.5). To prevent experimental-leakage across courses, the teacher educators either taught in the control condition or the intervention. At the end of the intervention, the pre-service teachers answered the posttest comprising the three motivation scales, the TPK-posttest, and the TPACK-posttest. The entire study was self-paced and implemented in SoSci-survey.

2.5. Implementation fidelity
To ensure that our TPACK- modules were delivered as intended, we implemented the following safeguards (see Carroll et al., 2007, for an overview). To ensure the adherence of our intervention, we implemented a teaching script for all instructors to keep the courses as comparable as possible. The three instructors had regular exchanges to ensure the comparability across courses. For this purpose, at the end of each session, the instructors were asked to answer a self-report questionnaire in which they assessed whether they realized the particular teaching activities per session. Across the interventions, all the instructors reported to have realized each of the intended learning activities in the TPACK intervention. Regarding pre-service teachers’ exposure to the treatment, the structure of the treatment courses as well as the amount of assignments and activities were kept constant across treatment courses. Overall, 86% of the participating pre-service teachers attended all the sessions of the TPACK-intervention (cf., coverage, see Carroll et al., 2007). The control courses did not include technology-related content (see also 2.2.1 for more details). Until the beginning of the TPACK-intervention, instruction was comparable across conditions, suggesting that both conditions were exposed to a comparable amount of basic pedagogical-content knowledge. Also, the type of instructional methods between the TPACK-intervention and the business-as-usual condition was comparable during the TPACK-intervention. Students in the business-as-usual condition were also engaged in student-centered activities to deepen their knowledge, such as lesson planning or designing instructional material, however, without the requirement to use educational technologies (see 2.2.1, for more details). These findings indicate that implementation fidelity was high, and potential findings may be attributed to content-specific differences between the TPACK-intervention and the control condition.

2.6. Statistical analysis
As our data were nested within subjects and cohorts, we decided to use multilevel regressions to account for the multi-level structure data structure during our analyses (Hox, 2010). Such approaches have frequently been applied in aggregating research data (e.g., in studies across subjects or in individual-participant metanalytic approaches) as they provide more exact likelihood specification that avoid the assumptions of within-cluster normality and within-study variances (Burke, Ensor, & Riley, 2017). We used the lme4-package in R and applied a varying-slope model to account for the nested structure of our data (Hox, 2010). The models considered pre-service teachers to be nested within subjects and cohorts, where ‘pre-service teachers’ represented Level 1, ‘subjects’ represented Level 2, and ‘cohorts’ represented Level 3. The condition was included as a fixed dummy-coded effect. Subjects and cohorts were included as random effects. We decided to include the maximal pre-registered multi-level structure instead of following a step-wise integration approach as previous Monte Carlo simulation studies demonstrated that models generalize work best when they consider the maximal random effects structure (Barr, Levy, Scheepers, & Tily, 2013). The dependent variables included pre-service teachers' performance on the knowledge tests (i.e., TPK, TPACK) and their motivation (i.e., self-efficacy, utility-value, teaching enthusiasm). Additionally, we controlled for prior technology-related knowledge and their motivation at the pretest. As prerequisites (i.e., prior knowledge, motivation at pre-test) could vary across pre-service teachers, we allowed the slope of the prerequisites to vary by pre-service teacher per analysis which resulted in the following equation: outcome variable = condition + prerequisite + (1+ prerequisite | cohort/subject).

Additionally, as the intervention was realized in the context of regular teacher education courses, some participants missed the posttest which resulted in missing data. Following recent research, we used multiple imputation (m = 1000) and imputed missing values simultaneously (Grund, Lüdtke, & Robitzsch, 2016) by applying the R-package pan which considers multi-level structures during imputation. Given that multiple imputation is a probabilistic method, the estimators could slightly vary. We, therefore, repeated the multiple imputation, and reported the most conservative estimation.

3. Results
3.1. Preliminary analyses
A series of multi-level regressions and χ2 tests revealed no significant differences between the experimental conditions concerning age, β = −0.11, p = .439; gender, χ2 (2) = 3.12, p = .210, and prior knowledge, β = −0.07, p = .609. Similarly, pre-service teachers’ technology-related motivation at the pretest did not significantly differ among conditions, for self-efficacy, β = −0.15, p = .287, utility-value: β = 0.10, p = .458, and teaching enthusiasm: β = −0.06, p = .687 (see Table 1, for the descriptive statistics).


Table 1. Means and standard deviations (in parentheses) for the dependent measures.

Control condition	TPACK-Intervention
Knowledge assessments
 Prior knowledge	4.92 (2.45)	4.62 (2.74)
 TPK	16.95 (5.00)	15.42 (5.02)
 TPACK	8.60 (3.92)	10.21 (3.35)
Motivational assessments
 Self-efficacy pretest	2.47 (0.51)	2.40 (0.51)
 Self-efficacy posttest	2.43 (0.46)	2.82 (0.48)
 Utility-value pretest	3.25 (0.55)	3.30 (0.49)
 Utility-value posttest	3.37 (0.45)	3.28 (0.55)
 Teaching enthusiasm pretest	3.23 (0.49)	3.21 (0.46)
 Teaching enthusiasm posttest	3.31 (0.47)	3.39 (0.42)
 Subjective support	1.92 (0.67)	2.93 (0.45)
Note. The descriptives are based on the raw scores of the dependent measures.

3.2. RQ1: analyses regarding professional knowledge
A summary of the entire test statistics can be found in Appendix B. The descriptive statistics can be found in Table 1. Regarding pre-service teachers’ technological pedagogical knowledge (TPK), the effect of the condition was not significant, β = −0.22, p = .172. As such, our hypothesis that the TPACK- modules would outperform the control condition in the TPK-test was not confirmed.

Regarding pre-service teachers’ technological pedagogical content knowledge (TPACK), in line with our hypothesis, we found that the TPACK- modules outperformed the control condition, β = 0.44, p = .002. The effect of the TPACK- modules was of medium size, as the acquired TPACK in the intervention was 0.44 standard deviations higher than in the control condition.

3.3. RQ2: analyses regarding technology-related motivation
Regarding pre-service teachers' technology-related self-efficacy, again, we obtained a significant effect of the TPACK-modules, β = 0.80, p < .001. This finding indicates that after the TPACK-modules, pre-service teachers possessed higher levels of technology-related self-efficacy (0.80 standard deviations) than the pre-service teachers in the control condition. The effect of the TPACK-modules, however, was not significant for the perceived utility, β = −0.17, p = .268 and also not significant for technology-related teaching enthusiasm, β = 0.21, p = .167. As such, our motivation hypotheses were partially confirmed, as the TPACK-modules only contributed to pre-service teachers’ self-efficacy but not to the perceived utility nor teaching enthusiasm.

3.4. RQ3: analyses regarding the perceived subjective support
Regarding the perceived subjective support during the intervention, again, we obtained a significant effect of the condition, β = 1.38, p < .001. This finding suggests that when pre-service teachers were participating in the intervention condition, they perceived the obtained support regarding technology integration to be 1.38 standard deviations higher than in the control condition.

3.5. Exploratory mediation analyses
As students in the TPACK-module showed greater TPACK, technology-related self-efficacy, and perceived support, we explored whether the differences in TPACK and technology-related self-efficacy could be explained via the perceived support for technology-integration during the TPACK-modules. We conducted two multi-level mediation analyses separately for TPACK and technology-related self-efficacy via the mediation package implemented in R. The condition was the predictor and perceived support the mediation variable. TPACK and technology-related self-efficacy were the dependent variables. We used 1000 simulations to derive a 95%-bias-corrected confidence interval for the indirect effects. Our findings did not support the idea that perceived support was a mediator for technology-related self-efficacy, as the indirect effect was not significant, a × b = 0.00, p > .999. However, we obtained a significant unstandardized indirect effect for TPACK, a × b = 1.81, p < .001, suggesting that part of the effect of the intervention on TPACK could be explained by pre-service teachers’ perceived support for technology-integration.

4. Discussion
The aim of the current study was to examine the effects of an evidence-based intervention (i.e., TPACK-modules) to foster pre-service teachers' technology-related professional knowledge and technology-related motivation. In line with our hypotheses regarding pre-service teachers' professional knowledge, we found that the intervention condition outperformed the control condition regarding their acquisition of subject-specific technological pedagogical content knowledge (i.e., TPACK) but not regarding generic technological pedagogical knowledge (i.e., TPK). As our intervention was specifically designed as a subject-specific intervention, a possible explanation could be that it was difficult for pre-service teachers to generalize their subject-specific knowledge to generic teaching situations, which is a typical problem in instructional research (see Barnett & Ceci, 2002; Goldwater & Schalk, 2016). Regarding pre-service teachers’ motivation, we obtained a significant effect of our intervention on self-efficacy as the intervention condition demonstrated higher levels of self-efficacy than the control condition. However, contrary to our hypotheses, we did not obtain significant effects of the intervention on the perceived utility-value and technology-related teaching enthusiasm. This finding likely resulted as our pre-service teachers already reported high levels of utility of technology and teaching enthusiasm at the beginning of the intervention suggesting that the non-significant findings may be attributed to ceiling effects in the experimental conditions. Given that motivation is a multifaceted construct, comprised of potential interactions among different constructs, it would be a potential path for future research to map a broader picture about the development of teacher motivation by including different approaches (Ryan & Deci, 2003) or testing a broader set of variables, as proposed by broader models, such as TAM-models (Teo, 2011). As indicated by our mediation analysis, a potential explanation for why our intervention was effective is that pre-service teachers perceived higher levels of subjective support to integrate technology, which contributed to their professional knowledge acquisition. Since we deliberately implemented our TPACK module based on recent principles derived from teacher education (Grossman et al., 2009; Tondeur et al., 2012), students received higher levels of support which contributed to their professional knowledge acquisition.

What are the theoretical insights of our intervention? As a first contribution, we claim that our intervention is one of the first empirical attempts which explicitly tested the potential of evidence-based and theoretically grounded interventions in a subject-specific and quasi-experimental manner in real-world contexts. The scarcity of such interventions is surprising as Mishra and Koehler (2007) already highlighted the role of fostering TPACK for future technology integration. We strictly designed our intervention based on general principles of teacher education (Grossman et al., 2009) and specific guidelines for supporting technology integration (Tondeur et al., 2018). As we realized a quasi-experimental field study and randomly assigned individual courses to our experimental conditions, we can make distinct conclusions about the role of the availability of such implementation features on the acquisition of TPACK and self-efficacy. Although our mediation analyses supported this claim, that it was the perceived support which explained the effectiveness of the TPACK-module (at least for the acquisition of TPACK), it is an open question, however, how much of which feature of the module accounted for pre-service teachers’ TPACK. Therefore, more granular studies are needed which experimentally investigate the single benefits of the instructional constituents regarding TPACK.

A further strength of our study was that we designed and applied test-based instruments to assess pre-service teachers’ TPACK, given that most previous research relied on self-reports (e.g., Tondeur et al., 2018) or generic instruments which roughly ignored the subject-specific character of TPACK (Kramarski & Michalsky, 2010; Lachner et al., 2019). Our test-based instruments were constructed by an interdisciplinary team to heighten constructive validity. Furthermore, the findings demonstrated satisfactory reliability. Put differently, we also obtained significant overall effects of our intervention by means of our instrument, indicating the prognostic validity of our test-based instruments. However, more research is needed to further explore the adequacy of our TPACK-tests as diagnostic instruments.

As a practical implication, the intervention can be used to further develop subject-specific interventions. Against this background, all the materials can be downloaded as Open Educational Resources (see anonymized link) which may facilitate the adoption of our intervention in teacher education programs. As such, we hope that our interventions can serve as a fruitful starting point for the further development of subject-specific interventions.

Besides the potential of our findings, there are also some limitations. In our study, we realized a classical effectiveness study (e.g., Herbein et al., 2018) and analyzed pre-service teachers’ cognitive and motivational outcomes. Such studies on the one hand allow to test the applicability and effectiveness in an authentic and ecologically valid setting. However, such settings do not allow to examine fine-grained analyses about the potential underlying learning processes. Therefore, more research is needed to investigate the learning processes during such an intervention. We also did not examine delayed knowledge tests, which would allow to test for long-term effects of our intervention.

Another issue regards the decision to implement the TPACK-modules in five different subjects comprising different approaches to integrate technology and different subject-matter pedagogies. To ensure comparability among subjects, we aimed to implement the same structure across subjects. Additionally, the instructors in the TPACK-modules regularly interacted with each other to ensure that the modules were as comparable as possible. This approach was also reflected in the data-analysis approach, as we included subjects and cohorts as random factors to determine whether such an intervention has an overall effect across different subjects. Therefore, we rather see this potential limitation as a type of robustness check of the intervention. Nevertheless, a replication with likely a larger number of participants and ideally realized as a true experimental study would be desirable to draw legitimate causal judgments regarding the effectiveness of the TPACK-modules. Furthermore, some emphasis on further improving our applied test instruments, particularly the TPK-tests and the self-efficacy ratings would help provide more reliable estimates of our outcomes.

Finally, another limitation of the study regards the potential confounding difference in cohort 2 due to the switch from face-to face to online teaching as compared to cohort 1. Students in the control condition were also exposed to online teaching and could have acquired technological knowledge regarding potential technologies in addition to pedagogical content knowledge. These circumstances could have somewhat lowered the effectiveness of our intervention. However, we want to note that we considered this potential effect in our analyses as we included the cohort as a control variable in our analyses.

Our study provides important evidence regarding the effective design of instructional interventions to foster pre-service teachers’ TPACK and self-efficacy. TPACK and self-efficacy can be regarded as important prerequisites for pre-service teachers to successfully integrate technology during their subject specific teaching. As such, our findings may help improve the quality of technology-enhanced teaching.

