We examined the use and effectiveness of an incentive system—one of the five elements of a theory-based motivational architecture in educational games that we proposed—in a computer-based physics game on students' learning and performance. The incentive system's purpose was to motivate students to access learning supports designed to facilitate content knowledge acquisition (i.e., content-related supports) and minimize the use of solution videos (i.e., game-related supports). Students (n = 199) could earn game money by accessing content-related supports but had to pay to watch solution videos. Results indicated that the incentive system effectively increased how often students viewed content-related supports and decreased their reliance on solution videos. Furthermore, students who viewed more content-related supports showed higher posttest scores and solved more game levels compared to those who watched fewer supports, controlling for pretest scores. Solution videos, however, appeared to have no effect on either posttest scores or number of levels solved. Finally, our analysis of students' behavioral data, extracted from log files, confirmed that students did not abuse solution videos. We conclude by proposing areas of interest for future research.

Previous
Next 
Keywords
Game-based learning

Motivation

Incentives

Learning supports

Educational games

1. Introduction
The popularity of video games among children and adults is undeniable. For instance, 75% of Americans have at least one gamer in their household (Entertainment Software Association, 2019). Therefore, the growing video game industry has much potential for innovative researchers who want to use games as vehicles for learning (Gee, 2005; Prensky, 2001). However, not all video games are useful for learning—generally just well-designed ones (Shute & Ke, 2012).

Well-designed video games are intrinsically motivating to children (and adults). Players can make mistakes and learn from them without being afraid of negative consequences (Gee, 2005; Shute & Ke, 2012). Such games can be useful learning tools because they provide ongoing feedback and interactivity, and require active participation (Gee, 2003; Ifenthaler, Eseryel, & Ge, 2012; Prensky, 2001). Moreover, the challenges in well-designed video games are incremental, which helps students build the required skills as they progress through the games (Gee, 2005). Progression in these games often leads to the improvement of players’ skills, which in turn keeps players motivated and facilitates the state of flow (Csikszentmihalyi, 1988). When one is experiencing flow, he or she loses track of time, becomes fully immersed in the task environment, and performs at his or her best while enjoying the experience.

Game-based learning (GBL) research has shown that educational games foster learning by including relevant learning supports and appropriate learning principles (e.g., Wouters & van Oostendorp, 2013). For example, educational games have been used to teach content such as mathematics (e.g., Ke, 2008), physics (Shute et al., 2020), and ecosystems (e.g., Metcalf et al., 2011), and have been shown to assess and improve students’ non-cognitive skills such as creativity (e.g., Blanco-Herrera, Gentile, & Rokkum, 2019; Shute & Rahimi, 2020), and persistence (e.g., Ventura & Shute, 2013). These and other research studies have shown positive results, but more research is needed in this area.

For instance, in recent years, researchers and game designers have faced the challenge of developing educational games that maximize learning while maintaining engagement in educational games (e.g., Hamari et al., 2016; Shute, Ke, et al., 2019)). In a systematic review on the effects of digital games, Boyle et al. (2016) found that educational games mainly influence participants' knowledge acquisition, but further research in this area should investigate which game features are most effective in enhancing engagement and supporting learning (Boyle et al., 2016). This study focuses on one important game feature—the incentive system—which is often included in commercial games, but just occasionally in educational games. In particular, we examine the effects of an incentive system on regulating players’ use of learning supports to enhance performance and learning in an educational game.

One effective method used to maximize learning and performance in educational games involves embedding learning supports in games (Shute, Ke, et al., 2019; Shute & Ke, 2012; Wouters & van Oostendorp, 2013). The effectiveness of learning supports in educational games depends on factors such as level of guidance (e.g., indirect vs. direct), type of support (e.g., specific feedback vs. general advice), purpose (e.g., to support game performance vs. content knowledge), and time of delivery (i.e., before vs. after gameplay) (Schrader & Bastiaens, 2012a; Tsai, Kinzer, Hung, Chen, & Hsu, 2013; Wouters & van Oostendorp, 2013). The effectiveness of learning supports in promoting learning and performance, however, can vary from low to high. This depends on various factors such as where, when, and how the supports are being used in educational games (Leemkuil & De Hoog, 2005).

For example, students who have access to direct guidance (e.g., expert video solutions for a particular game level) during gameplay might simply rely on the examples to solve game levels without engaging in learning (Kao, Chiang, & Sun, 2017; Sun, Chen, & Chu, 2018). Based on these findings, one could argue that it is better to exclude direct guidance from educational games. However, students may need help via direct guidance when they are stuck and growing increasingly frustrated (e.g., ter Vrugte et al., 2017). Moreover, while some frustration can help learning (e.g., Gee, 2007), sustained or intense frustration can lead to quitting behavior (Kapoor, Burleson, & Picard, 2007; Spann, Shute, Rahimi, & D’Mello, 2019). Thus, it is important to regulate students’ access to different types of learning supports. We need more research in this area which is the focus of the current study.

Incentive systems, a key feature in many commercial games and in some educational games, are designed to reinforce specific gameplay behaviors and motivate students to play (King, Delfabbro, Griffiths, & Gradisar, 2011; McKernan et al., 2015). Incentive systems are based on behaviorist reinforcement methods (Skinner, 1953) with the purpose of increasing players' extrinsic motivation (Sansone & Harackiewicz, 2000). Extrinsic motivation is defined as “performing behavior in order to achieve some separable goal, such as receiving rewards or avoiding punishment” (Vallerand, 1997, p. 271). Intrinsic motivation is defined as “behavior performed for itself, in order to experience pleasure and satisfaction inherent in the activity” (Vallerand, 1997, p. 271). It is harder to foster intrinsic motivation in educational games than extrinsic motivation (Konetes, 2010). Incentive systems can be used as extrinsic motivators to regulate player's behaviors in educational games using different reinforcement strategies. If designed well, incentive systems can eventually lead to the enhancement of the player's internal motivation. High motivation (intrinsic and extrinsic) in educational games can lead to high engagement, better performance, and ideally improved learning in educational games, which is the goal we pursue: maximizing learning without sacrificing the fun in educational games.

More research is needed that investigates how incentive systems can regulate students’ behavior and motivation in educational games to maximize learning. The findings from such research—including this study—can help GBL researchers design educational games that can direct students to desired behaviors (e.g., using content-related learning supports) and regulate behaviors that can be detrimental to learning. In the next section, we review relevant theories about motivation in games in general, and propose a motivational architecture with five elements needed in educational games (see Fig. 1) to motivate students to engage in gameplay and learning without disrupting the fun in educational games.

Fig. 1
Download : Download high-res image (212KB)
Download : Download full-size image
Fig. 1. Motivational architecture in educational games.

1.1. Motivation in educational games
As mentioned, video games are usually intrinsically motivating to play (Gee, 2003; Habgood & Ainsworth, 2011). There are various theories—e.g., Self-determination Theory (SDT) (Deci & Ryan, 1985; Ryan & Deci, 2000)—that explain why this is the case (Egenfeldt-Nielsen, 2006). The intrinsic motivational appeal of video games can be understood using SDT (Denis & Jouvelot, 2005; King & Delfabbro, 2009; Przybylski, Rigby, & Ryan, 2010; Sørebø & Hæhre, 2012; Zainuddin, 2018). According to SDT, people feel intrinsically motivated when they gain a high level of competence, autonomy, and relatedness (Deci & Ryan, 1985; Ryan & Deci, 2000). Using SDT, Przybylski et al. (2010) noted that video games can help people (a) achieve high levels of competence in various skills needed in video games (e.g., problem solving, reaction time, creativity), (b) gain high levels of autonomy through various choices and control options available in video games, and (c) develop social bonds with one to tens of thousands of people who live in remote locations from each other. Most well-designed video games are intrinsically motivating, but what about educational video games?

When designing educational video games, careful thought should similarly go into their design to make them as intrinsically motivating as commercial games—especially when subject-matter content is added to the games (Habgood & Ainsworth, 2011). We refer to this as the basic intrinsic motivational layer in educational games (i.e., the second element shown in Fig. 1). Then, when content is added to such games, subtle manipulation of behaviors should be considered. That is, some behaviors should be strengthened (e.g., accessing educational content) or weakened (e.g., reducing the overuse of solution videos). This defines an extrinsic motivational layer (e.g., rewards and penalties).

Behavioral theories suggest that by using rewards and penalties, we can strengthen desired behaviors or weaken undesired behaviors in a learning environment (Ferster & Skinner, 1957; Skinner, 1953). Keller (1979) has similarly noted that when developing learning environments, to influence learners’ motivation, one should provide reinforcements to help sustain desirable changes in behavior. Moreover, behavioral learning theories assume that the behaviors are controlled by their consequences (Ferster & Skinner, 1957; Keller (1979). For instance, if accessing the content in an educational game (i.e., a desired behavior) is rewarded, then chances are that the students will repeat this behavior.

Keller (1979) suggests that students’ motivation can be further enhanced when they receive, learn from, and apply the content in learning environments. Therefore, the integration of content in educational games needs to be contextualized so that its inclusion does not disrupt gameplay and flow (Habgood & Ainsworth, 2011). Kafai (1996) has referred to this type of contextualization as content being intrinsically integrated. Thus, in the context of educational games, accessing learning content in the game is warranted and can be rewarded. In this case, students will be externally motivated to engage with the content and enhance their knowledge. By engaging in this process, students can enrich their in-game performance (Habgood & Ainsworth, 2011). When students benefit from accessing the content in an educational game, this enhances their confidence and satisfaction through game performance—two important components of the ARCS motivational model introduced by Keller (2009). Next, we discuss the literature on incentive systems in educational games.

1.2. Incentive systems in educational games
Given the popularity of commercial video games, we can learn valuable lessons regarding their incentive systems' influence on game performance and learning. For instance, Rapp (2017) investigated the reward features in World of Warcraft and their experiential effects on players. Through observations and interviews with players, Rapp posited that rewards such as points and privileged equipment made students feel more autonomous as they had a greater variety of resources to choose and use in the game. The results of Rapp's study suggested that those rewards pushed students to continually perfect their in-game abilities and enhance their game performance.

Tüzün, Barab, and Thomas (2019) conducted an ethnographic study to explore which incentive elements were more effective at increasing student participation. Students played Quest Atlantis, an educational game where the goal is to save a virtual world from an impending disaster by solving problems related to science, medicine, and mathematics. The game included two types of rewards: non-materialistic (e.g., awards, points, and social approval), and materialistic (e.g., virtual trading post, trading cards, and t-shirts). Students earn points by exhibiting desired gameplay behaviors (e.g., completing educational tasks) and spend points to “buy” materialistic items. Among the items that could be purchased, trading cards were perceived as the most valuable as students explained that they were willing to work harder to obtain them. Tüzün and colleagues also argued that the incentive system could balance the sources for earning and spending points.

In contrast, Snow, Allen, Jackson, and McNamara (2015) examined how students' spending behaviors impacted learning and game performance in a study with 40 US high school students. They found no relationship between students’ spending behaviors and motivation or enjoyment. In addition, they reported that placing a high emphasis on spending behaviors had a negative impact on learning and transfer. Snow et al. concluded that in-game spending, as a game feature, is a complex element, and further research is needed to investigate more deeply the relationship between in-game spending and learning.

In two separate studies reported in one paper, Biles, Plass, and Homer (2020) investigated the effects of using badges, another type of incentive system, on students' learning. Their first study (comparing students who received badges to those who did not receive badges) showed that badges did not work the same for all students. Students with high situational interest (i.e., interest in an unknown content which is generated as a result of one's interaction with a learning environment) performed better with badges, while learners with low situational interest performed worse with badges. In their second study, Biles and colleagues compared two types of badges: mastery goal orientation badges and performance goal orientation badges. The first study's findings again appeared (i.e., the interaction between condition and situational interest). Moreover, students receiving performance badges outperformed the students in the mastery badges condition on the posttest. In general, these two studies suggest that the type of badges available, and students' interest and motivation are essential factors for increasing educational games' learning outcomes.

In general, incentive systems in educational games are intended to motivate students to achieve better game performance and learning. However, we find limited empirical research that directly explores the relationship between incentive systems and educational game performance. Keeping students motivated as well as engaged, and improving in-game performance and learning is a large challenge in GBL research (Boyle et al., 2016). To shed light on this matter, we investigated the effects of an in-game incentive system on students’ access to learning supports and the effects of such supports on learning content-related knowledge and game performance (i.e., solving game levels). Our educational game included two types of learning supports: content- and game-related supports, discussed next.

1.3. Learning supports in educational games
Content-related supports are designed to help students learn the underlying content in the game (Leemkuil & De Hoog, 2005; Schrader & Bastiaens, 2012b; Shute et al., 2020). For example, Schrader and Bastiaens (2012b) used a physics educational game with 47 eighth graders and included an ever-present button linking to a textbook. Results showed that students who accessed the learning support scored significantly higher on the posttest compared to the students who did not access the support. However, the number of students accessing the learning supports was low, and 17 out of 47 students simply ignored the button. The authors suggested that the infrequent access of supports was because students were forced to leave the game environment to use the supports.

Tsai et al. (2013) embedded content-related supports in a game environment, consisting of questions related to the target content knowledge. In their study, 79 middle school students were split into three conditions: (1) Required access of supports—where students had to access the supports before each level, (2) Optional access of supports—where students had access to the same material but were not required to use them, and (3) No supports. Results showed that students who were required to access the supports scored significantly higher on the posttest than the other conditions. Similarly, Liao, Chen, and Shih (2019) examined the use of instructional videos in game-based learning coupled with collaboration in a 2 × 2 factorial design (i.e., showing vs. not showing instructional videos as one factor, and collaboration vs. individual gameplay as the second factor). The participants in this study (n = 109) were seventh-grade students randomly assigned to one of four experimental groups. The authors found that game-based learning is effective with instructional videos used as learning supports. Specifically, results revealed that use of an instructional video in collaborative digital game-based learning significantly reduced both intrinsic and extraneous cognitive loads—both of which are detrimental to learning.

Overall, these studies suggest that content-related supports are effective in promoting learning outcomes, but without direction or incentives, students are less likely to use them, especially if they are not embedded in the game environment.

Game-related supports are designed to help students manipulate and interact with game mechanics to solve game tasks. One of the common game-related supports is the complete solution, which presents expert solutions to game levels for students to imitate (Lang & O'Neil, 2008). Some researchers, however, have criticized the inclusion of complete solutions in games, stating that overusing them could lead to simply replicating the solution (the “how”) without deep thinking (the “why”). For example, Kao et al. (2017) found that providing partial solutions (i.e., hints) produced greater learning compared to either the provision of complete solutions or no supports. Additionally, they found no significant difference between complete-solution supports and the no-support conditions. The authors suggested that students who received complete solutions may have just replicated the solution without thinking about the concepts underlying the levels. At the same time, complete solutions are necessary to reduce frustration and help struggling students, particularly when tasked with solving difficult levels (Shen & O’Neil, 2006). Thus, some provisions need to be made to ensure that students have access to complete solutions, but not overuse them.

There are two main methods used to reduce players’ reliance on complete solutions: (a) restricting the availability of complete solutions (e.g., make them available only for very difficult levels), and (b) restricting the use of complete solutions by adding costs per usage (Schrader & Bastiaens, 2012a, b; Sun et al., 2018). For example, Sun et al. (2018) implemented an incentive system to regulate the reliance on complete solutions. Two types of incentive mechanisms were implemented. The point-earned mechanism awarded 1000 points for solving levels without using any partial (i.e., hints) or complete supports, and 10 points for solving levels using partial or complete supports. The point-loss mechanism would deduct 2 points for using partial solutions and 10 points for using a complete-solution support. Results showed that students in the “point-loss” condition used significantly fewer supports than those in the “point-earn” condition.

Based on the preceding findings, students should access content-related supports to maximize their learning, and use complete solutions judiciously to reduce their frustration when faced with difficult levels. In this study, we investigated the effects of an in-game incentive system (see Fig. 1) to encourage (and discourage) relevant behaviors. Specifically, we investigated the use of an incentive system to regulate the use of complete solutions (spending money) and encourage the use of content-related supports (earning money).

Toward that end, based on the theories about motivation in educational games such as Self-determination Theory (Deci & Ryan, 1985; Ryan & Deci, 2000) and other motivational and behavioral theories (e.g., Ferster & Skinner, 1957; Keller (1979), and the elements of well-designed video games discussed earlier (e.g., rules, clear goal, feedback and interactivity, and require active participation), we created a motivational architecture intended to help enhance learning by regulating students’ behaviors regarding the use of learning supports in educational games (Fig. 1).

Our motivational architecture includes five main elements with brief justifications for their inclusion:

(1)
The foundation of the educational game: This includes the game genre (e.g., puzzle, sandbox), the game mechanics (i.e., rules and tools), the underlying subject matter (e.g., physics, mathematics, biology), and the learning supports for enhancing learning and game performance (i.e., content- or game-related—more about the supports in the next section).

(2)
The intrinsic motivators: This relates to the general game elements that make gameplay intrinsically appealing and motivating (e.g., clear goal, narrative, interactivity, feedback, incremental challenges), and provide opportunities for gaining high levels of competence, autonomy, and relatedness.

(3)
The extrinsic motivators: This layer represents an incentive system aiming to strengthen desired behaviors with rewards, and opportunities for using the rewards (e.g., allowing the student to buy game-related items in a game store) and weaken undesired behaviors with penalties.

(4)
Use of the incentive system: This relates to students' behaviors relative to the incentive system (e.g., attempting to get rewarded by accessing content-related supports).

(5)
Effects of the incentive system. This layer shows student improvement in game performance, learning, and enjoyment. If accessing content-related supports was rewarded, and those supports were well-designed and useful, students may continue using the supports even when they are not incentivized after the first use. The extrinsic motivators, if designed well, may end up enhancing the intrinsic motivation of the students during gameplay (Habgood & Ainsworth, 2011).

The first and second elements of this proposed architecture have been listed as necessities for well-designed educational games (e.g., Gee, 2005; Prensky, 2001; Shute & Ke, 2012). The third, fourth, and fifth elements relate to an incentive system designed to regulate students’ behaviors. We included those elements based on the past research on incentive systems in video games in general and educational games, in particular. In the current study, we employed all five elements in our educational game and specifically focused on the connection between the intrinsic and extrinsic motivators—i.e., elements 4 and 5. Next, we briefly introduce the game Physics Playground.

1.4. Physics Playground
Physics Playground (PP; Shute, Almond, & Rahimi, 2019) is a 2D computer-based game created to help middle and high school students learn Newtonian physics such as the laws of force and motion, linear momentum, and torque (see Fig. 4 for the concepts that PP levels cover). The goal in this game, for all levels, is to direct a green ball to hit a red balloon. There are two level types: sketching and manipulation. To solve sketching levels, students draw simple machines (i.e., ramps, levers, pendulums, and springboards) to maneuver the ball to the target balloon (Fig. 2). To solve manipulation levels, students interact with various sliders to change physics parameters (i.e., gravity, air resistance, mass and bounciness of the ball), and also manipulate external forces such as puffers and blowers (Fig. 3).

Fig. 2
Download : Download high-res image (410KB)
Download : Download full-size image
Fig. 2. An example of a sketching level (left) with its solution (right).

Fig. 3
Download : Download high-res image (288KB)
Download : Download full-size image
Fig. 3. An example of a manipulation level.

Fig. 4
Download : Download high-res image (240KB)
Download : Download full-size image
Fig. 4. Physics understanding concepts and sub-concepts covered in PP.

Multiple studies have been conducted using PP to investigate various research questions—from the validity of various stealth assessment measures (Shute, 2011), to the effectiveness of the game in enhancing students' physics understanding. For example, PP was used to measure creativity (Shute & Rahimi, 2020) and persistence (Ventura & Shute, 2013) using stealth assessment. Stealth assessment, in short, is an assessment method that uses the evidence-centered design framework of assessment (ECD; Mislevy, Steinberg, & Almond, 2003) to design and develop various models that are included directly into the fabric of the game. Overall, PP consistently has shown a positive impact on students’ conceptual physics learning, and both boys and girls equally enjoy playing PP (e.g., Shute et al., 2015; Shute, Ke, et al., 2019; Bainbridge et al., 2020).

Over the past decade, PP has undergone multiple design iterations, and various features have been included in it using design-based research studies. In its most recent design, we have included an incentive system to address an issue we noticed in several of our earlier studies. For instance, results from a recent study (Bainbridge et al., 2020) showed that students, overall, tended to overuse the game-related supports (i.e., solution videos) and neglect the content-related supports (i.e., physics videos). In the current study, we created an incentive system with both point-earn and point-loss mechanisms in PP to increase the use of content-related learning supports and regulate the use of game-related supports. Through the red Help button (shown in Fig. 3), students could access the learning supports (both content-related and game-related supports).

Through three usability studies and a final learning study, we designed, developed, and tested the final set of learning supports in PP (Shute, Ke, et al., 2019). More details about the incentive system and the learning supports are discussed in the Method section. The following are our research questions:

RQ 1. What is the effect of the incentive system on using content-related and game-related supports?

RQ 2. What is the effect of the usage of content-related and game-related supports on learning and game performance?

RQ 3. What is the effect of earning and spending money on learning and game performance?

2. Method
2.1. Participants and procedure
We used a one-group pretest-posttest research design in this study. The sample consisted of 199 students (9th to 11th grade) from a large K-12 school in the southeastern US. Students self-identified as male (n = 105) and female (n = 95), with a wide range of ethnicities. Self-reported ethnicities representing more than 1% of the respondents were: White (n = 83), Black or African American (n = 62), Asian (n = 8), Hispanic (n = 15), Other (n = 6), Black or African American and White (n = 6), and Hispanic and White (n = 4).

Students completed both the pretest and posttest and received a $30 gift card for participation. Students played the game in 50-min sessions across six days and had access to both content-related supports and game-related supports throughout gameplay. On the first day, participants completed a demographic survey and an online pretest of physics knowledge (18 items), followed by an introduction to the mechanics of the game. Then, from sessions 2–5, students played the game independently while being monitored by members of our research team. The final session consisted of gameplay followed by the online posttest, a game satisfaction survey, and gift card distribution.

2.2. Materials
2.2.1. Learning supports
The game consisted of 10 tutorial levels and 81 game levels, including both sketching and manipulation levels. To access the learning supports, students had to click on the help button, which was always active during gameplay. The help button presented three options: (a) Show me the Physics—content-related supports; (b) Show me a Hint or Solution—game-related supports; and (c) Show me Game Tips—short descriptions of the game mechanics (outside the scope of this study) (Fig. 5).

Fig. 5
Download : Download high-res image (483KB)
Download : Download full-size image
Fig. 5. Students access learning supports using the Help button available during gameplay.

Table 1 presents the descriptions of each support. Physics supports that were related to the underlying concept of each level (i.e., physics videos, definitions, and Hewitt videos) were believed to be more effective than the other two less conceptual physics supports (i.e., formulas and glossary), therefore, we decided to provide greater amounts of money to students for accessing the more conceptual supports. Our aim was to entice students to access the more effective learning supports.


Table 1. Definitions of different supports in PP. Content-related supports earn money while one game-related support—solution videos—costs money.

Supports	Definition	Value
Content-related Supports
Glossary	Brief explanations of physics terms	+ $5
Formulas	Presented when a physics concept has an associate formula or equation, includes a description of each formula component	+ $5
Definitions	Composed of a short animation about a physics term (e.g. “gravitational force”) and a drag-and-drop quiz, in which students drag phrases to fill in the blanks to form the definition of a physics term	+ $10
Hewitt Videos	Cartoon animations developed by Paul Hewitt explaining different physics concepts	+ $10
Physics Videos	Short animations presenting the connection between physics concepts and game solutions	+ $10
Game-related Supports
Solution Videos	Complete solution for the game level at hand	- $60
Hints	Partial solution that direct students to the correct path (e.g. “Try drawing a springboard”) without revealing the complete solution	Free
2.2.2. Incentive system
The decision to implement an incentive system was based on the results from prior studies using PP. Results of those studies showed that students tended to (a) overuse the solution videos (i.e., complete solutions), and (b) ignore the content-related supports (Bainbridge et al., 2020). In those cases, students who watched more solution videos scored lower on the posttest than to those who watched less solution videos, controlling for the pretest. Moreover, watching physics videos predicted posttest scores, controlling for the pretest. Therefore, our goal for designing and implementing the current incentive system was to regulate these behaviors (i.e., increase viewing of physics videos and decrease the overuse of solution videos) to maximize learning. Physics videos include a demonstration and explanation of how to apply the physics knowledge to solve a game level (e.g., knowledge about properties of torque for a level that can be solved using a lever). These physics videos follow the same structure with narration and on-screen text: (1) introduction of the concept that will be presented in the video (e.g., “Here you are going to see how energy is transferred to a ball using a springboard”), (2) stating the concept (e.g., “gravitational potential energy is the energy of height”), (3) demonstrating a failed attempt to solve a level in the PP environment (e.g., the pendulum does not have enough angular height), and (4) showing a successful attempt to solve that level.

We designed and developed the physics videos using the first principles of instruction (Merrill, 2002) and the principles of multimedia learning (Mayer & Mayer, 2005). Specifically, from the first principles of instruction we used the following principles: activation (i.e., learning is enhanced when prior knowledge is used as a foundation for new knowledge), demonstration (i.e., learning is enhanced when new knowledge is demonstrated to the learners through examples and non-examples, demonstration and visualization of steps or procedures, and modeling for action or behavior), and application (i.e., learning is enhanced when new knowledge is applied to or practiced in a variety of situations by students).

We also considered the following multimedia learning principles: multimedia (i.e., people learn better from words and graphics than words alone), modality (i.e., people learn better from graphics with narration than graphics with on-screen text), redundancy (i.e., people learn better from graphics and narration than from graphics, narration, and on-screen text), coherence (i.e., people learn better when extraneous elements are excluded rather than included), spatial contiguity (i.e., placing corresponding words and graphics near each other leads to more effective correspondence between the words and parts of the graphics), signaling (i.e., people learn better when visual cues highlight the organization of the material and the important content), temporal contiguity (i.e., learning increases when corresponding words and graphics are delivered simultaneously rather than sequentially), personalization (i.e., people learn better when narration is presented in a conversational style rather than formal style), voice (i.e., people learn better from a friendly human voice rather than a machine-like voice). Since the focus of this study is on the effectiveness of the incentive system, we do not discuss use of these principles further (see Kuba, Rahimi, Smith, Shute, & Dai, in press), for a full explanation about how we used these principles when designing and developing the physics videos).

2.2.2.1. Earning Money Resources
One way of earning game money in PP is by solving game levels. Students can earn either a silver coin ($10) or a gold coin ($20) when they solve a level. For sketching levels, the solutions must use fewer than a minimum number of drawn objects to earn a goal coin. For manipulation levels, gold coins are awarded for solving under a minimum number of attempts, where attempt is determined by clicking the “play” button. Solutions that exceed the minimum number of drawn objects or attempts earn a silver coin. Students can play a level multiple times but can only earn one gold and one silver coin per level. Accessing the physics supports is another means of earning game money. Although students can access the learning supports whenever and however often they choose, game money is awarded only on the first time they access each support.

2.2.2.2. Spending Money Opportunities
Students can check their progress, money balance, physics understanding, and the store within the “My Backpack” dashboard (Fig. 8). Within the store, students can spend game money to customize their gameplay—this feature helps to enhance students’ sense of autonomy explained by SDT (Ryan & Deci, 2000). For example, students may change the background music (for $30), background image for game levels (for $20), and ball design (for $60). During gameplay, however, students can spend their money on solution videos. Each time a student selects “Show me a solution,” it costs them $60.

Fig. 8
Download : Download high-res image (1020KB)
Download : Download full-size image
Fig. 8. Game store in My Backpack which includes music, background, and ball stores.

2.2.3. Measures
2.2.3.1. Variables extracted from the log files
When students play PP, various events are logged. Events associated with the incentive system include accessing learning supports, money earned, and money spent. When any of these events occurred during gameplay, PP recorded information such as player, level name, money, support type, type of item purchased, and a timestamp. To measure students’ game performance, usage of learning supports, and game behavior related to the incentive system (e.g., earning money by accessing the learning supports), we parsed the log files and computed different variables for each student: frequency of accessing each support, gold coins earned, silver coins earned, levels completed, total money earned, money earned from coins, money earned from accessing physics supports, total money spent, money spent in store, money spent on solution videos, and money spent per each type of store item.

2.2.3.2. Physics understanding test
To measure students’ physics understanding, we created two isomorphic tests with multiple-choice items covering the nine sub-concepts shown in Fig. 4 (pretest = 18 items, α = 0.77; posttest = 18 items, α = 0.82) (Fig. 9). The items were (a) designed in the context of PP (i.e., including a video or an image from the game environment), (b) developed with the help of two physics experts, and (c) subjected to several pilot tests before being administered in the current study.

Fig. 9
Download : Download high-res image (372KB)
Download : Download full-size image
Fig. 9. Example of an item from the physics understanding test (the correct answer is A).

3. Results
3.1. The effect of incentive system on using the learning Supports—RQ 1
To examine the effects of the incentive system in accessing physics videos and solution videos, we parsed the log data and computed the variables related to the frequency of accessing physics videos and solution videos. The descriptive statistics show that, on average, students accessed physics videos (M = 3.90, SD = 4.55) more than solution videos (M = 2.55, SD = 2.84). This finding contrasts with findings from our previous studies (without an incentive system), suggesting that our incentive system is having an effect, in the right direction. The rest of the supports described in Table 1 were not used very often, except for hints (M = 5.10, SD = 5.41). However, our regression analyses showed that viewing hints was not predictive of learning (βhint = 0.03, t = 0.56, p = .58) or game performance (βhint = 0.10, t = 1.58, p = .12). Therefore, we focus on physics and solution videos in our subsequent analyses.

Overall, the results suggest that the incentive system was an effective regulator of learning support usage, encouraging students to access physics videos and controlling overuse of solution videos.

To confirm this claim, we analyzed the gameplay behavior data related to use of learning supports by data mining techniques. Specifically, we examined the gameplay behavior of students who bought solution videos to see if they even attempted to solve the game level before buying a solution video. The results showed that 137 students (69%) bought at least one solution video, and of those students, 85% tried to solve the level first before purchasing a solution video. On average, students attempted to solve a level nine times and stayed in a level for 5 min before buying a solution video. Similarly, of the 143 students (72%) who viewed the physics videos at least once, students tried to solve levels 36% of the time on their own before collecting money from physics videos. On average, students attempted to solve levels between 2 and 3 times before accessing the physics videos. Moreover, students accessed the physics videos at the beginning of gameplay (78%), with fewer accessing supports in the middle (13%), or at the end of gameplay (7%). These results suggest that the incentive system acted as an effective control on the abuse of solution videos and that students tried to solve levels before accessing either solution videos or physics videos. To answer our second research question, we investigated the effects of accessing solution videos and physics videos on learning and game performance.

3.2. The effects of using learning supports on learning and game Performance—RQ 2
We first examined the correlations among the variables. Results showed that frequency of watching physics videos significantly correlated with students’ posttest scores (r = 0.32, p < .01). Similarly, the frequency of watching physics videos significantly correlated with the number of levels students solved (r = 0.43, p < .001). In contrast, the frequency of watching solution videos did not correlate with posttest scores (r = 0.04, p = .60) and levels completed (r = 0.11, p = .14).

Next, we conducted four multiple regression analyses. The first two regressions set posttest score as the dependent variable, and pretest and frequencies of watching physics videos and solution videos as predictors. The second two regressions used game performance as the dependent variable (defined as the total number of levels each student solved), and pretest and frequencies of watching physics videos and solution videos as predictors. Table 2 shows the results from the regression analyses.


Table 2. Regression results with frequency of accessing the supports as independent variables.

DV	Predictors	β	t	F	Adj. R2
Model 1	Posttest	Physics Videos Freq.	.11	2.11*	97.46**	.49
Pretest	.66	12.47**		
Model 2	Solution Videos Freq.	−.03	−.48	93.37**	.48
Pretest	.7	13.64**		
Model 3	Levels Completed	Physics Videos Freq.	.33	5.15**	40.63**	.29
Pretest	.34	5.44**		
Model 4	Solution Videos Freq.	.07	1.02	24.78**	.19
Pretest	.44	6.84**		
Note. *p < .01, **p < .001; DV = Dependent Variable.

Overall, watching physics videos was a significant predictor of both posttest and game performance (i.e., levels completed). Students who watched more physics videos scored higher on the posttest and completed more levels compared to those who watched fewer or no videos, controlling for their incoming knowledge. It is worth noting that watching physics videos has an almost similar effect on predicting the levels completed as incoming knowledge. This finding shows that viewing physics videos was effective for both learning and game performance. We expected that watching solution videos would have a positive effect on game performance (i.e., solving more levels). However, watching solution videos did not predict either posttest scores or levels completed, controlling for the pretest. One possible reason for this finding could be the high cost attached to watching them. This finding suggests the negative effect of overusing solution videos was reduced in this study. Next, we examine the effect of students’ earning and spending behaviors on learning and game performance.

3.3. The effects of earning and spending game money on learning and game Performance—RQ 3
We computed several variables related to money earning and spending behaviors. Table 3 shows the descriptive statistics of the six variables. Results show that, on average, students earned most of their game money from solving levels and spent most of their money on solution videos.


Table 3. Descriptive statistics of total money earned and spent by students in PP (n = 199).

Min.	Max.	M	SD
Total Money Earned	110	2555	934.32	398.16
Earned: Physics Videos	0	240	37.49	43.55
Earned: Solving Levels	100	2100	882.06	357.47
Total Money Spent	0	1440	228.34	207.96
Spent—In the Store	0	1320	66.73	132.93
Spent—On Solution Videos	0	840	161.61	175.52
There is a significant correlation between total money earned and posttest scores (r = 0.50, p < .001) and money earned from watching physics videos and levels completed (r = 0.43, p < .001). Our correlational analyses showed that the total amount of money spent (on solution videos and in the store) did not correlate with posttest scores. Conversely, there was a small but significant correlation between total money spent and the number of levels solved (r = 0.21, p = .003). We conducted several multiple regression analyses with posttest scores and levels completed as dependent variables and the variables in Table 3 as predictors. We did not include money earned from solving levels as a predictor in the regression analyses with levels completed as the outcome variable to avoid a multicollinearity issue (the two variables were highly correlating). Table 4 shows the results of the regression analyses.


Table 4. Regression results with money earned and spent variables as independent variables.

DV	Predictors	β	t	F	Adj. R2
Model 1	Posttest	Total Money Earned	.21	3.79***	107.16***	.52
Pretest	.62	11.39***		
Model 2	Earned: Solving Levels	.20	3.45**	72.44***	.52
Earned: Physics Videos	.04	.64		
Pretest	.61	11.23***		
Model 3	Total Money Spent	−.01	−.26	93.20***	.48
Pretest	.70	13.60***		
Model 4	Spent: Store	.01	.15	61.92***	.48
Spent: Solution Videos	−.02	−.43		
Pretest	.70	13.58***		
Model 5	Levels Completed	Earned: Physics Videos	.33	5.44***	40.72***	.29
Pretest	.34	5.16***		
Model 6	Total Money Spent	.14	2.25*	27.29***	.21
Pretest	.43	6.75***		
Model 7	Spent: Store	.15	2.30*	18.64***	.21
Spent: Solution Videos	.08	1.28		
Pretest	.43	6.78***		
Note. *p < .05, **p < .01, ***p < .001; Dependent Variable.

Overall, total money earned was a significant predictor of posttest scores and levels completed controlling for the pretest. However, upon further investigation, the results from a multiple regression analysis showed that only money earned from solving levels significantly predicted posttest scores and levels completed. Earning money in PP is mainly from solving game levels, while the rest of the money from PP comes from accessing physics videos. In both cases, students have an opportunity to learn more physics. This positive predictive power of money earned is what we expected when designing the incentive system in PP. Similarly, earning money from watching physic videos significantly predicted levels completed controlling for the pretest. That is, those who earned more money from watching physics videos completed more levels compared to those who earned less or no money from that source. This result suggests that incentivizing students to use physics videos helps students perform better in the game, and game performance (i.e., number of levels solved), in turn, predicts learning (i.e., posttest scores) controlling for the pretest.

The relationship between spending money in PP and learning and performance was important to investigate because of two reasons. First, students who got stuck during gameplay might spend their money on solution videos and get themselves unstuck and possibly enhance their performance. Second, spending money in the store can result in some positive affective boost that can potentially enhance students’ performance. Both of these scenarios can provide evidence for the effectiveness of the incentive system.

The total money spent significantly predicts the number of levels solved, but does not predict posttest scores, controlling for the pretest. These results show a clear relationship between spending money in general, and game performance. Further, game performance predicts learning. Therefore, we can conclude that spending money has an indirect effect on learning. That is, spending money positively impacts game performance, and game performance positively impacts learning.

We also found that money spent on solution videos is not a significant predictor of the number of levels solved. However, money spent in the store is a significant predictor of the number of levels solved controlling for the pretest and money spent on solution videos. These results suggest that spending money for changing game items in the store could help students solve more game levels in indirect ways (e.g., helping them take a break from the game and perhaps attenuate feelings of frustration, then return to solving levels).

In summary, the key findings of this study are as follows: (1) students viewed more physics videos than solutions videos on average, (2) students tended to try solving the levels first and then use the supports—which was desired, (3) watching physics videos was predictive of posttest scores and game performance controlling for the pretest, (4) watching solution videos was not a significant predictor of posttest and game performance, (5) earning money (mostly from solving levels) predicted posttest scores controlling for the pretest, (6) earning money from watching physics videos was a significant predictor of game performance controlling for the pretest and, (7) and spending money (mostly in the game store and not on solution videos) predicted the number of levels solved. In general, we believe that the incentive system worked as intended. We discuss these findings next.

4. Discussion and conclusion
In this study, we proposed and evaluated a 5-element motivational architecture, based on relevant motivational and behavioral theories, for use in the design of educational games: (1) Foundation of the educational game, (2) Intrinsic motivators, (3) Extrinsic motivators, (4) Use of an incentive system, and (5) Effects of the incentive system. According to the literature (e.g., Kao et al., 2017) and our previous research (Bainbridge et al., 2020), students tend to overuse solution videos when they have free access to them. This behavior can have negative effects on student learning (Kao et al., 2017). On the flipside, students tend to ignore content-related supports in educational games (e.g., Schrader & Bastiaens, 2012b). In this study, we examined the effectiveness of an incentive system we developed to increase students' use of content-related supports and minimize students’ use of one particular game-related support—solution videos— (i.e., the fourth element of the motivational architecture). We also examined the effect of this behavioral regulation on game performance and learning (i.e., the fifth element of the motivational architecture). In the following sections we discuss the findings per research question.

4.1. The effect of the incentive system on using learning Supports—RQ 1
Our findings showed that the incentive system we included in PP was effective in terms of increasing the use of physics videos and decreasing the use of solution videos. In short, our incentive system effectively regulated students' behavior regarding their access of particular learning supports. These findings align with the results from Sun et al. (2018) who reported that a “point-loss” mechanism is effective in regulating use of solution videos. Our findings indicate that the fourth element in our motivational architecture (Fig. 1) called use of the incentive system was established. In other words, the rewards and penalties (extrinsic motivations) used in our game could, to some extent, control students' behavior regarding how they used the supports. These findings align with motivational and behavioral theories (Keller (1979); Ferster & Skinner, 1957; Ryan & Deci, 2006) that assert the use of rewards and penalties (i.e., external motivators) can strengthen desired behaviors or weaken undesired behaviors in learning environments. Therefore, we suggest that implementing an incentive system with direct and appropriate penalties (e.g., adding a cost for viewing solution videos) can push students toward more attempts to solve game levels before buying solution videos. In that case, students will probably use solution videos only when stuck or very frustrated, which is the appropriate time for doing so based on the literature (e.g., Shen & O’Neil, 2006; ter Vrugte et al., 2017). Our findings showed that students attempted to solve levels nine times and stayed in a level for 5 min before purchasing a solution video. This finding indicates that, on average, students mostly used the solution videos when struggling, and not as “cheats” in the game.

Because most students tended to hold onto their money rather than spending it on solution videos, we believe that the $60 price helped regulate students’ access of solution videos. The reason for the reduction in watching the solution videos was not lack of money, but was due to the $60 cost (i.e., the direct penalty). Based on the findings of our study, we suggest including incentive systems with both rewards (to strengthen desired behavior) and penalties (to weaken undesired behavior) in educational games. This can have a positive effect on both game performance and learning—the fifth element of our motivational architecture called effects of the incentive system.

4.2. The effects of learning support usage on learning and game Performance—RQ 2
Students who watched more physics videos scored higher on the posttest (controlling for pretest score), and solved more game levels than those who watched fewer or no videos. These findings align with previous research on the use of content-related supports in educational games (e.g., Liao et al., 2019; Schrader & Bastiaens, 2012b; Tsai et al., 2013). In addition, physics videos were the only content-related support accessed repeatedly, even though students did not earn additional money by accessing the same support multiple times in the same game level. This result suggests that students could perceive the value of watching physics videos. Based on the self-determination theory (SDT), the best form of extrinsic motivation is when students perceive the value of task, called integrated regulation (Ryan & Deci, 2000). Thus, while the external regulation in the form of game money encouraged students to access the physics videos the first time, it was the perceived value or integrated regulation that encouraged students to access the videos multiple times. This finding shows that the effects of the incentive system as external regulation was aligned with the self-determination theory (i.e., external regulation can lead to integrated regulation in educational games).

As mentioned previously, Schrader and Bastiaens (2012b) argued that content-related extrinsic supports (i.e., not embedded within the game) interrupt the flow of gameplay, thus causing extraneous cognitive load which leads to low usage. However, we think one reason we found the preference for physics videos over the other physics supports is because they are the only support that connects physics knowledge and game mechanics. Specifically, physics videos present the underlying physics behind the level solutions—the “why” things happen as they do—which we argue is important to solving game levels. The physics videos were intrinsically integrated (Habgood & Ainsworth, 2011; Kafai, 1996) into the game context. Therefore, our findings align with Schrader and Bastiaens’ (2012b) argument and the reason for not accessing other physics supports is that they were viewed as extrinsic supports, not directly connected to the game levels. Moreover, the fact that students kept accessing physics videos demonstrates a conversion to intrinsic motivation and alignment with what Keller (2009), Habgood and Ainsworth (2011), and Kafai (1996) reference, that extrinsic motivators can lead students to show the desired behaviors (e.g., accessing learning content in a learning game) when no extrinsic rewards are given.

Our findings additionally suggest that content-related supports are effective for increasing game performance. That is, while time spent watching physics videos did take away from gameplay time, it helped students solve more levels. Encouraging students to access these supports was our goal with the incentive system, and it worked as intended. Contrary to our expectations, we found viewing solution videos was not related to solving levels and learning outcomes. The minimal use of solution videos indicates students may have restricted use to when they were really struggling, instead of using solution videos to solve more levels. If this was the case, we can conclude that including solution videos in the current study to manage students' intense frustration which can lead to quitting behavior (Kapoor et al., 2007) was warranted. However, more research using affect detectors (e.g., D'Mello & Graesser, 2010) or field observations of student behaviors and affective states (e.g., Ocumpaugh, Baker, & Rodrigo, 2015) is needed to confirm this assumption.

4.3. The effects of earning and spending game money on learning and game Performance—RQ 3
We found that, on average, students earned most of their game money from solving levels and spent most of their money on solution videos. These behaviors were expected as students were highly engaged in solving levels (hence, they made most of their money from solving levels), and when they got stuck they needed direct help (hence, they bought solution videos).

Our findings showed that earning money, especially from solving levels, predicted learning, as measured by posttest scores holding pretest constant. This finding was expected as earning money in PP is heavily reliant on solving levels, and we found that solving levels (i.e., game performance) was predictive of learning. This finding confirms what Shute et al. (2015) found—an indirect effect of earning coins on learning via a significant effect on game performance. This finding also aligns with the results of studies by Rapp (2017) and Tüzün et al. (2019) who reported that external rewards, such as points and privileged equipment, can push players to work harder and enhance their game performance. Moreover, our findings show that earning money from viewing physics videos predicts game performance—but not learning. Therefore, we suggest that incentivizing students to use well-designed, content-related supports helps them perform better in educational games, and better game performance can lead to greater learning. Therefore, we suggest that there is an indirect effect of incentivizing students to access content-related supports and learning.

Spending money (on both solution videos and in the store) did not impact students' learning. We did not have an expectation for a direct effect of money-spending behaviors and learning. However, we found that spending money in general, especially in the store, is a significant predictor of the number of levels solved, controlling for the pretest. This finding contrasts with the result of Snow et al.‘s work (2015) which reported a negative relation between students' spending behaviors and game performance. Since spending money on solution videos (a type of support that is typically expected to increase the number of levels solved) did not show an effect on the game performance, we presume that students who took a break from gameplay by accessing the game store could better manage their game performance (even if unaware) and solve more game levels. In that sense, the game store could have helped their affective state positively as an attention-redirection or situation-modification tool (Pacheco-Unguetti, Acosta, Callejas, & Lupiáñez, 2010; Spann, Shute, Rahimi, & D’Mello, 2019) to regulate their frustration and improve their game performance, both of which influence learning. However, further investigations are needed to support this assertion. Moreover, we presume that the opportunities for buying various items in the store could enhance students' autonomy. Based on SDT, enhanced autonomy leads to better intrinsic motivation (Ryan & Deci, 2000), which enhances performance.

Overall, these findings show the ability of an incentive system to induce desired behaviors and regulate undesired behavior that can directly or indirectly affect learning and game performance. In general, the results from our analyses for research questions 2 and 3 confirmed the existence of the fifth element of our motivational architecture for educational games—effects of the incentive system. We expect to see the same results in similar educational games (i.e., puzzle games with game-related and content-related supports) using a similar population (9th to 11th graders). In games based on solving puzzles or problems, students tend to rely on solution videos and ignore content-related supports (e.g., Kao et al., 2017; Schrader & Bastiaens, 2012b). Therefore, we believe a point-earn and -loss incentive system can effectively induce the desired behavior in educational games. However, more research using other research designs (e.g., experimental), different educational games, and in other contexts are needed to confirm our findings. Considering these limitations, we put together several implications—discussed next.

5. Implications
Based on these findings, we compiled a list of implications that can be useful for educational game designers and game-based learning researchers to consider:

1)
Include an incentive system with point loss or appropriate cost mechanism to discourage overuse of viewing solutions. We do not recommend excluding such videos or supports as they might be useful for students who are struggling or frustrated.

2)
Include a game store with customizable items to allow students to enhance their sense of autonomy, take a break from gameplay, boost their affective state, and possibly enhance their game performance.

3)
Provide learning supports that explicitly show the connection between the content knowledge behind the game levels and the game mechanics involved in the game level solution. This way, students are not given the solution which is detrimental for learning as suggested by previous literature. Instead, they learn more about the game mechanics and the content knowledge involved in the game level.

4)
Provide sufficient rewards to entice access of effective learning supports but limit the rewards to avoid gaming the system behaviors. These rewards can work as extrinsic motivators that can grab students' attention for the first time. The ideal situation is when the supports are beneficial to students and they chose to use them even when there are no rewards available—a shift to intrinsically motivated access of the learning supports.

6. Limitations and future steps
The first limitation of this study is the research design. We used a one-group research design because we conducted this study as part of a larger experiment with 263 students (4 groups, with one control group) to investigate the effects of adaptive sequencing of game levels (Shute et al., 2020). Future research can investigate similar research questions using an experimental research design with at least two groups (e.g., one with and the other without an incentive system). That kind of study can test the effects of the incentive system in isolation and show its impact on student behaviors, game performance, and learning (as the only difference between the treatment conditions would be the presence or absence of an incentive system). Furthermore, as we used only one educational game, our study's findings may or may not replicate in different situations with other educational games. Therefore, we suggest investigating the effectiveness of similar incentive systems in other educational games to increase the findings' generalizability.

Based on our findings, students tended to keep most of the money they earned; thus, they were never in need of money. If the flow from earning to spending was more balanced, we might have seen even stronger learning and performance effects. Therefore, we suggest two possible improvements for incentive systems based on the results of this study. First, attempts should be made to strike a better balance of money (or points) earned vs. spent. For example, educational game designers and researchers can do that by (a) increasing the price of solution videos and the items in the store, as well as increasing the number and variety of items in the store, (b) decreasing the amount of money earned by solving game levels, and (c) encouraging students to pause the game and spend their money (e.g., at the end of a level, “You have X amount of money. Do you want to spend it?” or advertising an item in the store during gameplay, e.g., “Hey! There is a great store in this game where you can do cool stuff. Want to take a look?“). However, usability studies are needed to find the right costs and rewards in incentive systems and choosing effective strategies for implementation.

We also see the possibility of investigating the effects of using incentive systems as we tested herein on other outcome variables such as game enjoyment or students' affective states (e.g., frustration). It would be informative for game designers to know how an incentive system's addition in an educational game impacts students' affective state. Results from such investigations and related research on incentive systems in educational games can serve as the basis for enhancing students' motivation (i.e., intrinsic motivation sparked from the promise of extrinsic rewards) and increasing learning. One challenge facing researchers in this area involves optimizing the design, development, and careful embedding of content-related learning supports within educational games to facilitate rather than disrupt learning and engagement. Research in areas such as incentive systems can help address this challenge.