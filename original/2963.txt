Indicators of behavioral engagement derived from log data may provide insight about variation in participants' interactions with and the efficacy of digital cognitive skills training games. We first sought to determine whether distinct groups of adolescents (N = 163; Mean age = 14.1 years, SD = 1.3) could be identified based on variables derived from digital log data collected while participants played a game designed to enhance inhibitory control. We then examined whether these data-driven participant groupings were associated with improvement in inhibitory control. Latent class mixture modeling was conducted both with reaction time and a measure of response accuracy (d’) of log data. Results indicated two distinct classes based on reaction time, and four classes based on response accuracy over the course of training. Class membership based on reaction time was associated with differential improvements in performance on a subsequent standardized measure of inhibitory control. The findings point towards the need for formative metrics of progress, as well as the need for more adaptive and user-centered cognitive skills interventions. Our findings suggest that there may be some utility in analyzing log data as an indicator of student engagement, particularly when used in complement with more traditional measures of performance.

Previous
Next 
Keywords
Games

Architectures for educational technology system

Data science applications in education

Pedagogical issues

1. Detecting patterns of engagement in a digital cognitive skills training game
How do different patterns of activities in a cognitive skills training game relate to learning outcomes? There is a growing interest in the use of digital games to develop certain cognitive skills, such as executive functions (Homer, Plass, Raffaele, Ober, & Ali, 2018; Parong et al., 2017). Executive functions (EF) are cognitive processes required to plan, monitor and control cognition (Diamond & Lee, 2011). They are considered critical for academic and personal success (Ahmed, Tang, Waters, & Davis-Kean, 2019). Researchers have begun to investigate which game features enhance related learning outcomes (Plass et al., 2019a, 2019b) as well as the efficacy of these games (Clark, Tanner-Smith, & Killingsworth, 2016). How the actions performed by a player in a cognitive skills training game relate to the intended cognitive training outcomes of a game have received less attention (Schwartz & Plass, 2020). In the present investigation, we sought to identify patterns of engagement during a game training the cognitive skill of inhibitory control.

2. Development of inhibitory control
Inhibitory control refers to the ability to suppress a prepotent response (Miyake & Friedman, 2012). Multiple factors influence the developmental trajectory of inhibitory control. We focus on three major contributing factors: age, gender, and language background.

2.1. Age and development of inhibitory control
The EF skill of inhibitory control develops during childhood and adolescence, with younger children exhibiting slower processing speeds on tasks measuring the construct (Cepeda, Kramer, & Gonzalez de Sather, 2001; Davidson, Amso, Anderson, & Diamond, 2006). Previous findings suggest that performance on inhibitory control tasks differs based on developmental changes: younger participants prioritize responding quickly over responding accurately, while older participants do not sacrifice accuracy for speed (Pachella & Pew, 1968; Salthouse, 1979). Some research has pointed towards a neurological basis for these observed developmental changes (Bogacz, Wagenmakers, Forstmann, & Nieuwenhuis, 2010). Luna, Garver, Urban, Lazar, and Sweeney (2004) found that while response inhibition, as measured by response accuracy, reached adult maturity by 14 years of age, processing speed (evidenced by reaction time) reached maturity slightly later, by approximately 15 years of age. Furthermore, Homer et al. (2019) found that younger adolescents (i.e., approximately age 13 years) tend to have greater improvements in inhibitory control after playing a cognitive skills training game that emphasized speed of response, while older adolescents (i.e., approximately age 17 years) tended to have greater improvements when playing a version of the same game that emphasized accuracy of response. In light of evidence of developmental changes in inhibitory control during childhood and adolescence (Blakemore & Choudhury, 2006), this skill may be particularly malleable before brain maturation occurs in adulthood.

2.2. Gender and development of inhibitory control
Male and female children and adolescents develop inhibitory control at different rates, such that females display advanced inhibitory control skills earlier in adolescence than males (Malagoli & Usai, 2018). There is evidence that these gender-related developmental differences in behavioral and cognitive performance are due to structural changes in the brain that occur during critical developmental phases (De Bellis et al., 2001; Ruigrok et al., 2014). Some evidence suggests that the functional maturation of specific brain regions associated with inhibitory control may vary between males and females.

2.3. Language and development of inhibitory control
Past research suggests that children with multilingual backgrounds may have a performance advantage in certain tasks that require inhibitory control (Declerck & Philipp, 2015). Bialystok, Martin, and Viswanathan (2005) found that bilingual children, adults, and older adults performed better on the Simon task, a measure of inhibitory control. The researchers, however, did not find such an advantage in a young adult sample, thus concluding that the performance advantage is less apparent when inhibitory control skills are at their peak (Bialystok et al., 2005). Past research has also found that the extent of switching between two languages is associated with more general inhibitory control skills (Verreyt, Woumans, Vandelanotte, Szmalec, & Duyck, 2016). There is some mixed evidence suggesting that the ability to speak multiple languages improves more general cognitive functions, such as inhibitory control. At least one recent meta-analysis found that any effect favoring bilingual participants in tasks requiring response inhibition was non-significant after accounting for publication bias (Donnelly, Brooks, & Homer, 2019).

3. Games-based training of EF
Digital games may be ideal for developing cognitive skills because they are engaging environments that provide learners with immediate and personalized feedback (Shute & Rahimi, 2017; Van der Kleij, Feskens, & Eggen, 2015), a flexible learning experience (Homer, Ober, & Plass, 2018), support in sustaining attention (Shute, 2011; Shute & Kim, 2014) and different types of engagement (Schwartz & Plass, 2020). Though an elusive construct, in an academic context, engagement is often considered as the intensity of cognitive and behavioral involvement, and emotional quality of a person's effort on a task (Bouvier, Lavoué, & Sehaba, 2014). In the present study, we focus specifically on behavioral engagement in digital contexts, which is a construct often measured by the speed and accuracy of motor movements that involve the manipulation of physical and virtual stimuli (Deater-Deckard, Chang, & Evans, 2013).

Sustained and active engagement is thought to be critical for the effectiveness of cognitive skills training (Anguera & Gazzaley, 2015; Gathercole, Dunning, & Holmes, 2012). The use of game-like features in training is a well-established mechanism for promoting meaningful engagement (Cardoso-Leite, Joessel, & Bavelier, 2020; Lumsden, Skinner, Woods, Lawrence, & Munafò, 2016), with findings from a meta-analysis indicating a strong association between action videogame-play and enhanced attention and spatial cognition (Bediou et al., 2018). Furthermore, there is evidence that this association does not emerge as a result of selection bias, where children with greater cognitive skills seek out engaging activities such as gaming, but rather is an effect of game-play itself. For example, Fikkers, Piotrowski, and Valkenburg (2019) did not find support for a selection bias perspective in their longitudinal study of fluid intelligence. Instead, with a sample of 934 children over four years, Fikkers et al. found partial evidence for a directional effect, such that game-play enhances cognitive skills.

Studies investigating the efficacy of digital games for cognitive skills training have found mixed results. Cognitive skills training presumes that a specific cognitive skill can be improved through targeted practice of that skill. Several meta-analyses have reported inconsistent findings and illustrated the difficulty in meaningfully operationalizing transfer of training effects. Examining both quasi-experimental and experimental studies, Powers, Brooks, Aldrich, Palladino, and Alfieri (2013) found evidence that the small-to-large effect sizes across domains of information processing reported in quasi-experimental studies were susceptible to bias. By contrast, effect sizes reported with respect to EF skills in experimental studies were nearly negligible. Another meta-analysis found that digital game-play was weakly associated with cognitive skills, and found no evidence in support of a causal association (Sala, Tatlidil, & Gobet, 2018). Some have suggested that the associations may vary depending on the learners. For example, Lamb, Annetta, Firestone, and Etopio (2018) found evidence of effects on cognition from playing serious games among younger participants, though not in adults.

Characteristics of the game's design and targeted cognitive skill may also influence the efficacy of game-play. Bediou et al. (2018) found that action-video games enhance attentional control and spatial cognition. Attentional control is often regarded as a component of inhibitory control (Hampshire, Chamberlain, Monti, Duncan, & Owen, 2010). Furthermore, another meta-analysis indicated the effects of digital games on learning can vary considerably depending on certain design characteristics of the game (Clark et al., 2016), such as the game mechanics (Homer et al., 2019), use of visual and narrative elements and other aspects of emotional content (Ninaus et al., 2019), game design (Plass, Homer, MacNamara, et al., 2019), and responsiveness to user-input (Plass et al., 2019b). Other factors also appear to influence the efficacy of games for learning, including the number of game sessions, the use of solitary play or collaboration, type of scaffolding prompts, integration of game and learning mechanics, as well as visual and narrative design features including the use of realism, anthropomorphism, camera perspective, and story relevance (Clark et al., 2016).

3.1. Games to train inhibitory control
Inhibitory control is an important cognitive skill, particularly in childhood and adolescence, as it has been linked with not only cognitive skills, but also social and emotional competencies such as theory of mind (Carlson & Moses, 2001) and emotion regulation (Carlson & Wang, 2007). There is some evidence of similar positive effects for games that tap into inhibitory control. Ramos and Melo (2019) examined the effects of playing a digital game daily for 15 minutes over the course of 6 weeks and found that children in the treatment group had greater gains on standard measures of attentional control compared to peers in a no-treatment control group.

3.1.1. Methodological shortcomings of research on EF training with games
Concerns around the topic of cognitive skills training have centered around methodological issues in psychological research including the recruitment of participants, the specific measures used, and interpretation and generalizability of the results beyond the context of the study (Boot, 2015). Cognitive researchers are particularly concerned with finding evidence that skills acquired through cognitive training are transferable (Simons et al., 2016). Lintern and Boot (2019) reviewed papers which examined the effects of flying or driving simulations. The authors noted that the studies lacked appropriate measures of transfer and further concluded that many studies that utilized games or simulations for skills training purposes did not provide sufficient support for transfer of training effects.

Additionally, few studies have considered the extent to which training should target a specific cognitive skill. Anguera et al. (2013) examined older adults who played a video game that manipulated multi-tasking (i.e., single-v. multi-tasking). Participants who completed a multi-tasking version were found to have improved working memory and sustained attention compared to participants in a control condition. These findings suggest that variation in activities during game-play may lead to greater improvement in cognitive skills. In work with adolescents, Homer, Plass, Raffaele, Ober, and Ali (2018) had participants play a digital game designed to teach cognitive flexibility once a week for 20 min over six weeks and found significant gains in adolescents’ scores on standard measures of EF, specifically shifting (as measured by the Dimensional Change Card Sort Task; Zelazo, 2006) and inhibitory control (as measured by the Flanker task; Eriksen, 1995). Parong et al. (2017) found that older adolescents and young adults who played the same cognitive flexibility training game had significant gains in shifting compared to participants who played a control game. Furthermore, this gain was found only when participants played for 2 hours over four sessions, but not if participants played for only 1 hours. Therefore, in addition to variation and types of activities, the amount of time spent on game-play appears to matter.

Another methodological concern is that many studies exploring the efficacy of games to train cognitive skills are performed before the design factors of that game intended to contribute to the development of EF have been sufficiently investigated. Examining the efficacy of games to train cognitive skills should also involve the study of learner behaviors and actions during such games, as these can reveal insights into the processes and mechanisms by which the game is able to achieve the intended outcomes. The present research is intended to contribute to this line of investigation.

3.2. Analyzing learning process data using machine learning
From the studies reviewed above, it is evident that understanding what works for training cognitive skills with digital games is complex, particularly when taking a learner-centered approach to understand individual differences in how children approach a game. To better address this issue, a more detailed understanding of what learners are actually doing in the game, and how this relates to outcomes, is needed. One promising approach is to examine digital log data from training games. Recently, large volumes of log data that capture interactions in digital environments have become more readily accessible. This, coupled with advances in the tools and techniques to analyze time-based sequences within log data has made it more feasible to interpret patterns in user performance during a computer-mediated task (see Owen & Baker, 2020). The digital log data from user game-play offers an unobtrusive means to gather insights about a player's performance (Homer, Ober, & Plass, 2018), and has been used to develop prediction models that formatively assess learner knowledge (Alonso-Fernández, Calvo-Morata, Freire, Martínez-Ortizet, & Fernández-Manjón, 2019).

In addition to being an unobtrusive means of assessing learner knowledge, digital log data can be used to make educational computer games highly adaptive. A recent meta-analysis found that many computer-based adaptive educational systems are designed to identify a learner's personal traits in the learning environment, as well as their content knowledge and progress (Normadhi et al., 2019), accommodating the needs of the learner in achieving content mastery. Machine learning approaches are more suitable for analyzing digital log data than traditional methods, especially when data reduction is necessary. Machine learning has been used to solve problems in understanding latent groupings within a set of observations in situations both when the groupings are known (i.e., supervised learning) and when they are not known (i.e., unsupervised). The use of machine learning is becoming more common in educational research. For example, machine learning has been used to identify problem-solving behavior in the context of computerized large-scale international assessments (Greif, Wüstenberg, & Avvisat, 2015; Kroehne & Goldhammer, 2018). With regard to digital log data within the context of educational games, there is a growing interest in examining machine learning applications for assessment of learner performance (Gibson & Clarke-Midura, 2015; Ke & Shute, 2015).

4. Research objectives
The goal of the current study was to examine the feasibility of using log data from a digital cognitive skills training game to better understand how different patterns of in-game activities related to learner outcomes. We sought to identify patterns of engagement during an intervention study examining the efficacy of a game-based cognitive skills training paradigm. We were especially interested in applying data-driven approaches to identify cases where lack of fidelity to the treatment is a concern. As an exploratory study, we aimed to address the following questions:

•
RQ1: Can distinct classes based on participants' within-game performance be detected over the course of an intervention?

•
RQ2: Is there an association between these classes and participants' improvement in performance on standard measures of inhibitory control, after accounting for key demographic factors (i.e., age, gender, language background)?

5. Method
5.1. Participants
Participants (N = 163) were middle and high school students from the greater New York City metropolitan area between the ages of 12–18 years (Mage = 14.1 years, SDage = 1.3, 50.7% female). The participants were recruited through a collaboration between researchers and schools during the 2018–2019 academic year, which allowed for participation in the intervention study in schools during non-instructional time. Prior to any data collection, and in order to be eligible for the study, all participants were required to have completed necessary parental consent and assent documentation.

The sample appeared to be culturally and economically diverse. Self-reported ethnicity among the sample was as follows: 76.1% identified as Hispanic/Latinx, 5.1% identified as Black/African American, 2.2% as White/European American, 0.7% as Middle Eastern, and 15.3% identified according to more than one category. We asked respondents to indicate their mother's highest educational attainment as a proxy of socio-economic status. Of those who responded, 30.2% indicated their mother's highest educational attainment was less than a high school degree, 27.6% indicated a high school diploma was the highest education attained, 18.4% indicated some college, 11.8% indicated finished college, with the remaining 11.9% having some graduate or professional degree training.

In addition to being culturally and economically diverse, the sample was also linguistically diverse: 53.5% reported speaking Spanish at home, 43.7% reported speaking English, and the remaining sample spoke languages including Arabic and Chinese (Mandarin). In the context of the present study, we examined speakers who were monolingual English speaking in contrast to non-monolingual English-speakers. Given the large proportion of respondents who indicated Spanish was the language spoken at home, and thus might be more inclined to use language-switching on a regular basis, we also entered a dichotomous variable indicating whether the respondent spoke Spanish at home or not.

5.2. Materials and measures
5.2.1. Flanker task
As an independent measure of inhibitory control, a version of the Flanker task (Eriksen, 1995) was administered during the pre and posttest session. Participants were shown a row of arrows after having been previously instructed to press keys indicating the direction of a target arrow in the center of the screen, ignoring the direction of surrounding arrows which “flanked” the target. During trials where flanking arrows are pointing in an incongruent manner with the target arrow, participants tend to slow down or produce more errors. A total of 25 trials, with 16 congruent and 9 incongruent trials, were presented in a pre-specified order. From this task, two scores were calculated according to the National Institute for Health (NIH) Toolbox scoring procedure (Zelazo et al., 2013): a reaction time score and an accuracy score. The reaction time and accuracy scores were calculated as follows:
 

Accuracy score = 0.125 * (Number of correct responses).

5.2.2. Inhibitory control training game: gwakkamole
The game, Gwakkamole1, was designed to have similar cognitive demands as the Go/No-Go task, which is a commonly used measure of inhibitory control (Gomez, Ratcliff, & Perea, 2007). In this game, targets were avocado-like characters that were “squished” into guacamole as they appeared (i.e., clicking on the target), see Fig. 1. Such targets were therefore meant to elicit a “Go” response. Non-targets had the same basic shape, but wore hats or carried objects to signal that they were not to be touched, thus similar to the “No-go” response. For a more detailed description of the game, see Homer, Ober, Rose, MacNamara, Mayer, and Plass (2019). During each brief level, participants had to correctly hit as many targets as possible, and not hit the deceptive non-targets.

Fig. 1
Download : Download high-res image (245KB)
Download : Download full-size image
Fig. 1. Four distinct target types presented to players in the Gwakkamole game.

Game levels would get harder over the course of playing the game. More advanced levels of the game introduce a delay: participants must wait for a hat to be removed, for example, before the target could be successfully hit.

Game log data. Digital log data was recorded during game-play, and included information about the target type (non-delay or delay, target or non-target), the response type (hit, incorrect, or miss), and the reaction time of the response to the target. Since the target types change the nature of reaction time information, we excluded delay trials from the analyses. We chose to examine the first four sessions of the intervention for the practical reason that not all participants completed six sessions. This also resulted in a model that could be sensitive enough to find differences in patterns of within-game performance prior to the end of the intervention.

Game levels tended to be very short in duration, so were thus grouped into bins of 5 game levels with similar affordances (i.e., the speed of avocado movement and complexity of rules governing correct responses). In the design of the game, this binning of levels was referred to as “game worlds.” Each game world began in the same manner with a set of completely visual instructions presented to the user, designed without emphasis on speed or accuracy.

Reaction time. The time difference between the appearance of the first pixel of a target onscreen and the response of a participant in the form of clicking the target was logged and used as a measure of reaction time. Reaction time was logged in fractions of a second and the raw reaction time was used. Larger reaction times indicate a slower speed of response. We excluded non-targets and non-delayed targets from analyses specifically involving reaction time, because we wanted to best ensure no confounds between target presentation and the activation of a participant's response.

Accuracy. As a measure of performance accuracy, we used d’ (“d-prime”), a common measure of sensitivity from signal detection theory (Stanislaw & Todorov, 1999), which compares the hit rate (where hitting the non-delayed target is a correct response) to the false alarm rate (where hitting the non-delayed non-target is an incorrect response). The d’ indicates the sensitivity of a participant's response, meaning a participant's ability to hit the target when a response was required, and inhibit hitting when no response was required. A greater value indicates a participant is more sensitive to detection of the targets.

5.3. Procedure
5.3.1. Data collection
Participants took part in a 4-week intervention study conducted in school during non-instructional time in the 2018–2019 academic year. All participants played a version of Gwakkamole, for about 15 min per week amounting to 60 min in total over the entire intervention. Before the first game session, participants completed a background questionnaire and the Flanker task as a pretest. After completing the 4-week intervention, participants completed the same Flanker task as a posttest. Participants progressed through the game at their own rate; even though all participants started at the same game level during the first session, they may have ended each session at different levels. Participants started each game session with the game level following the last game level they had completed in the previous game session. Project materials, including the instructions provided to students at the beginning of the pretest, game, and posttest sessions can be found in the Open Science Framework repository that accompanies that manuscript.2

Participants were randomly assigned to counterbalanced treatment conditions wherein they played Gwakkamole for about 15 minutes of a 30 minutesmini session at a time. In one condition, participants played Gwakkamole first during each session, followed by another cognitive skills training game for the next 15 min. The order of the games was reversed in the other condition. Though the treatment conditions were not central to the current study, we included a control variable adjusting for any effect of the treatment condition on the latent classifications. Given that the duration and administration of the 15-minutes game-session was equivalent across conditions, we did not anticipate an order effect.

5.3.2. Analysis
We were first interested in determining whether there were differences in participants’ patterns of performance over time (RQ1), and thus assumed a person-centered approach to understanding the relation between game-play and cognitive enhancement. Latent class mixture modeling is conceptually a combination of growth modeling and latent class analysis techniques (Proust-Lima, Philipps, & Liquet, 2017). Like traditional growth modeling, latent class mixture modeling estimates growth parameters based on repeated measures, but unlike growth modeling, it does not assume all individuals are drawn from a single observed population with common growth parameters (Wang & Bodner, 2007). Instead, the method identifies unobserved subpopulations in data, thereby providing separate growth models with unique parameters (i.e. intercept and slope), estimates of variance, and the influence of covariates (Jung & Wickrama, 2008; Wang & Bodner, 2007). The lcmm package (Proust-Lima et al., 2017) in the R statistical environment (R Core Team, 2019) was used to conduct the analyses using the linear link function. Mixed effects variables included the game session number, and covariates included the treatment condition and the game-level. Treatment condition refers to the order in which the game Gwakkamole was played, which was either before or after another cognitive skills game that was designed to target task-switching. All analyses were run with 100 iterations. The latent class mixture modeling procedure was run five times to test models with different numbers of latent classes (Cn = 2, 3, 4, 5, 6). We did not test for a one-classification solution since mixture models cannot be specified with only one group.

The evaluation of model fit was both a pragmatic process as well as a deterministic one. Model selection began by evaluating multiple model fit statistics. The most suitable model would be one which had the log-likelihood (LL) closest to zero, and the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) with the smallest values. Since it is recommended to select models based on substantive interpretability, utility, and classification diagnostics, the posterior classification of participants to groups was also considered (Muthén, 2003; Nylund-Gibson & Choi, 2018; Proust-Lima et al., 2017). After examining model fit statistics, we then examined the participants’ classification as well as the probability of being assigned to a particular latent class. Following the recommendation of Nylund, Asparouhov, and Muthén (2007), the BIC value was given precedence over the other fit indices. In addition, models with lower probabilities and one or fewer observations in some latent classes were to be rejected, even if they had the best LL, AIC and BIC values.

After establishing latent classification, we next sought to determine whether classification accounted for variation in improvement in inhibitory control after taking into consideration those same factors used as predictors in the prior analysis (RQ2). The first part of the post-hoc analyses was conducted using generalized linear models and probit ordinal logistic regression with the MASS package (Ripley et al., 2020) in the R statistical environment. In these models, we considered the mixed effect of school in which participants were enrolled. However, preliminary analysis revealed a conditional intra-class correlation (ICCconditional) of between 0.007 and 0.020, indicating that conditional on the fixed effects, clustering at this level explained between 0.7 and 2.0% of the variation in the outcome. Therefore, given the small amount of variation explained by grouping at the school-level, we proceeded with fixed-effects only analysis.

The second part of the post-hoc analyses involved modeling the Flanker NIH change score (change score = post score - pretest score) with both reaction time and accuracy as outcomes. These analyses were conducted as simple linear models in R. As in the previous set of analyses, school was entered as a fixed effect. Additional covariates in the present model were the same as those entered as predictors in the previous one, and included the participant's age, gender, language background (English or other, Spanish or other) and performance as measured by the Flanker NIH score. After accounting for these covariates, we wanted to see whether the change in Flanker NIH score from pre-to post-intervention was associated with latent classification as determined in the previous stage of analysis.

6. Results
As stated previously, the analysis can be broken down into two stages. The first stage was conducted to find and characterize latent classes using in-game reaction time and response accuracy measures (RQ1). The second stage of the analysis was conducted to determine whether classification accounted for variation in improvement in the target skill of inhibitory control as measured by the Flanker task, after taking into consideration certain demographic factors (i.e., age, gender, language background) (RQ2). Prior to the analyses, data was inspected to ensure that accuracy and reaction time outcomes were approximately normally distributed, both having skew close to 0 and kurtosis around 3 (Cain, Zhang, & Yuan, 2017).

6.1. Latent class mixture models
The first stage of analysis involved identifying latent classes based on reaction times of participant responses in the game-log data (RQ1).

6.1.1. Reaction time
A measure of reaction time was derived from the non-delayed (normal) targets (nobservations = 4019). The latent class analyses using the non-delayed (normal) target reaction time as an outcome converged and the fit indices for each of the five models are shown in Table 1.


Table 1. Model fit statistics with different numbers of latent classes based on Gwakkamole reaction-time.

Number of Classes Cn	LL	AIC	AIC Difference Cn-Cn-1	BIC	BIC Difference Cn-Cn-1
C2	2310.644	−4589.288	–	−4539.788	–
C3	2310.644	−4583.288	6.000	−4524.507	15.281
C4	2310.644	−4577.288	6.000	−4509.226	15.281
C5	2314.283	−4578.566	−1.278	−4501.222	8.004
C6	2314.283	−4572.566	6.000	−4485.941	15.281
Note: The log-likelihood, AIC and BIC values of the selected model are bolded.

In the two-class model, 15 (9.2%) participants were assigned to Class 1 and 148 (90.8%) were assigned to Class 2. Table 2 summarizes the latent class sizes in terms of participant counts. Classes with zero matching participants may be a symptom of a relatively small number of participants and an overfitted mixture model (Lubke & Luningham, 2017). Since the number of groups was a researcher-provided parameter, the real participant data could not always match the resulting model parameters, producing classes with zero participants.


Table 2. Posterior class-membership for Gwakkamole reaction-time.

Number of Classes
Cn	Largest Class Size	Smallest Class Size	Mean Class Size
C2	148	15	81.5
C3	146	0	54.3
C4	145	0	40.8
C5	98	0	32.6
C6	76	0	27.2
Posterior class-membership probabilities refer to the probability that a particular participant belongs to a certain latent classification given the data available (Proust-Lima et al., 2017). Posterior class-membership probabilities were calculated using Bayes theorem. Table 3 reports the probability of participants being assigned to a particular latent class. Inspection of the posterior classification probabilities indicates that all classes had a mean posterior classification probability greater than 0.86. A perfect classification would produce a probability of 1 in each diagonal cell of the table and 0 elsewhere, with higher diagonal probabilities indicating good discrimination of the population (Proust-Lima et al., 2017). Thus, the two-class model provided generally good probabilities for the classification of participants in a latent class, given the present data.


Table 3. Mean of posterior class-membership probabilities in the two-class model for Gwakkamole reaction-time.

Class 1	Class 2
Class 1	0.8689	0.1311
Class 2	0.0193	0.9807
Fig. 2 shows the average reaction time trajectory of each latent classification over the game sessions. Class 1 consistently had longer reaction times across all sessions, indicating a slower response tendency. By contrast, Class 2 had faster and less variable reaction times across the different game sessions. For both classes, reaction times appeared to become longer as the participants progressed through the game sessions and game levels, likely due to the increasing complexity of the game.

Fig. 2
Download : Download high-res image (152KB)
Download : Download full-size image
Fig. 2. Line plot of average reaction-time for non-delayed (normal) targets over the different game sessions for the latent class mixture model with two classes.

Fig. 3 shows the average reaction time trajectory for both latent classes over each game world. Relatively few participants were able to advance beyond the sixth “game world,” and thus all game worlds completed beyond that (i.e., 7, 8, 9, 10) were grouped into the last category. As illustrated in Fig. 3, participants in Class 1 tended not to advance as far and had reaction times that were considerably longer and more variable than their peers in Class 2.

Fig. 3
Download : Download high-res image (149KB)
Download : Download full-size image
Fig. 3. Line plot of average reaction-time for non-delayed (normal) targets over the different game worlds for the latent class mixture model with two classes.

6.1.2. Accuracy
We next applied the same method in extracting latent classes from the data on accuracy (d’), the chosen indicator of sensitivity calculated based on the accuracy rates for the non-delay targets and non-targets (nobservations = 4,393).

Based on an inspection of fit indices, class size, and classification probabilities, the four-class solution appeared most viable, see Table 4. Although the six-class solution appeared to have the best fit according to LL and AIC indices, both indices favor complex models. The BIC indicated the simpler 4-class solution had the best fit, and penalizes model complexity more heavily. The 6-class solution also included classes of only 1 observation, which suggests the more complex model may be overfitting the data. Thus, we chose the simpler model. A total of 134 (82.2%) participants were assigned to Class 1, 9 (5.5%) participants were assigned to Class 2, 4 (2.5%) participants were assigned to Class 3, and 16 (9.8%) participants were assigned to Class 4. Table 5 summarizes the latent class sizes in terms of participant counts.


Table 4. Model fit statistics with different numbers of latent classes based on Gwakkamole d’.

Number of Classes
Cn	LL	AIC	AIC Difference
Cn-Cn-1	BIC	BIC Difference
Cn-Cn-1
C2	−6118.189	12258.380	–	12292.410	–
C3	−6104.460	12236.920	−21.460	12280.230	−12.180
C4	−6096.421	12226.840	−10.080	12279.440	−0.790
C5	−6103.867	12247.730	20.890	12309.610	30.170
C6	−6082.846	12211.690	−36.040	12282.850	−26.760
Note: The log-likelihood, AIC and BIC values of the selected model are bolded.


Table 5. Posterior class-membership for Gwakkamole d’.

Number of Classes
Cn	Largest Class Size	Smallest Class Size	Mean Class Size
C2	146	17	81.5
C3	134	13	54.3
C4	134	4	40.8
C5	132	0	32.6
C6	117	1	27.2
Posterior class-membership probabilities, which refer to the probability of participants being assigned to a particular latent class (Proust et al., 2017) are shown in Table 6. Inspection of the posterior classification probabilities indicates that all classes had mean posterior classification probabilities greater than 0.67, with the posterior probability lower for Class 4 relative to the other three classes. The four-class model provided generally good probabilities for the classification of participants in a latent class given the present data. The posterior probability of membership to Class 4 is lower than that of the other three classes, indicating that assignment to that class may be the least stable.


Table 6. Mean of posterior class-membership probabilities in the four-class model for Gwakkamole d’.

Class 1	Class 2	Class 3	Class 4
Class 1	0.943	0.013	0.018	0.027
Class 2	0.014	0.821	0.035	0.130
Class 3	0.118	0.003	0.880	0.000
Class 4	0.128	0.197	0.001	0.673
Graphical inspection of the trajectories of accuracy for the four classes revealed unique trends. Fig. 4 shows the line plot of the four-class model over the four game sessions. Fig. 5 shows the four-class model over the different game worlds. Following a slight decline between game session 1 and 2, Class 1 appears to have a relatively stable performance and appears to maintain a higher d’ (indicating better accuracy) compared with the other three classes across the intervention. Based on Fig. 5, Class 1 also appears on average to advance into higher game levels than the other two classes. Class 2 appears to have an average d’ that gradually decreases over the game sessions, likely as the game levels themselves become more challenging. In contrast to Class 2, which has a more gradual decline in performance, Class 3 has a more rapid decline in d’ over the game sessions. Relative to all of the other classifications, Class 4 appears to demonstrate a slight improvement in d’ performance over the course of the game sessions.

Fig. 4
Download : Download high-res image (183KB)
Download : Download full-size image
Fig. 4. Line plot of d’ over game sessions for the latent class mixture model with four classes.

Fig. 5
Download : Download high-res image (242KB)
Download : Download full-size image
Fig. 5. Line plot of d’ over game worlds for the latent class mixture model with four classes.

6.2. Latent classifications as predictors of change in inhibitory control
The second stage of the analysis was conducted to determine whether classification accounted for variation in improvement in inhibitory control, the target skill domain, after taking into consideration certain background factors (RQ2).

6.2.1. Descriptives of flanker NIH reaction time
For this analysis, we used the change from pre-to posttest of the Flanker NIH reaction time score as the outcome because it is also a measure of speeded responding. A positive reaction time score indicates a faster response tendency. The NIH reaction time scores from the pretest (M = 2.60, SD = 0.93) were not significantly different than the NIH reaction time scores on the posttest (M = 2.59, SD = 0.71) in a paired samples t-test, t(144) = −0.17, p = .86. The descriptives for age and the Flanker scores are shown for each latent classification in Table 7.


Table 7. Descriptives for Flanker task reaction-time scores per Gwakkamole reaction-time classification.

Class 1 (n = 15)	Class 2 (n = 148)
Mean	SD	Min	Max	Mean	SD	Min	Max
Age (Years)	16.10	1.21	14.00	18.61	13.81	1.11	12.04	17.37
Flanker NIH RT Pretest Score	2.55	0.65	1.53	3.62	2.60	0.95	0.00	5.00
Flanker NIH RT Posttest Score	2.32	0.58	1.44	3.00	2.63	0.80	0.00	3.80
Flanker NIH RT Change Score	−0.21	0.63	1.08	0.69	0.03	0.90	−3.76	2.97
Background variables as predictors of Gwakkamole reaction-time classification. We conducted a logistic regression with the latent classification based on reaction time as the outcome, see Table 8. Each predictor was entered into a cumulative link mixture model predicting participant classification (Class 1 or 2). The likelihood ratio χ2 was then examined to determine whether the predictor was indicative of the probability of membership in Class 1 vs Class 2. The likelihood ratio χ2 (LR χ2) reports the difference between the model without the variable (as a baseline comparison) and the χ2 with the variable included. The results of this analysis are shown in Table 8. Age was not found to be significant; however, Class 1 tended to comprise slightly older participants on average than Class 2, see Table 7. We also did not find a significant effect of participants’ gender or language background with respect to latent classification based on reaction time performance.


Table 8. Predicting Flanker NIH reaction time change score based on latent Gwakkamole reaction-time classification.

Classification (C2)
(N = 113)	Flanker NIH RT Change Score (N = 103)
df	LR χ2	p	df	F	p	
Covariates
 School	4	7.13	0.129	3	1.14	1.000
 Age (Years)	1	2.72	0.099ॱ	1	1.93	0.169
 Gender (Male=1)	1	1.84	0.175	1	2.57	0.112
 Language (English =1)	1	0.03	0.863	1	0.14	0.709
 Language (Spanish =1)	1	0.03	0.873	1	0.70	0.406
Flanker NIH RT Pretest Score	1	0.32	0.573	1	97.54	<.001***
Classification (C2)	–	–	–	1	5.70	0.019*
***p < .001, *p < .05, ॱ < 0.10.

Flanker reaction time performance as a function of Gwakkamole reaction-time classification. Next, we examined the same variables in addition to classification as predictors of the change score in the Flanker NIH reaction time score, see Table 8. As expected, NIH reaction time pretest score was significantly associated with the change in NIH reaction time score, t = −9.88, p < .001, η2partial = .512, such that those with higher initial scores tended to gain less. Though the change in participants’ Flanker NIH reaction time score was not statistically significant from 0 in either group (p > .05), there was nevertheless a significant difference between the two classes, after accounting for the other covariates, t = 2.39, p < .05, η2partial = .058. Class 2 appeared to show a more positive change than Class 1 members (see Table 7 for group means). This finding suggests that even after accounting for the other predictors in the model, there were significant differences in the amount of improvement from pre-to posttest on the Flanker NIH reaction time score as a function of the latent classification based on within-game reaction time performance.

6.2.2. Descriptives of flanker NIH accuracy
We wanted to see whether performance in terms of accuracy on the Flanker task was associated with the d’ latent classifications. The Flanker NIH accuracy scores on the posttest (M = 4.81, SD = 0.50) were significantly greater than the Flanker NIH accuracy scores on the pretest (M = 4.64, SD = 0.63), t(144) = −2.49, p = .01, thus indicating an average improvement in accuracy across the entire sample. The descriptives for age and the Flanker scores are shown per classification in Table 9.


Table 9. Descriptives for Flanker task accuracy scores per Gwakkamole d’ classification.

Class 1 (n = 134)	Class 2 (n = 9)	Class 3 (n = 4)	Class 4 (n = 16)
Mean	SD	Min	Max	Mean	SD	Min	Max	Mean	SD	Min	Max	Mean	SD	Min	Max
Age (Years)	13.92	1.22	12.04	18.61	15.58	1.16	13.69	16.54	13.66	1.40	12.29	15.42	15.02	1.78	12.37	17.37
Flanker NIH Accuracy Pretest Score	4.68	0.60	3	5	4.56	0.53	4	5	4.25	0.96	3	5	4.44	0.81	3	5
Flanker NIH Accuracy Posttest Score	4.79	0.55	3	5	4.75	0.46	4	5	4.75	0.50	3	5	4.67	0.62	3	5
Flanker NIH Accuracy Change Score	0.09	0.55	−2	2	0.12	0.64	−1	1	0.50	1.0	0	2	0.27	0.80	−1	2
Background variables as predictors of Gwakkamole d’ classification. We conducted logistic regression using the same set of covariates as the previous model. As in the previous model predicting latent classification based on reaction time performance, school significantly differed between the four classes. No other predictors significantly differed between classes.

Flanker accuracy performance as a function of Gwakkamole d’ classification. We then examined the same set of variables, in addition to classification, as predictors of the change score in the Flanker NIH accuracy score, see Table 10. We again found that the NIH pretest score, in this case measuring accuracy, was significantly associated with the change in the accuracy score from the pre-to the posttest, t = −7.90, p < .001, η2partial = .407, such that those with lower initial scores had greater gains in performance. There was also a significant effect of gender, t = −2.02, p < .05, η2partial = .043, indicating that females (Flanker NIH accuracy score change: M = 0.23, SD = 0.64) tended to demonstrate greater gains on the Flanker NIH accuracy score compared with males (Flanker NIH accuracy score change: M = 0.03, SD = 0.52). None of the other predictors including classification (C4) accounted for any variation in the Flanker NIH accuracy score change from pre-to posttest.


Table 10. Predicting Flanker NIH accuracy change score based on latent Gwakkamole accuracy classification.

Classification (C4)
(N = 113)	Flanker NIH Accuracy Change Score (N = 103)
df	LR χ2	p	df	F	p	
Covariates
 School	4	10.45	0.034*	3	0.37	0.774
 Age (Years)	1	0.02	0.887	1	0.05	0.827
 Gender (Male=1)	1	0.19	0.660	1	4.06	0.047*
 Language (English =1)	1	0.61	0.437	1	0.52	0.472
 Language (Spanish =1)	1	0.42	0.516	1	0.33	0.565
Flanker NIH Accuracy
Pretest Score	1	0.56	0.454	1	62.41	<.001***
Classification (C4)	–	–	–	3	0.59	0.624
***p < .001, *p < .05.

7. Discussion
Past research on the effectiveness of computerized training interventions for improving learners' cognitive skills has yielded inconsistent findings (e.g., Jacob & Parkinson, 2015; Simons et al., 2016). One source of variation in these findings may be the extent to which learners maintain active engagement over the course of the training (Gathercole et al., 2012). The motivation of the current study was to examine the viability of using data-driven approaches for analyzing digital log data to identify patterns of engagement within the context of these kinds of training interventions. First, we wanted to determine whether distinct classes based on participants' within-game performance could be detected over the course of an intervention (RQ1). Latent class mixture modeling was used to determine different patterns of performance based on reaction time and accuracy of responses in an intervention study with a computerized cognitive skills training game. Subsequently, we wanted to establish whether there was an association between such classes and participants' improvement in performance on standard measures of inhibitory control, after accounting for key demographic factors (RQ2). Further analyses indicated that the classification associated with speed of response in the game, but not with accuracy, was associated with improvement in performance on a transfer task of inhibitory control, the targeted cognitive skill. This approach, which can be considered a “stealth assessment” because it is unobtrusive and informative of learner's progress (Shute & Kim, 2014). It further sheds light on how detecting patterns of performance that are otherwise unobserved by aggregate statistical summaries can be informative about learner progress. Our hope is that this approach will contribute to a growing understanding of the use of digital log data to interpret behaviors and can be used to improve the design of such interventions.

Overall participants did not show consistent improvement on the Flanker test before and after the intervention; however, there was evidence of change for a subset of participants. Participants in Class 2, who tended to have faster reaction times at the beginning of the study, appeared to demonstrate improvements in the reaction time performance on a standard measure of inhibitory control. This finding stands in contrast to the long-held belief that students who are furthest behind their peers also have the greatest to potentially gain from such interventions (e.g., Holmes & Gathercole, 2014). Our findings suggest that students who are faster in their responses at the onset of the intervention actually gained the most. Students with slower response times may initially struggle with a time-based activity, thus driving the differences in the efficacy of the intervention we see between these two classes. Adding levels with slower targets, or adapting difficulty based on performance in the game, could support students with slower response times at the beginning of the intervention (Plass, Homer, Pawar, et al., 2019). Another possibility is that these students were learning, though the current measures were not sensitive enough to detect any change. According to multiple theories of human development, such as the utilization deficiency hypothesis (Bjorklund, Coyle, & Gaultney, 1992), as well as the overlapping waves theory (Siegler, 2016), learners in a transitional phase will often fail to demonstrate proficiency of a particular strategy or skill even though they are indeed learning. Thus, members in the classification of slower responders within the game may indeed be improving the requisite skills that lead to improved response times. However, without a delayed posttest such a conclusion is outside the scope of the present study and remains speculative.

In contrast to the latent classes based on reaction time, the latent classes based on within-game d’ were not significantly associated with changes in accuracy. Accuracy is thought to develop slightly earlier in adolescence, prior to speed of responding (Luna et al., 2004). As such, there may have been less variation in accuracy between participants as there was on the basis of reaction time. Interestingly, gender appeared to account for some variation in the change score in accuracy on the Flanker task, suggesting that females tended to improve more than males on this particular measure of accuracy. These findings build on prior research suggesting differential gains in performance with respect to speed and accuracy of cognitive skills training between males and females in adolescence. While Dorfberger, Adi-Japha, and Karni (2009) found male adolescents improved in speed of responding following training though females did not, in the present study, gender differences were not found with respect to improvements in reaction time performance on the Flanker task. Instead, we found that while conditioning on the other predictors in the model (see Table 10), females were more likely than males to improve in Flanker accuracy performance following training.

7.1. Limitations
As is the case for any empirical investigation, there are limitations that should be noted in the current study. Aspects of the game design itself may be driving some of the results found in the present study. In the context of the present Gwakkamole game, one potential source of variation in game-play experience could be the game level design. Learners advanced to the next level only if they were able to meet accuracy criteria in performance; learners who did not meet criteria repeated the level. This is an issue with any adaptive intervention - learners who do better receive a more challenging training. One possible means to control for such differences is the use of a benchmarking game level, where the parameters of difficulty are the same at each encounter, to provide a consistent point for comparing performance both between individual learners, as well as within the same learner at different time points.

In addition to game design, there are research design issues related to the consistency of the dose of game-play (i.e., amount of time) between participants. Past research has pointed towards the dose of the intervention as one potential source of the inconsistency of findings of cognitive skills intervention (Bediou et al., 2018). While we attempted to control for this by restricting the analytical sample to participants who had completed at least four game sessions, there was variation in the precise amount of cumulative game-play time, and there may have been inconsistencies in the quality of engagement during each game session.

The data-driven approach to classification used here means the present solution may not be the only viable grouping of these data (Domingos, 2012). Given the complexity of the game parameters and participant responses, it is possible that a finite number of groupings could not be well represented given the current relatively small sample size. As such, there are some obvious limitations in drawing inferences about the causal nature of the associations between game play and changes in inhibitory control outside the context of the game used in the present study.

While the study sample is diverse in many respects, it remains possible that the participants and their parents who opted to take part in the study are also more likely to favorably view games for learning. The sample may not be representative of other populations of adolescent learners, and future work should seek to replicate the findings presented here on different adolescent populations. Another factor threatening the generalizability of these findings stems from whether or not certain students had underlying learning or attentional control differences. In 2018–2019, about 5% of all public school students received federally supported special education services for specific learning disabilities (National Center for Education Statistics NCES. U.S. Department of Education, 2020). Therefore, it is not unreasonable to expect that a small percentage of the sample here may have had a documented learning disability. Particularly for classifications with fewer members, it does raise questions about whether there were fundamental differences not only in students’ performance on the task, but also related to other factors affecting cognitive performance such as a learning difficulty. For example, Mawejee et al. (2017) found that deviations in game-play in a computerized working memory training intervention were not necessarily due to deliberate lack of engagement, but rather differences in EF and related attentional skills relative to peers. While not considered outliers in the present study, further work on analyzing and interpreting log data should strive to account for such differences.

There are several additional limitations in interpreting the efficacy of efforts to train cognitive skills. First, we stress that the associations between latent classes based on game-play performance and changes in performance on standard measures of cognitive skills described within the present study are correlational (Simons et al., 2016). Second, the associations found between latent classes and changes in performance on standard measures of cognitive skills were both derived from measures administered in a computer-mediated setting (Green et al., 2019). Thus, we still do not know whether these latent classes could be explained by another factor, such as computer experience or self-efficacy. Third, the present study also did not assess the rate of retention and whether such groups were still present if delayed (e.g., one month following treatment) game session or posttest had been used as an additional data collection time. Therefore, it is not clear whether the current groupings would explain any sustained improvements over the long-term, nor whether the current latent classes assignments found in the present study would remain unchanged if more data were collected. Further research should address some of these issues by recruiting a large and diverse sample, administering a variety of standardized cognitive tasks in multiple response modalities, and conducting a delayed posttest.

8. Conclusion
Latent class mixture modeling appears to be a viable method for revealing distinct patterns in participants' within-game performance in terms of reaction time and accuracy as measured by d’. After accounting for participant background factors, classification based on reaction time, but not accuracy, was associated with improvement in a standardized measure of inhibitory control. As our findings suggest, more work is needed to support participants with lower initial EF skills at the onset of the intervention, as such early differences in engagement may lead to long-term deviations from patterns of engagement that correlate with improved EF skills, particularly on measures of response time.

Our current findings suggest that latent class mixture model analyses may be one effective means to identify patterns in engagement in a game-based cognitive skills intervention such as those designed to enhance EF skills. In addition, better and ongoing metrics of performance may be developed that can formatively assess student progress within the context of the game (Shute & Kim, 2014) and could be used to develop objective game-based measure of cognitive skills (Homer, Ober, & Plass, 2018). Future work that links behavioral indicators from metrics extracted from computer log data to measures such as self-report could provide a better understanding of its utility (e.g., Ober, Hong, Rebouças, Carter, Liu, & Cheng, under review). Finally, real-time results of the games metrics could be used to adjust the level of difficulty of the game in order to enhance the efficacy of training (Holmes, Gathercole, & Dunning, 2009; Plass & Pawar, 2020). Ultimately, we hope our findings provide some evidence that machine learning approaches can be a useful tool for the analysis of complex logs of user behavior in intervention studies as they may uncover systematic differences in engagement with cognitive skills interventions.