Commonly, the network configuration leans upon the operators’ experience to operate network, including command-line configuration, middle-ware scripts, and troubleshooting. However, with the rise of neoteric B5G services, the manual way lacks flexibility and timeliness, resulting in an unsatisfactory level of configuration. It is necessary to consider a manual free configuration way for transport network. To cope with this problem, we present an intent-driven network architecture with self-adapting slicing policy and slices reconfiguration in an intent-orient manner. Aiming at intent request, intent analysis based on latent dirichlet allocation is introduced to establish the semantic graph to comprehend and enact the required slicing configuration language, namely intent translation. Then, in line with intent translation, we propose a self-adapted slicing policy generation and optimization base on deep reinforcement learning (SPG-RL) to find combined strategies that meet the intent requirements by dynamically integrating fine-grained slicing policies. Finally, deep neural evolution network (DNEN)-assisted model (SPG-RL-DNEN) is introduced to locate the incompatible slices at the millisecond level for slicing reconfiguration. When the network entropy reaches the threshold, SPG-RL-DNEN would reconfigure the incompatible slices for intent guarantee. The efficiency of our proposal are verified on enhanced SDN testbed.

Previous
Next 
Index Terms
Intent-driven network

Network slicing

Slices reconfiguration

1. Introduction
Due to the highly dynamic and variable services in beyond 5G (B5G) era, which have different network requirements, the network needs end-to-end slicing to deal with differentiated services (Zhou et al., 2016). The slice-based network architecture will be the basic capability requirement of the transport network. With flexible spectrum allocation mechanism in term of network slicing, elastic optical network (EON) has the capacity to support user-defined dynamic service provision at the optical layer. EON has become one of the most attractive solutions to the challenges of next-generation networks (Oliveira and da Fonseca, 2019). The EON combined with slicing technology allows users to enjoy connection and data processing that meets the specific service requirements stipulated in the service level agreement (SLA). With the continuous development of technologies and the rapid evolution of standards, slicing brings flexibility to the network and increases the complexity of management (Guan et al., 2018).

Meanwhile, there are more and more emerging services requiring time-critical interaction with dynamic environments and expectation from users (Kohler et al., 2018). For instance, automatic drive involves sensor data stream delivery to the specified domain and expectation of reliable performance for the transport network. In B5G scenario, users care more about the achievement of configuration, rather than the procedure of configuring operation on the network. These emerging services just supply with the expected goal without specified network configuration parameters (Saha et al., 2018). From the perspective of operators, the desired goal of service is regarded as intent, which is represented as a high-level intent description for intent-driven networking (Ejaz et al., 2020). In addition, software-defined optical networking (SDON) and network function virtualization (NFV) implement the software of the network. Software of the network makes it possible for operators to allow users to customize their own logical network slices in line with their own intent (Yang et al., 2016a). SDON can provide a global view of the network and programmable network control. With NFV, network functions and resources are no longer limited to dedicated physical network infrastructure. From above discussion, the ultimate goal of intent-driven networking is to achieve requirements of intent services through creating and maintaining its unique network slice. To the best of our knowledge, intent-driven slicing configuration and guarantee through slices reconfiguration problem of the intent goal has been not solved, peculiarly in the optical transport network (Yang et al., 2019a).

On the other hand, artificial intelligence (AI)-enhanced automatic operation and maintenance, driven by full process modeling, provides the capacity to achieve flexible matching of service demands and network resources to meet the demands of rapid customization and deployment (Chen et al., 2020), (Yang et al., 2016b). In addition, considering the characteristics and advantages of slicing technology, the B5G network can solve the problem of intent-driven network from the perspective of dynamic slicing (Zhou et al., 2016) (Samdanis et al., 2016). It means that a unified and intelligent system is needed to achieve end-to-end orchestration management of slicing for intent requests (Yang et al., 2020a). AI technology provides the network controller with the capability to automated continuous analysis and learning for promotion without being explicitly programmed (Yang et al., 2019), (Yang, 2021) (Gupta and Raskar, 2018). It can help to automatically generate network slicing configuration policies, self-healing slices reconfiguration policies, and support continuous optimization of policies.

1.1. Related work
There has been a lot of work on intent-driven networking. Reference (Kiran et al., 2018) presents the iNDIRA tool to parse intent for enabling intent-based networking. Reference (Chen Haoet al., 2016) detects user emotions through an emotion detection network, performs emotion matching processing, and uses singular value decomposition (SVD) and latent semantic indexing (LSI) to identify user intent, thereby enhancing quality of experience (QoE) of users. In (Yang Yuanet al., 2020), the graphical abstraction of strategy (PGA) is proposed, which describes the intent in the form of a graph. By labeling each endpoint, each label represents a group, and there are inclusions or conflicts between groups. In the open source community, there are also many new network designs around intent-based networks. The open source project GBP (Group-Based Policy) is different from SDN that provides users with low-level operational interfaces for creating networks, routes, subnets, etc. GBP is based on the “group” granularity policy model, by providing users with more advanced abstractions. Directly oriented to application deployment, rather than various network elements in neutron, it is convenient for users to directly express their intent requests (Rustogi, 2018). The core modules of GBP include policy targets and policy target groups, policy rules and policy rule sets, actions, and classifiers. When using GBP, users define various “groups” and network characteristics between “groups”, including security, performance, and network services. Among them, the intent can be edited through RESTFul API or Web interface. In order to speed up the standardization of the Northbound Interface (NBI), ONF released the white paper “Intent NBI-Definition and Principles”, which is the first document describing intent-based NBI (Janz, 2016). The document elaborates the definition of the intent-based northbound interface, including the characteristics and basic architecture of the intent northbound interface. On this basis, literature (Pham and Hoang, 2016) proposed a three-tier application architecture based on micro-services and service-oriented design principles to achieve intent-based NBI. In addition, the Network Modeling (NEMO) project has developed a programming for network services as a new form of SDN northbound interface, and the language breaks the traditional “chimney-style” way of defining interfaces one by one based on scenes. The expression model based on intent summarizes a set of primitives for network services and implements any scene application through flexible combination description and deployment (Opendaylight, 2015). Congress is a framework based on heterogeneous cloud environment proposed by OpenStack and VMware, which uses intention to describe, monitor, deploy, and evaluate strategies (https://www.cisco.com/c/z). Congress obtains data from different services on the cloud, and then enters it into the Congress policy engine to verify that the services on the cloud operate as intended.

However, due to intent context, it is still hard to precisely convert intent description into slicing configuration language resulting an unsatisfactory level for intent goal without manual intervention (Kiran et al., 2018). Likewise, due to the complexity of the slicing operation and heterogeneity of multiple domains, the problem of closed-loop slicing configuration policy is unsolved yet after intent translation (Aguado et al., 2016). Besides, due to the complexity and dynamics of the network, in case of incompatible, closed-loop slices reconfiguration for intent guarantee and efficiency of resource is equally critical (Triki et al., 2019), (Yu et al., 2019). The above problems are the keys for the implementation of intent-driven optical network (IDON) in all-life-cycle maintenance. Our previous work in Yang et al., (2020b) starts from the intent itself, and introduces AI approaches to solve the problem of rigid network configuration, not involving the network slices to adapt to the B5G services.

In this paper, considering the rise of neoteric B5G services, we study the intent-driven optical network slicing and slices reconfiguration problem in SDN-enabled networks. First, we present an overall IDON architecture, including intent translation, slicing policy autogeneration, and slices reconfiguration for intent guarantee. Then, to perform intent translation, intent analysis based on latent dirichlet allocation (IA-LDA) is introduced to accurately establish a semantic graph to comprehend and translate the required slicing configuration language. Then, according to translation result, self-adapted slicing policy generation base on deep reinforcement learning (SPG-RL) is utilized to make the decision of slicing policy that meet the intent requirements by dynamically integrating fine-grained slicing policies. At the end, deep neural evolution network (DNEN)-assisted incompatible slices position model is utilized to locate the incompatible slices at the millisecond level for slicing reconfiguration. When network congestion entropy reaches the threshold, SPG-RL-DNEN would reconfigure the incompatible slices for intent guarantee. In summary, the novelty of the proposal can be three points which are the intent-driven IDON architecture combining with the user intent and network slicing, automatic intent slicing configuration based on the deep deterministic policy gradient (DDPG) model, and DNEN-based slicing reconfiguration algorithm for intent guarantee.

1.2. Motivation
In the B5G era, there are various application scenarios and service types, such as large-scale Internet of Things (IoT) services, unmanned driving, industrial automation and other services requiring low latency and high reliability of connection. The network requirements of the above services are very strict, and these services are generated by users.

Users will become the main object of concern in B5G scenario. In order to simplify the user's operation as much as possible, the network can be triggered to automatically complete a series of operations by directly entering what the user wants to do, namely the intent.

From the perspective of network, it is necessary to provide users with all kinds of network resources they need flexibly in order to realize the user's intent. Network slicing technology enables operators to separate multiple virtual end-to-end networks on a unified infrastructure through on-demand networking. Each network slice is logically isolated from the wireless access network to the core network to adapt to various types of applications. Therefore, the intent-driven slicing scheme can flexibly allocate the intended slicing resources from the user's perspective, to ensure user's network requirements.

In general, the motivations of IDON are listed as follows.

●
Accuracy of intent translation and adaptability of intent-orient slicing policy. In spite of the diversity of intent request and the complexity of slicing operation procedures, the intent requests ought to be precisely converted into slicing configuration language with assistance of AI. Meanwhile, due to the complexity and dynamic of the network, it is hard to work out slicing policy to adapt to the variation of the network environment in line with the result of intent translation.

●
Intent guarantee in case of incompatibility and fault. Since slicing involves heterogeneous resources in multiple domains, once the intent is violated due to the changes and failures of network, it will be difficult to timely perform small-scale slices reconfiguration for self-healing (Kokkinos et al., 2019). Hence, in case of low efficiency of resource utilization and fault. It is troublesome to guarantee the utilization efficiency and effective implementation of the intent.

1.3. Contribution
The main contributions of our work can be summarized as follows.

●
We develop IA-LDA model to build the internal relationship between characteristics of intent service request and network performance. The mapping relation model is constructed to realize the rapid extraction of diversified characteristics of different intent, accurately identify intent request, and form a standardized expression of intent, so as to provide basis for slicing policy.

●
We construct a self-adapted slicing policy generation and optimization model SPG-RL-DNEN through integrating multiple fine-grained slicing policies in a closed-loop automatic manner.

●
To perform slicing reconfiguration for intent guarantee, we propose a DNEN-assisted position model for incompatible slices location. The DNEN is used to effectively deal with the incompatible slices location problems in optical network. Then, the position result is returned to SPG-RL-DNEN for incompatible slices reconfiguration, maximizing the guarantee of intent and realizing the complete closed loop of intent control.

The reminder of this article is organized as follows. Section II presents the network model. In Section III, we propose our SPG-DNEN algorithm and verify its effectiveness in Section IV. Finally, Section V concludes the paper.

2. Network model
The underlying optical transport network topology is represented as G (N, L, F, C, S), where N = {n1,n2, …, nm} represents the set of nodes, L = { lij |ni, nj  N } is on behalf of the fiber links, and lij represents the one-hop connection between nodes ni and nj. F = {Fs,t |s,t} denotes the state of the frequency slots (FS) on each fiber link. C = {Ci | ni}denotes the processing capacity of node ni including a collection of computing resources. S = {Si | ni} is the storage capacity of node ni.

The quality of intent service is measured by Quality of Service (QoS). The QoS evaluation system specifically includes parameters such as network bandwidth, delay, packet loss rate, and jitter. It is a numerical evaluation that objectively reflects the performance of network transmission (Yang et al., 2015). Currently, there is a lack of the ability to create complex mapping steps between intent requests and slicing QoS requirements (Kiran et al., 2018). It is necessary to define more structured network slicing requirement of intent services. Requirements of intent services may include traffic capacity, isolation, end-to-end delay, user density, priority level, service availability, service reachability, rate, etc. The basic information describing the network slice instance of intent service should include the resource model information and the management model information. The former describes the functional components and static parameters of the slice including ID, slice type, additional system characteristics (such as multicast, edge computing, etc.), priority, SLA model (such as bandwidth, delay, forwarding capability, etc.), etc (Yang et al., 2019b), (Yang et al., 2016c), (Yao and Yang, 2021), (Yang, 2019). The latter indicates slices lifecycle management, including configuration files such as application configuration parameters, etc (Yang, 2021). Specifically, slicing QoS requirements will be mapped to the network performance indicators (NPIs) which include blocking probability, load balancing, delay, etc. In particular, indicators with greater influence on intent service are selected from QoS metrics to be the components of NPI. For example, if the indicators such as delay, jitter and packet loss have a greater impact on the intent satisfaction, then these indicators will be selected as NPI components.

When the SDN/NFV receives the requirements of intent service, it creates new or reuses existing network slice instances to satisfy the communication demands of intent requests. According to (Raza et al., 2019), the slicing configuration of the transport network can be granulated into many fine-grained slicing policies. These fine-grained policies can be mainly categorized into three categories based on the way of their affection on the performance of the optical transport network, including storage resource slicing, computing resource slicing, and spectrum slicing Marquez et al., (2019). From the above discussion, the intent request can be modeled as 
 , where s and d respectively represent the source node and destination node. b, m, and c denote the bandwidth, storage, and computing requirement, respectively.

3. Intent closed-loop slicing configuration
3.1. Overview
Step 1: intent parse. The intent request service needs to be converted into the slicing configuration language understood by the controller. In section IV.B, we present the Intent Analysis based on Latent Dirichlet Allocation (IA-LDA) keyword extraction algorithm based on the topic model of the optical network. In addition, it is also necessary to encapsulate the intent keyword information into a standard data model based on the experience database, namely intent request message, which serves as the bridge between intent and slicing policy generation. The formation of experience database refers to (Li et al., 2015). (①②).

Step 2: slicing policy. Under the constraints of the above intent translation, Section IV.C illustrates a slicing policy generation algorithm based on reinforcement learning (SPG-RL). Considering constraints of intent request as reward part of SPG-RL, SPG-RL can set up slicing configuration through integrating fine-grained policies to satisfy the intent request. Meanwhile, on the premise of a satisfactory intent request, SPG-RL would improve network resource utilization as much as possible through taking network performance into consideration. (③④⑤).

Step 3: intent guarantee. Moreover, due to the dynamic nature of the network environment, the slicing policy may not be suitable for the current environment. Section IV.D proposes a high-precision unsuitable slices positioning algorithm, namely DNEN, to locate incompatible slices, and then recycle SPG-RL to perform slices reconfiguration. (⑥⑦⑧⑨).

In our proposal, Step2 is the slicing policy generation based on DDPG algorithm. Step3 is intent guarantee involving DNEN-based slices location. In this step, the location results on incompatible slices will be fed back to DDPG. Specifically, the results will be the NPI related information of the incompatible slices. In other words, DDPG interacts with DNEN through NPI information. The NPI information of the slices located by DNEN will be used as the input of DDPG for slice reconfiguration.

In the proposed IDON architecture, by combining RL and DNEN, the intent-based slicing policy generation and reconfiguration process can be well realized to better meet the users’ requirements.

3.2. Translation between intent and slicing configurable language
IDON does not need to focus on all aspects of user intentions, but only needs to focus on a small number of keywords related to the network. Therefore, this section uses the keyword extraction algorithm based on optical network topic model called IA-LDA. The core of IA-LDA is to use the nature of the topic distribution in the optical network topic model to extract keywords and construct an intent theme model. The intent issued by the users is a mixed distribution of certain topics, and the topic is also a probability distribution of vocabulary. As long as the intent topic is found, the representative word in the topic is the core meaning of this intent, which is the keyword of the topic.

In the IA-LDA model, each intent issued by the user is a probability distribution composed of several topics, including expected or constrained intentions. Meanwhile, both the probability distribution composed of topics and the probability distribution composed of keywords obey Dirichlet prior distribution. The IA-LDA probability model is shown in Fig. 2 where  and  are the hyper parameters of the prior distribution, and  is the probability distribution of the vocabulary under the kth topic.  is the topic distribution of intent, w is the result of intent word segmentation, and z is the topic corresponding to w.

Fig. 2

Fig. 2. LDA probabilistic model.

IA-LDA randomly gives the value of topic probability, iteratively executes until convergence, and finally outputs valid keyword information. The IA-LDA algorithm flow is given as below.

(a)
The ith word in the input intention I is wi. If the corresponding subject of the word is zj, the probability distribution in the intent text can be calculated by the formula p(wi |I) = p(wi | zj)∗ p(zj |I).

(b)
Repeat step (1) to calculate the probability distribution p(wi |I)1, p(wi |I)2, …, p(wi |I)k, of wi corresponding to k topics, and select the topic with the highest probability value, which is the topic with the highest correlation with wi.

(c)
If the topic corresponding to wi obtained in (b) is different from the initial topic probability , it will in turn affect the value of . Repeat the above process until convergence.

Moreover, we also need to encapsulate the intent keyword information into a standard data model based on the experience database, namely intent request message, which serves as constraints of intent QoS. Experience database contains the mapping relationship between the current diversified services keywords and various network indicators in detail.

3.3. Deep reinforcement learning for automatic intent slicing configuration
In this section, we mainly present automatic intent slicing configuration process based on deep reinforcement learning (DRL). Especially, considering the continuity of slicing actions, we illustrate the slicing policy generation algorithm based on the deep deterministic policy gradient model which can cope with high-dimensional input, realize end-to-end control, and can output continuous actions. In the optical transport network, more than 100 fine-grained slicing configuration policies are available for the slicing configuration. In this case, the DDPG is an effective solution as a result of its excellent enhancing component action characteristics (Chen et al., 2019). In addition, it needs to be noted that the essence of the slicing policy generation mechanism is to find a combination that meets the requirements of intent service by dynamically integrating fine-grained slicing policies (Aguado et al., 2016), (Yang et al., 2016c). The purpose of DDPG is to find a suitable component strategy to best satisfy the requirements of user intent. The number of slicing configurable parameters dramatically increases the state's space, leading to the possibility of state explosion. It would cause significant overhead. Meanwhile, some of slicing parameters are more significant than others in impacting the performance. To increase the feasibility of automatic slicing configuration using the DDPG-based approach, we only consider the most performance-significant parameters including parameters for spectrum, computing and storage resource slices.

Environment, actions and rewards constitute the basic elements of reinforcement learning. Therefore, in the SPG-RL model, we first need to define the environment, actions and rewards (Yang et al., 2020c), (Zhu Liet al., 2021).

●
Environment, State Space, and Fine-grained policy. State s refers to the state of the network environment. The structure of intent request (Ir) contains multi-dimensional information such as objects, operations, results, etc., which can be used to represent the environment E. The state s can be formulated as (1), where (Ir1, Ir2, …, Irn) is a vector of Ir components.

(1)
A fine-grained policy implements the slicing of some functional nodes resource slicing. For instance, fine-grained strategies include spectrum slicing (SS), computing resource slicing (CRS), storage resource slicing (SRS), etc. These fine-grained policies related to NPI directly affect the various components of the network, including blocking probability, load balancing, delay, etc. NPI can be formulated as (2).(2)

●
Action Space. According to the logic of intent service, fine-grained policies are combined into a loose coupling, and extensible set of slicing policy, namely slicing action. An action involves three fine-grained policies, which can be formalized as A= (,  ), where , ,  correspond to the magnitude of the change in a certain component of NPI.

●
Reward Function. Slicing policy reward is the feedback function that is calculated after execute slicing policy. The goal of integrating the best slicing policy action is to search for the combination strategy with the highest slicing reward. Therefore, the criterion based on the combination of fine-grained strategies is to get as many rewards as possible.

In order to simplify the model, Ir is adopted with binary quantization as to whether the intent request is satisfied, indicated by VIri, which is shown in Eq. (3).(3)
 where Iri is the component of the Ir vector.

Due to the huge difference in the numerical value of each dimension index, it is necessary to normalize the NPI to facilitate the display of results. Here, we refer to the processing method of service QoS in (Montero Agrazet al., 2018), and the calculation of the quantized value is given as Eq. (4).(4)
 
where NPIi represents the value of one dimension of NPI, NPIil and NPIir respectively represent the boundary value of the dimension interval. Xl and Xr respectively represent the boundary value of the quantization value interval.

In Eq. (3), in order to verify whether the generated slicing policy satisfies the intent request Ir, the Ir threshold Ir0 needs to be specified. Literature (Suto Miyanabeet al., 2015) gives the impact of NPI performance metrics on Ir, shown in Eq. (5), where B, D, LB, and BR respectively represent the normalized values of bandwidth, delay, load balancing, and blocking probability after processing based on Eq. (4).(5)

The design of the reward function is presented in Eq. (6), where rs is the reward in state s. And dim(s) is the dimension of the s = (Ir1, Ir2, …, Irn) vector, related to the intent request Ir. The components of the NPI= (NPI1, NPI2, …, NPIn) are normalized by 
 as the penalty part of the reward function, which is related to the network performance metric NPI.(6)

From Eq. (6), the reward part of the reward function can be expanded into Eq. (7). When a certain component of the intended request Ir is satisfied, a positive feedback, which is less than or equal to the dimension of s, will be given. If the intent request is not satisfied, it would return 0.(7)
 
 
 

The penalty part rs,NPI in the reward function (6) is shown in Eq. (8). Since the NPI has a large difference in each dimension value, a normalization function is used to normalize the value of each dimension to the [0,1], avoiding the domination position of some metric. In addition, different weighting factors wj can be set for each dimension of NPI, shown in Eq. (9).(8)
(9)
☆

From the above definition of the reward function, it is necessary to constantly adjust the actions of the slicing policy and find a balance between Ir and NPI to maximize rewards.

DDPG, which combines Deep Q-Network (DQN) and Deterministic Policy Gradient (DPG), has the characteristics of policy-based neural network and value-based neural network. SPG-RL uses a deterministic policy  to select actions, as shown Eq. (10) where 
 is the parameter of the actor network that generates deterministic actions.(10)

Policy network is used as the policy behavior, value network is used to fit formula snext = F (scurrent, a) where snext and scurrent are the next and current states. The objective function of DDPG is shown as Eq. (11) where  represents the proportion of future rewards that are close to the current moment and ri is the reward.(11)

DDPG uses the structure of DQN to fit the Q function based on the Q network, where the Q function represents the expected value of the reward for the selected action under deterministic policy , as shown in Eq. (12).(12)
where r(st, at) is the reward for performing at action in the st state. 
 represents the expected value of the reward of the  selecting actions in state s, and can be solved using integrals for the continuous action space. So Eq. (13) can be used to evaluate the quality of the strategy, where ρ is the behavior strategy and ρτ indicates the status of the discount environment under the strategy ρ.(13)

The DDPG introduces the DQN structure, and adds the target value network on the basis of the current value network. The experience replay memory unit, which has the characteristics of empirical playback and adaptive learning rate, is also introduced to improve the efficiency of data usage. The structure diagram of SPG-RL is shown in Fig. 3. The replay memory unit buffers the state-action-feedback-next state obtained after each slicing action, and randomly samples from the replay memory unit during training. The complete algorithm process is as Algorithm 1. Note that when slicing, DDPG takes global network state into account, but performs local actions to generate local slices that meet certain requirements.

Algorithm 1: SPG-RL Algorithm
Input: Intent request description Ir and network state st
Output: slicing policy  (SS, CRS, SRS | st)
Initial N capacity of Replay Buffer: D Initial parameters of evaluation and target networks for the actor and critic network of DDPG with 
 Procedure:
1: for episode  1 to M do
2: obtain initial observed state st with Ir and G(N, L, F, C, S), reset rs = 0
3: for step t  1, to T do
4: Get slicing action at from st using Eq. (8) with the parameter 
5: Observe the subsequent state s’ and reward rt
6: If the number of experience < N then Store the experience {st, at, rt, s’} Into the replay experience D
7: else
8: Replace the first saved experience with {st, at, rt, s’} In the replay memory; Randomly sampling a batch of samples from D
9: Update the parameter in the actor: 
 
10: Update the parameter in the critic: 
 
11: calculate reward using Eq. (4)
12: end for
13: end for
Fig. 3

Fig. 3. Structure of SPG-RL

3.4. DNEN-based slicing reconfiguration for intent guarantee
After completing the slicing configuration of the intent request, it also needs to continue to track the slicing configuration. This is because that the QoS of the slices may change due to the dynamic network environment, resulting in the violation of intent constraints. In this case, we need to perform a reconfiguration operation on the slices. In order to reduce the reconfiguration time of the slice, we need to locate the incompatible slice, and then feedback the positioning result to the SPG-RL. Due to the characteristic of mutation and reorganization, DNEN featuring excellent global search capability can be well applied to the unsuitable slicing location during the intent configuration in optical networks (Yang et al., 2020d). Then its results can be forwarded back to SPG-RL for slice reconfiguration. To this end, the DNEN-based intent guarantee mechanism is introduced. DNEN's high-precision positioning characteristics are highly related to its structure, we first look at its input and output relationship to understand its structure. The relation between input and output of DNEN is shown as Eq. (14).(14)
 where x, y, and b(l) are the input, output, and bias. L is the number of neural network layers, [n0, n1, n2, …, nL] represents the dimensions of each neural layer, and [
, 
, 
, …, 
] is on behalf of activation function. The relationship expression of input and output is shown in Eq. (15)(15)

Meanwhile, after obtaining incompatible slice positioning, we set a threshold function of network congestion entropy for reconfiguration to determine when to perform slices reconfiguration (Yao et al., 2019), (Wang et al., 2019). A joint congestion entropy is given as Eq. (16).(16)
 
 
 
 where Bm,i represents the bandwidth occupied by the mth service on slice Slici, Mi is the number of intent services on Slici and Slic is the total number of slices in the network. 
 and  are the maximum possible bandwidth requirement and the average bandwidth demand on Slici, respectively. 
 (0<
<1) is tuning factor to adjust the trade-off between degree of congestion and slicing reconfiguration time. H indicates the time required for slice reconfiguration under a certain degree of congestion.

When the entropy value reaches threshold , the slicing reconfiguration would be performed (Tootaghaj et al., 2018). The result of positioning operation of DNEN is fed back to the SPG-RL, and then the reconfiguration operation is performed on the specific slice. SPG-RL executes slicing reconfiguration action A= (ΔSS, ΔCRS, ΔSRS), where ΔSS, ΔCRS, ΔSRS correspond to the magnitude of the change in certain resource slicing. We can see that the interaction process of DNEN and SPG-RL is shown in Fig. 4.

Fig. 4

Fig. 4. Interaction flow between DNEN and SPG-RL function modules.

Following above principle, we propose DNEN-assisted slices positioning reconfiguration algorithm, as shown in Algorithm 2, including the interplay with Algorithm 1. During this process, it needs to consider the global network state to perform local actions to achieve the generation of reconfiguration strategy.

Algorithm 2: DNEN-assisted Slice Positioning Reconfiguration Model
Input: The incompatible resource slices set Fsus, where Fsus = {Fsus(i)|i = 1,2, … }
Output: slice reconfiguration policy action 
1: Initialize the structure of DNEN
2: Encode the neural network genome
3: Generate initial network population M, size(M) = m
4: for t  0 to T do
5: for bestFitness < Accuracy threshold do
6: for i = 1 to m do
7: Mi,fitness = calculateFitness(Mi)
8: Select the ethnic group with high fitness
9: Generate offspring by crossover and mutation
10: bestFitness = max(bestFitness, Mi,fitness)
11: The new network population is M’,size(M′) = m
12: end for
13: end for
14: If  then
15: Obtain position of incompatible slices
16: Calculate slicing reconfiguration by algorithm 1
17: Return slicing action 
18: else monitor 
19:end
4. . Evaluation of idon
This section demonstrates the performance evaluation of IDON attaching SPG-RL-DNEN. We build a testbed to evaluate SPG-RL-DNEN using Tensorflow. All the simulations are conducted on the server with Intel Gold 6138 CPU @ 2.00GHz  16.

1)
Simulation setup. According to the calculation of Eq. (4) and Eq. (5), we can obtain the corresponding relationship between the NPI main performance metric interval and the quantization value interval, as shown in Table 1.


Table 1. NPI quantified value interval comparison table.

Items	NPI quantified value interval
NPI	<60	60–70	70–80	80–90	90–100
Bandwidth (Mbps)	<10	10–20	20–50	50–100	>100
Delay (ms)	>200	100–200	50–100	10–50	<10
Load balance	<0.04	0.04–0.06	0.06–0.08	0.08–0.1	>0.1
Blocking rate (%)	15–20	10–15	5–10	1–5	<1
Additionally, it is built on the Python 3.6 platform, running on the Ubuntu 18.04 operating system. The simulation selects the intent request of “continuously building a connection to a high-performance data center”. We set the bandwidth to 30 Mbps, delay 50 ms, load balancing 0.05, blocking probability 5%, and then calculate Ir, which is used as the threshold Ir0. We substitute them into Eqs. (4), (5), then calculated Ir0 is 72. It is noted that Eq. (5) and the SPG-RL model are independent of each other, and Ir is only used to define whether the threshold of the intent request is satisfied. The adjustment of the NPI indicators still needs to be adjusted through model training. TensorFlow is utilized to build SRG-RL-DNEN slicing module. The main network and the target network of the same structure are constructed based on the TensorFlow module. The parameters and activation functions of each layer are shown in Table 2. The weight parameters of each neuron in the main network are randomly initialized at the beginning of training, and these parameters are updated by the random gradient descent method during every subsequent training. Coupled with the storage space of the host running the simulation experiment and the computing power of the processor, the capacity of the experience pool is set to 5000 to avoid excessive storage requirements that affect the simulation results. Network performance including blocking probability, jitter, delay, and active flows of slices, would be gathered as the environment state input. In the simulation, SPG-RL-DNEN-IDON has run totally 1000 training episodes to inspect enough robustness and stability level. To verify the correctness of our SPG-RL-DNEN approach, we compare the proposed SPG-RL-DNEN with DQN proposed in Yang et al., (2020b), (Yang et al., 2016c) and benchmark solution in (Oliveira and da Fonseca, 2019). Once the operation is completed, the SPG-RL-DNEN approach is verified according to performance indicators such as cumulative rewards, slicing execute time etc.

2)
The convergence result of proposed model under different network initial values. We first validate the performance on different NPI. Fig. 6 shows NPI variation of SPG-RL-DNEN with respect to the number of action steps under different initial NPI settings. The initial values of Fig. 6 (a), (b), (c), and (d) corresponding to the NPI quadruple (blocking probability-load balancing-bandwidth-delay) are (90,90,90,90), (10,10,10,10), (50,50,50,50), and (90,10,90,10), respectively. It can be seen that although the initial values are different, after a certain number of steps of adjustment, the blocking probability-load balancing-bandwidth-delay are eventually stabilized at 82, 62, 72, and 67, respectively. From Eq. (5), the corresponding Ir is 75 at this time. Obviously, after the adjustment of the slicing policy selection action, the result of slicing policy can be maintained near the threshold Ir0 72 upstream. The NPI quadruple has a stable size relationship consistent with the weight ratio in Eq. (5), proving that the definition of reward in Eq. (6) is suitable for the network environment. In addition, in Fig. 6, indicators such as bandwidth and blocking probability are not monotonically increasing or decreasing, and there may be fluctuations at the beginning of the adjustment phase. Taking Fig. 6 (c) as an example, around step 40, the bandwidth shows a faster rate of rise and is higher than the blocking rate, and then the bandwidth shows a downward trend while the blocking rate further increases, and finally reaches stability level. This proves that, in the process of training, the reward part rs,Ir in Eq. (6) always comes into play first, meaning that the model tends to satisfy the intent request Ir at a faster rate. Then, the punishment part rs,NPI comes into play, and the model tries to reduce the consumption of network resources while maintaining the intent request, and finally stabilizes in the state where the accumulated maximum reward is obtained.

3)
Result of Intent translation, and slicing policy execution rewards. The results of intent parse and slicing configuration action policy are shown in Fig. 7. It can be seen that the intent is converted into source address and constrain of QoS, etc. Variations in cumulative rewards in relation to training episodes are presented in Fig. 8. It can be observed that the cumulative rewards of all SPG-RL-DNEN, DQN, and benchmark gradually converge with the increasing number of training episodes. The cumulative rewards of SPG-RL-DNEN almost maintain stable after about 400th and 200th training episodes respectively under two different topologies, as showed in Fig. 8. We can see that SPG-RL-DNEN finally achieves the highest slicing configuration rewards, indicating that the proposal SPG-RL-DNEN can learn a positive slicing policy. SPG-RL-DNEN also performs best in comparison to the DQN without DNEN and benchmark configuration. In the initial training process, the property of the proposal is barely satisfactory in comparison with the others. This is principally because the proposal is continually exploring various slicing configuration policies due to lack of experience. But it step by step learns how to configure slices in the best manner and outperform the others until the 300th episodes.

4)
The convergence of slicing execution time consumption and resource utilization during training. We assess the impact of SPG-RL-DNEN on the performance of slicing execution time. As shown in Fig. 9, it provides the related variation on slicing execution time with respect to training episodes. It can be seen that slicing execution time of SPG-RL-DNEN is shorter than DQN and benchmark after 300th and 150th episodes respectively under two different topologies. This is explained by the fact that the process of slicing policy generation of SPG-RL-DNEN can be promptly accomplished with the aid of DNEN. DNEN can search the location of unsuitable slices, engaging closed-loop slicing reconfiguration aim at incompatible slices. With the assistance of DNEN's accurate location on improper slicing, SPG-RL-DNEN can execute slicing reconfiguration for promotion in a goal manner, evading reconfiguring along the entire service path. Therefore, the proposal decreases lots of slicing execution time and decreases the risk of improper slicing configuration as well.

5)
Performance of slice reconstruction time and blocking rate under different number of intent services. Fig. 11 shows the comparison of the slicing reconfiguration time consumption and the number of reconfigured slices between SPG-RL-DNEN and DQN. Specifically, the number of slices that needs to be configured has also been illustrated in Table 3. The amount of slices to be reconfigured directly affects the reconfiguration time and service continuity of the entire network. In Fig. 11, for the performance evaluation result, we first make comparisons the slicing reconfiguration time of the proposal under the different number of intent services on topology 1. SPG-RL-DNEN, which discourages unnecessary slicing reconfiguration, outperforms the DQN and its time consumption is only about 88.7 ms and 159.8 ms under 1000 and 6000 intent services on topology 1, respectively. In addition, under topology 2, the slicing reconfiguration time of the proposal is 109.3 ms and 274.4 ms under 1000 and 6000 intent services, respectively. DQN works alone without the assistance of DNEN, the entire slices will be carried out. With the assistance of DNEN, SPG-RL-DNEN can reconfigure slices aiming at high blocking probability or low resource utilization slices, reducing the reconfiguration scale and speeding up reconfiguration time. Therefore, SPG-RL-DNEN decreases the pause time of the intended service. The DNEN-assisted scheme significantly improves the continuity of on-chip services by reducing the amount of reconfiguration. The proposal is at least 17.6% and 19.4% less time-consuming than DQN respectively with two different topologies. The proposal time consumption is small enough to achieve online slicing reconstruction in SDN-enabled networks.

6)
The learning time evaluation under different number of intent services. Fig. 13 indicates the learning time result compared with the DQN scheme and it shows that the learning time of the proposed scheme is indeed longer than that of DQN. This is because the proposed SPG-RL-DNEN ensures the realization of the intent by using DNEN to locate slices that do not meet the requirements. In the case of DNEN, it takes longer time to be inherited, mutated, evolved in a large population to precisely locate incompatible slices. Especially with high network load, the network scheduling becomes more complex and the convergence time of the model is longer. Therefore, the final learning time of proposed SPG-RL-DNEN is higher than DQN without integrated DNEN.


Table 2. Parameters of SPG-RL-DNEN model.

SPG-RL-DNEN	Parameters
Actor Hidden Layers	400,300,200
Critic Hidden Layers	400,300,200
DNEN Hidden Layers	50,50,50,10,10
0.15
0.2
0.4
Temporal difference	10−6
Optimizer	Adam (Yu Yanget al., 2021)
Actor learning rate	10−4
Critic learning rate	10−3
Weight decay coefficient	10−6
Replay experience	5000
loss function	Square loss

Table 3. The number of RECONFIGURED SLICES.

The number of intent service	SPG-RL-DNEN	DQN
topology1	topology2	topology1	topology2
1000	8	8	10	9
2000	10	9	12	11
3000	11	9	15	14
4000	12	10	18	16
5000	13	11	22	20
6000	15	13	25	21
The variations of resource utilization with respect to training episodes are presented in Fig. 10. As seen in the figure, the resource utilization of the proposal is obviously higher than the benchmark and DQN solution after the 300th and 200th training episode with two different topologies. This stems from the fact that SPG-RL-DNEN considers global optimization of the network by utilizing the evaluation mechanism of slicing rewards, and configures the most appropriate slice size for intent services, thereby maximizing rewards of slicing configuration operation. This means intent-driven intelligent SPG-RL-DNEN slicing control is considered from an optimal global perspective. The performance of our proposal is improved by 6.8% and 26.5% respectively, compared to DQN and benchmark in the topology1. It performs 15.1% better than DQN on the topology2, and 27.7% better than the benchmark.

Fig. 9
Fig. 9. Slicing execute time of different algorithms: (a) topology1 (b) topology2.

Fig. 10
Fig. 10. Resource utilization of different algorithms: (a) topology1 (b) topology2.

We can see from Fig. 12 that the variation of the blocking probability as the number of intent requests increases. SPG-RL-DNEN can flexibly control the number of reconfigured slices according to DNEN's slice positioning results, meaning that it takes the slicing configuration scale into consideration. Thus, SPG-RL-DNEN performs the best in the simulation. It can be observed that SPG-RL-DNEN entirely beats DQN and benchmark solution under the different number of intent services and eventually achieves a blocking reduction of 32.6% and 42.6% in the case of 6000 intent services with two different topologies. In a dynamic network environment, SPG-RL-DNEN performs a positioning and reconfiguration operation on network slices to ensure that each slice can meet the intent constraints. And does not allocate too many resources to ensure the efficiency of resources utilization. So the blocking probability performance of SPG-RL-DNEN is better than benchmark. The lower SPG-RL-DNEN blocking rate is due to the capability of DNEN when the slicing is not suitable. Through finding out the slicing of inappropriate size, SPG-RL-DNEN feedback the result to the DDPG for scaling or expansion operation, meaning that not all slices need to be reconfigured and its number depends on the DNEN positioning result.

Fig. 11
Fig. 11. The time consumption of slicing reconfiguration: (a) topology1 (b) topology2.

Fig. 12Fig. 12. Blocking probability of different algorithms under different number of intent services: (a) topology1 (b) topology2.

Fig. 13
Fig. 13. Learning time of different algorithms under different number of intent services: (a) topology1 (b) topology2.

We can see that the average learning time of the proposed scheme was 2589.0s, while that of the DQN scheme was 1878.1s in topology1. The two corresponding values in topology 2 are 2292.4s and 1697.2s. In practical application scenarios, this is within an acceptable time range, so the proposed scheme can be applied to a realistic scenario.

5. Conclusion
In this article, we studied how to implement an intent-driven network architecture. We introduce the IA-LDA algorithm, to split the description of intent request into key topic words and map intent requests to network performance expectations, which establishes the semantic graph to comprehend and translate the required slicing configuration language. Then, according to result of intent translation, we used SPG-RL to perform slicing configuration for intent services through integrating fine-grained slicing policies. In case of incompatible and fault, DNEN-assisted SPG-RL can locate the position of incompatible slices, and performs slices reconfiguration when the congestion entropy reaches a specified threshold. We verify the IDON with SPG-RL-DNEN in term of slicing execution time, slices reconfiguration time consumption and blocking probability. Our research shows that SPG-RL-DNEN provides a better choice for intent-driven optical network solutions, towards a fully self-healing, autonomous zero-touch optical network.