The purpose of this paper is to gain knowledge about the implementation and development of the Community of Inquiry survey. This paper describes a systematic review of peer-reviewed journal papers where the survey has been used to collect and analyze empirical data about a learning experience. A total of 103 journal papers published between 2008 and 2017 were reviewed to reveal the context, research design, and results obtained using the survey. These results specify that the Community of Inquiry survey provide results that are valid and reliable. The instrument has been used effectively to examine learning experiences and to compare different premises in many contexts. It is, however, necessary to expand the settings in order to make more general claims about the nature of online and blended learning.

Previous
Next 
Keywords
Community of Inquiry

CoI survey

Systematic review

1. Introduction
The Community of Inquiry (CoI) introduced by Garrison et al., 2000, Garrison et al., 2001 is a theoretical framework developed to structure the process of learning in an online environment. This framework, which stems from the theoretical perspectives of Dewey (1933), Peirce (1955), and Lipman (2003) can be described as a “generic and coherent structure of a transactional educational experience whose core function is to manage and monitor the dynamic for thinking and learning collaboratively” (Garrison, 2017, p. 24). In this process, the CoI framework consists of three unique, interrelating elements: cognitive, teaching, and social presence. Cognitive presence outlines the process of learning, teaching presence the moderation and guidance of the inquiry, and social presence the human experience of learning. The three elements are often illustrated with the Venn diagram displayed in Fig. 1. For each element, several categories are also defined to represent different aspects of the specified presence. For example, cognitive presence consists of a triggering event, exploration, integration, and resolution; teaching presence involves design and organization, facilitating discourse, and direct instruction; and social presence comprises affective communication, open communication, and community cohesion. This framework has been heavily used, discussed, and examined since its introduction (Garrison, 2017). The CoI framework has, in addition to the online learning environment, also been established for blended learning environments (Garrison & Kanuka, 2004; Vaughan, Cleveland-Innes, & Garrison, 2013).

Fig. 1
Download : Download high-res image (222KB)
Download : Download full-size image
Fig. 1. Community of Inquiry.

Garrison et al. (2000). Used with permission.

Two main approaches have been regularly applied to collect and analyze empirical data based on the CoI framework, transcript coding, and a survey procedure. The transcript method is guided by a coding scheme in which a unit of analysis (such as a message) is coded as belonging to one or several of the categories and their corresponding elements in the CoI framework. This is then followed by quantitative calculations, where the generated data is used to identify statistical insights of the discourse. The second method of collecting and analyzing data, the survey procedure, is the basis for this current study. The founding paper for the CoI survey: Developing a community of inquiry instrument: Testing a measure of the Community of Inquiry framework using a multi-institutional sample, was published by Arbaugh et al. (2008) in this journal. That paper reports the development of an instrument consisting of 34 items where each item was developed to reflect a category and an element. The instrument's ability to provide reliable and valid results was tested in the establishing paper and in the follow-up study by Swan et al. (2008) using factor analysis. The instrument is reproduced in Appendix A.

Since the introduction of the CoI survey, the tool has been used in many contexts. According to Garrison (2017), the survey instrument has made “a significant enhancement and proliferation of CoI research through more efficient data analysis and by making possible large-scale studies across institutions, disciplines, demographic groups and technologies” (p. 165). However, despite a large body of literature no systematic review of the CoI survey has so far been published. It is therefore argued that a systematic review is needed in order to establish a current state of knowledge, formulate integrated synthesis about the performed research and outline possible directions for the future of research about the CoI survey.

The purpose of this paper is to gain knowledge about the implementation and development of the CoI survey. This is done through a systematic review of the peer-reviewed journal papers where the survey, as presented by Arbaugh et al. (2008), or as a modification based on the original survey is used to collect and analyze empirical data. The review is guided by the following research questions:

1.
Where, when, and by whom has research about the CoI survey been published?

2.
In what demographic contexts has the CoI survey been used?

3.
For what purposes and with which research design has the CoI survey been used?

4.
What main results and conclusions have been drawn, based on the CoI survey?

2. Method
Systematic review is a research method where several research articles are collected, analyzed, synthesized, and presented in order to draw integrated conclusions based on numerous studies (Fink, 2013). The process of conducting a systematic review is typically performed with eight steps: 1) formulate the aim of the review, 2) select bibliographic database(s), 3) choose search terms, 4) conduct the search, 5) perform an initial screening, 6) do the review, 7) synthesize and interpret the results and, 8) present the outcome of the review (Cooper, Hedges, & Valentine, 2009). A central requirement for systematic reviews is that they use explicit, rigorous, and transparent procedures for each step in order to reduce bias and enable reproducibility (Cohen, Manion, & Morrison, 2013).

2.1. Data collection
For the present study, the purpose is to gain knowledge about the implementation and development of the CoI survey. Studies were included in this review if they met the following inclusion criteria:

1.
The article should be listed in Scopus, Web of Science, or the Education Resources Information Center (ERIC).

2.
The article should either cite Arbaugh et al. (2008) or the title, abstract, or keyword of the article should include the words Community of Inquiry and either the word survey or the word questionnaire.

3.
The article was published during 2008–2017.

4.
The article was written in English.

5.
The study contained a collection and analysis of empirical data collected using either the CoI survey as presented in Arbaugh et al. (2008) or a modification based on the Arbaugh et al. (2008) survey.

The data collection was conducted in two steps. First, inclusion criteria 1–3 were addressed with searches of the three research databases. Secondly, inclusion criteria 4–5 were addressed by a manual screening of the body of literature developed from the searches.

In the first step, three databases were selected to conduct the search: Scopus, Web of Science, and ERIC. They were selected because of their reputations as the most recognized databases in the field of online education. Two separate search terms were developed. The first search term was a combination of the words Community of Inquiry and either the word survey or the word questionnaire in the title, abstract, or keyword. The second search term was constructed to retrieve all papers citing Arbaugh et al. (2008), the original article about the CoI survey. The search criteria were that a paper should meet at least one of the search terms. For all searches, journal papers published between 2008 and 2017 were considered. The searches were carried out April 3, 2018, and the results are shown in Table 1. All the matching papers were then collected in a local database and duplicates of papers were removed. This resulted in the identification of 217 unique journal papers.


Table 1. Search results.

Search terms	Scopus	Web of science	ERIC
“Community of Inquiry” AND (“Survey” OR “Questionnaire”)	70	48	92
Citing Arbaugh et al. (2008)	133	91	N/Aa
a
The ERIC database does not have this feature.

The second step of the review was an initial manual screening of the research papers with the aim to identify papers meeting inclusion criteria 4–5. Papers that comprised collection and analysis of empirical data using the CoI survey or a modification based on the original survey written in English were included for further analysis. Finally it was decided to manually add Swan et al. (2008) to the database since it is seen as a second founding paper for the CoI survey, addressing the validation, but was published in a journal that is not listed in any of the three databases selected for this review. In total, 103 research papers were selected to be included in this systematic review. A list of the selected papers is presented in Appendix B. The research papers that were excluded during the fifth step typically mentioned the CoI survey or Arbaugh et al. (2008) in their introduction or discussion but did not use the survey themselves.

2.2. Data analysis
A review protocol was developed in order to thoroughly analyze the articles. Following the research questions, the protocol consisted of four sections: bibliometric data, demographic data, data about the performed study, and the results and conclusions of each study. The bibliometric data were collected using metadata from the research databases while the other data were collected through manual examination of the papers. Bibliometric data included the body of authors, journals, and publication years. Demographic data included participant sample size, in what country the study was performed, participants' level of education, and the subject area of instruction. Data about the performed study included the purpose of employing the CoI survey, what version of the CoI was used, what other data were collected, and the statistical analysis methods of each study. The results and conclusions section included no subparts. Following this, the selected papers were read in order to complete one form per paper.

The forms were then examined per category with either a deductive or an inductive approach in order to find commonalities and differences among the performed studies (Neuman, 2013). The deductive approach was used when all possible alternatives were presumed to be known prior to the manual examination of the papers. For example, it was known that all studies were supposed to have a number of participants and a subject area of instruction, which could be collected and classified directly. This in contrast to the expectation that each study was presumed to have an aim and could have completed a statistical analysis, but the alternatives were unknown so no classification could be performed directly. For these categories, an inductive two-step approach was employed. In the first step, relevant text from the papers were copied into the review protocol to form quotes. In the second step the quotes were coded using open, axial, and selective coding (Neuman, 2013). All demographic data were examined using the deductive approach while most data regarding the performed studies and the synthesis were examined using the inductive approach. Exceptions when the deductive approach was used are the included CoI elements in the study, major modifications to the items, and whether the study employed factor analysis. For all examinations using the deductive approach, exact numbers are reported, although this is not the case for the inductive approach as some of the reviewed papers are vague in reporting the information.

3. Result
3.1. Bibliometric results
In this section, the findings based on the bibliometric data are presented. First, the authors of the reviewed papers are presented. This is followed by a list of the most active journals that have published papers with the CoI survey and the years in which the papers were published.

3.1.1. Authors
In total, 224 authors are included in the review. The vast majority of articles are written in collaboration between several authors. A list with the most productive authors is presented in Table 2, and the most productive first authors in Table 3. D. Randy Garrison has the highest number of publications overall (nine publications) while Zehra Akyol is the most productive first author (six publications). It is also important to note that only 41 authors (out of 224) have written more than one article included in the review.


Table 2. List of authors.

Author	No. of articles
Garrison, D.R.	9
Cleveland-Innes, M.	7
Ice, P.	7
Richardson, J.C.	7
Akyol, Z.	6
Shea, P.	6
Swan, K.	6
Arbaugh, J.B.	5
Bidjerano, T.	5

Table 3. List of first authors.

First author	No. of articles
Akyol, Z.	6
Arbaugh, J.B.	4
Kozan, K.	4
Rockinson-Szapkiw, A.J.	4
Shea, P.	4
Rubin, B.	3
Swan, K.	3
3.1.2. Journals
The articles in this review have been published in 47 different journals. A list of journals with multiple articles are listed in Table 4. The vast majority of articles are published in Internet and Higher Education, followed by Journal of Asynchronous Learning Network/Online Learning, International Review of Research in Open and Distance/Distributed Learning, and Computers and Education.


Table 4. Journals with multiple articles.

Journal	No. of articles
Internet and Higher Education	22
Journal of Asynchronous Learning Network/Online Learning	11
International Review of Research in Open and Distance/Distributed Learning	9
Computers and Education	6
Interactive Learning Environments	3
Journal of Educational Computing Research	3
Turkish Online Journal of Educational Technology	3
Australasian Journal of Educational Technology	2
British Journal of Educational Technology	2
Contemporary Educational Technology	2
E-Learning and Digital Media	2
International Journal of Teaching and Learning in Higher Education	2
Journal of Interactive Online Learning	2
3.1.3. Years
3.2. Demographic results
This section reports on the various demographic contexts where the CoI survey has been put into practice. This section describes the sample sizes, in which countries the survey has been issued, the subject areas of instruction, and at which levels the education has been delivered.

3.2.1. Participant sample size
The participant sample size comprises the number of persons that responded to the CoI survey in each study. The number of participants that responded to the survey varies a great deal between studies. The smallest study contains only 5 participants while the largest study contains 64,781 participants. The median value is Mdn = 158, while the 25th percentile is Q1 = 41 and the 75th percentile is Q3 = 361.

3.2.2. Country
The geographical locations of the studies were obtained by identifying the country or countries where the survey is said to have been administered. In the few cases where this is not noted, the country of the first author's affiliation is used. An overwhelming majority of the studies were done in the USA (55 studies), Canada (seven studies), or a combination of the two countries (four studies). Other countries are Greece, Malaysia, and Turkey (four studies each), China, Korea, and Taiwan (three studies per country), Cyprus, Belgium, and Sweden (two studies each), and Australia, Japan, Mexico, Morocco, Portugal, Singapore, Slovenia, South Africa, and Spain (one study per country). There is also one study with data collected in Canada, New Zealand, Italy, and Taiwan.

3.2.3. The subject area of instruction
This category was measured by the collection of the subject of instruction (or equivalent) for each study. The subjects were then clustered to form areas of instruction. The most common finding was that studies used samples from several different topics and disciplines of instruction. This was the case for 34 studies. The single most common area of instruction was E-learning (including Educational Technology, Blended Learning, and Learning, Design, and Technology) with 22 studies. The following areas were (in descending order) Education (11), Languages and Literature (10), Business Administration (8), Medicine and Health Sciences (6), Computer Science (4), Sociology (2), Engineering (1), History (1), Research Methods (1), and Special Education (1). The subject of instruction was not reported for two studies.

3.2.4. Participants' level of education
Studies using the CoI survey that were included in this review have almost exclusively been performed with participants at the post-secondary level. Out of the 103 studies, only two studies were performed in elementary education and three in professional development. Within the post-secondary level, most studies included participants at the graduate level (35 studies), followed by the undergraduate level (25 studies). There are also 23 studies performed with participants at both graduate and undergraduate levels while 15 studies do not state the level within post-secondary education of the participants.

3.3. The performed study
This section describes the findings related to the performed studies. These findings includes the purposes of employing the CoI survey, which of the CoI elements are evaluated, possible modifications or additions to the survey, what other data are used with the survey, and a list of the statistical analysis tools employed.

3.3.1. Purposes of employing the CoI survey
The purposes of using the CoI survey were investigated by assessments of the research questions, aims, purposes, and discussions of every paper using the inductive approach. The following overall categories of rationales appeared: to explore a single learning environment, to examine differences using the CoI survey, to observe relationships among the different elements of CoI and their relationships with other data, and to address the reliability and/or validity of data using the CoI survey. Most studies focused on one of these rationales while some had multiple rationales. The first category consists of studies where the survey was used simply to gain insights about one specific learning environment. Examples include exploring a course or evaluating a tool. The second category consists of studies where different features are compared or an intervention is tested. Examples include comparing an online course to blended course, to test student retention, or to test for disciplinary differences. The third category includes studies of general relationships among the different elements of CoI and their relationships with other data. Examples include testing for causal relationships, searches for predictions, and building structural models. The fourth category reflects studies that aim to address the validity and reliability of data using the CoI survey. Examples include the founding papers, translations of the CoI survey into other languages, and suggested changes to the framework.

3.3.2. Included CoI elements
The original CoI framework element comprises three interdependent elements: cognitive, teaching, and social presence. Out of the 103 reviewed studies, 83 included the three original elements. Some studies considered only one element: teaching presence (five studies), cognitive presence (two studies), and social presence (two studies). There were two studies with two elements of the framework: one with cognitive and teaching presence, as well as one with social and cognitive presence. Finally, nine studies considered new or revised elements. Learner presence was added to the original elements in four studies, emotional presence in two studies, a modification of teaching presence named faculty presence in one study, and an instructor social presence element in one study.

3.3.3. Modifications of the survey
In the reviewed literature, most studies used the CoI survey as presented in Arbaugh et al. (2008) or with minor modifications. As a minor change, this review includes the change of tense and replacing the word instructor with instructors, teachers, or similar terms. Another change to the survey is to replace the word “I” with “students” and to replace “instructor” with “I” when instructors fill out the questionnaire. There was also a total of 26 studies that addressed of more comprehensive changes to the survey tool. These adaptations include removing or adding items, major rewordings of the statements, and CoI surveys in other languages than English. There were also some cases where the study was said be inspired by the original CoI survey but developed their own set of items.

3.3.4. Additions to the survey
Besides the actual CoI survey, most studies included demographic data, information about the course setting, and data related to the learning outcomes of the students. Common student characteristics data are age, gender, ethnicity, experience of online and blended education, and whether the participants were full-time or part-time students. Information about the course (or similar) was usually collected, especially for studies that included more than one setting. The information usually includes: the topic of instruction, academic level, design of the course, delivery medium, and institution. Data related to the learning outcomes of the students includes their satisfaction, performance, achievements, and evaluations of the instructor.

3.3.5. Other data
Apart from the survey, some studies used other data collections as a part of their study. These other datasets included well-defined questionnaires on specific topics, such as technology acceptance, metacognition, students' self-regulated learning, and formal scales about perceived learning. The review also identified some studies using transcript analysis (generally with the CoI coding procedure), interviews, usage data from learning management systems, and exam/test scores.

3.3.6. Statistical analysis methods
A myriad of analysis methods has been employed to analyze the CoI survey individually and together with other data. The explorative single learning environment studies typically used only descriptive statistics to support the analysis. The smaller comparative studies typically employed non-parametric tests (i.e., Kruskal-Wallis, Mann-Whiney U or Spearman Rank tests) while the larger studies used student t-tests, correlations, ANOVAs, and regression. A common test was to use hierarchical multiple regression with cognitive, social, and teaching presence as predefined independent variables. Relationships have in general been tested with structural equation modeling analysis (mostly path analysis). The reliability of smaller studies was sometimes tested with Cronbach's alpha, although factor analysis was generally used to address validity and reliability. Factor analysis was used in 32 of the reviewed studies. These studies included both exploratory and confirmatory factor analysis with mostly principal component analysis using Oblimin followed by Varimax rotation. In the studies that cover several rationales, multiple statistical tests were usually employed.

3.4. Synthesis of the results and conclusions
This section reports the synthesis of the results and conclusions of the reviewed papers. This includes combined results where several papers address a common theme.

3.4.1. Validity and reliability of data using the CoI survey
The validity and reliability rest in the instrument's ability to provide empirical data guided by the measurement of cognitive, social, and teaching presence. Apart from the two founding papers, Arbaugh et al. (2008) and Swan et al. (2008), multiple following studies have acknowledged the CoI survey provide results that are valid and reliable (Bangert, 2009; Carlon et al., 2012; Díaz, Swan, Ice, & Kupczynski, 2010; Kozan & Richardson, 2014; Shea & Bidjerano, 2009). The major argument for this conclusion is the extensive reproduction of exploratory and confirmatory factor analysis performed in several different learning environment contexts over almost ten years. The survey has also been translated and tested in several other languages: for example Turkish, Korean, Chinese, and Portuguese (Horzum & Uyanik, 2015; Ma et al., 2017; Moreira, Ferreira, & Almeida, 2013; Yu & Richardson, 2015).

3.4.2. Correlations and causal relationships
Relationships between the elements within CoI and relationships between CoI and other data have been tested using both correlation and causal relations. An early study found positive correlations among teaching presence, cognitive presence, social presence, students' perceived learning, and satisfaction in a course. (Akyol & Garrison, 2008). Strong positive correlations have also been found when pairwise testing the three elements (Kozan & Richardson, 2014). Confirmed causal relationships among the presences of the CoI framework are “that teaching and social presence have a significant perceived influence on cognitive presence and that teaching presence is perceived to influence social presence”. (Garrison, Cleveland-Innes, & Fung, 2010, p. 31). These relationships have been verified in several other studies aiming at causal relationships (Gutiérrez-Santiuste, Rodríguez-Sabiote, & Gallego-Arrufat, 2015; Lin, Hung, & Lee, 2015; Shea & Bidjerano, 2009). The causal relationships between CoI and other data have also been investigated. The data suggest that cognitive presence has a positive effect on training effectiveness, while self-efficacy is positioned between social/teaching and cognitive presence (Lin et al., 2015). Self-efficacy and effort regulation as a mediator for cognitive presence has also been investigated by Shea and Bidjerano (2010); Shea and Bidjerano (2012) with the same result. Therefore, Shea and Bidjerano call for the inclusion of a new element into the CoI framework, named learner presence. Another suggested reconceptualization is to consider the emotional aspect as a separate element as proposed by Cleveland-Innes and Campbell (2012), supported by a factor analysis study in which emotional presence is loaded as a separate element. Another recent study addresses the relationship between CoI and learning outcome. Rockinson-Szapkiw, Wendt, Wighting, and Nisbet (2016) found that “students with higher levels of perceived social presence, cognitive presence, and teaching presence had higher course scores. Likewise, perceived learning was also positively associated with students' course points” (p. 28).

3.4.3. Results and conclusions underpinned by the CoI survey
Numerous results and conclusions about online and blended learning environments have been drawn in studies underpinned by the CoI survey. The survey has, for example, been used to evaluate the use of some specific tool or resource in a course (e.g., Burgess, Slate, Rojas-LeBouef, & LaPrairie, 2010; Nagel & Kotzé, 2010; Ozturk, 2015), or to serve as a guide for design of courses (e.g., Akyol, Vaughan, & Garrison, 2011; Swan, Day, Bogle, & Matthews, 2014; Swan, Matthews, Bogle, Boles, & Day, 2012). In this section, prominent themes addressed in several studies are presented.

3.4.3.1. Online and blended learning
Some studies have compared courses delivered in online mode with courses delivered in blended mode. Akyol, Garrison, and Ozden (2009) found that “students in the blended course had slightly higher perceptions compared to the students in the online course … [and] there was a statistically significant difference on the perceptions of teaching presence” (p. 1837). The same conclusion was drawn by Shea and Bidjerano (2013) with the addition that students in blended courses “feel more affectively and socially connected to their peers”. (p. 366). It has also been found that group cohesion (a category of social presence) was significantly higher in the blended mode, while no significant difference was found for teaching presence (Kucuk & Sahin, 2013). One can conclude that none of these studies indicates that online mode of instruction would gain higher perception than a blended course.

3.4.3.2. Synchronous and asynchronous interaction
Another well-discussed topic is the comparison between synchronous and asynchronous online interaction. This has been addressed in three studies, all with the same first author. Two of these papers put forward that students using synchronous interaction or a combination of synchronous and asynchronous interaction have higher levels in the CoI survey than just asynchronous interaction (Rockinson-Szapkiw, Baker, Neukrug, & Hanes, 2010; Rockinson-Szapkiw & Wendt, 2015). The third study reported no significant difference (Rockinson-Szapkiw, 2012). Following this, an exploratory study in a nursing context also concluded that synchronous learning was associated with significantly higher scores (Claman, 2015).

3.4.3.3. Students' retention
Two studies, the ones in this review with the largest sample size, evaluates the relationship between the CoI survey indicators and students' retention. The results of Boston et al. (2010) are that “social presence in general and affective expression in particular are important determinants for persistence in online education” (p. 76). Ice, Gibson, Boston, and Becher (2011) on the other hand found no overall relationship on element or category level. That said, they found that four items of the survey were account for a large portion of the retention. For low disenrollment, the CoI survey items 1 and 25 (see Appendix A) were the key parts while high disenrollment was related to CoI survey item 6 and item 31.

3.4.3.4. Disciplinary differences
Disciplinary differences, with respect to the CoI survey is another researched context. Arbaugh, Bangert, and Cleveland-Innes (2010) identified differences where courses in more applicable disciplines reported higher CoI scores than pure disciplines. This was also confirmed in another study where “polytechnic students appear to be a more robust community when compared to university students” (Moreira et al., 2013, p. 165). An extending study by Arbaugh (2013) found discipline differences between the sub-elements of teaching presence and perceived learning. The result from this study was that, when comparing hard and soft disciplines, the harder disciplines seem to prioritize the teaching presence category of direct instruction heavily over facilitating discourse.

3.4.3.5. Differences in learner characteristics
When using the CoI survey, it is also common to test for differences based on learner characteristics. Some examples of features to test include age, gender, and academic level. Several of the studies previously addressed here does also test for this. Examples are Shea and Bidjerano (2009) whose model predicts a direct effect of student gender, age and academic level. Also, Akyol, Ice, Garrison, and Mitchell (2010) found age to be significant, while Horzum (2015) found age and grade significant.

4. Discussion
The purpose of this paper was to gain knowledge about the implementation and development of the CoI survey. This was done through a systematic review of collection that includes all peer-reviewed journal papers related to the CoI survey listed in Scopus, Web of Science, or ERIC,. Guided by a review protocol, the collected body of literature was studied in order to address the research questions: (RQ1) Where, when, and by whom has research about the CoI survey been published?; (RQ2) In what demographic contexts has the CoI survey been used?; (RQ3) For what purposes and with which research design has the CoI survey been used?; and (RQ4) What main results and conclusions have been drawn, based on the CoI survey?

Bibliometric results indicate that the CoI survey has been put into practice by many different authors. That said, the data indicate that the CoI survey has largely been elaborated by a small network of dedicated scholars. Out of the reviewed papers, 24% include at least one of the original authors. Furthermore, several of the most frequent authors have relationships as either doctoral student and supervisor or postdoc and mentor with an original author. A future success factor is to involve more scholars in order to eliminate the risks of a mutual admiration society. It is also clear that there are four journals that have regularly publish papers about this topic with an increasing number of papers each year since its introduction. The demographic area within which research using the CoI survey has been conducted is heavily concentrated towards courses at the graduate level in the United States where the topic of instruction is E-learning. There are many contexts where the CoI survey still has not been tested. The number of participants in each study consists of a very large range, from five to 64,781. The descriptive statistics, however, indicate a clear skewness towards smaller studies (the median number of participants is Mdn = 158). The purposes of employing the CoI survey have been concentrated to use it as a way to explore, evaluate, or compare learning environments as well as to improve the instrument in some way. Most studies use the CoI survey as presented in Arbaugh et al. (2008) in its original form or with minor modifications. It appears that no standards exist for altering tense, number of instructors, or change in point-of-view towards the instructors. Some studies include more comprehensive changes, such as adding new elements to the CoI framework or rephrasing the survey items. Several studies have also chosen to use a reduced number of items in the instrument. The vast majority of studies also collect other data such as participant demographics and other perceptions about the learning experience. This is natural in order to make use of the survey, given its purposes. There are also a few studies that have used mixed-methods with both the survey and the CoI transcript coding procedure within their paper.

The combined result of this study is that the CoI survey is a widely accepted instrument for revealing participants' perceptions of a learning experience. When combining the results of the 103 studies reviewed in this paper, it is clear that the CoI survey provide a reliable and valid measure of cognitive, social, and teaching presence as outlined in the CoI framework. The structural relationship between the elements indicates that teaching presence predicts student perceptions of cognitive presence with social presence as a partial mediator. The studies also provide insights to several of the classical research questions in E-learning. This review shows that blended interaction to some degree does outperform online interaction, that synchronous or a combination of synchronous and asynchronous courses are superior to only asynchronous courses, and that applied disciplines are preferable to pure disciplines. In addition, student retention seems to be related to some aspects measured by the instrument.

4.1. Future research
The CoI survey has already been used to address a large number of aspects related to online and blended learning. It is therefore of great importance that future studies focus on retesting pronounced results in more varied contexts. This will help to address generalizability and persistence of the conclusions drawn. It is also important to strive for larger sample sizes in order to address the significance of the results. The author of this paper also identifies a need for standardized variations of the items to adapt the survey to different contexts. Another extensive area of research is to examine the possibility of reducing the number of items in the survey while sustaining validity and reliability. This is important since some studies remove items, arguing that the survey is too long but do not acknowledge the significances of a reduced survey. Another vital question that needs to be investigated is that Anderson, Rourke, Garrison, and Archer (2001) describe teaching presence as a responsibility of the instructors, but students also show this presence as they organize their own learning, and facilitate and instruct peer students. This important aspect of teaching presence is, however, currently left out of the survey instrument since all items refer to only what the instructor does. This may be of value in the debate on whether the role of the learner should be seen as a separate element or considered as already measured in the CoI survey itself.

4.2. Limitations
This systematic review of collecting, analyzing, synthesizing, and presenting the research performed using the CoI survey has been performed by one person. It is therefore not possible to provide reliability calculations of this review as the normal procedure require several independent persons screening data to enable calculations of inter-rater agreement. Instead, the significance of this review rests in the systematic approach that has been used in all stages of the process as presented in the methods section. Limitations of this study might occur if the author has misinterpreted the studies' settings, operations, or conclusions. A problem during the analysis phase has been that some papers lack clear information. For example, some studies do not clearly state whether the original CoI survey or a modification is used. In these cases, that part of the review protocol has been left blank in order to prevent incorrect assumptions. For this review, it was decided to collect only the most rigorous studies. Therefore, the inclusion criteria were to include only the peer-reviewed journal papers listed in Scopus, Web of Science, or ERIC. As a result, a limitation of the review is that it does not include papers only listed in, for example, Google Scholar. This makes the available dataset smaller, but it can be argued that the comprehensive research in online and blended learning is typically published in journals listed by the three identified databases. Another potential limitation is that the papers reviewed were all in English. This criterion is appropriate because English is the language used to communicate research about CoI; two studies were excluded from the review due to this criterion.

5. Conclusion
In this paper, the CoI survey has been examined. Findings support that the CoI survey has gained a large audience as an instrument to provide empirical data about participants' perception of a learning experience. To date, 103 articles have been published, providing data on learning environments by using the CoI survey. The survey provides results that are valid and reliable based on the multiple articles with similar result. In further research, it will be necessary to expand the settings in which the instrument is applied in order to make more general claims about the nature of online and blended learning.