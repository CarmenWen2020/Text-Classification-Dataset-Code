The ability to regulate one's own learning is essential for success in online courses. Recent efforts have used clickstream data to create timely, fine-grained, and comprehensive measures of self-regulated learning (SRL) in online courses in an attempt to shed light on the process of SRL and to improve the identification of students who lack SRL skills and are at risk of low achievement. However, key questions remain: to what extent do these clickstream measures correspond to traditional self-reported measures about specific SRL constructs? Do these clickstream measures provide more information than existing self-reported measures in predicting course performance? This study used the clickstream data collected from a learning management system to measure two aspects of SRL: time management and effort regulation. We found that the clickstream measures were significantly associated with students' self-reported time management and effort regulation after the course. In addition, these clickstream measures significantly improved predictions of students' performance in the current and subsequent courses over predictions based on self-reported measures alone. These results provide evidence for the validity of the clickstream measures and guide the use of clickstream data to understand the process of SRL and identify students who might not be well served by taking classes online.

Previous
Next 
Keywords
Self-regulated learning

Clickstream data

Self-report questionnaire

Online learning

1. Introduction
As a promising method for increasing the accessibility and decreasing the costs of higher education, the rapid expansion of online learning is an international phenomenon; digitally mediated distance education has been widely adopted in countries such as China, India, South Korea, Australia, and United States (Kumar, Kumar, Palvia, & Verma, 2017; Qayyum & Zawacki-Richter, 2018). For instance, in Australia, around 27% of college students were enrolled in one or more online courses in 2014 (Norton, 2016). More than 30% of American college students were enrolled in at least one online course and around 15% of college students were completing their degree entirely online in 2016 (National Center for Education Statistics, 2018).

Despite the widespread adoption of online learning in higher education, current research has found that low course performance is a consistent issue in online courses (Finnegan, Morris, & Lee, 2008; Fritz, 2011; Macfadyen & Dawson, 2010). Students in online courses tend to have lower persistence rates and worse course grades as compared to their counterparts in in-person courses (Bettinger, Fox, Loeb, & Taylor, 2017; Xu and Jaggars, 2011, Xu and Jaggars, 2013). The low performance in online learning is due, in part, to the fact that some students are not well prepared to study online (Artino Jr & Stephens, 2009; Broadbent & Poon, 2015; Yukselturk & Bulut, 2007). More so than in in-person courses, students in online courses must regulate their own learning by establishing study plans, monitoring and controlling their learning processes, and constantly reflecting on and adjusting their study plans (Dabbagh & Kitsantas, 2004; Roll & Winne, 2015).

In light of the critical role that self-regulated learning (SRL) strategies play in online learning, it is essential to assess student uses of SRL strategies and to identify students who are likely to struggle in online courses so that institutions and instructors can provide timely support. Researchers and practitioners have mainly relied on self-report questionnaires to identify students with low SRL skills (Broadbent & Poon, 2015; Winne, 2010). However, these self-report questionnaires are costly and time intensive to administer. Additionally, students' self-reports before or after an online course are not always accurate. They may not predict or reflect student actual behavior in the course, since self-reporting is usually based on unrepresentative and abbreviated memories (Gilbert & Wilson, 2007; Loewenstein, O'Donoghue, & Rabin, 2003; Winne, Jamieson-Noel, & Muis, 2002; Winne & Perry, 2000).

These concerns have given rise to new avenues into research on measuring SRL in online learning environments. Clickstream data, the detailed and real-time record of students' observable interactions with online learning environments, provide new opportunities to measure SRL (Greene & Azevedo, 2010; Roll & Winne, 2015; Winne, 2010). Past research has shown that clickstream data can be used to capture SRL more accurately and to provide a more comprehensive understanding of students' behaviors than self-reporting (e.g., Cicchinelli et al., 2018; Winne & Jamieson-Noel, 2002). A growing body of research has used clickstream data from learning management systems, a type of commonly used learning environment, to describe, interpret, and evaluate student SRL behaviors (Roll & Winne, 2015).

While there is cumulative evidence that some clickstream measures, such as the number of assignments submitted before deadlines, are predictive of student achievement (e.g., Baker, Evans, Li, & Cung, 2018; Cicchinelli et al., 2018; Crossley, Paquette, Dascalu, McNamara, & Baker, 2016), these clickstream measures are often not triangulated with data from other instruments that have been previously evaluated. Therefore, the extent to which the clickstream measures capture SRL as intended by researchers remains unclear. Additionally, practitioners, who are generally familiar with self-reported measures of SRL, may question the benefits of exerting effort to collect and analyze clickstream data. Therefore, more direct evidence is needed to determine the extent to which clickstream measures of SRL can meaningfully improve the prediction of student performance.

To address these questions, this study used both a self-report questionnaire and clickstream data to measure two sub-constructs of SRL in an online course: time management and effort regulation. Specifically, we investigated 1) the extent to which clickstream measures could provide valid inferences about the constructs of time management and effort regulation and 2) whether the clickstream measures of time management and effort regulation could meaningfully improve the prediction of student performance.

2. Literature review
2.1. Broad frameworks for defining and measuring SRL
There is a large body of literature examining how students actively regulate their learning process. Numerous definitions and models have been developed over the last two decades, with some models describing the overall processes of SRL (e.g., Pintrich, 2000; Zimmerman, 2000) and others focusing on specific sub-components of SRL, such as the sub-process of goal-setting process (Boekaerts, 2011) and the cognitive aspect of SRL (Winne, 1996), or SRL in a specific context, such as collaborative learning (Järvelä & Hadwin, 2013). Among them, the model proposed by Pintrich (2000) is considered to be one of the most comprehensive models that classify the main processes of SRL. Importantly, Pintrich's, 2000 model has been used as a theoretical framework to validate and classify existing self-report questionnaires of SRL skills, including measures in the Motivated Strategies for Learning Questionnaire (MSLQ) – the most widely used instrument of SRL skills in online learning in higher education (Azevedo, Behnagh, Duffy, Harley, & Trevors, 2012; Broadbent & Poon, 2015; Pintrich, 2004). Because it has been used extensively in this context and because it provides clear guidance for developing clickstream measures that theoretically align with the MSLQ, we use this model as a starting framework.

Pulling from previous models of SRL, Pintrich (2000) defined SRL as the process in which students actively and constructively set goals, constantly adjust those goals, and regulate their cognition, motivation, and behaviors to achieve their goals in constrained learning environments. Based on this definition, Pintrich (2000) depicted SRL using a taxonomy of four processes and four domains that students could apply the processes to. Specifically, the four processes include forethought, planning, and activation; monitoring; control; and reaction and reflection and the four domains are cognition; motivation/affect; behavior; and context (Pintrich, 2000). Using this taxonomy, Pintrich proposed a four-by-four matrix as a conceptual framework to validate and categorize existing measures of SRL. For instance, the time management strategy of keeping up with the coursework in MSLQ measures students' propensity to control their behavior of spending time on coursework and the self-testing strategy in MSLQ measures students' propensity to monitor their cognition. For a full review of how this model is used to validate and classify measures of SRL strategies in MSLQ, please see Pintrich (2004).

2.2. The measurement of SRL
Past research on SRL has focused on measuring students' use of SRL strategies in an effort to better understand the process, determinants, and consequences of SRL (Winne, 2010). Practitioners have also relied on established measures to identify students with low SRL skills so that they can offer these students academic supports (Schellings & Van Hout-Wolters, 2011). Most of the previous work in online learning has relied on either student reports of their SRL behaviors via questionnaires or time-intensive researcher-oriented methods, such as observations and think-aloud protocols, to measure SRL (Schellings & Van Hout-Wolters, 2011; Winne, 2010). A growing number of studies, however, have suggested that it is possible to better measure SRL using the detailed clickstream data available in online learning environments. Below, we provide an overview of previous work on the measurement of SRL in online learning, focusing on two approaches: self-report questionnaires and clickstream data.

2.2.1. Self-report questionnaire and SRL
2.2.1.1. Using self-report questionnaires to measure SRL
Self-report questionnaires, such as the MSLQ (Pintrich & De Groot, 1990), the Learning and Study Strategies Inventory (LASSI; Weinstein, Schulte, & Palmer, 1987), and the Study Process Questionnaire (SPQ; Biggs, 1987), have been used to measure students' use of SRL strategies. These questionnaires usually instruct students to respond to several Likert scale statements reflecting their learning behavior by either predicting their behavior in an upcoming course or recalling their behavior in a course that just ended. Most of the SRL questionnaires are designed for traditional in-person classroom settings and have high or acceptable reliability (e.g., Loong, 2012; Taylor, 2012; Yilmaz & Orhan, 2011). A large body of research has borrowed or adapted measures from previous questionnaires, mainly MSLQ, to capture student SRL in online learning and has also reported high reliability (e.g., Artino Jr & Stephens, 2009; Cho & Shen, 2013; Kizilcec, Pérez-Sanagustín, & Maldonado, 2017; Lynch & Dembo, 2004; Wang, Shannon, & Ross, 2013).

2.2.1.2. Self-reported measures of SRL predicting online success
Despite evidence of high psychometric quality of self-reported SRL measures in online contexts, the evidence concerning the relationships between self-reported SRL measures and academic outcomes is mixed. Some studies found significant and positive relationships between self-reported SRL and online course performance (e.g., Chang, 2007; Cho & Shen, 2013; Puzziferro, 2008). Broadbent and Poon (2015) conducted a meta-analysis on twelve studies that examined the relationships between self-reported measures of SRL and academic achievement in the context of online higher education and found significant and positive associations between students' online achievement and both their overall SRL measures and certain subscales (time management, effort regulation, and metacognition).

In contrast, some notable studies failed to find significant correlations between academic outcomes and self-reported measures of both overall SRL (e.g., Cicchinelli et al., 2018; Pardo, Han, & Ellis, 2016) and subscales such as time management (e.g., Bruso & Stefaniak, 2016; Cazan, 2014; Klingsieck, Fries, Horz, & Hofer, 2012; Lynch & Dembo, 2004) and effort regulation (e.g., Bruso & Stefaniak, 2016; Dunnigan, 2018). There are at least two potential explanations for these findings of no relationship between self-reported SRL behaviors and academic outcomes: the applicability of specific measures to the online context and students' ability to accurately report their use of SRL strategies.

The lack of a significant relationship may be partially explained by the fact that some studies used questionnaires designed for traditional in-person courses (Lynch & Dembo, 2004; Pardo et al., 2016). Some researchers argue that since the types of SRL strategies students would use may vary based on the learning contexts, instruments of SRL that are valid in traditional in-person courses may not be valid for online environments (Barnard, Lan, To, Paton, & Lai, 2009). However, this does not fully account for the null findings, as several studies that used instruments established for and validated in online learning environments also failed to identify significant relationships between student course performance and self-reported SRL measures (e.g., Cazan, 2014; Dunnigan, 2018).

Another potential explanation for these null findings is that students are generally unable to accurately report or predict their SRL strategies (e.g., Bruso & Stefaniak, 2016; Klingsieck et al., 2012). Indeed, there are substantial barriers to using self-reported data to capture past or predict future SRL behaviors (Gilbert & Wilson, 2007; Winne et al., 2002; Winne & Perry, 2000). Self-reporting one's SRL behaviors after a course involves memory reconstruction that may not accurately capture one's actual experiences in the course (Bruso & Stefaniak, 2016). These responses may suffer from issues including response bias and memory deficiencies (Kahneman, Fredrickson, Schreiber, & Redelmeier, 1993; Morewedge, Gilbert, & Wilson, 2005). In a study that directly compared students' perceived use of and actual use of SRL strategies, Winne and Jamieson-Noel (2002) found that students were positively biased in reporting their use of SRL strategies.

Perhaps even more problematic is using self-report questionnaires before a course starts to predict student SRL behaviors later on, which is often how the early identification of students with low SRL skills is attempted. Self-reporting the probability of carrying out an SRL behavior, such as planning in advance to finish work on time, requires students to make predictions based on their memories of similar events in the past. In addition to the problem of memories being inaccurate, memories are aggregated over many events and thus may lack significant contextual features (Gilbert & Wilson, 2007). Such features (e.g., the nature of the task or resources available), however, may profoundly influence students' SRL behaviors. Previous studies have found that at the beginning of the course, students tend to ignore the difficulties of carrying out SRL behaviors and overestimate their SRL skills (e.g., Bernard, Brauer, Abrami, & Surkes, 2004; DiBenedetto & Bembenutty, 2013; Matuga, 2009).

Predicting one's SRL behaviors in an upcoming online course may be especially challenging for students who lack prior experience with online learning. As noted above, past experience is necessary, though insufficient, for predicting future behavior (Gilbert & Wilson, 2007). For students who have limited or no experience with formal online learning, their predictions of SRL behaviors in online courses may not be reliable because such predictions may largely rely on students' past experience in in-person classrooms, a learning environment that substantially differs from online courses.

2.2.2. Clickstream data and SRL
2.2.2.1. Using clickstream data to measure SRL
A growing body of literature has used clickstream data collected from online learning environments to obtain more objective information on students' use SRL strategies (e.g., Baker et al., 2018; Cicchinelli et al., 2018; Crossley et al., 2016; Winne & Jamieson-Noel, 2002). Clickstream data are a class of detailed, frequent, and unobtrusive records of users' click behavior in online environments. In the context of online learning, these can include behaviors such as logging into the learning platform, pressing the pause buttons on video lectures, submitting assignments, and so on. While they are not direct measures of the underlying mental processes, they correspond to students' cognition and metacognition and therefore provide promising opportunities for tracing and measuring SRL (Winne, 2010).

Researchers argue that clickstream data have several advantages over self-reported data as measures of SRL (Winne, 2010). First, clickstream data are collected in authentic learning settings while learning is happening and therefore can be used to measure student behavior more objectively, accurately, and comprehensively than self-reported data that are based on unreliable and decontextualized memories (Winne, 2010). Second, clickstream data are unobtrusive and do not require attention or effort from students; they can be collected without interrupting the learning process (Greene & Azevedo, 2010; Sha, Looi, Chen, & Zhang, 2012). In contrast, self-report questionnaires may encourage students to reflect on their behavior and therefore change students' behavior. This could bias results in an unpredictable manner (Greene & Azevedo, 2010). Finally, the automatically collected clickstream data can provide timely, frequent, and large-scale measures of student behavior, which are usually not feasible with self-reports.

An emerging literature has explored the use of clickstream data from learning management systems (LMS), which are commonly used in higher education contexts, to measure SRL in online courses. LMS (e.g., Blackboard and Canvas) provide the basic functions needed for teaching and learning online, including delivering learning materials (e.g., lecture video), managing learning activities (e.g., quizzes, assignments, and discussion), and supporting assessments (e.g., exams and essays; Lewis et al., 2005). While most previous studies used clickstream data from LMS to measure student general engagement rather than SRL, a few studies have taken a step further to measure time management, a sub-construct of SRL (e.g., Baker et al., 2018; Cicchinelli et al., 2018; Lim, 2016; Park, Denaro, Rodriguez, Smyth, & Warschauer, 2017).

Three types of behaviors related to time management have been measured: studying on time, studying in advance, and spacing. Studying on time is defined as viewing course materials or completing assignments before deadlines. Researchers have used measures such as the frequency with which students in blended courses view resources pertaining to the face-to-face meetings before the actual course meetings to capture the amount of course work that students study on time (Cicchinelli et al., 2018; Park et al., 2017). Studying in advance is defined as studying early instead of postponing studying until it is close to deadlines (Baker et al., 2018). Researchers have used measures such as how far in advance students start working on/turn in assignments in fully online courses to measure to what extent students study in advance (Crossley et al., 2016; Kazerouni, Edwards, & Shaffer, 2017; Levy & Ramim, 2013). Spacing is defined as distributing study time over a long time period instead of finishing a lot of coursework during a short time period (Baker et al., 2018; Park et al., 2017). For instance, prior research has used how widely one's work sessions are distributed within a week to capture the behavior of spacing (e.g., Baker et al., 2018; Lim, 2016; Park et al., 2017; You, 2016).

2.2.2.2. Clickstream measures predicting success in online learning
There is emerging evidence showing that clickstream measures of studying on time, studying in advance, and spacing consistently predict course performance (Baker et al., 2018; Cicchinelli et al., 2018; Crossley et al., 2016; Kazerouni et al., 2017; Lim, 2016; Park et al., 2017; You, 2016). For instance, several studies found consistent evidence that the more assignments students finished on time and the earlier students attempted or completed assignments, the better they performed on quizzes and final exams (e.g., Baker et al., 2018; Crossley et al., 2016; Park et al., 2017). In an online course where students were required to watch a number of videos by the end of the week, Baker et al. (2018) found that the behavior of spacing, measured by the standard deviation of the watch time for each of the course videos within a week, was significantly and positively associated with quiz performance and final course grade.

Moreover, there is evidence that clickstream measures have better predictive power over self-reported measures collected before the course (e.g., Cicchinelli et al., 2018). In one study examining student SRL in a blended course, Cicchinelli et al. (2018) used both self-report questionnaire and clickstream data to measure SRL and found that self-reported data collected at the beginning of the course did not predict course performance. In contrast, they found that a behavioral measure of delaying study time—the average time until a student returned to the platform after each in-person class—was significantly and negatively associated with quiz scores and final exam score.

2.3. Rationale of the study and research question
Identifying valid measures of SRL is important for researchers and practitioners in online learning. Although self-reported measures of SRL are widely used, they are time intensive to administer and may not accurately predict students' actual behaviors in the course nor their course performance. Clickstream data collected in online learning environments provide novel and promising opportunities for timely, objective, and comprehensive measures of SRL at a large scale (Roll & Winne, 2015). Prior research has mainly used clickstream data collected from LMS to measure SRL behavior related to time management. These studies have provided consistent evidence that clickstream measures of time management are predictive of student online performance.

However, despite the promising evidence on the associations between clickstream measures of time management and performance, there are three important gaps in knowledge. First, it is not clear the extent to which these clickstream measures of time management can provide valid inferences about the constructs of time management skills. The current interpretations of these clickstream measures as measuring time management skills are researchers' inferences regarding observable interactions between students and the learning management systems. Very few of the prior studies have looked beyond the associations between these clickstream measures and student performance to triangulate clickstream measures with other previously evaluated instruments (e.g., the MSLQ) to provide support for the validity of the interpretation of the clickstream measures.

Moreover, although previous studies have found significant relationships between clickstream measures of time management and student performance, very few studies have examined the extent to which these clickstream measures could significantly improve the prediction of achievement outcomes over self-reported time management alone. As self-report questionnaires have already been widely used in higher education to measure SRL, such evidence is needed to better inform practitioners deciding whether to invest their effort in understanding and utilizing the clickstream data provided by learning management systems.

Finally, there are relatively few studies using clickstream data from LMS to measure sub-constructs of SRL beyond time management. This is partially due to the types of interactions students can have within the learning environment. The features of learning management systems are often not set up to explicitly support or record SRL behaviors, such as the use of cognitive strategies (e.g., note-taking and highlighting), and therefore impose challenges in measuring SRL. However, more studies are needed to explore the potential of innovative approaches for using clickstream data from learning management systems to measure other sub-constructs of SRL, such as effort regulation.

To address these gaps, this study examined the following research questions: (1) to what extent do clickstream measures of time management and effort regulation correspond with students' self-reported use of time management and effort regulation strategies from before and after the course? (2) to what extent do clickstream measures of time management and effort regulation complement self-reported measures in predicting student performance in the current and subsequent courses?

3. Method
3.1. Research context
3.1.1. Course
This study was conducted in the context of a 10-week fully online Chemistry course at a public university in Fall 2016. The course was offered through Canvas, a learning management system, and contained four modules. Each module was comprised of between 9 and 14 small study units. All the materials were released at the beginning of the course and were available to students until the end of the course. In each module, students needed to take a one-hour quiz. The instructor recommended that students finish one module (i.e., complete all the study units and the one-hour quiz in a given module) every two to three weeks. Specifically, the four module quizzes were due on the Sundays of the second, fourth, seventh, and ninth weeks. Students' course grades were comprised of the scores from homework assignments (15%), the module quiz scores (20%), the midterm exam score (20%), and the final exam score (45%). This course was the first course of a series of general chemistry courses offered to first year college students, and students needed to get a grade of C– or better in this course in order to enroll in the subsequent courses.

3.1.2. Participants
A total of 319 freshmen enrolled in this course. Of these, 238 completed both the pre- and post-course surveys and were used as the main analytic sample. Using this sample allowed us to compare students' self-reported measures with clickstream measures of time management and effort regulation. As noted above, this course was the first of a course series. Therefore, we followed the subset of 220 students who continued to the next course and examined their course grades in the subsequent course.

3.2. Data
3.2.1. Demographic variables
The institution provided data on student prior achievement and a variety of student demographics. Eight of the 238 students who completed the pre- and post-course surveys had missing data on one or two demographic variables. Table 1 presents summary statistics on student demographic characteristics for the 230 students. The sample was predominantly female (79%). Students were, on average, around 18 years old. The sample was 48% Hispanic, 34% Asian/Pacific Islander, 13% White, and 5% African American. More than half of the students were first generation students. Around half of the students were from low-income families. Students' average high school GPA and SAT total score were 3.96 and 1619 (on a 2400 scale), respectively.


Table 1. Descriptive statistics of student demographic characteristics.

Mean	SD
Female	0.79	/
Age	18.37	0.4
Hispanic	0.48	/
Asian/Pacific Islander	0.34	/
White	0.13	/
African American	0.05	/
First generation	0.63	/
Low income	0.56	/
SAT score	1619	130.82
High school GPA	3.96	0.19
N	230
Note. 230 students (97%) in the analytic sample had complete data on demographic variables.

These characteristics are slightly different from the overall demographics of the university. Based on administrative data available from the campus, in fall 2016, the campus was 53% female, 27% Hispanic, 44% Asian/Pacific Islander, 16% White, and 3% African American; 48% of undergraduates on the campus were first generation college students, and 34% were low-income students. The average SAT score of admitted students was 1725. We address how this context might affect the generalizability of our results in the discussion section.

3.2.2. Self-reported measures
Self-reported data were collected through pre- and post-course surveys launched during the first and last week of the course, respectively. Measures adapted from MSLQ were used both in the pre- and post-course surveys to measure two sub-constructs of SRL: time management and effort regulation.

Time management was measured by two statements (α = 0.69): “I keep/kept a record of what my assignments are/were and when they are/were due” and “I plan/planned my work in advance so that I could turn in my assignments on time.” Effort regulation was measured by four statements (α = 0.67): “I often feel/felt so lazy or bored when I study/studied that I quit before I finish what I planned/had planned to do” (reverse coded), “I work/worked hard to do well in courses even if I don't/didn't like what I am/was doing,” “Even when course materials are/were dull and uninteresting, I manage/managed to keep working until I finish/finished,” and “I am/was quick to catch up with coursework when I start/started falling behind.” All the self-report questions were measured in a 5-point answer format ranging from 1 (strongly disagree) to 5 (strongly agree).

3.2.3. Clickstream measures
We generated three clickstream measures for time management and one clickstream measure for effort regulation. We drew on three sources to create these measures: the definitions of the two concepts, the key behaviors captured by the survey measures, and previous studies on clickstream data in learning management systems (e.g., Baker et al., 2018; Park et al., 2017; Pintrich, Smith, Garcia, & McKeachie, 1993).

We defined three clickstream measures to capture time management. The two survey measures of time management focus on the behavior of getting coursework done on time. Therefore, we created a clickstream measure of studying on time based on the proportion of units accessed before the deadline. Specifically, the behavior of studying a unit on time is defined as a student having visited unit page i of a given module j before the deadline of the final quiz of module j. The proportion of units a student studied on time was calculated for each module (Pj) and the average value of the proportions of units studied on time in the four modules (
 
) was used in the analysis.

In addition, previous studies suggest students with higher time management skills are more likely to study early and to space out their study time instead of procrastinating, cramming, and completing coursework right before the deadlines (e.g., Michinov, Brunot, Le Bohec, Juhel, & Delaval, 2011). Therefore, we included two additional clickstream measures—studying in advance and spacing—that have been commonly used in previous studies to measure time management (e.g., Baker et al., 2018; Crossley et al., 2016; Park et al., 2017). The behavior of studying in advance is defined as students studying a unit in advance of the deadlines. It can be captured by the time difference (Tj − Ti) between the deadline of the final quiz of a given module j (Tj) and the timestamp of when a student visited the unit page i in module j for the first time (Ti). We calculated the average value of such time differences for each module (
 
) and used the average value across the four modules as a measure of studying in advance in the analyses (
 
 
).

Spacing is defined as spacing out one's study time and it is operationalized as the standard deviation of the time differences (std(Tj − Ti)) between the deadline of the final quiz of a given module j (Tj) and the timestamp of when a student visited the unit page i in module j for the first time (Ti). Again, we used the average value of the standard deviations of the four modules in the analyses (
 
). We expected students with higher time management skills would space out their visits of the study unites and thus would have larger standard deviation values for the measure of days before deadline.

The one clickstream measure generated to capture effort regulation was based on the definition of effort regulation. Effort regulation is defined as the extent to which students can maintain their effort level when they encounter difficulties (Pintrich et al., 1993). Although it is difficult to identify specific moments when students experience difficulties, effort regulation could be approximately captured based on the overall trend of student effort level in the course. In previous studies, student effort level is usually measured by student time spent on the system, defined as time on task (Grabe & Sigler, 2002; Munk & Drlík, 2011). Therefore, we used the change in time on task during the course to measure effort regulation. For each individual student, the change in time on task during the course was operationalized as the slope of a simple linear regression that regressed time on task in a given module on the module number.

3.2.4. Performance outcomes
We used student final exam scores and overall course grades in the current course as the performance outcomes to compare the predictive power of self-reported and clickstream measures. The final exam score and overall course grade were measured on a 100-point scale and 4-point scale, respectively (see Table 2). We also predicted student course grades in the subsequent course to examine the predictive power of self-reported and clickstream measures over longer-term outcomes.


Table 2. Descriptive statistics of self-report measures, clickstream measures, and course performance.

M	SD	Min	Max	N
Pre-course self-report measures					
Time management					
 Keep record of assignments_PRE	4.07	0.93	1	5	238
 Plan in advance_PRE	4.11	0.83	1	5	238
Effort regulation					
 Quit before finishing_PRE	3.73	0.86	1	5	238
 Work hard to do well_PRE	4.2	0.83	1	5	238
 Keep working until finish_PRE	4	0.89	1	5	238
 Catch up when falling behind_PRE	3.5	1.07	1	5	238
Post-course self-report measures					
Time management					
 Keep record of assignments_POST	3.84	1.05	1	5	238
 Plan in advance_POST	3.51	1.06	1	5	238
Effort regulation					
 Quit before finishing_POST	3.55	1.02	1	5	238
 Work hard to do well_POST	3.77	0.95	1	5	238
 Keep working until finish_POST	3.97	0.91	1	5	238
 Catch up when falling behind_POST	3.64	1.05	1	5	238
Clickstream measures					
Time management					
 Study on time_CL	0.80	0.2	0.12	1	238
 Study in advance_CL	4.69	2.32	0.45	13.72	238
 Space_CL	2.88	1.05	0.29	5.01	238
Effort regulation					
 Change in time on task_CL	−0.84	0.54	−2.31	0.97	238
Course performance					
 Current Course final exam	64.99	17.78	2	99	238
 Current course grade	3.14	0.73	1.00	4.00	238
 Subsequent course grade	1.13	0.98	0.00	4.00	220
Note. 238 completed both the pre- and post-course surveys and were used as the main analytic sample. We followed a subset of students who continued to the next course. Since 18 students did not take the subsequent course in the following quarter, the analytic sample for subsequent course outcome included 220 students.

3.3. Analysis
3.3.1. Correlation analysis
To answer the first research question, we analyzed the relationships between self-reported and clickstream measures of time management and effort regulation. The analyses were conducted separately for time management and effort regulation. For each construct, we examined the Pearson correlation coefficients between the clickstream measures and both the pre-course survey measures and the post-course survey measures. If the clickstream measures aligned with students' own predictions of their time management and effort regulation behaviors, one would expect to see significantly positive correlations between the clickstream measures and the pre-course survey measures. If clickstream data can measure time management and effort regulation behaviors, and if students can accurately recall these behaviors in the course, one would expect to see significantly positive correlations between the clickstream measures and the post-course survey measures.

3.3.2. Regression analysis
To examine if clickstream measures can enhance the utility of time management and effort regulation measures, we regressed student performance outcomes on both the self-reported and clickstream measures. For each outcome variable, we conducted multiple regression analyses in five steps. The same regression analyses were conducted for pre- and post-course self-reported measures separately as clickstream measures may complement the two types of self-reported measures in different ways. The five regression models using pre-course surveys are written as:(1)
(2)
(3)
(4)
(5)

Model 1 regresses the outcome variable on the two measures of self-reported time management, denoted as TMPREki. Model 2 adds the three clickstream measures of time management, denoted as TMCLki. For each clickstream measure, a quadratic term, denoted as 
, is also included as previous research has found that the relationship between clickstream measures and performance tend to be nonlinear (Li, Kidzinski, Jermann, & Dillenbourg, 2015). To determine whether the quadratic term is needed given that a linear term is already in the model, we first regressed the outcome variable only on the linear and quadratic terms of a clickstream measure and examined if the coefficient on the quadratic term was statistically significant. Model 3 regresses the outcome variable on the four measures of self-reported effort regulation, denoted as ERPREki. Model 4 adds the linear and quadratic terms of the clickstream measure of effort regulation, denoted as ERCLi and 
. Finally, Model 5 regresses the outcome variable on the self-reported and clickstream measures of both time management and effort regulation, controlling for all the demographic variables listed in Table 1, denoted as Student_controli.

4. Results
4.1. Correlations between self-reported measures and clickstream measures
We first report the Pearson's correlation coefficients between clickstream measures and self-reported measures. Table 3 presents the results for time management and Table 4 presents the results for effort regulation. There were differences in the extent to which clickstream measures were related to the same self-reported measures from the pre- and post-course surveys. For both time management and effort regulation, there were moderate, positive, and significant correlations between clickstream measures and post-course survey measures. However, the correlations between clickstream measures and pre-course survey measures were, in general, small and insignificant.


Table 3. Correlations between self-report and clickstream measures of time management measures and course performance.

K_PRE	P_PRE	K_POST	P_POST	SOT_CL	SA_CL	SP_CL	CFE	CCG
Keep record of assignments_PRE	1								
Plan in advance_PRE	0.53⁎⁎⁎	1							
Keep record of assignments_POST	0.31⁎⁎⁎	0.30⁎⁎⁎	1						
Plan in advance_POST	0.31⁎⁎⁎	0.37⁎⁎⁎	0.56⁎⁎⁎	1					
Study on time_CL	0.08	0.07	0.22⁎⁎⁎	0.27⁎⁎⁎	1				
Study in advance_CL	0.02	0.17⁎⁎⁎	0.22⁎⁎⁎	0.35⁎⁎⁎	0.33⁎⁎⁎	1			
Space_CL	0.04	0.10	0.20⁎	0.13⁎	0.54⁎⁎⁎	0.49⁎⁎⁎	1		
Current course final exam score	−0.09	0.00	0.15⁎	0.16	0.47⁎⁎⁎	0.36⁎⁎⁎	0.33⁎⁎⁎	1	
Current course grade	−0.07	0.02	0.14⁎	0.16⁎	0.50⁎⁎⁎	0.36⁎⁎⁎	0.32⁎⁎⁎	0.94⁎⁎⁎	1
⁎
p < .05.

⁎⁎
p < .010.

⁎⁎⁎
p < .001.


Table 4. Correlations for self-report and clickstream measures of effort regulation measures and course performance.

Q_PRE	W_PRE	K_PRE	C_PRE	Q_POST	W_POST	K_POST	C_POST	CT_CL	CFE	CCG
Quit before finishing_PRE	1										
Work hard to do well_PRE	0.23⁎⁎⁎	1									
Keep working until finished_PRE	0.32⁎⁎⁎	0.43⁎⁎⁎	1								
Catch up when falling behind_PRE	0.25⁎⁎⁎	0.34⁎⁎⁎	0.41⁎⁎⁎	1							
Quit before finishing_POST	0.35⁎⁎⁎	0.03	0.25⁎⁎⁎	0.08	1						
Work hard to do well_POST	0.19⁎⁎	0.2⁎⁎	0.34⁎⁎⁎	0.07	0.32⁎⁎⁎	1					
Keep working until finish_POST	0.22⁎⁎⁎	0.04	0.27⁎⁎⁎	0.12	0.42⁎⁎⁎	0.44⁎⁎⁎	1				
Catch up when falling behind_POST	0.29⁎⁎⁎	0.08	0.29⁎⁎⁎	0.17⁎	0.34⁎⁎⁎	0.35⁎⁎⁎	0.46⁎⁎⁎	1			
Change in time on task_CL	0.22⁎⁎⁎	0.00	0.1	−0.05	0.21⁎⁎	0.26⁎⁎⁎	0.30⁎⁎⁎	0.28⁎⁎⁎	1		
Current course final exam score	0.07	0.08	0.01	−0.07	0.17⁎⁎	0.18⁎	0.30⁎⁎⁎	0.23⁎⁎⁎	0.41⁎⁎⁎	1	
Current course grade	0.05	0.09	0.03	−0.05	0.20⁎⁎	0.21⁎⁎	0.32⁎⁎⁎	0.29⁎⁎⁎	0.42⁎⁎⁎	0.94⁎⁎⁎	1
⁎
p < .05.

⁎⁎
p < .010.

⁎⁎⁎
p < .001.

These results for the time management are shown in Table 3. There were significant positive correlations between the measures of time management from the post-course survey and the clickstream measures of studying on time, studying in advance, and spacing. However, for the pre-course survey measures, only planning in advance was significantly correlated with the clickstream measure of studying in advance, r(238) = 0.17, p < .05. We found similar results for effort regulation, shown in Table 4. All of the e effort regulation measures in the post-course survey were positively and significantly correlated with the change in time on task. In contrast, on the pre-course survey only the self-reported measure of quitting before finishing was significantly correlated with this clickstream measure, r(238) = 0.22, p < .001.

These significant correlations between clickstream measures and post-course survey measures show the alignment between the behavioral clickstream measures and students' own interpretations of their time management and effort regulation behaviors. These significant relationships provide evidence for the validity of using clickstream measures to infer students' time management and effort regulation skills. Additionally, the sizes of the correlation coefficients between post-course survey measures and clickstream measures were relatively small, suggesting the clickstream measures captured unique information about students and might potentially help to improve course performance prediction above survey measures alone. Finally, the lack of significant correlations between pre-course survey measures and clickstream measures, which aligns with the results from previous studies (Gilbert & Wilson, 2007), suggests that students' predictions of their behavior made before the course may not reflect their actual behavior in the course.

4.2. Relationships between survey and clickstream measures and course performance
While the bivariate correlations indicate that the clickstream measures were associated with student self-reported self-regulation of time and effort after the course, the question remains as to what extent that these clickstream measures could provide additional information. That is, can they be used to improve the predictions of student performance based on self-reported data alone? We used regression analyses to examine the predictive power of both self-reported and clickstream measures on students' course performance. Table 5, Table 6 presents these results; Table 5 shows results from using clickstream measures and self-reported measures from the pre-course survey to predict course performance, and Table 6 presents results from the same regression analyses using self-reported measures from the post-course survey.


Table 5. Pre-course self-report and clickstream measures of self-regulation predicting performance.

Course Grade	Final Exam Score
M1	M2	M3	M4	M5	M1	M2	M3	M4	M5
Time management										
 Keep record of assignments_PRE	−0.111	−0.116+			−0.070	−0.121	−0.122+			−0.089
(0.08)	(0.07)			(0.06)	(0.08)	(0.07)			(0.06)
 Plan in advance_PRE	0.081	0.017			0.078	0.064	−0.004			0.055
(0.08)	(0.07)			(0.06)	(0.08)	(0.07)			(0.06)
 Study on time_CL		0.441⁎⁎⁎			0.160⁎		0.395⁎⁎⁎			0.161+
(0.07)			(0.08)		(0.07)			(0.08)
 Study in advance_CL		0.238⁎⁎			0.143⁎		0.258⁎⁎⁎			0.155⁎
(0.07)			(0.07)		(0.08)			(0.07)
 Study in advance_CL2		−0.019			−0.005		−0.042			−0.028
(0.04)			(0.04)		(0.04)			(0.04)
 Space_CL		−0.028			0.003		0.001			0.033
(0.07)			(0.07)		(0.07)			(0.07)
 Space_CL2		0.004			0.004		0.015			0.013
(0.05)			(0.04)		(0.05)			(0.05)
Effort regulation										
 Quit before finishing_PRE			0.050	−0.031	−0.048			0.075	−0.005	−0.017
(0.07)	(0.06)	(0.06)			(0.07)	(0.06)	(0.06)
 Work hard to do well_PRE			0.114	0.137⁎	0.148⁎⁎			0.109	0.131⁎	0.146⁎
(0.07)	(0.06)	(0.06)			(0.07)	(0.07)	(0.06)
 Keep working until finish_PRE			0.007	−0.057	−0.066			−0.008	−0.067	−0.070
(0.08)	(0.07)	(0.06)			(0.08)	(0.07)	(0.06)
 Catch up when falling behind_PRE			−0.103	−0.027	−0.030			−0.119	−0.049	−0.050
(0.07)	(0.06)	(0.06)			(0.07)	(0.07)	(0.06)
 Change in time on task_CL				0.449⁎⁎⁎	0.245⁎⁎⁎				0.428⁎⁎⁎	0.206⁎⁎
(0.06)	(0.07)				(0.06)	(0.08)
 Change in time on task_CL2				−0.193⁎⁎⁎	−0.115⁎⁎				−0.159⁎⁎⁎	−0.080⁎
(0.04)	(0.04)				(0.04)	(0.04)
Student controls					Yes					Yes
Partial F test										
 Self-reported time management	1.10					1.24				
 Clickstream measures of time management	19.24⁎⁎⁎					17.55⁎⁎⁎			
 Self-reported effort regulation			1.09					1.30		
 Clickstream measure of effort regulation			41.22⁎⁎⁎					32.85⁎⁎⁎	
 N	238	238	238	238	230	238	238	238	238	230
 R square	0.009	0.301	0.018	0.277	0.507	0.010	0.284	0.022	0.238	0.459
Note. Two outcomes in the current course—course grade and final exam score—were used. For each performance outcome, five regression models were tested. Model 1 regresses course performance on self-reported time management and Model 2 adds the clickstream measures (Eqs. (1), (2)). Similarly, Model 3 regresses course performance on self-reported effort regulation and Model 4 adds the clickstream measure (Eqs. (3), (4)). Finally, Model 5 regresses course performance outcomes on all self-report measures, clickstream measures, and student controls listed in Table 1 (Eq. (5)). All coefficients are standardized.

+
p < .1.

⁎
p < .05.

⁎⁎
p < .010.

⁎⁎⁎
p < .001.


Table 6. Post-course self-report and clickstream measures of self-regulation predicting performance.

Course Grade	Final Exam Score
M1	M2	M3	M4	M5	M1	M2	M3	M4	M5
Time management									
 Keep record of assignments_POST	0.075	0.031			−0.005	0.091	0.044			0.012
(0.08)	(0.07)			(0.06)	(0.08)	(0.07)			(0.06)
 Plan in advance_POST	0.118	−0.059			−0.066	0.104	−0.065			−0.046
(0.08)	(0.07)			(0.07)	(0.08)	(0.07)			(0.07)
 Study on time_CL		0.439⁎⁎⁎			0.127		0.391⁎⁎⁎			0.141+
(0.07)			(0.08)		(0.07)			(0.08)
 Study in advance_CL		0.260⁎⁎			0.108		0.276⁎⁎⁎			0.133+
(0.08)			(0.07)		(0.08)			(0.08)
 Study in advance_CL2		−0.021			0.011		−0.043			−0.013
(0.04)			(0.04)		(0.04)			(0.04)
 Space_CL		−0.041			0.020		−0.015			0.033
(0.08)			(0.07)		(0.08)			(0.07)
 Space_CL2		−0.003			0.002		0.006			0.016
(0.05)			(0.04)		(0.05)			(0.05)
Effort regulation										
 Quit before finishing_POST			0.047	0.040	0.056			0.029	0.020	0.037
(0.07)	(0.06)	(0.06)			(0.07)	(0.06)	(0.06)
 Work hard to do well_POST			0.047	0.025	0.048			0.027	0.001	0.021
(0.07)	(0.06)	(0.06)			(0.07)	(0.07)	(0.06)
 Keep working until finish_POST			0.202⁎⁎	0.105	0.100			0.224⁎⁎	0.134+	0.117+
(0.08)	(0.07)	(0.06)			(0.08)	(0.07)	(0.07)
 Catch up when falling behind_POST			0.166⁎	0.084	0.044			0.113	0.036	−0.013
(0.07)	(0.07)	(0.06)			(0.07)	(0.07)	(0.07)
 Change in time on task_CL				0.367⁎⁎⁎	0.219⁎⁎				0.367⁎⁎⁎	0.186⁎
(0.06)	(0.07)				(0.06)	(0.08)
 Change in time on task_CL2				−0.172⁎⁎⁎	−0.111⁎⁎				−0.140⁎⁎⁎	−0.078⁎
(0.04)	(0.04)				(0.04)	(0.04)
Student controls				Yes					Yes
Partial F test									
Self-reported time management	3.58⁎					3.62⁎				
Clickstream measures of time management	17.06⁎⁎⁎					15.22⁎⁎⁎			
Self-reported effort regulation	8.87⁎⁎⁎					6.70⁎⁎⁎		
Clickstream measure of effort regulation		26.50⁎⁎⁎					22.02⁎⁎⁎	
N	238	238	238	238	230	238	238	238	238	230
R square	0.030	0.292	0.132	0.294	0.509	0.030	0.271	0.103	0.247	0.450
Note. Two outcomes in the current course—course grade and final exam score—were used. For each performance outcome, five regression models were tested. Model 1 regresses course performance on self-reported time management and Model 2 adds the clickstream measures (Eqs. (1), (2)). Similarly, Model 3 regresses course performance on self-reported effort regulation and Model 4 adds the clickstream measure (Eqs. (3), (4)). Finally, Model 5 regresses course performance outcomes on all self-report measures, clickstream measures, and student controls listed in Table 1 (Eq. (5)). All coefficients are standardized.

+
p < .1.

⁎
p < .05.

⁎⁎
p < .010.

⁎⁎⁎
p < .001.

4.2.1. Relationships between pre-course survey and clickstream measures and student performance in the current course
Results from Model 1 and Model 3 in Table 5 reveal that students' self-reported time management and effort regulation from the pre-course survey did not predict performance in the current course. The joint F test for the overall significance of Model 1 revealed that neither of the coefficients on the two time management measures was statistically significant for course grade, F(2, 235) = 1.10, p = .35, or final exam score, F(2, 235) = 1.24, p = .29. Similarly, the joint F test for the four self-reported measures of effort regulation in Model 3 showed that none of the coefficients significantly predicted course grade, F(4, 233) = 1.09, p = .36, or final exam score, F(4, 233) = 1.30, p = .27.

In contrast, we found that the clickstream measures of both time management and effort regulation significantly improved the prediction of both course grades and final exam scores in the current course. Adding the clickstream measures of time management significantly increased the explanatory power of the regression models for both course grades and final exam scores, shown by the partial F tests in Model 2 (course grade, F(5, 230) = 19.24, p < .001; final exam scores, F(5, 230) = 17.55, p < .001). This is particularly true for the clickstream measures of studying on time and studying in advance. For instance, a one standard deviation increase in studying on time was associated with approximately a 0.4 standard deviation increase in course grade and final exam score.

We found similar results for effort regulation. Adding linear and quadratic measures of change in time on task significantly increased the explanatory power of the regression models for both course grade and final exam score, after controlling for self-reported effort regulation. These are shown by the partial F tests in Model 4 for course grades, F(2, 231) = 41.22, p < .001, and final exam score, F(2, 231) = 32.85, p < .001. For instance, the change in time on task had a significantly positive linear relationship (ß = 0.449, p < .001) and a significantly negative quadratic relationship (ß = −0.193, p < .001) with course grade. These results suggest that an increase in time on task was associated with better performance; however, the relationship was weaker for students who had larger increases in their time on task.

Finally, the clickstream measures of studying on time, studying in advance, and the change in time on task were significant predictors of course performance even after controlling for a variety of student background characteristics (e.g., gender, race, and prior performance) (see Table 5 Model 5). For instance, a one standard deviation increase in studying on time was associated with around a 0.16 standard deviation increase in course grade and final exam score. Again, after controlling for student background characteristics, there was a positive relationship between change in time on task and course grade (ß = 0.245, p < .001), but the relationship was weaker for students who had larger increases in time on task, as indicated by the coefficient on the quadratic term (ß = −0.115, p < .01).

4.2.2. Relationships between post-course survey and clickstream measures and student performance in the current course
We then repeated the same analyses using self-reported measures from the post-course survey and the same clickstream measures (see Table 6). First, results from Model 1 and Model 3 suggest that, unlike self-reported measures in the pre-course survey, the measures from the post-course survey were predictive of student performance in the current course. The joint F tests of the overall significance of Model 1 show that together the two time management measures were significantly associated with course grade, F(2, 235) = 3.58, p < .05, and final exam score, F(2, 235) = 3.62, p < .05, although neither of the coefficients on the two time management measures in Model 1 was individually significant at the 0.1 level for either course grades or final exam scores.

For effort regulation, the joint F tests of Model 3 reveal that together the four self-reported measures of effort regulation were significantly associated with course grade, F(4, 233) = 8.87, p < .001, and final exam score, F(4, 233) = 6.70, p < .001. In particular, results in Model 3 showed that the self-reported measure of keeping working until finished was predictive of course grade (β = 0.202, p < .01) and final exam score (β = 0.224, p < .01), and the self-reported measure of catching up when falling behind was predictive of course grade, (ß = 0.166, p < .05), though not final exam score. These significant relationships between course performance and student self-reported measures from after the course may suggest that students were more accurate at reporting their time management and effort regulation after they had experienced online courses. However, these findings may also suggest that, when asked to report one's use strategies after the course, performance in the course might influence students' self-reports.

In spite of the good predictive power of self-reported measures from the post-course survey, we found that adding clickstream measures still improved the prediction of student performance in the current course. The partial F tests for all the clickstream measures of time management in Model 2 show that adding the clickstream measures of time management significantly increased the explanatory power of the regression models for both course grade, F(5, 230) = 17.06, p < .001, and final exam score, F(5, 230) = 15.22, p < .001. Specifically, there were large, positive, and significant relationships between course performance and the measures of studying on time and studying in advance. For instance, the clickstream measure of studying on time was significantly associated with course grade (ß = 0.439, p < .001) and final exam score (ß = 0.391, p < .001), even after controlling for self-reported time management from the post-course survey. Similarly, results in Model 4 showed that adding the linear and quadratic terms of the change in time on task significantly increased the prediction of course grade, F(2, 231) = 26.50, p < .001, and final exam score, F(2, 231) = 22.02, p < .001, after controlling for self-reported effort regulation from the post-course survey.

When including all self-reported and clickstream measures and additionally controlling for student background characteristics in Model 5, the clickstream measures of studying in advance and studying on time were still predictive of final exam score, though not of course grade. Again, there were significant, positive relationships between the measure of change in time on task and both course grade and final exam score, however, the positive relationships were smaller for students with larger increases in time on task, as indicated by the negative coefficients on the quadratic terms.

4.2.3. Relationships between post-course survey and clickstream measures and student performance in the subsequent course
Finally, we examined whether clickstream measures could improve predictions of subsequent course outcomes from models using self-reported measures from the post course survey. First, to make sure that any potential difference in observed relationships between SRL measures and course outcomes from the current and subsequent courses was not due to the change in the student sample, we re-estimated the relationships between student grades in the current course and clickstream and self-reported measures on the subset of students who enrolled in the subsequent course (N = 220). The results are presented in the first five columns in Table 7. Most of the regression coefficients were similar in size and directions to those in Table 6, suggesting that potential differences in the two samples were not qualitatively changing the observed relationships. We then conducted the same analyses using student grade in the subsequent course as the outcome measure. The results are presented in the last five columns in Table 7.


Table 7. Post-course report and clickstream measures of self-regulation predicting subsequent course grade.

Current Course Grade	Subsequent Course Grade
M1	M2	M3	M4	M5	M1	M2	M3	M4	M5
Time management										
 Keep record of assignments_POST	0.002	−0.013			−0.017	−0.086	−0.101			−0.080
(0.07)	(0.07)			(0.07)	(0.08)	(0.07)			(0.06)
 Plan in advance_POST	0.118	−0.040			−0.048	0.283⁎⁎⁎	0.126			0.166⁎
(0.07)	(0.08)			(0.07)	(0.08)	(0.08)			(0.07)
 Study on time_CL		0.373⁎⁎⁎			0.163⁎		0.288⁎⁎⁎			0.125
(0.07)			(0.08)		(0.07)			(0.08)
 Study in advance_CL		0.312⁎⁎⁎			0.163⁎		0.298⁎⁎⁎			0.130+
(0.08)			(0.08)		(0.08)			(0.07)
 Study in advance_CL2		−0.030			−0.000		0.005			0.008
(0.04)			(0.04)		(0.04)			(0.04)
 Space_CL		−0.076			−0.013		−0.035			−0.010
(0.08)			(0.07)		(0.08)			(0.07)
 Space_CL2		−0.029			−0.004		−0.032			−0.018
(0.05)			(0.05)		(0.05)			(0.04)
Effort regulation										
 Quit before finishing_POST			0.019	0.033	0.055			−0.013	−0.002	−0.059
(0.07)	(0.07)	(0.06)			(0.07)	(0.07)	(0.06)
 Work hard to do well_POST			0.007	−0.032	0.006			0.086	0.051	0.085
(0.07)	(0.07)	(0.06)			(0.08)	(0.07)	(0.06)
 Keep working until finish_POST			0.244⁎⁎	0.159⁎	0.139⁎			0.130	0.057	−0.068
(0.08)	(0.08)	(0.07)			(0.08)	(0.08)	(0.07)
 Catch up when falling behind_POST			0.154⁎	0.118+	0.060			0.120	0.088	−0.049
(0.07)	(0.07)	(0.07)			(0.08)	(0.07)	(0.06)
 Change in time on task_CL				0.290⁎⁎⁎	0.123				0.252⁎⁎⁎	−0.063
(0.07)	(0.08)				(0.07)	(0.08)
 Change in time on task_CL2				−0.140⁎⁎⁎	−0.078⁎				−0.121⁎⁎	−0.017
(0.04)	(0.04)				(0.04)	(0.04)
Student controls				Yes					Yes
Current course grade									Yes
Partial F test									
 Self-reported time management	2.02					6.95⁎⁎				
 Clickstream measures of time management	13.50⁎⁎⁎					11.10⁎⁎⁎			
 Self-reported effort regulation		7.56⁎⁎⁎					3.74⁎⁎		
 Clickstream measure of effort regulation				12.65⁎⁎⁎					8.61⁎⁎⁎	
 N	220	220	220	220	213	220	220	220	220	213
 R square	0.018	0.252	0.123	0.175	0.460	0.060	0.254	0.065	0.104	0.549
Note. Regression analyses in the left panel regress student grades in the current course on clickstream measures, self-report measures in the post-course survey, and student controls listed in Table 1 only for the subset of students who enrolled in the subsequent course (N = 220). Regression analyses in the right panel regress student grades in the subsequent course on clickstream measures, self-report measures in the post-course survey, and student controls listed in Table 1 for the same subset of students. All coefficients are standardized.

+
p < .1.

⁎
p < .05.

⁎⁎
p < .010.

⁎⁎⁎
p < .001.

In general, we found evidence that clickstream measures of time management and effort regulation could improve the prediction of students' subsequent course grades using just self-reported measures from the post-course survey. In Models 2 and 4 in the right panel of Table 7, the partial F tests show that, while the self-reported measures were predictive of subsequent course performance, adding the clickstream measures of time management, F(5, 212) = 11.10, p < .001, and effort regulation, F(2, 213) = 8.61, p < .001, significantly improved the prediction of subsequent course grade. Finally, results from Model 5 in the same panel indicate that, after further controlling for students' background characteristics and current course grade, there was still a significant and positive relationship between students' subsequent course grade and the clickstream measure of studying in advance (ß = 0.130, p < .1).

5. Discussion
5.1. Key findings
In this study, we examined the extent to which clickstream data collected from the LMS can be used to measure and understand students' time management and effort regulation behaviors and to increase the effectiveness of the identification of at-risk students. Specifically, we triangulated clickstream measures with student self-reported data from before and after the course. These analyses provide direct empirical evidence on the extent to which clickstream measures align with self-reported measures. In addition, we used regression analyses to examine whether adding clickstream measures to models predicting current and subsequent course outcomes could improve predictions from models using only self-reported measures. The results provide a useful guidance to wisely choose SRL measures to trace the student learning process and to support students with low SRL skills.

5.1.1. Pre-course survey measures did not correspond to clickstream measures nor did them predict course performance
We found that self-reported measures from the pre-course survey were not correlated with students' clickstream behaviors later in the course nor were they predictive of students' current course performance. In contrast, students' self-reported measures of time management and effort regulation from the post-course survey were correlated with their clickstream behaviors and were predictive of current and subsequent course performance outcomes.

As suggested by previous studies, one potential reason for the lack of significant relationships of pre-course survey measures is that students tend to be overconfident at the beginning of the course and cannot accurately predict their behavior in the course (DiBenedetto & Bembenutty, 2013; Gilbert & Wilson, 2007). This may be especially problematic in our research setting. Students in our sample were in their first year of college and had little or no prior experience with online learning. Indeed, we found students' self-reported time management and effort regulation behaviors both decreased from the beginning to the end of the course; except for the measure of catching up when falling behind, students reported lower values on all of self-reported measures in the post-course survey as compared to the pre-course survey.

5.1.2. Clickstream measures corresponded to post-course survey measures and improved course performance prediction
We found that many of our clickstream measures were significantly correlated with self-reported measures from the post-course survey. Specifically, we found that the clickstream measures of studying on time, studying in advance, and spacing were significantly correlated with students' self-reported time management skills. The clickstream measure of the change in time on task was significantly correlated with students' self-reports of effort regulation. Additionally, the clickstream measures significantly improved the predictions of both current and subsequent course performance outcomes over models using only self-reported measures from the post-course survey. These findings show that the clickstream measures of time management and effort regulation were both related to measures of the same concepts from a well-established instrument (MSLQ) and predictive of student academic success in an expected way, suggesting that these clickstream measures can be used as valid tools to trace student SRL process and to identify at-risk students (Messick, 1995).

5.2. Implications
5.2.1. Research implications
Collectively, these findings have important implications for future research regarding SRL in online learning environments. First, we found suggestive evidence that students might overestimate their time management and effort regulation skills at the beginning of the course, which may explain why these self-reported measures did not predict course performance. These findings are in alignment with previous research that identified miscalibrations between students' actual and self-reported abilities and skills: students tend to overestimate their performance and SRL behaviors at the beginning of the course, with low-performing students exhibiting the most biased estimates (Dang, Chiang, Brown, & McDonald, 2018; DiBenedetto & Bembenutty, 2013; Osterhage, Usher, Douin, & Bailey, 2019; Winne & Jamieson-Noel, 2002).

Various explanations have been proposed for the miscalibration, such as students' low metacognitive skills, the novelty of the course or learning environment, and the lack of external feedback on students' performance and behavior (Dang et al., 2018; Winne & Jamieson-Noel, 2002). However, more empirical evidence is needed to understand what factors contribute to students' misperceptions of their ability and skills, how students correct their estimations over time, and what supports are needed to help students better estimate their own behaviors. For instance, future research could examine the relationship between students' characteristics, such as metacognitive skills, and the accuracy of their estimation. Longitudinal studies are needed to investigate if and how students' estimation improves as they gain more experience with a certain type of learning environment (e.g., online courses). Finally, experimental studies could test if interventions, such as external feedback in the form of teacher or peer evaluations, could influence students' self-evaluations.

In addition, the evidence on the validity of these fine-grained and unobtrusive clickstream measures allow researchers to use them in future studies to extend our understanding of the dynamics of time management and effort regulation behaviors at a more micro-level. In particular, along with longitudinal analysis methods, these measures could be used to track how time management and effort regulation behaviors gradually and dynamically unfolds in authentic learning environments and to examine the different changing trajectories across students. Furthermore, using these detailed clickstream measures, researchers could explore how personal and environmental factors (e.g., students' interest in the course content and the academic and social resources available) shape students' behavior by examining the context under which a given behavior (e.g., students completing homework in advance) is most likely to occur.

5.2.2. Practical implications
Much work has identified the ways in which self-reported questionnaires that measure SRL can be used to support students in online classes, both in terms of identifying at-risk students and in terms of better understanding potential challenges. Self-reported SRL surveys have been used to inform students' own decisions regarding course selection, to help institutions evaluate students' skills needed to succeed in online learning, as well as to guide the provision of timely and personalized support to prevent student failure (Bork & Rucks-Ahidiana Bork & Rucks-Ahidiana, 2013; Chen, 2009; Lee, Choi, & Kim, 2013; Rowe & Rafferty, 2013). However, our results suggest that self-reported data from before a course starts may not be reliable. This raises important concerns about the usefulness of self-reported measures of SRL. This problem may be particularly acute for students who have little online learning experience. Practitioners need to be cautious when using and interpreting self-reports of SRL behaviors from students who lack online learning experience. As a potential solution for this concern, practitioners could administer surveys during, instead of before, the course to give students some time to develop an appropriate understanding of their own behavior and online learning more broadly.

However, self-evaluations that are administered during a course may be too late for students to make a choice about which classes to take or for instructors provide appropriate supports for students. Thus, another potential policy solution that arises as an implication of this research is the provision of online orientation courses that students could take before enrolling in online courses. Such modules could prepare students with appropriate expectations of online learning and support them in more accurately predicting their future behavior (Bork & Rucks-Ahidiana, 2013).

In addition, while clickstream data have been used to predict student performance and identify at-risk students, their utility have been critiqued in past studies (e.g., Gašević, Dawson, & Siemens, 2015; Tempelaar, Rienties, & Nguyen, 2017; Van den Bogaard & De Vries, 2017) as raw clickstream measures (e.g., number of total page views and frequency of login) provide little, if any, insight into why students might be at risk and thus offer no clear guidance on how to intervene. This study, however, identified several clickstream measures of time management and effort regulation that can provide actionable information and potential directions for interventions. Since these measures are generated from data that are commonly recorded in learning management systems widely used by higher education institutions, real-time reports based on these clickstream measures can be easily automatically generated to inform education decision-making by students, instructors, and administrators. For instance, our findings suggest that instructors could use clickstream measures to identify students who may be suffering from poor time management skills and provide support (e.g., sending them reminders to encourage them make a study plan ahead of time) based on updated estimates of student time management skills using real-time clickstream data.

5.3. Limitations
There are a few limitations to this study. First, we observed some interesting differences in the ways that self-reported measures predicted course performance in the current and subsequent courses. For instance, while the post-course survey measure of planning in advance was not predictive of current course performance, it was significantly associated with subsequent course performance. One potential explanation for the difference is that most of the students (99.95%) in the subsequent course analysis were enrolled in the in-person section, which may require different types of skills. Therefore, future research is needed to examine how student self-reported and clickstream measures of SRL collected in online courses may differentially predict students' performance in different types of subsequent courses.

Additionally, as we noted in the section describing our data, this study took place on a selective college campus with a racially and ethnically diverse student body. This context has implications for the generalizability of the findings. By virtue of being enrolled in a selective four-year college, many students in this study likely had had the opportunity to develop SRL skills and thus might be relatively capable of accurately reporting their SRL skills. Self-report questionnaires of SRL may be even less effective for accurately measuring students' SRL skills in other settings in higher education such as community colleges. Moreover, as the range of SRL skills exhibited by students in this study might not represent the range of skills in other settings, the clickstream measures we found to be effective at detecting these skills within this sample might not perform similarly in other contexts. Work that examines the contextual factors that affect the effectiveness of these self-reported and clickstream measures could inform potential applicability to other contexts.

5.4. Conclusion
This study provides a methodological foundation and practical guidance for the use of clickstream data to trace and understand SRL behaviors and to identify students who lack SRL skills and are at-risk of low performance in virtual learning environments. Using the clickstream measures that have been verified in this study, future research can track student SRL behaviors and explore the antecedents and consequences associated with SRL behaviors. Such examinations may help with the development of comprehensive frameworks of how student behaviors dynamically interact with personal and environmental factors. Additionally, this study raises important concerns regarding the use of self-report questionnaires to measure SRL and identify at-risk students. Since the memories that students use to reflect on their past behavior or predict their future SRL behaviors are not always accurate, relying solely on self-reported data may lead to inaccurate measures of SRL and under- or over-identification of at-risk students. Finally, this study highlights the unique and significant contributions of clickstream data in the identification of at-risk students. Institutional efforts can be made to use clickstream data to develop and provide real-time analytic reports of online students so that students, instructors, and institutions can make more timely and informed decisions.

