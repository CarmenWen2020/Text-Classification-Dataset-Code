Remedial college courses generate tuition and fit neatly into existing course structures. But they often fail to deliver access and success in foundational “gateway” undergraduate courses. Because under-represented minorities are over-represented in these courses, remedial courses obstruct equitable access and success. Schools are increasingly turning instead to supplemental instruction and Internet-based intelligent tutoring systems (ITSs). But these alternatives don't generate tuition, are difficult to evaluate, and can require substantial infrastructure. This study compared 2561 students who qualified for Principles of Chemistry and Biochemistry by passing Developmental Chemistry with 607 students who qualified by completing a commercial Internet-based ITS. Propensity-score techniques were used to control for biased selection and assignment. We found that spending approximately 30 h on a $30 ITS was equally as effective as spending hundreds of hours and thousands of dollars of tuition on a three or five credit remedial course in terms of final grades in Principles for the entire population as well as for under-represented minorities. This finding has implications for advising students and for designing and evaluating programs for underprepared students and under-represented minorities.

Previous
Next 
Keywords
Developmental education

Intelligent tutoring systems

Supplemental instruction

Educational equity

Propensity score matching

1. Introduction
Most colleges and universities offer some form of remediation or assistance for students who are underprepared for foundational “gateway” lower division courses. Because access to and success in gateway courses is essential for desirable majors and degrees, these practices have tremendous implications for selection of majors and graduation rates. Ongoing efforts to increase college access and success have drawn new attention to these practices. In English speaking countries and many other countries around the world, schools have traditionally relied on developmental education (DE) to prepare students for gateway courses. Students are typically assigned to DE courses based on scores on placement tests and/or entrance exams. Usually, students must pass those courses (and sometimes the placement test) before they can enroll in the targeted gateway courses. Proponents cite reviews of the extensive published literature (e.g., Boylan and Bonham, 1992, Boylan and Bonham, 2007; Boylan & Boone, 1995) to argue that high-quality DE courses (which are sometimes labeled remedial) give struggling students the time and focus needed to prepare for more rigorous gateway courses.

As reported in the Wall Street Journal, the number of college students in the US taking at least one DE course rose from 1.04 million in 2000 to 2.7 million in 2012 (Mitchell, 2014). This trend reflects a rise in college enrollment among low-income, under-represented minority, and older populations, and increasing expectations regarding mathematical proficiency. Oakley and Burdman (2015) expressed concern over growing DE placements and pointed out that 85% of community college students in the US state of California were required to take at least one developmental math course. As with other aspects of education, stakeholders and researchers have debated the effectiveness and return on investment from DE. There is now broad agreement that only a fraction of students who test into DE language and math courses go on to graduate (findings range from 10 to 25%). The title of a 2012 report from seven leading higher education organizations in the US dramatically illustrated the perception of developmental education: Remediation: Higher Education's Bridge to Nowhere (Complete College America, 2012).

This paper aims to shed new light on DE in higher education by placing it in the broader context of what we are calling developmental, supplemental and tutorial services (DSTSs). The paper first describes (a) the shortcomings and persistence of DE, (b) the challenges facing an increasingly popular alternative known as supplemental instruction (SI), and (c) a newly available alternative represented by Internet-based intelligent tutoring systems (ITSs). The paper then considers how bias in assignment and selection makes it hard to evaluate the real-world impact and return-on-investment (ROI) of these very different solutions. Finally, the paper describes an initial study that used propensity score techniques to control for these biases to compare the impact of a three-credit or five-credit DE course with a $30 commercial Internet-based ITS, in terms of final grades in a gateway Chemistry course. Together, these observations and examples support the argument that schools should explore the range of alternatives for supporting the success of all students in gateway courses while using learning analytics to track impact and ROI.

1.1. The limitations and persistence of developmental education
The placement of underprepared students in developmental courses has tremendous implications for students who are members of under-represented minority (URM) groups. This is because URM students are dramatically over-represented in DE courses (Bailey & Cho, 2010). In most US schools, this includes African American, Hispanic, and Latinx students, but not Asian Americans. This racialization has led educators to sometimes characterize DE as a “remedial ghetto” (e.g., Zwerling, 1979). As such, DE courses are one of the largest barriers to inclusion and success of URM students in post-secondary education, degrees, and employment (Crisp & Delgado, 2014; Crisp & Nora, 2010).

On one hand, the president of the conservative Fordham Foundation argued that perhaps underprepared students should not be admitted to college (Petrilli, 2013, Petrilli, 2014). On the other hand, a growing body of research suggests that many students who test into the DE course might have been able to succeed in the gateway course. Multiple studies have compared students just above the placement test cutoff with students just below the cutoff, convincing many that DE placement substantially increases dropout rates (e.g., Scott-Clayton, Crosta, & Belfield, 2014). Many now question the predictive validity of placement tests, and some argue high-school GPAs are better predictors (Oakley & Burdman, 2015). One study concluded that over half of students placed in remedial English and mathematics could have earned a C or better without remediation (Scott-Clayton, 2012). The Community College Research Center at Columbia University has been particularly critical of DE (e.g., Bailey, 2009; Bailey & Cho, 2010; Bailey, Jaggars, & Scott-Clayton, 2013). These and other researchers question the evidence that proponents have marshaled to support DE. Indeed, transforming or eliminating DE is one of the five core principles of the aforementioned Bridge to Nowhere report. Outside of the US, similar concerns have been raised around the world regarding the limitations of DE courses and the need for more effective alternatives (Malm, Bryngfors, & Morner, 2011), with concentrations of concerns in the UK and Australia (see Arendale, 2002).

The persistence of DE in the face of compelling evidence of ineffectiveness for many students and inequity for some students points to important institutional factors supporting DE. It turns out that DE courses fit within the existing course-based structure of most schools. This means that it is straightforward to organize DE courses and charge tuition. In the US, financial aid policies allow students to use up to one year of their federal Pell Grants for remedial coursework (Long & Boatman, 2013). As such DE courses represent a significant revenue stream for many institutions. But many low-income and URM students exhaust their financial aid on DE courses without ever earning any credits towards a degree (Bailey & Cho, 2010).

1.2. The potential and the challenges of supplemental instruction (SI)
The Bridge to Nowhere report and many other authorities now argue that most traditional DE should be abandoned. At a minimum, they argue that any DE course should be specific to majors or programs. Better still, many argue that entrance requirement should be lowered or removed and that all students should be offered supplemental instruction (SI) to support their success in gateway courses. The concerns over conventional (i.e., “general”) DE courses reflects a broader shift towards more “contextual” models of cognition and learning in general (e.g., Brown, Collins, & Duguid, 1989) and within remedial education (e.g., Sticht & Hickey, 1991).

Some regions and institutions in English-speaking countries have stopped requiring remedial courses, while others are breaking them up into smaller more specific segments. In 2012, the organizations that issued the Bridge to Nowhere report acknowledged the likely persistence of DE courses and argued that the general nature of those courses was a readily solvable problem. At a minimum, the consortium argued that incoming students should be required to declare a “meta-major” (such as health sciences or STEM) so that DE courses could be tailored and contextualized to those majors (Charles, and Dana Center, Complete College America, Education Commission of the States, Jobs for the Future, 2012). In a 2015 update, an enlarged version of that same organization argued that remediation should “be provided in conjunction with gateway courses in the student's academic or career area of interest through co-requisite or other models with evidence of success in which supports are embedded in curricular and instructional strategies” (Achieving the Dream, American Association of Community Colleges, Charles A. Dana Center, Complete College America, Education Commission of the States, Jobs for the Future, 2015). In this way, the report provided the strongest endorsement to date of SI as an alternative to DE to support access and success and particularly for URM and first-generation students.

Supplemental instruction is typically offered as optional support, though some schools require students who do not meet the threshold on entrance exams to participate in SI. The most popular form of SI is the Peer-Assisted Study Session (PASS) model promoted by the International Center for Supplemental Instruction at the University of Missouri-Kansas City1 PASS typically has upper-division undergraduates who have successfully completed the course offer regular face-to-face meetings where current students compare notes, discuss readings, develop tools, predict test items, etc. Proponents point to reviews of dozens of studies showing that SI (a) reduces attrition, (b) improves achievement, (c) keeps students in more difficult majors, (d) is cost-effective in terms of increased tuition streams, (e) increases graduation rates, and (f) provides benefits to peer tutors (Bowman-Perrott et al., 2013; Dawson, van der Meer, Skalicky, & Cowley, 2014; Topping, 1996). Many argue that successful undergraduates can be more effective tutors than graduate students because they still remember learning difficult course concepts (e.g., Falchikov, 2001).

But for reasons elaborated below, claims regarding the return on investment (ROI) of SI have not been strongly tested. This is important because SI represents a significant financial and logistical investment for schools and programs and significant commitment of time for students. This means that shifting from DE to SI reduces tuition revenue while increasing instructional costs. Some institutions support SI with fees associated with enrollment in general or for specific courses. However, such fees are rising at a pace that currently outstrips inflation and tuition increases (Kelchen, 2016). SI also requires schools to recruit, train, and pay peer mentors, and then find space and schedule meetings. Proponents argue that SI pays for itself with increased retention (and therefore increased tuition, e,g, Blanc, DeBuhr, & Martin, 1983; Rath, Peterfreund, Xenos, Bayliss, & Carnal, 2007). Indeed, fiscal sustainability is a central topic in discussions of SI (e.g., Wachen, Jenkins, & Van Noy, 2011; Warnick, Cooney, & Lackey, 2010) and many SI programs must constantly battle to maintain their funding (Dawson et al., 2014). Furthermore, SI requires that students schedule and then attend sessions and is generally not available for online students. For these reasons, more systematic evidence regarding the ROI from SI is needed (e.g., Levin, 2009; Margolis, Nussbaum, Rodriguez, & Rosas, 2006), along with more rigorous comparisons of alternative approaches.

1.3. Expensive human tutors vs. inexpensive intelligent tutoring systems
Another alternative to DE is one-on-one human tutors. Such tutoring takes many forms, including drop-in academic assistance centers run by schools, commercial tutoring centers, and private free-lancers; recent years have seen a massive surge in online tutoring. The National Tutoring Association was founded in 1992 to certify individuals and programs and to organize an annual conference. One-on-one tutors have been studied extensively and are widely believed to be the single most effective form of instruction. VanLehn (2011) summarized the strategies that human tutors typically use to be so effective, including diagnostic assessments, individualized task selection, tutorial strategies, motivation, feedback, and scaffolding. Thanks to Bloom (1984) many assume that well-trained human tutors can consistently deliver two standard deviations greater learning gains than classroom instruction without tutors (i.e., an effect size of d = 2.0; e.g., Woolf, 2009).

Despite their effectiveness, the cost of one-on-one expert tutors is prohibitive in many circumstances. While the growing use of online overseas tutors has cut costs for individuals, such a response is unaffordable for most schools and programs. The widespread use of private tutors hired by students raises obvious questions of educational equity for the many students who cannot afford tutors competing with wealthier students who can (Dang & Rogers, 2008). Many college campuses are ringed with private tutoring centers, many colleges' classified advertisements list private tutors, and many departments posts lists of approved tutors (usually graduate students). The fact that many tutors are essentially delivering test preparation raises issues about the generalizability of such learning beyond the immediate exams (Crocker, 2003). Private tutors sometimes engage in blatant cheating by gaining illicit access to current items and exams (Lancaster & Clarke, 2016); such cheating seems particularly likely with private tutors whose advertisements guarantee course success. It is also worth noting that VanLehn's (2011) detailed analysis of the prior research on human tutors that only included well-controlled experimental studies found a rather lower effect size (d = 0.79) rather than the one claimed by Bloom.

Innovators have long attempted to use computer technology to replace human tutors. Initial efforts employed “programmed instruction” methods (e.g., Smith & Sherwood, 1976) that used computers to implement mastery learning schemes. In recent years, intelligent tutoring systems (ITSs) have emerged that accomplish some of the most important elements of human tutoring. ITSs emerged at the intersection of cognitive psychology, computer science, and artificial intelligence in the 1980s, and are most strongly associated with the Cognitive Tutors developed at Carnegie Mellon University (Anderson, Boyle, Corbett, & Lewis, 1990; Anderson, Boyle, & Reiser, 1985). In contrast to earlier programmed instruction, ITS are “intelligent” because they incorporate models of domain knowledge and maintain a model of each learner's developing knowledge. This allows ITSs to respond intelligently to learners' choices. Cognitive Tutors rely on production-rule models to represent domain knowledge and use Bayesian statistics to model learner's developing knowledge; the ALEKS tutor (Assessment and LEarning Knowledge Spaces, used in the study described below2), uses pre-requisite hierarchies and knowledge space theory (see Baker, 2016 for a helpful overview).

Intelligent tutors have been the focus of very large investments by the National Science Foundation, the US military, and private investors; this has supported a substantial community of researchers who have conducted extensive refinements, controlled experiments, and field-based research (see reviews by Ahuja & Sille, 2013, and Kulik & Fletcher, 2016). In terms of overall impact, many cite the review by Anderson, Corbett, Koedinger, and Pelletier (1995) who reported an average effect size of 1.0. (To reiterate, VanLehn, 2011 review of carefully controlled experimental comparisons of ITS to identical instruction without the tutors found an average effect size of 0.71).

Given the focus of this paper, it is worth noting that numerous field studies of ITSs have been carried out in developmental and supplemental contexts. A particularly relevant study given our concerns over access and equity for under-represented minorities is the one published by Hu, Xu, Hall, Walker, and Okwumabua, 2013. They compared the success of African American and White students in an ALEKS-based statistics course and in a conventional lecture statistics course. They found that racial disparities in final exam scores that emerged in the lecture course did not appear in the ALEKS-based course, even after adjusting for prior performance. Other relevant studies include those by Siemer and Angelides (1994) and Johnson, Phillips, and Chase (2009) who studied the impact ITSs when used as SI in professional educational contexts; Chen (2011) and Hsieh, Lee, and Su (2013) demonstrated the effectiveness of ITSs that provided personalized remedial learning pathways to students learning introductory computer programming; Hrubik-Vulanovic (2013) explored using ALEKS mathematics activities as SI to prepare students for lectures. Given that networked technology makes it possible to offer ITSs for larger numbers of students with little or no marginal cost for each additional learner, they have obvious potential in a range of developmental, supplemental, and tutorial contexts.

2. Challenges in studying DSTS effectiveness and a solution
Grubb (2001) and Levin and Calcagno (2008) summarized the many challenges in evaluating and comparing DSTSs. Because of the financial implications for shifting away from DE, it is important to obtain evidence that supplemental and tutorial alternatives support access and success. As shown by VanLehn's (2011) review, even studies featuring random assignment of learners to conditions can present serious confounds that preclude strong conclusions. The comparison of DSTSs is particularly challenging in real educational contexts, where random assignment to conditions is often impossible. A common workaround (particularly in studies of SI) is randomly assigning class sections to different conditions. But this is still problematic because other factors (e.g., competing classes, class meeting time) can introduce systematic differences between students in those classes. Even with group-stratified random assignment, it is often difficult to randomly assign enough sections or classes to control for intra-class correlation and to obtain statistically significant differences.

Without random assignment, the self-selection bias (where different types of students select different options) and assignment bias (where different types of students are assigned to different options) seriously undermines comparisons of DSTS (e.g., Hrubik-Vulanovic, 2013). Students who elect to take advantage of optional DSTSs are inevitably going to be different than the students who do not; even when students are randomly assigned to conditions, wide variations in motivation and engagement can introduce significant amounts of unexplained variance that can swamp treatment differences (e.g., Craig et al., 2013; Xu, Meyer, & Morgan, 2009).

Fortunately, a statistical technique known as propensity score matching (PSM) is available to help address these challenges. PSM uses relevant covariates to identify or create experimental groups that are nearly identical on every independent variable except for the variable of interest (in this case the type of DSTS used to prepare students for a gateway course). PSM does this by considering the propensity for ending up in one of the groups vs the other. PSM is widely used in observational studies of risk factors like smoking where participants cannot be randomly assigned (e.g., Da Veiga & Wilder, 2008). An initial review only located two studies of DSTSs using PSM (Attewell, Lavin, Domina, & Levey, 2006; Crisp & Delgado, 2014). While Greer and Mark (2016) point out the obvious potential of PSM for studying ITS systems, no studies were located that used PSM to compare an ITS with DE or with SI in a real-world context.

3. Examining DSTSs for a gateway chemistry course
Extended efforts by the second author to improve access and success in Principles of Chemistry and Biochemistry (Chem 117) at a large research university in the midwestern US provided an ideal context for exploring some of the issues introduced above. Chem 117 is a classic gateway course in that students must earn a passing grade in order to be admitted to many of the most desirable majors at this university (including pre-med). Historically, around 20-25% of students who enrolled in Chem 117 failed to earn a grade of C– or better. These students either earned a grade of D or F or withdrew from the course before the specified deadline. The so-called “DFW” rate for underrepresented minority students and first-generation college students had been as high as 50% in some years.

Starting in 2011, this faculty member began investing substantial effort refining the existing 20-item chemistry placement exam (CPE) for Chem 117 and examining access and success for students in light of their scores on that exam. Students who pass the CPE with a score of 15 or higher are allowed to enroll in C117 directly. As described next, the second author oversaw three existing or new services intended to help students enroll in and then succeed in C117.

3.1. Developmental “prep Chem” course
Traditionally, students who did not meet the entrance criteria for Chem 117 were required to first earn at least a C– in Chem 103 Introduction to Chemical Principles (or simply “Prep Chem”). The Prep Chem course was specifically designed to “alleviate deficiencies in chemistry and algebra to better prepare students for Chem 117” and was roughly equivalent to a rigorous high school chemistry course. Students participating in a university-wide program for under-represented minority students (at this school, almost entirely African American, Hispanic, and Latinx) and first-generation college students (known as 21st Century Scholars) reportedly normally did not take the entrance exam and were advised to directly enroll in the alternative Chem 101 Elementary Chemistry 1 (also known as “Prep Chem”).

While enrolling in Chem 101 or 103 cost three or five regular tuition credits, those credits did not count towards most degrees in the physical or life sciences at the university. At the standard expectation of 45 h per credit hour (1 h of coursework and 2 h of homework for 15 weeks per credit), the Chem 101 and 103 courses ostensibly required 135 or 225 h. By all accounts, the Prep Chem courses were very high-quality DE courses and were taught by well-qualified instructors who were closely supervised by the second author. This is important. According to Boylan and Saxon (2009), underfunding and lack of oversight often result in low-quality DE courses.

3.2. Introduction of the ALEKS intelligent tutoring systems (ITS)
Starting in 2013, all students who did not qualify for Chem 117 were given the option of completing the ALEKS Summer Prep Course for Chemistry from McGraw Hill, Inc. (2019). The sub-topics to be completed in the ALEKS ITS were selected by the instructor. Students were charged $30 to access ALEKS and spent an average of 33 h to attain the 90% score needed to enroll in 117.

The ALEKS system was introduced in 1996 and has primarily focused on algebra and related areas in mathematics. The company expanded into chemistry in 2005. One of the developers of ALEKS chemistry products argued that adaptive tutoring systems appear particularly well suited for learning chemistry. In contrast to mathematics where there is relatively broad consensus about the order in which topics should be introduced, instructional sequences vary tremendously across different chemistry textbooks and instructors.

To put this in the language of KST [knowledge space theory], while it is relatively straight forward to define knowledge states expressing complete ignorance or complete mastery of the major chemistry concepts, defining and ordering knowledge states expressing partial mastery is challenging, because those intermediate states are in practice defined by student progress along one or more chains of models simplified in various ad hoc ways, and we have as yet no unambiguous way to map degrees of mastery of these models to degrees of mastery of the underlying principles (Grayce, 2013, p. 94).

In addition to being intelligently adaptive to each learners' mastery of the targeted disciplinary principles, most items in the ALEKS ITS also presented students with open-ended problems that required students to enter in a response. This greatly increases the difficulty of the items (by eliminating hints in the form of multiple-choice answers) and eliminated the possibility of determining the correct answer by guessing.

3.3. An innovative low cost alternative to peer-assisted study sessions
After a small pilot in Spring 2016, this faculty member introduced undergraduate teaching assistants (UTA) who began offering SI in the form of weekly 60-min sessions. During these sessions, the UTAs facilitated small group discussion of difficult problems and concepts. Starting in Fall 2016, enrolled students were required to attend these sessions; attendance is recorded and students lose points for not attending.

Significantly, funds were not available to support conventional PASS with hourly undergraduates. Instead, these UTAs were offered two course credits and were supervised by the faculty member. Because all UTAs were already enrolled full-time, university policy meant that they were not charged for these additional course credits—even though the Chemistry Department accrued the additional credit hour generation. This financially sustainable approach was further supported by the fact that the faculty member informed the UTAs that the experience would further extend their mastery of chemistry and enhance their applications to graduate school.

This revenue-neutral (or even slightly positive) model of SI seems worthy of further consideration, in light of concerns introduced above about costs and sustainability. Indeed, prior introduction of PASS in another department at the same university had surfaced deep tensions between that department and the school administration. It turned out that the department felt that those resources should have instead been used to support their doctoral students. Likewise, another department at the university encountered an uproar from their undergraduates when they suspended an alternative approach to PASS in the face of a budget deficit and the reassignment of the supervising faculty member.

3.4. Research questions and data sources
Our collaboration was organized to explore the following questions: (1) Did the introduction of SI in 2016 improve success for all students and for URM and first-generation (FG) students? (2) To what extent was the selection or assignment of students to DE versus ALEKS a function of ethnicity and other factors? (3) How did the Prep Chem, ALEKS, and directly admitted (DA) students compare on demographics, admission test scores, and GPA? (3) How did the final grades in Chem 117 of the DE and the ALEKs students compare to each other and to DA students? (5) How did final grades in Chem 117 compare for Prep Chem and ALEKS students after using propensity score matching techniques to control for systematic differences resulting from biases in selection or assignment? (6) How did the final grades for Prep Chem and ALEKS students compare for the URM students after using PSM to control for systematic differences?

The Chemistry Department provided Chem 117 grades and scores for 4492 students from 2012 to 2017. This included 2561 students who gained access via Chem 101 or Chem 103, 607 students who gained access by attaining 90% mastery on ALEKS, and 1324 students who accessed to Chem 117 directly via a passing score on the Chemistry Placement exam. Student IDs were used to merge this data with comprehensive demographic data in the university's student information system to conduct the analyses described next. Unfortunately, we were unable to access data for students who failed to pass Chem 101/103 or who started ALEKS but did not attain 90%.

3.5. Impact of SI on Chem 117 grades
Our first analysis explored the impact of our innovative financially-sustainable approach to SI. The same three instructors taught Chem 117 during the Fall semesters from 2013 to 2018 (Chem 117 was taught by different faculty and instructors during the Spring and Summer semesters and UTAs were not offered). As described above, supplemental instruction via undergraduate teaching assistants (UTAs) was introduced in Fall 2016. Fig. 1 compares the average DFW rates for the three Fall semesters before the UTAs were introduced with the average DFW rates for the three semesters after the UTAs were introduced. This reveals a substantial decline in DFW rates after the introduction of the UTAs in 2016, with a particularly large drop for African American students (from 60% to 38%). However, Fig. 2 shows the same data for each of the six years. This shows trends towards lower DFW rates for all groups before the UTAs were introduced; the faculty suspected that this was partly due to an effort to include more organic chemistry in 2013; the fact that the Fall 2015 DFW rates were similar to the Fall 2016–2018 rates for most groups shows that average grades do not provide strong evidence that the introduction of the UTAs in 2016 decreased DFW rates. Furthermore, other typical confounds such as the creation of entirely new exams each semester precludes reaching any strong conclusions about changes in instruction using course grades.

Fig. 1
Download : Download high-res image (82KB)
Download : Download full-size image
Fig. 1. DFW rates before and after introducing supplemental instruction.

Fig. 2
Download : Download high-res image (100KB)
Download : Download full-size image
Fig. 2. DFW rates for each year of the study.

Further consideration failed to uncover any easy solutions to this common problem. Previous efforts to standardize the exams met with typical faculty resistance. One possible solution would have been asking all instructors to include a subset of required items on their exams and comparing performance on just those items. But that raises the distinct possibility of instructors focusing excessively on those items. We concluded that while we failed to generate evidence about the effectiveness of this approach to SI, its favorable financial implication made this less of an issue for the Chemistry Department. Nonetheless, this leaves open the question of whether this non-trivial commitment of student time led to a corresponding increase in student learning and whether students might have better spent this time studying on their own or in study groups (or perhaps working on more advanced modules in ALEKS). We are currently exploring the possibility of randomly assigning students to different variations of this SI during the semesters when the faculty author teaches most or all sections of Chem 117 and where these students complete the same exam.

3.6. Selection or assignment of populations to the developmental Chem vs. ALEKS
Our second analysis examined whether populations were over-represented or under-represented in the Chem 101/103 or ALEKS groups. Chi-square analyses were used to compare the proportions of female, first generation (FG), Asian, URM, White, Unclassified, state residents, and Pell Grant Eligible (low income) students in each group, relative to their overall proportions. Chi-square analyses were run separately for gender, FG, residency, and Pell Grant Eligible; Race and Ethnicity were compared in a single analysis. The results are shown in Table 1. All differences in selection/assignment reached statistical significance. While the effect sizes for Gender, First Generation and Pell Grant Eligible were quite small (d < 0.14). the effect sizes for Race & Ethnicity were larger (d = 0.22). The most notable differences (bolded) were (a) Asian students were over-represented in the DA group and under-represented in the 101/103 group, (b) URM students were under-represented in the DA group and over-represented in the 101/103 group, and (c) Unclassified students were over-represented in the DA group and under-represented in the 101/103 group.


Table 1. Actual and expected proportions of students in the three conditions.

Group	ALEKS	Direct admit	Prep chem	
Actual	Expect	Actual	Expect	Actual	Expect	χ2
Female	393	369	689	804	1646	1555	59.5⁎⁎
First-Generation	526	507	1172	1108	2061	2143	45.8⁎⁎
Resident	489	513	1137	1120	2177	2168	9.6⁎
Pell-Grant Eligible	113	142	207	310	732	600	90.6⁎⁎
Asian	49	50	210	109	114	212	209.3⁎⁎
Under-Rep. Minority	100	105	163	229	514	442	
White	445	436	889	951	1895	1840	
Other (Unclassified)	13	15	62	33	38	64	
The most notable differences were bolded.

⁎⁎
p < .0001

⁎
p < .05.

These findings appear to confirm the more general pattern of Asian students (which include foreign nationals as well as Asian Americans) being under-represented in developmental courses and URM students being over-represented. While the under-representation of Unclassified students in the developmental courses was particularly large, this group is quite diverse and the overall number was small. Meanwhile, there were no discernable differences in the proportions of students who gained access to Chem 117 by completing ALEKS. If the Prep Chem course is indeed no more successful than ALEKS in preparing students for Chem 117, this over-representation of URM students in Prep Chem has significant consequences for access and success. Unfortunately, we have yet to obtain data about the students who enrolled in Prep Chem but did not obtain a passing grade and/or do not enroll in Chem 117, and it is currently impossible to identify students who began ALEKS but did not attain 90% and/or did not enroll in Chem 117. Such data is needed for a more comprehensive characterization of the different pathways of access and success in Chem 117.

3.7. Success in Chem 117 for different populations of students
Our third analysis examined success in Chem 117 in terms of final grades for each of the primary groups (ALEKS, DA, and Prep Chem) and then broke that analysis down by different types of students in those groups. Fig. 3 shows the Chem 117 grades for each of the three admission groups by primary demographic groups, while Fig. 4 shows that same data for the more specific ethnic and racial minorities (Native Americans and Hawaiian/Pacific Islander were excluded because there were <5). Both figures show that students who qualified for Chem 117 via ALEKS attained significantly lower grades than the directly admitted students, while the students qualified by passing Chem 101/103 attained significantly lower grades than the ALEKS students. The difference in 117 grades between the ALEKS and 101/103 students was particularly pronounced for African American students (2.42 vs 1.87).

Fig. 3
Download : Download high-res image (225KB)
Download : Download full-size image
Fig. 3. Chem 117 grades by primary group and primary race/ethnicity.

Fig. 4
Download : Download high-res image (273KB)
Download : Download full-size image
Fig. 4. Chem 117 grades by primary group and specific race/ethnicity.

On the surface then, this appears to support the claim that the 30-h, $30 ALEKS ITS is more effective at preparing students for Chem 117 than a three-credit or five-credit Developmental Chem course. However, such a conclusion would only be warranted if these two groups were the same and these groups were definitely not the same. As shown in Table 2, the students who qualified for Chem 117 via ALEKS had higher SAT composite scores and higher high school and university GPAs than the Prep Chem students. Notably, far more of the Chem 101/103 students were eligible for Pell Grants, participants in the 21st Century Scholars Program and first-generation college students. Notably, ALEKS students included a smaller proportion of student in each of these three categories than the students who were directly admitted in the Chem 117. Given these differences, it is unwarranted to claim that ALEKS was more effective than Chem 101/103 in preparing students for success in Chem 117


Table 2. Summary of descriptive statistics by group.

Entry characteristics	ALEKS (N = 551)	Direct admit (N = 1324)	Prep chem (N = 2557)
Gender (Male)	35.6%	47.9%	35.8%
Ethnicity (Asian)	8.1%	15.7%	4.4%
Ethnicity (White)	74.1%	67.2%	74.0%
Ethnicity (URM)	15.4%	12.31%	20.0%
Ethnicity (Other)	2.0%	4.68%	1.5%
High school GPA	3.82	3.87	3.73
SAT composite	1315	1378	1241
State resident (yes)	80.4%	85.9%	85.0%
Pell grant eligible	18.6%	15.6%	28.6%
21st century scholar	10.2%	8.2%	18.2%
First generation	13.3%	11.5%	19.5%
3.8. Comparing ALEKS and prep Chem after matching
Without controlling for these differences in academic preparation and demographics, it is impossible to make valid inferences about the impact of the two different entrance pathways on subsequent success in Chem 117. We approach this problem here by applying Propensity Score Matching (PSM). The propensity score is the probability that a particular case would be assigned to a group (Ridgeway, McCaffrey, Morral, Burgette, & Griffin, 2017). Most studies used propensity scores to correct for imbalances only between two groups (i.e. treatment and control) (e.g. Li, Palma, & Xu, 2017). We used multinomial logistic regression to estimate multiple propensity scores to control for the imbalances among three groups on demographic variables and academic preparation as demonstrated by Ridgeway et al. (2017).

All the variables listed in Table 2 were included in the multinomial logistic regression to estimate the propensity score. Fig. 5 shows the estimated means grades in C117 after propensity matching was carried out for all students, the bottom half of students in terms of high school GPA and SAT, and for under-represented minorities. The first matching analysis with all students (Fig. 5, left) confirmed that the grades of the Direct Admit students were significantly higher than the grades of the ALEKS students (p < .01) while the grades of the Prep Chem students were not significantly different than the grades of the ALEKS student (p = .42). The second matching analysis (Fig. 5 center) examined the 1230 students with high school GPAs below 3.8 and composite SAT scores below 1230. This was carried out because the lower performance of the Prep Chem interacts with the matching process in ways the might make it hard to make accurate inferences about lower performing students. Once again, the grades of the Direct Admit students were significantly higher than the grades of the ALEKS students (p < .01) while the grades of the Prep Chem students were slightly lower (0.073) than the ALEKS students but this difference did not reach statistical significance (p = .25). Our third matching analysis (Fig. 5, right) only looked at the URM students to examine whether the findings held for those students. While the advantage of the ALEKS students over the Prep Chem students was slightly larger (0.13), this difference also did not reach statistical significance (p = .11, presumably due in part to the smaller sample size).

Fig. 5
Download : Download high-res image (104KB)
Download : Download full-size image
Fig. 5. Chem 117 grades for all students, bottom-half, and under-represented minorities after matching.

3.9. Estimated return on investment (ROI)
In summary, there was no statistically significant evidence that earning a passing grade in a three-credit or five-credit Prep Chem course was any more effective at preparing students for Chem 117 than than reaching 90% in the ALEKS Chemistry ITS. This is a significant finding. The Prep Chem course ostensibly represented a 135-h or 225-h investment of student time; in 2018, this represented $1068 or $1780 in tuition for an in-state student or $3545 or $5904 in tuition for an out-of-state student (however, as noted above, most undergraduates pay a flat rate once they are enrolled in 12 credits). In contrast, each student paid just $30 to sign up for ALEKS and students spent an average of 33 h to attain 90% correct. Generally speaking then, ALEKS vs. Chem 101/103 represented an investment of 22/13% of the student time and 2.8/1.6% of in-state tuition. While this analysis was unable to examine how many students who enrolled in Prep Chem did not earn a passing grade and/or did not subsequently enroll in Chem 117, prior research suggest that the proportion is likely to be high (e.g., Bailey, Jeong, & Cho, 2010) Given the over-representation of URM students in the Prep Chem course and the historically high rates of failing grades in DE courses, these findings appear to have significant implications for gateway success and major choices for URM students.

Because the introduction of undergraduate teaching assistants was revenue-neutral and because it was not proven to have a measurable impact on grades, it seemed unwarranted to explore the ROI of using UTAs in this context. While it seems like we have made significant progress towards considering ROI for DSTS, we certainly have more work to do to attain the much more precise estimates envisioned by some economists (e.g. Levin, 2009; Margolis et al., 2006)

4. Discussion and future research
These results suggest that, at least in terms of grades in Chem 117, the investment of $30 and approximately 30 h in the ALEKS ITS was equally as effective for preparing students to succeed when compared with a much larger investment of tuition and time in the developmental Prep Chem course. Given the number of hours required to pass the Prep Chem course and the cost of three or five credits of tuition, it seems that a strong case can be made for simply abandoning the Prep Chem course. However, there are three issues that likely call for further consideration before such a practice is warranted.

From our perspective, evaluations of developmental, supplemental, and tutorial services need to pay more attention to what test validity theorist Messick (1995) called construct-irrelevant easiness. This is what the rest of the world commonly calls “teaching to the test.” This occurs when the content of instruction too closely mirrors the content of the targeted tests. This is particularly a risk in supplemental and tutorial services. Furthermore, human tutors in supplemental contexts (particularly free-lancers) significantly increase the risk of outright cheating. Thanks to mobile devices, social networks, and even university-run websites (e.g., Stöckelová & Virtová, 2015), it is easier than ever for tutors to gain access to current exam items and even complete exams. This allows tutors to offer “guarantees” and charge more than their competitors. While not as problematic, there is evidence the supplemental instruction can focus excessively on test questions in a way that discourages more conceptual meaning-oriented engagement in student study skills more broadly (Ashwin, 2003).

But even with developmental courses and the ITS used here, there is also a risk that the preparation focuses too closely on the relatively narrow representation of disciplinary knowledge presented in the multiple-choice exams that are necessitated by large gateway courses. In addition to the risk of misrepresenting the discipline as a collection of overly specific facts and procedures, developmental courses and ITSs may discourage students from engaging in more discursive and interactive kinds of disciplinary practices that are typically required for success in upper division courses and eventual careers.

The second issue is that there are additional potential confounding factors that the present analyses might have overlooked. For example, the present analysis did not include data for the students who enrolled in Prep Chem and did not attain a passing grade or attempted ALEKS but did not attain the required score of 90%. Alternatively, it is possible that the students who qualified for Chem 117 via Prep Chem might have earned higher grades in subsequent chemistry course than the students who qualified via ALEKS. Fortunately, university information systems are now making such analyses quite possible and even automated. As argued by Baker (2016), these are precisely the sort of issues that the emerging fields of learning analytics and educational data mining promise to address. As described in You (2016), such systems and practices promise to dramatically simplify the sorts of analyses carried out in this study. This availability also encourages the systematic gathering of relevant data such as student-reported use of private and commercial tutors and programmatically-gathered data of participation in supplemental instruction.

Finally, to reiterate, there remains the issue of the revenue stream generated by tuition from DE courses. While DE courses typically have a lower student: instructor ratios than gateways courses, DE courses are typically taught by part-time adjunct instructors (rather than relatively expensive doctoral students or faculty). While most schools and programs are presumably genuine in their commitment to preparing students efficiently for success in gateway courses, it may be difficult for them to give up the tuition revenue generated by DE courses. We hope that the research summarized and reported here will encourage them to consider doing so, while systematically examining the impact of those courses and potential alternatives on success in targeted gateways courses, intended majors, overall graduation rates, and career success.