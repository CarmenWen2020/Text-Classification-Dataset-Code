The literature regarding formative assessment and Self-Regulated Learning (SRL) has focused on the ways in which formative assessment improves SRL. This study, on the other hand, evaluated whether SRL characteristics impact successful engagement with formative assessment, and subsequent summative performance in both online and blended learning contexts. Ninety-six blended and 85 online learners completed a formative assessment task, received feedback, and then resubmit the assessment for a summative grade. Overall, while there were differences between learning contexts, SRL, and performance, many variables were not significant predictors of performance. Online learners who were confident, managed their time well and regulated their efforts saw the greatest benefits, though these effects were small when viewed individually. Blended learners, to a lesser extent, also benefited from confidence and effort regulation. To the authors' knowledge, this is the first study to test SRL characteristics as drivers of performance during a formative task across two learning contexts.

Previous
Next 
Keywords
Self-regulated learning

Formative assessment

Summative assessment

Online learning

Blended learning

Higher education

Formative assessment accompanied with actionable feedback is thought to be an integral component for student learning (Hattie & Timperley, 2007; Lipnevich & Smith, 2018; Wiliam, 2011). When done properly, it should theoretically lead to enhanced student performance (Black & Wiliam, 1998; Wiliam & Thompson, 2007). Nicol and Macfarlane-Dick (2006), among others, argued that formative assessment enhances students' academic success by empowering them to become self-regulated learners (SRL), a construct that has received a significant amount of attention in recent years (for a review, see Panadero, Andrade, & Brookhart, 2018). SRL is acknowledged as important for academic success in both online (Broadbent, 2017; Broadbent & Poon, 2015) and traditional learning contexts (Richardson, Abraham, & Bond, 2012). In the last decade, the literature regarding formative assessment and SRL has focused primarily on the ways in which formative assessment improves SRL, with less regard for how SRL impacts performance during formative assessment.

Additionally, much of the focus on formative assessment has been in the classroom setting, with less attention paid to how online and blended learners may differ in their approach to formative assessment tasks. This is problematic because there is some evidence that blended learners, who have the opportunity for classroom face-to-face interaction, may use different strategies than online-only learners or may have more opportunity for co-regulation with teaching staff. Studies that have examined SRL of traditional, online, and/or blended learning learners have found that SRL behaviours differ between these groups (Broadbent, 2017; Broadbent & Poon, 2015; Richardson et al., 2012). Given the growing demand for online courses, it is worth exploring whether these two groups differ in the SRL characteristics and dispositions needed to engage with a formative assessment and subsequent summative tasks.

1. Formative assessment and feedback
Since the seminal work of Black and Wiliam (1998), research in formative assessment has developed significantly as a field. Here we adhere to the following definition of formative assessment:

“Practice in a classroom is formative to the extent that evidence about student achievement is elicited, interpreted, and used by teachers, learners, or their peers, to make decisions about the next steps in instruction that are likely to be better, or better founded, than the decisions they would have taken in the absence of the evidence that was elicited” (Black & Wiliam, 2009 p. 9).

Formative assessment is often characterised as assessment for learning because its focus is to help the student improve on future work (Black & Wiliam, 2009). Summative assessment, on the other hand, is an assessment of learning used to measure a student's academic achievement through the use of grades (Andrade & Brookhart, 2020). One of the central features of formative assessment is the provision of formative feedback which is defined as “information communicated to the learner that is intended to modify his or her thinking or behaviour for the purpose of improving learning” (Shute, 2008, p 154.). Hattie and Timperley (2007) argue that for feedback to be part of a formative process, the feedback needs to have clear goals (where am I going?), qualitative information about current performance (how am I doing?), and information about how to improve subsequent performance (where to next?). Formative feedback is crucial because it establishes conditions that increase the likelihood that learners can act upon feedback and make improvements such as modifying subsequent behaviours and learning strategies (Hattie & Timperley, 2007; Lipnevich, Berg, & Smith, 2016; Molloy, Boud, & Henderson, 2019; Orsmond & Merry, 2011). This area of research has garnered substantial attention in the last two decades, with an increased focus on the ways in which formative assessment can be used to improve students' self-regulated learning (e.g., Allal, 2016; Nicol & Macfarlane-Dick, 2006; Panadero et al., 2018; Panadero, Broadbent, Boud, & Lodge, 2019; Perrenoud, 1998).

2. Self-regulated learning
Self-regulated learning refers to “self-generated thoughts, feelings, and actions that are planned and actions that are planned and cyclically adapted to the attainment of personal goals” (Zimmerman, 2000; p. 14). Self-regulated learners plan, set goals, and engage in strategies to achieve those goals. Through evaluation and reflection, these strategies are monitored and modified to enhance one's progression toward goal achievement. Self-regulated learners are motivated, persistent, manage their time effectively, and seek assistance when necessary (Pintrich, Smith, García, & McKeachie, 1993). A large body of literature shows that SRL is related to academic achievement for both campus-based (Richardson et al., 2012; Schneider & Preckel, 2017) and online students (Broadbent & Poon, 2015), with strong support for the strategies of time management, metacognition, effort regulation, critical thinking (Broadbent, 2017; Broadbent & Poon, 2015; Richardson et al., 2012), and self-efficacy (Honicke & Broadbent, 2016). Importantly, as SRL is amenable to improvement, even poor-performing students can learn to enhance their SRL skills under the right conditions (Broadbent & Poon, 2015).

3. Self-regulated learning and formative assessment
Nicol and Macfarlane-Dick (2006) argued that formative assessment sits within an SRL framework, and it can be used as a driver to improve students' self-regulation. More recently, Panadero et al. (2019) proposed three models in which formative assessments help learners to foster SRL by guiding learners to develop successful strategies over time. In particular, the active role taken by the learner during formative assessment tasks teaches learners to develop metacognitive skills, to reflect, use feedback, plan and set goals, and engage with other strategies to improve learning (Butler & Winne, 1995; Nicol & Macfarlane-Dick, 2006).

However, there is another way that SRL and formative assessment interact that is often overlooked. Self-regulated learning can also be seen as a set of individual characteristics and dispositions needed to engage successfully with formative assessment from task outset (Butler & Winne, 1995; Hattie & Timperley, 2007), particularly if the task requires the learner to enact feedback to improve their performance. While it is acknowledged that SRL is needed to enact feedback, few studies have focused on which SRL skills are necessary to take full advantage of formative assessment tasks (Panadero et al., 2018). Learners need to be sufficiently motivated, able to establish goals, reflect on prior performance, think critically about feedback, monitor their progress, make corrections during their performance, manage their time effectively to achieve their performance goal, and evaluate and reflect on their performance and its outcomes in order to make the best use of formative assessment (Nicol & Macfarlane-Dick, 2006; Panadero & Alonso-Tapia, 2013). Learners also need to find ways to move forward when confused or stuck during learning (Lodge, Panadero, Broadbent, & De Barba, 2018).

By not investigating baseline self-regulated learning ability, most studies are assuming, by default, some equivalence in learners prior to engagement with formative assessment tasks. Yet, to successfully engage with a formative task and enact external feedback, learners are limited by their cognitive and metacognitive strategies, and their motivational beliefs, including self-efficacy, interest, and effort beliefs (Wiliam, 2011). One may reasonably assume that these skills differ between learners. Students who are successful self-regulated learners are more likely to assess their performance, and take steps to modify future performance using internal cognitive, affective, and behavioural regulatory strategies, responding positively to external feedback, and ultimately increasing efforts to achieve learning and performance goals (Bose & Rengel, 2009; Sitzmann & Ely, 2011). We can speculate that self-regulated learners may also be more likely to engage with the initial task more successfully (e.g. higher grade) as well as be more successful at engaging with subsequent tasks. Thus, measuring SRL before engagement with formative assessment is worth exploring.

Currently, it appears that several key research gaps still remain. First, it is of interest to determine if there are learners with particular SRL characteristics that benefit more academically when given the opportunity to use formative assessment and feedback to improve work. Second, as SRL is not fixed (Black & Wiliam, 2006; Pintrich & Zusho, 2002), focusing on formative assessment could help us better understand which learners are most at risk - and need the most support - to achieve better learning outcomes during formative assessment tasks. Third, online and blended learners may rely on different SRL capabilities when engaging with formative assessment; though differences in utilisation of SRL strategies may seem intuitive and obvious, we are not aware of any empirical confirmation of this.

We speculate that learners who score higher on self-regulated learning characteristics will have greater academic success in at least two ways: (1) by submitting higher quality work to begin with (formative assessment), and/or (2) by actioning the feedback more effectively, as demonstrated by a greater improvement from the formative assessment task to the final submission. It is also possible that online learners utilise different strategies than blended learners. As past research has found that time management, metacognition, effort regulation, critical thinking, and self-efficacy are the most important strategies and motivations for both online and blended learners (Broadbent, 2017; Broadbent & Poon, 2015; Richardson et al., 2012), these will be the focus of the current study. Lastly, given the lack of research in the area of SRL's impact on formative assessment, we have made a deliberate decision to focus on the dispositions and characteristics of the learner, rather than the quality of the feedback provided to them during the formative assessment task.

4. Aim, research questions and hypotheses
Our study investigates the effects of SRL capabilities on a formative task and the enactment of formative feedback to improve summative grade in online vs. blended learning contexts. This was explored through two research questions:

RQ1. Do SRL capabilities predict an indicative grade from a formative assessment task in blended and online learning environments?

H1. Learners with higher levels of SRL capabilities will be awarded higher indicative grades on a formative assessment task.

RQ2. Do SRL capabilities predict final grade on a summative task and improvement score in blended and online learning environments?

H2. Learners with higher levels of SRL capabilities would be awarded higher summative and improvement grades.

As learning context (blended vs online) is exploratory, no direct predictions were made.

5. Method
5.1. Participants
The original sample size was 224 participants; however, 43 participants' data were excluded from analyses because they missed collection points throughout the study. The remaining participants were 181 students enrolled in a cognitive psychology subject at [Anonymous] University and aged between 18 and 58 years of age. There were 96 blended learners and 85 online-only learners. The majority of blended learners were female (81.3%) with a mean age of 22.96 years (SD = 6.77; range = 18–56). Most were in their second year (70.8%; first year 8.3%; third year 18.8%; fourth year 2.1%). The majority of online learners were also female (85%) with a mean age of 32.51 years (SD = 10.40; range = 19–58). Most were also in their second year (61.2%; first year 21.2%; third year 3.5%; fourth year 14.1%). The difference in age between the groups was significant (t(179) = 7.40, p < .001). There was no significant difference in gender distribution by study mode.

5.2. Materials
5.2.1. Demographics
Participants reported their (1) age, (2) gender, (3) class level (e.g., year of study in a three or four-year undergraduate bachelor degree or equivalent), and (4) enrolment mode (blended or online).

5.2.2. Motivated strategies for learning questionnaire (MSLQ; Pintrich, Smith, García, & McKeachie, 1991)
The MSLQ is the most commonly used measure of SRL (Roth, Ogrin, & Schmitz, 2016). The questionnaire has six motivational scales and nine learning scales (Pintrich et al., 1993). As 15 scales would need a very high number of participants to reach sufficient statistical power, we selected the scales that have demonstrated the greatest predictive power (Richardson et al., 2012). To measure motivation we employed the self-efficacy for learning and performance scale; to measure the use of cognitive and metacognitive strategies we employed two scales: critical thinking and metacognitive self-regulation scales; finally, to measure resource management strategies we employed two scales time and study environment and effort regulation (note: we use shortened versions of the scale names throughout the rest of the article). Items are measured on a 7-point scale, with 1 representing ‘not at all true of me’ and 7 representing ‘very true of me’. Scales were scored according to the original scoring manual (Pintrich et al., 1991) with higher scores indicating greater levels of motivational and self-regulated strategy use. Each subscale was found to have a reasonable to a high level of internal consistency ranging from α = 0.66 to 0.91, with the exception of time management which was low but still deemed acceptable (α = 0.55). See Table 1 for the number of items and Cronbach's alpha per scale.


Table 1. Number of items and Cronbach's alpha for each scale for online and blended learners.

No. of items	α online learners	α blended learners
Self-efficacy	8	0.91	0.90
Critical thinking	5	0.88	0.78
Metacognition	12	0.66	0.71
Time management	8	0.55	0.55
Effort regulation	4	0.72	0.67
Online (n = 85), Blended (n = 96).

5.3. Formative assessment task
Students submitted a draft 900-word introduction to a lab report on a cognitive psychology topic. Students were instructed to start with a general opening statement that introduces the reader to the topic, describe the background research to the current experiment, state the link between the past research and the current research, and finish with aims and hypotheses.

After submission, teachers provided clear, specific, and actionable written feedback aimed at helping learners improve the piece of work for resubmission. Feedback took an average of 25 min, and teachers were asked to focus on three feedback characteristics:

(1)
Teachers concentrated on the main issues of the current performance relevant to the marking criteria. Markers addressed each section of the rubric, avoided getting overly focused on correcting every spelling and grammatical mistake or focusing on areas that are unrelated to the marking criteria. Efforts were made to highlight both what the students did well and areas they needed to improve upon.

(2)
Teachers made the feedback actionable to improve subsequent performance. Markers were specific about what needed to occur to improve the piece of work and to achieve a higher standard on the rubric. For example “This section contains some relevant information, but it could have been strengthened by highlighting why it is important we study this topic. Providing an example of 1 or 2 sentences at the end of this paragraph taken from past readings would strengthen this section”.

(3)
Teachers were objective, did not include emotive language in feedback, and focussed on the task, not the person.

To note: the current study did not examine the different types of feedback received by learners and what impact that had on improving grades. Consequently, types of feedback information are not discussed or analysed further than what is provided here. The limitations of this are described in further detail in the Discussion section.

Students also received a numerical score out of 22 from the rubric, an indicative percentage score (out of 100) and grade (university grading bands Fail ≤50%; Pass = 50–59%; Credit = 60–69%; Distinction = 70–79%; High Distinction ≥80%) to help students calibrate their performance. Marking was standardised to ensure consistency across all areas of feedback. The indicative grade ranged from 0 to 100.

5.3.1. Resubmission of formative task for a summative grade
Students were asked to submit the final version of a 900-word introduction to a lab report. After receiving feedback on the formative assessment, students could incorporate the suggested changes, and then resubmit to be graded officially. Students were required to use track changes within their resubmitted document so that changes were clearly visible to markers. Marking was standardised to ensure consistency across all areas of feedback. Students also received a numerical score out of 22 from the rubric, an indicative percentage score (out of 100) and grade (as per university grading bands mentioned above).

5.3.2. Improvement grade
Improvement grade was calculated based on the change score from indicative grade to summative grade and represents how much a student has improved (summative grade – indicative grade = improvement grade).

5.4. Procedure
The University's ethics committee approved this study. Students were recruited through the University's Learning Management System (LMS), over two semesters from 2019 to 2020. The blended study mode comprised face-to-face instruction, which included weekly tutorials, as well as access to resources (lecture slides and recordings, readings, discussion boards, etc.) in an online learning management system. Online-only learners had access to the resources provided online in the learning management system. These online-only learners do not attend any face-to-face on-campus classes.

Learners were instructed to complete a formative assessment task on a topic related to cognitive psychology (as described above) as part of their cognitive psychology course. After the submission of the formative task, learners received an indicative grade, a rubric, and written feedback designed to improve the work. Learners then had the opportunity to improve their work in response to feedback and resubmit the same piece of work to receive a summative grade, alongside a rubric and written feedback. The MSLQ was completed once by learners, before the submission of the formative assessment task.

5.5. Data analytic plan
Several analyses were conducted to address the research hypotheses. To test Hypothesis 1 (SRL factors should predict grades on the formative task), we conducted a multiple regression with formative grade regressed onto the SRL factors (time management, metacognition, effort regulation, critical thinking, and self-efficacy). We tested Hypotheses 2 using multilevel modelling to control for non-independence due to repeated assessment of grade per participant (formative grade and final grade). In this model, grade was regressed onto a time variable (coded −1 for the formative grade and 0 for the final grade so that the intercept is with respect to the final grade). We included a random intercept in the model to enable evaluation of whether SRL variables could predict final grade, as well as a random slope for the time effect (reflecting change in grade following feedback), and regressed final grade onto the SRL variables to determine whether they could predict the level of grade improvement. Exploratory analyses examining differences between online and blended learners for SRL variables and grades were conducted using t-tests.

Participants' improvement scores were examined by grouping learners by the grade bands on the formative task (see Fig. 1; bands Fail ≤50%; Pass = 50–59%; Credit = 60–69%; Distinction = 70–79%; High Distinction ≥80%). As expected, the biggest gains on the summative task were made by learners who received the lowest scores on the formative task. The smallest gains on the summative task were for learners who initially scored the highest, at a High Distinction level, on the formative task (this was also the smallest group in terms of sample size). This is not surprising as the level of improvement in performance should depend on the quality of the initial submission. If learners receive over 80% on their formative assessment task, then they have less room for improvement after actioning any suggested feedback (i.e., a ceiling effect). This group of high achievers comprised 7.1% of the online learners and 9.4% of the blended learners. t-tests revealed no significant difference for blended or online learners in the High Distinction band for score on the formative task (81.93 vs. 84.32 respectively; t(13) = −1.16, p > .05) or by how much they improved from formative to summative grade (M = 9.85 vs. 8.51 respectively; t(13) = 0.629, p > .05). To avoid a ceiling effect in regression-based analyses, learners who received an indicative grade on the formative task 80% or higher were removed from analyses that included the summative task and change grade.

Fig. 1
Download : Download high-res image (103KB)
Download : Download full-size image
Fig. 1. The average improvement in score from formative to summative task grouped by grade band.

6. Results
Descriptive statistics are presented in Table 2. Mean scores show that the MSLQ motivation and learning strategies scales had on average above neutral (4.0) endorsement, indicating greater use of that particular strategy or higher confidence. Online learners scored higher than blended learners on all variables; however, only self-efficacy, time management, and effort regulation were significantly different across groups, with metacognition approaching significance (p = .055). There was no difference between online and blended learners in relation to their distribution across the grade categories. Once students who scored above 80% on the formative assessment task were removed, learners improved two grades on average (~15%) in the final submission.


Table 2. Descriptive statistics for online and blended learners.

Minimum	Maximum	M	SD	t(179)
Indicative grade	Online	28.33%	86.59%	61.08%	12.72%	−0.66
Blended	25.00%	100.00%	77.36%	12.93%
Summative grade^	Online+	50.00%	94.55%	74.90%	9.66%	−0.49
Blended++	25.00%	94.17%	75.75%	12.44%
Improvement in grade^	Online+	2.27%	34.50%	15.40%	7.46%	−0.17
Blended++	3.41%	37.50%	15.59%	7.54%
Critical Thinking	Online	1.00	7.00	4.43	1.37	0.20
Blended	1.00	7.00	4.18	1.18
Self-efficacy	Online	2.63	7.00	5.41	0.87	2.61*
Blended	2.13	6.88	5.07	0.91
Metacognition	Online	2.92	6.58	4.85	0.84	1.93
Blended	2.42	6.33	4.61	0.82
Time Management	Online	3.00	7.00	5.45	0.95	2.18*
Blended	2.00	7.00	5.13	1.05
Effort Regulation	Online	3.00	7.00	5.76	0.98	3.48**
Blended	1.50	7.00	5.22	1.10
*p < .05, **p < .01. Online learners (n = 85 except +n = 79 with high achievers removed), blended learners (n = 96 except ++n = 87 with high achievers removed). ^df for summative and improved grades = 164.

6.1. RQ1: Do SRL capabilities predict an indicative grade from a formative assessment task in blended and online learning environments?
Table 3 shows that self-efficacy was a significant predictor of indicative grade on a formative assessment task for online learners, whereas effort regulation was a significant predictor for blended learners. The combination of variables predicted 8.7% of the variance in initial grade for blended learners and 3.9% of the variance for online learners, which would be considered a low amount of the variance explained, particularly for online learners. The results support the hypothesis in that higher scores of SRL capability do predict indicative grade; however, they are not strong predictors. SRL capabilities were shown to have different predictive value for blended learners and online learners, though the regression coefficients for all predictors (regardless of study mode) suggested small unique effects of each SRL strategy on task performance.


Table 3. Multilevel modelling of SRL strategies and self-efficacy with indicative grade on a formative assessment task for online and blended learners.

b	Lower CI	Upper CI	p(one tailed)
Online Learners
 Critical Thinking	0.36	−2.33	3.04	0.41
 Self-efficacy	3.26	0.01	6.50	0.05⁎
 Time Management	−0.02	−4.41	4.37	0.50
 Metacognition	−0.08	−2.61	2.44	0.48
 Effort regulation	−1.06	−3.68	1.55	0.25
Blended Learners
 Critical Thinking	−0.33	−3.03	2.38	0.42
 Self-efficacy	−1.28	−4.66	2.11	0.27
 Time Management	−1.76	−6.26	2.73	0.26
 Metacognition	−2.43	−5.15	0.29	0.07
 Effort regulation	2.72	0.01	5.42	0.05⁎
⁎
p < .05. Online (n = 85), Blended (n = 96).

6.2. RQ2: Do SRL capabilities predict final grade on a summative task and improvement score in blended and online learning environments?
The level of improvement in performance should depend on the quality of the initial submission. If learners receive over 80% on their formative assessment task, then they have less room for improvement after actioning any suggested feedback (i.e., a ceiling effect). Therefore, research question 2 relates to learners who received an indicative grade lower than 80% on their formative assessment task.

As shown in Table 4, time management significantly predicted grade improvement for online learners, with all predictors combined accounting for 8% of the variance, which is higher than for the formative task but still considered low. In contrast, a moderate amount of variance is explained in summative grade (14%), when the SRL predictors are combined. The results also show that self-efficacy and effort regulation are significant predictors. Even so, the regression coefficients show that the unique effects of these predictors on task performance were small.


Table 4. Multilevel modelling of SRL strategies and self-efficacy with improvement score (change between indicative grade to summative grade) as well as summative grade for online learners who score less than 80% on the formative assessment task (n = 79).

b	Lower CI	Upper CI	p(one tailed)
Improvement Score
 Critical Thinking	0.33	−1.27	1.92	0.37
 Self-efficacy	−0.88	−2.41	0.66	0.17
 Time Management	2.32	0.57	4.07	0.01⁎
 Metacognition	0.59	−2.13	3.31	0.36
 Effort regulation	−0.82	−2.56	0.92	0.22
Summative Grade
 Critical Thinking	−0.64	−2.50	1.22	0.29
 Self-efficacy	3.16	0.47	5.86	0.03⁎
 Time Management	−0.61	−3.41	2.19	0.36
 Metacognition	−0.22	−3.58	3.15	0.46
 Effort regulation	2.93	0.63	5.22	0.02⁎
⁎
p < .05.

As shown in Table 5, self-efficacy significantly predicted grade improvement for blended learners, with all predictors combined accounting for 45% of the variance, which is considered high. For the summative grade, the SRL predictors explained 8% of the variance in summative grade, though none of the predictors made a significant unique contribution. However, the effect of effort regulation approached significance (p = .06).


Table 5. Multilevel modelling of SRL strategies and self-efficacy with final grade on a summative assessment task for blended learners who score less than 80% on the formative assessment task (n = 87).

b	Lower CI	Upper CI	p(one tailed)
Improvement Score
 Critical Thinking	0.07	−1.56	1.70	0.47
 Self-efficacy	1.92	0.03	3.80	0.05⁎
 Time Management	−0.62	−2.67	1.42	0.31
 Metacognition	−0.08	−2.18	2.03	0.48
 Effort regulation	−1.49	−3.14	0.16	0.07
Summative Grade
 Critical Thinking	−0.89	−3.41	1.63	0.28
 Self-efficacy	0.93	−1.68	3.53	0.28
 Time Management	−1.50	−4.56	1.55	0.21
 Metacognition	−2.77	−7.28	1.74	0.16
 Effort regulation	2.77	−0.12	5.67	0.06
⁎
p < .05.

For both improvement grade and summative grade, more SRL capabilities resulted in a higher grade, supporting the hypothesis. However, variance explained was sometimes low and the unique predictive effects of predictor variables were small. SRL capabilities were shown to have different predictive value for blended learners and online learners.

7. Discussion
Much of the literature has focused on the ways in which formative assessment practices improve SRL. This study investigated whether SRL characteristics are related to successful engagement with formative assessment (including an indicative grade, rubric, and written feedback) and subsequent summative performance. A secondary aim of the study was to explore differences between online and blended learners' performance.

7.1. What is the effect of SRL skills on the formative assessment process and final summative grade?
Our hypothesis 1 that higher scores on SRL capability predict indicative grade was supported by significance testing; however, these SRL constructs were not strong predictors. Hypothesis 2 was also supported: for both improvement grade and summative grade, more SRL capabilities resulted in a higher grade; however, variance explained was sometimes low. Once students that scored high in the formative assessment task (>80%) were removed, learners improved two grades on average (~15%) in the final submission. Thus, regardless of study mode (blended vs. online), as one would expect, the formative assessment had a positive impact on student learning.

Despite no differences in grades, online learners had higher confidence and self-rated strategy use than blended learners. There were also significant differences in self-efficacy, time-management, and effort regulation (with metacognition approaching significance). Given that grades were comparable across the two groups, these particular characteristics may have been more important for online learners to achieve the same learning outcomes. This makes sense given the level of autonomy often required for online learning (Serdyukov & Hill, 2013). Yet, the lack of correlations of these SRL variables with grades reduces support for this hypothesis. Another possibility is that blended learners have more opportunity for co-regulation than online learners. Co-regulation occurs through student interactions with others (such as a teacher), whereby the teacher not only helps students perform the task but also helps them regulate their actions before, during, and after the task (Allal, 2016; McCaslin & Hickey, 2001; Panadero et al., 2019). Panadero et al. (2019) theorised that co-regulation aided learners to not only improve SRL but also improved understanding of what quality looks like through enhanced evaluative judgement. According to Panadero et al., a key characteristic of co-regulation is the level of interaction between the student and the teacher. The higher the interaction frequency, the greater chance the student will adopt the teacher's regulatory actions. While online learning can often include synchronous interactions and communication with instructors and peers, it also provides for asynchronous learning in which traditional barriers of geography and time of class scheduling are no longer barriers (Ku & Chang, 2011; Means, Toyama, Murphy, Bakia, & Jones, 2009). We hypothesise that it is possible that blended learners had more opportunity for co-regulation than online learners, and this explains the differences seen between the level of strategy use needed for high performance between these group.

Lastly, although several significant predictors of performance were identified (and are discussed below), it is worth emphasising that the total amount of variance explained in performance was typically small to moderate, and that the unique contributions of each predictor were also small. For instance, the largest unique contribution in the reported models was around 3 grade points (out of 100) for a 1-point change in the predictor. In itself, this constitutes a meagre improvement in grade, and suggests that in order to generate substantial improvement in performance, an intervention with modest improvements in SRL would need to target multiple aspects of SRL in order to push a student's performance to the next grade band (e.g., from a distinction to high distinction). By contrast, an intervention with moderate effects (e.g., a 2-point increase in each targeted SRL strategy) could possibly achieve a whole grade level improvement through: (i) targeting individuals with lowest levels of SRL initially, and (ii) prioritising intervention on two or three SRL strategies (present results suggest effort regulation, time management and self-efficacy may be most impactful).

More broadly, the small effects observed in the current study also signal that the SRL strategies measured in the present study may not be the only contributors to individual differences in performance. For example, how much feedback was provided, how productive and actionable it was, as well as how the student used it would likely have played a role in student performance and is worth exploring in future research. Other factors such as value students place on the given task, level of prior knowledge for this subject, and amount of time students have available to complete the task may also contribute to performance. It is possible too that the relationship between SRL and performance is more complex than modelled in the current study. While each SRL strategy may have some variance to contribute to performance, it may be that the presence of a combination of SRL strategies is the best predictor of performance (e.g., the best performance for students who are effective time managers, motivated, and have self-efficacy). Present sample sizes are not well suited for such moderation tests, and it is recommended that future studies take up this question. It is noted too that the variance explained for blended learners' improved grade from pre- to post-feedback was substantial. As this effect was considerably larger than other tested effects, caution is recommended in interpreting this effect until further studies have attempted to replicate it with a new sample.

7.2. What are the differences in SRL between online and blended learners?
The results demonstrate that there were differences in SRL between online and blended learners. However, the two groups did not significantly differ in their scores on the assessment task (indicative, summative, or improvement). Crucial to online learners is the need to be confident in approaching both the formative and summative task with an expectation that they will succeed. After receiving feedback, goal commitment, maintaining effort, and continued use of strategies helped learners achieve the highest summative grades. For the biggest gains, online learners need to concentrate on planning and engaging in blocks of time for effective and undisturbed study. If we assume the online learning environment is highly autonomous, it is unsurprising that the resource management strategies of time management and effort regulation are important to academic performance. These findings align with a study by Broadbent (2017), which found that only time management and effort regulation strategy use were predictive of summative grades for online learners. Teachers should make efforts to encourage learners to use diaries with a timetable for weekly planning and to create and prioritise lists of tasks. Teachers should also make short-, medium-, and long-term plans to embed management skills in students, including weekly structured virtual classroom sessions throughout the semester.

Blended learners also highlighted the need to focus on the confidence of learners in improving grades and maintaining effort when first submitting formative work. It should be noted that despite using SRL strategies less often, blended learners had larger variance accounted for by both the formative grade and the grade improvement than online learners. As speculated by Broadbent and Poon (2015) and Broadbent (2017), it is possible that the effects of SRL strategies are dampened in the online learning environment, and that online students need to utilise more strategies to have a similar impact on academic performance. Indeed, the lack of difference in grades between the two groups despite the broader adoption of SRL strategies for online students is consistent with this notion.

For both online and blended learners, learning design should take into account and plan for tasks that build students' confidence. A meta-analysis by Honicki and Broadbent (2016) highlighted the importance of self-efficacy in academic achievement. Seemingly, this is because students who hold stronger beliefs about their ability to perform academically are more likely to do so than students who do not hold strong beliefs in their academic ability. Thus, teachers should design curriculum and learning environments to promote self-efficacy in learners (Broadbent, 2016), with a focus on mastery experiences, by scaffolding tasks with some achievable steps, through vicarious experiences such as the use of exemplars (Schunk, 2003), with verbal persuasion through a sense of relatedness with, and support from, the teacher (Crimmins et al., 2016), and through managing emotions (Schunk & Pajares, 2009). Focus too should be placed on encouraging effort regulation, whereby teachers help students to persist, and to continue to draw on strategies, even when there are more interesting things to do. Helping online learners to plan their time and be free of distractions is also crucial.

7.3. Limitations
The university from which participants were recruited has a reasonably large proportion of mature age students who choose to study online, and hence the age range of participants in the present study may differ from other institutions. Traditional correlates such as intelligence, secondary school grades, and other previous grades were not considered in this study. Conventional predictors of subject grade have been found to have positive, small to moderate effects (Richardson et al., 2012; Robbins et al., 2004) and potential, unmeasured moderators of SRL strategies impact on grades. Further, emotions such as hope, anxiety, and frustration have been found to predict strategy use and these emotions' effects on performance could be mediated by SRL strategy use (Marchand & Gutierrez, 2012). Conversely, there could be other learner characteristics, not measured here, that influence the relationship (e.g., number of hours of paid employment, full-time or part-time enrolment status). While measuring intelligence, prior achievement, etc. was outside the scope of this paper, these variables would likely add explanatory value to the model.

The active role taken by the learner during formative assessment tasks teaches learners to develop metacognitive skills, to reflect, use feedback, plan and set goals, and engage with other strategies to improve learning (Butler & Winne, 1995; Hattie & Timperley, 2007; Nicol & Macfarlane-Dick, 2006). The current study did not account for any changes in SRL that may have occurred as a result of engaging in the formative task. Students may have developed successful strategies through interaction with feedback after the baseline measure. In future, it would be interesting to measure SRL both before the formative task and after submitting the summative tasks to see if learners show improvements.

While staff were directed to give actionable feedback to enable the student to improve their work and marking underwent a moderation process, the current study did not examine the different types of feedback received by learners and what impact that had on improving grades. This was a deliberate decision, as the feedback literature to date has focused on what the teacher does, and not what the learner brings to the interaction. However, as formative feedback is a critical component of formative assessment, it would be important in future to explore not only how SRL impacts on formative assessment, but the interaction of SRL on formative assessment alongside different feedback practices. Lastly, it should be acknowledged that improving an assessment at one-time point as we have done here, tells us little about improvement long term, which would be worth exploring in future research.

8. Conclusion
To the authors' knowledge, this is the first study to test the key drivers of performance during a formative task that are generalisable across online and blended learning contexts. Overall, formative assessment helped to improve both online and blended learners' grade on a summative assessment task. The strongest predictors for online learners were self-efficacy, time management, and effort regulation. For blended learners, it was self-efficacy and effort regulation, but to a lesser extent. Our emphasis on SRL characteristics needed for formative assessment and feedback has helped us better understand which learners are most at risk - and need the most support - to achieve better learning outcomes during formative assessment tasks. In particular, assistance should be prioritised for those who lack confidence, do not manage their time well, and have difficulty persisting in tasks before engaging in a formative assessment task.

