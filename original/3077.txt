This brief paper develops a series of provocations against the current forms of Learning Analytics that are beginning to be implemented in higher education contexts. The paper highlights a number of ways in which Learning Analytics can be experienced as discriminatory, oppressive and ultimately disadvantaging across whole student populations, and considers the limitations of current efforts within educational data science to increase awareness of ‘ethics’ and ‘social good’. This culminates in a stark choice: is it possible to substantially improve the field of Learning Analytics as it currently stands, or should we abandon it in favour of new forms of applying data science that are aligned with the experiences of non-conforming ‘learners’ and un-categorizable forms of ‘learning’?


Keywords
Learning Analytics
Educational data science
Critical data studies
Data politics
Queer data


1. Introduction
Much of this special issue is understandably concerned with thinking the best of Learning Analytics. After all, the idea of Learning Analytics raises a number of seductive promises for all stakeholder groups currently involved in the development and implementation of these technologies in higher education settings. What educational data scientist would not want their work to foster potentially powerful forms of active learning across large student populations? What higher education leader would not want rich, detailed insights into key institutional ‘performance points’ such as student performance, retention and engagement?

In contrast, then, this brief article deliberately considers the premise of this special issue in a contrary manner. Instead of ‘reading with’ the promises of Learning Analytics, what happens if we choose to ‘read against’ them? What are the fundamental social problems inherent in the ways that Learning Analytics products and practices are being realized in higher education contexts? Who is most likely to be experiencing these issues? How might we ‘think otherwise’ about the application of analytics in higher education – particularly if ‘we’ is taken to include the many interest groups not currently included in the notion of Learning Analytics ‘stakeholders’? As I hope this paper will show, ‘thinking the worst’ can be a useful means of ‘stress testing’ the core premises, principles and politics that the current implementation of learning analytics into education is currently built around.

Of course, what readers choose ultimately to do with these insights will depend on their own underpinning agendas, values and ideologies. Yet regardless of one’s background, this is a highly appropriate moment to be introducing an element of pessimism into proceedings. People working in the area of learning analytics, education data-mining and other forms of ‘educational data science’ find themselves at a crossroads. On one hand, the vast majority of people working along these lines are clearly very thoughtful and well-intentioned - developing products, protocols and practices that they genuinely hope (if not believe) will considerably improve learning and learners’ experiences of engaging in education. On the other hand, going by the forms of ‘analytics’ that we see being implemented in higher education contexts, there might well be a strong case for radically rethinking how ‘Learning Analytics’ is playing out beyond the confines of LAK, SOLAR and the other academic manifestations of Learning Analytics.

To be blunt, then, this paper starts from the contention that something is surely amiss if the main aim of academics working in this area is to be “caring and supportive” (Prinsloo, 2019), but significant numbers of people continue to experience Learning Analytics tools and techniques as “data being used against me to screw me” (Essa, 2019). This tension has been highlighted in the recent Twitter-controversies over the propensity of learning analytics tools and systems to be used for purposes of institutional surveillance rather than individual support (e.g. Kovanovic, 2019). As I have argued elsewhere:

“All told, there is an emerging suspicion (warranted or not) that students are not the primary beneficiaries of the Learning Analytics technologies they are subjected to during their school or university education” (Selwyn, 2019).

So, in this brief paper I want to reflect a little further on these tensions – especially the question of what academics working in the area of Learning Analytics consider the political intent of their work to be. If we take the politics of Learning Analytics seriously, then perhaps we need to begin thinking along more radical lines than simply embracing ‘ethics’ and trying to foreground possible ‘social goods’ that educational data science might support. Instead, it might be a useful thought experiment to pursue a more radical logic – what PaulPrinsloo (2019)identifies as “question[ning] the very existence of Learning Analytics” (or, at least, questioning the very existence of the forms of Learning Analytics that are currently being implemented in educational settings around the world).

In working through this prospect, I want to draw on various recent provocations from within the broader data science community – all data science ‘insiders’ who are voicing informed frustrations over the politically uninterested malaise that they see pervading their field of work. These writers are beginning to argue that it is not good enough for data scientists to presume that technology is essentially neutral, that data is objective, and resort to all-absolving claims of ‘I am just an engineer’. In my view, these insider critiques offer some interesting future directions for educational data science to pursue.

2. Learning Analytics as political action
So, all I wish to do in this paper is reflect on how these burgeoning arguments might translate to the specific domain of Learning Analytics. In particular, I want to start by unpacking one landmark piece by the Harvard data scientist Ben Green, making the case for ‘data science as political action’ (Green, 2018). Green develops two aspects of this thesis – firstly, considering why data scientists should recognize themselves as political actors, and secondly reflecting how data scientists might ground their practice in politics. In so doing, the following points are raised that relate neatly to how alternate forms of Learning Analytics might be envisaged.

2.1. Educational data scientists are not apolitical/ educational data is not neutral
Green starts by reminding us that attempting to present oneself (or one’s actions) as apolitical is itself a political stance. More specifically, attempting to claim neutrality is a ‘fundamentally conservative’ position that signals implicit support for maintaining the status quo and, therefore, the interests of dominant social groups and hegemonic political values. As such, it makes no sense for anyone working within Learning Analytics to claim neutrality, or consider themselves to be somehow operating ‘outside of politics’. No knowledge or action is purely objective, and no data science can be carried out in the expectation of simply discovering ‘knowledge for knowledge’s sake’. Here Green draws on DonnaHaraway (1988)to make the powerful point that no branch of science is able to lay claim to providing a completely detached, objective “conquering gaze from nowhere”. Despite the claims of some in the Learning Analytics community, there is no detached ‘scientific rationality’ that sits above societal concerns. There is no commonly agreed-upon ‘problem that Learning Analytics is meant to solve’ (Rosé, 2019).

This certainly encapsulates one of the underlying points of recent critiques of learning analytics from outside the education data science community. In short, knowledge about learning, students or education cannot be value-free. Instead, this knowledge is inherently aligned with the social contexts that generate it. As such, Learning Analytics is not a matter of developing neutral technologies that are capable of being used for good or bad ends. To reiterate this point, Green draws on LangdonWinner’s (1980)argument for embracing the understanding that every artefact arising from data science ‘has politics’. All data systems, processes and procedures are based on design decisions that have impacts that are determinative for society. This is not to ‘blame’ Learning Analytics practitioners for the consequences of their design and development work. Yet it is important for the field to assume some degree of responsibility – especially for how Learning Analytics developers, designers and vendors choose to interact with the aspects of education and society that their tools and techniques interact with.

2.2. The trap of turning to Learning Analytic ‘ethics’
One burgeoning area of interest in addressing the issues just outlined is imbuing Learning Analytics a heightened awareness of ethics and professional understandings of fairness, accountability and transparency. These are clearly (small) steps in the right direction, but Green rightfully warns against seeing these shifts in emphasis as sufficient. In this sense, I would not want to advocate that Learning Analytics actors simply replicate recent high-profile episodes of technology-related ‘ethics-washing’ (Wagner, 2018), where ethics frameworks and ethics boards are established to no great effort (other than as an attempt to avoid regulation). While attuning Learning Analytics practice toward issues of ethics is a welcome ‘first step’, it remains an insufficient response by itself.

For example, Green argues that recent calls for computational and technical professions to adopt a form of Hippocratic oath or other such ‘ethics codes’ overlook the fact that professional codes rarely (if ever) result in social justice. These codes seldom contain clear normative directions of what data scientists should be doing (i.e. beyond vague illusions to ‘being aware’ of the social, cultural and political impact of their work). Moreover, these codes rarely are reinforced by mechanisms to ensure that designers, developers, programmers and engineers follow the stated principles or else are held accountable for any violation. It can also be argued that the idea of easily achievable ‘ethical’ action simply propagates the false dichotomy that technology and society are somehow distinct from each other rather than being inherently entwined. In all these ways, then, I would agree that simply pushing for a heightened awareness of Learning Analytics ‘ethics’ is unlikely to radically alter the underlying disparities of unequal power that underpin current criticisms of the ongoing ‘datafication’ of contemporary education (seeSelwyn, 2015).

2.3. The trap of turning to ‘data science for social good’
Alongside data ethics, Green also problematizes the seemingly progressive position of pursuing data science for ‘social good’. This is the logic that while never capable of providing perfect solutions, data science can be used to improve current circumstances. Again, the idea of reframing ‘Learning Analytics for social good’ is an obvious conclusion that some commentators are drawing from their recent critiques of educational data science. On one hand, Green commends data scientists for being willing to engage in more nuanced thinking and engagement with social issues. After all, an ambition to ‘do good’ brings a human focus to what might otherwise be largely technical concerns. Nevertheless, Green laments how these efforts are hampered ultimately by their reliance on vague and unarticulated political assumptions about what ‘social good’ might constitute (let alone the question of whether an unproblematic ‘good’ might be achievable at all).

These concerns certainly temper any enthusiasms that we might have for establishing some form of ‘Learning Analytics for Social Good’. At best, Green argues, these efforts tend to fall into a non-politicized “know it when you see it” approach to deciding what constitutes social good. This can lead quickly to crude equivalencies such as ‘poverty=bad’ or ‘staying enrolled on a university course=good”. Couching one’s actions in such broad-brush presumptions is a convenient way of glossing over the fact that deciding what constitutes ‘good’ involves normative judgement which ideally should be driven by an underpinning guiding political philosophy. This lack of grounding principles means that the ‘social goods’ that data scientists end up pursuing can cover a wide (and sometimes conflicting) range of political characteristics. This can result in dangerous over-simplifications of issues that are actually politically complex and might lack clear consensus over what is desirable. As such, data scientists run the risk of blithely “wading into hotly contested political territory” and acting in a contestable (perhaps regressive) manner. AsGreen (2018, n.p)concludes:

“By framing their notions of ‘good’ in such vague and undefined terms, data scientists get to have their cake and eat it too: they can receive praise and publications based on broad claims about solving social challenges while avoiding any actual engagement with social and political impacts”.

2.4. Meaningful social change can only result from direct engagement with the politics of educational data
At best, then, my take-home message from Green’s analysis is that talk of Learning Analytics ‘ethics’ or Learning Analytics for ‘social good’ should only be opening points of complex conversations about what we consider to be the most desirable applications of data science in real-life educational contexts. In short, this requires engaging properly with some soul-searching questions - what do we really want to achieve from devoting our careers to working in Learning Analytics? … What are we trying to do here? Crucially, these conversations need to be framed by explicit sets of values, and be prepared to embrace the politics of negotiating between competing perspectives, goals, and agendas. As such, there can be no clear-cut ‘right’ or ‘wrong’ applications of Learning Analytics that do not merit scrutiny. Instead, we need to push for a cultural shift throughout Learning Analytics practitioners to encourage a collective understanding of being co-engaged in political action that has varying impacts on different groups of people over time.

Pursuing Learning Analytics along these lines clearly requires additional time and effort. Indeed, if Green’s arguments are taken to their logical conclusion, decisions regarding how to apply Learning Analytics to any higher education setting can only be taken after a considerable amount of deliberation, debate, dialogue and consensus building. These deliberations need to be especially mindful of the complexities of the social, cultural and political contexts in which any Learning Analytics system, tool or application is to be implemented. This is not to say that Learning Analytics practitioners need to compromise their technical interests, expert knowledge, or passion for problem-solving and innovation. Yet, asGreen (2018), n.p reasons, any computational skills and passions need to be bolstered by a concurrent acknowledgement that:

“… data science is a form of political action. Data scientists must recognize themselves as political actors engaged in normative constructions of society and, as befits political work, evaluate their efforts according to the material downstream impacts on people’s lives”

3. Toward alternate ‘Learning Analytics’
So, what might as politically-engaged Learning Analytics look like, and how might its practitioners think and act differently? Of course, answering this question first requires clarity on precisely what political agendas are to be pursued. This is where one’s personal politics and values come to the fore. Taking my own political agenda as a starting point, then, I am most interested in considering how an area of academic activity such as Learning Analytics might evolve toward a more deliberative and rigorous grounding in a politics of ‘social justice’. I suspect from the tenor of discussions that are taking place in recent special issues of journals such as BJET and JLA (Buckingham Shum, 2019;Buckingham Shum & Luckin, 2019) that there are others in the academic Learning Analytics community who feel the same way.

My suspicion is, however, that this requires a completely new approach and rebuilding of what ‘Learning Analytics’ is. To repeat PaulPrinsloo’s (2019)point reported earlier, I do believe that we need to question the very existence of the types of Learning Analytics that currently dominate the educational landscape. In terms of this pursuit of social justice, then, Green outlines four phases that can guide individual change and institutional reform across the Learning Analytics community. In brief, this involves:

1.
Becoming interested in directly addressing social issues;

2.
Recognizing the politics underlying these issues;

3.
Redirecting existing methods toward new applications;

4.
Developing new practices and methods that orient Learning Analytics around a mission of social justice.

These suggestions raise a number of interesting new directions that a Learning Analytics explicitly concerned with issues of social justice might wish to pursue. First, is a need for data scientists to pursue clearly articulated visions of social benefit. This might require exponents of Learning Analytics to develop better understandings of the social contexts that Learning Analytics work is being implemented. For example, educational data scientists might well benefit from secondments to work in secondary schools, teach undergraduate humanities classes, or relocate to the Global South.

Green’s suggestions also raise the prospect of consulting and/or conducting social research on the issues that Learning Analytics is attempting to address. Here, Green recommends engaging with academic literature rooted in the STS (science and technology studies) tradition. He also suggests conducting studies that adopt ‘critical design’, ‘anti-oppressive design’ and other participatory approaches to perceiving data science problems and then developing data-led ways to address these problems (e.g.Dunne & Raby, 2013;Smyth & Dimond, 2014). To these ends, Green evokes the South African disability rights mantra of “Nothing About Us Without Us”. In other words, participatory approaches to Learning Analytics cannot merely rely on tokenistic ‘end user’ consultation, but instead must genuinely commit to ensuring the central involvement of voices of those who are directly impacted by Learning Analytics tools and techniques in all stages of design, production and implementation.

All of this implies a radically different approach to educational data science and Learning Analytics. As a data scientist himself, Green is certainly not developing an ‘anti data science’ rant. If anything, Green is simply attempting to imbue his chosen field with a heightened sense of perspective. In this sense, Green’s arguments culminate in a straight-forward enough challenge – in short, are data scientists seeking to work with dominant repressive systems or work against them? Here Green looks back to AndréGorz’s (1967)distinction between “reformist reforms” (actions that limit their objectives to what is rationally achievable within a given system), and “non-reformist reforms” (actions which are driven by an interest in what should be made possible in terms of human needs and demands). In short, reformist reformers start with existing systems and strive to improve them, while non-reformist reformers start from a set of desired social conditions and seek ways to attain them (regardless of system constraints).

This is where I might be accused of slipping into arguments that might be seen as unrealistic or romantic. Nevertheless, these are important discussions to pursue. To date, Green reasons that data science has almost always been focused on ‘reformist reforms’. After all, this is a field founded upon a standard logic of accuracy, efficiency and improving the performance of systems rather than substantively altering them. As such, conventional data science is an inevitably conservative pursuit. This reading certainly appears to hold true for the forms of Learning Analytics that have developed over the past decade or so. Nevertheless, Green raises the prospect that we perhaps need to set about developing more radical and resistant forms of data science.

As mentioned at the beginning of this paper, we can see this sort of thinking now percolating in various areas of data science. For example, writing from a critical race perspective, RodericCrooks (2019, n.p.)has argued:

There’s a very useful difference here: some people believe we can develop a liberatory data science, others argue that the intent of data collection is always (and has always been) to harm. I’m calling this our Audre Lorde problem.

Here, Crooks is referring back to AudreLorde’s (1984)denunciation that “the master’s tools will never dismantle the master’s house”. Thus, as Crooks intimates, this is a fault-line that runs throughout all progressively-minded efforts to think about ‘data justice’, ‘data for good’ and the like. Even if the explicit intent of data collection is not always to harm per se, it could be argued that data collection is always undertaken with the intention to control. Certainly, a key question to ask of any instance of data collection and analysis (such as Learning Analytics) is ‘what the underlying intent here?’. I would argue that for all its talk of ‘influencing learner decision-making’, ‘supporting learner choices’, or ‘informing teacher actions’, Learning Analytics is fundamentally concerned with control and the exercise of power. What one person might see as offering ‘support’, is what another person might experience as being ‘screwed’.

4. Steps toward more radically-minded forms of Learning Analytics
If the idea of social justice is to be taken seriously, then it is crucial that we begin to reassess how Learning Analytics is encountered by those groups who tend to experience education as a form of oppression and being controlled. One particularly useful data science voice on these matters is Os Keyes – especially their provocative assessment of “Why data science is a profound threat for queer people” (Keyes, 2019). Keyes starts by defining ‘queer’ primarily in terms of fluidity, autonomy, a distinct lack of definition, and “the freedom to set one’s own path”. They argue that data science is fundamentally set in opposition to these qualities – grounded as it is in norms, discrete categories, precise definitions and predicable futures. In this sense, Keyes raises a number of interesting ways in which to reassess the politics of the dominant forms of Learning Analytics currently populating university classrooms and elsewhere.

For example, Keyes draws parallels between data science and what the trans activist DeanSpade (2015)has termed ‘administrative violence’. This describes the ways that administrative systems “create narrow categories and force people into them in order to get their basic needs met”. AsKeyes (2019), n.p)paraphrases, “the rigid maintenance of hierarchy and norms is really what the state is for… We are attempting to negotiate with a system that is fundamentally out to constrain us”. Similarly, Keyes also draws on the notion proposed by Anna LaurenHoffman, 2018of ‘data violence’ – a much-extended and expanded form of violence perpetuated through the masses of data that are collected through all our digital systems. In this sense, the dominant form of data science underpinning what ShoshanaZuboff (2019)has popularized as ‘surveillance capitalism’ is premised upon an ambition to control and standardize the paths that all aspects of our lives can take – from the films that we watch to the likelihood of getting a home loan and/or being incarcerated. From the perspective of the individual student who is being prompted, nudged and profiled by their university’s digital systems then Learning Analytics also falls into this mode of oppressive ‘datafication’.

In all these ways, there is little about the ongoing implementation of Learning Analytics into education settings that bodes well for queer and transgender individuals. Indeed, Keyes quite reasonably contends that the people who stand to be harmed most by the application of data science to everyday life are those who donotfit neatly into standardized systems, and those whose lives fall between the cracks of dataveillance. In short, data science does not respond well to outliers or those whose lives do not fit neatly into discrete categories. Take, for instance, a trans school student whose home life is disjointed – meaning that they have a slightly irregular pattern of attendance, erratic parental engagement with school online systems, non-standard medical records, and an awkward ‘Other’ gender category. Any gaps, omissions and blanks in this students’ data profile will invariably lead to reduced calculations and a limited range of diagnoses and decisions being reached about them. Crucial issues will either be ignored, or perhaps additional unwarranted assumptions made. Either way, the chances of being mis-represented will be high.

Of course, the standard data science response to such a scenario is that we need to work harder to ensure that there are no such gaps and omissions. In short, the generally accepted solution to any data-related shortcomings would be that the school and family need to work to increase this student’s data visibility and participation – i.e. to expand the extent to which dataveillance operates. Yet asKeyes (2019, n.p)reasons, “I don’t know about you, but my idea of a solution to being othered by ubiquitous tracking is not ‘track me better’”.

All this leads Keyes to argue against what they contend is an essentially inhumane activity. They contend that datafication is essentially concerned with using inevitably limited sources of information to monitor, track, profile and corral people into preferred courses of action. As they put it: “perhaps a more accurate definition of data science would be: the inhumane reduction of humanity down to what can be counted”. In a little more detail …

We can use datalogical systems for efficiency gains and for consistency gains; we can remove that fallible, inconsistent ‘human factor’ in how we make decisions, working more consistently and a million times faster. Which is, you know, fine, sort of. But by definition, a removal of humanity makes a system, well, inhumane! (Keyes, 2019, n.p).

So why would anyone actively work to legitimize inhumane forms of datafied education? Indeed, from this perspective, Keyes reasons that there is little point fighting to reform and improve data-driven systems that are fundamentally designed to control and harm marginalized populations. For example, training school facial recognition systems on more diverse data sets so that they recognize black faces more accurately simply increases the harm that these systems can then do to black populations. As such, the end-point to Keyes’ argument is therefore one of non-participation, rejection and radical reinvention. They argue that it the most logical response for queer and trans communities is to refuse to participate in such systems that are fundamentally designed to control and do harm.

This is the complete opposite to the acquiescent view amongst some in the Learning Analytics community of “whether we like it or not, we live in times of accountability” (Essa, 2019). Instead, this is the resistant argument that we need to develop alternate ways of “being, living and knowing” that work around data science and its artefacts. Ultimately, then, this requires us to somehow work toward an alternate form of ‘radical data science’ – in other words …

A data science that is not controlling, eliminationist, assimilatory. A data science premised on enabling autonomous control of data, on enabling plural ways of being. A data science that preserves context and does not punish those who do not participate in the system. (Keyes, 2019, n.p).

5. Conclusions
As noted at the beginning of this paper, how readers react to these insights will depend on their underpinning agendas, values and ideologies. As implied earlier, many of these critical issues relate to a fundamental clash in ontological assumptions regarding the extent to which education (and those involved in education processes) can be objectively known and people can choose to rationally respond to these insights.

In this sense, I would not expect any of these arguments to necessarily ‘sway’ readers who are already heavily invested in the Learning Analytics project. Nevertheless, for university leaders and Learning Analytics developers then the issues raised in the paper might at least highlight areas that could be considered to be ‘grey areas’ (if not complete blind spots) in their current practice. For example, one might take these points as highlighting aspects of Learning Analytics that we might need to be more circumspect and/or cautious of. These might include heightened awareness of the limitations of what can be represented through data, as well as the oppressive and discriminatory affordances of any system designed to monitor behavior. As has been suggested, some of these issues might be foregrounded through curricula and workplace reforms. For example, the few weeks of ‘ethics training’ that are often an adjunct to computer science degrees could be superseded by sustained education concerned with the politics of technology. Similar courses might be required for those responsible for procurement decisions within higher education institutions. As suggested earlier, these efforts might be supported by mandatory secondments for data scientists involved being embedded in the educational contexts that they are designing for.

Above all, this paper could also be read as highlighting ways in which a more diverse range of ‘stakeholder’ perspectives might be foregrounded. This would certainly include what are euphemistically referred to as ‘non-traditional’ students, as well as students from non-white, non-binary and other marginalized backgrounds. Universities might incorporate these perspectives in communal procurement, institutional analytics review boards, open data trusts, and other forms of data oversight that make Learning Analytics vendors (and institutional procurers) properly accountable for their actions. Finally, the paper also raises the need to develop a genuinely interdisciplinary future for the academic field of Learning Analytics. In particular, there are a number of emerging critiques that are potentially valuable from emerging hybrid fields such as feminist data studies, queer and/or indigenous data sciences.

Yet, from the point of view of someone not fully vested in the current form of Learning Analytics, it is also interesting to consider the more radical connotations of this paper. Thus for me, Keyes’ conclusion is perhaps the most interesting idea for the academic Learning Analytics community to begin to seriously consider. How might a substantially different form of data-based education be established that undermines, usurps and utterly blows away the current conditions of the surveilled datafied classroom? What would a re-imagined form of Learning Analytics look like if it were to genuinely enable an individual’s autonomous control of data, enable plural ways of being, and be built around preserving context?

These are provocative arguments to be making, and there are some in the learning analytics community that would consider them to constitute an unachievable ‘romantic’ notion of a world free from scientific reasoning (e.g.Essa, 2019). Instead, I would argue that the type of arguments foregrounded in this paper constitute a ‘resistant’ notion of a world free from the particular flavor of scientific reasoning that we currently defer to – i.e. the dominant forms of scientific reasoning that have arisen from hyper-masculinized, militarized and white forms of scientific endeavor. What we now come to call ‘data science’ (and, by extension, Learning Analytics) sits firmly within this dominant tradition of ‘scientific reasoning’. Yet this is not to say that things have to be this way.

Indeed, it is well worth considering what alternate forms of scientific reasoning (and therefore data science) might be possible if they arose from more feminized concerns relating to education, or queer framings that are more sensitive to the experiences of non-conforming ‘learners’ and un-categorizable forms of ‘learning’? What forms of data science are possible if imagined from explicitly feminist, race-conscious and/or non-capitalist agendas? In this sense, this is not simply a case of appropriating Learning Analytics ‘for good’, but a far more powerful proposition of harnessing Learning Analytics for reform and revolt!
