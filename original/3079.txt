Abstract
MOOCs have been advanced as a mechanism for increasing access to higher education for underserved populations. However, we still know little about the socio-demographics of MOOC participants in general and even less about underserved MOOC participants in particular. In order to broaden our understanding of MOOC participants, including those who stand to benefit the most from free college coursework, this study relies on a sample of 2634 U.S. MOOC users who participated in at least 398 different MOOCs offered by 129 different universities and 22 different providers. This study replicates findings that suggest MOOC participants are already educationally advantaged while also contributing new findings on the underrepresentation of some racial/ethnic minorities in MOOCs. In addition, data indicate that while underserved users were more likely to take MOOCs for educational advancement, they were also less likely to complete MOOCs. Such findings further challenge the democratizing power of MOOCs as currently conceived.

Keywords
MOOCs
Underserved students
Higher education

1. Introduction
Despite significant increases in U.S. postsecondary enrollment for underserved students (e.g., low-income, students of color), retention and completion rates remain low. Recent statistics on Pell grant recipients (need-based financial aid), many of whom are also the first in their families to attend college, indicate that 45% leave college before their second year (Schudde & Clayton, 2014). Compared to their high-income peers, low-income students were eight times less likely to obtain a bachelor's degree by age 24 in 2013—a gap that has increased over time (Cahalan & Perna, 2015). Relatedly, significant disparities exist for racial and ethnic minorities relative to higher education. For example, recent statistics indicate that 43% of whites between the ages of 25–29 had attained a postsecondary degree in 2015, versus 21% of Black students and 16% of Hispanic students (National Center for Education Statistics, 2016).

On an institutional and systemic level, the rising cost of postsecondary tuition and decreasing financial aid create a system of higher education that is increasingly stratified by social class and race/ethnicity (Carnevale & Strohl, 2010). For example, two-year and for-profit, four-year institutions that target financially disadvantaged students have the lowest retention and completion rates, leaving a large percentage of these students with enormous debt and without a degree (Baum & Steele, 2010). Although making college more affordable is a laudable goal, it will not solve the number of other equity issues facing underserved postsecondary students (Cahalan & Perna, 2015). For example, because of high rates of under-preparedness of low-income, first-generation students, and students of color in particular, this population also has the highest rate of remedial work to complete upon entry to college (Cahalan & Perna, 2015); however, formal remedial (developmental) coursework has “notoriously low rates of success” and students required to complete such coursework are less likely to persist through to degree completion (Goldrick-Rab, 2010, p. 443). Additionally, less than a quarter of students who take remedial courses at two-year colleges and less than one third of students who take remedial courses at four-year colleges complete associated “gateway courses” (introductory courses that act as an entry point to advanced courses and majors) (John N. Gardner Institute, 2016).

In light of these increasingly concerning patterns, massive open online courses (MOOCs) have been advanced as the most recent effort to broaden access to higher education and postsecondary coursework/knowledge by removing many of the institutional barriers that stand before low-income students and students of color (e.g., tuition costs, admissions criteria, consequences to one's formal academic record). Though there is little evidence of the effectiveness of MOOCs (Ng'ambi & Bozalek, 2015), they present enormous potential to act as agents of democratization and have outlived their hype as the number of users continues to rise (Koller, 2015). However, research to date challenges the democratizing effects of MOOCs, indicating that the majority of those who enroll in and complete MOOCs are already highly educated and employed (Christensen et al., 2013, Dillahunt et al., 2014, Laurillard, 2014, Zhenghao et al., 2015). Further, because of difficulties associated with accessing user information, existing MOOC research tends to ignore race/ethnicity and income (Kasunic, Hammer, & Ogan, 2015). Additionally, this research has been largely limited to studies of singular MOOCs or multiple MOOCs from a single provider. Because of these limitations, we still know very little about MOOCs, their participants in general, and participants who arguably serve to benefit the most from free college coursework (those who are historically underserved), in particular. In order to address such limitations, this study broadly examines the characteristics (e.g., socioeconomic status, race/ethnicity), educational motivations, and outcomes of MOOC participants, and underserved participants, in particular. Specifically, in this paper we address the following research questions across MOOCs:

1.
What are the characteristics of U.S. MOOC participants (e.g., race/ethnicity, socioeconomic status)?

2.
To what extent are U.S. MOOC participants motivated by educational advancement (e.g., gaining entry to a postsecondary institution)?

3.
What are U.S. MOOC participants' perceived MOOC-related educational advancement (e.g., gaining entry to a postsecondary institution) and learning outcomes?

4.
What is the relationship between U.S. MOOC participant characteristics and:

a.
MOOC motivations for educational advancement?

b.
MOOC type (i.e., gateway course status)?

c.
MOOC persistence? How do those relationships vary by perceived level of relative course difficulty?

d.
Perceived MOOC-related educational advancement and learning outcomes? How do those relationships vary by perceived level of relative course difficulty?

2. Review of literature
2.1. MOOC participants: who MOOCs?
In theory, MOOC participants should be more heterogeneous than students in formal education (DeBoer, Ho, Stump, & Breslow, 2014). Generally, MOOCs have unrestricted enrollments and they lack selection mechanisms relative to academic and motivational factors. These “open” qualities should contribute to diverse, virtual classrooms that better mimic the larger population and should include a wide range of traditionally underserved students. However, research on MOOCs and their participants to date suggests that the majority of participants are already well-educated and employed (Christensen et al., 2013, Dillahunt et al., 2014, Laurillard, 2014, Zhenghao et al., 2015). Similar to previous findings, one of the most recent surveys on MOOCs and their participants in 32 courses provided by Coursera found that 83% of survey respondents held a postsecondary degree (two- or four-year) and 58% were employed full time (Zhenghao et al., 2015). This body of research also draws attention to the relatively high proportion of male, degree-holding, 26–35 year-old professionals taking MOOCs (Ho et al., 2014). Although MOOC participants do demonstrate diverse background characteristics (e.g., in one MOOC, participants were registered from 194 different countries, see DeBoer et al., 2014), the findings reveal the predominance of particular users and have led many to conclude that MOOCs are not meeting the goal of providing access to underserved and underrepresented populations (e.g., Emanuel, 2013). Rather than addressing or ameliorating problems of access to knowledge and institutions of higher education for those who need it most (e.g., individuals who are low-income and/or racial/ethnic minorities), Laurillard (2014) argues: “…the problem MOOCs succeed in solving is: To provide free university teaching for highly qualified professionals” (para. 4). Though existing studies offer important insights and starting points, research on MOOCs and their participants is still relatively thin, and research on MOOCs and underserved populations [low-socioeconomic status (SES) and/or racial/ethnic minority] in particular is even thinner (Dillahunt et al., 2014).

Exceptions include a study by Schmid, Manturuk, Simpkins, Goldwasser, and Whitfield (2015) on the “educationally underserved.” This research suggests that particular underserved populations (participants under 18, older than 65, and those who reportedly had limited access to higher education) were provided access they otherwise would not have had. While providing an important contribution to questions relative to access and democratization, the authors found only “some evidence to suggest that MOOCs attract students who were underserved in traditional classroom settings” (p. 119). In fact, 35% of participants who reported having limited access also reported having a Bachelor's degree and 32% reported having a Master's degree. Reasons for limited access included family and work commitments and disabilities or medical problems. Although these findings make an important contribution to knowledge surrounding questions of access, the term “nontraditional” as used within Schmid et al.'s study is not representative of all traditionally underserved students. In other words, though the populations highlighted are certainly underrepresented in higher education, these participants are not necessarily “at risk” or “financially disadvantaged”—populations that arguably need access to higher education the most.

In a different study, researchers examined participants in nine Harvard MOOCs through third-party census data to attain greater knowledge of participants' socioeconomic status (SES)—data MOOCs do not currently collect in order to maximize enrollment through a fast and accessible registration process (Hansen & Reich, 2015). Because national measures of SES for younger students (under the age of 18) include family income and parental education and occupation, the authors examined neighborhood affluence and parental education. Findings indicate that participants within the nine MOOCs lived in higher income neighborhoods and had parents with higher levels of education than the national median. A third study focusing on underserved populations examined the motivations, enrollment, engagement, and performance of financially disadvantaged MOOC participants (those who could not afford formal higher education) in six University of Michigan MOOCs offered through Coursera (Dillahunt et al., 2014). Findings indicate that financially disadvantaged participants (about 9% of the survey sample) were significantly underrepresented in the six MOOCs and were also less likely to complete the courses; however, research on MOOCs overall is largely focused on particular demographics such as age, gender, employment status, and geographic location and largely ignores race/ethnicity and socioeconomic status (Kasunic et al., 2015).

Also, very little is known about relationships between learner characteristics and types of courses taken, including those that are more advanced (have prerequisites), those that are introductory (e.g., courses that may be introductory but still require a certain skill level and/or background knowledge), and those that are considered “gateway” courses (courses that offer foundational knowledge and act as entry points to core disciplines/majors). As one of very few studies to focus on a gateway MOOC, Jiang, Williams, Warschauer, He, and O′Dowd (2014) examined the enrollment and performance of participants in one, pre-college biology course at the University of California at Irvine (UCI) offered through Coursera. Similar to other large-enrollment formal gateway courses, this particular course is noted as “a major obstacle for underrepresented minority students” (p. 3) at the university. The course was composed of the general population (participants not attending UCI), incoming UCI students who identified Biological Science as their first choice major (but did not meet SAT math score requirements to qualify) and incoming UCI students who did meet the requirements for entry into the Biological Science major. Incoming students categorized as having low preparation (did not meet SAT major requirements) were offered an incentive, while incoming students who already met the requirements were not. Interestingly, UCI students entering with low math SAT scores outperformed students who already had been deemed ready to enter the major. The authors argue that MOOCs offering no-cost incentives may better reach and prepare underserved students for college-level courses. Given what we know to date, this particular study is promising in terms of how universities and MOOC instructors, designers, and providers might better reach underserved students through preparatory and/or gateway MOOCs. However, more research is needed on course type/level, and the evidence concerning MOOC participant motivations, and underrepresented MOOC participants in particular, is also limited in scope.

2.2. Motivations: why MOOC?
Christensen et al. (2013) argue that “there are two main reasons survey respondents cite for enrolling in a MOOC course: advancing a current job and curiosity” (p. 5); however, others reveal a wide variety of participant motivations for enrolling in MOOCs (Breslow et al., 2013, Koller et al., 2013), including the desire to obtain knowledge and skills, face a personal challenge (Breslow et al., 2013), seek fun and enjoyment, overcome the geographic isolation from formal learning institutions and financial barriers to formal education, supplement college work/classes (Belanger & Thorton, 2013), and connect with people (Zheng, Rossen, Shih, & Carroll, 2015). Despite this diversity in motivations, it is largely unclear who takes MOOCs for educational advancement (e.g., to gain entry to formal education). One exception includes a study by Zhenghao et al. (2015), which reported only 28% of participants were primarily motivated by educational advancement (versus 52% who were motivated by career advancement). This is not surprising, given what we know about who takes MOOCs (majority of users already possess degree in higher education and are employed full-time); however, we might also expect this percentage to be higher if MOOCs are in fact reaching underserved populations who have a vested interest in accessing higher education. Because we know so little about MOOC participants from traditionally underserved populations—those who potentially stand to gain the most from free, accessible higher education—we also know very little about what motivates these students to take MOOCs. In one previously mentioned study by Dillahunt et al. (2014), the authors found that those who reported the inability to afford formal education were twice as likely as the comparison group (those who did not report the inability to afford formal education) to report being motivated by the opportunity to decide whether to take a formal university course on the topic. This study suggests that educational advancement is indeed an important motivator for underserved populations (in this case, those who cannot afford higher education), those who are largely overlooked by existing research.

MOOC participants, including those from educationally underserved backgrounds, also report taking MOOCs to supplement other courses they are taking (Belanger and Thorton, 2013, Schmid et al., 2015), a reason akin to educational advancement. In a recent qualitative study by Zheng et al. (2015), the authors identified “course complement” as a primary motivator among MOOC participants. In depth interviews with MOOC participants revealed two factors underlying this motivation: to keep up with fast-paced, credit-bearing courses and to broaden the scope of a credit-bearing course in order to learn more and better meet a student's needs.

Further, incentives such as a financial investment for a certificate of completion, have also been found to motivate the general participant population to join, persist, and complete MOOCs. In a study on student retention, Koller et al. (2013) report that completion rates are markedly higher for students who pay ($30–$100) for and receive a more formal credential upon completion. Phan, McNeil, and Robin (2016) reiterate the significance of a formal certificate on motivation and performance in their study of one Coursera MOOC and Zheng et al. (2015) find that MOOC participants were motivated by credentials they believed would impress employers. Jiang et al. (2014) also support findings on the motivational power of external incentives in their study on the enrollment and performance of participants in one pre-college biology course at the University at California at Irvine (UCI). In this study, incoming students categorized as having low preparation and who did not meet the minimum SAT requirements for acceptance into the Biological Science major were offered early transfer to the major if they completed the gateway MOOC and two additional in-person courses as an incentive. Results indicate that UCI students (both those who met criteria and those who did) had a much higher rate of completion than non-UCI students, including those who were considered lower performing.

2.3. MOOC outcomes: who persists, completes and benefits from MOOCs?
Consistent findings have revealed that MOOC completion rates hover between 5% and 12% (Ho et al., 2014, Jordan, 2014, Koller et al., 2013, Liyanagunawardena et al., 2013, Perna et al., 2014, Zhenghao et al., 2015) and drop out rates have been recorded as high as 90% (Hew & Cheung, 2014). Overall, existing research suggests that outcomes will likely vary as a function of: 1) participant characteristics; and 2) course characteristics. Existing research on MOOCs finds a significant relationship between particular learner characteristics and MOOC retention and completion. Morris, Hotchkiss, and Swinnerton's (2015) study of participants in five FutureLearn MOOCs found that those who are older (age), those with prior online learning experience, greater educational attainment, and those who are not working (employment status), are more likely to complete MOOCs.

Relative to traditionally underrepresented students, Firmin, Schiorring, Whitmer, Willett, and Sujitparapitaya (2013) studied participants who failed to pass three formal gateway math courses (Remedial Algebra, Introduction to College-Level Algebra, and Introduction to College-Level Statistics). Participants were offered the opportunity to re-take these courses in “MOOC-like” form for a $150 fee. Findings indicate that the completion rate for these “at-risk” students was worse than the rate for the original face-to-face gateway courses. This supports the finding that “males, African-American students, and students with lower levels of academic preparation—had much more difficulty in online courses than they did in face-to-face courses” (Jaggars, 2014, Student Success in Online Coursework section, para. 4). Importantly, Jaggars further concludes that the performance gaps that underserved students experience in face-to-face classrooms become even greater in online courses. This does not bode well for underserved students who do take MOOCs. However, a more recent study on one introductory physics MOOC challenges this prior research and indicates that within this particular MOOC, learning outcomes were roughly equivalent across cohorts differentiated by level of preparation, demonstration of “low” or “high” ability, and level of education (Colvin et al., 2014).

However, measuring success in MOOCs via conventional methods can be problematic given their unique structure and the diversity of participants. For example, course design and duration, among other factors, can be vastly different (e.g., some MOOCs are designed to be self-paced whereas others include schedules and deadlines). Additionally, measuring educational success via completion rates does not account for participants who meet their learning goals by engaging in only part of a MOOC (Kizilcec, Piech, & Schneider, 2013). In case of point, Kizilcec et al. (2013) offer four categories of completion based upon what they identify as four engagement trajectories: auditing, completing, disengaging, and sampling. In other words, in addition to diverse backgrounds, MOOC participants demonstrate a wide range of intentions, a factor that has prompted the reoperationalization and reconceptualization of traditional education variables in the context of MOOCs (DeBoer et al., 2014). Importantly, Koller et al. (2013) note the distinction between motivation and intention across 86 Coursera courses. By re-categorizing MOOC participants into “browsers” and “committed learners,” the authors reveal very different goals and motivators for taking and completing MOOCs. Similarly, in examining participants' motivations to complete one nanotechnology MOOC, Barak, Watted, and Haick (2016) also complicate simplistic notions of “completers” that better reflect these diverse motivations. In doing so, the authors identified five types of MOOC completers based upon their motivation to learn: problem-solvers, networkers, benefactors, innovation-seekers, and complementary-learners. Completers were motivated by a desire to problem-solve, socially engage with others who hold similar interests, stay up-to-date on the field, and share knowledge in order to benefit others. Further, measuring success through completion may obfuscate the full range of benefits that fall outside this narrow conception (Haggard, 2013, Ho et al., 2014, Whitmer et al., 2015). Relatedly, Perna et al. (2014) have sought to reconceptualize outcomes based upon MOOC participant progression through 16 Coursera courses.

These reconceptualizions also lead us to question what is meant by “success” in MOOCs. For example, Breslow et al. (2013) define success, in part, as achievement or grades earned. Although the authors found only a marginal association between highest degree earned and achievement, they found a strong correlation between whether or not the participant worked offline with someone else on the course material and achievement (higher grades). This indirectly supports other research that suggests that because of the open nature of MOOCs and individuals' limited interaction within them, these courses require greater levels of self-regulated learning, which demands ease of adjustment to new learning contexts and knowledge of when and how to engage (Littlejohn, Hood, Milligan, & Mustain, 2016). In addition to generic skills such as the ability to self-regulate learning, one's prior knowledge (content knowledge) is also an important predictor of success in MOOCs (Kennedy, Coffrin, de Barba, & Corrin, 2015). Milligan, Margaryan, and Littlejohn (2013) also found that confidence, prior experience and motivation affected participant engagement—a predictor of retention and completion in MOOCs. However, motivation in particular, along with one's perceived confidence, “may underpin the development and use of digital and participatory literacy skills” (Terras & Ramsay, 2015, p. 477), which can strongly influence student persistence and completion (Barak et al., 2016, Wang and Baker, 2015). Because the primary focus of the research on MOOCs is the completers, we not only know little about the experiences and perceptions of those who leave, but even less about why participants leave or do not “succeed,” including factors related to course characteristics. However, and as we argue herein, research on completers remains limited, as it has largely avoided the disaggregation of data by particular demographic factors (socioeconomic status, race/ethnicity).

Among those who complete MOOCs, again, the majority of whom are largely educated (83% held at least a bachelor's degree) and are employed full time (58%), many experience benefits. Research by Zhenghao et al. (2015) on learners who completed a Coursera MOOC suggests that the majority of completers experience some kind of career (87%) or educational (88%) benefit. For example, 33% of completers whose primary motivation for taking a MOOC was to receive career benefits reported having received a tangible benefit as a result of taking a MOOC. Tangible benefits include receiving a raise, finding a new job, starting a business or receiving a promotion. Among those who listed career benefits as their primary motivator, 62% reported having enhanced their skills for a job and 43% reported having improved their candidacy for a job, both of which are considered intangible benefits. Overall, this research confirms that those who are already educated and employed (in developed countries) are more likely to report both intangible and tangible career benefits; however, and most notably, the authors also found that participants of lower socioeconomic status with less education are about as likely to report tangible career benefits in developed countries. Among those who are motivated by educational advancement (28% of completers), 88% reported an intangible or tangible educational benefit. For example, 87% reported having received an intangible benefit (gaining knowledge in a particular field, helping one to decide what to study, refreshing knowledge before going back to school, improving admissions applications, preparation for an exam or helping one to identify where to apply to college/university), while 18% percent reported a tangible benefit (earning credit toward degree, completing prerequisite for program). Importantly, the authors found that participants with lower socioeconomic status are more likely to be education seekers. Although the authors conclude that “economically and academically disadvantaged populations are taking particular advantage of MOOCs” (Zhenghao et al., 2015, Overall Findings section, para. 1), this is more the case within developing countries. And though important and encouraging findings on a global scale, this does not seem to be the case within developed countries such as the United States.

In one of few studies to investigate the relationship between course characteristics and outcomes, Do, Chen, Brandman, and Koller (2013) found a relationship between final exam performance and formative assessment that allowed for multiple attempts in 28 Coursera courses. In this research, the authors found a significant positive correlation between improvements on formative assessment scores and final exam performance. This research offers important insights for MOOC educators; however, this study does not extend findings to include which MOOC participants (learner characteristics) benefit most from this structure (mastery learning). In their qualitative study, Zheng et al. (2015) found that because the structure of MOOCs allows learners to access material at any time, including after the conclusion of the course, many did not feel pressure to complete the course. Even many who intended to complete the course in their spare time did not. Zheng et al. (2015) also found that participants felt as though the structure of MOOCs did not provide a sense of community. As the authors note, “Existing MOOC platforms do not provide features to promote community awareness” (p. 1890). Other course characteristics that affected retention included long wait times between when participants register and when the course officially opens.

Based upon our review, the majority of extant empirical literature on MOOCs is limited in scope to one or two MOOCs or to several courses with one provider. Additionally, very few studies have fully examined the representation of socio-economically disadvantaged and racial/ethnic minority students, others, in MOOCs in general, and in gateway MOOCs in particular. Further, the current literature leaves room for improvement not only in breadth but also in quality, rigor and novelty, as evidenced by non-empirical or ambiguous aims, largely descriptive and sometimes poorly articulated methods, and overlap in data reported across some articles. Our study seeks to broaden this research base by working across many courses and providers and by examining an extended suite of MOOC participant characteristics. At the same time, we pose questions concerning the degree to which different socio-demographics of MOOC participants are motivated by educational advancement specifically, and how socio-demographic characteristics relate to MOOC course completion and outcomes. Given challenges faced by traditionally underserved populations in higher educational settings generally, in our study we also consider the perceived level of MOOC difficulty. In doing so, this research aims to contribute to larger, outstanding questions about who is taking MOOCs and how they enhance access and educational opportunity.

3. Methods
The present paper's data were collected during a large-scale, mixed-methods study concerning the role of MOOCs in promoting access to higher education and knowledge. This larger study involved: a) an electronic survey of past MOOC participants; b) targeted, in-depth interviews with a group of survey participants who were either taking or had taken MOOCs and were first-generation college students; as well as c) participant observations of three “gateway” MOOCs. This paper relies on this larger study's survey data only, as these data were most appropriate to address these specific research questions. As our research questions pertained to population characteristics and relationships, we employed quantitative analyses of these survey data.

3.1. Participants
Given the proprietary, silo-like nature of extant MOOC data, and the fragmentation of the MOOC literature base, this study's target population is deliberately broad, consisting of MOOC participants in the United States from 2008 to 2015 (including both completers and non-completers). Recruitment of survey participants relied upon three mechanisms. First, we identified MOOC instructors from publicly available information from major MOOC providers (e.g., Coursera, Udacity, edX), and contacted each instructor to request that they disseminate a link to our survey to their past participants. Second, we disseminated a link to our survey via MOOC-related web and social media sites, discussion boards/forums, and listservs curated by project graduate assistants. Third, we requested that participants distribute the link to the survey to other members of the target population after survey completion.

In order to maximize the survey sample size, we recruited participants over the course of approximately seven months. All survey participants were able to provide their email address to enter a drawing for incentives (Göritz, 2006), specifically Apple TVs and GiftCertificates.com gift certificates. In total, the analytic sample comprised 2634 U.S. MOOC participants from all 50 states who participated in their first MOOC between 2008 and 2015 and provided informed consent for study participation. Sample members ranged in age from 18 to 96, with a mean age of 43.88 (SD = 15.28). The analytic sample reflected participants in at least 398 different MOOCs concerning various topics, which were affiliated with at least 129 different universities (e.g., Harvard University), and were offered by at least 22 providers (e.g., Coursera). About 69% of the sample completed the MOOC about which they responded in the three years prior to this writing (2013, 2014, or 2015). Other sample characteristics are described in the proceeding results section in relation to our first research question.

In deriving the final analytic sample, we filtered out individuals who did not indicate they lived in the U.S. when they participated in their first MOOC because the larger study did not limit eligibility to U.S. MOOC participants. Furthermore, we excluded from analysis individuals who indicated that: 1) they had never taken a MOOC (or taken 0 MOOCs in a subsequent question); 2) they registered for the MOOC but never logged in; 3) they did not participate in course activities; 4) their first (or only MOOC) had not yet already ended; and 5) they registered for the MOOC after it had started. In addition, if respondents indicated “Don't know” or “Don't remember” to any of these validation or filter questions, they were excluded from analysis.

3.2. Instrumentation
An electronic survey comprising close- and open-ended item types and administered via Qualtrics (2015) survey software provided data pertaining to all research questions. The survey questions centered on several key domains: 1) MOOC participant characteristics; 2) MOOC participant motivations; 3) MOOC course characteristics and experiences; and 4) MOOC participant persistence and perceived outcomes. If a participant had enrolled in multiple MOOCs (91.8%), they were instructed at the beginning and throughout the survey to respond relative to their first MOOC and their characteristics at that point in time; about 8% of the sample had only completed one MOOC, about 62% had taken between two and nine MOOCs, and about 30% had taken 10 or more MOOCs. We chose to require participants to respond concerning their first MOOC for comparability purposes; that is, all respondents responded concerning their first-ever MOOC. Had we instructed respondents to select their most memorable or most recent MOOC, the data would have been temporally incomparable; that is, some respondents would have responded concerning their first MOOC, some concerning their most recent, and some concerning some other MOOC. The survey also employed conditional branching wherein inappropriate questions were not administered to some participants based on their responses. For example, for individuals who never logged into or did not “participate” in the MOOC, questions related to course persistence and perceived outcomes were not administered.

Several steps were taken to support survey data reliability and validity (Groves et al., 2011). First, the content of the survey was reviewed by five educational/instructional technologists, as well as instructional technology graduate students, for clarity and in order to minimize response error variance and bias. Second, to support the validity of survey question-based inferences, the survey provided definitions for esoteric terminology (e.g., “massive open online course”). Third, in light of concerns about the length of time elapsed since some respondents' first MOOC, respondents were offered “Don't know” and “Don't remember” options for close-ended questions or were asked to write “Don't remember” or “Don't know” in response to open-ended questions as needed. In addition to mitigating the introduction of improper survey response variance by forcing respondents to answer questions for which they did not know or recall the answer, these questions also helped us explain some missing data. In the sections that follow, we describe specific survey questions by domain. The full survey can be accessed here: https://niuits-my.sharepoint.com/personal/a1725232_mail_niu_edu/_layouts/15/guestaccess.aspx?guestaccesstoken=hkcx4IoSlRhr7KWSn8qgDLouuIAaw6hzjv%2buihQiyvs%3d&docid=0ad409614805e412fa59029e91e022831&rev=1

3.2.1. MOOC participant characteristics
The initial section of the survey collected data on participants' characteristics at the time when they first registered for a MOOC via close-ended survey questions. Relative to the present study, measured participant characteristics included age, race/ethnicity, individual socioeconomic status (i.e., education, occupation, and income), and current employment status. The educational attainment question was aligned with U.S. Census Bureau (2010) survey practices. The occupation question was aligned with the International Standard Classification of Occupations' (ISCO-08) 10 major groups (e.g., managers, clerical support workers; International Labour Organization, 2007). The income question asked respondents to select their “individual annual gross income (before taxes or deductions)” from a list of 13 categories (e.g., “Less than $10,000,” “$60,000–$69,999,” through “$150,000 or more”).

3.2.2. MOOC participant motivations
Participants reported via rating scale items the degree to which their participation in the MOOC was motivated by each of 16 reasons, broadly organized into four domains identified in the MOOC literature: 1) educational advancement [e.g., “gaining entry to a postsecondary institution (college or university)”]; 2) professional advancement (e.g., “increasing compensation/salary”); 3) personal interest and development (e.g., “interest in the topic”); and 4) opportunities for interaction (e.g., “interaction with peers”). In this paper, we focus on only the seven items in the educational advancement motivation category.

3.2.3. MOOC course characteristics and experiences
Each survey participant also reported data concerning the characteristics of the first MOOC course in which he/she participated—responses to a sub-set of which were analyzed in this paper. For example, via a close-ended questions in particular, respondents indicated the MOOC provider (e.g., Coursera) through which the course was offered, if applicable. For the question concerning MOOC provider, respondents were afforded an “Other (please specify)” option with a text box in which to provide the name of a non-listed provider.

In another close-ended question, the respondents indicated the MOOC's relative course difficulty. We conceptualized relative course difficulty as the perceived difficulty of a MOOC relative to one's current level of knowledge (e.g., very easy, appropriate level of difficulty, very difficult). We opted to use perceived relative difficulty as an indicator of course difficulty (and incorporate consideration of course difficulty more generally in our analyses) given 1) the absence of objective indicators of MOOC course difficulty and 2) the demonstrated diversity of MOOC participants in terms of initial levels of MOOC course topical knowledge.

Via open-ended questions, the respondents also indicated the name of the course and, if applicable, its affiliated institution(s). Finally, this section of the survey also elicited data concerning the respondents' level of participation in the course (e.g., “Did you access (login to) the massive open online course at least once?”) for sample filtering purposes.

3.2.4. MOOC persistence and perceived outcomes
The final section of the survey collected evidence of participants' course persistence (completion) and perceived course outcomes. For persistence, participants were asked a dichotomous question: “Did you stop participating in the massive open online course (MOOC) before it ended?” Because of the dearth of findings concerning MOOC outcomes in the literature, participants' outcomes were multiply operationalized in this study. First, to elicit evidence of perceived MOOC course participation-related educational advancement outcomes, participants were asked a dichotomous question concerning their perceived attainment of each of seven educational advancement outcomes (e.g., “Gaining entry to a postsecondary (college or university) degree program (e.g., undergraduate major, or M.B.A. program”). The educational advancement outcomes paralleled the educational advancement motivations for which evidence was gathered earlier in the survey.

Second, the survey elicited evidence of perceived learning with a set of 13 rating scale items with an agreement rating scale response format. Six of these items were developed in 1994 by Hiltz (e.g., “I learned to interrelate the important issues in the course material,” “I gained a good understanding of the basic concepts of the material,” and “I learned to identify the central issues of the course”). These six items were supplemented by seven additional researcher-developed items to elicit evidence of perceived learning outcomes (e.g., “I learned a lot during the course,” “The course increased my knowledge,” and “The course increased my skills”).

3.2.5. Other data
On the basis of valid course titles and their descriptions, a variable was constructed to characterize whether known courses were of a “gateway” nature. In classifying such courses, we relied on the John N. Gardner Institute (2016) definition of a gateway course: a course that is foundational in nature, high-risk and typically has high enrollment. These courses act as an entry point or are required for further study in advanced courses within a major. Our classification was not simply dichotomous in nature, but instead we differentiated between gateway courses in English/language arts, mathematics and science. For research question one, we obtained known U.S. population parameters and estimates related to race/ethnicity, highest level of education, occupation, and income from U.S. federal and international organizations for comparison purpose, namely the International Labour Organization (2015) and the U. S. Census Bureau, 2014a, U.S. Census Bureau, 2014b, U. S. Census Bureau, 2015. Where possible, we also drew comparisons between our data and publicly released data from the major MOOC provider edX (MITx & HarvardX, 2014).

3.3. Analytic approach
3.3.1. Data cleaning and missing data analysis
Prior to analysis, it was necessary to manually clean open-ended responses concerning course titles, affiliated institutions and providers in order to assign them unique identification numbers for analytic purposes. For the provider question, cleaning also involved classifying “Other (please specify)” responses into existing categories (e.g., classifying MITx into edX category) or creating new provider categories (e.g., Canvas Network). Valid course titles, institutions and providers were determinable for 69.0%, 78.7%, and 97.3% of the full analytic sample. Next, all “Don't know” and “Don't remember” responses were set missing, as were others that were indeterminable, unclassifiable or irrelevant for analytic purposes (e.g., responses of “independent” MOOCs not associated with a particular provider, responses of “homemaker” or “retired” for occupation, and multiple institutions with which a MOOC was affiliated).

We then investigated the scope and nature of missing data using the SPSS Missing Values Analysis procedure (IBM Corporation, 2012). Across the variables required for the present study, missing data ranged from 0.3 to 31.0%. Little's (1988) formal test for whether the data were Missing Completely at Random (MCAS) was significant, χ2(1717) = 2576.47, indicating that the data were not MCAS. In turn, a sophisticated approach to handling missing data was needed. These missing data analyses also investigated the degree of missing data across the dataset for individual cases, finding that no case was missing all data needed for the analyses.

Subsequently, we used multiple stochastic imputation procedures to handle missing data via SPSS. Multiple imputation improves the efficiency of estimates, preserves power, mitigates bias, and maintains the same variance as the original data (Allison, 2002; IBM IBM Corporation, 2012, Little and Rubin, 1987). Multiple imputation was conducted on all variables in the dataset, including nominal-, ordinal-, and ratio-scaled variables. The specific approach employed for all datasets was fully conditional specification in which each variable is imputed by modeling it as a function of all other available variables. For variables that were to be used to construct composite variables (e.g., the 13 perceived learning outcome items), we imputed item-level data. We did not impute course, institution or provider variables because the non-missing data in the dataset did not comprise all possible categories for these variables (e.g., all possible MOOCs).

For multiple imputation procedure, we imposed some constraints in order to prevent the imputation of impossible or implausible values. We specified a minimum age of 18, a minimum and maximum that was consistent with each corresponding rating scale for all continuous variables. Imputation was also constrained to the nearest integer, which is consistent with the nature of non-missing data in the dataset. Given the complexity of the missing data model, the maximum number of parameters was set to 1000, the maximum number of case draws was increased from 50 to 100, and the maximum number of parameter draws was increased from 2 to 4.

3.3.2. Psychometric analysis
\We also investigated the reliability and internal structure (validity) of scores derived from four, multi-item scales intended to represent: 1) educational advancement motivations; 2) perceived educational advancement outcomes; 3) perceived learning outcomes; and 4) individual socio-economic status. We examined score reliability using KR-20 and Cronbach's alpha and internal structure using common factor analysis1 and Rasch analysis techniques. The reliability and validity evidence reported here is based on the first multiply imputed dataset, but results for the other four datasets were highly similar. After verifying the adequacy of the internal structure and reliability of scores derived from the educational advancement motivation, educational advancement outcome, and perceived learning outcome measures, composites variables were constructed by taking the means of the respective 7, 7, and 13 items. Individual socioeconomic status scale scores were estimated using the Rasch model. Evidence pertaining to score internal structure and reliability is reported in the next sections.

3.3.2.1. Educational advancement motivations
Inspection of univariate item distributions suggested that that the multivariate normality assumption would be untenable for this and subsequent factor analyses, thus principal axis factoring was used (Tabachnick & Fidell, 2013). Exploratory common factor analysis revealed a single dominant latent factor underlying these 7 items; the factor had an eigenvalue of 4.38 and explained 65.51% of the common item variance. Only one factor had an eigenvalue larger than one and inspection of the scree plot using the elbow rule strongly suggested the presence of a single, dominant factor. For this factor analysis, the Kaiser-Meyer-Olkin measure of sampling adequacy (0.90) was acceptable (Kaiser, 1974), and Barlett's sphericity test was significant, χ2(21, N = 2634) = 14827.68, p < 0.001. Extracted communalities ranged from 0.28 to 0.84 and factor loadings ranged from 0.53 (for “supplementing learning in a non-massive open online course in which you were enrolled”) to 0.92 [for “gaining entry to a particular postsecondary institution (college or university)”]. Internal consistency reliability (α) was 0.90.

3.3.2.2. Perceived educational advancement outcomes
Exploratory common factor analysis (principal axis factoring) revealed a single dominant latent factor underlying these 7 items; the factor had an eigenvalue of 2.77 and explained 39.60%of the common item variance. A second factor had an eigenvalue of 1.01, inspection of the scree plot using the elbow rule strongly suggested the presence of a single, dominant factor. For this factor analysis, the Kaiser-Meyer-Olkin measure of sampling adequacy (0.82) was acceptable (Kaiser, 1974), and Barlett's sphericity test was significant, χ2(21, N = 2634) = 5400.50, p < 0.001. Extracted communalities ranged from 0.30 to 0.77 and factor loadings ranged from 0.48 (for “Supplemented learning in a non-massive open online course in which you were enrolled”) to 0.74 [for “Gained entry to a postsecondary (college or university) degree program (e.g., undergraduate major, or M.B.A. program)”]. Internal consistency reliability (KR-20) was 0.80.

3.3.2.3. Perceived learning outcomes
Exploratory common factor analysis (principal axis factoring) revealed a single dominant latent factor underlying these 13 items; the factor had an eigenvalue of 9.01 and explained 69.29% of the common item variance. Only one factor had an eigenvalue larger than one and inspection of the scree plot using the elbow rule strongly suggested the presence of a single, dominant factor. For this factor analysis, the Kaiser-Meyer-Olkin measure of sampling adequacy (0.97) was acceptable (Kaiser, 1974), and Barlett's sphericity test was significant, χ2(78, N = 2634) = 36994.68, p < 0.001. Extracted communalities ranged from 0.44 to 0.83 and factor loadings ranged from 0.66 (for “the course changed how I think about the subject matter”) to 0.91 (for “I have a deeper understanding of the course material after taking the course”). Internal consistency reliability (α) was 0.97.

3.3.2.4. Individual socioeconomic status
Given the diverse scales of the items it comprised, the measurement model used to estimate individual-level socioeconomic status measure was the Rasch partial credit model (Masters, 1982). Prior to Rasch analysis, we excluded any invalid responses beyond “don't know” or “don't remember” (e.g., “prefer not to say” for income, “retired” and “homemaker” for occupation). In terms of model fit, person and item separation were 1.54 and 50.52 respectively, and person and item reliability were respectively 0.70 and 1.00. Item-measure correlations were also acceptably high, ranging from 0.52 to 0.85; and infit mean square item fit statistics were generally within acceptable ranges (0.55 for income, 1.04 for occupation, and 1.20 for education; Bond & Fox, 2007).

3.3.3. Derived data and transformations
Prior to the regression analyses described later, we dummy coded categorical variables (e.g., race/ethnicity, native English language status, sex, completion intention) and standardized continuous variables (e.g., perceived relative course difficulty). For the non-dichotomous categorical variable of race, the reference group was White. For employment status, we created a single dummy variable representing whether the individual was employed at all versus not (rather than differentiating between full- and part-time employment). Similarly, for gateway course status, a single variable was created to represent whether the course was a gateway course in general (versus not), rather than creating separate dummy variables for English, mathematics, and science gateway courses. An alternative treatment of the gateway variable—separate dummy variables for English, mathematics, and science gateway courses with non-gateway course as the reference group—did not change the overall substantive results. Next, both continuous dependent and independent variables were standardized before regression analyses. Finally, interactions were computed as the product of the respective variables (i.e., relative level of difficulty was multiplied by each race/ethnicity dummy variable).

3.3.4. Descriptive and inferential statistical analysis
Data were analyzed using both descriptive and inferential methods, with analyses conducted separately with each multiply imputed dataset and then pooled (Little & Rubin, 1987). To address the first research question concerning the distribution of U.S. MOOC participants in terms of race/ethnicity, highest level of education, and occupation, we computed descriptive statistics and then employed chi-square goodness-of-fit tests to determine whether the distributions statistically diverged from the U.S. population at large. To address the second and third research questions calling for description of U.S. MOOC participants' motivations and outcomes, we employed descriptive statistics, either means and standard deviations or counts and percentages depending on the nature of the variables.

To address the remaining questions, we included only cases for which the MOOC course was identifiable since these questions invoked course-level variables. For the fifth research question concerning the relationship between MOOC participant characteristics and course type (i.e., whether the course was of a gateway nature), we used binary logistic regression. For the fourth, sixth, and seventh questions concerning predictors of educational advancement motivations, course completion, and educational advancement and general outcomes, we estimated multi-level regression models (Raudenbush & Bryk, 2002). Preliminary 2-, 3-, and 4-level, unconditional, random-effects, multi-level analyses conducted with cases for which courses, institutions, and providers were determinable (individuals within courses within institutions within providers and nesting variations thereof) suggested that all dependent variables were best and most parsimoniously modeled at two levels: individuals within courses. For the persistence model, we used hierarchical generalized linear modeling (population-average model) because the dependent variable was not continuous but instead binary (Raudenbush & Bryk).

For the research question examining the factors related to educational advancement motivations, the regressor (independent) variables included key participant characteristics (age, employment status, race, ethnicity, socioeconomic status, and native language), prior knowledge, and whether or not the course was a gateway. The models used to examine potential predictors of persistence and outcomes (research questions four, six, and seven) were identical, with the exception that some additional variables were also included: educational advancement motivations; course intention completion; and relative difficulty. The motivation model included a fewer number of variables because the research question concerned how educational advancement motivation was distributed among participants. On the other hand, understanding persistence and outcomes required consideration of additional variables, beyond participant characteristics such as relative course difficulty and motivational factors.

Models were built in a successive fashion, with unconditional models estimated first, then level-1 predictors added (main effects then interactions), and then the level-2 variable added. With the exception of course type (i.e., gateway), all predictors were entered at level-1, and interaction variables were excluded if they were not significant in formulating the final model due to the potential for collinearity problems. Preliminary analyses suggested that cluster sizes were insufficient to estimate reliably random effects for slopes, thus only the intercept was allowed to vary randomly across level-2 units, but future work should investigate cluster-to-cluster slope variation. All variables were uncentered because they were already standardized; standardizing the continuous variables allowed us to interpret results in terms of their practical significance and in relative terms. Finally, we computed proportions of variance explained by the model, and we computed descriptive statistics for and examined bivariate relationships among all variables in the regression analyses (which were limited to only the sub-set of cases for which course was known).

3.4. Limitations
Our findings should be interpreted in light of this study's key limitations. First, our non-experimental design necessarily precludes causal inferences. As such, it is possible that unmeasured variables confounded observed relationships. Second, while our study employed incentives to recruit participants, and while our sample is quite large and constitutive of many providers and courses, our non-probability sampling design may constrain the representativeness of our sample and thus the generalizability of our findings.

To examine the generalizability of our survey data, we compared select characteristics of our U.S. survey sample (e.g., gender, highest level of education) with those of participants in a publicly-released edX dataset (to our knowledge, the only publicly available estimates of MOOC participant characteristics disaggregated by country) (MITx & HarvardX, 2014). Indeed, the sex distribution in our sample differed from that estimated by edX released data concerning U.S. MOOC participants, χ2(1, N = 2634) = 526.67, p < 0.001, with females more likely to be in our sample (z = 18.64). As reported subsequently, our sample was also significantly less educated than that represented in the edX dataset. This difference may be explained by the nature of the courses reflected in our dataset compared to those reflected in the edX dataset.

With respect to external validity, however, it is notable that the majority of extant empirical MOOC literature is limited in scope to one or two MOOCs or a particular provider. Our study broadened this research base by strategically working across many MOOC providers and courses. We consider the collection of data around many different MOOCs and MOOC providers to be a major strength of the present work relative to prior scholarship. Nevertheless, future research should attempt to replicate our findings using stronger designs and representative samples.

Beyond these common methodological limitations, other limitations of this study relate specifically to our data and instrumentation. First, our design necessitated participant-reported data (including data used to operationalize MOOC impacts on participants' access to higher education and learning). While official or objective measures of some outcome variables are preferable in general, given the diversity of MOOCs and MOOC outcomes, it would be rather prohibitive to do so in the context of a study such as this. It would also be difficult to use objective measures such as achievement tests because no single cognitive learning construct could be defined across different courses. At the same time, differences in terms of course grading regimes (e.g., rigor) might confound comparisons.

Another potential problem is that survey respondents might not have remembered the information required to ensure an accurate response to some questions. This might be especially the case for participants who responded concerning early MOOCs (e.g., those in 2008), though it bears reiterating that the majority of our sample responded concerning MOOCs ending in 2013 or later. For this reason, survey items featured “Do not remember” response options to minimize error introduced by forced-choice items. While we asked specifically about participants' first MOOC for comparability purposes (i.e., all respondents responded concerning their first MOOC), we could have asked participants to report on their most memorable or most recent MOOC, which might have somewhat mitigated this limitation. Another potential limitation related to asking participants to respond concerning their first MOOC is that such MOOCs might be atypical relative to current MOOCs. Future research should, of course, attempt to replicate our findings through studies with a large swatch of MOOCs as they are being implemented (rather than retrospective studies of past MOOCs).

Next, while our study considered an expanded set of MOOC participant characteristics, and gateway course status in understanding the underserved populations' access to higher education via MOOCs, we did not address other course (or instructor) variables that might explain MOOC outcomes (e.g., course design, teaching presence). Future MOOC research should invoke such additional variables, and also address questions concerning mediators and moderators of the relationships observed here. In addition, our question concerning whether one's first MOOC formally ended may not have been appropriate in the context of some connectivist MOOCs (cMOOCs), given that these courses often remain open for participants. We assumed that respondents interpreted this question in terms of the whether their activity had largely slowed down or stopped in such courses. More generally, we were unable to differentiate among cMOOCs, xMOOCs and other forms of MOOCs due to data limitations.

4. Results
In this section, we present findings with respect to each research question:

4.1. Research question 1: what are the characteristics of U.S. MOOC participants (e.g., race/ethnicity, socioeconomic status)?
Table 1 presents the distribution of the sample with respect to race/ethnicity. Based on chi-square goodness-of-fit tests, statistically speaking the U.S. MOOC participant race distribution is distinguishable from that of the general U.S. population, χ2(5, N = 2634 = 608.97), p < 0.001 (U.S. Census Bureau, 2015). In particular, inspection of standardized residuals showed that Blacks/African Americans were the underrepresented (z = − 13.10), and Asians (z = 13.17), Native Hawaiians or Pacific Islanders (z = 13.39), and individuals who were two or more races (z = 9.18) were overrepresented, relative to their proportions in the general U.S. population. Similarly, Hispanic/Latino individuals were statistically underrepresented in MOOCs (z = − 12.31) in relation to their proportion in the U.S. population, χ2(1, N = 2634) = 182.04, p < 0.001.


Table 1. Estimates of U.S. MOOC participants' race/ethnicity (N = 2634).

Category	Count	%
Race	–	–
 White	2029	77.03
 Black or African American	103.4	3.93
 American Indian or Alaska Native	34.2	1.30
 Asian	295.2	11.21
 Native Hawaiian or Pacific Islander	36	1.37
 Two or more races	136.2	5.17
Ethnicity	–	–
 Hispanic/Latino	189.2	7.18
 Non-Hispanic/Latino	2444.8	92.82
Note. Frequencies pooled across the five multiply-imputed datasets.

Table 2 presents our sample-based estimates of the socio-economic characteristics of U.S. MOOC participants (i.e., highest level of education, occupation, and income). In terms of the distribution of U.S. MOOC participants' highest education level, our data imply that the distribution is significantly different from that of the 18 + U.S. population in general, χ2(6, N = 2634) = 6074.22, p < 0.001 (U.S. Census Bureau, 2014a). Individuals with less than a high school education (z = − 17.51), a high school diploma or equivalent (z = − 26.36), who have completed some college but no degree (z = − 11.79), and an associates degrees (z = − 9.96) were underrepresented in MOOCs, and individuals with a bachelor's (z = 16.50), master's (z = 52.22), and doctoral degree (z = 42.84) are overrepresented. We also found a significant difference between the U.S. MOOC participants' highest level of education distribution, as estimated by our study, and that derived from publicly-released data from major MOOC provider edX, χ2(4, N = 2299) = 1749.39, p < 0.001 (MITx & HarvardX, 2014). Individuals with less than a high school education (z = − 9.26) and individuals with only a high school education (z = − 24.48) were even more underrepresented in our data, and individuals with master's (z = 18.93) and doctoral degrees (z = 26.58) were even more overrepresented compared to the edX data. Given the nature of the released edX highest level of education data, we were only able to compare the distribution of individuals across five categories: less than high school diploma or equivalent, high school diploma or equivalent, bachelor's degree, master's degree, and doctoral degree.


Table 2. Estimates of U.S. MOOC Participants' socio-economic characteristics: highest level of education, occupation, and gross income (N = 2634).

Category	Count	Percent
Highest level of education	–	–
 Less than high school	9.2	0.35
 High school diploma or equivalent	44	1.67
 Some college, no degree	244.8	9.29
 Associate's degree	90.2	3.42
 Bachelor's degree	865	32.84
 Master's degree	931.8	35.38
 Doctoral degree	449	17.05
Occupation	–	–
 Managers	438.2	16.64
 Professionals (e.g., nurses, teachers)	1359.4	51.61
 Technicians and associate professionals	271.8	10.32
 Clerical support workers (e.g., secretaries)	130.4	4.95
 Service and sales workers (e.g., cashiers, waiters)	107.8	4.09
 Skills agricultural, forestry and fishery workers	71.4	2.71
 Craft and related trades workers	53	2.01
 Plant and machine operators, and assemblers	63.2	2.40
 Elementary occupations (e.g., construction workers, janitors)	82	3.11
 Armed forces occupations	56.8	2.16
Gross income	–	–
 Less than $10,000	348.4	13.23
 10,000–19,000	156.6	5.95
 20,000–29,000	214.2	8.13
 30,000–39,000	256.6	9.74
 40,000–49,000	247.4	9.39
 50,000–59,000	223.8	8.50
 60,000–69,000	202.8	7.70
 70,000–79,000	173.6	6.59
 80,000–89,000	130.8	4.97
 90,000–99,000	154.2	5.85
 100,000–119,000	180.4	6.85
 120,000–149,000	152.4	5.79
 150,000 or more	192.8	7.32
Note. Frequencies pooled across the five multiply-imputed datasets.

We also found that the occupational distribution of U.S. MOOC participants as gleaned by our study and the occupational characteristics of the U.S. population more generally were statistically different, χ2(6, N = 2495.2) = 3202.62, p < 0.001 (International Labour Organization, 2015). Professionals and technicians and associate professionals (z = 45.82) and skilled agricultural workers (z = 13.38) were statistically overrepresented in MOOCs, and clerical support workers (z = − 10.14), service and sales workers (z = − 22.76), craft and related trades workers, plant and machine operators and assemblers were underrepresented (z = − 17.28). The available 2013 comparison data (International Labour Organization, 2015) collapsed professionals, technicians and associate professionals, and craft and related trades workers, plant and machine operators and assemblers into the same categories, and did not include elementary or armed forces occupations, limiting our comparisons. Finally, while it was not possible for us to directly compare our study's individual gross income estimates for MOOC participants to more general population estimates, the median income category in our data is $50,000 to $59,999, which is higher than the U.S. median individual income (U.S. Census Bureau, 2014b).

4.2. Research question 2: to what extent are U.S. MOOC participants motivated by educational advancement (e.g., gaining entry to a postsecondary institution)?
Table 3 summarizes participants' responses concerning the degree to which they were motivated by each of seven educational advancement-related reasons for MOOC participation. Inspection of the means, which ranged between 1.35 and 1.78 (all between “Not at all” and “Slightly”), suggests that overall, participants were not motivated by educational advancement. Similarly, the percentages of respondents indicating that they were “Not at all” motivated by the seven mechanisms of educational advancement ranged from about 70.34 to 84.14%; however, the magnitudes of the standard deviations also suggest some heterogeneity among respondents.


Table 3. Descriptive statistics for educational advancement motivation items.

Educational advancement motivation item	M	SD
Gaining entry to a postsecondary institution (college or university)	1.40	0.98
Gaining entry to a particular postsecondary institution (a particular college or university)	1.35	0.91
Gaining entry to a postsecondary (college or university) degree program (e.g., undergraduate major, or M.B.A. program)	1.38	0.95
Earning postsecondary education (college or university) credit	1.37	0.94
Earning credit toward certification/licensure	1.48	1.06
Supplementing learning in a non-massive open online course in which you were enrolled	1.78	1.35
Assessing ability to succeed in postsecondary education (college or university)	1.57	1.12
Note. Descriptive statistics pooled across the five multiply-imputed datasets.

4.3. Research question 3: what are U.S. MOOC participants' perceived MOOC-related educational advancement (e.g., gaining entry to a postsecondary institution) and learning outcomes?
Table 4 summarizes the participants' responses to whether they experienced each of seven educational advancement outcomes as a function of MOOC course participation. The percentages of respondents indicating that they experienced particular educational advancement outcomes were rather small, ranging from 10.65 [for “Earned postsecondary education (college or university) credit”] to 21.91 (for “Supplemented learning in a non-massive open online course in which you were enrolled”).


Table 4. Percentage of respondents experiencing educational advancement outcomes.

Educational advancement outcome	Yes	No
Gained entry to a postsecondary institution (college or university)	15.78	84.22
Gained entry to a particular postsecondary institution (a particular college or university)	13.23	86.77
Gained entry to a postsecondary (college or university) degree program (e.g., undergraduate major, or M.B.A. program)	11.75	88.25
Earned postsecondary education (college or university) credit	10.65	89.35
Earned credit toward certification/licensure	11.19	88.81
Supplemented learning in a non-massive open online course in which you were enrolled	21.91	78.09
Assessed ability to succeed in postsecondary education (college or university)	19.19	80.81
Note. Frequencies pooled across the five, multiply-imputed datasets.

These relatively small estimates concerning the percentages of MOOC participants experiencing educational advancement outcomes notwithstanding, our findings concerning perceived learning outcomes are more promising. Means for the 13 perceived learning outcome items with an agreement rating scale ranged between 3.65 (between “Neither agree nor agree” and “Agree” and for the item “The course changed how I think about the subject matter”) and 4.14 (between “Agree” and “Strongly agree” and for the item “My knowledge of course content increased during the course”). Using one-sample t-tests, it was determined that each individual item mean was statistically different than three (ps < 0.001), which represented neutral perceptions concerning perceived learning outcomes; all of the t-tests were conducted with 2633 degrees of freedom and ts ranged from 31.90 to 64.92 across these tests. These findings suggest that, on the whole, MOOC participants are deriving benefits from MOOCs (i.e., increased knowledge and skills), but not necessarily advancing educationally from taking them.

4.4. Research question 4a: what is the relationship between U.S. MOOC participant characteristics and MOOC motivations for educational advancement?
Table 5 presents descriptive statistics for the sub-set of cases for which the course an individual participated in was determinable (N = 1818) and with which we addressed research questions four through seven. Bivariate correlations among all variables are available from the authors upon request, but are not included here due to space constraints. All but three inter-regressor correlations were < 0.35, which largely did not suggest the potential for multi-collinearity issues in the multi-level regression models. Larger correlations between some pairs of regressors—relative course difficulty with both its interaction with gender (r = 0.75) and its interaction with native English status (r = 0.93), and the interaction of relative course difficulty with gender and the interaction of relative course difficulty with native English status (r = 0.70)—were not actually included in the final model together.


Table 5. Descriptive statistics for regression-analytic sub-sample (N = 1818).

Variable	M	SD
Educational advancement motivation	.00	1.00
Completion	.71	.45
Perceived educational advancement outcomes	.04	1.02
Perceived learning outcomes	−.01	.99
Completion intention	.96	.19
SES	−.01	1.00
Employment status	.73	.44
Age	.00	1.00
Female	.55	.50
Black or African American	.04	.19
American Indian or Alaskan Native	.01	.11
Asian	.11	.32
Native Hawaiian or Other Pacific Islander	.01	.12
Two or more races	.05	.22
Ethnicity	.07	.26
Native English speaker	.84	.37
Initial level of knowledge	.00	1.00
Perceived relative level of difficulty	.00	1.00
Gateway	.24	.43
SES ∗ Perceived relative level of difficulty	−.03	1.00
Age ∗ Perceived relative level of difficulty	.12	.97
Female ∗ Perceived relative level of difficulty	−.04	.74
Black or African American ∗ Perceived relative level of difficulty	.00	.18
American Indian or Alaskan Native ∗ Perceived relative level of difficulty	.00	.10
Asian ∗ Perceived relative level of difficulty	−.01	.31
Native Hawaiian or Other Pacific Islander ∗ Perceived relative level of difficulty	.00	.13
Two or more races ∗ Perceived relative level of difficulty	.00	.20
Ethnicity ∗ Perceived relative level of difficulty	.00	.24
Native English speaker ∗ Perceived relative level of difficulty	.00	.93
Note. Descriptive statistics pooled across the five multiply-imputed datasets.

Table 6 presents final regression results concerning the relationship between educational advancement motivations on the one hand and U.S. participant characteristics (as well as our other regression analysis results) on the other. An unconditional, two-level multilevel model showed significant intercept variance by course in terms of the educational advancement motivation dependent variable [
=. 06910, χ2(397) = 559.18688, p < 0.001]. The intraclass correlation coefficient was 0.08, and intercept estimate reliability was 0.20. In the final model, a variety of variables were related to educational advancement motivations. Blacks/African Americans, Asians, non-Native English speakers, and males were more motivated by educational advancement than their white, native English speaking, and female counterparts. In addition, age and socio-economic status were negatively related to educational advancement, indicating that younger individuals and lower-income individuals were more motivated by educational advancement. The magnitudes of these aforementioned relationships were, in general, rather small; however, Black or African-American MOOC participants were more motivated by educational advancement than white counterparts by about two-thirds of a standard deviation. Non-native English speakers were about 30% of a standard deviation more motivated than their native English-speaking counterparts.


Table 6. Summary of hierarchical linear model estimates (and standard errors) for educational advancement motivations, completion, and perceived educational advancement and learning outcomes.

Predictor	Educational advancement motivation	Completion	Perceived educational advancement outcomes	Perceived learning outcomes
Level 1	UC	FM	UC	FM	UC	FM	UC	FM
Est.	SE		Est.	SE		Est.	SE		Est.	SE	
Educational advancement motivation	–	–	–	–	–	.14	.08		–	.48	.06	⁎⁎⁎	–	−.02	.03	
Completion intention	–	–	–	–	–	2.82	.42	⁎⁎⁎	–	−.06	.14		–	.44	.15	⁎⁎⁎
SES	–	−.09	.02	⁎⁎⁎	–	.01	.07		–	−.04	.02		–	−.08	.03	⁎⁎
Employment status	–	−.03	.05		–	−.46	.17	⁎⁎	–	.01	.05		–	−.03	.07	
Age	–	−.14	.02	⁎⁎⁎	–	.32	.08	⁎⁎⁎	–	−.05	.02		–	.05	.03	
Female	–	−.18	.04	⁎⁎⁎	–	−.40	.13	⁎⁎	–	−.07	.04		–	−.07	.05	
Black or African American	–	.64	.12	⁎⁎⁎	–	−.65	.31	⁎	–	.00	.12		–	−.17	.14	
American Indian or Alaskan Native	–	.12	.22		–	.16	.75		–	.31	.29		–	.26	.27	
Asian	–	.23	.08	⁎⁎	–	−.19	.24		–	.16	.11		–	−.16	.09	
Native Hawaiian or Other Pacific Islander	–	.07	.24		–	.38	.86		–	.27	.30		–	.15	.29	
Two or more races	–	.15	.10		–	.20	.30		–	.19	.09	⁎	–	−.02	.11	
Ethnicity	–	.07	.10		–	−.19	.27		–	−.14	.11		–	−.04	.09	
Native English speaker	–	−.28	.07	⁎⁎⁎	–	− 0.09	0.20		–	− 0.03	0.07		–	− 0.04	0.09	
Initial level of knowledge	–	0.01	0.02		–	0.04	0.07		–	0.02	0.02		–	0.01	0.02	
Perceived relative level of difficulty	–	–	–	–	–	− 0.27	0.10	⁎	–	0.04	0.02		–	0.06	0.03	⁎
SES ∗ Perceived relative level of difficulty	–	–	–	–	–	–	–	–	–	–	–	–	–	0.06	0.02	⁎⁎
Female ∗ Perceived relative level of difficulty	–	–	–	–	–	.26	.13	⁎	–	–	–	–	–	–	–	–

Level 2
Gateway course status	–	.13	.09		–	−.35	.25		–	−.04	.07		–	−.12	.09	
Variance components																
Level-1 variance	.81		.74		–		–		.84		.62		.94		.92	
Level-2 variance	.07	.05			–		–		.02		.01		.04		.04	
Proportion variance explained																
Proportion level-1 variance explained	–	.09			–		–		–		.27		–		.02	
Proportion level-2 variance explained	–	.31			–		–		–		.63		–		.11	
Proportion total variance explained	–	.11			–		–		–		.28		–		.02	
Note. Fixed effect estimates for continuous variables are standardized with respect to X and Y and fixed effect estimates for dummy variables are standardized with respect to Y only. UC = unconditional model. FM = final model. SE = standard error for regression coefficient. SES = socioeconomic status.

⁎
p < 0.05.

⁎⁎
p < 0.01.

⁎⁎⁎
p < 0.001.

4.5. Research question 4b: what is the relationship between U.S. MOOC participant characteristics and MOOC type (i.e., gateway course status)?
We also examined how MOOC socio-demographic characteristics (i.e., SES, age, race/ethnicity, and native language) related to whether or not the individual participated in a “gateway” MOOC course. Of the individuals in our sample for which the course title was known (N = 1818), about 18% competed a gateway MOOC. Specifically, about 2.1% completed a gateway English language course, 5.5% completed a gateway mathematics course, and about 10.8% completed a science-related gateway MOOC. A binary logistic regression estimated with multiply imputed data to examine relationships among whether an individual completed a MOOC or not relative to their characteristics (simultaneously) showed that only socioeconomic status was significantly related to gateway MOOC participation [B = 0.18, p < 0.01, Exp(B) = 0.83], while accounting for the other variables. Individuals with a higher socio-economic status were less likely to have first participated in a gateway MOOC. No other socio-demographic characteristics were related to gateway course participation.

4.6. Research question 4c: what is the relationship between U.S. MOOC participant characteristics and MOOC persistence? How do those relationships vary by perceived level of relative course difficulty?
Table 6 also contains results concerning the relationship between MOOC course persistence (completion) and U.S. MOOC participant characteristics. An unconditional, two-level multilevel model showed significant intercept variance by course in terms of the completion dependent variable [
=. 0.32831, χ2(397) = 478.39054, p < 0.01]. In accord with Snijders and Bosker (1999), the interclass correlation was 0.09, and intercept estimate reliability was 0.14. Several variables in our final model were related to participant-reported course completion. Most notably, but not surprisingly, the intent to complete the course at the time of course registration was very highly related to completion (β = 2.82). At the same time, MOOC participants who were not employed, white, older, and male were more likely to complete the course. Among these latter variables, the largest difference in completion rate was that observed between Black and white participants. Finally, we found that the more difficult a course was relative to one's level of knowledge, the less likely one was to complete the course; furthermore, the interaction between perceived relative difficulty and gender was significant such that the relationship between perceived relative difficulty and completion was smaller (and close to zero) for females.

4.7. Research question 4d: what is the relationship between U.S. MOOC participant characteristics and perceived MOOC-related educational advancement and learning outcomes? How do those relationships vary by perceived level of relative course difficulty?
Table 6 presents regression model results concerning the relationship between U.S. MOOC participant characteristics and perceived educational advancement as well as perceived learning outcomes. In terms of educational advancement outcomes, an unconditional, two-level multilevel model showed significant intercept variance by course in terms of the educational advancement outcome dependent variable [
=. 0.02367, χ2(397) = 502.27556, p < 0.001]. The intraclass correlation coefficient was 0.03, and intercept estimate reliability was 0.09. Being motivated by educational advancement was positively related to the degree to which one perceived experiencing educational advancement outcomes. In addition, individuals identifying with two or more races reported more educational advancement outcomes than individuals reporting as white. While the two or more race-white difference was rather small (about 0.2 standard deviations), the relationship between educational and advancement motivations and outcomes was sizable (β = 0.48). No other interactions between perceived relative difficulty and participant characteristics were statistically significant; thus; these interactions were not included in the final model.

In terms of perceived learning outcomes, an unconditional, two-level multilevel model showed significant intercept variance by course in terms of the perceived learning outcome dependent variable [
=. 0.04475, χ2(397) = 504.17991, p < 0.001]. The intraclass correlation coefficient was 0.05, and intercept estimate reliability was 0.13. In the final model, individuals who intended to complete the course reported higher learning than individuals who did not intend to complete the course (and this difference was about four-tenths of a standard deviation). Also, socioeconomic status was negatively associated with perceived learning outcomes such that individuals with a lower socio-economic status reported more gains, although this relationship was small. Finally, we found that the more difficult a course was relative to one's level of knowledge, the more likely one was to learn. This finding is reasonable from the perspective that individuals have more room for growth. In addition, the interaction between perceived relative difficulty and socioeconomic status was significant such that the relationship between perceived relative difficulty and perceived learning outcomes was stronger for individuals with a higher socioeconomic status. In other words, individuals from a higher socioeconomic background benefitted more from taking a course that was challenging.

5. Discussion
This study revisited several questions concerning the role of MOOCs in promoting access to knowledge and higher education among traditionally underserved populations. While existing research on MOOCs and their participants suggests that a number of benefits are accruing for those who are already educationally advantaged, this body of work has not fully disaggregated data or focused on particularly relevant participant characteristics such as socioeconomic status, and to a larger extent, race and ethnicity. Within the U.S. context, these factors are critical to identifying MOOC participants from underserved populations in order to amply assess and increase the potential of MOOCs to broaden access for those who need it most. Moreover, research has not sufficiently addressed the degree to which MOOC participants are motivated by educational advancement and experience educational advancement outcomes. Greater knowledge of why certain participants take MOOCs for educational advancement and whether they meet their goals in those courses may help those designing, developing and teaching MOOCs to better address the needs of underserved and underprepared learners. Overall, the research presented in this paper contributes to existing knowledge concerning the relationship between MOOC participant characteristics and educational advancement motivations, as well as MOOC course outcomes, with particular attention to underserved populations (low-socioeconomic status and minority participants). Further, this research extends conversations about gateway courses, foundational courses that act as gateways to higher-level coursework and majors. As presented in the cost-free, MOOC format, these courses are especially important for underserved populations and arguably hold the most potential for broadening access and democratizing education.

Relative to socio-demographic characteristics of U.S. MOOC participants, by these data traditionally underserved groups, such as Blacks/African Americans and Hispanics/Latinos, are largely underrepresented in MOOCs. Though not surprising given what we know about students of color within the United States, these findings contribute to research on MOOC participant characteristics that has largely ignored participants' race/ethnicity. Interestingly, despite increases in access to and enrollment in formal higher education for students of color, these numbers are not reflected in general online education (Herrera, Jones-Davis, Gates, Jaggars, & Suiter, 2014), nor, as we highlight here, in MOOCs. Similarly, with respect to socioeconomic factors, our research supports findings that indicate MOOC participants are largely more highly educated (Christensen et al., 2013, Dillahunt et al., 2014, Laurillard, 2014, Zhenghao et al., 2015) and have more prestigious occupations than the general population. Overall, data suggest that U.S. MOOC participants are more educated than the general population (even more-so than reported in HarvardX data, which may be explained by the broader set of courses reflected in our data, compared to studies that examine one or more courses from the same provider). Thus, students who traditionally lack access to higher education were least likely to take MOOCs.

Further, in support of existing research (Zhenghao et al., 2015), participants in our study were not largely motivated by educational advancement, and correspondingly, the majority of MOOC participants do not experience educational advancement outcomes. However, U.S. MOOC participants did perceive to have learned more generally. In terms of educational advancement as a motivation for MOOC participation, our findings indicate that such motivations are evenly distributed across MOOC student sub-populations. Specifically, data revealed that Blacks/African Americans, Asians, non-Native English speakers, and males were more motivated by educational advancement than their white, native, English-speaking, and female counterparts. Importantly, lower-income individuals were also more motivated by educational advancement. In other words, underrepresented populations such as Blacks/African Americans and participants from low-income backgrounds are most likely to hold educational advancement motivations for taking MOOCs. These findings, in part, support research that found MOOC participants with lower socioeconomic status are more likely to be education seekers (Zhenghao et al., 2015). However, as previously mentioned, participants from lower socioeconomic backgrounds are least likely to enroll in MOOCs.

With respect to factors related to course outcomes, intent to complete was highly associated with reported completion. This aligns with research by Milligan et al. (2013) on varying patterns of engagement in cMOOCs. The authors observed three general patterns among participants: active participants, lurkers, and passive participants. Lurkers, for example, do not necessarily intend to engage in or complete courses, but rather, these users enroll and observe and sample course content. Relative to our findings, course completion was more likely among MOOC participants who were white, older, male, and not employed—again, not the traditional profile of the underserved, low-income or racial/ethnic minority. We also found that the more difficult a course was relative to one's level of knowledge, the less likely one was to complete the course. Findings concerning lower completion rates for Black/African Americans and individuals with insufficient prior knowledge might suggest problems with MOOCs in serving those individuals with the greatest need for access to higher learning. In terms of factors associated with MOOC outcomes, we found several instances wherein outcomes differed by participants' characteristics, including socio-demographic characteristics.

Higher educational advancement outcomes were associated with intending to complete the course, as well as being motivated by educational advancement. In our study, intention to complete the course was also a significant predictor of perceived learning. This finding speaks to the importance of understanding motivational factors in MOOC learning environments relative to assessing “success” in these courses. Interestingly, compared to white participants, individuals who were two or more races were more likely to report advancing educationally as a result of the course. Further, individuals with a lower SES reported more learning, suggesting differential effects of MOOCs by SES in which those who might stand to gain the most actually do. Similarly, we found that the more difficult a course was perceived to be relative to one's level of knowledge, the more one perceived to have learned. Our interpretation of this finding is that individuals with more room for growth learn more during MOOCs. On the other hand, the significant interaction effect in this model suggests that individuals from a higher socioeconomic background benefitted more from taking a challenging course.

While age, gender, race, and native English status were related to motivations for education advancement, these variables were not related to perceived educational advancement outcomes. That is, while younger, male, and Black/African American participants were more motivated by educational advancement, they did not perceive to advance educationally as a result of MOOC participation more so than did their counterparts. However, the fact that these variables were not significant in the educational advancement outcome model may be due to the fact that educational advancement motivations were concomitantly included in the statistical model. Thus, these null findings might be taken to mean that when educational advancement motivations are taken into account, MOOCs did not differentially educationally advance these sub-populations. Still, those who were more motivated by educational advancement did appear to advance more educationally (at least perceptually) as a result of MOOC participation.

Our study also invoked further consideration of the level of course in terms of whether or not the course was a “gateway” MOOC. Although individuals with a lower socio-economic status were more likely to have first participated in a gateway MOOC, results did not show that persistence or outcomes varied by a course's gateway status. This finding stands in contrast to that typically observed in formal education, wherein gateway courses often function as “gatekeepers” by presenting significant roadblocks to progress and completion for particular students (Goldrick-Rab, 2010, Jiang et al., 2014). Indeed, formal gateway courses are often particularly difficult for undergraduate students, and especially difficult for students who are underserved and/or underprepared for higher education (Goldrick-Rab, 2010). Gateway MOOCs then, though fewer in number in terms of existing MOOC offerings, may hold a great deal of potential to ease access to higher education and particular fields of study. However, there may be important differences between formal and informal MOOC courses relative to curricular and assessment rigor that explain this discrepancy.

6. Conclusion
Overall, online education is particularly difficult for those who do not have full access to technology. Within the United States, the digital divide between low-income, Black and Hispanic families and their higher-income white counterparts remains (Jaggars, 2014). Christensen et al. (2013) cite a lack of technological access as the primary reason why those who are financially disadvantaged have not taken MOOCs. But in looking beyond the most fundamental level of access—access to the technology that allows an individual to engage in a MOOC—Meisenhelder (2013) reaffirms the need to question a design/format that offers a realistic opportunity for all students: “Assuming a student has the hardware and infrastructure for meaningful access through a MOOC, another question to ask is whether that format offers her/him a reasonable chance at success” (p.13). Currently, as Whitmer et al. (2015) argue: “MOOCs are often designed for these students, who already possess the kinds of study skills and habits that many remedial students lack” (2015, p. 1). Clearly, further research is needed on how MOOCs can better reach, retain and support underserved populations. Gateway courses, in particular, may provide the best starting point.

Although the story is not entirely bleak—MOOCs are indeed far-reaching and are, at the very least, increasing the quality of education for some (Jaggars, 2014)—too often we accept moves toward democratization as a sufficient “step in the right direction” (Zhenghao et al., 2015) while education continues, at all levels, to benefit the advantaged rather than those who need it most. Arguably, MOOCs face the very same obstacles that have presented themselves at every turn in higher education's journey toward democratization (e.g., expansion of the U.S. system of higher education intensified stratification and inequality). Just as structural theories of social stratification challenge the democratizing effects of the expansion of higher by asking “whether it reduces inequality by providing more opportunities for persons from disadvantaged strata, or magnifies inequality by expanding opportunities disproportionately for those who are already privileged” (Shavit et al., 2007, p. 1), we conclude this research by asking the same. As much as we hoped to find that MOOCs actually disrupt the system and provide greater access to traditionally underserved populations within the United States, our findings are contrary: MOOCs predominantly serve the interests of the advantaged, rendering notions of their democratizing powers as insufficient at best.