Structured tasks and peer-moderated discussions are pedagogical models that have shown unique benefits for online collaborative learning. Students appointed with leadership roles are able to positively affect the dynamics in their groups by engaging with participants, raising questions, and advancing problem solving. To help monitoring and controlling the latent social dynamics associated with leadership behavior, we propose a methodological approach that makes use of computational techniques to mine the content of online communications and analyze group structure to identify students who behave as leaders. Through text mining and social network analysis, we systematically process the discussion posts made by students from four sections of an online course in an American university. The results allow us to quantify each individual's contribution and summarize their engagement in the form of a leadership index. The proposed methodology, when compared to judgements made by experts who manually coded samples of the data, is shown to have comparable performances, but, being fully automated, has the potential to be easily replicable. The summary offered by the leadership index is intended as actionable information that can guide just-in-time interventions together with other tools based on learning analytics.

Previous
Next 
Keywords
Leadership

Computer-supported collaborative learning

Text mining

Social network analysis

Learning analytics

Online learning

1. Introduction
As ways to support online collaborative learning, structured tasks and peer-moderated online discussions are pedagogical models that have shown unique benefits (Choi, Land, & Turgeon, 2005; Coll, France, & Taylor, 2005; Rovai, 2007). In these learning activities, students often take on leadership roles to facilitate discussions. They can positively affect the dynamics in their groups by engaging with participants, raising questions and advancing problem solving (Micari, Pazos, Streitwieser, & Light, 2010; Zha & Ottendorfer, 2011). The social dynamics in peer-moderated online discussions are complex. For example, student leadership can be appointed officially by the instructor (Xie, Yu, & Bradshaw, 2014). They can also emerge through group interactions without official appointment of leadership roles (Wickham & Walther, 2007; Xie, Hensley, Law, & Sun, 2017a). However, these complex processes in online group learning are often latent and not explicitly observed since students are physically isolated and they only interact with each other through computer-mediated communications (Xie, Lu, Cheng, & Izmirli, 2017b). This makes the assessment of leadership in such settings critical yet challenging.

Previous studies on leadership heavily relied on students' self-report (Chang & Lee, 2013) or were conducted through qualitative approaches (Gressick & Derry, 2010), both of which have methodological and practical limitations (Berg, Lune, & Lune, 2004; Greene, 2015). On the other hand, data tracked in technology-based learning systems afford powerful new analytical approaches to uncover these complex processes of group learning interactions (Baker & Inventado, 2014; Xie, 2013). In the current study, we propose the adoption of a computational approach for the detection of leadership in peer-moderated online collaborative learning. We aim to develop a quantifiable index of team leadership through the mining of the content of discussion posts and log data recorded in an asynchronous online discussion system.

2. Literature review
2.1. Team leadership in collaborative learning
While there have been voluminous leadership theories (see reviews in Bass, 1990), we take a perspective of leadership as behavioral complexity as our theoretical foundation (Quinn, 1984). Effective leadership under this perspective is considered as performing multiple roles simultaneously. This theory specifies eight typical leadership roles based on to what extent their behaviors are flexible/stable and internally/externally focused: innovator, broker, producer, director, coordinator, monitor, facilitator, and mentor. Empirically, studies found that leaders were considered more effective when they were capable of playing more roles even if some roles are contradictory to each other in terms of flexibility and focus (Dension, Hooijberg, & Quinn, 1995). As web technologies have been widely used to support remote communications and collaborations, research on team leadership therefore has been extended to these virtual spaces, such as virtual teams. Leadership behaviors in virtual teams are manifested through engaging in online activities and communication within a team is mediated by technologies (Huang, Kahai & Jestine, 2010). In online academic settings, when learners are assigned to complete self-managed group tasks (e.g., peer-led discussions), leadership emerges in the group along with an observable shift in students' behavioral patterns in communications and interactions, such as planning, initiating conversations, setting group goals, topic control, input seeking, moderating discussions, managing conflicts, monitoring project progress, and evaluating team product (Chang & Lee, 2013; Hew, Cheung, & Ng, 2010; Xie et al., 2017a).

In addition to the leadership complexity perspective, we also believe that leadership can be shared by multiple members (Pearce & Conger, 2003). There may be multiple leaders in a collaboration team. Team members who play the leadership role together enable shared leadership. The shared leadership perspective is even more prominent in self-managed teams where no official leaders are appointed (Barry, 1991). Empirical studies have showed that shared leadership has an advantage in making use of team members' intelligence and creativity to enhance the organization's performance (Wageman, 1997). In educational settings, a student often teams up with peers and completes academic tasks together without instructor's intervention all the time. Gressick and Derry (2010) empirically demonstrated that groups worked successfully when leadership was shared in balance. They argued that an ideal condition of successful group learning is that all members participate in multiple leadership roles. Furthermore, shared leadership often evolves through members' active participation in group processes (Carson, Tesluk, & Marrone, 2007; Spillane, 2005). Even when some specific members are formally assigned with a leading role (e.g., project manager or discussion moderator assigned by instructor), other members may also collaboratively play informal leadership roles (Carte, Chidambaram, & Becker, 2006; Neubert & Taggar, 2004).

Concerning how leadership emerges through technology-mediated communications, research has found some measurable information to identify leadership behaviors. First, computer-mediated discourse is an information source of leadership roles. In other words, leaders tend to “speak” in a certain way in order to influence group processes in an online collaborative context (Sudweeks & Simoff, 2005; Timmerman & Scott, 2006). For example, Xie et al. (2014) found that leaders participated in online discussions more actively in terms of numbers of messages, numbers of replies, time spent on discussion tasks, interactions with others in more diverse ways. Particularly, leadership functioned as a trigger of more replies from more diverse peers in the discussion-based online community. Also, leadership roles can be recognized by analyzing social interaction scripts (Carte et al., 2006). Therefore, to identify leadership behaviors in virtual teams, we first focus on the quantitative and qualitative features of online discourse. In additional to the focus on individual discourse, group-level characteristics such as members' social relationships and organizational structure are important aspects of team leadership (Xie et al., 2014). The idea of using graph theory and networks to portray social structure allows quantitative investigations on team structure and leadership (Balkundi & Kilduff, 2006; Hoppe & Reinelt, 2010). These studies show that influential group members (e.g., leaders) tend to take more central positions in their surrounding networks, that is, they are more connected with many members. At the same time, members with higher centrality are perceived as leaders by their peers in the group.

2.2. Issues in measuring and detecting team leadership
For many studies on the topic of team leadership, detecting leadership is a necessary step prior to further analysis. There are generally two approaches to the detection of team leadership: trait and membership. The trait-based approach usually assumes that leadership is a specific personality trait. The extant research has used self-report surveys to measure a person's leadership characteristics (Purvanova & Bono, 2009). For example, an instrument has been developed based upon the behavioral complexity theory (Quinn, 1984) to capture the dynamic and contradictory nature of leadership behaviors (Lawrence, Lenk, & Quinn, 2009). While this approach provides some level of details about leadership characteristics and dispositions, it fails to capture the contextual factors that may influence the actual practice of leadership in teams (Kayworth & Leidner, 2002; Lee-Kelley, 2002). The membership approach focuses on the social relationship of members in team collaboration settings, in which the leadership detection is achieved through member nominations, including both self- and peer-nominations. The leadership detection relies on member's perceptions about each other. In this approach, researchers can perform additional analysis such as social network analysis and generate social graphs to represent leadership within group (Balkundi & Harrison, 2006; Huffaker, 2010). While both approaches have their theoretical foundations, they both involve self-report of perceptions and dispositions, one at the individual level and the other at the group level. They both requires follow-up analyses in order to detect leadership and its associated patterns in the group, which prevent the possibility of real-time invention on leadership in group learning. An automatic method that can dynamically and time-efficiently detect leadership would add great values to online collaborative learning.

2.3. Affordances of learning analytics in detecting team leadership
Learning analytics, defined as “the measurement, collection, analysis, and reporting of data about learners and their contexts, for the purposes of understanding and optimizing learning and the environment in which it occurs” (Siemens, 2013), is a field of inquiry that advanced rapidly, in parallel with the availability of online learning tools. It is influenced by a wide range of disciplines, with computer science and educational psychology being the main ones (Dawson, Gašević, Siemens, & Joksimovic, 2014), and its main focus is to enhance learning in all of its aspects by leveraging data mining and machine learning techniques (Baker & Inventado, 2014) to extract value from trace data. These trace data represent information about learners' behavioral engagement mined from log files of online environments that host pedagogical activities (Xie, 2013). The research outputs of learning analytics, while aiming to ground theoretical frameworks on behavioral trace data (Kovanović, Gašević, Joksimović, Hatala, & Adesope, 2015), intend to generate “just-in-time” interventions due to the capability to automate data processing (Macfadyen & Dawson, 2010; Siadaty, Gašević, & Hatala, 2016), and to enable the personalization of learning experience (Köck & Paramythis, 2011).

The availability of learning analytics for educational psychology research contributes also to the adoption of trace data as alternative or complementary sources to overcome the limitations of self-report instruments. The assessment of cognitive and metacognitive skills relies on an array of methodologies, like questionnaires and interviews, thinking-aloud protocols, mining of trace data from online systems, eye-movement registration (Veenman, Van Hout-Wolters, & Afflerbach, 2006). Self-report instruments, such as surveys, are easy to administer and therefore widely adopted, but have been criticized for their limitations (Greene, 2015; Veenman, Prins, & Verheij, 2003), while data analytics can help to preserve the context of the construct we are trying to measure. This is especially important in the current study, in which latent and emergent dynamics related to leadership are difficult to access by the single individual and call for computational and analytical approaches capable of capturing the contextual and social aspects of learning through text mining and social network analysis (Grunspan, Wiggins, & Goodreau, 2014).

2.4. Purpose of study
In this study, we are interested in examining team leadership in an online collaborative learning setting. Therefore, we situate the definition of leadership in the context of peer-moderated online discussions, specifically referring to the individual contributions made online and the effect discussions have on group structure. Starting from the analysis of the messages logged into the digital forum associated to an online course, we developed and tested computational techniques capable of identifying patterns of interactions associated with messages that display elements of leadership. Our objective is twofold: to design a methodology that requires little to no human intervention and to combine our analysis into a single outcome index, capable of reflecting a quantitative summary of students' leadership behavior in the group.

The following research questions guided the design of this study: (1) To what extent can data mining extract linguistic features to detect leadership at the message level? (2) To what extent can social network analysis model leadership at the person level? (3) To what extent does our computational approach provide evidence of team leadership?

3. Method
3.1. Participants and study context
The participants of this study were 57 students from four sections a mixed-level course at a university in the Southeastern United States. They were 11 males and 46 females whose age ranged from 19 to 53 with a median age of 29. The majority of the participants was majoring in education-related disciplines. The distribution of participants by academic level was: freshmen 4 (7.0%), sophomores 6 (10.5%), juniors 18 (31.6%), and seniors 29 (50.9%). They reported their ethnicity as follows: White 31 (54.4%), African-American 21 (36.8%), and Others 5 (8.8%).

This 16-week course was offered entirely online and presented students with discussion topics drawn from issues related to technology integration in K-12 education. The four sections were taught by the same instructor and followed identical learning procedures. Student-led discussions were the major class activities. In each discussion session, up to two students were appointed as moderators. They designed discussion questions around the topic of the module, and led the class discussions, while the rest of the class followed instructions designed by the appointed moderators and participated in asynchronous online discussions. Every student in the class was given an opportunity to lead a discussion session during the semester. The instructor facilitated the first few weekly discussions. The rest of the sessions were led by students.

3.2. Analytical approaches
To address our research questions, we analyzed students' online discussions recorded in the university's learning management system. The discussion data contains 4083 posts. Text, hyperlinks, and emoticons were the main content of each post. Information such as post ID, the type of post (initial or reply-to), de-identified author ID, posting time, and posting content were aligned together for analysis. In addition, for each student, all activities including every login to the discussion forum and every time the student read a post were recorded by the system as log data.

The analytical process is illustrated in Fig. 1. The main input of the process are the forum posts, with associated metadata, which students submitted each week to fulfill class requirements. The output of the analysis is the students leadership index, the measure we constructed to rank the individuals' weekly contribution to the classroom. In between there are two major computational steps, designed to automate the computation of the leadership indexes: (1) Message-level analysis: the first analytical step focused on the messages as unit of analysis, taking as input the entire set of forum posts, to process their text content and separate them in two groups, leader messages and regular messages – where leader messages, compared to regular discussion ones, have the function of moderating interactions, facilitating discussion, or eliciting participation from others. (2) Person-level analysis: the second analytical step focused on students as unit of analysis and took the results of the message-level analysis, together with the messages metadata, to quantify the student interactions and calculate each individual contribution to the group, their leadership index, a measure used to rank students and track their engagement over time.

Fig. 1
Download : Download high-res image (116KB)
Download : Download full-size image
Fig. 1. Analytical steps.

3.2.1. Sampling and coding of students' messages
During the message-level analysis we adopted supervised learning techniques based on natural language processing (NLP) to classify the set of forum posts. Two types of balanced datasets, containing examples of moderating messages and generic messages, were used to train and test machine learning algorithms, which were subsequently used to identify leader messages in the entire collection of posts. A first balanced dataset was generated by three raters, who manually coded a sample of the messages after adapting the leadership complexity model from Denison et al. (1995) and Carte et al.'s (2006) to our context by generating four main types of leadership behaviors: transformative leadership including innovator and broker, directive leadership including producer and director, conservative leadership including coordinator and monitor, and participative leadership including facilitator and mentor (see definitions and examples in Table 1). In the presence of any of the Leadership Roles, a message would be marked as a leader message. In the absence of all these roles, a message would be marked as a regular message. The three raters worked independently, reaching a good level of agreement (Fleiss's Kappa = 0.696, z = 44.3, p < 0.001). Their evaluations were later compared, discussed and resolved to obtain unanimity in the coding. A second balanced dataset containing a random sample of the forum posts was prepared by taking advantage of one of the feature of the course design: the presence of appointed moderators. Working under the assumption that online contributions made by appointed moderators contain leadership elements with a frequency higher than contributions from other students (Xie et al., 2014), we directly labeled their message as leader messages and fed them to the machine learning models to mine their features and classify the rest of the posts. Both the manually coded dataset and the automatically labeled dataset were used to train the same machine learning algorithms and their performance are compared in the result section below (Section 4.1). However, the second dataset allowed us to enhance the automation of the analysis. By using NLP to categorize messages it is possible to minimize the amount of labor required to process the data; by modeling the leader messages after the implicit behavior of appointed moderators it is possible to remove the use of expert judgement entirely, a methodological choice that makes the proposed analytical process faster and easily reproducible.


Table 1. Coding scheme adapted from Dension et al. (1995) and Carte et al.'s (2006).

Leadership roles	Definitions	Examples
Transformative leadership
(Innovator, Broker)	Critiques the routine of discussion activities and asked for a change by using external resources (e.g., instructor)	Instead of focusing in how technology could potentially screw up, we should have focused on the idea of discussion itself.
Directive leadership
(Producer, Director)	Sets goals, establishes clear expectations, provide explicit instruction, provides explicit instruction, and seek closure.	You need to add the link to your posts so that they can access the webquest.
Conservative leadership
(Coordinator, Monitor)	Maintains structure, coordinates, and solve problems.	If you have any questions, please feel free to email me. I am online all day until 3 p.m.
Participative leadership
(Facilitator, Mentor)	Seeks consensus, negotiates compromise, and invite people to self-reflect	I totally agree that drawing feature could enhance a presentation or a word document. Did you have any problems with creating today's assignment since you haven't used this feature in a while???
3.2.2. Message-level analysis through text mining techniques
The machine learning algorithms adopted for the final classification of this message-level analysis were two binary classifier models, a Logistic Regression model (LR) and an Adaptive Boosting model (AdaBoost). Adaptive Boosting, (Freund & Schapire, 1995), a model somewhat less common than logistic regression (Cox, 1958), was implemented to increase coverage of the analysis of the features that made up a leader message. AdaBoost uses an ensamble of decision trees as weak classifiers, where each sequentially introduced classifier boosts the performances of the whole model. For example, it starts with a decision tree capable of performaning just slightly better than a random model (weak classifier), and iteratively builds new decision trees (boosting) in order to improve the overall outcomes (ensamble method). Here the model is used to process a representation of student messages in the form of a weighted table of words. In the end, each classifier model produced a probabilistic output, in the range of 0 to 1, for each of the posts recorded on the discussion forum. A post was hence classified as a leader message if its associated value was equal or >0.5.

3.2.3. Person-level analysis using social network analysis
The second analytical step focused on the students as units of analysis. It used as input the set of classified posts produced in the previous step and produced as output a weekly index to measure student behavior over time, the leadership index. The person-level analysis aimed to study leadership as a personal characteristic displayed by students in their behavior and interactions, therefore it made use of social network analysis (SNA) to quantify the influence students have when communicating with their peers and to define their structural relationship (Dawson, 2006; Xie et al., 2014).

The influence of actors in a social network is a function of the number of connections they have, which is often referred as their centrality—with eigenvector centrality being a widely-adopted version of this measure (Dawson, 2010). Eigenvector centrality calculates the influence of an actor as the sum of the centrality of his or her connections. In short, it assumes that not all connections are equals and that being linked with an influential actor will further boost one's own influence. In the context of the present study, eigenvector centrality is calculated with the variation introduced by Katz (1953): a baseline centrality score of 1 was applied to all the students whose communication exchanges were marked as leader messages by the classification algorithms deployed during the previous analytical step. Katz's baseline centrality score is an exogenous parameter commonly adopted in the study of centrality among asymmetric relations (Bonacich & Lloyd, 2001) and it is particularly suited when analyzing directed acyclic graphs—such the ones generated by our student population—in which poorly connected nodes in a network with a limited number of nodes might prevent the algorithm to converge (Newman, 2010).

Using Katz centrality, we could rank the performances of all the students that participated in activities of peer-moderation, whether formally instructed or voluntarily engaged. This ranking index, the leadership index, was thereby defined in terms of a node centrality value in the weighted directed networks connecting the senders and the recipients of the forum posts identified as leader messages (with their respective probabilities as edge weights). The leadership index measures were computed on the basis of both sampled datasets, the manually coded one and the automatically labeled one, and the results are compared in Section 4.3.

4. Results and discussion
4.1. Comparison of binary classification models
The data processing module was able to obtain a feature vector matrix containing 1305 posts of appointed moderators and regular participants with 3592 unique words as features. A logistic regression (LR) algorithm and an AdaBoost algorithm were implemented to classify messages in a binary category: leader messages versus generic discussion messages. Both LR and AdaBoost models were implemented using the scikit-learn python library (http://scikit-learn.org/). For the AdaBoost method, two hundred single-depth decision trees are used as base classifiers for the AdaBoost-SAMME.R real boosting algorithm (Hastie, Rosset, Zhu, & Zou, 2009). The analysis was done by splitting the entire data into two datasets: the training dataset (90% of the entire data), and the testing dataset (10% of the entire data). Ten-fold cross-validation was applied to both LR and AdaBoost methods. The trained models were subsequently tested using the testing dataset after completion of the cross-validation.

Accuracy, precision, recall, and F1-measure were measured to evaluate the performance of training and testing steps for both LR and AdaBoost models. Both models were trained and tested using both the automatically labeled dataset and the manually coded one (see Table 2).


Table 2. Comparison of modeling methods per training dataset.

Automatic labeling (a)	Manual coding (b)
Logistic regression	AdaBoost	Logistic regression	AdaBoost
Cross-Validation	Accuracy	0.702	0.568	0.799	0.688
Precision	0.677	0.613	0.808	0.808
Recall	0.750	0.585	0.750	0.583
F1-Measure	0.712	0.599	0.778	0.678
Testing	Accuracy	0.671	0.718	0.860	0.797
Precision	0.747	0.762	0.912	0.857
Recall	0.635	0.686	0.838	0.727
F1-Measure	0.686	0.722	0.873	0.787
The results indicate that the manual coding condition (condition b) outperformed the automatic labeling condition (condition a) across both LR and AdaBoost methods, indicating that a set of leader messages in the manually coded dataset contains more unique linguistic patterns associated with leadership than those in the automatic labeled one. These results are well within our expectation. As described in Section 3.2.1, the training datasets used in condition a assumes that all moderators' posts as leader messages. But not all moderators' posts are intended to lead. Some are neutral communications. In the manual coding condition, three researchers reviewed each post and coded them as leader or neutral messages, therefore, the sampled messages are likely to be better separated. This process involved labor-intensive manual coding. However, the performances of algorithmic models trained in condition a, being very promising, justify our assumption that an exogenous factor, like the mechanism of peer-moderation adopted in our online course, can affect student behavior in a consistent way.

In addition, the results from the LR model are meaningfully better than those from the AdaBoost model. Based on the inherent characteristics of LR and AdaBoost, the following three factors can be called upon to explain the differences. First, it highlights the fact that the set of feature vectors used as input is roughly linear. It is assumed that a small number of specific features (words or short phrases) in this high dimensional space plays a significant role, and made the model focus on those important features during the training phase. When this happens, the problem becomes similar to a linearly separable problem and it is the condition responsible for the good performance of the LR model. Second, an AdaBoost model is inherently prone to overfitting due to its boosting process when dealing with noise in the data. It is logical to assume that the given natural language dataset used for this analysis contains more noise than a well-organized numeric data. This noisy data would significantly impact the AdaBoost model during its boosting process as the model would add weights on misclassified noisy data while training. The previous factor, combined with the relatively small size of the overall dataset, finally makes the AdaBoost model more vulnerable to overfitting than the LR model. Overfitting also originates from the boosting process of the AdaBoost model: as it focuses on the small number of misclassified elements, the hyperplane set at the end of the training process is naturally placed closer to those data elements than the LR model. Therefore, it is not easy for the AdaBoost model to avoid overfitting when the number of training data elements is insufficient.

4.2. Detection of team leaders in student communication networks
The second step of our analysis examines the interaction patterns of individual students who carried out leadership activities in the discussions among peers. All the posts identified as leader messages in the first step were carried over into this second analytical step in order to further examine student moderation activities.

Social network analysis (SNA) was used to examine the relational structure underlying students' communication exchanges, with the goal to identify individuals who were central to the network structure and compare their engagement with the engagement of appointed moderators. Senders' and recipients' information were used to build a graph representing the weekly leadership patterns for each chapter's discussion as recorded by the learning management system. The probabilistic output of the machine learning model developed in the previous step was then applied to weight the edges in the graph—or, in case of multiple messages among the same students, the mean of the probabilistic indices—thus converting communication networks into leadership networks. An example of the resulting graph is shown in Fig. 2, which highlights the appointed moderators as well as students who had at least one message flagged as leader message in our message-level analysis.

Fig. 2
Download : Download high-res image (100KB)
Download : Download full-size image
Fig. 2. Convert communication network to leadership network, and map onto leadership- communication network.

Note: The appointed moderators are marked in green.

The interactions recorded during week 5 of the first section of the course are shown in the sociogram of Fig. 2.a. Each student is a node of the network and the links represent direct message exchanges among them through the discussion forum. The appointed moderators – in this example there are two – are marked in green. The graph in Fig. 2.b is obtained removing the generic messages and retaining only those that were classified as leader messages in our first analytical step. This subset of links represents the attempts made at peer-moderation by all the students: it highlights even more how this group is actually structured in two distinct organizational unit. By visualizing the nodes' relative centrality, we also observe how appointed moderators are not always the most influential node in the network. The size of the nodes indicates student's centrality to represent their importance in the network structure (Freeman, 1978). As Fig. 2.b. shows, several students stand out for their contribution. More specifically, using the python library NetworkX 1.11 (https://networkx.github.io/), we calculated the Katz centrality of the nodes and used it as a ranking index of the students who display leadership online—we define it as the leadership index. As mentioned previously, Katz centrality uses eigenvectors to attribute influence to a node based on the relative influence of the other nodes that are connected to it. Translated in our scenario, where each link represents a reply post in a threaded conversation, this measure of centrality captures the fact that intervening to moderate a thread lead by a central student will further enhance this individual's centrality score. In our final step, we mapped the leadership indexes back onto the communication network creating a leadership-communication network (Fig. 2.c.) to visualize how emergent leaders influence the interaction and communication among group members.

What is noteworthy in the example network shown in Fig. 2, as with all the other networks derived from our logged interactions, is the fact that appointed moderators, although influent, are not always the most central nodes. This indicates that other students emerge as leaders and social network analysis can help us bring them into focus. Those are the team leaders that our approach tries to identify.

4.3. Validity evidence of leadership index
In order to provide validity evidence for our analytical approaches in detecting team leadership in group learning, in Section 4.1 we compared two approaches to the classification of students' posts, one informed by human judgement, the other completely automated. In the case of equivalent output at the person-level analysis, the latter condition has a clear advantage, since it doesn't require multiple people reading samples of online interactions. We assume a correlation between the results of the two conditions. Each week, a subject with a high centrality value in the manual coding condition will also have a high centrality value in the automatic labeling condition. To verify our hypothesis, we tested the correlation between the average centrality scores obtained by each student in these coding conditions, as classified by our best performing machine learning model (Logistic Regression). We found a positive correlation r = 0.776, t (50) = 8.704, p < 0.05, which indicates that the two conditions are able to capture similar relationships among students. Since not all the score sets appear normally distributed we double checked the correlation using a non-parametric test: tau = 0.561, p < 0.05, which again indicate a highly significant positive correlation. The outputs of these two coding conditions align with each other indicating that the computational approach we adopt in this study produces comparable results as the human expert. The manual coding condition requires intensive labor for the interpretation of the discussion transcripts. Our fully automated computational approach can provide automatic and real-time feedback, meaningful to teaching and learning practice.

In addition, we looked at correlations between leadership index and engagement measures derived from the trace data aggregated at the week level. Table 3 provides the descriptive statistics and the correlation coefficients. In general, students' leadership index was significantly correlated with their engagement measures, including the number of posts, number of replies, length of logins, length of posts, topics created, and topics read at the week level. These results align with the finding from the literature on leadership that team leaders often exercise their influence through active interactions and communications (Sudweeks & Simoff, 2005; Timmerman & Scott, 2006). In online collaborative settings, leaders often post more messages, interact with more diverse peers, and stay longer in online discussion systems (Xie et al., 2014).


Table 3. Descriptive statistics of weekly engagement and correlations (N = 365).

Mean	Std. dev.	Min	Max	Correlations with leadership index
Leadership index	1.125	0.135	1	2.082	
Number of posts	9.542	6.413	1	50	0.639a
Number of replies	8.933	6.175	0	42	0.623a
Length of posts (character)	5816.121	4152.379	350	27,332	0.425a
Topics started	0.610	1.183	0	8	0.215a
Topics read	22.421	17.516	2	115	0.420a
Length of logins (second)	20,134.24	16,122.25	3189	144,997	0.535a
Times of logins	90.236	67.634	8	430	0.098
a
Correlation is significant at the 0.01 level (2-tailed).

4.4. Patterns of emergent leadership and engagement
The computational approach being proposed in our study affords the investigation of team leadership from new perspectives. Here we provide two examples of possible approaches: one from a network perspective and the other from a developmental perspective.

The computational approach allows us to study the influence of leadership and the social structure of networks in group learning. We first assess team leadership at the message-level generating leadership scores for discussion posts, which in turn allows to convert communication networks into leadership networks and, finally, to calculate leadership indexes (Fig. 2.a & b). By mapping the leadership indexes onto communication networks (Fig. 2.c), we are able to examine the interaction between leadership and communication at the group level. In our observation of the sociograms generated in the social network analysis, three unique and representative cases emerged from the data reflecting how leadership was distributed within the group. Fig. 3.a presents a dominated leadership case where the assigned leaders had dominant power within the social network and the other class members mainly acted as followers. Fig. 3.b presents a shared leadership condition where assigned leaders and informal leaders existed at the same time and the leadership were shared among the social network members. Fig. 3.c presents one extreme case of the shared leadership condition, a replaced leadership case, in which the leadership of the assigned moderators diminished and was replaced by other members to demonstrate the leadership and manage the class.

Fig. 3
Download : Download high-res image (350KB)
Download : Download full-size image
Fig. 3. Leadership distribution patterns.

Our observation aligns with the previous findings in the leadership literature that leadership emerge in groups very differently. In some situations, the communication group is dominated and controlled by the appointed leaders (Hambley, O'Neill, & Kline, 2007). In other situations, the leadership tends to be distributed among the group members (Carson et al., 2007; Zha & Ottendorfer, 2011). Future studies may combine our computational approach with other data sources to better examine the impact of these different leadership structure on individual and group performance.

In addition, the computational approach allows the assessment of team leadership at a fine-grained level. In this study, the leadership index allows us to study the developmental aspect of team leadership. We observed students' engagement over time, how they responded to being appointed moderators and clustered students based on their recorded patterns of leadership to further highlight specific profiles. We pre-processed the dataset to represent each student as a set of five observations: the leadership index scored during the week they were appointed peer-moderators – at the center, as a reference point – plus the two scores preceding and the two scores following that reference week. The derived feature vectors were then clustered using a k-means algorithm. The appropriate number of clusters, k, used in the analysis was determined by the gap statistic (Tibshirani, Walther, & Hastie, 2001). The plot of gap values as a function of the number of clusters is shown in Fig. 4, where k = 5 represents the first local maximum. From the figure it is also possible to notice how a slightly higher Gap(k) value is associated with higher cluster numbers, but considering the size of the standard error it would certainly imply overfitting. Therefore, five was chosen as our cluster number.

Fig. 4
Download : Download high-res image (59KB)
Download : Download full-size image
Fig. 4. Gap statistic of k-means cluster analysis.

The results of the k-means cluster analysis are graphically represented in Fig. 5, which presents together students with similar engagement trends along the five representative data points. The students appeared to be influenced in different ways by the mechanism of moderation appointment and few patterns were clearly distinguishable. Some students' behavior was only affected as long as they were acting as official moderators for the weekly discussions (cluster 2): their leadership index spiked while being appointed moderators, and stayed down before and after. Others, instead, appeared to carry over that behavior even after their turn was over and their leadership index remained relatively high after moderation week (cluster 4). For students of cluster 3, the opposite seemed true, as they displayed leadership before and up to moderation week, but disengaged from the activities right after. The first cluster grouped together the students with low leadership, while the last cluster was made up by students with persistently high leadership. These clusters show that emergent leadership in group learning is a social and developmental process and students develop their leadership in a variety of ways (Emery, Daniloski, & Hamby, 2011). Future studies may examine what factors influence the way that leadership emerge and how emergent leadership impacts student learning.

Fig. 5
Download : Download high-res image (90KB)
Download : Download full-size image
Fig. 5. Trends in students' leadership index.

Note: The five clusters are produced analyzing a 5-week vector of leadership indices (the index for the week they were appointed moderators, plus the two indices before and the two after that) using a k-mean algorithm.

5. Conclusions
This study examined student participation in structured tasks and peer-moderated online discussions as recorded by one course LMS and proposed a novel measure to detect leadership in group learning. It highlights the dynamic nature of leadership behavior, the result of both an explicit mechanism of appointment to moderating roles and social dynamic emerging from student interactions. The derived leadership index is the output of a methodology designed to minimize human intervention and expert judgement. Analyzing different linguistic patterns in the context of peer-moderated collaborative learning, the resulting classification is shown to perform in a way comparable to one produced by three researchers manually coding samples from the dataset, a conclusion that highlights the reproducibility of this study and analogous ones in the broader framework of learning analytics.

The leadership index, a single metrics based on text mining and social network analysis, is also intended as actionable information, suitable to be included in modern learning management systems in order to enhance their reporting and analytical features. A simple but timely signal of the degree to which a student engages in online classroom discussions could constitute the basis for interventions, some of which could be triggered automatically, aimed at retaining and sustaining their participation. Additional research would be required to assess the link between leadership index and performance of the entire group. For instance, future research could examine whether students that are very central to the group structure influence the participation of less central ones. However, that would confirm the role played by emergent leaders in group dynamics and further justify the proposed approach.

The present study has nevertheless a number of limitations. A set of limitations is due to the small size of the dataset and affects the generalizability of our results. We are aware that the performance of machine learning algorithms depends on the ability to extract a high number of meaningful features from student messages and that, to ensure robust results, it is necessary to replicate our study with datasets obtained by other online courses. But having based our approach on automated natural language processing makes replicating this study very affordable. Another limitation comes from the fact that by using a behavioral model of leadership based on the characteristics of appointed moderators our proposed methodology cannot say why a student is acting as a leader, only when and to what extent we should consider them one. In other words, the derived ranking order, as the classification algorithm for student messages, cannot inform us about the characteristics, linguistic or social, that make a specific message perform its function.

Nevertheless, having obtained good results with two different classification models, together with the application of inexpensive computational techniques based on social network analysis, we believe this study revealed interesting finding with promising practical application for online and distance education.

