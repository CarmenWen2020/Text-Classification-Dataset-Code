With regard to the implementation of Blended Learning (BL) in higher education, not much is known about the institution-wide participation status by the teacher, and ways to quantitatively assess such participation. This research first developed a framework for quantitatively assessing teachers' online participation in BL, and then evaluated it with data produced by 7272 teachers in 15,128 BL courses in six universities across China. This evaluation adopted a mixed methods design to investigate the intensity, regularity and interactivity of these teachers' online participation in BL. Three key findings emerged: 1) the framework effectively assessed the degrees and features of teachers' online participation in BL implementation, 2) these results advanced our understanding of BL adoption stages, and 3) the proposed framework proved to be technically adequate in assessing teachers' online participation in BL at an institutional level. Using this framework, institutions could gain a fuller picture of their BL implementation so as to refine their strategies and advance their BL agenda.

Keywords
Blended learning
Teacher online participation
Blended learning adoption stages
Online teaching presence
Quantitative analysis, framework proposal

1. Introduction
It would not be an exaggeration to say that Blended Learning (BL) has become an integral part of the 21st century education. It is a learning approach that seems to be widely adopted, yet it is often done so without a uniform definition. For this research, we adopted Graham's (2006, p. 5) broad definition that BL is a combination of “face-to-face instruction and computer-mediated instruction”.

In terms of institutional BL implementation, much of the current research has been centred around the three-stage framework proposed by Graham, Woodfield, and Harrison (2013), namely, Stage 1 - awareness and exploration, Stage 2 - adoption and implementation, and Stage 3 - maturity and growth. These studies include but are not limited to Taylor & Newton, 2013; Porter, Graham, Spring, & Welch, 2014; Porter, Graham, Bodily, & Sandberg, 2016; Porter & Graham, 2016). However, not much has been reported with regard to a comprehensive and quantitative assessment of the degrees and features of teachers' participation in BL at an institutional level, although scholars such as Porter and Graham (2016: p.749) have realized the importance of institution's identification of “their faculty's innovation status”. That said, there has been a great number of studies investigating teachers' technology adoption in teaching. However, some of these studies often focus on teachers' perspectives of or experiences in adopting technologies in teaching (e.g., Buchanan, Sainter, & Saunders, 2013; Oh & Park, 2009; Scott, 2013), while others investigate factors impeding or facilitating their adoption (e.g., Porter & Graham, 2016), or teachers' ICT competency (e.g., Sua'rez-Rodri'guez & Almeric, 2018). To our knowledge, no study has been published, quantitatively assessing the institution-wide status of teachers' BL participation and exploring the implications of such a status to the three key markers (i.e., strategy, structure and support) of the BL adoption stages proposed by Graham et al. (2013).

In addition, surveys and interviews are the most frequently used methodologies in existing BL research regarding institutional involvement. While they are important instruments for gauging individual opinions, different approaches are needed to complement one another in order to gain a fuller picture of BL implementation. In light of these needs, this research first developed a framework to quantitatively and objectively assess teachers' online participation in institution-wide BL implementation. The proposed framework was then evaluated through the assessment of the teachers' online participation in six universities across China. Findings from this research can not only be used to further refine the proposed framework, but can also be used by the institution as a reference when supporting the specific needs of teachers involving in different levels of online and blended learning. Moreover, such an evaluation can help institutions to gain a fuller picture of their BL implementation so as to improve/adjust their BL strategies and advance their BL agenda.

2. Literature review
2.1. Assessing institutional BL implementation
BL implementation at an institutional level has received considerable attention in the last few years as exemplified by a series of studies including West, Waddoups, and Graham (2007), Graham et al. (2013), Lim and Wang (2016), Porter et al. (2014) and Porter et al. (2016). Among them, the study by Graham et al. (2013) is the most frequently cited because of the three-stage framework they proposed for institutional adoption of BL in higher education. Based on the data from interviews with administrators of institutions of higher learning in the US, they identified three stages in an institution's BL adoption, that is, the awareness and exploration stage, the adoption and implementation stage, and the maturity and growth stage. Three key drivers that facilitate BL adoption were also identified, namely, strategy, structure and support. Each driver has its own set of subthemes. There are five subthemes in strategy including purpose, definition, policy, advocacy and implementation. Structure comprises governance, BL models, scheduling and evaluation. Support encompasses technical support, pedagogical support and faculty incentives. These three drivers and subthemes were then “differentiated across three stages of adoption to show how institutions move from interest in BL towards a mature institutionalization of it” (Graham et al., 2013, p.7). Applying this framework, a more recent study by Porter and Graham (2016) surveyed 214 teachers in an American University and analysed the faculty's perspectives concerning the factors that facilitated and impeded the faculty's BL adoption. This study found that adequate infrastructure, technological and pedagogical support, evaluation and an institution's purpose for BL adoption were the significant factors that influenced the faculty's involvement in BL. It also called for institutional identification of teachers ‘innovation adoption status and addressing the needs of innovation adopters at an institutional level.

Han, Wang, Li, and Cheng (2016) and Wang and Han (2017) extended these studies by applying this framework to the assessment of BL implementations in universities and vocational colleges in China. These studies validated the framework through the identification of the roles that the institution played in policy making, support strategy formulation and infrastructure renovation to promote and facilitate the implementation of BL. However, no quantitative assessment of institutional BL implementation has been found in the literature, and teachers' participation is not the focus of the above-mentioned studies.

2.2. Assessing teachers' online participation
Valuable as it is, the framework proposed by Graham et al. (2013) does not include the teacher as a key marker in assessing institutional BL implementation. In other words, the framework only addresses institutional measures to advance BL implementation, and keeps the teacher in the background. According to Rogers (2003, p.429), “One important factor in explaining the degree to which an innovation is sustained by an organization is participation, defined as the degree to which members of the organization are involved in the innovation process (Green, 1986)”. In this sense, we can argue that the degree of the success and sustainability of BL as a process of “diffusion of innovations” (Rogers, 2003), is largely determined by the degree of teachers' participation.

As this research only concerns teachers' online participation in BL, we turned to the Community of Inquiry model (CoI) for the theoretical underpinnings for this research. CoI, originally stemming from the work of John Dewer, sees educational experience as an interplay of three core elements of a learning community – cognitive, social and teaching presence. This model was later adopted by Garrison, Anderson, and Archer (1999) for the investigation of interaction in online discussions, and was subsequently employed by a number of studies relating to online learning (also see Anderson, Rourke, Garrison, & Archer, 2001; Shea, Li, & Pickett, 2006). Teachers' participation in online discussions was described as teachers' online presence in these studies.

Teaching presence in CoI is defined as “the design, facilitation and direction of cognitive and social processes for the purpose of realizing personally meaningful and educationally worthwhile learning outcomes” (Anderson et al., 2001, p.5). Shea et al. (2006, p.177) further argued that “active learning can be effectively orchestrated by the three elements of teaching presence: effective design, facilitation, and direction of cognitive and social processes on the part of online instructors”. According to Anderson et al. (2001), the process of design and organization begins well before actual online teaching and continues throughout the course. This includes curriculum design and redesign, resource development and building, setting up group and individual activities and providing guidelines and guidance for the use of different online tools. Facilitation refers to the teacher's interaction with students throughout the learning discourse, such as providing regular feedback on student progress, guiding online discussions and assessing students' progress. In direct instruction, teachers impart their subject matter knowledge and expertise with students directly.

Based on his factor analysis of over 200 student surveys, Shea (2006) combined facilitation and direct instruction into one construct and labelled it “directed facilitation”, claiming the two constructs, i.e., design and directed facilitation, better interpreted teaching presence in their study than the three constructs of design, facilitation and direct instruction. In our study, limited by the types of data we can collect from an LMS, teaching presence is operationalized as the design and facilitation of the online components of a blended learning course, with the understanding that facilitation includes all teacher-generated activities online apart from course design.

The direct and significant impacts of teaching presence on student learning have been validated by some studies (e.g., Garrison, Cleveland-Innes, & Fung, 2010; Richardson et al., 2015; Richardson, Besser, Koehler, Lim, & Strait, 2016; Shea et al., 2006; Shea & Bidjerano, 2009). Studies on teaching presence were also conducted outside the CoI research and a positive impact of instructors' participation in discussion forums on student engagement was established (e.g., Beer, Clark, & Jones, 2010). However, it has to be pointed out that these studies all investigated teaching presence in online discussions, not online teaching in the sense of BL per se, and none of them adopted a quantitative approach using teacher produced data. At an institutional level, we are still unclear as to what extent teachers have engaged with students online in BL implementation, especially in terms of the intensity, regularity, and interactivity of course design and facilitation. As BL is becoming more mature than 10 years ago, it is time that teachers' online presence was assessed more accurately and comprehensively in order to inform an institutional BL endeavour. To this end, the framework below was proposed and evaluated.

3. Proposing a framework for an institution-wide quantitative assessment of online teaching presence in BL
The above-mentioned gaps led this research to the development of a framework for quantitatively assessing teachers' online presence in BL at an institutional level. We need to point out at the outset that this framework only concerns the online component of teachers' BL participation as it would be beyond the scope and focus of this research to include an assessment of teachers' face-to-face teaching activities.

We argue here the more frequent, regular and interactive the teaching presence is, the more facilitating it would be to learner engagement. In other words, maintaining ongoing teaching presence in online learning is instrumental in building a supportive online learning community which would prevent students from disengaging from learning. In fact, this argument can readily find support in the literature relating to the importance of interaction between the teacher and student in online learning (see Swan, 2001; Ally, 2008, as an example). For example, the study by Shea et al. (2006) found a clear connection between teaching presence and students' sense of learning community. Sheridan and Kelly (2010) also found that clear course requirements, responsiveness to students' needs, timeliness of information, and instructor feedback are crucial success factors in online learning. Similarly, regular communication with the instructor and instructor feedback were among the top three students' expectations found in the study by Mupinga, Nora, and Yaw (2006). Ma, Han, Yang, and Cheng (2015) took a learning analytic approach to track and analyse the log data of teaching and learning activities in all the courses in one university in China, and confirmed that the teachers' preparation and support had a significant impact on student engagement.

Informed by these perspectives and the studies reviewed in Section 2, and through a preliminary analysis of the teacher-produced data in the BL courses offered by 395universities on a Learning Management System (LMS) called TsingHua Education OnLine (THEOL), we formulated a framework, named Quantitative Assessment of Online Teaching Presence (QAOTP) in institution-wide BL implementation (see Fig. 1). It consists of three key constructs– the intensity, the regularity and the interactivity. The degrees of each construct can be quantitatively assessed.

Fig. 1
Download : Download high-res image (121KB)
Download : Download full-size image
Fig. 1. The Framework for a Quantitative Assessment of Online Teaching Presence (QAOTP) in institution-wide BL implementation.

The intensity of online teaching presence can be assessed by the frequency of the teachers' overall course site visits in any given period of time (e.g., an academic year, or a semester). In other words, the more visits to the course sites, the stronger the online teaching presence would be in this period. Thus the frequency that teachers visit their course sites is a primary indicator of the developmental stages of BL at an institution. A more detailed picture can be depicted by grouping teachers according to the number of course visits and calculating the percentage of each group to see the frequency of course visits by a group. Here we would like to point out that this component of the framework only measures the frequency of teachers' course visits, rather than the duration of these visits. We recognize that the duration of teachers' course visits is also an important indicator of teachers' online presence but it is hard to measure accurately using log data alone. Nevertheless, future research could look into the duration of teachers' course visits as a complementary study to this framework.

The regularity of online teaching presence can be assessed by dividing the period under investigation into smaller time units and calculating the frequency of teachers' course visits in each unit. The unit can be a month, a week or any meaningful division of a time period. This is the second primary indicator indicating the level of BL normalization by checking the regularity or irregularity of the teachers' course site visits incrementally throughout the whole period under investigation. This will further explain the first construct by showing a more detailed course site visit status phase by phase. Hypothetically and ideally, along with the normalization of BL, in normal teaching weeks (excluding exam and self-study weeks) in a semester, the total number of teachers' visits to their course sites as a whole should be more or less evenly distributed throughout the normal teaching weeks. The rationale is that after teaching begins, teachers should moderate and/or teach the course online on a regular basis to maintain student engagement during this period of time. Thus, if the total number of teachers' course visits for the whole institution is 100% for the teaching weeks in a semester, the average percentage of visit per teaching week should be 100% divided by the number of teaching weeks in the semester. This average can be used as a baseline to judge the regularity of institution-wide teachers' online participation phase by phase. Deviation from this baseline could be used to alert the institution to the emergence of possible issues in its BL implementation in a particular period.

The third construct seeks data on the level of interactivity that a teacher engages students online. As the QAOTP framework uses the log data from an LMS, it is not easy to determine the depth of the interactivity of an action generated by a teacher. Thus, the interactivity construct is only qualified as being non-interactive or interactive. As mentioned above, teaching presence in this research only concerns the design and facilitation of online learning in a BL course. Teaching activities in the design category are usually non-interactive, while in the facilitation category, teachers engage learners in either interactive or non-interactive fashion. The interactivity construct should cover all the activities generated by the teacher in course design and facilitation, both interactive and non-interactive. Our assessment of all the courses on THEOL and some of the courses on Blackboard captured the types of key activities generated by the teachers, as summarized in Table 1. Those activities can be used as a reference by individual studies.


Table 1. Categories and Indicators of online teaching activities in the interactivity construct of the QAOTP framework.

Category of online teaching activities	Indicators
Non-interactive	Setting up/updating teachers' information
Design course site structure (e.g., creating content links and folders, designing course navigation)
Creating online learning spaces (e.g., online classrooms, discussion forums, blogs)
Creating/updating online learning content (e.g., lecture notes, PowerPoint slides, mini video lectures, online quizzes, links to online resources)
Creating/updating assessment items (e.g., test briefs, online submission mechanisms)
Uploading homework requirements
Uploading/updating learning resources such as lecture notes, PowerPoint slides
releasing online tests
Uploading test results
releasing course surveys
posting discussion topics (on Discussion forum or blogs)
Sending out announcements
Online marking
Interactive	replying to students ‘posts (e.g., on Discussion Form or blogs)
answering student questions in Q/A
Providing feedback on student work
Facilitating online teaching in synchronous online classrooms (e.g., Blackboard Collaborate)
This construct should also cover the frequency of each activity during the period under investigation to further explore the features and levels of interactivity. Our rationale for this is that the more frequently the teacher interacts with students, the stronger the interactivity is. We also hypothesize that the more non-interactive the online teaching activities are, the weaker the teaching presence. By the same token, the more interactive the online teaching activities are, the stronger the online teaching presence.

In summary, the three constructs in the QAOTP framework should be equally important and indispensable. They complement one another in generating a more accurate and comprehensive picture of the degrees and features of online teaching presence than a single construct is able to achieve. That said, this is only an overarching framework that is designed with special attention to its applicability and replicability in that all three dimensions are only broadly defined with no specific requirements for how data should be categorized and treated. This leaves room for individual studies to interrogate their specific data within the broad boundaries of this framework.

4. Methods
4.1. Purpose
This research aims to propose and evaluate a framework for assessing online teaching presence in institution-wide BL implementation. Results from this evaluation were analysed to inform the following research questions:

1.
To what extent does the proposed framework help us to assess the intensity, regularity and interactivity of online teaching presence in institution-wide BL implementation?

2.
How does the proposed framework advance our understanding of the stages of BL implementation at an institutional level?

3.
Is the framework technically adequate in facilitating our understanding of online teaching presence, in terms of its ease of use, accuracy and efficiency in data collection and analysis, customizability, and replicability? If so, in which ways? If not, in which ways?

A mixed methods design was adopted to answer these research questions. Thus both qualitative and quantitative data were collected and analysed. During data analysis, comparisons of online teaching presence were made between the universities and between the three BL stages in order to better explore the depth and breadth of teachers' online participation.

It is hoped that this research will add a new dimension, the teachers' participation, to the three indicators (strategy, structure and support) of BL adoption proposed by Graham et al. (2013). It is also hoped that the proposed framework will be effective in facilitating future research into teachers' online participation and advancing our understanding of this important dimension in BL development so that institutional support can be offered in a timely manner and student learning can be improved.

4.2. Background and research procedures
BL adoption in Chinese higher education started roughly around the turn of the century when the Ministry of Education promoted the installation of Learning Management Systems (LMS) in universities throughout China (Han et al., 2016). THEOL, one of the LMSs, is used by over 500 institutions in China, and in the past 15 years or so, our research team has been dedicated to the support of each institution's course development on THEOL. Our support includes course design guidance, teacher training, ongoing professional development and evaluation of BL courses. This level of involvement with each institution's BL adoption provides us with good knowledge of their BL implementation progress. This knowledge and our understanding of the three-stage framework informed our initial selection of eight universities which we believed formed a representative spread of the universities across the three BL stages (Awareness/Exploration, Adoption/Early implementation, and Mature implementation/Growth). We then emailed a consent form to each of the eight universities explaining our research focus and inviting the universities to participate in this research in two ways: 1) allowing us to use the log data of their BL courses offered on THEOL; 2) providing further information regarding their BL implementation strategies, structures and support mechanisms. All the eight universities signed the consent form. We did not seek consent from individual teachers as data in this research were presented in an aggregated form without identifiers linked to any individual teachers or courses. To compare online teaching presence in different BL stages, we needed to first classify the universities into stages. Thus four raters trained by the research team started the initial classification, independently identifying which of the three stages a university should be in (please see Section 4.3 below for detail). After several rounds of comparison and discussion of the four raters' classification results, a consensus was reached on the classification of six of the eight universities. These six were then chosen for this study. The other two were excluded due to inter-rater disagreements on their BL adoption stages. To protect their anonymity, the six universities are represented here as University A, B, C, D, E, and F.

To reduce variables and ensure comparability, we made sure that all six universities are comprehensive universities offering both STEM and STEAM courses. A survey was then sent to the administrative departments of each university, seeking confirmation regarding the total number of years of BL implementation, the number of teachers teaching online and the BL courses offered on THEOL in the fall semester between September 2017 and the end of January 2018. Table 2 summarizes the data we received from each university.


Table 2. General BL implementation information of the six universities in the fall semester of 2017.

University	No. of years of BL implementation	No. of teachers teaching BL courses	No. of BL courses
A	2 years	289	518
B	1 year	1280	2871
C	5 years	1464	2964
D	12 years	1370	2748
E	8 years	1588	3139
F	3 years	1281	2888
Total	7272	15,128
4.3. Data collection
4.3.1. Qualitative data collection
The qualitative data we collected included policy documents obtained from the IT and administration departments of each university regarding their strategies (e.g., BL policies, advocacy and purpose), structures (e.g., BL models, evaluations and infrastructure building) and support mechanisms (e.g., grants, IT support, support from blended learning advisors, university incentive schemes). Such information was also triangulated with data collected on each university's LMS, including the announcements published on the universities course sites relating to BL course development initiatives, teacher training and professional development, support and incentives etc. These data were organized using the matrix developed by Graham et al. (2013, p.7) as shown in Appendix 1, and the matrix was applied to the classification of the stage that each university should be in. Following this initial assessment, we emailed a checklist to the administrative and IT departments in each university seeking their confirmation of the indicators that marked their university's progress in BL up to the end of January 2018. The checklist contains similar key indicators to those in Appendix 1. The data collected through the checklist were then compared with the information used for the initial classification. Telephone interviews were conducted when information was missing or unclear in the completed checklists.

During our classification, we found that the three-stage framework proposed by Graham et al. (2013) was useful for analysing the features of each stage. However, when it came to classifying a university into a distinct developmental stage, it could only be used as a reference as BL is a complex and dynamic process, and the boundaries between stages are not as discrete as suggested in the framework. There was overlapping in certain categories and stages, and discrepancies in others. This was especially true with universities in transiting stages such as universities B、C、D and E. It was relatively easy to identify starters and mature adopters of BL as in the case of universities A and F. In view of this complexity, we eventually used a scoring system to decide on the BL status of a university. To be more specific, the more indicators that a university had for one stage, the higher the score would be for that university. The highest score gained in a stage for a university would determine the stage that the university would be in. This process resulted in the classification of University A and B to Stage 1, University C and D to Stage 2 and University E and F to Stage 3. The inter-rater agreement reached 100%.

4.3.2. Quantitative data collection
Following the QAOTP framework, three groups of data regarding teaching presence were collected from the six universities' BL courses offered in the fall semester in 2017, namely, teachers' overall course visit status, teachers' weekly course visit status, and teachers' online teaching activities. These were all teacher-produced data collected from the log files of the six universities on the THEOL LMS.

To understand the intensity of teaching presence, we collected the number of teachers' visits to all the BL courses in each of the six universities throughout the semester, covering a total of 15,128 courses and 7272 teachers. Following this, data assessing the regularity of online teaching presence were collected in the form of the frequency of teacher's weekly course site visits, focusing on the 16 teaching weeks excluding the two weeks for self-study and two weeks for examinations. Data regarding the interactivity construct came from the online teaching activities in each of the 15,128 courses offered on THEOL. These data covered 14 kinds of activities (see Table 3). We first grouped these activities into two categories, non-interactive and interactive, and then further divided the data into three groups, two under the non-interactive category, labelled as “course structure and content design”, and “non-interactive facilitation”, and one under the interactive category, labelled as “interactive facilitation”.


Table 3. Categories and data sources of online teaching activities in six universities.

Category of online teaching activities	Indicators	Data source (log data from THEOL)
Course structure and content design	Setting up/updating teachers' information	1) updating teachers' information
Design course site structure (e.g., creating content links and folders, designing course navigation)	2) Creating teaching resources
Creating online learning spaces (e.g., discussion forums, blogs)
Creating/updating online learning contents (e.g., lecture notes, mini video lectures, online quizzes, links to online resources)
3) Creating mini video lectures
Creating/updating assessment items (e.g., test briefs, online submission mechanisms)	4) Creating assessment items
Non-interactive course facilitation	Uploading homework requirements	5) Uploading homework requirements
releasing online tests	6)Uploading online tests
Uploading test results
releasing course surveys	7) releasing course surveys
posting discussion topics (on Discussion forum or blogs)	8) posting discussion topics
9) posting blogs
Sending out announcements	10) Sending out announcements
Online marking	11) sharing teaching reflections
Interactive course facilitation	replying to students ‘posts (e.g., on Discussion Form or blogs)	12) replying to students ‘posts (e.g., on Discussion Form or blogs)
answering student questions in Q/A	13) answering student questions in Q/A
Providing feedback on student work	14) providing feedback on student homework
Note: No data on synchronous online teaching are included in this table as no synchronous online classroom was offered on THEOL.

4.4. Data analysis
4.4.1. Assessing the intensity of online teaching presence in BL implementation
For ease of analysis, we categorized the 7272 teachers into four groups according to the number of course site visits in the semester, i.e., inactive adopters, less active adopters, active adopters and mature adopters. We calculated the percentages of each group in each university and compared them across the six universities. Table 4 summarizes the attributes of each category of adopters.


Table 4. Categories of BL adopters based on the number of course visits.

Category	Number of course visit per semester	Characteristics
Inactive adopters	1–14 visits	They adopted blended learning but stopped visiting the course site at some stage during the semester. Online teaching presence ceased.
Less active adopters	15–48 visits	They reached the minimum number of course visits required for BL. Online teaching presence was low and mostly non-interactive.
Active adopters	49–80 visits	They visited the course sites more than 3 times a week. Online teaching presence was stable, both interactive and non-interactive.
Mature adopters	Over 80 visits	They visited the course sites almost every working day. Online teaching presence was frequent, both interactive and non-interactive.
This categorization was based on the assumption that the minimum number of course visits was 3 per week, being twice before class for making announcements and assigning learning tasks, and once after class for checking and assessing students' homework. Thus, the minimum total number of course visits should be 48 per course in a 16 teaching week period. Here we referred to the BL definition by Allen and Seaman (2003, p.6) as a reference to determine the minimum number of course visits per semester. That is, a BL course should have 30% -79% content online. Thus, the minimum number of course visits used for this research is 14.4 (48*30%) per semester. We recognized that this classification was arbitrary, and only served the purpose of visualizing our data for a better understanding of the intensity of teaching presence.

4.4.2. Assessing the regularity of online teaching presence in BL implementation
To assess the regularity of the teachers' course site visits at an institutional level, we divided the 16 weeks into four periods, for ease of analysis. If we normalized the total number of course visits by the teachers during the 16 weeks as 100%, the average percentage of the teachers' course visits for each of the four periods should be 25% as shown in Table 5. This was based on the hypothesis that a sustained online teaching presence should be established to facilitate leaner engagement when BL has become normalized in day-to-day teaching, resulting in a more regular course visit pattern when all the BL courses are considered. At the same time, we recognize that there are many factors affecting the teachers' course visit patterns. For example, a course can be designed in such a way that online activities were more intensive by design in certain periods during a semester. However, as we focused on all the BL courses in an institution, rather than individual courses, the aggregated big data should be able to mitigate individual course differences. Nevertheless, in view of these complexities, we suggest that this baseline should only be used as a reference point for gauging the regularity of institution-wide teachers' online activities. Deviations from the baseline should be carefully interpreted taking specific course or institution related factors into account.


Table 5. The baseline for teachers' course visits during a semester.

Period	Period 1: Weeks 1–4	Period 2: Weeks 5–8	Period 3: Weeks 9–12	Period 4: Weeks 13–16
Baseline	25%	25%	25%	25%
The deviation of teachers' course visits during each period was worked out according to the following formula:

B represents the deviation for a given period, while ∑is the sum of the squared difference between the institution-wide percentages of course visits in any given four-week period and the baseline (25% in this case). Pi represents the average percentage of course visits per period by all the teachers in an institution, and Po is the baseline percentage, i is any given teaching period in a semester, and n is the last period in a semester. The greater the value of B has, the greater the deviation, and the lower the goodness of fit.

4.4.3. Assessing the interactivity of online teaching presence in BL implementation
When assessing the interactivity of online teaching presence, we first grouped the 14 kinds of activities contained in Table 3 into three broad sets, namely, course structure and content design, non-interactive course facilitation and interactive facilitation. Then we used the log data showing the number of times a particular action was performed by a particular teacher to calculate the frequency of action for each of the three groups of activities for each university. We hypothesize that the more interactive the teaching activities are, the stronger the teaching presence.

5. Results
This section presents the data collected and initial discussion of findings with regard to the three dimensions in the proposed QAOTP framework. Findings were compared between the universities to better understand the degrees and features of the teachers' engagement in BL. Reasons for the features were also probed and discussed together with our qualitative data. Furthermore, findings were also corroborated between the three dimensions in the QAOTP framework for a more accurate and in-depth understanding.

5.1. Overall course site visits by teachers in the six universities
That is, the two universities (A and B) in Stage 1 had the lowest percentages of course visits by the three adopter groups (less active, active and mature) over the threshold of 14.4 per semester (18% (9% + 3% + 6%) and 14% (6% + 2% + 6%) respectively). In contrast, the two universities in Stage 3 had the highest percentages in this regard with 51% (24% + 11% + 16%) for University E and 57% (21% + 13% + 23%) for University F. Although there is a considerable difference between the two universities in Stage 2 in terms of the total percentages of teachers' course visits above the threshold, both universities had lower percentages (34%; 48%), when compared with Stage 3 universities. University A also had the highest percentage for Non-Adopters (38%), perhaps because they did not implement BL until 2016. A closer examination of the percentages in Fig. 2 also reveals that, among the six universities, University F had the largest number of Mature Adopters (23%) and Active Adopters (13%) while University B had the smallest number of Mature Adopters (6%) and Active Adopters (2%). However, the two universities in Stage 2 exhibited a more complex picture. The overall statistics for University C indicated that this university was in the early stage of Stage 2, with a low percentage for adopters visiting the course sites more than three times per week (20% Less Active Adopters, 5% Active Adopters and 9% Mature Adopters), and 59% became inactive during the semester. In comparison, University D appeared to be at the higher end of Stage 2, leaning towards Stage 3, similar to those of University E.

5.2. Weekly course site visits by teachers in the six universities
Fig. 3 summarizes the percentages of teachers' course visits during each of the four periods in the six universities, and Table 6 provides the deviation percentages for each of the six universities.

Fig. 3
Download : Download high-res image (154KB)
Download : Download full-size image
Fig. 3. Teachers' course visits in the four periods in the fall semester of 2017.


Table 6. Deviations of teachers' course visits in the four periods in the fall semester of 2017.

Stage	University	Period 1: weeks 1–4	Period 2: weeks 5–8	Period 3: weeks 9–12	Period 4: weeks 13–16	Deviation from the base-line
Stage1	A	27.78%	18.34%	28.92%	24.96%	0.67%
B	20.98%	35.90%	26.76%	16.36%	2.13%
Stage2	C	37.72%	22.23%	21.23%	18.83%	2.22%
D	32.01%	22.92%	26.90%	18.16%	1.04%
Stage3	E	21.62%	24.97%	32.59%	20.82%	0.87%
F	26.64%	10.39%	28.94%	34.02%	3.13%
In brief, Table 6 and Fig. 3 demonstrate that University A had the best goodness of fit with 0.67% deviation, followed by University E (0.87%), while University F had the greatest deviation (3.13%), with Universities C and B in tow. However, the greatest deviation happened in different periods for different universities with University F in Period 2 (10.39%), University B and C in Period 4 (16.36% and 18.83%, respectively).

The presented data above indicate that the course visit deviation could happen to any university in any of the four periods. For example, the greatest deviation among all the universities happened to University F, a Stage 3 university. Their course visits by the teachers were all well above the baseline with the exception of period 2 when there was a sharp decrease to 10.39%. Our interview with the manager of the university's IT support unit confirmed that this decrease was mainly caused by restricted access to the university's intranet due to reasons beyond the university's control.

The case was different for University B's drop in course visits from 26.76% in Period 3 to 16.36% in Period 4, the lowest among all the universities in this period. Cross-checking with Fig. 2, we found that a large number of teachers (73%) became inactive after their first attempt at BL (see Fig. 2), which might explain why the course visits plunged by more than 10%. Furthermore, our qualitative data show that this university just started BL in the fall semester of 2017. Although strong strategies, structures and support were in place, the instability of their intranet in the first 4 weeks of the semester affected the teachers' active online access to their courses. However, teachers' course visits peaked in Period 2 reaching 35.90%, the highest in the same period among all universities, and maintained above the baseline in Period 3 thanks to the strong institutional support and the need for course site design and online content development. This need was further attested by Fig. 4 showing that 76.47% of teachers' online activities were course building. Thus the fact that this was the first semester of their BL implementation could explain this uneven distribution of the teachers' course visits.

Fig. 4
Download : Download high-res image (131KB)
Download : Download full-size image
Fig. 4. Percentages of online teaching activities regarding course structure and content design, non-interactive course facilitation and interactive course facilitation.

5.3. Online teaching activities in the six universities
Three groups of data are presented in Fig. 4, the percentages for course structure and content design, non-interactive course facilitation and interactive course facilitation, for each university.

As shown in Fig. 4, the two Stage 1 universities had the highest percentages in instructional course design (88.65% and 76.47%), distinctively contrasting with those for Stage 3 universities (28.23% and 23.32%). In terms of interactive course facilitation, the opposite trend emerged, with the two universities in Stage 3 showing much stronger interactive course facilitation (65.74% for University E and 71.21% for University F), forming a sharp contrast to the very weak interactive teaching presence in the Stage 1 universities (7.38% and 18.31%). Again, a discrepancy existed between the two universities in Stage 2, with University D showing a much stronger interactive teaching presence, even stronger than that of University E, a Stage 3 university.

5.4. Analysis of key findings about the BL implementation in the six universities
In this section, we analysed the key findings derived from data collected using the proposed framework. In this analysis, we triangulated data regarding the three constructs, namely, intensity, regularities and interactivity, and supplemented our quantitative data with the qualitative data we collected from each university, wherever needed.

Finding 1: Using the QAOTP framework, we were able to conclude that the overall online teaching presence proved to be in conformity with the stages that the universities were categorized to be at in accordance with the three-stage framework proposed by Graham et al. (2013). To be more specific, universities in earlier stages of their BL (e.g., Universities A, B and C) exhibited lower percentages of mature and active adopters and a larger portion of course design and building in teachers' online activities. On the contrary, universities in more advanced BL stages (e.g., Universities D, E and F) showed higher percentages of mature and active adopters and more interactive course facilitation emerging from their teachers' online activities.

University F exemplified Stage 3 well. Both its mature and active adopters achieved the highest percentages among all universities (23% and 13% respectively), with the total (36%) exceeding one-third of its total number of teachers. More than half (57%) of its teachers accessed their course sites at least three times a week. It also had the smallest percentage of Inactive Adopters. The strong teaching presence was further confirmed by its online teaching activities. Fig. 4 shows that this university had the highest percentage of interactive course facilitation, an important indicator of mature BL implementation. According to our qualitative data, this university initiated their BL policies and support in November 2014 and formally started teaching in BL mode in the spring semester of 2015. Since then, it had established various university-wide BL support mechanisms including grants dedicated to BL implementation to support individual course reform and innovations. They also evaluated those grant-supported courses at the beginning and end of each semester. This could be one of the reasons for the increased number of course visits in the fourth period.

In contrast, University A in Stage 1 represents the opposite end of the spectrum with the highest percentage of Non-adopters (38%) and the lowest percentage for Mature Adopter (6%). As many as 43% became inactive during the semester. Only 18% of adopters accessed their courses more than three times per week. Fig. 4 also shows that course structure and content design accounted for 88.65% of its online teaching activities. All these data suggest an early BL adoption status, which was confirmed by the fact that its BL adoption did not start until 2016.

Finding 2: An uneven distribution of course visits appeared throughout the semester in all the universities. More specifically, both Fig. 2 and Table 6 show that teachers' weekly course visits could deviate from the baseline in any of the four periods. Such data can be useful for the institution to pinpoint the causes for the disruption to regular course visits and intervene timely.

Finding 3: The boundary between the stages of BL adoption is not clear-cut. This finding features strongly in Stage 2 universities. University D is a good example. Although being classified as a Stage 2 university, its percentages for the different adopter groups were very similar to those of University E in Stage 3, and its percentages for interactive course facilitation was even slightly higher than University E. This strong online teaching presence was probably brought about by its 12 years of BL implementation. Although its strategy, structure and support were not as strong as those of University E, only suggesting a Stage 2 status for this university, BL had become more or less normalized in the past 12 years at this university. This finding has important implications for the classification of a university into a stage.

Finding 4: Our data indicate that a top-down approach characterised the BL implementation in all of the six universities, forming a distinct contrast to what has been reported by studies regarding BL in the US higher education sector (see Graham et al., 2013; Porter et al., 2014). For all six the universities, strong strategy, structure and support, were in place well before the teachers embarked on BL design and implementation. In addition to advocacy and policies, different levels and forms of ongoing support were also available university wide. Such strong institutional support is one of the important reasons for University A, although still in Stage 1, to maintain the best goodness of fit in terms of teachers' weekly course visits throughout the semester, and teachers' course visits were above the baseline in the first 4 weeks as several BL courses had been piloted the year before. Seeing a slight decrease in teachers' course visits between weeks 5–8, the university offered a professional development program training teachers in developing and managing online learning, towards the end of week 8. This triggered more course visits by dedicated teachers, reaching above the baseline in weeks 9–12, and hovering around the baseline in weeks 13–16. In addition, the end-of-semester evaluation of the BL courses also sustained the teachers' regular online activities. The effect of the top-down approach was more reflected in the institution-wide adoption in Stage 1, as in the case of University B, with as many as 87% of its teachers engaged in BL at different levels in their first semester of BL implementation (see Fig. 2). A strong institutional role was also exemplified in the case of University E, a Stage 3 university, which achieved the second best goodness of fit in weekly course visits by the teachers. Since 2010, the university further improved its online learning approaches and promoted BL at both the university and department levels through workshops and seminars. Different models for BL design were offered, recognizing the special needs of different disciplinary areas. The university ensured that their BL courses were evaluated by external BL experts, teachers and students each semester. Overall, both our qualitative and quantitative data suggest that BL had been normalized throughout the university.

6. Discussion
As mentioned before, the aims of this research were twofold: to develop a framework for quantitatively assessing teachers' online participation in institution-wide BL implementation and to evaluate the effectiveness of this framework. These aims were achieved and important findings have emerged from this research that are worth further deliberation to see in what ways they answered the three research questions. The implications and significance of these findings were also discussed in this section, with reference to existing literature whenever appropriate.

6.1. Findings regarding research question 1: the extent to which the QAOTP framework assesses online teaching presence in institution-wide BL implementation
The QAOTP framework proved to be effective in assisting our assessment and in advancing our understanding of the degrees and features of institution-wide teachers' online participation in BL. The intensity construct enabled us to see how active the teachers were in their day-to-day interaction with the students throughout the semester, whereas the regularity construct afforded us a closer look at such interaction period by period during the teaching weeks. Such information would facilitate a more accurate and deeper understanding of teachers' course site visit frequency so that informed support can be offered in a timely fashion if problems are detected. The interactivity construct brought our examination to the activity level revealing what the teachers actually did and how they behaved online to design and facilitate student learning. Such information shed light on the patterns and levels of the teachers' interaction with the course and students, although the impact of such interaction on students' learning could not be readily gauged from this type of platform data. Thus we can conclude that the three constructs complemented one another to paint a well-defined and comprehensive picture of the teachers' online participation in each stage of the BL implementation.

Such large-scale quantitative data enabled us to make various robust and objective comparisons between the three constructs, between the three stages and between the six universities, providing much-needed insight into the breadth, depth and features of the teachers' online engagement in different stages of BL implementation. In turn, such an insight can inform the prediction of the success or failure of a university's BL implementation and help the university administration to refine and target, with more precision, their strategy, structure and support. In fact, this research corroborated with Long and Siemens' (2014) recognition of the benefits of using learning analytics in higher education, particularly in terms of informing holistic decision making and resource allocations, and determining the value generated by teacher activities.

6.2. Findings regarding research question 2: the ways in which the QAOTP framework facilitates our understanding of the stages of BL implementation at an institutional level
The QAOTP framework allowed us to assess the stages of BL implementation through the lens of online teaching presence, complementing what could be assessed by Graham et al.'s (2013) framework alone. Findings from the evaluation of the QAOTP framework advance our understanding of institution-wide BL implementation in a number of ways.

Firstly, our findings enriched the three-stage framework of BL adoption. The validity of the three-stage framework by Graham et al. (2013) was further confirmed in that the overall online teaching presence for each of the six universities largely matched the stages they were classified to be in. That is, the more advanced stage a university was classified to belong to, the stronger the overall online teaching presence was, and vice versa. This was evidenced by the increase in the number of mature and active adopters and more intensified interactive course facilitation along with the maturity of the universities' BL implementation. This characteristic applies more distinctively to Stage 1 and Stage 3 universities than to Stage 2 universities.

Nevertheless, this finding does not mean that the boundary between the stages of BL adoption was easy to define. In fact, Graham et al. (2013, p.11) also recognized that the boundary of the stages was “fuzzy”. When classifying the universities into stages, we also found it hard to categorize some universities into a stage as they had indicators of more than one stage. This was especially true of those universities in the transition from one stage to another, universities such as C and D. Take University D as an example, it's strategy, structure and support were only indicative of a Stage 2 university, whereas the university's quantitative data show strong traits of a university in Stage 3. This is not surprising as BL is a complex and dynamic system that constantly changes (Wang, Han, & Yang, 2015).

The above finding led to the second contribution of this research to the study by Graham et al. (2013). That is, teachers' online participation should be regarded as an important marker when assessing the progress of an institution's BL adoption. Their three-stage framework is particularly useful when using institutional implementation markers such as strategy, structure and support, to classify and describe an institution's BL adoption status. However, it does not assess whether or to what extent, the strategy, structure and support were implemented at the teaching level. We argue that as BL advances, more factors should be taken into consideration when evaluating what has been achieved after strategy, structure and support have been in place in an institution, in particular, the degrees of involvement on the part of the teacher and the learner as they are integral to the BL system (Wang et al., 2015). In fact, the crucial role that teachers play in the success of BL has been widely recognized in the literature (e.g., Garrison & Vaughan, 2012) as Lim et al. (2016, p.10) pointed out that “without highly motivated, dedicated and well-prepared teaching staff, blended learning initiatives in HEIs [Higher Education Institutions] are most likely to fail”. Thus, online teaching presence should be regarded as a key indicator signifying the stage into which an institution has progress to.

Thirdly, using a quantitative approach, the QAOTP framework enabled us to gain a fuller and more accurate picture of the BL implementation progress in an institution, in comparison to the qualitative nature of Graham et al.'s (2013) framework. In other words, the proposed framework complements the existing qualitative approaches and adds a new and important dimension to the evaluation of institutional BL implementation.

6.3. Findings regarding research question 3: the technical adequacy of the QAOTP framework
By technical adequacy, we refer to the framework's ease of use, accuracy and efficiency in data collection and analysis, customizability, and replicability. This will be discussed together with its limitations.

In terms of ease of use, the QAOTP framework allowed us to gather large data sets easily in an efficient manner as teacher-produced data are readily available and trackable in an LMS. Tapping into such data takes much less time than conducting interviews and surveys. Such data can also be more objectively assessed through computational analysis to reveal patterns of online behaviours, and the analysis can be visualized easily through diagrams and graphics, and compared with baseline information to inform practice.

Generic in nature, the framework engenders the flexibility of being customizable by individual studies. This is best exemplified in its accommodation for our adoption of the three-stage framework in our data analysis. Classifying the universities into different stages allowed us to leverage our qualitative data when interpreting the quantitative data gathered using this framework. The proposed framework also has room for us to group the teachers into different levels of adopters (mature, active, less active and inactive) and examine each group in more depth to generate a more accurate picture of the intensity of online teaching presence. Such data should be particularly useful for institutions to identify individual faculty innovation status and needs, and provide support at the precise time needed.

Replicability is another feature that the framework offers as it is straightforward and the study can be easily repeated by future studies, including studies on fully online teaching and learning. Data relating to the three broad constructs of the framework can be easily tracked and quickly collected from an LMS as they are existing teacher-produced data. Furthermore, the framework does not specify how data should be analysed, leaving room for future adaption by individual studies according to their own needs.

However, the types of data collected through the framework can only provide numerical descriptions of what teachers do online in terms of the three constructs. What the framework cannot reveal is the context, causality and attitudinal aspects of teachers' behaviours. This is why we used qualitative data to further interpret what we found in our quantitative analysis. Furthermore, this framework only concerns teachers' online behaviours and interaction with students. To understand teachers' overall participation in BL, the face-to-face component of the teaching in BL should also be assessed. However, such an assessment is beyond the scope of the current study.

7. Conclusions
This research first proposed a framework for assessing teachers' online presence quantitatively, and then applied the framework to the evaluation of teachers' online presence in institution-wide BL implementations in six Chinese universities, to test the soundness of the framework. The effectiveness of this framework was confirmed through the course of this evaluation as the three dimensions, i.e., the intensity, regularity and interactivity of online teaching presence, informed and complemented one another to depict a detailed picture of the teachers' online engagement with BL in each university. Understanding teachers' participation in BL adoption would help institutions to develop more effective and targeted strategies, structures and support mechanisms to advance their BL agenda and sustain BL development. This framework also proved to be easily replicable, reliable and flexible, and can be applied to any quantitative analysis of teachers' online participation and behaviour patterns.

In this evaluation, we also drew from the three-stage BL adoption framework proposed by Graham et al. (2013) and used it as a reference when discussing our findings. We found that the framework was particularly valuable in providing a context for this research to examine and compare data regarding universities at different phases of their BL development. However, we also found that the accuracy of the BL stage classification could be improved by including more indicators such as the teacher's and learner's engagement levels in BL. However, with the focus of this study being on online teaching presence, we could not accommodate the face-to-face teaching and learner factors in this study. Future research could adapt the QAOTP framework to assess learners' BL participation to further facilitate our understanding of institution-wide BL implementation progress.