The purpose of this study was to identify the course design, assessment and evaluation, and facilitation practices from the perspectives of award-winning online faculty. Aligned with this purpose, we developed a conceptual framework focused on online course design, assessment and evaluation, and facilitation; and review relevant literature in light of this framework. We interviewed eight award-winning online faculty members from across the United States. These faculty received online teaching awards from one of the following professional associations: Online Learning Consortium (OLC), Association for Educational Communications and Technology (AECT), or United States Distance Learning Association. Based on the interviews, it was found that online instructors use a systematic design process, backwards design, considered learner needs, and designed learner interaction during the design process. Faculty recommended using a variety of assessments, using traditional and authentic assessments and used rubrics to assess students, course templates and quality assurance process and surveys, learning analytics, and peer reviews for assessment and evaluation. Timely response and feedback, availability and presence, and periodic communication were some facilitation strategies the award-winning instructors used. We discuss these findings and provide suggestions for future research and practice. These findings can add to what is known about effective online teaching best practices, standards, and competencies.

Previous
Next 
Keywords
Award-winning faculty

Online teaching

Course design

Online assessment

Evaluation facilitation strategies

Qualitative research

1. Introduction
As online learning continues to mature and evolve in higher education, both faculty and supporting staff (e.g., instructional designers, developers and technologists) need guidance on how to best design and deliver effective online courses. Recent reports show that online enrollments in institutions of higher education in the United States have continued to grow with approximately 31.6% of all higher education enrollments in 2016, which is a 4.5% increase from 2012 (Seaman, Allen, & Seaman, 2018). Although online environments continue to grow, faculty can be resistant to the adoption of online courses because of a number of perceived barriers, including perceived barriers to student success in online classes, uncertainty about their image as online instructors, technical support needs, and their desire for reasonable workload and manageable class enrollments in online classes (Wingo, Ivankova, & Moss, 2017). Notably, experienced online faculty have noted several supports institutions of higher education can provide to assist faculty with online course design and delivery, ranging from release time to the engagement of support staff (e.g., instructional designers, developers and technologists) to assist in the full life-cycle of an online course (Wingo et al., 2017). In the spirit of gaining insights from experienced online faculty, this paper extends the idea to those faculty members in our community recognized for exemplary practice and excellence on the design and delivery of effective online courses, or more specifically, faculty who have won awards from established professional associations for online teaching.

Award-winning online faculty are an untapped source of useful insights and practices on how to best design and deliver effective online courses. Along these lines, the notion of collecting useful information from “award-winning” faculty is not a new idea, and has been firmly grounded in higher education teaching practices in several published research studies as early as the 1990s (Dunkin & Precians, 1992; Kember & McNaught, 2007; Morris & Usher, 2011), even in the domain of online learning in more recent history (Bailey, 2008). These award-winning faculty perspectives can be translated into actionable and valuable best practices, standards, and competencies for faculty designing and delivering online courses in institutions of higher education. Best practices in online courses are commonly shared in peer-reviewed academic journals, and are read and practiced by both faculty and instructional designers to create effective online courses (Fish & Wickersham, 2009; Keengwe & Kidd, 2010). Award-winning faculty can offer guidance on online course standards (e.g., Quality Matters), which are commonly used to assess quality and guide the production of online courses in higher education (Baldwin, Ching, & Hsu, 2018). Effective online teaching practices from award winning faculty can be used by administrators, instructional designers, and faculty to plan relevant professional development experiences for faculty teaching online (Baran & Correia, 2014; Baran & Correia, 2017) and be used as a yardstick to assess individual faculty “readiness” to teaching in online spaces (Gay, 2016).

1.1. Conceptual framework
The broad dimensions of effective online courses are a topic of interest in both research and practice, and have led to new bodies of scholarship in distance education (Boling, Hough, Krinsky, Saleem, & Stevens, 2012; Margaryan, Bianco, & Littlejohn, 2015), and standards to guide the efforts of faculty in designing and delivering these courses, such as the well-known Quality Matter Rubrics (QualityMatters, 2018). In developing our conception of effective online courses, we reviewed extant literature and chose to organize this body of work into three broad areas: online course design, online course assessment and evaluation, and online course facilitation. Our literature search strategy involved using the words “online learning” with terms like “standards,” “best practices,” “roles and competencies,” and “outcomes” in a wide array of academic databases. This literature was carefully traced to the three domains mentioned.

This conceptual framework is illustrated in Fig. 1 and includes before, during, and after the online course delivery, or more precisely, the full life-cycle of an online course. Notably, online courses are generally not taught and forgotten. The courses are carefully designed before, facilitated with intention during, systematically evaluated after, and revised accordingly to support learning objectives. Our overall position is that effective online courses are a function of design, assessment and evaluation, and facilitation. This is not to say that there are no other elements of effective online courses (e.g., learner support), but rather, we focus on these three areas to organize the literature and operationalize our research study. We put forth the claim that effective online learning must account for the design, assessment and evaluation, and facilitation before, during, and after the student learning experience as illustrated as the intersecting domains in the diagram shown in Fig. 1.

Fig. 1
Download : Download high-res image (155KB)
Download : Download full-size image
Fig. 1. Conceptual framework for effective online courses: design, assessment and evaluation, and facilitation.

1.2. Online course design
As studies on the effectiveness of online learning have long been documented in the empirical research literature (Means et al., 2013), researchers and practitioners have spent a considerable amount of time trying to formulate the best practices and standards in online course design. However, these course design features are not always clearly connected to evidence-based student learning outcomes (Jaggars & Xu, 2016). Meanwhile, much emphasis in online learning has been placed on the development of standards to both assess quality and guide development efforts in course design, such as the well-known and widely adopted Quality Matters rubrics (Legon, 2015). While many scholars of online learning continue to ask questions about the efficacy of best practices and standards on student learning outcomes, as noted by Legon (2015), there are other impacts that the adoption of the Quality Matters rubrics offer institutions of higher education, such as a focus on continuous process improvement, fostering a dialog within an institution or academic unit on what constitutes quality in online learning, and encouraging consistency of online course design to name a few. That is, the adoption of best practice and standards for online courses helps to create a culture of intentionality with carefully constructed learning outcomes connected to engaging learning materials, systematic procedures and processes used throughout an online course's life-cycle, and an overall focus on quality leading to ongoing evaluation and revision of online courses. Online course design is effectively a context-specific form of instructional design oriented to online learning spaces. Therefore, online course design includes both the features of the online course, and the processes and procedures used to create that online course.

Guidance from the online learning literature has presented countless best practices and standards for online courses on a multitude of dimensions (Crews, Wilkinson, & Neill, 2015). Some of these best practices and standards are inspired by theories and models of online learning (e.g., Community of Inquiry), while others are based on other existing learning theories applied to online settings (e.g., Cognitive Load Theory). As noted by Tallent-Runnels et al. (2006), online learning research still does not have a unified theory of learning, and thus, much of the research in online learning is often fragmented with few online course design principles supported by a multitude of studies. Further, the confusion and use of varying terms to describe similar constructs, such as e-learning, distance learning, or distributed learning make it difficult to pinpoint the empirical research to support the best practices and standards (Moore, Dickson-Deane, & Galyen, 2011). Over the last several decades, instructional design models focusing on online learning experiences have been developed and tested (e.g., Czerkawski & Lyman, 2016; Dunlap, Verma, & Johnson, 2016; Puzziferro & Shelton, 2008), while existing instructional design models have also been adapted and applied to online learning (e.g., Kidney & Puckett, 2003; Shelton & Saltsman, 2011). While no single approach or model seems superior for all online learning situations, it is clear that the use of instructional design processes to guide the design and development of online courses is an effective practice. That is, elements of instructional design practice can be found in the literature supporting the effectiveness of online learning ranging from the formulation of well-written learning outcomes to “chunking” and sequencing an online course to assessing student learning and evaluating course outcomes.

1.3. Online course assessment and evaluation
Online course assessment and evaluation serves multiple purposes for students, teachers, and administrators of educational systems and programs. Assessment is an integral part of any form of teaching and learning, and can be found in most instructional design models as a salient feature connecting to the evaluation of the instruction (Branch, 2009). Assessment information from online courses can assist the faculty in making decisions about students' attaining the learning outcomes, diagnosing problems with student learning in specific areas, providing targeted feedback or additional scaffolding to students (Peterson, 2016), and making summative judgements pertaining to grades or retention. However, this assessment information is also useful for the evaluation of the online course in achieving the student learning outcomes, and can inform decisions about revising instructional material or assessments not performing properly, making larger curricular changes to the academic program, selecting appropriate learning experiences and technologies to support those experiences, or even help educational administrators document the outcomes of courses and programs for accreditation purposes (Guerrero-Roldán & Noguera, 2018). Online learning literature is relatively consistent on the importance of online courses clearly communicating the student learning outcomes and how those student learning outcomes will be assessed (Moore & Kearsley, 2011). Best practices and instructional design models also support the use of the assessment information to evaluate the online course to inform revisions (Morrison, Ross, Kalman, & Kemp, 2012).

Online assessment methods supported by empirical literature vary widely based on nature of the student learning outcomes to be achieved, and notably, the belief system of the faculty members designing the online course (Conrad & Openo, 2018). The assessment approaches in online courses can include a combination of techniques all within the same online course experience, such as traditional assessment methods like quizzes and examinations (e.g., multiple choice questions) or those labeled as authentic assessment methods, like ePortfolios, online journals, or group work. Diversity of assessment methods in online courses has been linked to overall learner satisfaction (Sun, Tsai, Finger, Chen, & Yeh, 2008). Much of the contemporary dialog on online assessment methods emphasize authenticity and engagement of the learning task and assessment method by creating “real-world” problems with ill-defined tasks, and that require integration and collaboration among learners (Conrad & Openo, 2018; Herrington, Reeves, & Oliver, 2006). This approach to online assessment requires careful attention to student and group progress with frequent check-points and opportunities for both peer- and instructor- feedback cycles. However, the more “established” approaches such as online discussion forums associated with clearly defined rubrics are still pervasive in practice and are frequently discussed in best practices for online learning literature (Wang & Chen, 2017). Ultimately, online faculty and researchers are rightfully concerned about issues of quality and validity with online assessment methods (Kirkwood & Price, 2015). As online learning technologies continue to evolve, new approaches to assessment are being tested, such as the growth in popularity of learning analytics (Nyland, Davies, Chapman, & Allen, 2017) or stealth assessment (Bhagat & Spector, 2017). Online instructors use various types of evaluation for their online courses including course certifications, peer evaluation and student evaluation. Baldwin et al. (2018) identified several national and statewide evaluation instruments for online courses including quality maters, blackboard exemplary rubric, Open SUNY Course Quality Review Rubric. Online instructors also rely on student evaluation and peer evaluation to enhance the quality of the online courses.

1.4. Online course facilitation
Online course facilitation broadly refers to how, what, when, and why an online faculty member makes decisions and takes actions to help students meet the learning outcomes. Online course facilitation refers to the day-to-day operations of a “live” course. Online course facilitation best practices, standards, and competencies have been developed and tested in varying online courses across studies. As online learning has the potential to isolate learners, the facilitation strategies used by faculty should target student behaviors that mitigate this threat (Gillett-Swan, 2017). Research on effective online course facilitation strategies has shown that some strategies are more effective than others in helping with instructor presence, instructor connectedness, engagement, and learning across students (Banna, Lin, Stewart, & Fialkowski, 2015). Specifically, facilitation strategies like timely instructor responses to email and discussion forums, timely instructor grading and feedback of assignments, and instructor personal response to reflections appear more influential on key outcomes, whereas other strategies like synchronous learning sessions or an interactive syllabus were less influential (Martin, Wang, & Sadaf, 2018). In their study, Martin et al. examined student perception of 12 facilitation strategies in online courses. Research suggests that instructor-led facilitation strategies leads to a stronger sense of community among the students (Epp, Phirangee, & Hewitt, 2017). These findings are consistent with recent research findings illustrating that students valued instructor-to-student interactions most when compared to student-to-student and student-to-content strategies (Martin & Bolliger, 2018). Salmon (2011) uses the term moderating for facilitation. In her book on E-Moderating discusses a five-stage model including access and motivation, online socialization, information exchange, knowledge construction, and development to prepare instructors for online moderation. Berge, 1995, Berge, 2008 proposed the Instructor's Roles Model which shifted focus of an instructor from a subject matter expert to a course facilitator, and categorized facilitation into four categories: Pedagogical, Social, Managerial, and Technical. Researchers have examined specific aspects of facilitation. Hosler and Arend (2012) found that discourse facilitation is key to elicit critical thinking or cognitive presence and noted that course organization and timely specific feedback improved students' participation. Shea, Li, and Pickett (2006) added that instructors' questioning and feedback have positive impact on students' perception of learning and connectedness. It is relatively clear that the choices an online faculty member makes to facilitate learning in the course can have dramatic effects on desired outcomes.

1.5. Purpose and research questions
Researchers have focused on examining course design and facilitation practices from faculty who have won awards for their online courses. Bailey and Card (2009) in their study found that award-winning experienced instructors who won the South Dakota e-learning award identified theories of andragogy, constructivism and transformative learning as effective theories for online teaching. They also identified eight pedagogical practices including fostering relationships, engagement, timeliness, communication, organization, technology, flexibility and high expectations. Baran, Correia, and Thompson (2013) in their interviews with six exemplary online teachers found tasks that the online teachers prioritized when transitioning to online teaching. Structuring and organizing the course content, extensive planning and designing, tailoring the course to meet student needs, enhancing student-instructor relationship, providing timely feedback to students, constant communication, establishing teacher presence and formatively evaluating the course were some of the tasks identified as common themes.

The purpose of this study was to identify online course design, assessment and evaluation, and facilitation practices from the perspectives of award-winning online instructors based on interviews. Three research questions were answered:

1.
How do award-winning online faculty design an online course?

2.
How do award-winning online faculty assess student outcomes?

3.
How do award-wining online faculty evaluate their online course?

4.
How do award-winning online faculty facilitate an online course?

2. Method
The research project was executed in three distinct phases: 1) reviewed existing research literature on online course design, assessment and evaluation, and facilitation to formulate a conceptual framework for the study; 2) developed as interview guide based on the conceptual framework to interview award-winning online faculty; and 3) interviewed the award-winning faculty teaching online at various institutions of higher education within the United States. In this section, we outline the participants, professional association awards, interview instrument, and data collection and analysis of this research study.

2.1. Participants
Fifteen faculty who had won awards for online teaching were contacted by email of which eight of them agreed to participate in the online interview as a purposeful sample, which enhances the transferability of our findings. Table 1 shows the eight distinguished online instructors that have either won the Excellence in Online Teaching Award from the Online Learning Consortium (OLC) or the Crystal Online Teaching Award from Association for Educational Communications and Technology (AECT), or the Online Technology Higher Education Award from United States Distance Learning Association three large professional organizations dedicated to the research and practice of online learning and teaching. Six of the interviewees were female, and two were male. The participants taught online coursework in several disciplines, including teacher education, educational technology, public policy, economics, communications, history, and English. As shown, the participants have a wide range of online teaching experience using several different Learning Management Systems (LMS) to support a blend of asynchronous and synchronous online courses.


Table 1. Demographics of eight award-winning faculty.

ID	Gender	Award	Years teaching in H.E.	Years teaching online	LMS experience	Modality
1	F	Excellence in online teaching, OLC Award	20	15	Genzibar, webct, Desire2Learn, canvas, blackboard	Blend of asynchronous and synchronous
2	F	Excellence in online teaching, OLC Award	30	6	Blackboard	Asynchronous
3	F	Excellence in online teaching, OLC Award	14	12	Blackboard, Moodle, Canvas	Asynchronous
4	F	Crystal Award, AECT	23	5	WebCT, Blackboard, Wordpress, WikiSpaces	Mostly asynchronous with some synchronous
5	F	Crystal Award, AECT	15	5	None identified	Blend of asynchronous and synchronous
6	M	Gold, online technology ~ Higher education, best practices Awards for excellence in distance learning teaching	31	9	Blackboard	Mostly asynchronous with some synchronous
7	M	Excellence in online teaching, OLC Award	44	42	Blackboard	Asynchronous
8	F	Excellence in online teaching, OLC Award	18	15	CAD, Blackboard, Interlearn, Moodle	Asynchronous
2.2. Professional association awards
The three awards we used as a criterion to identify faculty were the Excellence in Online Teaching Awards that were U.S based from the Online Learning Consortium (OLC), Crystal Online Teaching Award from Association for Educational Communications and Technology (AECT) and the Best Practices Awards for Excellence in Distance learning Teaching from the United States Distance Learning Association. The OLC is a community of higher education professionals dedicated to advancing quality digital teaching and learning experiences. The Excellence in Online Teaching Award states that winners must have designed and taught one or more online or blended courses with an imaginative approach, well-designed course materials and instructional strategies, and a demonstrated rapport with the course participants (OLC, 2018). Additionally, the recipient is expected to provide evidence of the effectiveness in reaching the desired learning outcomes. AECT is a professional organization for those for those actively involved in the design of instruction and a systematic approach to learning. The Crystal Award recognizes innovative and outstanding multimedia-based distance learning courses across a rubrics of eight criteria, including innovation in course design, evidence of effectiveness, and is grounded in scholarly literature (AECT, 2018). The United States Distance Learning Association (USDLA) supports distance learning research and development in the areas of education, training and communications. The Excellence in Distance Learning Teaching/Training awards are given to an outstanding individual or team of individuals whose teaching demonstrates extraordinary achievements (USDLA, 2018).

2.3. Instrument
As noted, we reviewed the existing literature as a starting place to create our conceptual framework highlighting online course design, assessment and evaluation, and facilitation. Using the conceptual framework and relevant literature as a guide, we then developed a semi-structured interview protocol with 14 questions to collect in-depth qualitative information from award-winning online instructors. All questions were carefully reviewed by members of the research team, all of whom have taught online, for clarity and intent. We intentionally did not use technical jargon from online learning research or instructional design to ensure that the faculty from all disciplines and experiences would understand the intent of the questions. The questions were all open-ended to elicit in-depth information, and in many cases, probes (e.g., can you provide an example?) were used to ask for clarification or elaboration from the interviewee. Some example questions are provided below along with the focus area:

•
Could you describe to us how you design your course? (Design)

•
Could you describe to us how you assess your students (e.g., quizzes, discussions, etc.)? (Assessment)

•
Could you describe to us how you teach your course (e.g., the day to day work)? (Facilitation)

•
How do you evaluate whether your course is meeting your intended outcomes? (Evaluation)

2.4. Data collection and analysis
We interviewed the eight faculty via Net Meeting (web conferencing software) to learn about what they do in their online courses relating to the conceptual framework. Additionally, we maintained a detailed audit trail during both the data collection and analysis processes to establish the dependability and confirmability of the findings (Lincoln & Guba, 1985). Specifically, we employed reflexive notes, first and second round code lists, and brief notes of coding discussion between two researchers as an audit trail. During the online interview process, we displayed the interview questions on the screen to assist the interviewees in staying focused and answering the questions. As noted, probes were used in cases to clarify or gauge for additional information when necessary. All interviews were digitally recorded using the web conferencing software for later transcription and coding by the research team.

Two cycles of coding (Saldaña, 2015) were used to analyze the interviews. Two researchers read through each interview to ensure that the same questions had been asked and compiled the data by responses to research question across the eight interviews. All eight responses to one question were first coded by two members of the researcher team in the first cycle using elemental coding methods. The descriptive, in Vivo, and process codes (Saldaña, 2015) were then discussed by the two researchers to further enhance the credibility and dependability. Data for the remaining questions were then similarly coded and reviewed to reach agreement, followed by a second coding cycle in which axial coding was applied (Saldaña, 2015). The codebook was examined to eliminate redundancy and group together pertinent codes into categories that were compared across questions to consolidate and finalize the themes. Finally, a third researcher reviewed the final codes for connections to the conceptual framework and aligned the findings based on the conceptual framework.

3. Results
The results are presented in sections below according to the research questions: a) online course design, where award-winning online instructors describe their approaches to course design for student learning and engagement, b) online course assessment where they describe their use of assessments and rubrics c) online course evaluation where they describe quality assurance and student or peer evaluations and d) online course facilitation where they highlight feedback, presence, and communication.

3.1. Online course design
3.1.1. Systematic approach to content design
All eight faculty approached the design of their courses in a very systematic manner, beginning with the course description and objectives, and drafting a syllabus before working on the online course. Faculty also articulated how the course objectives and their beliefs influenced their design of learning activities. Faculty began with the learning objectives, identified modular or weekly topics, and then included resources in different formats that would provide students with an understanding of each topic. One participant described it as follows:

First of all its coming up with that class structure, …the road map so that's the kind of the starting point is chunking down on your content. What your learning objectives will be for each module and how those align with the course outcomes. And then beyond that, thinking about… what do you expect your students to know and what do you expect your students to do in order to learn that and how will they demonstrate what they've learned so those are kind of those 3 components for each course design. It's the structure, alignment.

The participants were also systematic because they felt the content structure and outcomes would “guide the students” and help them understand why they were doing certain activities within the course. One participant described the systematic approach to course content as giving students a “continuous educational pathway” that “increases their self-efficacy” and communicating to them that they are “doing everything for a specific purpose.” Another participant emphasized that familiarity with industry practices was essential and such content should be integrated into a course.

3.1.2. Backwards design
Once the faculty had identified their learning objectives, course topics, and resources, they designed learning activities based on the type of learning outcomes they aimed for in their course design. Several participants used the word “alignment” to explain how they ensured that the syllabus, learning outcomes, assignments, learning activities, and learning technologies were aligned within the course. The availability of learning technologies at their institutions was a decisive factor in their design of learning activities. One faculty member reflected on the importance of alignment in the syllabus between expectations, requirements, assignments, learning activities, and technologies. Two faculty explicitly explained their process of backwards design, with one of them stating,

I look at my learning outcomes, I look at my assessment, I have the backwards design processes if you will, I lay-out learning activities. I do my syllabus, I look at it and then I take those learning activities and then I align them with the learning technologies, that's how I design my course, by matching the learning activity with the appropriate learning technologies.

3.1.3. Course organization
Six of the eight faculty organized their online courses according to modules, one organized them according to weeks, and one faculty member stated that her organization of courses by module or week depended on the content and type of course. Regardless, the faculty were all involved with “chunking” the course content meaningfully. The participants believed that consistent organization, whether in a modular or weekly format, is helpful to students “so they know where they are in the process.” One participant created “a Screen cast of the course architecture so that they [students] know where to find things,” while another explained,

I try to have consistency across my lesson units so every lesson unit…it outlines very clearly for them what are the objectives of the unit, what are the responsibilities that they have and what are the deadlines for what we're doing.

Two participants also mentioned the importance of communicating expectations within the course structure. One participant stated, “I also let them know about the time commitment that they should have in place each week…They need to structure that time to get the work done.”

3.1.4. Meeting learner needs
One participant stated that it was important to “make the materials alive to the students,” while another asserted that a variety of instructional materials was needed to ensure learners could learn in different ways. Reflection on the types of learners who would take the course, as well as their prior knowledge was important to the faculty. Three faculty designed their online courses with their adult learners and their busy schedules in mind. One participant stated,

“In our graduate program 98% of our students work full-time and study part-time. So they really are very busy people and you really need to be careful how you lay out the course for them...So it depends on your student population, if they're undergrad, if they're resident, not working full-time then you may you know design it or lay it out for them a little bit differently.”

At the same time, the larger purpose of a course within a program and for the profession were important considerations for the participants, one of whom stated,

“I assess what they need to know. And look at different criteria and credentials to make sure when the students come out of that course they've got the proper knowledge to step into whatever job they desire based around those learning competencies.”

3.1.5. Student interaction
All the participants mentioned interaction or community as a key element in designing learning activities. They gave examples of collaborative projects, discussion forums, or peer review activities as necessary for students to interact with each other and the course content in different ways. The structuring of student interactions with one another and their creation of digital content that demonstrated their learning was also important to two faculty. Two participants reflected on the importance of students communicating using different types of media, not only text. Another participant stated,

“I have to think about ways in which there is some community built into the course, they interact with each other, in discussion boards where they're reacting to issues and responding to each other or with shared projects. I think that that's an important aspect trying to create a sense of community. I actually think when I design a course that's the first thing, the go to.”

3.2. Online course assessment
3.2.1. Variety of course assessments
Faculty in this study assessed student learning using quizzes, discussion forums, exams, final papers, position papers, final projects (text-based or multimedia), peer assessments, self-assessments, and reflection. Six of the eight faculty used quizzes either weekly or during regular intervals during the course to assess whether students were reading, understanding, and learning course content. These quizzes sometimes included automated feedback, were timed, and in the case of one faculty member, were open book. Seven of the faculty also used discussion forums in several ways – students reacted to readings, posted required responses to peers, posted their own resources after searching or exploring a topic, etc. One faculty member described her use of VoiceThread for a discussion forum instead of text.

Voice thread allows for these conversations to take place between students… I do commenting activities with editing activities, very open-ended prompts. They would have to design, make, upload the slide, and leave a particular comment. Fulfill the criteria and every student does that by the end of the week.

3.2.2. Using traditional and authentic assessments
In addition to final papers and position papers, faculty often had students create digital content to demonstrate their learning. One faculty member found it important for students to choose their own technologies to create multimedia that demonstrated how they were connecting theories to practice. Another included projects where students could select their topics, how much of it they would cover, had to do the research, and create content to “demonstrate mastery” of the topic. A third faculty member wanted students to learn different digital tools to present content, and thus, required them to create content using Prezi, or a timeline software. A fourth faculty described a reflection assignment that took the form of a creative project (e.g., videos, songs, infographics, etc.) at the end of the semester, where students reflected on their work during the semester “in some sort of creative fashion.”

3.2.3. Using rubrics
All the faculty used rubrics to grade the discussion forum activities. One faculty member emphasized that it was easier for students to know what was expected of them if they were given the rubric in advance. Another faculty member had students use self-assessments with their discussion forums. For all these assignments, faculty reiterated the importance of using rubrics and being very specific about both expectations and grading criteria for assignments.

Course rubrics that were tied to student outcomes were used in the case of one participant who created an outcome achievement report that identified “whether, how each student learning outcome in each course met the student learning outcomes of the program.” Another participant described the use of an evaluation where students assessed whether the course and program objectives had been met. In the case of a third participant, assignments and artifacts from the online course were assessed using rubrics both internally, and by experts in the field, to evaluate if intended program outcomes were being met, and to what extent. The participant explained that this contributed to continuous quality improvement of the online courses in the program.

3.3. Online course evaluation
Participants in this study described various ways in which quality was assured and evaluated in their online courses.

3.3.1. Quality assurance process
Quality assurance processes were described as essential to maintain online course quality. One faculty member described the use of a quality assurance process and teams at the university to create online courses, that included a designer, a multimedia specialist, an editor and a subject-matter expert who was the faculty member. Once the course is created, it was reviewed by a second subject-matter expert, and an instructional designer who had not worked on the original course.

3.3.2. Student and peer feedback
Participants described mid-semester and end-semester surveys, student evaluations that focused on both course design and facilitation, and the use of data collected from learning management systems that are used to supplement student evaluations at their universities. Two participants described online course reviews or peer evaluations of online instruction at their institutions. One participant explained the peer evaluation as follows,

The course owner, the course lead faculty will go in and observe the performance of the teaching faculty inside of the course in multiple ways. They fill out a rubric, they provide that feedback to the teaching faculty and then we have a number of faculty development courses that we may recommend.

Accreditation and larger program outcomes were a major course quality consideration for three participants. They described different ways in which student feedback or student work was used to assess whether student learning outcomes were being met in an online course or program.

3.4. Online course facilitation
3.4.1. Timely response and feedback
When asked about their day-to-day routine when teaching online courses, all eight faculty stated that they checked in to the course at least once a day. Six of the faculty specified that they began their work day by reading student messages or responding to student discussion posts in the morning, and then checked in again later in the evening and sometimes during the day. Timely responses and feedback were important to all the faculty – four faculty specified that they would respond to student messages within 24 or 48 h, and graded student work within 48 h. One faculty explained,

You have got to keep up that engagement, especially if you have an accelerated course, and the student has a question – they cannot wait. They need to feel supported, they need to understand that they do indeed have a teaching faculty here to facilitate and engage with. Timely feedback is everything for online learning.

3.4.2. Availability and presence
Availability and presence of the faculty member in the online course were highlighted by two faculty members, one of whom was available by phone and email to students till late evening. One faculty member stated that he was more active during the initial parts of the course, and later more focused on giving feedback on formative assessments. He said,

The first 2 to 3 weeks are very constant engagement developing that awareness of who my students are… after that point, I start to scale back a bit. The first part is building awareness on my part, building communities, bringing students together kind of a social interaction or ice-breaker or those sorts of things. And in getting them to know who each other is so they can find the connection amongst themselves and also getting to know the technology.

Another participant explained the importance of being present in different ways:

So being actively present and engaged and be visible. By visible I mean through voice and/or video so that students…can hear the intonation in your voice, they can see you and that is not to imply a 60-minute talking head video, really encourage shorts clips to introduce units and providing feedback to students…with the use of that warm presence and with empathy…Let the student know that you've heard or understand them.

3.4.3. Periodic communication
Three faculty described their posting of weekly announcements with reminders of what is expected of students that week, while one faculty member stated that he posts a daily announcement each morning about the content or the course activities. In general, regular interactions with students and timely grading characterized all the faculty responses.

4. Discussion
Online teaching, if done effectively, has the potential to significantly enhance the quality of learning environments and learning outcomes (Perry & Edwards, 2005). Digging deeper into the approaches and strategies used by award-winninng online educators in online course design, assessment and evaluation, and facilitation is necessary to identify what makes online educators not only effective, but exemplary. Within most disciplines, there are expert faculty and novice faculty at any point. Experts are not just those who have the wealth of experience from their years teaching online, but have the “fluency of teaching and learning with technology, not just with technology, itself” (Jacobsen, Clifford, & Friesen, 2002, p. 44). The intentional and creative instructional practices performed by award-winning instructors on a daily-basis, such as the those featured in this study, strengthens the understanding of ‘what works’ in the online teaching environment and how online faculty can improve the way they plan, select, and implement strategies for online course design, assessment and evaluation, and facilitation. Novice online faculty can use results of this study as a benchmark future online course planning and revisions. The best practices highlighted in this study stimulate reflection on current faculty development efforts in higher education, providing a foundation upon which faculty development programs and policies can be built to achieve exemplary standards. While several of these recommendations benefit novice faculty who are new to online teaching, they are also a reinforcement for expert faculty who might already using these practices. In this study, we found that award-winning online instructors take the role of the designer, assessor, and facilitator. The findings from this study are examined through the lenses of these roles.

4.1. Online instructor as the designer
For course design, award-winning faculty recommended following a systematic approach to content, backwards design, course organization, meeting learner needs, and student interaction. While the award-winning faculty interviewed were from different disciplines, all stressed the importance of following a systematic approach to content design, which is the foundation of instructional design (Rothwell & Kazanas, 2011). They also reinforced the importance of backwards design which when used in online courses allows for designing the course with the end in mind, and provides opportunities for including a variety of teaching strategies and assessments (Wiggins, Wiggins, & McTighe, 2005).

Organizing the course by weeks, modules, or units is an important design practice (Ko & Rossen, 2017). This was reinforced by the award-winning faculty as assisting them in designing the course. Students place great value on course organization as contributing to their success in online courses (Fayer, 2014). Young and Norgard's (2006) survey showed that 92% of students prefer to have a consistent or common course structure, particularly in the way courses are structured across all courses in their program. Researchers have examined the importance of meeting online learner needs, using a learner-centered approach (Anderson, 2004). Hughes (2004) recommends creating learning communities to enhance interaction and also providing online support services to meet the online student needs (Hughes, 2004). Meeting the learner needs and providing opportunities for interaction emerged as themes that award-winning faculty thought was important in designing an online course.

4.2. Online instructor as the assessor
The strategies award-winning faculty used for assessing online courses included, using a variety of assessments, using both traditional and authentic assessments, and using rubrics. Researchers have recommended using a wide variety of assignments on a regular basis to provide meaningful and timely feedback to students regarding the quality of their work (Gaytan & McEwen, 2007). Researchers have recommended using a variety of assessments such as projects, portfolios, self-assessments, peer evaluations, and weekly assignments with immediate feedback (Gaytan & McEwen, 2007). Using formative assessment in the forms of quizzing, discussion posts, reflections, and online synchronous check-ins with the instructor assists in providing learners multiple opportunities to track their learning progress (Quality Matters, 2018). Other researchers have recommended using both traditional assessments and authentic assessment. Mueller (2005) describe authentic assessment as assessments that capture the constructive nature of student learning where they perform real-world tasks to demonstrate application of knowledge and skills. The award-winning faculty recommended using authentic assessment such as creating digital content and also reflecting through a creative project.

Award-winning faculty recommend using rubrics for all types of assignments, but also for using rubrics to evaluate if the course and program outcomes were met. Stevens and Levi (2013) recommend using rubrics which assists instructors by saving grading time, conveying effective feedback, and promoting student learning.

4.3. Online instructor as the evaluator
The award-winning instructors described strategies used at their institutions for the evaluation of the online course, both in terms of course design and teaching. Some of them participated in quality assurance processes at their institutions which involved their course being reviewed by an instructional designer and a subject-matter expert. Quality review of online courses are becoming an important aspect of evaluation in several universities. Quality Matters has established a structured review program for online faculty to receive feedback on their courses and for the courses to be certified (Crews & Wilkinson, 2015). In addition to using such rubrics, institutions have designed their own rubrics to measure quality of online courses. McGahan, Jackson, and Premer (2015) developed a quality checklist to assess quality of online courses on their campus. Additionally, these assessment data serve as the evaluation data used to make both formative and summative evaluation judgements about the online course. These data serve the full life-cycle of an online course as a form of quality assurance used by the faculty and administration. Additionally, the award-winning instructors described the use of student evaluations and formal peer evaluations of teaching at their institutions. Although many institutions continue to use student evaluation forms previously used in on-campus courses for online courses, there have been recent efforts to create evaluation forms specifically for online courses. These can be most valuable to online instructors if they contain a set of core items about online teaching and variable items that online instructors can choose based on the type of course.

4.4. Online instructor as the facilitator
For facilitation, award winning faculty recommended timely response and feedback, availability and presence, and periodic communication. Martin et al. (2018) found instructors timely response to questions and timely feedback on assignments were facilitation strategies that help students in online courses to enhance instructor presence, instructor connection, learning and engagement. Quality Matters (2018) recommend that online instructors respond to students' questions and also to grade their assignments and provide feedback timely for students' effective learning. This reinforces that the award-winning faculty recommended timely response and feedback as essential facilitation strategies.

Richardson, Besser, Koehler, Lim, and Strait (2016) found that online instructors viewed instructor presence as an important component in online courses. In this study, the award-winning faculty stressed the importance of being present and available to their students and recommend using instructor generated material which included their voice and video to show their presence in the online courses. Similarly, researchers have recommended using videos in online courses to enhance learner attention, recall, perceived learning and satisfaction (Wang & Antonenko, 2017). Finally, periodic communication was recommended by the award-winning faculty as an important strategy that they used in their online course. Martin and Bolliger (2018) found that the instructor sending/posting regular announcements or email reminders was a communication strategy that was rated very high by the students as important for their learning.

5. Limitations
Qualitative research methods are influenced by a variety of techniques to ensure and provide evidence of the rigor of the research study. Specifically, this study did not employ some of these techniques, like triangulation (e.g., only data source was the interview), prolonged engagement with the interviewee (e.g., we only conducted a single interview), or member-checking. However, we did manage to use purposeful sampling, audit trails, peer debriefing, and experienced researchers to enhance the credibility, dependability, confirmability, and transferability of our findings (Lincoln & Guba, 1985; Patton, 2002; Schwandt, Lincoln, & Guba, 2007; Spencer, Ritchie, Lewis, & Dillon, 2004). Findings from the present work should not be generalized. Obviously, these findings are largely influenced by the honesty and memory of the award-winning faculty that participated in the interviews.

The findings from our study of award-winning online faculty were strongly supported by existing literature and best practices in the field, and cleanly mapped to the domains in our conceptual framework. Although many of our findings confirm accepted good practice in online course design and facilitation from prior research, rather than presenting new technique and strategy for online learning, they provide strong evidence for the success of these strategies and their use by experienced and award-winning instructors. Also, our conceptual framework focused on the three domains of course design, assessment and evaluation, and facilitation. There are other dimensions of online learning that are also relevant, like student support or accessibility. This present study did not examine these dimensions.

6. Implications and future research
This study has implications for all faculty who teach online, for instructional designers who assist faculty in designing online courses, and for administrators who provide the necessary support for online faculty and designers. Further, the findings from this research also point to some promising avenues for future online learning research.

6.1. Implications for practice
The findings from this study are helpful in offering specific professional development for faculty in the areas of course design, assessment and evaluation, and facilitation. Faculty with limited online teaching experience are in need of effective models and strategies for online teaching. Our findings demonstrate the “willingness to learn” and “willingness to experiment” among the award-winning online faculty who report spending considerable time and effort thinking about how to best deliver the learning experiences online. These new online faculty should be encouraged to try out novel instructional strategies and make adjustments from semester to semester as a result. Most universities have centers for teaching excellence that provide professional development opportunities for both seasoned and novice online faculty. These opportunities can make use of the findings from this study to encourage effective online teaching practices, and model the appropriate behaviors and strategies noted in the professional development and certification programs at each institution. These data and findings may also assist with the formation of best practices, standards, and competencies for online instructors across settings and disciplines. Administrators and instructional designers are always in search for solutions to improve online learning across the full lifecycle of online courses and programs. Our findings show that effective online learning can be explained well using the conceptual framework presented in light of the award-winning online faculty, noting the important role of design, assessment and evaluation, and facilitation. Often, novice online instructors find it difficult to see the full picture of effective online courses from the early stages of course design, to connections to clearly aligned assessments, and how to improve those courses using the data collected from the live courses. Our study helps illuminate this process for faculty.

6.2. Future research
Future research should focus on specifics from the online courses that made their courses award-winning and types of support that assisted the faculty in creating award-winning courses. The necessary support structures (e.g., access to instructional designers) for faculty to create and facilitate award-winning online courses is an essential ingredient to fully understand the phenomenon of effective online learning. Further, these award-winning faculty should be studied more systematically and for prolonged periods using a combination of observation and interview techniques to gauge other details that cannot be examined using self-report methods alone. Award-winning online faculty might also best share their experiences in other methodological ways, such as using a Delphi method to build consensus of effective online learning, or focus groups to discern their experiences and practices in a dynamic conversation. Another important consideration is that the award-winning online course shells themselves should be carefully and systematically studied to provide further evidence of what makes these courses “award-winning” in light of online learning standards, best practices, and research. Future conceptual frameworks and models should account for those things missing from our conceptual framework, like student support structures and accessibility. The future of online learning research is a ripe opportunity to contribute to both the practice of online instructors, and body of knowledge surrounding effective online learning.
