The advancement in the computational capability and storage size of a modern mobile device has evolved it into a multi-purpose smart device for individual and business needs. The increasing usage of this device has led to the need for a secure and efficient authentication mechanism. For securing mobile devices, password, PIN, and swipe patterns are commonly used for user authentication. Entry-point face and fingerprint recognition have also gained traction in the past years. However, these authentication schemes cannot authenticate a user after the initial-login session. This limitation might put the device exposed to information theft and leakage if an illegitimate user could bypass the initial-login session. Therefore, a mobile device needs a continuous authentication mechanism that can protect a user throughout the entire working session, which complements the initial-login authentication to provide more comprehensive security protection. Touch biometric is a behavioural biometric that represents the touch behaviour pattern of a user when interacting with the touchscreen of the device. Touch biometric has been proposed as a continuous authentication mechanism, where the device can collect touch biometric data transparently while a user is using the device. However, there are still plenty of challenges and obstacles in touch-based continuous mobile device authentication due to its challenges as a biometric modality. This paper provides a comprehensive overview of fundamental principles that underpin touch-based continuous mobile device authentication. Our work discusses state-of-the-art methods in touch data acquisition, behavioural feature extraction, user classification, and evaluation methods. This paper also discusses some challenges and opportunities in the current touch-based continuous mobile device authentication domain to obtain a broad research community and market acceptance.

Previous
Next 
Keywords
Biometrics

Mobile device security

Continuous authentication

Touch biometric

1. Introduction
Mobile device is a widely used computing device for personal and business purposes. Due to the convenience and benefits offered by this device, it has become a ubiquitous device that people tend to rely on to ease their daily activities (Meng et al., 2018a). The advancement in computer science, communication technology, and the availability of faster and cheaper Internet connection have also directly contributed toward the increase of mobile device usage (Filippov et al., 2018). Many users have switched from the conventional computer to mobile devices for their daily usage (Teh et al., 2016). Unfortunately, this device can be easily stolen due to its small size (Hao and Li, 2016, Canfora et al., 2016, Fierrez et al., 2018, Filippov et al., 2018). Mobile device theft occurs due to the monetary value of the device and in some cases the information that stored on it Syed et al. (2019). Therefore, it is essential to have a reliable security mechanism that can protect the safety of information stored on mobile devices.

User authentication is a security mechanism that verifies the identity of a user who claims to be the legitimate user of a mobile device. The mechanism must be secure, useable, and efficient to protect the information stored while ensuring that it is convenient for users to perform the authentication (Inoue and Ogawa, 2017). If the mechanism allows an illegitimate user to access the device, information leakage might be harmful to the legitimate user. Besides, it must also be a convenience for a legitimate user where it should be easy, fast, and user-friendly (Alghamdi and Elrefaei, 2018). The high expectation of mobile device users for a secure and useable authentication mechanism has directly introduced several challenges to the research of the development of mobile device-based user authentication systems (Perera et al., 2018).

Conventional user authentication methods on mobile devices include password, PIN, and swipe pattern codes. Password and PIN are still the most commonly used authentication methods (Wang et al., 2020a). However, the conventional methods mentioned above have several vulnerabilities. First, users tend to use a simple (Brown et al., 2004) and easily guessed password (Lee and Lee, 2017b). An illegitimate user can access the device by guessing some common passwords (Budulan et al., 2015). Second, the illegitimate user can also see the password or PIN through shoulder-surfing (Khan et al., 2016). Once the illegitimate user knows the password or PIN, the attacker can access the device when it is not in its ownerâ€™s hand (Tari et al., 2006). Most importantly, PIN is less popular among users nowadays because they have to insert the code several times to access their device (Lee and Lee, 2017b).

The introduction of user authentication methods based on physiological biometrics has overcome the above limitations. Using physiological biometrics such as face or fingerprints, users do not have to memorise their password or PIN, but can simply use their biometrics traits for authentication. These methods usually require some specialised hardware to be installed on mobile devices, such as a high quality capacitive fingerprint scanner and a depth sensing front-facing camera, to capture fingerprints and face, respectively (Zhou et al., 2016). These specialised hardware are necessary to ensure high-quality biometric data can be captured. Even though most mobile devices in the market today have been installed with a front facing camera, the facial image needs to be ensured at a high quality to ensure high authentication accuracy, which might not be available in some low-end mobile devices. Fingerprint sensors on the other hand, are usually absent in low-end mobile devices because they are non-essential hardware. In cases where the device failed to capture the physiological biometrics at a high level of quality, it will affect the authentication accuracy (Wang et al., 2020a). Therefore, a supporting authentication mechanism is necessary to complement these physiological biometric-based authentication methods.

On top of that, password, PIN, swipe pattern, and physiological biometrics-based authentication methods are usually meant for the initial-login authentication (Smith-Creasey and Rajarajan, 2019). These authentication methods authenticate users once before allowing accessing the device (Aviv et al., 2010). The assumption that the legitimate user is always the same after the initial-login session might not always be true in some cases. For example, the device might not be set to be locked automatically by its default setting. Besides, a legitimate user who does not set the device to be locked automatically may unintentionally left his or her unlocked device in public areas. If an illegitimate user can successfully bypass the one-time authentication, it could allow the illegitimate user to access the device for a more extended period (Fierrez et al., 2018, Shen et al., 2018b). Therefore, in order to address the problem, mobile devices will require a complementary form of authentication method after the initial-login authentication, which can verify a user when he or she is using the device (Alzubaidi and Kalita, 2016).

Continuous authentication is an authentication method that can protect the user throughout the entire working session. To implement this method, biometrics modalities such as fingerprint and face are challenging to be implemented, where users are required to interact directly with the sensors (e.g. looking at the screen with a certain angle that the front-facing camera can capture the face, position their fingers at a specific position to authenticate themselves, and it requires specialised hardware (Liang et al., 2020, Abuhamad et al., 2020, Li et al., 2020). This kind of hardware is usually installed for a specific purpose, for example, to capture fingerprint or face recognition at an optimum level. Behavioural biometric provides advantages, where the device can capture the biometric data when the user is using the device, and the modality also does not require any dedicated hardware (Meng et al., 2018b, Meng et al., 2018a). It can leverage the existing hardware such as the touchscreen, which is an essential hardware as the main input interaction between users and the device. Behavioural biometric is the behavioural pattern of a user which represents how a user behaves. Examples of behavioural biometric modalities include handwriting, keystroke, touch gestures, gait, signature, voice, and behavioural profiling (Alzubaidi and Kalita, 2016). By implementing continuous authentication based on behavioural biometrics, it can support and complement the existing authentication methods (i.e. password-based and physiological-based authentication methods), where the continuous authentication scheme can detect the behaviour of illegitimate users from the background (Abuhamad et al., 2020).

Most of the mobile devices today use a touchscreen as the primary source of input. Users interact with the touchscreen all the time, and it can capture the timestamp, the touch pressure, the touch area covered by one or multiple fingers, and the position of the touch. Several studies have shown the capability of touch gestures to be used as a biometric modality (Frank et al., 2013, Serwadda et al., 2013, Zhang et al., 2015, Sitova et al., 2016, Shen et al., 2015c). The touch pattern of a user when interacting with a mobile device is known as touch dynamics (Syed et al., 2019). It can offer a non-intrusive and continuous authentication for the device where users can still use the device as usual (i.e. performing touch interaction normally), without realising that the continuous authentication mechanism is operating at the back-end (Shen et al., 2018b). While face recognition algorithm are accurate in distinguishing full frontal faces, as the facial profile is tilted away from the front-facing camera, the accuracy starts to drop significantly. In general, besides the pose variations, low-resolution face images are also very hard to recognise (Li et al., 2018). In terms of usability, authentication methods that utilise face recognition require direct attention from the users. This requirement can cause inconvenience to the users (i.e. users need to make sure that they look at the front-facing camera at a certain angle to allow authentication) (Liang et al., 2020, Abuhamad et al., 2020, Li et al., 2020). In contrast, touch biometric is more convenient since the biometric data can be captured while a user is performing touch interaction with the device as usual.

1.1. Related work
Several reviews have been published the past few years in the area of mobile devices authentication, continuous authentication, behavioural biometrics, and touch biometrics. We list the review papers published in the related area in Table 1. These review works involve user authentication in mobile devices, but with different aspects in term of authentication modes and authentication approaches.

Meng et al. (2015) focus on a biometrics-based user authentication approach on mobile devices, which includes static and continuous authentication. The authors present five physiological biometric approaches (fingerprint, face, retina, hand and palm, and voice) and six behavioural biometric approaches (voice, signature, gait, behaviour profile, keystroke dynamics and touch dynamics). The authors point out that touch-based biometric has the potential to become a more significant approach for user authentication on mobile devices.


Table 1. Summary of related works.

Year	Author	Authentication mode	Approach
2015	Meng et al. (2015)	Static and continuous	Physiological and behavioural biometrics
2016	Teh et al. (2016)	Static and continuous	Touch biometric
2016	Patel et al. (2016)	Continuous	Physiological and behavioural biometrics
2017	Mahfouz et al. (2017)	Continuous	Behavioural biometrics
2019	Ibrahim et al. (2019)	Static and continuous	Various approaches including biometrics
2020	Wang et al. (2020a)	Static and continuous	Various approaches including biometrics
2020	Abuhamad et al. (2020)	Continuous	Behavioural biometrics
Our work	Continuous	Touch biometric
Teh et al. (2016) focus their work on user authentication in mobile devices based on touch dynamics. The focus is mostly on the typing behaviour of a user on the virtual keyboard of a mobile device. The authors provide an analysis of approaches in different aspects of the area such as data acquisition, feature extraction, decision making, experimental settings, and performance evaluation. The authors have also pointed out several issues that worth further investigation, which include feature selection techniques for smaller significance features, one-class classifier for model building based on the training data of legitimate user, and touch pattern variability across different sessions.

Patel et al. (2016) present a review of continuous authentication approaches on mobile devices, which includes physiological and behavioural biometrics. The authors describe face biometric as a modality for continuous authentication. Other than this modality, the authors also describe behavioural biometrics-based continuous authentication approaches such as touch, gait, behaviour profiling (e.g. application usage Bluetooth and Wi-Fi), keystroke, device movement and ambient noise and voice. The authors also discuss other approaches such as linguistic profile, contextual information, and multi-modal continuous authentication. The authors suggest a few points to overcome the challenges in continuous mobile device authentication. These suggestions include the employment of domain adaptive methods since the biometric data at enrolment time may differ from authentication, more attention on the usability and acceptability of a particular method, and biometric template protection schemes for continuous mobile authentication.

Mahfouz et al. (2017) reviewed continuous authentication approaches using behavioural biometrics. The authors describe four behavioural biometrics modalities for continuous authentication on mobile devices, which are touch dynamics, keystroke dynamics, behavioural profiling, and gait. The authors also present fusion methods to combine different modalities using sensor-level, feature-level, score-level, and decision-level fusion techniques. The authors suggest several future directions in behavioural biometric-based continuous mobile device authentication. The suggestions include domain adaptation due to behaviour changes over time, in-depth analysis of behavioural feature extraction and selection, the usability of a scheme, and more attention to computation cost and energy consumption of the scheme.

The work by Ibrahim et al. (2019) present a review on a wide range of authentication approaches on mobile devices. These approaches include the authentication schemes based on PIN, swipe pattern, biometrics, graphical password, and other approaches such as accelerometer, geographical location, and multi-factor authentication approaches. The authors discussed that mobile device-based authentication can be viewed as a multi-objective optimisation problem. The main goal of an authentication method is to maximise the security level while minimising other aspects such as inconvenience level, storage space, or the cost of deployment. Therefore, these problems can be solved using optimisation algorithms to come out with an optimum authentication scheme.

Wang et al. (2020a) also present a review on various authentication approaches on mobile devices, which include and not limited to knowledge-based authentication, biometric-based authentication, and multi-factor authentication. Several multi-factor authentication approaches are presented, such as physiological biometrics with knowledge-based authentication, knowledge-based with ownership-based authentication, and biometrics with ownership-based authentication. The authors found that multi-factor authentication would be the trend of the authentication method on mobile devices because it is able to strengthen the single authentication approach.

Abuhamad et al. (2020) provide a review on continuous authentication on mobile devices using various behavioural biometric modalities such as motion, gait, keystroke, touch dynamics, voice, and multimodal authentication methods. The authors provide insights which include advantages and challenges of these behavioural biometric modalities in terms of adoption, usability, and performance. The authors point out the need for investigating security-related aspects and the consideration of the implementation of a behavioural biometrics method that is beyond the common standards.

1.2. Motivation
The discussed literature highlight the potential of continuous authentication as well as touch-based biometrics as an authentication scheme. While there are existing reviews done in the area of mobile device-based continuous authentication, a comprehensive review of continuous authentication based on touch biometric on mobile devices is still lacking. To the best of our knowledge, none of the existing works provide a comprehensive review that focusses on the topic of touch-based biometrics for continuous authentication on mobile devices. Existing review papers (Wang et al., 2020a, Meng et al., 2015, Ibrahim et al., 2019) are focussing on both static and continuous authentication based on various authentication methods. Besides, other review papers on continuous authentication (Patel et al., 2016, Mahfouz et al., 2017, Abuhamad et al., 2020) cover various methods for continuous authentication based on behavioural biometrics. In general, even though the mentioned review papers have covered touch biometric in their works, continuous authentication based on touch-based modalities is only a very small part of their entire focus. For review paper that is focussing on touch biometric (Teh et al., 2016), it mainly covers on touch biometric based on keystroke dynamics on the virtual keyboard of mobile devices and for both static and continuous authentication.

Our work, on the other hand, focusses specifically on touch-based continuous mobile device authentication, which is intended for readers who have a focussed interest in this area. Specifically, our work discusses the technical details of various aspects of the whole touch-based continuous mobile device authentication framework. These aspects include data acquisition, feature extraction, and classification methods. Since touch biometric is a different biometric modality, understanding the various aspects of the framework is crucial, especially for researchers who are new to the area. Furthermore, we discuss the challenges and opportunities specifically in this area, which is worth investigating due its advantages in term of convenience and non-instructive nature to complement any type of initial-login authentication.

1.3. Objectives and contributions
In this paper, we provide a comprehensive review of touch-based continuous mobile device authentication in different aspects of the domain. The review includes touch biometric data acquisition methods, touch behaviour representations, authentication decision-making methods, and evaluation methods. To the best of our knowledge, there are no existing works that provide a comprehensive review that is entirely focussing on touch biometric for continuous authentication on mobile devices. Therefore, this paper is intended for readers with some background in biometrics who wish to understand and explore some of the recently proposed touch biometrics for continuous authentication in mobile devices.

The main contributions of this paper are as follows:

1.
We present a comprehensive review by focussing on the domain of continuous mobile device authentication based on touch biometric as a supporting form of authentication method for mobile devices. Existing surveys, as mentioned in the previous section, do not entirely focus on touch-based continuous authentication.

2.
We provide an analysis of diverse perspectives and fundamental principles in the research area such as data acquisition, feature extraction, classification, and evaluation methods. We also describe a categorisation of classification methods in term of binary and one-class classification, which is not discussed in the existing surveys in the context of touch-based continuous mobile device authentication.

3.
We present insights on the open issues in the area and recommend the potential opportunity for further exploration for other researchers.

The rest of the paper is organised as follows. Section 2 presents the user authentication methods on mobile devices. Section 3 provides a general overview of touch-based biometric for continuous authentication in mobile devices. Sections 4â€“8, respectively, describe different aspects of touch-based continuous mobile device authentication in term of data acquisition, preprocessing, feature extraction, classification and fusion, and adaptation. Section 9 discusses some of the challenges and open issues in the research area. Lastly, Section 10 concludes this review paper.

2. User authentication on mobile devices
In this section, we provide an overview of the authentication methods used on mobile devices. We then introduce biometric-based user authentication focussing on behavioural biometric. We end the section by introducing the basic working mechanism of continuous user authentication.

2.1. Authentication methods
User authentication on mobile devices is a security mechanism that verifies the legitimacy of a user on the devices. A user may claims his or her legitimacy on a mobile device through several methods, including knowledge-based and biometric-based authentication methods.

2.1.1. Knowledge-based authentication
Knowledge-based authentication is an authentication method that is based on something that a user is aware of and something that the user need to memorise. Password, PIN, and swipe pattern are some of the most commonly used knowledge-based authentication schemes on mobile devices.

Password and PIN are cost-effective from an implementation point-of-view and can provide fast authentication (Kunda and Chishimba, 2018). However, password and PIN have several vulnerabilities (Al Abdulwahid et al., 2016). First, users tend to use a simple and easily guessed password due to the limitation of long-term memory (Meng et al., 2018b). An illegitimate user can access the device by guessing some common passwords (Lu and Liu, 2015). Second, an illegitimate user can also peek at the password or PIN through shoulder-surfing (Khan et al., 2016, Yang et al., 2018). A survey conducted by Nguyen et al. (2017) shown that 73% of participants had learned or observed other usersâ€™ PIN and 79% participants knew the PIN set by their family members or friends. Lastly, some users share their PIN or password with another person (Ayeswarya and Norman, 2019). Sharing password or PIN may expose the device to access by illegitimate users.

Besides password and PIN, swipe pattern codes allow users to draw their pattern codes on a 3 Ã— 3 grid. However, swipe pattern code is vulnerable to shoulder-surfing and smudge attack (Aviv et al., 2010). Smudge attack is performed through the effect of oily residue on mobile device screen after users draw the pattern frequently. Aviv et al. (2010) shows that full or partial pattern recovery is possible through various lighting and camera positions.

Besides, knowledge-based authentication method is also inconvenient to users where the users have to input the password, PIN, or pattern frequently (Abuhamad et al., 2020) which might entice them to disable the authentication method (Shahzad et al., 2017). On top of that, it is a one-time authentication at the initial-login session. It is well-acknowledged that mobile devices nowadays can be automatically locked after some times of idleness. However, in case where the user did not set the device to be locked automatically or an illegitimate user knows the credential and can by-pass the one-time authentication, the device is exposed to illegitimate access.

2.1.2. Biometric-based authentication
Biometric-based authentication has been introduced as an alternative authentication method on mobile devices to overcome the drawbacks of knowledge-based methods. This authentication method is based on the physiological or behavioural characteristic of a user. Unlike knowledge-based methods, users do not need to memorise their password or PIN, and it is more secure, user-friendly, and cannot be forgotten or lost (Ayeswarya and Norman, 2019). The wide adoption of biometric-based authentication in the current market have shown that it is a more robust and reliable authentication method. It can be described in term of physiological or behavioural characteristics. The main goal of an authentication scheme based on biometrics is to distinguish between a legitimate and illegitimate users based on physiological or behavioural characteristics of the user (Meng et al., 2015).

Physiological biometric.
It is the physical characteristics of a user that cannot be shared, such as face and fingerprints. It has a high recognition accuracy because the physiological characteristics of a user is highly unique and make it distinctive when compared against another user. This advantage makes it feasible for authentication (Meng et al., 2015). Physiological biometric requires an installation of specialised hardware on the mobile devices that leads to an extra cost of implementation (Wang et al., 2020a). The specialised hardware is crucial to ensure the quality of the biometric data captured is at a high level so that the scheme can perform authentications with high accuracy. Therefore, a high quality specialised hardware is needed to avoid errors in authentication, which may reduce the security and usability of the scheme. For example, to capture the fingerprint ridges and face features precisely, the device needs to be installed with high quality capacitive fingerprint scanner and a depth sensing front-facing camera, respectively.

In the case of face recognition, a low quality front-facing camera may capture blurry images, which makes it difficult to obtain reliable face features for authentication (Neal and Woodard, 2016). Low quality face images will significantly affect the accuracy of the face recognition scheme (Li et al., 2018). Besides, the scheme requires the users to have direct attention to the camera in order to capture the biometric data (Liang et al., 2020, Abuhamad et al., 2020, Li et al., 2020). For example, the userâ€™s face has to appear at the angle that the front-facing camera can capture it properly. The accuracy of the scheme may also be challenged when there is a change in the environment (e.g. dim or dark environment) or physical appearance such as face masks, make-ups, head wear, spectacles, or surgery, which will reduce the recognition accuracy (Bo et al., 2014). Face recognition is also vulnerable to spoofing attacks (Smith et al., 2015), where face images such as printed and displayed photos can be used to spoof the authentication mechanism. This attack is possible as live and spoofing face images of the same user may be similar. Even though methods for detecting liveliness of face images exist (Wang et al., 2017), these methods require high resolution face images and specialised equipments. For example, iPhone uses specialised infrared sensor for its face recognition, where infrared lights are projected to provide a 3D information about the face of the user (Bud, 2018). Hence, specialised camera is required to capture this kind of high resolution images like the one equipped with depth and infrared sensors. On the other hand, fingerprint recognition suffers from forge attack (Inoue and Ogawa, 2017, Yang et al., 2018).

Similar to knowledge-based authentication method, the physiological biometrics-based authentication method is more suitable for one-time authentication (Meng et al., 2015). This authentication method requires users to interact with the sensors and have to pay a direct attention during the data capturing process (Liang et al., 2020, Abuhamad et al., 2020, Li et al., 2020). This limitation makes it challenging to be used for continuous monitoring. In the event where the device is not set to be automatically locked by default after some time or an illegitimate user can forge the physiological biometrics data to pass the one-time authentication, the device is exposed to illegitimate access (Maatta et al., 2011, Erdogmus and Marcel, 2014). Therefore, if such a case happens, a complementary authentication is needed to further protect the user.

Behavioural biometrics.
It is the behavioural pattern of a user which represents how a user behaves when using a device. The biometric modalities include handwriting, keystroke, touch gesture, gait, signature, voice, and behavioural profiling (Alzubaidi and Kalita, 2016, Wang et al., 2020a). Compared to physiological biometrics, behavioural biometrics are easily affected by usersâ€™ behaviour changes over time, which might lead to a high false rejection rate (Wang et al., 2020a). The high false rejection rate can cause the legitimate user to be frequently rejected by the device, which can cause inconvenience. In other words, behavioural biometric data is less permanence compared to physiological biometric. Besides, the data captured by the sensors are easily affected by noise, which can cause impreciseness in measurements (Mahfouz et al., 2017). The sensors may have a low sampling rate, which can cause imprecise data. The sensors may not be able to collect informative data that can reflect the precise behaviours of users.

Despite of these limitations, behavioural biometrics have many advantages that make it also suitable for user authentication. First, the cost of implementation is much lower compared to physiological biometrics (Meng et al., 2015). Behavioural biometrics does not require specialised hardware to capture biometrics data (Meng et al., 2014). For example, the existing touchscreen can capture typing and swiping data performed by users while using the device naturally. Second, it requires minimal invasion which can increase the acceptability of the public. Lastly and most importantly, it is suitable for continuous monitoring where the device can transparently capture the biometric data of users (Stammati et al., 2016). For example, users can be verified continuously during the period of which they are using the devices (when they perform typing or swiping actions). Hence, it can work in the background while a user is operating the device (Basar et al., 2019). Also, as mentioned in the work by Wang et al. (2020a), it is more acceptable by users as the biometric data is less private compared to body traits like face and fingerprint.

2.2. Mode of authentication
We refer the mode of authentication in two ways. First, static authentication, which is the one-time initial-login session. Second, continuous authentication, which is a continuous monitoring scheme for user authentication.

2.2.1. Static authentication
Static authentication refers to the authentication mode where a user is authenticated at the one-time initial-login session or after some period (Teh et al., 2016). Entry-point authentication methods like password, PIN, swipe pattern, fingerprint recognition, and face recognition are some examples of static authentication. Users are required to focus on the authentication process before they start to operate the device (Frank et al., 2013).

After the user has logged in, the device is unable to verify if the user is still the same user that it has authenticated during the initial-login session (Ayeswarya and Norman, 2019, Perera et al., 2018, Smith-Creasey and Rajarajan, 2017). After this process, the device might be exposed to illegitimate user if the legitimate user does not set the device to be automatically locked or an illegitimate user can by-pass the initial-login authentication. This issue could potentially lead to intrusion into the device by an illegitimate user (Rybnicek et al., 2014, Shen et al., 2018b). Even though it is a quick authentication scheme, there is a need to have a complementary authentication method that can continuously monitor the device usage beyond the initial-login session.

2.2.2. Continuous authentication
Continuous authentication (CA) refers to the authentication mode where a user is verified throughout the entire session after passing the initial-login (Teh et al., 2016, Ahmad et al., 2017). The primary purpose of CA is to detect illegitimate users and to prevent them from accessing a device (Perera and Patel, 2017). CA is a more transparent, non-intrusive, and user friendly authentication method because it does not interfere with the usersâ€™ workflow (Filippov et al., 2018, Shen et al., 2018b, Yang et al., 2014). Behavioural biometric is a suitable modality for CA where it does not require a direct involvement of users when using a device and the sensors can collect the userâ€™s behaviour silently (Lee and Lee, 2017a). This characteristic is necessary since a user cannot authenticate themselves repeatedly (Murmuria et al., 2015).

In CA, once a user is detected as an illegitimate user, the mechanism will lock out the current user and switch to the traditional static authentication mode, i.e. asking for a password, PIN, or swipe pattern code (Filippov et al., 2018). CA can also be implemented along with other static authentication methods as a complementary authentication scheme. The main challenges in developing CA mechanism is its ability to authenticate users accurately in a shorter time and with lower consumption of resources (Perera et al., 2018). Besides, limited data and intra-user variance are also the main challenges in developing such a scheme (Kumar et al., 2016). Intra-user variance occurs when the features that represent the same user changed due to factors such as environment, psychological and physiological factors. Furthermore, CA is also known as active authentication (Saravanan et al., 2014, Shen et al., 2015c, Zhang et al., 2015, Lee et al., 2016, Perera et al., 2018), dynamic authentication (Alghamdi and Elrefaei, 2018), and implicit authentication (Khan et al., 2016, Shen et al., 2018a).

In this work, we focus on a type of behavioural biometric, namely, touch biometric for continuous authentication. We will discuss the fundamental principal of touch-based biometric for continuous mobile device authentication and present state-of-the-art in touch-based continuous mobile device authentication in the following sections.

3. Touch-based biometric for continuous mobile device authentication
The touchscreen is dominating user inputs for computing devices due to its usability and robustness to work with other complementary technologies (Shahzad et al., 2017). It is also the primary source of inputs for mobile devices, which makes it possible to be used as an authentication tool (Palaskar et al., 2016). Users usually interact with the screen by performing tap, double-tap, long press, swipe, pinch, rotate, and flick gestures (Ahmad et al., 2017). Typically, a touch gesture starts with touch down and ends with a touch up (Murmuria et al., 2015).

Touch biometric, also known as touch dynamics is the measurement of the touch pattern of users on touchscreen of mobile devices, such as smartphones and tablets. Several studies have shown that the behaviour of users when interacting with the touchscreen of a mobile device is discriminative and unique for each user, which in return, can be potentially used as one of the biometrics modalities (Frank et al., 2013, Serwadda et al., 2013, Li et al., 2013). Touch gestures are influenced by hand geometry and muscle behaviour, which provide discriminative capability of the modality (Feng et al., 2014, Feng et al., 2015b).

Touch dynamics share some similarities and differences with keystroke dynamics and mouse dynamics (Meng et al., 2013). In term of similarities, touch dynamics capture usersâ€™ gesture of touch down and touch up, which resemblance the way how keystroke dynamics capture usersâ€™ press down and press up on traditional keyboard. When compared against mouse dynamics, touch dynamics are also quite similar to it, where the former capture usersâ€™ action of click and movement when using the mouse and the latter capture usersâ€™ touch movement (such as swipe). The main differences between touch dynamics and keystroke as well mouse dynamics is that touch dynamics allow capture of multiple interactions simultaneously (e.g. swipe, -zoom, pinch and etc. when users are using more than one finger). These touch actions commonly known as multi-touch actions, while keystroke and mouse dynamics do not allow multi-actions (Meng et al., 2013).

The rest of this section explains the historical overview of touch-based continuous mobile device authentication, the strength of the scheme as well as the challenges in developing the scheme, its general framework, and metrics used to evaluate the performance of a particular scheme.

3.1. Historical overview
Many research have focussed on behavioural biometrics as a biometric modality for user authentication on computing devices. Before the rise of research in touch-based biometric, extensive research had been carried out to evaluate the feasibility of behavioural biometrics such as keystroke and mouse dynamics on desktop computers. Behavioural biometrics like keystroke dynamics is used to further reinforced the traditional password by using behavioural features such as duration of keystroke and time latencies between keystrokes (Monrose et al., 2002).

The increasing usage of mobile devices has led to growing interest in research on user authentication for these devices. The drawbacks of the traditional user authentication schemes (e.g. password/PIN) in term of security and usability for mobile devices have attracted interest in the research on the alternative methods of authentication. Early studies attempted to employ keystroke dynamic on feature phones using the built-in keypad for static (seob Hwang et al., 2009) and continuous authentication (Clarke and Furnell, 2006).

The advancement in mobile-based technologies have revolutionised mobile device to shift from keypad-based into touchscreen-based mobile devices due to the popularity and ease-of-use of touchscreen as the primary source of inputs. Although there is a shift to touchscreen-based mobile devices, behavioural biometric such as keystroke dynamics were still being been adopted into touchscreen-based virtual keyboards (Zahid et al., 2009, Damopoulos et al., 2013, Tasia et al., 2014, Alghamdi and Elrefaei, 2015, Shen et al., 2015a). Before the rise of the research in touch gesture-based authentication for mobile device, there were studies on gesture-based authentication on touchpad of notebooks (Saevanee and Bhatarakosol, 2008) and tabletops (Kim et al., 2010). Several early studies (Seo et al., 2012, Sae-Bae et al., 2012) have shown the feasibility of touch gesture on the mobile deviceâ€™s touchscreen. The traditional user authentication like PIN (Teh et al., 2019, Zheng et al., 2014) and swipe patterns (De Luca et al., 2012, Meng, 2016) have been combined with touch behaviour biometrics to improve the security of these traditional authentication approaches.

Research in the area of touch-based authentication have been further advanced with the usage of the touch movement and multi-touch events, which possess more behavioural events compared to tap gestures (Meng et al., 2018b). This development has emerged in continuous authentication based on touch biometric. One of the early studies on continuous authentication based on touch gesture can be seen in the work presented by Frank et al. (2013), where the authors proposed swiping actions as the modality to perform continuous authentication. Many research have carried out studies on touch-based authentication from different aspects and perspectives such as using different type of gestures (Xu et al., 2014, Alghamdi and Elrefaei, 2018, Meng et al., 2018a, Smith-Creasey and Rajarajan, 2019), feature extraction methods (Frank et al., 2013, Meng et al., 2014), classification methods (Fierrez et al., 2018, Meng et al., 2018a, Chang et al., 2018, Choi et al., 2018, Filippov et al., 2018), usage context (Meng et al., 2018b), and performance metric (Mondal and Bours, 2015b).

3.2. Strengths
There is a growing interest in touch-based authentication as one of the biometric-based authentication methods in recent years due to the increasing development of touchscreen-based devices (Meng et al., 2015). This interest increases the popularity due to its strength in multiple aspects of user authentication, which will be further discussed below.

3.2.1. Non-intrusive
Touch-based continuous mobile device authentication is able to collect touch data while a user is using the device naturally, without interrupting or disturbing their normal usage on the mobile devices (Feng et al., 2012, Mahfouz et al., 2017). The scheme does not require the user to pay a direct attention to the sensor during the authentication process (Gong et al., 2016, Yang et al., 2018). The user can use the device normally by interacting with the touchscreen as in the normal device usage and in any posture that the users prefer. This advantage makes it possible for touch-based biometric to be used for continues authentication (Syed et al., 2019). The non-intrusive nature of touch-based continuous mobile device authentication also provides a higher usability for end users compared to other biometric modalities for continuous authentication (e.g. face recognition) that require a user to interact directly with the sensors (Liang et al., 2020, Abuhamad et al., 2020, Li et al., 2020). Therefore, touch biometric provides some level of advantage for continuous authentication, which can complement with other one-time authentication methods.

3.2.2. Cost-effectiveness
No additional hardware is needed to collect the touch behaviour data (Meng et al., 2013, Xu et al., 2014, Shen et al., 2015c, Alghamdi and Elrefaei, 2018, Meng et al., 2018a, Meng et al., 2018b, Fierrez et al., 2018). The existing hardware, which is the touch sensor, can be used to collect relevant data to be used for touch-based continuous authentication. Other sensors (e.g. motion) can also be used to collect the data alongside data from touch sensors. As these sensors are already available on most of the modern mobile devices and touch-based data do not require dedicated hardware for data acquisition, it has the advantage of cost-effectiveness (Alghamdi and Elrefaei, 2018).

3.3. Challenges
Similar to any other biometrics modality, there are several challenges in touch biometric to provide a secure and useable continuous authentication mechanism.

3.3.1. Accuracy
Existing studies (Frank et al., 2013) have shown that touch biometric has a high inter-class variance, which allows the mechanism to easily distinguish between different unique users based on their touch biometric. However, this biometric modality also possesses a high intra-class variability (Xu et al., 2014, Mondal and Bours, 2015b, Mondal and Bours, 2015a), where the behaviour of the same user may change over time due to factors such as emotion and environment (Syed et al., 2015). These issues lead to challenges in the task of user classification. It also may reduce the classifier accuracy (Palaskar et al., 2016). Besides, the diversity of touch operations performed by users under different situations may also lead to unstable performance of a classifier (Yang et al., 2018). The poor performance of a classifier will cause high rate of accepting illegitimate user, which compromise the security of the device, also known as false positive. On top of that, false negative, which unintentionally locks out legitimates user, may cause inconvenience to them, which reduce the usability of the scheme.

3.3.2. Efficiency
As a continuous authentication scheme, a touch-based continuous mobile device authentication is expected to lock out illegitimate access as fast as it can. If the scheme takes too long time to detect illegitimate access, an illegitimate user will have plenty of time to access the information stored on the device (Perera et al., 2018). On top of the detection authentication accuracy, the scheme should have been able to perform efficient authentication.

3.4. General framework
Continuous user authentication based on touch biometrics is similar to the traditional biometric-based user authentication scheme, where it has an enrolment phase and authentication phase, as shown in Fig. 1. During the enrolment phase, the scheme acquires touch data from the touch gestures of the legitimate user. The scheme extracts the behavioural features from the raw touch data of the user and will generate a template for the user and store it as a user profile in a database.

During the authentication phase, the scheme captures touch data and extracts relevant features. The scheme compares these features with the userâ€™s profile using a classification algorithm (Meng et al., 2018b). If the scores from the classifier are above the predefined threshold, the current user is classified as a legitimate user and can continue to use or operate the device. Otherwise, the user will be classified as an illegitimate user and will be locked out from the device. The scheme will continue to perform authentication until the legitimate user locks the device. Next, we will discuss each module involved in the enrolment and authentication phases, which starts with the data acquisition module and ends with the decision-making module. Moreover, we present an optional module which is the adaptation module.

3.4.1. Data acquisition module
Raw touch data such as timestamp, location, pressure, and size of a touch area are acquired using the touchscreen sensor of the devices (Frank et al., 2013). These raw data are captured from the touch gestures like tap, swipe, zoom, and pinch performed by a user. The devices used for this purpose are the devices equipped with touchscreen, i.e. smartphones (Frank et al., 2013, Shen et al., 2015c, Meng et al., 2018b, Yang et al., 2018) and tablets (Syed et al., 2019). If the scheme is a touch-based multi-biometric, it will also employ other sensors (e.g. motion sensors) (Sitova et al., 2016, Smith-Creasey and Rajarajan, 2019). These raw data will later be used to extract more meaningful information to represent a user behaviour at the feature extraction module. Section 4 discusses further the data acquisition approaches in touch-based mobile device continuous authentication.

3.4.2. Preprocessing module
The preprocessing module will preprocess the data before the training phase using a classification algorithm. Preprocessing methods such as outlier removal (Frank et al., 2013, Murmuria et al., 2015, Shen et al., 2015c, Yang et al., 2018, Syed et al., 2019, Fierrez et al., 2018) and standardisation (Serwadda et al., 2013, Palaskar et al., 2016, Antal and SzabÃ³, 2016, Yang et al., 2018, Choi et al., 2018, Fierrez et al., 2018) can be implemented to improve the quality of the data and can be helpful in improving the performance of a classification algorithm. Section 5 further discusses the preprocessing techniques used in the area.

3.4.3. Feature extraction module
The feature extraction module will generate a set of features based on the raw data collected for each touch action. The features represent the discriminative profile of a user. Touchscreen-based feature sets such as touch duration, touch area, touch pressure, and touch position represent the behaviour of a user when performing touch actions on the touchscreen of a mobile device (Frank et al., 2013, Shen et al., 2015c, Yang et al., 2018, Fierrez et al., 2018, Syed et al., 2019, Meng et al., 2018b). Other than touchscreen-based features, other features can also be extracted alongside with touch features such as keystroke (Xu et al., 2014, Sitova et al., 2016) and motion features (Sitova et al., 2016, Smith-Creasey and Rajarajan, 2019), which are touch-based multi-biometrics features. Section 6 discusses further the feature extraction approaches in touch-based continuous mobile device authentication.

3.4.4. Matching module
In the enrolment phase, the profile of the legitimate user is built to model the user based on the features extracted from the data. In the authentication phase, the features of an unknown user is then compared with the profile of the legitimate user to generate matching score. Therefore, the matching module involves two components, which are generating the user profile and classifying users:

â€¢
User profile generation: During the enrolment phase, the features of the legitimate user are used to build a user profile using approaches such as distance-based approach (Serwadda et al., 2013, Sitova et al., 2016) and machine learning algorithms (specifically a classifier) (Frank et al., 2013, Shen et al., 2015c, Fierrez et al., 2018, Syed et al., 2019). If the matching module uses a binary classifier (Frank et al., 2013, Shen et al., 2015c, Fierrez et al., 2018, Syed et al., 2019), the classifier is trained using the feature of the legitimate users as the positive samples and the features of illegitimate users as negative samples. If the module uses a one-class classifier (Sitova et al., 2016, Yang et al., 2018), it will only use the features of the legitimate user for training the classifier. The same classifier will be used to classify an unknown user as legitimate or illegitimate user.

â€¢
User classification: During the authentication phase, the features of an unknown user will be compared against the profile of the legitimate user to determine its legitimacy. The classification process will usually produce a matching score. The scores indicates the similarity between the features of the unknown user with the profile of the legitimate user.

3.4.5. Decision-making module
The decision-making module will make an authentication decision whether to allow the current user to continue using the device or to lock the user out. The decision is typically made based on a threshold (Syed et al., 2019). If the matching score is above the threshold, the scheme will allow the user to continue to use the device, and locked out if otherwise. The threshold value can be determined based on different criteria such as the difference between false rejection rate (FRR) and false acceptance rate (FAR). FRR is the probability that the scheme incorrectly detects the touch strokes of the legitimate user as the strokes of illegitimate users. On the other hand, FAR is the probability that the scheme incorrectly detects the touch strokes of illegitimate users as the stroke of the legitimate user. It is worth nothing that some schemes perform fusion at the level of feature (Kumar et al., 2016, Choi et al., 2018), score (Kumar et al., 2016, Sitova et al., 2016, Kumar et al., 2018, Fierrez et al., 2018, Smith-Creasey and Rajarajan, 2019), or decision (Kumar et al., 2018) before the authentication decision is made.

3.4.6. Adaptation module
The user profile adaptation module is optional. In this module, the user profile in the database is updated to ensure the long-term performance of the continuous authentication system. The literature has shown that the user behaviour of a user will change over time due to emotional and environmental factors (Palaskar et al., 2016, Syed et al., 2015). Therefore, the user profile can be updated to overcome the problem of decreasing performance over time (Feng et al., 2014, Buduru and Yau, 2015, Palaskar et al., 2016).

3.5. Performance evaluation
The main aim of a continuous authentication scheme is to lockout illegitimate users from using the device as soon as possible and allow the legitimate user to continue using the device while ensuring the legitimate user is not lockout. To achieve this aim, several criteria are considered to evaluate the performance of a proposed continuous authentication scheme. These criteria are measured based on certain evaluation metrics.

In the existing studies, there are two main criteria that are considered to evaluate the performance of a continuous authentication scheme which are security and usability (Perera et al., 2018), where the former limits the access by illegitimate users and the latter maintains the convenience of that user. A continuous authentication scheme is expected to be able to detect illegitimate users at a high rate (Zhou et al., 2016). This criteria is necessary to avoid unwanted information leakage. The better the detection, the higher the security. A continuous authentication scheme is also expected to protect the privacy of userâ€™s data.

Beside being able to detect an illegitimate access at a high rate, a continuous authentication scheme should also avoid causing inconvenience for the legitimate user. If the scheme unintentionally locks out the legitimate user frequently, it will reduce the usability of the scheme where users have to revert back to the static authentication method (Perera et al., 2018). A continuous authentication scheme should also have the ability to quickly detect illegitimate access while maintaining the security and usability (Perera et al., 2018). More extended authentication period may allow an illegitimate user to access the device.

3.5.1. False acceptance rate (FAR)
False acceptance rate (FAR) is the probability of touch actions performed by illegitimate users, that were wrongly detected as touch actions performed by the legitimate user. A low FAR indicates the scheme accepts fewer illegitimate users and implies a better scheme in terms of security (Meng et al., 2018a, Alghamdi and Elrefaei, 2018, Meng et al., 2018b). FAR can be calculated as follows in Eq. (1): (1)where  is the number of touch samples of illegitimate users that are classified as touch samples from the legitimate user, and  is the total number of touch samples of illegitimate users.

3.5.2. False rejection rate (FRR)
False rejection rate (FRR) is the probability of touch actions performed by the legitimate user, which were falsely detected as touch actions performed by illegitimate users. A low FRR indicates the scheme rejects less legitimate users and is convenient for the user in terms of usability (Meng et al., 2018a, Alghamdi and Elrefaei, 2018, Meng et al., 2018b). Eq. (2) shows the calculation of FRR. (2)where  is the number of touch samples of legitimate users that classified as touch samples from the illegitimate user and  is the total number of touch samples of legitimate users.

FAR can be more critical than FRR because a high FAR indicates the failure of the scheme by accepting too many illegitimate users. In contrast, a high FRR only indicates the low usability of the scheme, which is less convenient for the legitimate users (Hao and Li, 2016). Both FAR and FRR require a smaller value, which indicates small errors in the scheme that has higher security as well as usability.

It is worth noting that a threshold can be adjusted to make the scheme more useable or more secure (Syed et al., 2019). The threshold can be lowered to increase the usability with low FRR, but at the cost of high FAR (less restrictive). On the other hand, the threshold can also be increased to be more restrictive with low FAR, but high FRR (less useable). A user-specific threshold can be adjusted for the authentication decision to allow more usability or more security (Al-Rubaie and Chang, 2016, Kumar et al., 2016). It can be done by varying the threshold (Al-Rubaie and Chang, 2016). Moreover, an adaptive threshold can be employed. For example, Smith-Creasey and Rajarajan (2017) proposed a technique for an adaptive threshold by comparing the real-time and historical data to adjust a trust parameter.

3.5.3. Equal error rate (EER)
An equal error rate (EER) measures the trade-off between security and usability (Meng et al., 2018a, Meng et al., 2018b), and it is the most used performance evaluation metric in biometric-based authentication scheme (Chang et al., 2018). EER is the value when FAR equals FRR (Khan et al., 2016). EER measures the overall accuracy of a continuous authentication schemes and its comparative performance with other schemes (Teh et al., 2016). EER is also used to measure the overall performance of an authentication scheme regardless of parameters used (Murmuria et al., 2015). It is worth to note that varying the threshold of decision value of a classifier is usually used to obtain ERR (Al-Rubaie and Chang, 2016). Eq. (3) shows the calculation of EER. (3)where the difference between FAR and FRR should have the smallest value based on the variation of thresholds (Smith-Creasey and Rajarajan, 2017). Lower EER indicates a more secure and useable authentication scheme. Therefore, a smaller EER is preferred (Nguyen et al., 2017). In the case of continuous authentication scheme, it can detect illegitimate users better, and the legitimate users do not have to be locked out frequently (Smith-Creasey and Rajarajan, 2019). EER of  indicates a perfect classification (Palaskar et al., 2016). However, in reality, it is unrealistic to achieve a perfect authentication accuracy as the classifier may not be able to accurately classify all touch strokes.

3.6. True acceptance rate
True acceptance rate (TAR) is the probability of touch actions performed by legitimate users, that were correctly detected as touch actions performed by that legitimate user. A higher TAR indicates the scheme accepts legitimate users at a higher rate and implies a better scheme. TAR can be calculated as follows in Eq. (4): (4)where  is the number of touch samples of legitimate users that are classified as touch samples from that legitimate user, and  is the total number of touch samples of that legitimate user. In other words, TAR can also be considered as .

3.6.1. Classification accuracy
Classification accuracy (ACC) is a metric to measure the detection ability of a classifier. It considers the accuracy in terms of correctly detected touch samples from all touch samples in a particular session. It is calculated in Eq. (5). (5)where  is the number of correctly detected touch samples of legitimate user,  the number of correctly detected touch samples of illegitimate user and  is the total number of touch samples in the session.

3.6.2. Receiver Operating Characteristics (ROC)
Receiver Operating Characteristics (ROC) curve uses the axis of true acceptance rate (TAR), and false acceptance rate (FAR) at different threshold values (Palaskar et al., 2016, Smith-Creasey and Rajarajan, 2019). TAR is the ratio of touch strokes of legitimate users that are correctly classified as strokes of a legitimate user () and FAR is the ratio of touch samples from the illegitimate users that are incorrectly classified as touch strokes of legitimate users. ROC graphically reflects the performance of a continuous authentication based on trade-off between TAR and FAR with various threshold values. The curve of a scheme that is close to the top-left corner of the plot indicates a better performance with a higher TAR with a lower FAR (being able to detect the legitimate user at a higher rate with a lower acceptance of illegitimate user) (Mostafa et al., 2019). For example, in Fig. 2, Scheme B performs better than Scheme A as its curve is closer to the top-left corner of the plot.

3.6.3. Area under the curve (AUC)
Area under the ROC curve (AUC) is a summary of the performance of a scheme in a single value (Mostafa et al., 2019). A larger value of AUC indicates a better performance of a scheme compared to another (Teh et al., 2016). As in Fig. 2, the AUC for Scheme B is higher than Scheme A. Therefore, Scheme B is better in this example. As an instance from the literature, the work by Kumar et al. (2018) use AUC as one of the performance metrics to compare the performance of single one-class classifiers with the fusion of the classifiers. The authors achieve AUC of 89.63% compared to 89.41% when using the best single classifier (one-class Support Vector Machine) based on their experiments with touch and phone movement dataset.

To evaluate the performance of a touch-based continuous mobile device authentication scheme, touch data have to be acquired as a starting point in designing a scheme. The next section discusses the technique used in data acquisition.

4. Data acquisition
In this section, we describe the data acquisition methods used in touch-based continuous mobile device authentication for mobile devices. We describe the methods in several perspectives, which include devices used, sensors involved, acquisition tool, subjects participated, collection period, environment, the task required, and types of gestures performed. We also discuss in this section some of the publicly available datasets in the area of touch-based continuous mobile device authentication.

Table 2 summarises the data acquisition techniques used in the related studies. The table shows the techniques used to acquire the data in terms of operating system (OS) of the device used, the sensor used to collect the data, the acquisition tool, the number of subjects, period of data collection, the number of sessions throughout the data collection, the duration of each session, the interval between sessions, experimental environment and touch operation employed. It can be seen that different studies used a slightly different protocols for data acquisition. This section explains more on the techniques used in data acquisition based on the related studies.


Table 2. Data acquisition techniques.

Author	OS	Sensor	Tool	Subject	Period	Session	Duration	Interval	Environment	Operation
Frank et al. (2013)	An	To	App	41	1 d	7	3â€“15 m	min/weeks	C	Sw
Li et al. (2013)	An	To	Custom	75	1 d	â€“	â€“	â€“	U	Ta, Sw
Meng et al. (2013)	An	To	Custom	20	3 d	6	10 min	â€“	U	Ta, Sw, Mul
Serwadda et al. (2013)	An	Touch	App	190	â€“	2	â€“	1 d	C	Sw
Bo et al. (2014)	An	To, Mo	App	100	1 d	â€“	â€“	â€“	â€“	Ta, Sw, Fl
Feng et al. (2014)	An	To	App	123	3 w	â€“	â€“	â€“	U	Ta, Sw, Mul
Xu et al. (2014)	An	To	App	32	1 m	â€“	15 min	â€“	C	Sw, Mul, Ty, Wri
Murmuria et al. (2015)	An	To, Mo, Po	Custom	73	2 d	2	45	1 d	C	Ta, Sw, Mu
Shen et al. (2015c)	An	To	App	71	â€“	3	â€“	1 d	U	Sw
Mahbub et al. (2016)	An	Toa	App	48	2 m	248	1 w	â€“	U	Sw
Sitova et al. (2016)	An	To, Mo	App	100	â€“	8	11.6 m	â€“	C	Ty
Zhou et al. (2016)	An	To	App	12	â€“	20	â€“	2â€“72 h	C	Ty
Meng et al. (2018a)	An	To	Custom	60	5 d	30	â€“	â€“	U	Ta, Sw, Mul
Meng et al. (2018b)	An	To	Custom	48	3 d	20	10 m	â€“	U	Ta, Sw, Mu
Shen et al. (2018b)	An	Mo	App	102	20â€“50 d	9	8 h	1 d	U	Ta, Sw
Yang et al. (2018)	An	To	App	45	2 w	â€“	â€“	â€“	â€“	Ta, Sw
Syed et al. (2019)	An	To	App	31	2â€“3 w	8	3	â€“	â€“	Sw
Smith-Creasey and Rajarajan (2019)	An	To, Mo	App	20	â€“	9	â€“	â€“	C	Ty
Abbreviations have the following meaning: An  Android OS, To  touch sensor, Mo  motion Sensor, Po  power sensor, m  month, d  day, w  week, min  minute, h  hour, C  controlled environment, U  uncontrolled environment, Ta  tap, Sw  swipe, Fl  fling, Mu  multi-touch, Ty  type, Wri  Handwriting, â€˜â€“â€™  not available.

a
In Mahbub et al. (2016), various sensors were also employed, which include front-facing camera, motion sensors, light sensor, GPS, Bluetooth, WiFi, proximity sensor, temperature sensor and pressure sensor.

4.1. Device
According to StatCounter (StatCounter GlobalStats, 2019), Android is the most widely used operating system (OS) for mobile devices with 74.13% of the market share worldwide as of December 2019. The usage of Android-based devices for research in the area of touch-based mobile device continuous authentication will be more impactful since the results obtained can be applied to a large number of mobile devices (Syed et al., 2019). To the best of our knowledge, most researchers use Android-based mobile devices to collect touch data.

The usage of the same operating system (OS) in data acquisition can ensure consistency in the data collected from all subjects (Meng et al., 2018b, Li et al., 2021). Different mobile device OS may have a different definition of touch actions (Meng et al., 2018b), which may affect the authentication performance. Apart from that, differences in screen size and resolutions of mobile devices could also result in biases in data acquisition (Serwadda et al., 2013, Feng et al., 2015b, Syed et al., 2019, Smith-Creasey and Rajarajan, 2019). For example, Feng et al. (2015b) found that the performance of touch-based authentication scheme is better when experimented with devices equipped with larger screen size.

On top of that, Android is an open-source OS where it offers a certain degree of freedom in terms of access to its features and functionality, which is a good fit for evaluating the effectiveness of touch-based continuous mobile device authentication (Smith-Creasey and Rajarajan, 2017). The OS can be modified by changing its application framework layer to record and collect raw data from the touchscreen (Meng et al., 2018b, Li et al., 2021).

4.2. Sensors
The role of sensors on a mobile device during data acquisition is to measure the actions performed by users and translate the signals into data that can be understood by a computing device. In general, a mobile device is equipped with touchscreen sensors, motion sensors, environmental sensors, and position sensors (Shen et al., 2018b). The primary sensor used in the area of touch-based continuous mobile device authentication is the touchscreen of the device (Shen et al., 2018b). Touchscreens can capture touch coordinates, touch pressure, touch area, and timestamp for each touch action (Cai et al., 2013, Serwadda et al., 2013). It can also detect up to 10 simultaneous touch actions (Leyfer and Spivak, 2019).

Moreover, some of the existing studies also include the signals collected from other sensors (Murmuria et al., 2015, Sitova et al., 2016, Smith-Creasey and Rajarajan, 2019). The purpose of using sensors other than the touch sensor is to increase the authentication performance (Shen et al., 2018b). For example, users may develop behavioural patterns in terms of rhythm, strength, and angle (Shen et al., 2018b). Motion-based sensors such as accelerometers, gyroscopes, and magnetometers are employed to measure behavioural patterns as mentioned earlier. An accelerometer measures the acceleration of the device in three different axes: lateral, longitudinal, and vertical axes (Smith-Creasey and Rajarajan, 2019, Shen et al., 2018b). A gyroscope measures the rate of rotation in three axes as well: pitch, roll, and azimuth (Smith-Creasey and Rajarajan, 2019). A magnetometer measures the ambient geomagnetic field (Shen et al., 2018b). The behavioural data collected from these sensors are collected alongside the touch data from the touch sensor to collect the multi-biometrics data.

4.3. Tools
Android OS usually does not allow the implementation of a background programme to collect touch data. This limitation causes the experimental protocol for data collection to be carried out with a simulated app (Syed et al., 2019). Furthermore, to collect data from a virtual keyboard, a custom virtual keyboard is used to collect the data. This custom keyboard is also used since Android does not permit a third-party application to access the information generated from touch and keypress (Sitova et al., 2016). However, Android device based on Google Nexus allows the modification of its OS to record raw data from the touchscreen (Meng et al., 2018b).

4.4. Subjects
Subjects for data acquisition are selected based on several demographical characteristics such as age, gender, and profession. Different characteristics of subjects may show different behaviour in terms of familiarity of usage of the touchscreen-based device. In general, studies in the area of touch-based continuous mobile device authentication choose subjects that are readily available, such as students, academic staffs, and colleagues at their institutions (Frank et al., 2013). The use of such subjects may reduce the cost of acquiring the data. There might be a higher chance of a similar behavioural profile if the population is large (Shen et al., 2018b). However, it is challenging to evaluate the performance of a system that involves a larger number of users (Meng et al., 2018b). Thus, most studies used a smaller number of subjects for data acquisition. It is worth noting that it is better to acquire data from subjects who are familiar with the touch-based device as this will provide a more realistic outcome (Syed et al., 2019).

4.5. Session, duration and interval
A session starts when a subject begins to use the device to perform the task and ends when the subject has stopped using the device. Typically, the subjects were asked to perform a task to collect the data in a particular duration. There will be an interval between each session. For example, Frank et al. (2013) collected the data for several sessions. The authors separated the sessions in two ways: several sessions on the same day with an interval of several minutes and one session in at least a week later. In each session, the subjects took around 3 to 15 min to perform the task. Besides, Serwadda et al. (2013) collected the data in two sessions, where the interval between these two sessions is at least one day.

4.6. Environment
The environment for the subjects to perform the task can be in a controlled or uncontrolled environment. Controlled environment refers to instances where the subjects are placed in a place to perform the taskâ€”for example, a lab. Bias can be avoided if the data are collected in a controlled environment. However, there is a limitation in a lab study where the subjects are not performing the actual activities as they usually do with the device. Thus, an uncontrolled environment can be used where the subjects can freely perform the task in anywhere they prefer, which will result in more realistic data (Feng et al., 2015b, Meng et al., 2019, Li et al., 2021).

4.7. Tasks
Subjects are given tasks related to touch interaction with the device. The tasks can be pre-defined tasks or free tasks. Pre-defined tasks can be given to the subjects such as the finger to be used, activities (e.g. sitting, standing, and walking) (Sitova et al., 2016, Smith-Creasey and Rajarajan, 2019, Incel et al., 2021), application usage (Meng et al., 2019, Li et al., 2021, Incel et al., 2021) and screen orientation (Ali et al., 2016, Syed et al., 2019). Several studies (Shen et al., 2015c, Meng et al., 2018b, Smith-Creasey and Rajarajan, 2019, Li et al., 2021) showed that the performance of the scheme based on pre-defined activities is better than free tasks. The better performance could be due to touch actions in pre-defined activities are more predictable and stable (Meng et al., 2018b, Li et al., 2021) with smaller variability (Shen et al., 2015c) when compared to free tasks, which are more sporadic. Besides, Murmuria et al. (2015) found that usersâ€™ behaviour is different from one application to another. Besides, when a user is handling a device, there are some effects of contextual behaviour on the performance of a scheme (Feng et al., 2015b). The examples of the usage context include screen size, physical context (e.g. standing, sitting or walking) and application context (e.g. email, browser, map, and social media).

4.8. Touch operations
Touch operations can generally be categorised into single touch, touch movement, and multi-touch (Meng et al., 2018b). Single touch refers to the touch action that starts with a touch down and ends with a touch up without any movement (e.g. tapping and typing). Touch movements refer to the touch action that also starts with a touch down and ends with touch up, but there are movements from a point to another point on the screen (e.g. swipe, flick, and drag). Multi-touch refers to the gesture that starts with a touch down at two or more different locations on the screen, with or without movement and ends with touch up (e.g. zoom, pinch, and rotate).

The types of actions performed on the screen can affect the performance of the touch-based authentication. For example, it was shown by Fierrez et al. (2018) that horizontal swipe generally produces the best performance because it is performed frequently and has more distinctive information. In general, more types of touch gesture performed by the users will provide more features to be used for touch-based continuous authentication. However, the increase in features may increase the variance for the classifier (Meng et al., 2018b). It is also worth noting that different touch gestures may have different characteristics of the touch actions (Xu et al., 2014). Other than touch gestures, typing on the virtual keyboard and drawing on the screen are also considered as the touch inputs on touch-based mobile devices (Shi et al., 2011).

4.8.1. Tap
Tap is the most frequently used touch gesture (Filippov et al., 2018). However, this gesture has little information to represent the touch behaviour of a user (Bo et al., 2013). A study conducted by Yang et al. (2018) showed that the performance of tap is inferior compared to swipe. This lower performance could be attributed to the less information obtained from the tap gesture (Frank et al., 2013), which is usually used to open a file or application.

4.8.2. Swipe
A user can perform a swipe by moving a finger horizontally or vertically which starts with touch down, followed by finger movement, and ends with touch up (Antal and SzabÃ³, 2016). It is usually performed for scrolling (Frank et al., 2013, Fierrez et al., 2018, Yang et al., 2018), horizontal sliding (Frank et al., 2013, Yang et al., 2018), and oblique sliding (Yang et al., 2018). Other than these gestures, dragging gestures also involves touch down and up with movement in between (Alghamdi and Elrefaei, 2018). Swipe is the most frequently performed touch gestures on mobile devices (Serwadda et al., 2013, Shen et al., 2015c). Thus, it is also widely used touch-based continuous mobile device authentication where it is usually used to perform actions such as reading text and browsing pages (Xu et al., 2014).

4.8.3. Typing
Typing refers to the typing pattern or rhythm of a user while he or she is typing (Teh et al., 2013). Examples of input devices used for typing are computer keyboard or the virtual keyboard of a mobile device. In the case of a mobile device, the virtual keyboard uses the touch screen sensor as the primary source of input. To employ this touch input, a user has to perform continuous tapping actions like a normal typing activity (Xu et al., 2014). Originally, typing on a touchscreen is also part of a tapping gesture. A user performs this touch action entirely on the virtual keyboard of a mobile device to produce text input (Meng et al., 2015). A continuous authentication scheme can use this gesture as an authentication tool based on the unique way how each type on a keyboard (Alzubaidi and Kalita, 2016). Other than performing typing by tapping on the screen, a user can also slide through the virtual keyboard to produce text input. Smith-Creasey and Rajarajan (2019) explored typing-based features where the users performed typing by sliding a finger on the virtual keyboard instead of tapping. The features proposed by the authors performed better than the features proposed in other typing-based features by around 81%.

4.8.4. Multi-touch gestures
Multi-touch gestures involve two or more fingers to perform a touch action. For example, users operate with two fingers to perform zoom and pinch gestures from one point to another in a specific direction (Alghamdi and Elrefaei, 2018). These gestures are typically used to increase or decrease the size of an object on the screen. Rotation gestures also involve multi-touch of two fingers to rotate an object on the screen. Besides, multi-touch movements are less frequent (Frank et al., 2013, Shen et al., 2015c, Yang et al., 2018), and it has high variability.

4.9. Public datasets
Most studies in the area of touch-based continuous mobile device authentication employed a private dataset, where the authors do not disclose the data. A publicly available dataset is very crucial to enable researches to replicate the findings and perform comparative experiments. The experiments may be useful in improving the replicability and generalisability of their research findings. Comparative experiments can be carried out by comparing different algorithms or different experimental settings on the same dataset. In return, this will allow researchers to focus more time on other challenging issues in the area of touch-based continuous mobile device authentication and spend less time and resources on data collection. However, the availability of dataset for public use is still limited in touch-based continuous mobile device authentication, which makes it hard to perform comparative studies.

We have identified six publicly available datasets where touch biometric is involved. For some datasets, modalities such as face (Mahbub et al., 2016) and motion (Yang et al., 2014), which were also collected from sensors other than touch sensor. The datasets are summarised in Table 3. It is worth noting that the datasets listed in Table 3 are chosen based on its suitability for touch-based continuous mobile device authentication. In the following subsections, we briefly describe the datasets presented in Table 3, and discuss how it is suitable for touch-based continuous mobile device authentication.


Table 3. Publicly available datasets on touch-based biometric for continuous authentication.

Dataset	Subject	Sensor	Gesture	Session	Duration	Interval	OS	Environment	Features
Frank et al. (2013)	41	To	Sw	7	25â€“50 min	min/w	An	C	30
Serwadda et al. (2013)	190	To	Sw	2	â€“	1 d	An	C	28
Antal et al. (2015)	71	To	Sw	â€“	4 w	â€“	An	C	15
Mahbub et al. (2016)	48	Toa	Sw	248	1 w	â€“	An	U	24
Syed et al. (2019)	31	To	Sw	8	3 min	â€“	An	C	18
Yang et al. (2014)	100	To, Mo	Ta, Sw, Fl, Mul, Ty	24	5â€“15 min	â€“	An	C	400
Abbreviations have the following meaning: To  touch sensor, Mo  motion Sensor, Ta  tap, Sw  swipe, Fl  fling, Mu  multi-touch, Ty  type, min  minute, w  week, d  day, C  controlled environment, U  uncontrolled environment, An  Android OS, â€˜â€“â€™  not available.

a
In Mahbub et al. (2016), various sensors were also employed, which include front-facing camera, motion sensors, light sensor, GPS, Bluetooth, WiFi, proximity sensor, temperature sensor and pressure sensor.

4.9.1. Frank dataset
Frank et al. (2013) collected swipe data (horizontal and vertical swipes) from 41 subjects on Android smartphones (Nexus One, Nexus S, Samsung Galaxy S, and Droid Incredible). The subjects were required to read texts and compare images in three different sessions for each task. After at least a week, some subjects participated in another session of data collection for the same tasks. In the dataset, the authors proposed 30 touch-based features to be used for touch-based biometric authentication.

4.9.2. Serwadda dataset
Serwadda et al. (2013) collected swipe data from 190 subjects using an Android device, Google Nexus S, in two separate sessions with an interval of at least one day. The device is fixed to avoid bias in terms of screen size and resolutions. In each session, subjects were required to answer a series of multiple-choice questions. The tasks produced horizontal and vertical swipes when subjects swiped back and forth to answer the questions. The authors proposed 28 features.

4.9.3. Antal dataset
Antal et al. (2015) collected touch data from 71 subjects using eight different Android devices in four weeks. The subjects were required to perform tasks related to the reading of documents and browsing of an image gallery, which produce vertical swipes and horizontal swipe, respectively. Each subject was required to perform the tasks in multiple sessions and might have used different devices in different sessions. The authors proposed 15 features.

4.9.4. Syed dataset
Syed et al. (2019) collected swipe data from 31 subjects through a photo matching game to collect vertical and horizontal swipes in at least eight sessions. This dataset is quite similar to the dataset curated by Frank et al. (2013). However, the main difference is in term of postures where subjects were required to perform the task in the following manner: (1) the device is lying flat on a table in portrait orientation, (2) the subjects held the device in portrait orientation and (3) the subjects held the device in landscape orientation. Another major difference between Syed et al. and Frank et al. is that the former used two mobile devices and two tablets as the acquisition device and each subject had to perform the task on all the devices. In return, each subject was required to perform the task 12 times in each session. The authors proposed 18 features.

4.9.5. Mahbub dataset
University of Maryland Active Authentication Dataset 02 (UMDAA-02) (Mahbub et al., 2016) is a multi-modal dataset for continuous authentication. The dataset was collected from 48 subjects using Google Nexus 5 smartphones over two months. The original dataset is a multi-modal dataset that was collected using various sensors which are the front-facing camera, touchscreen, gyroscope, accelerometer, magnetometer, light sensor, GPS, Bluetooth, WiFi, proximity sensor, temperature sensor, and pressure sensor. Since the touchscreen is one of the sensors used to collect the data, we decided to include it as one of the touch-based datasets. In this dataset, there are no pre-defined tasks to perform during data collection (or in other words, free tasks), which is quite different from all the other public datasets.

4.9.6. Yang dataset
Hand movement, orientation, and grasp (HMOG) dataset (Yang et al., 2014, Sitova et al., 2016) is a multi-modal dataset that employs touch sensors, accelerometers, gyroscopes, and magnetometers. The data was collected using the Samsung Galaxy S4. One-hundred subjects were asked to perform three tasks: document reading, text typing, and map navigation, where each task must be done in a sitting and walking posture. Each subject performed all tasks in eight sessions under each posture condition, which makes up a total of 24 sessions for each subject. Touch gestures such as tap, scale, scroll, fling, and typing were collected alongside readings from accelerometer, gyroscope, and magnetometer.

Several interesting observations can be devised from the public datasets discussed above. First, most datasets employ touch sensor only to capture the data except for Mahbub et al. (2016) and Yang et al. (2014), which also captured data from other sensors. Second, all datasets except Yang et al. (2014) focusses on swipe gestures only. This decision could be due to the fact that swipe gestures are the most frequently performed touch gestures on mobile devices (Serwadda et al., 2013, Shen et al., 2015c). Third, most datasets except Mahbub et al. (2016) are collected in a controlled environment. In general, the datasets are more controlled in terms of the task performed and environment during the data acquisition. We believe it would be beneficial if there are more datasets which involve an uncontrolled environment and tasks in order to run experiments that can mimic the real-world operating environment.

The raw data collected from the sensors of a mobile devices will then be used for extracting informative features. However, before extracting features to represent usersâ€™ behaviour, the raw data may need to be preprocessed to ensure its quality. The next section will discuss some preprocessing techniques to create a better quality of data before extracting features.

5. Preprocessing
The raw data captured by the sensors generally contain noises. The data need to be preprocessed to improve the quality of the data before extracting the features. This step includes removing outliers and standardising values in the data. Other preprocessing steps, which include categorising the touch strokes, filtering inaccurate and noisy data and resampling an imbalanced data can also be utilised to further improve the quality of the data.

5.1. Outlier removal
One of the most commonly used preprocessing techniques is outlier removal. Noises are the data points that are not normal compared to other data points. Their existence in the training model may have an impact on the performance of a classifier that could degrade its performance (Hao and Li, 2016, Yang et al., 2018, Fierrez et al., 2018). These include removing irrelevant types of gesture (Syed et al., 2019), removing too large or too small data (Murmuria et al., 2015, Shen et al., 2015c), removing exceptional touch operations (Yang et al., 2018), removing short strokes (Frank et al., 2013, Fierrez et al., 2018) and making an equal number of strokes for each user (Syed et al., 2019). Small data may not be enough and less meaningful for user modelling. Moreover, abnormal usage may cause unnecessary large data (Smith-Creasey and Rajarajan, 2016).

5.2. Standardisation
Each property in the data contains values in different ranges. Standardisation can be performed (e.g.  scaling (Serwadda et al., 2013, Palaskar et al., 2016, Antal and SzabÃ³, 2016, Yang et al., 2018, Choi et al., 2018, Fierrez et al., 2018)) to avoid any bias in the modelling, where the values are in the same range. The schilling can be performed using methods such as Minâ€“Max Scaler (Incel et al., 2021), tanh-estimators (Jain et al., 2005) and Standard Scaler.

5.3. Strokes categorisation
In case where the modelling for a classifiers is built upon different screen orientations (i.e. portrait or landscape) (Serwadda et al., 2013, Fierrez et al., 2018) and directions of strokes (i.e. vertical, horizontal, leftwards, rightwards, upwards, or downwards) (Frank et al., 2013, Serwadda et al., 2013, Shen et al., 2015c, Choi et al., 2018, Fierrez et al., 2018), the data first has to be processed separately according to this criteria so that model can be built according to this different criteria. The rational behind this step is to leverage on the characteristics of different strokes, where each touch operation is performed differently (Shen et al., 2015c).

5.4. Data filtering
Data filtering technique is used to select a subset of samples from the original data (instance selection) (Wilson and Martinez, 2000). The selected data will then be used for training a classification algorithm. Data filtering algorithms such as Edited Nearest Neighbour (ENN) (Wilson, 1972), Relative Neighbourhood Graph (RNG) (SÃ¡nchez et al., 1997), and Random Mutation Hill Climbing (RMHC) (Skalak, 1994) can be used to reduce the original size of samples while maintaining the representativeness of the data. The purpose is to eliminate inaccurate and noisy samples and therefore, improve the performance of a classification algorithm. For example, the aforementioned techniques such as ENN, RNG, and RMHC can be used to remove samples of illegitimate users that are located around the samples of the legitimate user in the training set. The rationale behind applying a data filtering algorithm is to smooth the classification decision boundaries in the data, which then assists a classification algorithm to perform better in discriminating between the samples of different classes in the feature space (GarcÃ­a et al., 2012).

5.5. Data resampling
In a classification problem, class imbalance occurs when the samples of certain classes are more than the others (He and Garcia, 2009). In touch-based continuous mobile device authentication, the samples of illegitimate users are usually more than the samples of legitimate users. This situation could happen in a dataset with a number of users, where one user will be selected as the legitimate user (where the samples are treated as legitimate samples), while the rest of the users are selected as illegitimate users (where the samples are treated as the samples of illegitimate users). This is common in the context of binary classification problem. The process will be repeated until all users have been trained. In such cases, legitimate user will be the minority class and the illegitimate users will be the majority class. The performance of a classification algorithm can be affected by the under-representation of the minority class that makes the algorithm to favour the majority class (Incel et al., 2021). In the case of touch-based mobile device authentication, the minority class, which is the legitimate user, has an important role in the learning task. Oversampling methods, such as Random Sampling (Menardi and Torelli, 2014, Incel et al., 2021), Synthetic Minority Oversampling Technique (SMOTE) (Chawla et al., 2002, Incel et al., 2021), and Adaptive Synthetic Sampling (ADASYN) (He et al., 2008) can be used in the classification task to solve the imbalance problem.

Once the raw data has been preprocessed, the next step is to extract features that can represent usersâ€™ behaviour.

6. Behaviour representation
A touch stroke  is a sequence of  of touch data that starts with a touchdown and ends with a touch up from the screen. For each touch stroke , the values of the location of the touch , timestamp , pressure , and area  are recorded. The touch data cannot be directly used to train a classifier to model a user profile. Behaviour features must be extracted to represent the touch behaviour of a user (Shen et al., 2015c). Besides, a single touch stroke usually is not enough to represent the behaviour of a user. Several features should be derived from the raw data (Chang et al., 2018). Other than features extracted based on touchscreen sensor, other features can also be extracted from other sensors alongside with touch sensor such as motion sensors (Sitova et al., 2016, Shen et al., 2018b).

The continuous authentication scheme will use these features for the classification algorithms to distinguish between one user from another. According to Jain et al. (2004), biometric features should be universal, distinctive, permanence, and collective. In general, extracting more features might lead to better authentication. However, as the number of features increases, the authentication scheme requires more computational time (Meng et al., 2018a). For continuous authentication scheme, this will cause a delay to perform authentication continuously. Table 4 summarises the features extraction from touch interactions based studies in the area. This section describes the behavioural features extracted from touch interactions. We first describe the touch-based features that can be extracted from raw touch data. Besides touch-based features, we also present other features that have been incorporated with touch interactions, such as keystroke features, motion features, behavioural profile, and other types of features.


Table 4. Feature extracted from touch biometrics for continuous authentication.

Author	No.											NT
Frank et al. (2013)	27	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â€“
Li et al. (2013)a	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â€“	â˜‘	â˜‘	â€“	â€“
Meng et al. (2013)	21	â˜‘	â€“	â€“	â€“	â€“	â˜‘	â€“	â€“	â€“	â˜‘	â€“
Serwadda et al. (2013)	28	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â€“
Bo et al. (2014)	3	â˜‘	â˜‘	â€“	â€“	â€“	â€“	â€“	â˜‘	â€“	â€“	â˜‘
Feng et al. (2014)	6	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â€“	â€“	â˜‘	â€“	â€“
Xu et al. (2014)a	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â€“	â˜‘	â˜‘	â€“	â€“
Murmuria et al. (2015)	5	â˜‘	â€“	â˜‘	â˜‘	â€“	â€“	â€“	â˜‘	â˜‘	â€“	â˜‘
Shen et al. (2015c)	58	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â€“	â€“
Mahbub et al. (2016)	24	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â€“	â€“	â€“
Sitova et al. (2016)	11	â˜‘	â€“	â€“	â€“	â€“	â˜‘	â€“	â€“	â˜‘	â€“	â˜‘
Smith-Creasey and Rajarajan (2016)	27	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â€“	â˜‘	â€“	â˜‘
Zhou et al. (2016)	25	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â€“
Fierrez et al. (2018)	33	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â€“
Meng et al. (2018b)	21	â˜‘	â€“	â€“	â€“	â€“	â˜‘	â€“	â€“	â€“	â˜‘	â€“
Meng et al. (2018a)	9	â˜‘	â€“	â€“	â€“	â€“	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â€“
Perera et al. (2018)	27	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â€“
Shen et al. (2018b)b	â€“	â€“	â€“	â€“	â€“	â€“	â€“	â€“	â€“	â€“	â€“	â˜‘
Yang et al. (2018)a	â€“	â˜‘	â˜‘	â˜‘	â€“	â€“	â˜‘	â€“	â˜‘	â€“	â€“	â€“
Smith-Creasey and Rajarajan (2019)	74	â˜‘	â€“	â€“	â€“	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘
Syed et al. (2019)	14	â˜‘	â˜‘	â˜‘	â€“	â€“	â˜‘	â€“	â˜‘	â€“	â€“	â€“
Incel et al. (2021)	126	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â˜‘	â€“	â˜‘
Notations have the following meaning: No.  number of features,   timing-based feature,   position,   length-based feature,   direction,   angle-based feature,   speed/velocity,   acceleration,   pressure,   size of touch area,   frequency, NT  non-touch features.

a
Li et al. (2013), Xu et al. (2014) and Yang et al. (2018) extracted the features for different types of touch interactions.

b
Shen et al. (2018b) only employed motion sensors while touch actions are performed. Thus, no features extracted based on touch actions.

6.1. Touch-based features
A touch-based continuous mobile device authentication scheme extracts features to represent the touch behaviour of a user in measurable values. This step is necessary as touch interaction data cannot be used directly by a classifier for user classification (Shen et al., 2015c). The scheme extracts the features from the raw touch data and generates a feature vector that contains the biometric data for that user (Palaskar et al., 2016). These features represent the distinguishable characteristics of usersâ€™ touch behaviour (Teh et al., 2016). In the subsequent subsections, we will discuss the features used in touch-based continuous mobile device authentication in detail. We categorised the most commonly used features of touch-based biometric as movement features, operational features, spatial features, and timing features by referring to Teh et al. (2016) and Zhou et al. (2016).

6.1.1. Timing features
During data acquisition, the device records timestamps of every touch stroke. From the timing data, the continuous authentication scheme can extract several timing features. In general, timing features can describe the speed of users to perform touch strokes. For example, some users read text on the screen slowly, and some other users read quickly (Frank et al., 2013). The timing features include (1) touch stroke duration and (2) inter-stroke duration. The former refers to the duration to perform a touch stroke that is between touch down and touch up (Meng et al., 2018b, Alghamdi and Elrefaei, 2018), and the later refers to the time delay between two consecutive touch strokes (Frank et al., 2013)

6.1.2. Movement features
Movement features involve the position of the touch, its movement, and the direction of the movement. Touch position describes the -coordinates of the touch action. The touchscreen of a mobile device can determine the pixel coordinates of each touchpoint. The touch position can be recorded by determining the coordinates of the centroid of the area by a finger (Shahzad et al., 2017). The position includes the start and the endpoints of a stroke. Shen et al. (2015b). Since users tend to interact with the screen on different screen areas (Feng et al., 2015b), representing a touch stroke based on the position can describe the behaviour pattern of a user (Frank et al., 2013). In the case of a single touch, the position is simply represented by the coordinate of the touchpoint. In the case of a touch movement, the position is the start and end coordinates of touch movements. Based on the position, the scheme can derive other features such as distance, displacement, direction, velocity, acceleration, angle, and curvature.

Furthermore, based on the length of trajectory between two touchpoints, length-related features such as distance and displacement can be extracted. Feng et al. (2015b) The distance between two touchpoints can be determined as the length travelled from the touchdown point to touch up point, while the displacement is the length of the straight line connecting two touch points (Mahfouz et al., 2017). As an example, some users may perform long touch strokes on the screen while others may perform touch stroke in a short distance only (Feng et al., 2015b). Based on the timestamps and the distance, speed of a touch action can be extracted (Alghamdi and Elrefaei, 2018). This feature is influenced by the finger and muscle of a user and represents how fast a user performs a touch movement gesture (Feng et al., 2014).

The direction of touch is based on the coordinate of a touchpoint (Alghamdi and Elrefaei, 2018). Velocity is the ratio of the distance travelled by every pair of adjacent points in a unit time in a particular direction of a touch movement (Serwadda et al., 2013). It can be derived from the distance, duration, and direction (Mahfouz et al., 2017). Specifically, it is the ratio of distance (length of the trajectory) to duration (Antal and SzabÃ³, 2016). Based on the velocity, touch acceleration, which is the rate of change of velocity from two values of adjacent velocity can also be derived (Serwadda et al., 2013). In other words, it is the ratio of velocity to the duration between two adjacent touchpoints (Shen et al., 2015c).

Angle is calculated by using the points between the position of touch down and touch up (Palaskar et al., 2016). Deviation is from a straight line, regardless whether the deviation is on the right or the left of the line. This feature might indicate whether a user is right-handed or left-handed (Frank et al., 2013). Curvature is the amount of deviation of a touch stroke from the straight line that connects the start and endpoint of a stroke (Li et al., 2013, Mahfouz et al., 2017). It also represents the slope of a stroke (Feng et al., 2015b).

6.1.3. Spatial features
Spatial features refer to the features extracted from the physical characteristics of a touch (Teh et al., 2016), such as touch pressure and touch area. Touch pressure is an approximation of the force asserted on the screen when a user is performing touch actions. The device captures it in the range of normalised value  (Zheng et al., 2014, Nguyen et al., 2017, Alghamdi and Elrefaei, 2018). Touch area is the approximation of the size of the area touched by a userâ€™s finger on the screen. The value of the touch area also lies in the range of  (Zheng et al., 2014, Nguyen et al., 2017, Alghamdi and Elrefaei, 2018). It is influenced by a user finger size (Feng et al., 2014). The value also represents how hard a user touches the screen (Feng et al., 2015b).

6.1.4. Operational features
Operational features refer to the characteristics of activities of a touch. For instance, frequency is the number of touch actions such as tap, swipe, and multi-touch actions performed by a user in a particular session (Meng et al., 2013, Meng et al., 2014, Meng et al., 2018a). Besides the number of actions, the fraction of a particular touch gesture per session can also be extracted (Meng et al., 2018b).

6.2. Non-touch features
Some studies also include other features alongside touch-based features. The aim of including such features is to improve the performance of the current continuous authentication scheme and to overcome the fact that features extracted from behavioural biometrics are not as distinctive as the features extracted from physiological biometrics. Moreover, a single sensor might not always be triggered by the sensor during continuous monitoring (Kumar et al., 2016).

6.2.1. Keystroke features
Some studies employed keystrokes as part of touch gestures. Keystroke-based features are extracted to represent a userâ€™s typing behaviour (Alghamdi and Elrefaei, 2018). Two timing-based features can be extracted: (1) dwell time, which is the duration of the typing of the same key and (2) flight time, which is the duration of two of the successive key touches such as upâ€“down, and downâ€“down key touches (Xu et al., 2014, Alghamdi and Elrefaei, 2018). Other non-timing features, like the rate of a typing error, can also be extracted. It is a feature that represents the typing behaviour of a user based on the backspace key (Trojahn and Ortmeier, 2013). Other feature such as touch size (Xu et al., 2014, Alghamdi and Elrefaei, 2018), touch pressure (Xu et al., 2014, Alghamdi and Elrefaei, 2018), and motion features (Gascon et al., 2014) can also be incorporated with a keystroke.

6.2.2. Motion features
Other than the touch sensor, a modern mobile device is also equipped with built-in hardware to detect motion using sensors such as accelerometer, gyroscope, and magnetometer (Wang and Tao, 2019). Several studies have employed these sensors to collect behavioural biometrics data before, during, or after a touch gesture (Bo et al., 2014, Kumar et al., 2016, Sitova et al., 2016, Shen et al., 2018b, Smith-Creasey and Rajarajan, 2019, Liang et al., 2020, Incel et al., 2021). The motion sensors provide information on the userâ€™s motion behaviour (Bo et al., 2014). Behaviour features based on a motion sensor are not directly visible to other users, which is advantageous in preserving the userâ€™s privacy (Shen et al., 2018b). Motion features can represent the behavioural of a user in terms of prehension (Sitova et al., 2016), device movement (Kumar et al., 2016), device orientation (Ali et al., 2016), and motion change (Antal and SzabÃ³, 2016, Shen et al., 2018b, Smith-Creasey and Rajarajan, 2019). Even though the behaviour features extracted from motion sensors can add more information on user behaviour, developing a continuous authentication scheme based on these sensors is challenging due to the noise associated with these types of sensors (Mostafa et al., 2019). Nevertheless, it has been shown that incorporating features from motion sensors can improve the authentication performance (Incel et al., 2021).

6.2.3. Behaviour profile
Behaviour profile is the pattern of device usage, such as usage frequency of applications or services (Patel et al., 2016, Acien et al., 2020). This type of data is also collected alongside touch gestures. For example, typing gestures such as the way users hold their device and their daily habits (Canfora et al., 2016), touch gestures with device movement, application context and power usage (Murmuria et al., 2015), and touch gestures with WiFi, GPS, and application usage (Acien et al., 2020).

6.2.4. Other features
Image-based features have also been found to be used with touch gestures. Image features are extracted from the image when a touch gesture is performed. For example, Smith-Creasey and Rajarajan (2016) combined touch gestures and face when touch gestures were performed. Other than the face, touch gestures have also been represented as an image on a canvas (Zhao et al., 2013, Zhao et al., 2014, Ahmad et al., 2017). The image is used to compare the image of gestures performed by the legitimate user and the illegitimate user.

6.3. Feature selection
In general, more features provide a more discriminative representation of touch behaviour and thus, the better the performance of the authentication scheme. However, a large number of features may consist of redundant features, reduce memory efficiency, and increase the processing time. For example, Frank et al. (2013) found in their study that the length of the trajectory and the end-to-end distance are highly correlated. The authors discarded the length of trajectory as it describes almost similar information as the end-to-end distance. Therefore, feature selection technique can be used to select a subset of features from the original number of features. The aim is to maintain the performance of the authentication scheme by eliminating irrelevant features. The technique can be categorised as filters, wrappers, and embedded methods (Aljarah et al., 2019). Table 5 summarises the feature selection techniques employed in this research area.


Table 5. Features selection techniques.

Author	Method
Frank et al. (2013)	Based on the authorâ€™s understanding
Li et al. (2013)	Kolmogorovâ€“Smirnov test
Shen et al. (2015c)	Inter-class scatter, intra-class scatter
Sitova et al. (2016)	Fisher score ranking, minimum-Redundancy Maximum-Relevance
Temper et al. (2017)	Particle swarm optimization
Ouadjer et al. (2021)	XGBoost
Incel et al. (2021)	Sequential backward selection
6.4. Feature transformation
Some feature transformation methods such as Principal Component Analysis (PCA) (Wold et al., 1987) and Linear Discriminant Analysis (LDA) (Duda et al., 2000) are usually utilised to improve the performance of a classification algorithm (Sitova et al., 2016). PCA is used to reduce the dimension of feature sets (Sitova et al., 2016). It creates a projection of each sample onto a smaller dimensional space. Redundant features can also be eliminated and the size of the dataset can be reduced to train a classification algorithm (Incel et al., 2021). On the other hand, LDA aims to project the samples to maximises the separation between samples from different classes. This step will be helpful when training a classification algorithm.

Once the features that represent touch interactions have been extracted, the continuous authentication scheme is ready to perform user classification based on the features. A classification algorithm is needed to detect whether a particular touch stroke represented by certain features belongs to the legitimate user or not.

7. User classification
The primary goal of touch-based continuous mobile device authentication is to verify users who claim the rights on their devices. The mechanism has to detect whether a user is a legitimate user or an illegitimate user. Generally, there are two types of data involved for user classification: the legitimate usersâ€™ data and illegitimate usersâ€™ data (Porwik et al., 2019). If the touch-based continuous mobile device authentication scheme detects that the newly captured touch data are similar to the data of the legitimate user, it will allow the user to continue to use the device. Otherwise, it will detect the user as an illegitimate user and lockout the user.

In order to achieve the above goal, the scheme needs a classifier to learn the user behaviour and to classify whether a user is a legitimate or an illegitimate user (Shen et al., 2015c). Existing studies have implemented the mechanism in several approaches. We categorise the approaches as distance-based approach, traditional machine learning approach, and deep learning approach. The rest of this section describes the types of classification approaches and algorithms used in the existing studies. Besides, we also describe postprocessing step and fusion techniques used in this domain.

7.1. Classification approaches
We categorise the classification approaches into three types: distance-based, traditional machine learning and deep learning.

7.1.1. Distance-based approach
A distance-based approach measures the distance between the test sample and the training sample. It shows the similarity or dissimilarity between the touch samples of the current user and the legitimate user. It will compute the classification score and compare it with a threshold. Existing studies have used methods like Manhattan distance (Serwadda et al., 2013, Sitova et al., 2016) and Euclidean distance (Serwadda et al., 2013, Sitova et al., 2016).

7.1.2. Traditional machine learning approach
A machine learning algorithm will first learn from the feature vectors of the legitimate user to generate a user model. The model will then be used to classify whether an unknown user is a legitimate user or an illegitimate user. The algorithm will generate a classification score for each new touch sample and will classify it as belonging to the legitimate user or not based on the predefined threshold (Teh et al., 2016). The score indicates the similarity between the stroke of the unknown user and the strokes of legitimate user (Lu and Liu, 2015). If the classification score produced by a particular algorithm is greater or equal to the predefined threshold, the touch sample will be classified or recognised as belongs to the legitimate user. Otherwise, the sample will be classified as belonging to the illegitimate user. Examples of such classification algorithms include Support Vector Machine, -Nearest Neighbour, Decision Tree, Random Forest, NaÃ¯ve Bayes, Logistic Regression and Neural Network. Traditional machine learning classification approach is suitable for small-sized data. However, this approach depends on hand-crafted features where it needs features to be engineered to improve the classification performance, which is a manual time-consuming process (Al-Garadi et al., 2020). To address this limitation, deep learning approach is introduced to automate feature engineering (Mahdavifar and Ghorbani, 2019)

7.1.3. Deep learning approach
Apart from traditional machine learning approaches, recent studies have started to explore deep learning approaches to perform feature extraction automatically, which is the main difference when compared with the traditional machine learning algorithms (Mahdavifar and Ghorbani, 2019). Traditional machine learning algorithms require feature engineering to extract features from data. In contrast, deep learning uses multiple processing layers of the network to learn the representation of data (LeCun et al., 2015). Recently, studies have started to employ deep learning methods such as Deep Belief Network (DBN) (Lee et al., 2016), Deep Neural Network (DNN) (Volaka et al., 2019, Montgomery et al., 2019), Kernel Deep Regression Network (KDRN) (Chang et al., 2018), and Recurrent Neural Network (RNN) (Gunn et al., 2019). Deep learning approach in general can provide superior performance compared to traditional machine learning (Al-Garadi et al., 2020). However, deep learning-based approaches require a large amount of data and higher computation time to learn the feature representation effectively. Therefore, in the situation where the size of touch data is small and the computational capability of a mobile device is low, this approach might not be useful. Nevertheless, there are some research in machine learning that attempts to address the issues with deep learning that requires a large training dataset. For example, Few-shot Learning (FSL) (Wang et al., 2020b) approach allows the learning of data using relatively smaller amount of training data. Therefore, more work is needed to explore the potential of employing deep learning in the area of touch-based continuous mobile device authentication.

7.2. Classification algorithms
We categorise the context of the classification of users as binary and one-class classification problems. The former requires the data from both legitimate and illegitimate users to train a user model, while the latter only requires the data from legitimate users to train the model. In both cases, a specific algorithm is required to perform the classification task.

Besides, we will present (in tables) the performance of a particular algorithm in terms of several performance metrics as presented in Section 3.5. These metrics include false acceptance (FAR), false rejection rate (FRR), equal error rate (EER), classification accuracy (ACC) and area under the ROC curve (AUC). In addition, less commonly used performance metrics which are average error rate (AER) were also used in some studies (Meng et al., 2013, Meng et al., 2018a, Meng et al., 2018b). It is a simple average of FAR and FRR. It is worth to note that a particular study might not use all these performance metrics. Other than the performance of the algorithm, we also present the dataset used, the number of features and the parameters used for a particular algorithm, in case the information is available. It is worth to note that we are not able to compare the performance of each algorithm as most studies used different kinds of data to evaluate the algorithm. Nevertheless, we report the best result achieved by each algorithm in each study.

7.2.1. Binary classification
Binary classification is a classification task that involves two classes: positive and negative classes. Touch-based continuous mobile device authentication views the classification task as a binary classification where the positive class is the legitimate user, and the negative class is the illegitimate user (Zhou et al., 2016). Device-sharing is possible, where people like children, family members or acquaintances might borrow the device (Feng et al., 2015a). Therefore, it is worth to employ binary classification to model a user profile considering that situation. Fig. 3 illustrates how a binary classifier works. The classifier will classify a touch sample as belonging to the legitimate user or illegitimate user.

Support Vector Machine (SVM).
SVM is a classification method that generates a separating hyperplane to distinguish two classes of users (legitimate vs. illegitimate users) (Cortes and Vapnik, 1995, Vapnik, 2013). In the training phase, an optimal hyperplane is maximised based on the distance between the nearest training points of the two classes. The hyperplane is the location of the margin between these two classes. In the testing phase, a new sample (touch stroke) will be classified based on the score of the distance of the new sample and the hyperplane.

Table 6 summarises the studies on touch-based continuous mobile device authentication that employed SVM to classify users. For this classifier, we would like to note that:


Table 6. Performance of SVM classifier (%).

Author	Dataset	Features	Kernel	FAR	FRR	EER	ACC	Other
Frank et al. (2013)	Frank	27	RBF	â€“	â€“	0.00â€“4.00	â€“	â€“
Li et al. (2013)	Private	16	RBF	â€“	â€“	â€“	95.78	â€“
Serwadda et al. (2013)	Serwadda	28	â€“	â€“	â€“	13.10	â€“	â€“
Shen et al. (2015c)	Private	58	RBF	0.10	20.42	â€“	â€“	â€“
Zhou et al. (2016)	Private	25	â€“	â€“	â€“	â€“	69.80	â€“
Kumar et al. (2018)	Private	14	â€“	18.12	3.04	â€“	â€“	AUC  89.42
Meng et al. (2018a)	Private	9	â€“	4.95	4.37	â€“	â€“	AER  4.66
Fierrez et al. (2018)	Frank	28	RBF	â€“	â€“	5.30	â€“	â€“
Serwadda			â€“	â€“	4.40	â€“	â€“
Antal			â€“	â€“	4.40	â€“	â€“
Mahbub			â€“	â€“	10.90	â€“	â€“
Chang et al. (2018)	Frank	30	RBF	â€“	â€“	0.76	â€“	â€“
Syed et al. (2019)	Syed	14	â€“	â€“	â€“	18.70	â€“	â€“
Incel et al. (2021)	Private	126	RBF	0.04	3.88	3.50	99.88	TPR  96.12

Table 7. Performance of NN classifier (%).

Author	Dataset	Features	k	Distance	FAR	FRR	EER	ACC	Other
Frank et al. (2013)	Frank	27	1â€“7	Euclidean	â€“	â€“	0.00â€“4.00	â€“	â€“
Serwadda et al. (2013)	Serwadda	28	â€“	Euclidean	â€“	â€“	14.00	â€“	â€“
Shen et al. (2015c)	Private	58	11	Euclidean	â€“	28.52	â€“	â€“	â€“
Mahbub et al. (2016)	Mahbub	24	9	â€“	â€“	â€“	â€“	â€“	â€“
Zhou et al. (2016)	Private	25	â€“	â€“	â€“	â€“	â€“	70.20	â€“
Kumar et al. (2018)	Private	14	â€“	â€“	14.02	3.87	â€“	â€“	AIC  91.06
Incel et al. (2021)	Private	126	2	â€“	0.30	5.85	5.39	99.58	TPR  94.15
â€¢
Frank et al. (2013) achieved an EER of 0.00% to 4.00% across all usage scenarios. The authors did not explicitly state the performance of a particular classifier.

â€¢
Li et al. (2013) achieved a classification accuracy of 95.78% for sliding up gesture.

â€¢
Serwadda et al. (2013) ac hived an EER of 13.10% on horizontal stokers in landscape screen orientation.

â€¢
Shen et al. (2015c) achieved a FRR of 20.42% with a fixed FAR of 0.10% on sliding leftwards touch operations.

â€¢
Zhou et al. (2016) achieved an accuracy of 69.80% on big screen mobile phones.

â€¢
Kumar et al. (2018) achieved a FAR of 18.12%, a FRR of 3.04%, and an AUC of 89.42% on a swiping and phone movement pattern dataset.

â€¢
Overall, Meng et al. (2018a) achieved a FAR of 4.95%, a FRR of 4.37%, and an AER of 4.66%.

â€¢
Fierrez et al. (2018) achieved the following results in their study: (1) an EER of 5.30% for rightwards strokes in an intrasession experiment using Frank dataset, (2) an EER of 4.40% for leftwards strokes on portrait screen orientation in intrasession experiments using Serwadda dataset, (3) an EER of 4.40% for downwards strokes in an intrasession experiment using Antal dataset, and (4) an EER of 10.90% for rightwards strokes on an intrasession experiment using Mahbub dataset.

â€¢
Chang et al. (2018) achieved an EER of 0.76% in intrasession experiments.

â€¢
Syed et al. (2019) achieved an EER of 18.70% in the experiment trained with 60% of the training data.

â€¢
Incel et al. (2021) achieved a FAR of 0.04%, a FRR of 3.88%, an EER of 3.50%, a TPR of 96.12%, and an accuracy of 99.88% when evaluated with SMOTE sampling method.

It is worth noting that the linear hyperplane of SVM may not separate the two classes very well. Thus, the nonlinear kernel can be used to map the data to different spaces to improve the effectiveness of the algorithm. This mapping technique can make the data more separable. Some studies in the literature have used kernels such as radial basis function (RBF) and polynomials to improve the effectiveness of the algorithm. Besides, SVM has better generalisation ability and useful in the case where the number of features is high and the number of samples is low.

-Nearest Neighbour (NN).
NN is a lazy-learning classification method that assumes the new sample of touch stroke from the test data is similar to the data in the training set (Aha et al., 1991, Duda et al., 2000). It will find the  nearest touch stroke samples based on the distance between these strokes. The algorithm finds the touch strokes in the training samples that are close to the touch strokes based on a certain distance measure. This algorithm is simple and can perform effective classification (Blasco et al., 2016). However, NN is less effective when handling large data where it requires comparing a test sample with all feature vectors in the training set (Frank et al., 2013).

Table 7 summarises the studies on touch-based continuous mobile device authentication that employed NN to classify users. For this classifier, we would like to note that:

â€¢
Frank et al. (2013) achieved an EER of 0.00% to 4.00% across all usage scenarios. The authors did not explicitly state the performance of a particular classifier.

â€¢
Serwadda et al. (2013) achieved an EER of 14.00% for horizontal stokers in landscape screen orientation.

â€¢
Shen et al. (2015c) achieved a FRR of 28.52% with a fixed FAR of 0.10% on sliding leftwards touch operations.

â€¢
Zhou et al. (2016) achieved an accuracy of 70.20% on big screen mobile phones.

â€¢
Kumar et al. (2018) achieved a FAR of 14.02%, a FRR of 3.87%, and an AUC of 91.06% on a swiping and phone movement pattern dataset.

â€¢
Incel et al. (2021) achieved a FAR of 0.30%, a FRR of 5.85%, an EER of 5.39%, a TPR of 94.15% and an accuracy of 99.58% when evaluated with SMOTE sampling method.

It is worth noting that different studies used a different number of neighbours, . Apart from that, some studies did not mention the number of  used in their experiments.

Decision Tree (DT).
DT is a classifier that generates a tree for prediction (Quinlan, 1996). The tree has nodes which evaluate the feature vectors for each touch stroke and also has leaves where each leaf specifies the decision whether the touch stroke belongs to the legitimate or illegitimate user. A decision tree-based algorithm like J48 will generate a tree based on questions that describe the touch features. The test sample will be classified based on the rules generated from the tree during the training phase.

Table 8 summarises the studies on touch-based continuous mobile device authentication that employed a decision tree to classify users. It can be seen that the most commonly used decision tree algorithm is J48 (Canfora et al., 2016, Meng et al., 2018a, Meng et al., 2018b). For this classifier, we would like to note that:

â€¢
Meng et al. (2013) achieved a FAR of 22.43%, a FRR of 25.01%, and an AER of 23.72% as overall results.

â€¢
Serwadda et al. (2013) achieved an EER of 30.70% for horizontal stokers in portrait screen orientation.

â€¢
Zhou et al. (2016) achieved an accuracy of 65.10% on big screen mobile phones.

â€¢
Meng et al. (2018a) achieved a FAR of 8.42%, a FRR of 7.61%, and an AER of 8.02% as overall results.

â€¢
Meng et al. (2018b) achieved a FAR of 17.26%, a FRR of 16.32%, and an AER of 16.79% in website browsing experiments.

â€¢
Incel et al. (2021) achieved a FAR of 0.28%, a FRR of 11.13%, an EER of 9.61%, a TPR of 88.87%, and an accuracy of 99.49% when evaluated with SMOTE sampling method.

Random Forest (RF).
Another decision tree-based classifier is RF (Breiman, 2001). It is an ensemble-based classifier where it contains multiple decision trees. During the training phase, training samples from each decision tree are randomly selected using a classifier ensemble method. During the testing phase, the output from each tree is averaged to obtain the final result.


Table 8. Performance of Decision Tree classifier (%).

Author	Dataset	Features	Type	FAR	FRR	EER	ACC	Other
Meng et al. (2013)	Private	21	J48	22.43	25.01	â€“	â€“	AER  23.72
Serwadda et al. (2013)	Serwadda	28	J48	â€“	â€“	30.70	â€“	â€“
Zhou et al. (2016)	Private	25	â€“	â€“	â€“	â€“	65.10	â€“
Meng et al. (2018a)	Private	9	J48	8.42	7.61	â€“	â€“	AER  8.02
Meng et al. (2018b)	Private	21	J48	17.26	16.32	â€“	â€“	AER  16.79
Incel et al. (2021)	Private	126	â€“	0.28	11.13	9.61	99.49	TPR  88.87
Table 9 summarises the studies on touch-based continuous mobile device authentication that employed random forest to classify users. For this classifier, we would like to note that:

â€¢
Serwadda et al. (2013) achieved an EER of 12.70% for horizontal stokers in landscape screen orientation.

â€¢
Shen et al. (2015c) achieved a FRR of 1.88% and a FAR of 2.72% for middle-period authentication.

â€¢
Mahbub et al. (2016) achieved an EER of 22.10% on swipe data.

â€¢
Smith-Creasey and Rajarajan (2016) achieved an EER of 19.45% on touch data.

â€¢
Zhou et al. (2016) achieved an accuracy of 75.10% on big screen mobile phones.

â€¢
Kumar et al. (2018) achieved a FAR of 7.80%, a FRR of 12.06%, and an AUC of 90.07% on a swiping and phone movement pattern dataset.

â€¢
Syed et al. (2019) achieved an EER of 3.80% when the device models are held in landscape mode.

â€¢
Smith-Creasey and Rajarajan (2019) achieved an EER of 3.32% when the scheme was trained and tested on sitting activities.

â€¢
Incel et al. (2021) achieved a FAR of 4.85%, a FRR of 9.09%, an EER of 9.58%, a TPR of 90.91%, and an accuracy of 92.97% when evaluated with Random Sampling method.

Besides, most studies did not explicitly mention the number of trees set for the algorithm. Only the work by Kumar et al. (2016) and Incel et al. (2021) stated the number of trees used. The former used 1000 trees, while the latter used 30 trees with random sampling method and 22 tree with SMOTE oversampling method.

Naive Bayes.
NB is a probabilistic method based on Bayes theorem where it assumes the value of a particular feature is independent of other features (Zhang, 2004). The feature vectors belonging to a user will follow the same probability distribution of the feature vector of the training set. A touch stroke is classified based on the probability that it belongs to a particular class. It is worth to note that NB is a special case of Bayesian Network where nodes representing the features have the user nodes as the only parent.


Table 9. Performance of Random Forest classifier (%).

Author	Dataset	Features	Tree	FAR	FRR	EER	ACC	Other
Serwadda et al. (2013)	Serwadda	28	â€“	â€“	â€“	12.70	â€“	â€“
Shen et al. (2015c)	Private	58	1000	1.88	2.72	â€“	â€“	â€“
Mahbub et al. (2016)	Mahbub	24	â€“	â€“	â€“	22.10	â€“	â€“
Smith-Creasey and Rajarajan (2016)	Private	27	â€“	â€“	â€“	19.45	â€“	â€“
Zhou et al. (2016)	Private	25	â€“	â€“	â€“	â€“	75.10	â€“
Kumar et al. (2018)	Private	14	â€“	7.80	12.06	â€“	â€“	AUC  90.07
Syed et al. (2019)	Private	14	â€“	â€“	â€“	3.80	â€“	â€“
Smith-Creasey and Rajarajan (2019)	Private	74	â€“	â€“	â€“	3.32	â€“	â€“
Incel et al. (2021)	Private	126	22/30	4.85	9.09	9.58	92.97	TPR  90.91
Table 10 summarises the studies on touch-based continuous mobile device authentication that employed NB to classify users. For this classifier, we would like to note that:

â€¢
Meng et al. (2013) achieved a FAR of 22.45%, a FRR of 18.36%, and an AER of 20.41% as overall results.

â€¢
Serwadda et al. (2013) achieved an EER of 17.80% for horizontal stokers in portrait screen orientation.

â€¢
Zhou et al. (2016) achieved an accuracy of 44.50% on small screen mobile phones.

â€¢
Kumar et al. (2018) achieved a FAR of 9.79%, a FRR of 11.04%, and an AUC of 89.58% on a swiping and phone movement pattern dataset.

â€¢
Meng et al. (2018a) achieved a FAR of 10.87%, a FRR of 9.31%, and an AER of 10.09% as an overall result.

â€¢
Meng et al. (2018b) achieved a FAR of 13.54%, a FRR of 15.82%, and an AER of 14.68% in website browsing experiments.

â€¢
Syed et al. (2019) achieved an EER of 8.60% in the experiment trained with 90% of the training data.

â€¢
Smith-Creasey and Rajarajan (2019) achieved an EER of 31.14% on whole-word gestures.

â€¢
Incel et al. (2021) achieved a FAR of 8.63%, a FRR of 15.73%, an EER of 14.91%, a TPR of 84.27%, and an accuracy of 91.23% when evaluated with SMOTE sampling method.

Logistic Regression (LR).
LR is a statistical method based on linear regression where the prediction of the legitimate user is transformed using the logistic function. Touch samples from the training data estimate the coefficients of the model using maximum likelihood estimation. The best coefficients would predict a value very close to  for legitimate user and value very close to  for the illegitimate user.


Table 10. Performance of Naive Bayes classifier (%).

Author	Dataset	Features	FAR	FRR	EER	ACC	Other
Meng et al. (2013)	Private	21	22.45	18.36	â€“	â€“	AER  20.41
Serwadda et al. (2013)	Serwadda	28	â€“	â€“	17.80	â€“	â€“
Zhou et al. (2016)	Private	25	â€“	â€“	â€“	44.50	â€“
Kumar et al. (2018)	Private	14	9.79	11.04	â€“	â€“	AUC  89.58
Meng et al. (2018a)	Private	9	10.87	9.31	â€“	â€“	AER  10.09
Meng et al. (2018b)	Private	21	13.54	15.82	â€“	â€“	AER  14.68
Syed et al. (2019)	Syed	14	â€“	â€“	8.60	â€“	â€“
Smith-Creasey and Rajarajan (2019)	Private	74	â€“	â€“	31.14	â€“	â€“
Incel et al. (2021)	Private	126	8.63	15.73	14.91	91.23	TPR  84.27
Table 11 summarises the studies on touch-based continuous mobile device authentication that employed logistic regression to classify users. For this classifier, we would like to note that:

â€¢
Serwadda et al. (2013) achieved an EER of 10.50% for horizontal stokers in landscape screen orientation.

â€¢
Smith-Creasey and Rajarajan (2016) achieved an EER of 27.45% on touch data.

â€¢
Kumar et al. (2018) achieved a FAR of 12.04%, a FRR of 7.91%, and an AUC of 90.03% on a swiping and phone movement pattern dataset.

â€¢
Syed et al. (2019) achieved an EER of 24.90% in the experiment trained with 60% of the training data.

â€¢
Smith-Creasey and Rajarajan (2019) achieved an EER of 19.03% on accelerometer features.

Neural Network (NN).
The neural network of the human brain has inspired NN classification methods. It consists of an input, hidden layers, and an output (Zhou et al., 2004). The neurons in the input layer receive touch features of each user where the algorithm assigns each neuron with a weight based on a particular function. This information is transferred within the hidden layers. The algorithm produces an output at the output layer after several iterations. The output will be used to determine the legitimacy of a user who generates the touch feature. Several NN-based classifiers have been implemented in this area, such as Radial Basis Function Network (RBFN) (Meng et al., 2013, Meng et al., 2018a), Back Propagation Neural Network (BPNN) (Meng et al., 2013, Shen et al., 2015c, Zhou et al., 2016, Meng et al., 2018a, Meng et al., 2018b), and Multi-layer Perceptron (MLP) (Chang et al., 2018, Kumar et al., 2018, Syed et al., 2019, Incel et al., 2021).

Table 12 summarises the studies on touch-based continuous mobile device authentication that employed NN to classify users. For this classifier, we would like to note that:

â€¢
Meng et al. (2013) achieved a FAR of 2.50%, a FRR of 3.34%, and an AER of 2.92% using RBFN optimised with Particle Swarm Optimisation (PSO) algorithm (Kennedy and Eberhart, 1995). Besides, the study also achieved a FAR of 8.85%, a FRR of 14.30%, and an AER of 11.58% using BPNN.

â€¢
Serwadda et al. (2013) achieved an EER of 14.80% for horizontal stokers in landscape and portrait screen orientation.

â€¢
Shen et al. (2015c) achieved a FRR of 26.52% with a fixed FAR of 0.10% on sliding leftwards touch operations.

â€¢
Zhou et al. (2016) achieved an accuracy of 75.70% on big screen mobile phones.

â€¢
Kumar et al. (2018) achieved a FAR of 15.08%, a FRR of 6.72%, and an AUC of 89.10% on a swiping and phone movement pattern dataset.

â€¢
Shen et al. (2018b) achieved a FAR of 11.34%, a FRR of 14.32%, and an EER of 13.14 in hand-hold scenario.

â€¢
Meng et al. (2018a) achieved a FAR of 5.48%, a FRR of 4.53%, and an AER of 5.01% using RBFN. Besides, the study also achieved a FAR of 5.81%, a FRR of 5.21%, and an AER of 5.51% using BPNN.

â€¢
Meng et al. (2018b) achieved a FAR of 2.22%, a FRR of 2.54%, and an AER of 2.38% using RBFN optimised with Particle Swarm Optimisation (PSO) algorithm (Kennedy and Eberhart, 1995). Besides, the study also achieved a FAR of 7.83%, a FRR of 8.13%, and an AER of 7.98% using BPNN. Both classifiers achieved the results in website browsing experiment.

â€¢
Chang et al. (2018) achieved an EER of 1.66% based on three hidden-layer MLP in intrasession experiments.

â€¢
Syed et al. (2019) achieved an EER of 53.00% in the experiment trained with 10% of the training data.

â€¢
Incel et al. (2021) achieved a FAR of 0.08%, a FRR of 3.37%, an EER of 3.17%, a TPR of 96.63%, and an accuracy of 99.85% when evaluated with SMOTE sampling method.

Other binary classifiers.
Other than the binary classifiers used in the previous sections, some studies also used other classifiers to perform user classification. Table 13 summarises the studies on touch-based continuous mobile device authentication that employed other binary classifiers to classify users.


Table 12. Performance of Neural Network classifier (%).

Author	Dataset	Features	Variant	FAR	FRR	EER	ACC	Other
Meng et al. (2013)	Private	21	RBFN	2.50	3.34	â€“	â€“	AER  2.92
BPNN	8.85	14.30	â€“	â€“	AER  11.58
Serwadda et al. (2013)	Serwadda	28	MLP	â€“	â€“	14.80	â€“	â€“
Shen et al. (2015c)	Private	58	BPNN	0.10	26.52	â€“	â€“	â€“
Zhou et al. (2016)	Private	25	BPNN	â€“	â€“	â€“	75.70	â€“
Kumar et al. (2018)	Private	14	MLP	15.08	6.72	â€“	â€“	AUC  89.10
Shen et al. (2018b)	Private	192	â€“	11.34	14.32	13.14	â€“	â€“
Meng et al. (2018a)	Private	9	RBFN	5.48	4.53	â€“	â€“	AER  5.01
BPNN	5.81	5.21	â€“	â€“	AER  5.51
Meng et al. (2018b)	Private	21	RBFN	2.22	2.54	â€“	â€“	AER  2.38
BPNN	7.83	8.13	â€“	â€“	AER  7.98
Chang et al. (2018)	Frank	30	MLP	â€“	â€“	1.66	â€“	â€“
Syed et al. (2019)	Syed	14	MLP	â€“	â€“	53.00	â€“	â€“
Incel et al. (2021)	Private	126	MLP	0.08	3.37	3.17	99.85	TPR  96.63
Ooi and Teoh (2019) proposed Temporal Regression Forest (TRF) to perform classification based on the temporal information of the touch strokes of a user. The proposed method achieved an EER of 1.10% for leftwards strokes on intrasession scenario using Frank dataset. The authors also achieved an EER of 1.00% on leftwards strokes (intrasession scenario with landscape screen orientation) using Serwadda dataset. Fierrez et al. (2018) employed Gaussian Mixture Model (GMM) to model the user model as a distribution of the touch behaviour. The classifier achieved an EER of (1) 7.50% for rightwards strokes in intrasession scenario of Frank dataset, (2) 6.90% for rightwards strokes on landscape screen orientation in intrasession scenario of Serwadda dataset, (3) 8.50% for downwards strokes in intrasession scenario of Antal dataste, and (4) 3.60% for rightwards strokes in intrasession scenario of Mahbub dataset. Meng et al. (2013) and Meng et al. (2018b) employed a statistical-based classifier, KStar (Cleary and Trigg, 2014) that uses entropy as a distance measure and as a similarity function to classify touch strokes. Meng et al. (2013) achieved a FAR of 14.11%, a FRR of 16.69%, and an AER of 15.40% in overall experiments. Besides, Meng et al. (2018b) achieved a FAR of 11.52%, a FRR of 10.32%, and an AER of 10.92% in website browsing experiments. Zhou et al. (2016) and Kumar et al. (2018) used an ensemble-based classifier, Adaptive Boosting (AdaBoost) (Freund and Schapire, 1996), which combines the predictions from several classifiers to overcome the weakness of weak classifiers. Zhou et al. (2016) achieved an accuracy of 41.80% on big screen mobile phone, whereas Kumar et al. (2018) achieved a FAR of 8.33%, a FRR of 13.41%, and AUC of 89.13% on a swiping and phone movement pattern dataset.

On top of that, some recent studies have also proposed to employ deep learning-based methods. Lee et al. (2016) employed Deep Belief Networks (DBN) and achieved an EER of 9.93% with an accuracy of 81.50% on overall experiments, but it was worse than RF (EER of 2.58%, accuracy of 86.50%). Chang et al. (2018) proposed Kernel Deep Regression Network (KDRN), a deep learning-based method to perform feature extraction and classification. This algorithm re-learns from the pre-extracted features to extract relatively more discriminative features. The algorithm proposed by the authors achieved an EER of 0.01% on intrasession scenario using Frank dataset, compared to 0.76% and 1.66% using SVM and MLP, respectively. Volaka et al. (2019) utilised DNN on Yang dataset and achieved an EER of 15.00% with an accuracy of 88.00% when multiple modalities were combined. Montgomery et al. (2019) also used DNN on Frank dataset using the raw data and extracted data. The study achieved an accuracy of 100% when evaluated on the extracted data. Gunn et al. (2019) employed Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) and achieved an accuracy of 91.60 on a touch dynamics dataset.

We can observe that in some other studies, the performance of deep learning approach is worse than the traditional machine learning approach. We believe the lacklustre performance is due to the small size of the data used in the study. It is generally acknowledged that in order for deep learning-based approaches to edge over traditional machine learning approaches, the amount of data needs to be relatively larger with more variability. This can be overcome by employing Few-shot Learning (FSL) (Wang et al., 2020b) approach that allows learning using less training data.


Table 13. Performance of the other Binary classifiers (%).

Classifier	Author	Dataset	Features	FAR	FRR	EER	ACC	Other
TRF	Ooi and Teoh (2019)	Frank	56	â€“	â€“	1.10	â€“	â€“
Serwadda	112	â€“	â€“	1.00	â€“	â€“
GMM	Fierrez et al. (2018)	Frank	5	â€“	â€“	7.50	â€“	â€“
Serwadda		â€“	â€“	6.90	â€“	â€“
Antal		â€“	â€“	8.50	â€“	â€“
Mahbub		â€“	â€“	3.60	â€“	â€“
KStar	Meng et al. (2013)	Private	21	14.11	16.69	â€“	â€“	AER  15.40
Meng et al. (2018b)	Private	21	11.52	10.32	â€“	â€“	AER  10.92
AdaBoost	Kumar et al. (2018)	Private	14	8.33	13.41	â€“	â€“	AUC  89.13
Zhou et al. (2016)	Private	25	â€“	â€“	â€“	41.80	â€“
DBN	Lee et al. (2016)	Frank	44	â€“	â€“	9.93	â€“	ACC  81.50
KDRN	Chang et al. (2018)	Frank	30	â€“	â€“	0.01	â€“	â€“
DNN	Volaka et al. (2019)	Yang	66	â€“	â€“	15.00	88.00	â€“
Montgomery et al. (2019)*	Frank	34	â€“	â€“	â€“	100.00	â€“
RNN	Gunn et al. (2019)	Yang	11	â€“	â€“	â€“	91.60	â€“
7.2.2. One-class classification
One-class classification approach can be used to solve the classification problem when only the data from the positive class are available (Khan and Madden, 2014). In practice, a mobile device is limited to a single user. In binary classification, the data from legitimate user and illegitimate users are used to train the classification algorithm (Palaskar et al., 2016, Kumar et al., 2018). However, sharing a mobile device is uncommon. Furthermore, biometric data is a primary privacy concern when it comes to binary classification (Sitova et al., 2016, Choi et al., 2018). Thus, the binary classification approach is unrealistic because sharing a mobile device is uncommon (Sitova et al., 2016). It is also impractical and challenging to collect data from illegitimate users in advance (Yang et al., 2018). Therefore, some studies also employ a one-class classification approach to perform the classification task in touch-based continuous mobile device authentication.

We can also consider the classification task as a novelty detection problem, where the feature data from the legitimate user is considered as normal data, while other users as anomaly data (Yang et al., 2018). In general, even though it has been proven to be a harder problem compared to binary classification (Khan and Madden, 2014), a one-class classification approach is more practical for the authentication of mobile devices (Hao and Li, 2016). Also, it is a promising method to solve the problem of unavailability of the negative class data. Fig. 4 illustrates how one-class classifier performs training and testing.

One-class Support Vector Machine (OC-SVM).
OC-SVM is the variant of binary SVM (SchÃ¶lkopf et al., 2000). The classifier does not need to know the distribution of the sample (Yang et al., 2018) and can perform anomaly detection with good accuracy and time-efficient. It is an unsupervised learning method that projects the feature vector to a higher dimensional space using a kernel function. Like the binary SVM, OC-SVM also generates a hyperplane that separates the majority of the feature vector from the origin. The algorithm maximises the distance from the hyperplane to the origin. Yang et al. (2018) found that OC-SVM performed better than Isolation Forest due to the higher ability of generalisation even in a limited sample of training data.

Fig. 4. One-class classification.

Table 14 summarises the studies on touch-based continuous mobile device authentication that employed OC-SVM classifiers to classify users. For this classifier, we would like to note that:

â€¢
Sitova et al. (2016) achieved an EER of 15.71% using the data collected during walking and with Fisher score ranking as a feature selection method.

â€¢
Kumar et al. (2018) achieved a FAR of 11.71%, a FRR of 9.48%, and an AUC of 89.41% on a swiping and phone movement pattern dataset.

â€¢
Shen et al. (2018b) achieved a FAR of 7.89%, a FRR of 10.12%, and an EER of 9.41% on hand-hold scenario.

â€¢
Incel et al. (2021) achieved a FAR of 9.65%, a FRR of 31.58%, an EER of 19.26%, a TPR of 68.42% and an accuracy of 79.38% when evaluated with SMOTE sampling method.

Hidden Markov Model (HMM).
HMM is a probabilistic method based on Bayesian network (Roy et al., 2014, Roy et al., 2015). As a Bayesian network-based method, it uses a directed acyclic graph where each node represents the state of the system and a set of observation that configure the probability states. The likelihood makes the classification of a sequence of the sample given the probability states. Roy et al., 2014, Roy et al., 2015 used HMM because it does not need data from other users and can be updated with new data over time. The authors claimed that the performance of HMM is promising and better than other state-of-the-art approaches.


Table 14. Performance of One-class SVM (%).

Author	Dataset	Features	Kernel	FAR	FRR	EER	ACC	Other
Sitova et al. (2016)	Yang	96	RBF	â€“	â€“	15.71	â€“	â€“
Kumar et al. (2018)	Private	14	â€“	11.71	9.48	â€“	â€“	AUC  89.41
Shen et al. (2018b)	Private	192	RBF	7.89	10.12	9.41	â€“	â€“
Incel et al. (2021)	Private	126	â€“	9.65	31.58	19.26	79.38	TPR  68.42
Table 15 summarises the studies on touch-based continuous mobile device authentication that employed HMM to classify users. For this classifier, we would like to note that:

â€¢
Roy et al. (2014) achieved an EER of 0.31% for scrolling strokes as well as a FAR of 0.17% (at FRR of 0.00%), and FRR of 1.65% (at FAR of 0.00%), where the results were obtained using 11 strokes.

â€¢
Shen et al. (2018b) achieved a FAR of 3.98%, a FRR of 5.03%, and an EER of 4.74% on hand-hold scenario.

Other one-class classifiers.
Other than OC-SVM and HMM, other one-class classifiers can also be found in the literature. Isolation Forest (IF) is an ensemble-based method which also a non-parametric and unsupervised learning method (Liu et al., 2012). It isolates the anomalies by building trees and detects outliers that have a short average path on the trees. The classifier also does not need to know the distribution of the sample (Yang et al., 2018). Other classifiers can also be seen in the literature, such as Elliptic Envelop (EE) (Rousseeuw and Van Driessen, 1999, Kumar et al., 2018), Local Outlier Factor (LOF) (Ankerst et al., 1999, Kumar et al., 2018), scaled Manhattan (Sitova et al., 2016), scaled Euclidean (Sitova et al., 2016), and One-class Random Maxout Probabilistic Network (RMPNet) (Choi et al., 2018).


Table 15. Performance of HMM classifier (%).

Author	Data	Features	FAR	FRR	EER	ACC	Other
Roy et al. (2014)	Frank	30	0.17	1.65	0.31	â€“	â€“
Shen et al. (2018b)	Private	192	3.98	5.03	4.74	â€“	â€“
Table 16 summarises the studies on touch-based continuous mobile device authentication that employed other one-class classifiers to classify users. Kumar et al. (2018) employed IF, EE, and LOF. The study achieved the following results: (1) IF: FAR of 15.15%, FRR of 24.56%, and AUC of 80.15%. (2) EE: FAR of 15.28%, FRR of 15.54%, and AUC of 84.59%, and (3) LOF: FAR of 12.83%, FRR of 10.89%, and AUC of 88.14%. All these results were obtained from a swiping and phone movement pattern dataset. Sitova et al. (2016) used Scaled Manhattan and Scaled Euclidean. For Scaled Manhattan, the study achieved an EER of 13.62% for walking activity, with Fisher score ranking as a feature selection. For Scaled Euclidean, the study achieved an EER of 15.31% for walking activity with PCA as feature transformation method. Choi et al. (2018) proposed RMPNet, which achieved an EER of 0.06% on intrasession scenario using Frank dataset and an EER of 22.00% on Yang dataset.

From the results of the performance of each classifier, we can observe that many studies were carried out on different datasets and evaluated using different classification algorithms. The results from some studies were also reported in different performance metrics. Hence, it is challenging to compare the performance of a particular algorithm across various datasets. On top of that, even though many studies used the same public datasets, these studies used different experimental setup, which also makes the comparison of various classification algorithms on the same dataset to be challenging. We believe a benchmark study on the evaluation of various classification algorithms across the same public datasets is needed to compare and evaluate the best performers and to further improve the existing classification system.


Table 16. Performance of the other One-class classifiers (%).

Classifier	Author	Dataset	Features	FAR	FRR	EER	ACC	Other
IF	Kumar et al. (2018)	Private	14	15.15	24.56	â€“	â€“	AUC  80.15
EE	Kumar et al. (2018)	Private	14	15.28	15.54	â€“	â€“	AUC  84.59
LOF	Kumar et al. (2018)	Private	14	12.83	10.89	â€“	â€“	AUC  88.14
Scaled Manhattan	Sitova et al. (2016)	Yang	96	â€“	â€“	13.62	â€“	â€“
Scaled Euclidean	Sitova et al. (2016)	Yang	96	â€“	â€“	15.31	â€“	â€“
RMPNet	Choi et al. (2018)	Frank	28	â€“	â€“	0.06	â€“	â€“
Yang	18	â€“	â€“	22.00	â€“	â€“
Besides, it worth noting that the acceptable authentication error may differ from one application usage to another. Higher authentication errors might be acceptable in typical applications such as text messaging or social media usage. However, for more private and sensitive application like mobile banking, a more restrictive mechanism should be in place, where only lower authentication error can be accepted (Incel et al., 2021).

7.3. Postprocessing
Typically, the output of the classification of a single touch sample is used to perform the authentication decision. In this case, a touch stroke is determined to belong to the legitimate user or not based on a single sample. However, the output of the classification for multiple touch stokes can be used to produce the final decision. This postprocessing can be done by averaging the classification score (Fierrez et al., 2018, Incel et al., 2021) or through majority voting rule (Syed et al., 2019). For a particular user, the former will use the averaged score of multiple touch strokes for the authentication decision, while the latter will first determine the class of an individual touch stroke and then perform the authentication decision based on the majority class label. The main purpose of this step is to increase the robustness of the classification task (Frank et al., 2013).

7.4. Fusion-based classifiers
Fusion is a technique used for combining multiple information to improve the performance of a scheme. The combination can be performed by combining different features or classifiers at different stages using fusion techniques. The stages include at the level of feature extraction, matching, or decision-making phase. Furthermore, a unimodal touch-based biometric authentication still suffers from lower authentication accuracy. In order to overcome this limitation, some studies proposed a multi-modal biometric by combining multiple modalities like touch with a keystroke and phone movement (Kumar et al., 2016, Sitova et al., 2016) and combining them using fusion techniques. Table 17 summarises these fusion techniques used in the area. The performance of these studies shows an improvement after applying the respective fusion technique.


Table 17. Performance of fusion techniques (%).

Author	Modality	Fusion level	Performancebefore	Performanceafter
Kumar et al. (2016)	Typing, swiping, phone movement	Feature	FAR  10.09, FRR  5.59	FAR  11.44, FRR  4.23
Kumar et al. (2016)	Typing, swiping, phone movement	Score	FAR  12.71, FRR  6.75	FAR  7.20, FRR  7.01
Sitova et al. (2016)	Tap, type and HMOG	Score	EER  13.62	EER  7.16
Kumar et al. (2018)	Touch	Score, Decision	FAR  11.71, FRR  9.48	FAR  11.51 FRR  9.24
Fierrez et al. (2018)	Touch	Score	EER  4.40	EER  2.60
Choi et al. (2018)	Touch	Feature	â€“	EER  3.00
Smith-Creasey and Rajarajan (2019)	Type	Score	EER  12.46	EER  3.58
7.4.1. Feature-level fusion
Feature-level fusion aims to combine several feature data into a single feature vector. The fusion can be performed either by combining features from touchscreen sensors with other sensors (Kumar et al., 2016) or from touchscreen sensor alone (Choi et al., 2018). For example, Kumar et al. (2016) combined the feature of a swipe and physical phone movements captured from the gyroscope. The combined features from multiple sensors will be used as an input for a classification algorithm. On the other hand, Choi et al. (2018) combined features from a sequence of multiple touch strokes (single sensor) to feed into classification algorithms. The features are combined into a single vector.

7.4.2. Score-level fusion
Score-level fusion aims to combine the scores generated from classification algorithms (Kumar et al., 2016, Sitova et al., 2016, Kumar et al., 2018, Fierrez et al., 2018). This fusion technique is performed after the matching phase. The scores are combined to a single final score for decision making purpose. Like feature-level fusion, score-level fusion can also be performed using multiple sensors (Sitova et al., 2016) or single touch sensor. The combination rules that can be used include minimum (Smith-Creasey and Rajarajan, 2019), maximum (Smith-Creasey and Rajarajan, 2019), sum (Smith-Creasey and Rajarajan, 2019), weighted sum (Sitova et al., 2016), product rules (Smith-Creasey and Rajarajan, 2019), average (Fierrez et al., 2018), weighted average (Kumar et al., 2016), and function (Perera et al., 2018).

7.4.3. Decision-level fusion
Decision-level fusion is also performed after the matching phase. However, the combination is based on the decisions made by multiple classifiers to form a single decision. Each classifier will first perform the classification task individually. Then, the decisions from these classifiers will be combined to produce the final decision. The combination can be performed using voting rules such as AND (Perera and Patel, 2017) and OR rules.

8. Adaptation
Similar to any behavioural biometrics, touch behaviour may change over time (Palaskar et al., 2016). These changes may degrade the accuracy of the model. In order to maintain the accuracy of a classifier, it is necessary to re-train the classifier with the latest data by updating the user profile (Feng et al., 2014, Buduru and Yau, 2015, Palaskar et al., 2016, Incel et al., 2021). In general, this approach constantly updates the user profile with the latest data after a successful authentication.

According to Meng et al. (2018b), there are two steps of training: initial and dynamic training. The former builds a user profile using features from several sessions and the later continuously updates the user profile using a new session. The adaptation of the user profile is crucial as there might be some patterns that are outside of the training during the enrolment phase (Buduru and Yau, 2015). A model that can be updated with new touch data over time (Roy et al., 2015, Buduru and Yau, 2015) will be helpful for effective authentication.

Besides, Meng et al., 2014, Meng et al., 2018a presented an adaptive approach that can select a better classifier to perform user authentication. Instead of template adaptation, this mechanism can periodically perform the classifier selection to maintain the authentication performance due to the unstable performance of a classifier. The author introduced a cost-based intelligent mechanism that can select a less costly classifier from a classifiers pool to perform user authentication.

The number of studies in the domain of touch-based continuous mobile device authentication that focus on adaptation module is limited. Nevertheless, we believe this module is very important in the domain of touch-based continuous mobile device authentication, where touch-based biometric is a behavioural biometric that typically changes over time. Hence, a robust classification system that can handle gradual touch behavioural changes is crucial to ensure the stability of the continuous authentication scheme. There are opportunities to explore more solutions to address the adaptation module in touch-based continuous mobile device authentication to further advance the field.

9. Open challenges and opportunities
Based on the analysis of the literature in the area of touch-based continuous mobile device authentication, we identify some of the potential aspects that can be further studied by the researchers in the domain. We believe that touch-based continuous mobile device authentication is worth investigating due to the advantages offered by this type of authentication method, which can complement the existing authentication methods on mobile devices.

9.1. Realistic public datasets
As mentioned earlier, most of the publicly available datasets (Frank et al., 2013, Serwadda et al., 2013, Antal et al., 2015, Yang et al., 2014, Syed et al., 2019) use a controlled experimental setup and environment. Subjects are usually given a specific task (e.g. type of gesture) in a closed environment. A more uncontrolled data collection protocol would be helpful to study the robustness of the proposed scheme towards an unconstrained situation, which is more close to the real-world usage of mobile devices.

9.2. Quality of features
Providing high-quality features is crucial in any classification task. High-quality features can provide uniqueness of touch biometric traits. Besides, feature selection techniques can improve the quality of the features. Only a few studies (Frank et al., 2013, Li et al., 2013, Shen et al., 2015c, Sitova et al., 2016, Temper et al., 2017, Incel et al., 2021) employed feature selection techniques before applying a classification algorithm. It is important to investigate a feature selection strategy to ensure that a particular classifier can use a small number of features (which are significant for the problem domain) for faster computation while optimising its performance.

9.3. Threat model
Most studies in the domain of touch-based continuous mobile device authentication use the data of other subjects to simulate illegitimate access. However, these data are considered as a random attack. It would be worth to explore the usage of the data collected from subjects that are trying to imitate the touch actions performed the legitimate users. The purpose of this experimental protocol is to simulate the situation where an illegitimate user is trying to access the information stored in the device by trying to perform touch actions like the legitimate user so that the authentication mechanism cannot detect him or her.

9.4. Robust classifier
Typically, a userâ€™s behaviour changes over time (Fierrez et al., 2018). The variations are due to variability of the userâ€™s behaviour under different usage scenarios (Lu and Liu, 2015). One of the factors to consider in a biometric trait is permanence (Jain et al., 2004). In most studies in touch-based continuous mobile device authentication domain, the data acquisition is in a controlled environment. Therefore, the data contain relatively less noise when compared with the real-world usage of mobile devices. Touch biometric is well-known to have high intra-class variability that might be due to hardware, software, environment, psychological (e.g. emotional state), and physiological (e.g. handedness) factors (Shen et al., 2018b, Syed et al., 2019). The variability, as mentioned earlier, can cause instability of the modality over time (Xu et al., 2014).

It is not very easy to maintain a stable behaviour in the long run. The instability of a userâ€™s behaviour over time may cause the unstable performance of an algorithm, which lead to a lower accuracy (Meng et al., 2018b). Choosing a promising classifier to perform the classification task is a challenging task. This challenge is due to the different datasets or features extracted (Meng et al., 2018a). Unstable performance of a classifier will cause the classifier not being able to outperform the other classifiers consistently. Therefore, various solutions need to be explored to come out with a more robust classification system. For example, an adaptive learning technique (Gama et al., 2014) can be employed to update the user profile which can adapt to the changes of usersâ€™ behaviour over time. This technique detects the changes in the data and adapt to the evolving data over time to avoid the degradation of authentication accuracy. Besides, an ensemble learning-based classifier selection technique (Britto et al., 2014, Bashbaghi et al., 2017, Almeida et al., 2018, Cruz et al., 2018) can be explored to overcome the issue of unstable classifier. This technique generates an ensemble of classifiers and selects the most optimum classifier to perform the classification task of particular test sample. Moreover, an adaptive threshold (Meszaros et al., 2007, Hosseinzadeh and Krishnan, 2008) is also a potential solution. This technique adjusts the authentication threshold on each successful authentication to adapt to a userâ€™s behavioural changes without the need of updating the user profile.

Besides, there is still a lack of studies that utilise deep learning approach in the area of touch-based continuous mobile device authentication, when it is getting more attention in other domains. The ability of deep learning to learn features may also be utilised to overcome the need of handcrafted feature extraction. Therefore, it is also worth to further study the robustness of deep learning approach in this area. On top of that, Few-shot Learning (FSL) (Wang et al., 2020b), a deep learning approach that has the ability to learn from small training data, can be further explored to address the lack of open source touch-based datasets. This approach could be a potential deep learning-based approach as it has shown some promising results in other biometric modalities (Jagtap et al., 2020, Wright and Stewart, 2020, Xu et al., 2020).

9.5. Computational time
The computational time of a continuous authentication scheme could be affected by the features and classifiers used. Low computational time such as statistical methods may lead to low performance (Fierrez et al., 2018). However, a more powerful machine learning algorithm may require higher computational time (Meng et al., 2018b). Besides that, the number of touch strokes to train the model also influences the computational time. In this case, the smaller number of swipes has a lower computation cost (Fierrez et al., 2018). Most studies only reported the results in term of authentication accuracy. Computational time should also be investigated to ensure the scheme is not only better in term of authentication accuracy but also has low computational time.

9.6. Resource consumption
In general, existing studies in the area evaluate the performance of the proposed scheme in terms of authentication accuracy. An accurate classier may require more CPU resources and may consume more power, which will drain the battery faster. In addition, the always-on sensors, operating system and apps may consume some energy from the device too (Bo et al., 2014, Lu and Liu, 2015). It is worth to study the effects of any proposed scheme on the resources available on the device by considering the limited resource in a mobile device.

10. Conclusion
Touch-based biometric has shown a huge potential in continuous monitoring and authentication of mobile devices users. Although it may not replace the one-time authentication, touch-based continuous mobile device authentication may provide a complementary authentication on mobile devices. It has the advantages of not requiring dedicated hardware and can run transparently in the background without interrupting the usersâ€™ current usage. Hence, the aim of this paper is to provide a comprehensive review of the research done in the area of touch-based continuous mobile device authentication. The paper first presents an overview of the continuous authentication scheme based on touch biometrics and the different phases involved in the scheme. We then provide a detail summary and analysis of the methods used in each phase of the scheme, which includes data acquisition, feature extraction, and user classification. Finally, we discuss some of the open challenges in the area and recommend some promising directions for further research. Therefore, this paper can provide an introductory reference to researchers who are interested in the area, especially for those who are new in the domain of touch-based continuous mobile device authentication.

