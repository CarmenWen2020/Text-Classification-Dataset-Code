Video-based online learning is becoming commonplace in higher education settings. Prior studies have suggested design principles and instructional strategies to boost video-based learning. However, little research has been done on different learner characteristics, such as how learners behave, what behavioral patterns they exhibit, and how different they are from each other. To fill this research gap in student-video interaction, we employed learning analytics to obtain useful insights into students' learning in the context of video-based online learning. From 11 log behaviors represented by log data from 72 college students, four behavioral patterns were identified while students learned from videos: browsing, social interaction, information seeking, and environment configuration. Based on the behavioral patterns observed, participants were classified into two clusters. Participants in the active learner cluster exhibited frequent use of social interaction, information seeking, and environment configuration, while participants in the passive learner cluster exhibited only frequent browsing. We found that active learners exhibited higher learning achievement than passive learners.

Previous
Next 
Keywords
Behavioral patterns

Learner cluster

Video log analytics

Learning analytics

Learner online behavior

1. Introduction
Video-based online learning is becoming commonplace in higher education settings due to the rapid development of self-paced asynchronous courses (Thomas, West, & Borup, 2017). Self-paced asynchronous online courses—such as massive open online courses (MOOCs)—offered at higher education institutions often leverage video lectures as a primary form of content learning (Atapattu & Falkner, 2018; Kim et al., 2014; Stöhr, Stathakarou, Mueller, Nifakos, & McGrath, 2019). The proliferation of video-based online learning in higher education is attributed to its usability and flexibility (Anggraini et al., 2018). In the learning environment, instructors can easily deliver both auditory and visual information in videos. Post-secondary students who are often off campus can gain access to video content without time and geographical constraints, enabling them to engage in their own learning in a self-paced manner (Giannakos, Chorianopoulos, Ronchetti, Szegedi, & Teasley, 2014; Siemens, Gašević, & Dawson, 2015).

As educators and researchers respond to the growth of video-based online learning, an attempt has been made to enhance the learning environment by integrating interactive features into video players (e.g., Kleftodimos & Evangelidis, 2016; Merkt & Schwan, 2014). Interactive features are intended to foster student engagement and facilitate students' intellectual endeavors while watching videos (Merkt, Weigand, Heier, & Schwan, 2011). In addition to basic interactive features for controlling video flow (e.g. play, pause, move forward), advanced features for commenting, bookmarking, and annotating have been integrated (Kleftodimos & Evangelidis, 2016). Empirical evidence has shown that interactive features added to video players enhance student engagement and achievement. However, not all students benefit from those interactive features (Reychav & Wu, 2015). While some students engage in the interactive video-learning environment, other students do not fully take advantage of it due to individual differences in learning patterns (Merkt et al., 2011). Angrave, Zhang, Henricks, and Mahipal (2020) has called for further research on how learners use multiple features on video players, which represents the different levels of their engagement with the learning content.

Researchers are increasingly recognizing the potential of learning analytics as a means of examining students' learning patterns by utilizing students' learning traces, such as log data (Atapattu & Falkner, 2018). Data tracking standards—such as experience application programing interface (xAPI)—enable an examination of learner-video player interaction to explore how students interact with videos. While some prior studies have leveraged such learning traces (e.g., Guo, Kim, & Rubin, 2014; Lan, Brinton, Yang, & Chiang, 2017), they have mainly focused on revealing associations between log behaviors and learner engagement without conceptualizing them. A lack of knowledge for interpreting learner behaviors has been a significant limitation in prior empirical studies, inhibiting a deeper discussion of how to design individualized support for learners. Furthermore, the literature on video-based online learning has indicated that learners exhibit different learning patterns, and thus individualized support should be designed assuming learners' heterogeneity (Chi & Wylie, 2014). As such, it is imperative to examine how learners learn differently from videos to enhance our knowledge about the nature of learning that occurs in video-based online learning. An understanding of learners' different learning patterns would also inform the future design of engaging video-based online learning environments that can meet the individual needs of learners with diverse learning patterns. To address the research gap described above, we 1) conceptualized students' behavioral patterns represented by their log data recorded on a video player, 2) classified the students according to the identified behavioral patterns, 3) explored the main factors that contributed to students' classification, and 4) examined the difference in learning achievement between the identified clusters. Specifically, we addressed the following research questions in this study:

1.
How are students' log behaviors converged into behavioral patterns in video-based learning?

2.
How can students be classified according to their behavioral patterns in video-based learning and what factors contribute to students' classification?

3.
Do differences exist between the identified clusters regarding learners' learning achievement?

2. Literature review
2.1. Video-based learning
Video is a medium that delivers content by combining audio with various visual elements including text, images, and animation (Asthana, 2006). Video-based learning is defined as a form of learning that utilizes video content as its primary teaching material (Picard, 1999). Given the rapid growth of online learning in higher education, video lectures are recognized as an effective medium to inform students about course topics because videos are able to feature various instructional elements such as visual information, auditory effects, and social cues (Snelson, 2010). According to Stöhr, Demazière, and Adawi (2020), videos can provide students with a learning experience equivalent to what they would receive with conventional instructor-led lectures. In fact, contemporary forms of online learning platforms—such as MOOCs and microlearning—are organized around video lectures with follow-up activities and assessments (McBrien, Cheng, & Jones, 2009). Online course types leveraging video-based learning range from fully asynchronous online courses to blended learning in which pre-recorded video lectures are used for main content learning (Derntl & Motschnig-Pitrik, 2005; Giannakos, 2013). The advantages of video-based learning include reduced cost and accessibility compared to face-to-face or real-time instruction. In particular, the use of pre-recorded video lectures is cost-effective when real-time lectures are not implementable due to place constraints such as a lack of physical classrooms (Giannakos et al., 2014). Students can benefit from the increased accessibility of video-based learning by, for instance, watching video lectures as many times as needed to master the course content. Video players' advanced features that enable bookmarking and annotations can also help students actively interact with the main learning content. For these reasons, video-based learning has been widely adopted to support learners of different levels of knowledge and skill for self-paced learning (Clark & Mayer, 2016).

However, since video-based learning occurs in an environment where learners are physically separated from their instructors, learners' ability to sustain engagement with video content is critical (Benson & Samarawickrema, 2009). Previous research has revealed that students' success in video-based learning is largely dependent on their learning strategies for absorbing and internalizing content delivered by videos (Kennedy, Ahn, & Choi, 2008; Seidel & Shavelson, 2007). Such in-depth learning is not guaranteed when students merely spend time watching the videos without exerting any cognitive effort. Thus, students' activities while watching videos may be indicative of their level and type of engagement. For example, Giannakos, Chorianopoulos, and Chrisochoides (2015) found that students' active control of buttons on a video player during play time was associated with learning achievement. Risko, Foulsham, Dawson, and Kingstone (2013) also revealed that students' commitment to annotation features on a video player predicted levels of understanding of the topics addressed in the video.

2.2. Learner engagement in video-based online learning
Learner engagement is a multifaceted concept and can be measured differently depending on learning contexts and objectives (Trowler, 2010). For example, if learners are placed in a collaborative learning environment, their engagement with their team would be of primary interest. In contrast, if learners are supposed to perform independent online learning, their engagement with online content should be an important indicator of their learning. Video-based learning assumes that distance learners study in an asynchronous manner. Given that there is no real-time guidance from their instructor who can help them make timely progress in such an environment, their engagement with learning content is critical to their independent learning (Hampton & Pearce, 2016). In that regard, Angrave et al. (2020) highlighted the need to identify reliable measures that represent the different aspects of learner engagement in video-based learning environment.

In order to conceptualize learner engagement in video-based learning contexts, previous research has examined learner behaviors observed in the learning environment. For instance, Chi and Wylie (2014) proposed the ICAP (Interactive, Constructive, Active, Passive) framework, which categorizes students' learning activities into four types of engagement. According to this framework, passive learners focus on “receiving;” i.e., viewing video lectures without further effort to embed the information in their schema relevant to the lecture topic. Active learners engage in “manipulating” behaviors by pausing, fast-forwarding, or rewinding video lectures to selectively obtain information. They also take notes and/or highlight sentences to integrate new information with their prior knowledge. Constructive learners are characterized by “inferring” behaviors; i.e., self-explaining concepts introduced in the video and comparing and contrasting to their prior knowledge or other materials. Interactive learners go beyond solo learning and engage in “co-inferring” by interacting with their peers for the justification and discussion of course topics.

Some empirical studies on learner behavior in video-based learning further examined the behavioral characteristics of engaged students. For example, Kim, Lee, and Park (2019) analyzed the learning patterns of learners participating in self-paced open courses through the lens of self-regulated learning. The authors linked learner engagement with learners' ability to self-regulate through, for example, time and resource management skills. In the study, learners who engaged in social interaction were considered to have high levels of self-regulated learning skills. Rybakova and Witte (2019) found that a disengaged student, in contrast, merely views the course content, showing poor engagement in social interaction. Nummenmaa and Nummenmaa (2008) labeled passive online learners “lurkers” who focus on observing others' activities without participating in constructive activities. For example, lurkers read others' comments in online discussions without making their own comments (Petrovčič & Petrič, 2014). Recent learning analytics research has leveraged student learning traces collected in online learning systems in order to measure student engagement (Kim, Lee, Leite, & Huggins-Manley, 2020). For example, D'Mello, Olney, Williams, and Hays (2012) analyzed students' gaze patterns to identify student engagement and disengagement while watching online lessons. They assumed that students were disengaged when they looked away from the screen for an extended period of time. Kim, Yoon, Jo, & Branch, 2018 proposed proxy variables representing students' self-regulated learning by utilizing students' log traces in an asynchronous video-based learning course. Their prediction model incorporating the proxy variables successfully detected at-risk students with low engagement in very early phases of the online course.

Students' traces have also been used to measure student engagement within video players. Video analytics approaches have been used to analyze log data collected while students were manipulating video players. The analytics of video player data helps to explore “what students did” on the video players. For example, Lan et al. (2017) used behavioral data to model learners' engagement while watching lecture videos and linked it to their learning outcomes. The authors identified behaviors exhibited on the video player—such as number of pauses, number of rewinds, number of fast-forwarding clicks, and average playback rate. The results demonstrated that these log variables were able to represent student engagement. The proposed model showed that it was possible to measure student engagement only with log data; however, a question remains about what those variables mean conceptually and how student behaviors should be conceptualized in video-based learning. The lack of conceptualization of student video engagement inhibits a full discussion of how to support students and what kind of personalized guidance should be provided for students with diverse engagement patterns.

2.3. Interactive video environment and video analytics
Due to the increased demand for video-based learning that engages learners, interactive video-based learning environments have been actively designed. Video lectures are inherently an instructor-led modality; thus, students cannot elicit responses from objects being displayed in the videos. Instead, it is important to enable students to engage in cognitive work for the delivered content to be integrated as a representation in their schemata (Mayer, 2009; Rickley & Kemp, 2020). One way to achieve this is by adding interactive features to video players to enable students to become agents of their own learning.

Common interactive features used for interactive video players include buttons or a progress bar that enable learners to explore content by pausing or moving backward or forward. By using these basic interactive features, learners are able to view videos in a non-linear manner, a viewing behavior that has been found to lead to better learning outcomes—especially when compared to videos without such features (Schwan & Riempp, 2004). Recently, advanced interactive features have been integrated into video players to promote learners' intellectual endeavors and social interaction with other learners. Video annotation tools are one of the advanced features that have been increasingly used in video-based online learning (e.g., Chatti et al., 2016; Mitrovic, Dimitrova, Lau, Weerasinghe, & Mathews, 2017). By engaging in annotation, learners have the opportunity to highlight points of interest and organize their thoughts (Kleftodimos & Evangelidis, 2016). For example, Saeed, Yang, and Sinnappan (2009) proposed an annotation system through which students can organize information at specific time points in a video and return to those later for review. This feature allows students to selectively recall a particular piece of information in the video. An annotation tool used in a study by Yousef, Chatti, Danoyan, Thüs, and Schroeder (2015) helped students engage in active learner-content interaction. In the study, students expressed satisfaction with the fact that they had control over what they wanted to highlight. This type of information processing that occurs during learning leads to the acquisition of transferable knowledge. Importantly, students' autonomy during one-way video lectures can promote student motivation and engagement.

Beyond annotation tools, social features can also be embedded into video players to facilitate students' interactions with each other. While video-based learning relies on video lectures as its primary form, social networking features—including discussion forums and messenger apps—can enrich the student experience. Before and after learning from videos, opportunities should be created for students to share opinions and ideas about the video topics. In fact, in a particular study, students who engaged in social interaction with their peers expressed that the social interaction positively impacted their commitment to the video-based course (Benson & Samarawickrema, 2009; Dubosson & Emad, 2015). Seeking help and interacting with peers are considered instrumental behaviors for increasing engagement in video-based learning (Aleven, Stahl, Schworm, Fischer, & Wallace, 2003; Newman, 1994). Social interaction encouraged within a video-based learning platform can thus help students manage and enhance their own learning.

Despite the importance of interactivity in video-based learning, there has been limited research on students' behaviors as observed during their engagement with video content. This could be explained, for instance, by the difficulty in collecting students' traces left on video players. The recent development of e-learning software—such as the experience application programming interface (xAPI)—has made it easier to track what students do while they learn from videos, enabling us to see what actually occurs and which behaviors predict student engagement and learning achievement on video platforms (e.g., Kim et al., 2020; Lan et al., 2017). For instance, Kim et al. (2020) explored the relationships between students' engagement with video lectures and the likelihood of continued use of an open mathematics learning platform. In this study, the number of watched video lectures and the frequency of using seeking buttons on players were found to contribute to retention through the learning platform.

Prior studies have revealed how log variables are associated with student engagement and achievement. However, individual log variables have not been conceptually examined. Furthermore, prior studies have typically regarded learners as a homogeneous group. The conceptualization of learner behaviors and classification of learners according to their behavioral patterns would help to produce more generalizable knowledge regarding the unique characteristics of learning that are exhibited in video-based online learning environments.

3. Methods
3.1. Participants and setting
The study's participants were 72 undergraduate students recruited from a university website and online community in South Korea. Students who wanted to participate in the video-based learning experiment sent an email or SNS application to the research team, and they received confirmation with an experiment schedule through a text message. All participants were undergraduates; 30 (41%) were men and 42 (58%) were women. Of the 72 total participants, 39 (54%) were majoring in the humanities and social sciences while 33 (45%) were majoring in the natural sciences or engineering.

3.2. Materials and apparatus
In this study, we employed a multimedia lesson on propositions designed by a mathematics educator and instructional designer. The lesson was presented by showing slides while the instructor delivered a synced audio. The lesson was about 12 min and 30 s. This video length was suggested by Guo et al. (2014) as an appropriate running time in which students can maintain their engagement. The lesson started by clarifying the learning objectives and then presenting mathematical concepts of propositions with examples. The concepts covered two types of statement quantifiers (i.e., (∀, ∃) and (∃, ∀); ∀ is a universal quantifier, and the ∃ stands for existential quantifier) in mathematics.

This study utilized an interactive video player designed to amplify self-paced video-based online learning, where learners are physically separated from the instructor and peer learners. The player was equipped with a commenting feature for learners to communicate with peer learners in an asynchronous manner. Physical distance and online communication between the instructor and learners are the typical characteristics of video-based online learning (Hung & Higgins, 2016).

Using this player, learners were able to control the pace of the video—by using play, pause, rewind, forward, speed change, seek, move slide, change volume, and adjust screen size buttons—and also create, reply to, and view comments. Learners were also able to add bookmarks to pinpoint important learning sections or view what they had bookmarked while watching each video lesson. The player showed learners a list of learning activities—such as comments and bookmarks to be created by the learner—to help learners monitor their learning progress while watching video lessons. The player featured four sections: a video section, a lecture slide section, a bookmark and comment library section, and a video annotation section based on a timeline. Fig. 1 shows the interface of the player used in this experiment.

Fig. 1
Download : Download high-res image (144KB)
Download : Download full-size image
Fig. 1. Interface of the interactive video player.

Once an instructor uploads lecture slides and a recorded video lecture narrating the slides, the video lecture is shown on the video section while the slides are displayed on the lecture slide section. In default mode, the player synchs the lecture video and the slides on the slide section, but learners are able to move the slides back and forth on the slide section while the video lecture is being played on the video section; this feature is intended to allow learners to explore slides at their own pace for review or preview. Learners are able to make annotations and/or comments while they are watching the lesson and see others' comments and/or annotations as well. However, we turned off the real-time annotation/comment sharing feature during the experiment in order to prevent students from viewing different numbers of comments or annotations. Instead, we created a few comments and annotations prior to the experiment for students to try the annotation/comment feature.

3.3. Procedure
Once participants arrived for the study, the experimenter provided them with a brief study overview, detailed information about the tasks to be completed, and guidelines for using the player. They were also informed that their log data would be collected and analyzed for research purposes. After this orientation, participants took a pre-test intended to measure their prior knowledge about the lesson topic (i.e., propositions). They then started watching the video lesson using the interactive video player. After the video lesson was over, participants completed a post-test.

3.4. Data collection
This study used data collected from participants' online behavior logs while they watched the video lesson on propositions. The log records were categorized and coded based on the prior study conducted by Lee, Kim, & Jo, 2020, as Table 1 shows. Table 1 provides a description of log behaviors.


Table 1. Description of log behaviors.

Log behavior	Log record	Description
Play	Play	The frequency of each participant's clicks on the play button
Pause	Paused	The frequency of each participant's clicks on the pause button
Bookmark	Add bookmark
Click bookmark	The frequency of each participant's clicks on the bookmark buttons
Slide	Next slide
Previous slide	The frequency of each participant's clicks on the slide buttons
Condition	Playback rate changed
Muted
Slide full screen
Video full screen	The frequency of each participant's clicks on the condition buttons
Comment	Add comment	The frequency of each participant's clicks on the add comment button
Reply	Reply to comment	The frequency of each participant's clicks on the reply to comment button
View	View comment	The frequency of each participant's clicks on the view comment button
Filtering	Filtering	The frequency of each participant's clicks on the filtering button
Seek	Seek filtering
Seeking	The frequency of each participant's clicks on the seek buttons
Annotation	Annotation	The frequency of each participant's clicks on the annotation button
3.5. Data analysis
3.5.1. Factor analysis
Prior to conducting a cluster analysis, we performed a principal component analysis (PCA) to extract the variance explained by each log behavior sorted into fewer components. We assumed that students' log behaviors could be classified into conceptually meaningful categories representing student-video interaction. The PCA approach helps to elicit meaningful findings when variables seem to be correlated and therefore warrant further investigation (Ku, Storer, & Georgakis, 1995). Moreover, Tomita, Park, and Sotomayor (2002) suggested that conducting a PCA can be beneficial for subsequent clustering analysis in terms of interpretability.

3.5.2. Clustering analysis through partitioning around medoids (PAM) method
We conducted a clustering analysis to classify students into two clusters employing the partitioning around medoids (PAM) method, which performs partitioning using K-medoids. This method is similar to the K-means clustering method in that both aim to identify the optimal number of clusters that can minimize the distance between points within each cluster around a designated center. The difference is that the PAM algorithm uses real data points as centers (i.e., medoids) whereas the K-means algorithm designates arithmetic points (i.e., centroids), which are not necessarily real data points, as centers. The PAM algorithm has also been demonstrated to be more robust to noise and outliers than the K-means algorithm (Pyo, Park, & Moon, 2010).

3.5.3. Covariates and outcome
Moreover, we conducted a logistic regression analysis in order to determine whether participants' personal factors predicted cluster membership. These covariates included participants' gender, major, and level of prior knowledge. The inclusion of these factors is based on prior studies' arguments (e.g., Cho & Kim, 2013; Martin & Bolliger, 2018) that they may influence student engagement and learning in online learning. The major variable (STEM vs. non-STEM) was considered because the video lesson used in the experiment addressed a mathematical concept. Gender and major were coded as a binary variable. We used participants' pre-test scores as the level of prior knowledge. We also conducted an analysis of covariance (ANCOVA) to identify whether participants classified into each of the two clusters differed in the post-test controlling their pre-test scores.

4. Results
4.1. Research question 1: How are students' log behaviors converged into behavioral patterns in video-based learning?
We retained factors with an eigenvalue over one, meaning that each component explained more variance than a single item (Kaiser, 1960). As a result, we determined that a four-component model would best fit the data (see Table 2). The four factors in this study were found to explain nearly 74% of variance. The Kaiser-Meyer-Olkin measure of sampling adequacy (0.626) and the result of Bartlett's test of sphericity (χ2 = 389.570, df = 55, p < .001) also indicated that the four-factor model fits the data. After carefully reviewing the existing literature and examining the present study's results, we defined what each of the components indicated. Specifically, we labeled the identified components as follows. “Browsing” represents behaviors related to superficial interaction with the video player. According to Schoeffmann, Hudelist, and Huber (2015), video browsing involves “search[ing] for a specific content segment” and “content browsing for inspiration purposes without a specific information need” (p. 2). Therefore, in the present study, the video play/pause and bookmarking behaviors corresponded to the above authors' definition of video browsing. “Social interaction” refers to log behaviors recorded when participants were interacting with others to exchange ideas and thoughts. Empirical studies on video-based online learning have suggested that commenting is a strong indicator of student engagement in social interaction (e.g., Sung, Wang, Huang, & Lin, 2017). “Environment configuration” refers to learner behaviors observed when learners intended to begin interacting with an optimal learning environment for effective learning. The term “configuration” has been widely used in prior studies (e.g., Sun, 2018; Villena, Goularte, & de Mattos Fortes, 2014) to represent these behaviors. By “information seeking”, we indicated learner behaviors involving the use of cognitive efforts to retrieve and organize information. Previous research on online learning has implied that information filtering and annotation require information-seeking processes (e.g., Glover, Xu, & Hardaker, 2007).


Table 2. Rotated matrix for principal component analysis.

Behavioral pattern	Component
Log behavior	Browsing	Social interaction	Environment configuration	Information seeking
Bookmark	0.848	0.052	−0.054	−0.207
Video pause	0.852	0.274	0.134	0.270
Video play	0.762	0.181	0.402	0.331
Reply to comment	0.150	0.827	0.038	0.096
View comment	0.045	0.912	−0.055	0.008
Comment	0.541	0.647	−0.168	0.105
Condition	0.047	−0.004	0.744	−0.081
Seek	0.517	−0.029	0.641	0.063
Slide	−0.018	−0.058	0.720	−0.035
Filtering	0.145	−0.129	−0.139	0.866
Annotation	−0.018	0.317	0.027	0.809
The first component mostly included “bookmark”, “video pause”, and “video play”, representing students' browsing behavior patterns. The second component was mostly represented by “reply to comment”, “view comment”, and “comment”, which are all related to students' peer interaction. The third component included the “filtering” and “annotation” variables, representing how students actively sought information to enhance their understanding of the video's topic. The fourth component reflected students' behavioral patterns intended to control the video player settings, such as changing the volume or screen size; for this component, “condition”, “seek”, and “slide” exhibited the greatest loadings. We labeled these four identified and classified behavioral patterns as “browsing”, “social interaction”, “environment configuration”, and “information seeking.”

4.2. Research question 2: How can students be classified according to their behavioral patterns in video-based learning and what factors contribute to students' classification?
We used the NbClust package in R statistics to determine the optimal number of clusters. As a default, the package internally conducts a clustering analysis with K, the number of clusters, ranging from 2 to 15. The package also examines 30 indices including “silhouette”, “gamma”, “pseudot2”, and so on (Charrad, Ghazzali, Boiteau, Niknafs, & Charrad, 2014). The results of this analysis suggested that participants should be classified into two clusters.

Following the suggested indices, we performed a clustering analysis using the PAM method to classify students into two clusters. Out of 72 participants, 56 were classified into the first cluster. These participants were characterized by high levels of engagement with social interaction, environment adjustment, and information seeking. Thus, we labeled the first cluster “active learner.” The remaining 16 participants were classified into the second cluster, which was characterized by frequent browsing. Second-cluster participants were not active in terms of social interaction, environment adjustment, or information seeking compared to those classified into the first cluster. Table 3 presents the standardized means score for the four components in the two clusters. For example, in the first cluster, the mean of browsing frequency was −0.107 standard deviations away from the grand mean.


Table 3. Means of each component by identified clusters.

Component	Cluster
Cluster 1 (n = 56)	Cluster 2 (n = 16)
Browsing	−0.11	0.27
Social interaction	0.35	−0.01
Environment configuration	−0.04	−0.18
Information seeking	0.08	−0.23
Cluster characteristic	frequent use of social interaction, environment configuration, and information seeking	frequent browsing use
Label	Active learner	Passive learner
We conducted a logistic regression analysis to determine if participants' gender, major, and pre-test scores could predict the probability of being classified into one of the two clusters. We classified students into two majors—science, technology, engineering, and mathematics (STEM) major and non-STEM major—because the video lecture addressed a mathematics topic with which STEM major students were more likely to be familiar than non-STEM major students. The logistic regression analysis results indicated that none of these personal factors predicted the probability of being classified into one of the two clusters (see Table 4).


Table 4. Results of logistic regression.

Variable	B	S.E.	Wald	df	Sig.	Exp(B)
Gender	0.78	0.66	1.39	1	0.24	2.18
STEM major	0.40	0.63	0.40	1	0.53	1.50
Pre-test	0.02	0.08	0.05	1	0.82	1.02
Constant	−2.23	1.45	2.36	1	0.13	0.11
4.3. Research question 3: Do differences exist between the identified clusters regarding learners' learning achievement?
We compared student achievement between the two clusters through an analysis of covariance (ANCOVA). This confirmed that there was no significant difference in the variance of residuals between the two clusters (F = 1.086, p = .301). The ANCOVA results showed that there was a significant difference (F = 4.233, p = .043) in the post-test score between the two clusters when controlling the pre-test score; namely, participants classified into the first cluster achieved higher scores than participants classified into the second cluster. (See Table 5.)


Table 5. Means (and SD) of learning performance by identified clusters.

Cluster 1
Active learner (n = 56)	Cluster 2
Passive learner (n = 16)	F	Analysis
M	SD	M	SD
Learning performance	17.7	3.2	15.8	4.6	4.2⁎	1 > 2
⁎
p < .05.

5. Discussion
The present study's main purpose was to examine students' learning behavioral patterns and learner clusters in a video-based online learning context. Specifically, we first categorized students' log behaviors represented by their log traces into a few learning behavioral pattern components in order to perform a subsequent cluster analysis. We then clustered learners using the identified learning behavioral pattern components and compared the characteristics of each cluster. Finally, we examined whether personal factors could potentially predict cluster membership and differences in learning achievement between the two clusters.

5.1. Identified behavioral pattern components
The study's principal component analysis revealed that the 11 log behaviors collected through the video player were converted into four behavioral pattern components representing different aspects of student-video interaction. The first pattern was “browsing”, and it was represented by a) play, when the video started playing or resumed after a pause; b) pause, when the video was paused by a student; and c) bookmark, when learners created a bookmark by clicking the button. Browsing has been defined as a subjective process used by learners for navigation (Shahraray, Cox, Haskell, LeCun, & Rabiner, 1999). The second pattern was “social interaction”, and it was represented by a) comment, when learners created a comment; b) reply to comment, when learners replied to existing comments; and c) view comment, when learners viewed comments made by other learners. These three activities related to commenting behaviors indicated student engagement through social interaction, which echoes Jung, Choi, Lim, and Leem's (2002) finding that learners' social interaction can be facilitated through commenting between peers and instructors. Borup, West, and Graham (2012) conducted a study featuring a video lecture-based asynchronous course and found that participants attempted to communicate with their peers by commenting. Indeed, participants' commenting behaviors contributed to social coherence within the class. Therefore, we suggest that commenting may be a critical activity for video-based learning where students are physically isolated from their instructors. Moreover, online social interaction via commenting can be a way to satisfy learners' intellectual and psychological needs. For example, Kim, Park, Yoon, & Jo, 2016 highlighted the importance of the time students spend commenting on online discussion forums as a follow-up activity for video lecture-based courses; specifically, commenting was found to enhance peer interaction and learners' understanding of course content. The third pattern was “information seeking,” represented by a) filtering, when learners filtered information such as lecture slides or comments created by the authors for the experiment); and b) annotation, when learners searched for an annotation. Filtering and searching for annotations both represent “the purposive seeking for information as a consequence of a need to satisfy some goal” (Wilson, 2000, p. 49); thus, we labeled these two behaviors as “information seeking.” The last pattern was “environment configuration”, and it was represented by a) condition, when learners changed the volume or adjusted the size of the video player; b) slide, when learners moved from one slide to another slide by clicking on arrow buttons; c) seek, when learners sought content by moving the video play head or rewinding.

5.2. Learner cluster profiles
Participants were classified into two clusters with different profiles based on the learning behavioral patterns represented by the study's four identified components. The first cluster, to which 56 (77%) participants were classified, was characterized by learners' engagement with social interaction, information seeking, and environment configuration. Consequently, we labeled this cluster “active learner.” Given the self-directed nature of video-based online learning, these learning patterns are frequently observed in learners with high levels of self-regulation skills (Hu, Zhang, Gao, & Wang, 2020; Wu, 2017). For instance, in Pellas's (2014) study, active learners exhibited strong metacognitive skills and high levels of engagement in both online and in-person social interaction (Ponti, 2014). In flexible learning environments such as video-based asynchronous courses, students who engaged equally in individual and social activities also exhibited high levels of self-regulation skills (Kim et al., 2019).

The study's second cluster was characterized by frequent use of browsing and minimal use of other learning behavioral patterns. As a strategy, browsing can be used to explore content and tends to involve a series of glimpses that may or may not lead to further intellectual endeavors (Lo, Chan, & Yeh, 2012). The study's participants classified into this cluster browsed through the lecture videos and web pages frequently but did not move to the next step of commenting or information seeking. Thus, we labeled this cluster “passive learner.” Nearly a quarter of participants (n = 16, 22%) were classified into this group. Prior studies on asynchronous online courses have outlined the characteristics of such students who view course content but do not engage in social interaction or cognitive processing (e.g., Rybakova & Witte, 2019; Speily & Kardan, 2018). So-called “lurkers” (Nummenmaa & Nummenmaa, 2008) in online learning complete the required content and passively observe others' activities without participating in constructive activities. For example, Petrovčič and Petrič (2014) discovered that lurkers read others' comments during online discussions but do not make any comments themselves. In the present study, participants classified into the passive group exhibited similar behavioral patterns with those recognized as lurkers in Petrovčič and Petrič (2014). In prior studies, lurkers did not engage in behaviors beyond viewing others' contributions to online courses; in this study, similarly, the passive cluster participants watched lectures but did not participate in social activities or information processing.

5.3. Learners' personal factors and cluster membership
Furthermore, we conducted a logistic regression analysis to determine whether learners' personal factors might affect cluster membership. The analysis results indicated that learners' gender, major, and prior knowledge were not predictive of cluster membership. In other words, the identified learning patterns were observed regardless of learners' personal factors. Previous research has reported findings consistent with this. For example, Yukselturk and Bulut (2009) suggested that there was no gender effect on students' learning strategies in video-based online learning. Kim et al. (2019) also found that students' learning patterns did not differ based on gender at the Open University, which employs video lectures as a main content delivery channel. Similarly, Kizilcec, Piech, and Schneider (2013) demonstrated the absence of a gender effect in terms of student engagement in video-based learning. According to Kim et al. (2019), the influence of personal factors may be dependent on learning content and students' personal traits. Therefore, further research should be conducted to determine whether personal factors can influence students' learning patterns in different settings.

5.4. Learner groups and achievement
The learners in the active learner cluster exhibited higher learning achievement than students in the passive learner cluster. In other words, learners who engaged significantly with social interaction, information seeking, and environment configuration achieved better outcomes than those who only browsed video lectures. These active learner characteristics are similar to those of high-performing students described in prior studies. In those studies, high-performing students were characterized by the use of comprehensive strategies encompassing social, cognitive (Pellas, 2014), and environmental (Liaw & Huang, 2013) aspects of online learning activities. The association between cluster membership and achievement found in the present study can be linked with the unique nature of video-based learning environments. Video-based online learning environments in which instructors' immediate support is not available require students to continually engage in the metacognitive process; students must understand what they are lacking and what actions they should take to fill the gaps in their learning progress (Niess & Gillow-Wiles, 2013). This metacognitive process has been recognized as positively associated with student achievement.

Educators and researchers are paying increased attention to online interaction due to the growing integration of social features in online learning environments. These features are often implemented in the form of virtual spaces dedicated to social interaction, such as online discussion forums (John, Thavavel, Jayaraj, Muthukumar, & Jeevanandam, 2016). Social interaction is one of the most important strategies for success in self-paced online learning leveraging video lectures (Borup et al., 2012; Lee & Wu, 2013). In Petrovčič and Petrič (2014), learners who frequently replied to others' comments were found to have higher levels of interpersonal environments; Hung, Chou, Chen, and Own (2010) also found that students' communication self-efficacy is fostered by questioning, responding, commenting, and discussing. The association between social interaction and achievement may be due to the opportunities that students had to organize their thoughts during discussions; according to Biasutti (2017), online discussions afford students the opportunity to summarize and synthesize discussion topics by sharing ideas and perspectives with their peer students. Reflection facilitated through commenting is a key step for self-regulated learning in self-paced learning environments (Zhu, Zhang, Au, & Yates, 2020). Furthermore, exchanging ideas among themselves can help students explore different views of course topics as well as resolve conceptual conflicts in their minds (Chalkiti & Sigala, 2008). For video-based learning to facilitate interactive and engaging environments, it is important to provide passive learners with the opportunity to become involved in social activities (Honeychurch, Bozkurt, Singh, & Koutropoulos, 2017). Interventions do not necessarily require the design of new activities. For example, Mitrovic et al. (2017) proposed nudging strategies that can be used in video-based learning; for instance, using exemplary comments to encourage learners to make other good comments. Instructors' simple incentives for participation—such as offering bonus points—could work as well (e.g., Harbarth et al., 2018).

Information seeking can also be defined as an intellectual endeavor to meet learning goals. In self-paced learning environments, searching for information can refine students' understanding of a course topic and help them answer their own questions (Lee & Wu, 2013). When students engage in information seeking, they are required to clarify the target information they need based on the self-monitoring of their own progress. During searching activities, students must evaluate the relevance of the information they find and integrate that information (Tsai, Liang, Hou, & Tsai, 2012). In the present study, active learners exhibited high levels of involvement with environment configuration. Video panel configuration has not been a primary focus of research on educational settings; however, given the rapid growth of video-based learning, it is increasingly important to understand how learners interact with video players to optimize their learning environments. For example, Villena et al. (2014) demonstrated that learners tend to configure subtitles, volume, and screen size in order to study in an optimized learning environment that makes them feel comfortable. Such configuration behaviors indicate that learners' psychological needs resulting from isolated learning environments should be adjusted for optimized video-based learning (Sun, 2018). In the present study, students in the active learner group may have changed the video player settings to suit their needs for optimized learning. Learners are known to perceive an unoptimized video player setting (e.g., small screen, low volume) as an obstacle when watching videos for learning purposes (Villena et al., 2014). Our findings suggest that environment configuration is an important regulatory strategy, confirming Pintrich, Smith, Garcia, and McKeachie's (1993) claim that study environment management is a critical part of self-regulated learning.

In contrast, participants in this study's passive learner cluster—which only exhibited frequent browsing behaviors—had lower learning achievement than participants in the active learner cluster. While browsing requires learners' willingness to take actions during learning, it often does not lead to further reflection on a learning topic (Dodson et al., 2018). As found in this study, a mere glimpse of learning content does not help learners achieve learning outcomes. This finding is aligned with Chi and Wylie's (2014) assertion that passive learners absorb information from educational videos in a linear manner without participating in constructive and/or interactive activities involving peer interaction. Passive learners, therefore, are less likely to achieve expected learning outcomes. The characteristics of passive learners identified in this study are similar to those described in the abovementioned framework.

6. Conclusion
In conclusion, the present study's findings have some implications for future research. We have demonstrated how learning behavioral patterns can be constructed through a principal component analysis of log behavior. The study's identified components may be used for future research aimed at exploring learner behaviors in similar video-based learning environments. Furthermore, this study leveraged rich data including students' log actions, personal information, and achievement scores to investigate the characteristics of sub-groups of students participating in video-based learning. Since video-based learning is being increasingly adopted in a wide range of online learning contexts, our findings can inform the design and development of optimized video-based learning for both active and passive learners. Our discovery regarding the link between students' level of engagement and achievement provides clues in terms of the types of interactive elements that should be added to video-based learning platforms, as well as how students should be guided. In specific, we provided useful insights into the different characteristics of the active and passive learners beyond the level of engagement in general. For example, the passive learners may seem engaged in terms of browsing, but we may need to keep an eye on their social activity and information seeking for additional supports. The profiles of video learners identified in this study provided empirical evidence to enrich theoretical models including the ICAP framework. Our findings would also inform online educators of teaching strategies to provide differentiated guidance for learners of different profiles.

7. Limitations
Despite the present study's new insights, several limitations should be noted. First, this study was conducted in a controlled laboratory setting; thus, it is possible that this environment did not perfectly duplicate a real setting. For example, the one-time experiment might have not given participants enough time to become proficient in using all the interactive features. Future research should be conducted in a more natural environment allowing learners to use a player for a longer period of time. Second, participants' use of social features on the video player might have been influenced by other personal factors that were not included as a covariate, such as a preference for social interaction. Therefore, future research could explore more influential factors to broaden our understanding of learning mechanisms in video-based online learning environments. Third, the interactive player used in this study was designed to support real-time interactions between learners and instructors. However, we decided to turn off certain features and have participants view comments made by the researchers. Although our strategy was to ensure that all learners would be presented with the same comments, it was impossible for us to observe natural real-time interactions that would have been captured in a real setting. Future research would benefit from investigating real-time interaction patterns with different research questions. Fourth, we only used the frequencies of participants' comments to measure the degree of which they used the social features. Future research could employ a qualitative approach to analyze comments' contents, which would reveal the different sides of student learning in a learning environment. Fifth, our findings were elicited from a relatively small sample, and the generalizability of this study may be limited. We suggest that future research be conducted to determine whether similar classification patterns are observed with a larger sample. Finally, there was an uneven number of participants classified into the two clusters, which might have resulted in a bias in conducting the subsequent analyses such an ANCOVA, especially when the assumptions were not perfectly met (Skidmore & Thompson, 2013). As we also suggested to address the fifth limitation, future research would benefit from securing a larger sample to avoid analyzing data in favor of larger clusters (Scott & Symons, 1971). A large sample would also improve the generalizability of clustering results.

