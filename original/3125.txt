The purpose of this paper is to explore the expectations of academic staff to learning analytics services from an ideal as well as a realistic perspective. This mixed-method study focused on a cross-case analysis of staff from Higher Education Institutions from four European universities (Spain, Estonia, Netherlands, UK). While there are some differences between the countries as well as between ideal and predicted expectations, the overarching results indicate that academic staff sees learning analytics as a tool to understand the learning activities and possibility to provide feedback for the students and adapt the curriculum to meet learners' needs. However, one of the findings from the study across cases is the generally consistently low expectation and desire for academic staff to be obligated to act based on data that shows students being at risk of failing or under-performing.

Previous
Next 
Keywords
Learning analytics

Academic staff

Expectations

Higher education

Questionnaire

Focus groups

1. Introduction
During the last few years, we have witnessed the rise of Learning Analytics (hereafter LA). A field that is strongly influenced by many other fields such as psychology, educational science, and computer science, it is commonly defined as “the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimising learning and the environments in which it occurs” (Long, Siemens, Conole, & Gašević, 2011). It is expected that LA can improve the quality of teaching and learning, identify at-risk students and support evidence-driven teaching and learning processes i.e., informing decisions related to teaching and learning based on data about student characteristics, performance, and interactions with course material, peers, and the learning environment (Syed et al., 2019). Although the level of adoption of LA at the institutional level is low, many Higher Education Institutions (hereafter HEIs) are either in the preparation phase of implementing LA or in the process of piloting LA solutions to be adopted by the whole institution later on (Tsai & Gašević, 2017).

One of the potentials of LA is the possibility to provide feedback to students about their learning activities, progress and performance; and timely and accurate on-task feedback could be one of the means to support the development of self-regulation skills (Schumacher & Ifenthaler, 2018). Providing good feedback can be seen as any strategy or content that could enhance students' capacity to self-regulate their learning performance (Cavalcanti et al., 2020). However, giving efficient feedback to support students' self-regulated learning is a resource-demanding for the teachers (Cavalcanti et al., 2019). With learning environments becoming more and more distributed, i.e. moving out of the classroom, away from the teacher and moving into formal as well as informal online platforms, it can get quite difficult for teachers to assess the learning processes and to provide feedback to their learners on their own. LA, however, can play a role in helping teaching staff to scaffold students' capacity for self-regulated learning by providing information to teachers about how their students are progressing (Lodge, Panadero, Broadbent, & de Barba, 2019). Cazan (2013) has recommended that teachers contribute to their students' development of metacognitive activities and skills of adapting strategies for self-monitoring, making strategic use of feedback, as well as their metacognitive knowledge about academic work and task-specific strategies.

Despite the LA potential for the teaching staff to support students' feedback process and enhance their metacognitive abilities and through that also to improve their own instructional practice, first there is a need to address the gap in LA adoption. There has been a growing interest in LA's potential, Ferguson et al. (2016) has pointed that adoption of LA by organisations is not as systematic as expected. A recent literature review on the current landscape of LA in higher education by Viberg, Hatakka, Bälter, and Mavroudi (2018) showed that only 6% of the 252 publications included in the review fulfilled the proposition of ‘LA are taken up and used widely, including deployment at scale’. There have been different reasons for that, but one of the major concerns is related to the user involvement into the design process of LA services and practices to meet end users' expectations. Not addressing the voice of the students and teachers in the design process of LA solutions, could be one of the major implications in successful implementation of LA in the institutional and instructional practice (Alvarez, Martinez-Maldonado, & Shum, 2020). Buckingham Shum, Ferguson, and Martinez-Maldonado (2019) have suggested that the challenge to embed novel technology in authentic contexts is as much a human challenge (cognitive, social, organisational, political) as it is a technical challenge. The same concern is also pointed by Tsai and Gašević (2017), who have said that one of the reasons for low adoption of LA services in education is the limited involvement of relevant stakeholders and thus the lack of a common understanding. This could be detrimental to the efficacy of LA, as successful implementation of LA requires highly trained educators (Siemens, Dawson, & Lynch, 2013) and solutions that take their needs into account. According to Dollinger, Liu, Arthars, and Lodge (2019) the value of technology is not only in the functionalities and technical possibilities, but more in the meaningfulness of this technology to the people who use it. It's extremely challenging to develop the LA services that fit for teachers pedagogical purposes and meet the needs of the users for whom the tools are developed for.

To tackle this challenge, it is evident that users should be involved in the process of designing LA solutions and related practices to understand their pedagogical value. Teachers should be involved in that process as they are able to interpret the data and understand how to use it to improve the learning design (Alhadad, Thompson, Knight, Lewis, & Lodge, 2018). To ensure a successful implementation of LA on an institutional level, end-users should be involved in the process of designing LA services and practices and of shaping an organisational culture for LA. Although LA developments are not a new trend in higher education, there are still issues around the acceptance and implementation of LA and support among academics in HEIs (West et al., 2018). Issues that might potentially undermine the progress of LA include unclear goals for LA (Mor, Ferguson, & Wasson, 2015), unequal data literacy among academics (Corrin et al., 2016); lack of actionable data (Bennett, Agostinho, & Lockyer, 2015); and concerns of ethics and privacy (Ifenthaler & Tracey, 2016). Addressing these challenges before implementing LA and understanding academic expectations is crucial to better buy-in from end-users and better planning of resources required for LA.

Different approaches have been suggested to engage key stakeholders (West et al., 2018) (Prieto, Rodrguez-Triana, Martinez-Maldonado, Dimitriadis, & Gašević, 2018) and several works have looked into academic staff's expectations of and experience with LA solutions and how to involve staff in LA processes. Dollinger and Lodge (2018) have proposed co-creation of LA with educators as a way to address the mismatch between LA solutions and academic staff's needs in order to increase the adoption of LA in HEIs. Similarly, Chatti and Muslim (2019) have presented the concept of human-centered LA as a solution that emphasises the human factors in LA and the necessity to meet the user's needs, i.e. involving users in the design, deployment, and evaluation of LA is to be seen as a key requirement to serve the needs of different users in an effective way. Alvarez et al. (2020) have proposed a card-based co-design tool crafted to support inter-stakeholder design of LA innovations, which has shown initial promising results to give different stakeholders a voice in shaping the tools expected to use by students, teachers and other non-technical stakeholders.

West et al. (2018) surveyed Australian and Malaysian academic staff about their experience and needs with regard to LA, specifically focusing on their engagement in LA initiatives. The results of the study showed that academics would rather use LA to improve their teaching than to improve student retention. Another notable example of exploring teaching staff's perceptions of LA has been the study conducted by Howell, Roberts, Seaman, and Gibson (2018). Their findings showed that not only did teaching staff expect to provide benefits to student learning, but to also provide insights that could facilitate their teaching. Moreover, teaching staff would also like to offer early interventions to underperforming students and to know how LA services may affect their workloads. In light of these findings, it is clear that HEIs need to involve teaching staff in LA processes so as to effectively embed LA into teaching practices.

This paper seeks to contribute to the understanding of teaching staff expectations of LA services. We aim to identify the expectations of academic staff for LA services in HEIs in Europe by looking at four different countries. We explore academic staff's expectations on two levels: not only did we ask what they expected in general, but we also asked them to specifically distinguish between what they would ideally like to happen (i.e. desired ideal) and what they expect to happen in reality (i.e. predicted reality). Moreover, another aim of our study was to find out whether academic staff can be clustered based on their ideal expectations regarding future LA services. Such clustering would enable HEIs to plan further steps on how to support different types of staff in the implementation process, e.g. based on their hesitations towards LA, training needs or the challenges they have faced. More specifically, in our four-country cross-case analysis, the following research questions were investigated:

RQ1

What are the expectations of teaching staff regarding using LA services to support evidence-driven teaching and learning in higher education?

RQ1a

What are the differences between four countries regarding teaching staff expectations to the LA services?

RQ1b

What are the differences between teaching staff ideal and predicted expectations?

RQ2

What are the meaningful clusters of teaching staff based on the differences in their expectations of LA services?

2. Methodology
Methodologically we focused on a cross-case analysis between four different cases in Spain, Estonia, Netherlands and UK. These four countries represent the diversity of European HEIs as they are distant from the geographical and cultural point of view with different educational policies. However, these cases were representing institutions who were involved in the SHEILA project that - in a cross-European effort - gathered input from a wide range of sources and stakeholders in order to create a learning analytics policy framework. Furthermore, these countries have different educational policies. The Estonian case represents smaller European universities with less LA experience; the Spanish case represents large universities with some LA experiences; the Dutch case focuses more on distance learning where staff and students have been involved in some LA initiatives. Although the UK case represents those institutions that are rather experienced in LA with more sophisticated IT solutions to support LA, at the time of the research, the university was in an exploratory stage with some pilot studies, which provided interesting research grounds. Therefore we believe that all cases provided different approaches based on their experiences to understand the factors having impact to the adoption of LA services among HEI staff.

A mixed-methods approach combining quantitative and qualitative analyses was used to explore teaching staff's expectations of LA services at four European universities (Case1 = Spain; Case2 = Estonia; Case3 = Netherlands; Case4 = UK). The data were gathered using questionnaires and focus groups and involved a total number of 271 academic staff members (212 for the questionnaire and 59 for the focus groups).

2.1. Questionnaire
The questionnaire was based on the same conceptualisation as the Student Expectations of Learning Analytics Questionnaire (SELAQ) which included two scales each one measuring ideal expectations (i.e., what an individual hopes to receive) and predicted ones (i.e., what an individual expects to receive in reality) (Whitelock-Wainwright, Gasevic, Tejeiro, Tsai, & Bennett, 2019). The teaching staff expectation questionnaire contained 16 items (see Appendix A) that measured teaching staff's expectations of LA services. Both exploratory and confirmatory factor analyses were applied to validate the original instrument. From the original 22 items distributed in the UK, 16 passed scale purification tests (the process of eliminating items from multi-item scales) and were then translated and used in the three other countries, which means that our analysis is based on these 16 items. Original surveys in English were translated to Dutch, Estonian and Spanish. To increase the cultural and linguistic validity, pilot sessions were carried with a small number of groups out to map the concepts to the target culture by replacing some concepts to increase understanding in the local context. Responses to each item of the questionnaire were measured on two seven-point Likert scales (1 = Strongly Disagree, 7 = Strongly Agree), which corresponded to what teaching staff desired from a LA service (ideal expectations) and what teaching staff realistically expected from the LA service (predicted expectations). The questionnaire was made available online in the local language between April and October 2017. Invitations to participate were sent out via email. In the end, a total of 212 responses were received (Spain = 26, Estonia = 49, Netherlands = 56, UK = 81) with 51.4% of participants being female and 48.6% being male.

To group the items of the questionnaire, we first implemented factor analysis but did not receive a substantiated and all-inclusive model. We therefore divided the 16 items of the questionnaire into four groups based on the questions' main topic: goals of LA, teachers' needs for LA services, teachers' perceptions about students' needs to LA services, and challenges regarding implementation of LA services at HEIs. The results of the cross-case analysis are presented according to those themes. Throughout our analysis we considered the “ideal expectation” as the general expectation of academic staff. In the results, we compare the cases in terms of ideal expectations, differences between desired ideal and expected reality and differences between the four countries.

We used paired t-tests to compare the averages of the ideal and the predicted ratings for all questions of every case and of the combined data and also analysed the differences between the four countries with regards to ideal and predicted expectations to LA services by using multivariate analysis of variance (MANOVA). When the results of the MANOVA showed statistically significant differences between countries, we used ANOVA separately for each dependent variable to identify differences between countries.

We also used K-Means clustering with all the substantive variables of the questionnaire to determine distinct clusters of teachers based on expectation levels and used analysis of variance pairwise comparison test (ANOVA). In addition, we compared clusters based on demographic characteristics using a cross table and a chi-square χ2 test to check the statistical significance of differences.

2.2. Focus groups
We conducted focus groups mainly with teaching staff, but also in some of the cases program directors were included, because they have to work closely with instructors and personal tutors, so we consider their views important to include in our research. The aim of the focus groups was to gain more detailed insights into their expectations of LA. The focus groups were conducted in the local language and took place between May 2017 and September 2018. The total number of participants was 59 (Spain = 16, Estonia = 20, Netherlands = 5, UK = 18). The focus groups followed a semi-structured interview process and consisted of 2–6 participants, which included academic staff such as professors and lecturers, but also researchers involved in the teaching at their institution as well as participants with administrative responsibilities such as programme directors and personal tutors.

The focus groups were guided by the literature and ten overarching questions (see 6) were grouped into the following topics: purpose of LA, teaching needs, ethics and privacy, educational support, interventions based on LA, and concerns related to using students' educational data in teaching and learning. All focus groups lasted for 1–1.5 h approximately and were recorded and transcribed subsequently. NVivo was used to code the data. The coding scheme was first developed based on a literature study (Tsai & Gašević, 2017) and updated by the lead researcher based on the initial observation of the data (field notes and summaries of emerging themes of each interview). The research team (the lead researcher and 4 representatives of each case) then practice coding the same interview using the shared coding scheme, and meet up afterwards to clarify misunderstanding and resolve disagreement. This process iterated twice until the coding scheme was considered ‘saturate’ (no more new themes emerged). These researchers subsequently used the finalised coding scheme to analyse their focus group data independently. In this paper, we indicate each participant by “T” (teacher) and the case groups that they belong to. For example, C1T1 indicates Participant 1 from Case 1.

3. Results
3.1. Expectations for LA - a cross-case analysis
3.1.1. Goals of learning analytics
Based on the analysis of the questionnaire data (see Fig. 1; Due to space limitations as well as readability, tables with detailed analysis results are not presented here. They are, however, available in the appendices of this document. We thus refer to the appendices where necessary.), one of the goals of LA that staff sees, is the opportunity to better understand students' learning outcomes in their own course context. Slightly less important was the expectation that LA could be a tool to promote students' academic and professional skill development. Average score of responses to the two items were higher than the average in all cases (max = 7). Staff from Case1 had the highest ideal expectations regarding LA as a possibility to support students' learning. Staff from Case4 had the lowest expectations (ideal expectations) for the LA as a supporting mechanism for the students.

Fig. 1
Download : Download high-res image (322KB)
Download : Download full-size image
Fig. 1. Ideal and predicted expectations for items describing goals of LA per country and overall. Case1 SP, Case2 EST, Case3 NL, Case4 UK.

Regarding staff perceptions of using LA to better understand students' performance (see Table C.3 in Appendix C), the biggest gap between ideal and predicted expectations were observed in Case1 and Case3. Regarding staff perceptions of using the feedback from the LA service to promote students' academic and professional skill development, the biggest difference between ideal and predicted expectations were observed in Case3. The biggest overall difference between ideal and expected reality was observed in Case3 (with some experience of LA in distance learning), and the most positive in both ideal and predicted expectations were the academic staff members from Case2 (with nearly no experience in LA). This indicates that experience with LA innovations may have impacted staff perceptions what can be actually implemented in the field of LA.

The comparison between countries (see Table G.7, Table G.8 in Appendix G) revealed significant differences when considering expectations in both LA goals: promoting students' academic and professional skill development and staff understanding students' learning performance on the variables ideal and predicted expectations. Case2 and Case4 academic staff have significantly higher predicted expectations on LA possibilities to promote students' academic and professional skill development than Case3 academic staff - this result again supports that the experience with LA services may have an impact on understanding of the LA possibilities and limitations. To use LA to better understand students' learning performances were significantly lower in ideal expectations for Case4 and in predicted expectations for Case3 and Case4 academic staff.

The questionnaire results indicated that staff would ideally rather see LA being used to gain better understanding of learner performance, which was also confirmed by the focus groups. Focus groups illustrated that all four cases agreed that LA at the university should have the aim of supporting students' learning experience and sensemaking of the current situation and through that to aim to improve the teaching delivery and quality. For instance staff from Case1 emphasised that the aim of LA is to support both teaching and learning to understand the learning environment (C1T2: “LA improves both - students and teachers, right. We can see - what is working or what is not there and what we can improve.”). In Case4, it was emphasised that LA expands the possibilities to improve students' learning experience (C4T1: “For me LA should be about identifying opportunities for the learner.”), but also to understand what works at the course level (C4T3: “To look at the data is really useful for the development of the course because you can reflect on what works, what doesn't.”). Staff from Case2 thought that LA could enable the tackling of challenges around drop-out of students (C2T1: “LA could enable us - university - to notice earlier that something is not working and student is low-performing. However, the question is that who should take the responsibility - student or the university staff?”). Teachers from Case3 considered an important goal of LA to be the possibility to improve the quality of the education and educational experience for students (C3T3: “The university should be able to use that on a higher level to draw some conclusions on the quality of the study programmes.”), but also for the teachers to be aware of the students' progress and to get feedback about the course to improve their course design (C3T2: “So maybe we can see, okay, this question was really difficult for them, we have to provide more feedback prior to the exam.”).

3.1.2. Teachers' needs for LA services
Our cross-case analysis for this group of items (see Fig. 2) shows that academic staff perceived the biggest benefit of LA for them is the opportunity to support their professional development. Analysis also showed that staff consider open discussions for sharing experiences of using LA as important and participants from all cases seem to agree in this aspect. This result is important to plan the management level implementation of LA innovations. The efficacy of LA depends on the competency of academic staff in making meaningful interpretations of data thereby providing actionable feedback. However, we can see from Fig. 2 that teachers rated ideal and predicted expectations about their competence to give feedback to students differently. Finally, in terms of teachers' needs, the item about obligation to act on LA when students are identified as at risk, received the lowest average scores on both ideal and predicted expectations, which is certainly the indication for further implications.

Fig. 2
Download : Download high-res image (455KB)
Download : Download full-size image
Fig. 2. Ideal and predicted expectations for items describing teachers' needs for LA services per country and overall. Case1 SP, Case2 EST, Case3 NL, Case4 UK.

The comparison of the four cases (see Table D.4 in Appendix D and Table G.7, Table G.9 in Appendix G) revealed that using LA to support professional development (ideal) received the highest scores from the academic staff in Case3 (Netherlands). The Case3 academic staff had a significantly higher ideal expectation on LA opportunities for their professional development than the Case4 academic staff. However, the difference in Case3, between the ‘desired ideal’ and the ‘expected reality’ was the biggest. The academic staff in Case4 had the lowest expectations for professional development, and the results differ the least between what was seen as ideal and what was expected to happen in reality.

Regarding having open discussions about LA experiences, Case1 had notable differences between the desired ideal and real expectations and Case3 had the largest differences between ideal and predicted expectations. The academic staff from Case3 had the highest expectation that open discussions will take place in reality, but there was not a significant difference between countries on ideal and predicted expectations to open discussion.

The academic staff of Case1 and Case3 had the highest ideal expectations about their own competence to act based on LA data. Differences in evaluations for the desired ideal and the expected reality of the competency of academic staff were rather high between all the cases. Compared between the countries, there were some significant differences when jointly considering staff expectations in competences to act on the variables ideal and predicted expectations. In ideal expectations, Case3 had a significantly higher rating than Case2 and Case4 as well as Case1 than Case4. In predicted expectations, Case4 had a significantly lower expectation than Case1 and Case3.

Obligation to act (ideal expectation) received the highest average score from teachers in Case2 compared to the other three cases. There was a significant difference in ideal expectations on the obligation to act between Case4 and Case2 and teachers had significantly higher expectations on obligation to act. The difference between ideal and predicted expectations was the highest in Case3. Opposed to the other cases, the academic staff in Case4 rated the expected reality higher than the desired ideal. Case1 can also be highlighted as there was no significant difference between the wanted ideal and expected reality.

The focus group results indicated that the main expectation for the teaching staff across the cases was that LA could enable them to better understand what was happening in their courses. It was, however, also discussed what possible follow-up actions for such feedback might be and who should act on it. Such discussions enabled additional insight into why staff did not think teachers to be obligated to act based on LA data or why staff is hesitant about integrating LA data to feedback, as outlined below.

According to academic staff from Case1, LA provides insight into the profile of both learners and teachers and the learning and teaching practices. It was also pointed out by teachers from Case1 that it was sometimes not only important to understand how students progress to improve their own courses but also how they learn outside of the classroom (C1T3: “I would like to know which pages they visit and which documents they download [...] from the point of view of LA that's very important because there are students who learn with materials that they look for, from I do not know where, and that enables me to improve my course.”). Also, the Estonian teachers (Case2) found that LA was a good tool to support teachers who were interested in improving their learning practices (C2T2: “I want to get feedback from my students: how do they engage and what can I do to increase their engagement.”). For the teachers of Case3, LA was seen as a good way to inform their course design (C3T1: “I would mainly see this analytics as helping me with my task and not prescribing what I, or the student or the process, has to do. [...] I would like to be helped in understanding whether a course design is accurate or functions well.”). The same was confirmed by Case4: LA offers the possibilities to implement research-based approaches to understanding their teaching (C4T1: “LA enables to enhance the quality of teaching whether at an individual course level, within an individual institution, or at a community level.”). However, it was discussed by the focus group participants of Case4 that it would be useful if LA could be used for the measurement of learning (C4T3: “Can you determine for any particular student what is effective engagement, what's not effective engagement?”) though there was a concern that student data might be misused (C4T2: “When this data exists there's this temptation to use it for things that it was never intended for.”).

All four cases agreed that it is important to have an overview of the students' full profile, i.e. it would be better to see learner performance in the context of several courses (C2T3: “It might be that the student has some temporary difficulties, which have affected only my course [...] But if it has lasted longer and the student is underperforming in many classes - I would probably act differently.”). However, more lively discussion happened in all the three cases around the question who should act based on the data. Academic staff from Case1 proposed that acting based on the data was the role of the tutors, but staff would also like to be aware of that (C1T1: “For me it is important to understand if a student may have a problem.”). The academic staff from Case2 found that study program coordinators or study counselors could be the one who should act when a student was underperforming but it was also stressed that students should take the final responsibility. The same was mentioned by participants from Case4, although LA enabled earlier monitoring (C4T1: “But if there was some cleverness that could be done about saying, ‘this looks like, this student always leaves things to the last minute’, [...] it might be useful.”), students should do the main actions (C4T1: “It's up to them to get a degree. And I think if anyone, if anyone fails because they didn't study or they didn't apply themselves, that's their business.”). However, Case2 confirmed that although it was the students' responsibility, the university should not ignore the facts when the students were underperforming (C2T6: “Yes, students 18+ are responsible for their own learning, but university should take the responsibility to understand what is our role when students underperform.”). The teachers from Case3 stressed that the question of whether and how teachers act should depend on what had been agreed on with students but also among the teaching staff in case an LA systems flags up a student (C3T4: “It depends a little on what the message is and I think that it also really depends on what you agree on within a group about how to deal with that. [...] there are some rules and that different people then react differently to this. And that you shouldn't do [...] it is important to talk about this with the group: What are we doing with this?”).

3.1.3. Teachers' perceptions about students' needs to LA services
Our study results indicate that the academic staff saw the students as the main beneficiaries of LA services (see Fig. 3). Staff saw the potential of LA to give immediate feedback for students and plan interventions before it was too late. The academic staff also saw that LA could help support students in taking the responsibility of their learning. LA enhances the possibilities for the students to make decisions about their learning and get feedback on how they are progressing compared to their learning goals and course objectives. For this to be possible, the academic staff considered it important to have regular updates for the students based on the analysis of their educational data. Providing a complete learning profile of the student across courses (e.g., the number of access times to online materials, acquired learning outcomes, and class attendance) as a result of LA data was considered as less important by the staff as one possible students' need. Although the item regarding having the complete learning profile as the expected ideal future possibility was evaluated higher compared to the other items.

Fig. 3
Download : Download high-res image (410KB)
Download : Download full-size image
Fig. 3. Ideal and predicted expectations for items describing teachers' perceptions about students'needs for LA services per country and overall. Case1 SP, Case2 EST, Case3 NL, Case4 UK.

In all cases (see Table E.5 in Appendix E), there were significant differences between the desired ideal and expected reality in all questionnaire items, except for Case4. The perceptions of the academic staff in Case3 could be highlighted. There was the least variance of their opinions of the ideal and the predicted expectation - the staff seemed to have believed that while applying to LA at the university, immediate support and counseling for students would be provided. LA provided students with an overview of achieving their learning goals and helped the students to make decisions regarding their learning. The staff from Case2 were the least optimistic about the expected possibility that LA could provide a complete profile of their studies for the students. The academic staff of Case1 (Spain) had the highest ideal expectation of interventions' potential supporting students and the staff from Case4 had the lowest. The staff of Case1 had the highest ideal expectations for aspects related to students' regulation and the staff of Case4 had the lowest expectations in all three aspects.

The comparison of the countries (see Table G.7, Table G.10 in Appendix G) unveiled some significant differences when jointly considering the variables of ideal and predicted expectations in all items. In the item “LA allows students to make their own decisions”, the academic staff of Case4 had significantly lower predicted expectations than those of Case2 and Case3. Also, Case4 had significantly lower ideal expectations on showing students' learning progress compared to their goals than those of Case1 and Case3. The Case3 academic staff had significantly lower predicted expectations on possibilities of early interventions than those of the Case1 and Case2 academic staff. On ideal expectations about students getting regular updates about their learning progress, the Case4 academic staff had significantly lower expectations than those of the other cases. For LA possibilities to present students a complete profile, the academic staff of Case1 had significantly higher ideal expectations than those of Case4 and predicted expectations than those of Case2 and Case4.

The questionnaire results revealed that for supporting students, the main possibility of LA was to notice early on if a student was underperforming and to plan interventions accordingly. During the focus group interviews we did not identify a variety of the examples of how exactly LA could support students' learning experience. Although the academic staff who completed the questionnaire did not consider having a complete learning profile so important compared to other possibilities, such profiles were considerably discussed during the focus groups. However, it was stressed by the academic staff that it was important to understand the whole progress of the student.

Academic staff from all participating universities considered the students' accessibility to the learning progress during the studies as important. The Case1 academic staff suggested that LA could help them identify students' academic issues and plan future activities accordingly (C1T3: “It would be good to suggest relevant materials for the learners based on their interests and strengths.”). Additionally, the staff from Case2 expected that LA solutions would provide the students with immediate feedback and help them develop learning strategies (C2T6: “If student is getting feedback about the learning progress and suggestions how to proceed - it might actually help them to take some responsibility.”). Similarly, the teachers from Case4 saw possibilities for supporting students to take responsibility about their own learning, but from a different angle (C4T11: “As soon as [...] you start saying to a student ‘oh well you're not doing well enough educationally’, you're actually removing agency from them, okay. You're actually taking out their own responsibility for learning.”). The participants from Case3 believed that LA would improve the communication between students and academic staff but that there should always be a combination of LA usage and human contact between students and teachers (C3T2: “I think there should always be a balance between what you really experience, [...] or the learning analytics you see. That you don't base everything on the learning analytics, but also the contact you have with the students and the atmosphere for example.”; C3T3: “We should use learning analytics as one component of many others. So it should not be the only source of taking high stakes decisions for students.”).

3.1.4. Challenges regarding implementation of LA services at HEIs
Our analysis indicates (see Fig. 4) that staff perceives that data accuracy and understandability were the most important possible challenges for implementing LA (ideal expectation). The second biggest challenge was related to the access to students' data which also touched on ethical and privacy aspects. In our study, the staff evaluated it more important to have an overview about students' progress in their own course context than accessing students' data in general. However, as discussed before, it was shown that the academic staff did not consider themselves obligated to act based on LA data, which raised the question of why staff considered it important to have access to students' progress. The academic staff also considered guidance and support from the university how to access and use LA data as an important element.

Fig. 4
Download : Download high-res image (708KB)
Download : Download full-size image
Fig. 4. Ideal and predicted expectations for items describing challenges of implementing LA services per country and overall. Case1 SP, Case2 EST, Case3 NL, Case4 UK.

The academic staff of Case3 and Case1 had especially high ideal expectations for data accuracy (see Table F.6 in Appendix F). The Case2 academic staff evaluated the importance of data accuracy the lowest. The academic staff in all cases reported the desired ideal and expected reality for data accuracy considerably different, whereas academic staff from the Netherlands (Case3) were the most sceptical and staff from Estonia (Case2) were the most optimistic in terms of differences between idea and predicted expectations. It can be explained that in the countries where LA implementations and experiences with data have been rather modest (e.g. in Estonia), it is difficult to predict that data accuracy could be a challenge.

The academic staff of Case3 had the highest ideal expectation that the university provided instructions for the staff about how to use LA, which can be also explained with the current lack of experience. The staff of Case1 and the staff of Case4 indicated that their expectations regarding guidance would become reality. The staff from Case2 and Case4 evaluated it more important to have access to students' overview about their progress in a specific course context.

The comparison of the countries (see Table G.7, Table G.11 in Appendix GG) did not reveal significant differences on expectations about guidance on how to use LA and access to student progress. On ideal expectations to access students data, the academic staff of Case3 had significantly higher expectations than those of the staff from Case4. The expectations on data understandability for academic staff of Case4 were significantly lower than those of Case3 in ideal and Case1 in predicted expectations.

The academic staff participating in the focus groups also saw a number of obstacles and challenges in implementing LA. The challenges discussed there were broader than those addressed in the questionnaire. One of the challenges was related to the mindset and culture, which was pointed out by teachers from Case2 (C2T2: “It's important to address the question ‘why’ already in the implementation phase. Now actually no one cares if I check LA data, improve anything, but in case we decide that our university will implement LA systematically, we should work with staff mindset and organisational culture related with evidence-informed teaching.”). This aspect was also related to the culture of taking feedback as a way forward, which was relevant for both students and staff. The participants from Case4 mentioned similar issues (C4T1: “You could provide a system to students that tells them you need to engage more or you need to start going to classes or you need to do all of these things. And my question is what will they, what will they do with that information? Will they do anything with it?”). Making data available is thus just the first step, but the actions beyond that as well as the mindset need even more work.

Although the goals of implementing LA were discussed significantly during the focus groups, all cases pointed out that using LA data could be harmful if not done right. The teachers from Case3 worried about the legitimacy of using students' personal data for LA (C3T3: “I think for the system data you could apply a wide range of purposes. For the really personal data like behavioural data, or data about movement or anything like that, I would say there must be a direct benefit for the individual student otherwise it is not legitimate to use this data and of course it is only possible with consent.”). The participants from Case4 were worried whether the LA data can actually be matched to students' learning (C4T4: “It's what you can't really tell about their learning, that's something that happens in the brain, in their mind. And I would be very cautious about casually equating behaviour and performance with learning.”). The teachers from Case4 were also worried about the purposes of using LA data from a staff perspective (C4T2: “My concern is that this is going to be used to compare staff across, either across school or worse across different schools”; C4T1: “Data could be used against the people.”). It was emphasised that universities should invest in training on how to interpret LA data assuming that data was understandable and easy to interpret (C2T5: “Trainings for staff are very needed from the grassroot: why we are doing and how we are doing it, what is not ethical to do, what we must certainly not to do with data, what does visualisations tell us etc.”). It was expected that strategic decisions about the use of LA should be made at university level and that balance and objectivity should be ensured when using data.

3.2. Clusters of the academic staff
One aim of our study was to also find out whether academic staff can be clustered based on their ideal expectations regarding ideal future LA services. Such clustering would enable HEIs to plan further steps on how to support different types of staff in the implementation process, e.g. based on their hesitations towards LA or the challenges they already faced. We applied a fixed three-cluster model to the questionnaire data in which the clusters had to be statistically significantly different enough in terms of the ratings for the sixteen items that formed the basis of all clusters. We chose the three cluster solution in order to distinguish clusters with high ratings, medium ratings and low ratings (see Table 1).


Table 1. Clusters of academic staff based on ideal expectations.

Variables of clustering	I cluster n = 94 (44.34%) Enthusiasts	II cluster n = 89 (41.98%) Positive thinkers	III cluster n = 29 (13.68%) Sceptics	F	p
M	SD	M	SD	M	SD		
Goals of learning analytics
Promote students' academic and professional skill development	5.67	1.339	4.56	1.314	3.66	1.518	30.185	0.000
Understand students' learning performance	6.20	0.875	5.19	1.176	3.34	1.798	68.871	0.000

Teachers' needs for LA services
Professional development	6.19	1.008	5.61	1.258	3.83	1.671	41.503	0.000
Open discussions	5.89⁎	0.978	5.67⁎	1.156	4.17	1.627	25.118	0.000
Analytics into feedback and support	6.40	0.723	5.17	1.308	3.41	1.524	84.162	0.000
Obligation to act	5.67	1.282	3.30	1.488	2.45	1.526	92.016	0.000

Teachers' perceptions about students' needs for LA services
Student decision making	5.85	1.278	5.35	1.262	3.79	1.398	28.282	0.000
Early interventions	6.33	0.795	5.37	1.247	3.17	1.560	88.504	0.000
Regular updates about learning progress	6.36	0.746	4.88	1.260	3.45	1.526	90.045	0.000
Learning goals	6.27	0.857	4.96	1.331	3.62	1.265	69.719	0.000
Complete profile	6.04	1.015	4.78	1.286	3.41	1.500	60.014	0.000

Challenges
Analytics guidance	6.35	0.991	5.61	1.411	4.03	1.842	34.956	0.000
Access to student progress	6.60	0.693	5.85	1.134	4.59	1.524	43.722	0.000
Access student data	5.90	1.503	4.33⁎⁎	1.795	3.97⁎⁎	1.322	28.544	0.000
Accurate data	6.52	0.786	6.03	1.016	4.17	1.513	60.243	0.000
Understandable data and feedback	6.67	0.537	5.97	1.092	4.28	1.750	61.536	0.000
There are significant differences between the mean rating of each item for each pair of clusters except where marked otherwise.

⁎
Significant differences only with cluster III.

⁎⁎
Significant differences only with cluster I.

The biggest cluster contained 44.34% of the academic staff involved in the questionnaire. Their expectations for LA were the highest across all items (mean values between 5.67 and 6.67). This group of staff highly appreciated access to LA about students' progress; that LA was regularly updated, accurate and clear; that the university provided support to teaching staff in understanding and implementing LA; and that LA could ensure that students would get immediate support should difficulties or problems arise. In addition, academic staff in the first cluster evaluated LA as an opportunity to support students in making decisions and developing their academic and professional skills. Also, the need for open discussion on LA and the obligation for teaching staff to act promptly on the basis of LA (student counseling, tutoring) could be highlighted as evaluated slightly less important. As the ratings of the academic staff in this cluster were very high for all items compared to academic staff in other clusters, they could be identified as teachers who see a great potential in LA to support both learning and teaching. They are ‘enthusiasts’ of LA.

In the medium-ratings cluster, there were 41.98% of the academic staff involved in the questionnaire. Their average ratings ranged from 3.30 to 6.03. The academic staff in this cluster deemed it very important that LA should be based on accurate data and that the data and LA need to be easy to understand. In order to implement LA, the academic staff in this cluster would like to receive training and guidance on how to interpret LA and were in favour of sharing best practices. They also appreciated opportunities to use LA in their professional development. For them it seemed to be less important to keep students informed about their progress and to construct their complete study profiles nor did they believe that feedback from LA supported the development of students' academic and professional skills. The lowest rated item was the obligation of the lecturer to act when LA identified students at risk of failure (for example, to support students). As discussed in the previous section, the teachers were interested in having an overview about students' progress, but the students were the ones who were assumed mainly to take the responsibility about their own learning, not the academic staff. Overall, the teachers in this group could be classified as ‘positive thinkers’.

The smallest cluster (13.68%) was made up of academic staff who did not see the benefits of LA to support learning and teaching. The means of their ratings range from 2.45 to 4.59 across all items. Specifically, for several of the items their average rating was below the scales' middle value of 3.5: they did not see that LA could help them better understand learners' learning outcomes and did not consider LA as an input for counseling and providing feedback of students. Thus, it was also not important for them to have a complete overview of the progress of students' studies and to have regular updates. The academic staff belonging to the third cluster also provided low ratings for LA being an opportunity for identifying students at risk and for taking actions on the basis of LA. These teachers were considered the ‘sceptics’.

With the clusters identified, we compared them based on socio-demographic characteristics (gender, pedagogical work experience, country). With regards to gender and pedagogical work experience, no statistically significant differences could be detected. However, statistical differences were present when looking at the different countries (see Table 2): The ‘enthusiasts’ cluster was mostly made up of the academic staff from Case1 (Spain) and Case3 (Netherlands), while the ‘sceptics’ cluster mainly contains academic staff from Case2 (Estonia) and Case4 (UK). It is important to note that none of the staff from Case1 and only very few from Case3 were in the ‘sceptics’ cluster (p = 0.03).


Table 2. Comparison of clusters based on country.

Clusters	Total	χ2	Sig. (2-tailed)
Cluster I	Cluster II	Cluster III			
Case 1 SP	Count	15	11	0	26		
% within Country	57.70%	42.30%	0.00%	100.00%
% within Cluster	16.00%	12.40%	0.00%	12.30%
Case 2 EST	Count	22	18	9	49
% within Country	44.90%	36.70%	18.40%	100.00%
% within Cluster	23.40%	20.20%	31.00%	23.10%
Case 3 NDL	Count	32	21	3	56	18.102	0.030
% within Country	57.10%	37.50%	5.40%	100.00%		
% within Cluster	34.00%	23.60%	10.30%	26.40%
Case 4 UK	Count	25	39	17	81
% within Country	30.90%	48.10%	21.00%	100.00%
% within Cluster	26.60%	43.80%	58.60%	38.20%
Total	Count	94	89	29	212
% within Country	44.30%	42.00%	13.70%	100.00%
% within Cluster	100.00%	100.00%	100.00%	100.00%
The clusters we identified were rather obvious and confirm that engaging stakeholders is complex, because people have different perceptions, expectations and experiences. Our results firstly systematize this problem that has been often reported: we received an estimate of how large the size of these groups are, how exactly the expectations differ between them, and how the situation is different in different institutions. Secondly, our results allow us to devise strategies for LA implementation by considering the LA implementation as a process of adopting innovations. This requires us to engage different groups differently. Applying some model of innovation adoption could help to support different stakeholders in the implementation process - e.g. the Knowledge Appropriation Model proposed by Ley et al. (2019) to co-create meaningful practices for LA innovations. Adoption of the LA innovations could be planned in different phases in the institutions by involving different groups of teachers with different strategies - first, enthusiasts are engaged, next the activities are planned for the teachers in the middle group and finally sceptics are addressed in co-creation activities. The group of enthusiasts could be used as a catalyst and experts for the institutions to move forward LA innovation, but who are speaking the same language with the other staff. Teachers in this group could be the first to pilot novel LA solutions and could also be used to promote LA among other teachers and stakeholders.

4. Discussion and conclusion
With our study we aimed to identify the expectations of teaching staff regarding using LA services to support teaching and learning in higher education, which were collected via the focus groups and the questionnaire. The results of our study showed that staff perceived that the greatest potential for LA is to enable early intervention as soon as possible if the analysis of a student's educational data suggested they could have some difficulty or problem. In addition, the academic staff believed that LA supports students' decision-making and to give feedback about their learning progress, which has been also acknowledged in earlier studies as one of the potential of LA (e.g. (Cavalcanti et al., 2020)). The teaching staff found that it was important to have open discussions about LA when using it in their teaching practice. This can be interpreted as the prerequisite for the successful implementation of LA is sufficient communication (Colvin et al., 2016).

With regards to RQ1a about the differences between four countries regarding teaching staff expectations to the LA services, we learned that although academic staff perceived a great potential of LA in supporting learning and teaching, they were not so convinced that all their ideal expectations would get realized. There were significant differences between ideal and predicted expectations for academic staff from all countries for many of the items. The academic staff from the UK had high predicted expectations that the university should provide guidance on how to access data related to their students and that LA services provide students with regular updates about their learning progress. Also, the Spanish teaching staff showed no difference between ideal and predicted expectations with regards to the obligation to act, whereas the other countries did. However, one of the most interesting findings from the questionnaire data across all cases was the generally consistently low expectation and desire for academic staff to be obligated to act based on data that shows students being at risk of failing or under-performing. Similarly, a study by Prinsloo and Slade (2017) indicated that although LA enables different stakeholders to know more about students, it does not necessarily result in action. They propose that although students and institutions should have a co-responsibility, institutions have a moral and legal obligation to act, i.e. to involve, inform and enable students to take the necessary steps to mitigating the risks. We found that academic staff did not necessarily perceive it as their role to support students, rather they thought that students should take the responsibility for their own learning and if problems arise, the responsibility to provide support lays with the university. This might indicate that although the academic staff understood the value and benefits of LA for the students and for their own practice, in reality they did not see it as a big part of their teaching practice. The findings of the current work are similar to those presented by (Howell et al., 2018) in that they show that teaching staff expect LA services to not undermine student independence, to receive detailed insights into their students' learning, and for such services to not unnecessarily increase workloads.

The results related to the question about differences between teaching staff ideal and predicted expectations, showed that there were some significant differences when considering staff expectations jointly on the variables about ideal and predicted expectations. Our results indicated that the highest ideal and predicted expectations of LA for supporting students' learning was perceived by the academic staff from Spain. As mentioned earlier, in the case of Spain, LA implementations were rather rare, which means that staff may not have enough experience to assess the realization potential of their ideal expectations. Technical issues of LA were considered to be most important in ideal and predicted by the academic staff of the Netherlands, but they also saw opportunities for LA to improve teaching. As the Netherlands represented the case of more experienced in distance learning and experiences with LA innovations, it makes sense that in the distance learning situation, technical aspects become more evident. The lowest ideal and predicted expectations for LA in all areas came from the UK academic staff, where perhaps a higher proportion of staff members have experienced LA, and thus have a better knowledge of its potential challenges and risks (e.g., ethics & privacy issues, etc.).

With the questionnaire results we also aimed to identify clusters of teaching staff based on the differences in their expectations of LA services. Unsurprisingly, it was possible to distinguish three distinct clusters, i.e. ‘enthusiasts', ‘positive thinkers', and ‘sceptics'. Our results showed that more than 85% of teachers were ‘enthusiasts' or ‘positive thinkers and only around 13% were sceptical towards LA. We deem this an important and promising result as this information could help universities to better plan and adapt the implementation of LA innovations based on the different experiences, expectations, training needs and hesitations of the staff. Therefore we see that although the academic staff from all four cases were generally optimistic about LA and its impact on students learning, LA implementation could be seen as any other innovation adoption process where meaningful practices, dialogue and ownership should be established.

We are aware that the four cases of our study do not represent their country as a whole. Also, our results most likely only represent the attitudes of those teaching staff that were interested in LA as the low proportion of ‘sceptics' suggests that the study did not attract the participation of those teachers for whom the topic of our study was complex or irrelevant. These obtained findings, however, are important for higher education institutions as they highlight the expectations that teaching staff hold towards LA services.

In the future, we can see several possible research directions for our study. Our study confirmed that LA cannot be operated in a one-size-fits-all manner (Tsai et al., 2018), because it is not consistent across different locales and even further, we identified that even in one organisation, academic staff should be engaged differently based on their experiences and expectations. We suggest the following recommendations for the future.

First, we identified statistically significant differences in teaching staff ideal and predicted expectations for the LA services - staff seems to see the potential, but there are some hesitations about what can be actually realized. We suggest that it is important to investigate further those hesitations - is it related with the experiences with current LA applications, teachers' skills, beliefs etc. It is important to point out that we did not explicitly take earlier experience of academic staff with LA into account, but in the future this could provide an opportunity to assess whether ideal and predicted expectations are related to experience gained or lack of knowledge of the possibilities of LA innovations and design the interventions accordingly.

Second, we identified three clusters of staff based on their expectations for the LA services. We also identified that despite what the potential staff sees in LA, their own role in acting based on LA data and supporting students' learning, was perceived less relevant. Based on that, we recommend to plan the implementation of LA innovations as any other innovation adoption process in the organisation, which could be systematically supported by co-creation practices. Such co-creation practices could give a voice for the end users in shaping the tools and practices they expect to adapt, but also, teachers should create practices and pilot them in their own instruction to understand the benefit for their own teaching and through that also to students' learning. This approach would increase the understanding of the meaningfulness of the LA innovations to the people using them, as also stated by Dollinger et al. (2019). Building such ownership is not easy and therefore, LA enthusiasts could be involved in the co-creation practices as experienced colleagues who could help to address the hesitations of colleagues. Planning of the training and interventions in different groups should be planned differently for different groups. Implementation of innovation adoption model (e.g. Ley et al. (2019)) in the LA innovation adoption process could be seen as an important future direction of our research. Third, management level strategies and policy formulations are needed to engage the staff. Efficient leadership practices support creating the dialogue and proposing meaningful change. Addition to that, communicating the messages about the change based on continuous monitoring and sensemaking of the LA initiatives, could also help the academic staff to better understand what is the potential impact of LA and what can be realized.
