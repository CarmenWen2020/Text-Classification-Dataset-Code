This article presents a model for designing e-assessment processes aligned with competences and learning activities. The authors examined assessment in student-centered, competence-based learning in online contexts. We analyzed the importance of alignment for properly selecting the learning activities that best guide students towards the desired level of competence acquisition (i.e. learning outcomes). We explored the leading types of assessment and new opportunities for assessment derived from the use of technologies. The model developed takes advantage of the potential for technologies to go beyond traditional assessment approaches and proposes a classification of e-assessment activities organized by competences. When the model was applied in a real online course, results suggested it can help teachers and students better understand the meaning of competence-based learning and how the formative assessment approach is useful for helping students attain the desired competence levels.

Previous
Next 
Keywords
Alignment

Competences

E-assessment

Learning activities

Model

Online higher education

1. Introduction
In recent decades there have been great changes in the structure, function and funding of higher education, which have resulted in an increase in student diversity. This new context has highlighted the failure of traditional approaches to university teaching and boosted student-centered teaching methods (Biggs & Tang, 2011). In relation to this, 1999 saw jointly coordinated educational reform among European countries (the Bologna process) to increase internationalization and assure the quality of higher education systems. This process resulted in the creation of the European Higher Education Area (EHEA) in 2010. The EHEA has helped to bring the two core premises of the Bologna process to the fore: student-centered learning and competence-based curriculum (European Ministers of Higher Education, 2012).

Teaching at European universities has evolved from a teacher-centered approach – involving teaching objectives – towards a student-centered approach focused on students' learning outcomes (Gil-Jaurena & Kucina Softic, 2016). Consequently, the role of students has changed from passive (content-based approach) to active (learning-centered approach). The differences between the teacher-centered and the student-centered paradigms have been investigated extensively (Bennett, Davis, & Weddel, 2010; Hannafin, Hill, & Land, 1997; Slunt & Giancarlo, 2004). In essence, in the teacher-centered paradigm, instructors define courses based on the actions they have to perform and are responsible for all decisions regarding the course (Armstrong, 2012). In the student-centered paradigm, instructors concentrate less on what they know and more on student learning (Gunderman, Williamson, Frank, Heitkamp, & Kipfer, 2003). Teachers have shifted from instructors to facilitators, while students have moved from listeners to active participants (Barman, 2013; Baxter & Gray, 2001; Freire, 2010).

Several attempts have been made to define student-centered learning (SCL) (Cannon & Newble, 2000; Freire, 2010; Gibbs, 1992; Hooks, 2010; McCombs & Whisler, 1997; Tsegay, 2015; Zabit, 2010). SCL refers to “student responsibility and activity in learning” (Cannon & Newble, 2000:16) which results in “greater autonomy and control over choice of subject matter, learning methods and pace of study” (Gibbs, 1992:23). This approach to learning is apparently beneficial both for students (motivation, peer communication, student-teacher relationships, active learning) and for teachers (evolution of the teacher's role, response to large class sizes) (Barman, 2013; ESU, 2010a).

Research over the past fifteen years has explored the translation of this theoretical paradigm into practice in higher education (e.g. Edwards & Thatcher, 2004; Kinchin, De-Leij, & Hay, 2005; Livingstone & Lynch, 2000; Montgomery, 2008; Rust, 2002). Findings demonstrated that SCL poses many challenges when it comes to creating the desired atmosphere and students still play a passive role, either because of teachers' continued dominance, or students' resistance or insecurity (Estes, 2004; Farrington, 1991; Fishman et al., 2013; Freire, 2010; Lea, Stephenson, & Troy, 2003; Liu, Qiao, & Liu, 2006; Lizzio & Wilson, 2005; Lu, 2012). In contrast, a recent study conducted by Tsegay (2015) showed that some teaching methods, including learning by doing, lead to less dominant attitudes from teachers and an effective implementation of SCL.

The literature suggests that successful implementation of SCL requires changes in the function of content, the role of the instructor, the responsibility for learning, the personalization of learning, the processes and purposes of assessment, and the balance of power (ESU, 2015; Weimer, 2002). In online courses, this means establishing positive interpersonal relationships, facilitating the learning process, adapting to the individual, social and class learning needs, and encouraging students to take on responsibility and personal challenges (McCombs, 2015). These considerations regarding the need to improve SCL show that plenty of effort is still required to design courses that truly put students at the center of the learning process.

Perhaps not surprisingly, similar difficulties have been encountered when implementing another core premise of the Bologna process: competence-based curriculum (CBC) (Wesselink, Dekker-Groen, Biemans, & Mulder, 2010). Much of the research on CBC warned of the ambiguity of the concept and the difficulties for putting it into practice (Kafyulilo, Rugambuka, & Moses, 2013; Mulder, Gulikers, Biemans, & Wesselink, 2009; Struyven & De Meyst, 2010; Wesselink et al., 2010; Yanhua & Watson, 2011). Theoretically, CBC is characterized by competences (instead of objectives), outcomes (instead of content), learner-centered teaching activities (instead of teacher-centered), and formative assessment (Sudsomboon, 2008).

SCL is a fundamental concept in CBC. (Gervais, 2016; Le, Wolfe, & Steinberg, 2014). As Wagenaar (2007,11) said, “the use of the concept of learning outcomes and competences requires study programmes and its course units or modules to be student-centered/output oriented”. Indeed, SCL is perceived as “more suitable than traditional forms of education when it comes to the development and acquisition of generic competences” (ESU, 2010b:38). Therefore, organizing the curriculum by competences entails recognizing that different students learn at a different pace and have different needs, interests, experiences and knowledge (ESU, 2015). For instruction, this requires paying attention to each student's ability, learning style and learning pace (Gervais, 2016) – in other words, centering instruction and assessment on the student rather than the group.

CBC requires certain steps to place the student at the center of curricular design. First, the competences that students will acquire through the learning activities need to be established. This involves describing the competence, defining a means for measuring or assessing the competence, and a standard to judge competences (Barman & Konwar, 2011). Second, the course needs to be organized in terms of the learning outcomes that students will acquire rather than in terms of the contents that the teacher will provide. Third, active learning methodologies and activities that involve students in the learning process need to be promoted. Fourth, assessment needs to be designed not simply to see whether students can reproduce any given content but whether they can demonstrate their command of the subject.

Competence-based assessment requires focusing on the evolution of each student's abilities, measuring their performance and providing individual feedback to help them progress with their learning process. Research has demonstrated that orientating learning towards competences and learning outcomes makes assessment more transparent for students and aids quality assurance and course design. Nevertheless, it represents a challenge for teachers in its application (ESU, 2015).

A recognized solution for effective implementation of CBC involves “alignment” – what the teacher does with the learning activities to help students achieve the learning outcomes (Anderson & Krathwohl, 2001; Biggs & Tang, 2007; Boud & Falchikov, 2006; Gil-Jaurena & Kucina Softic, 2016; Koenen, Dochy, & Berghmans, 2015). Over the last decade, the idea of alignment has been widely advocated in educational research to strengthen the relationships between different areas of course design: competences, learning outcomes, objectives, learning activities, teaching approaches, assessment/tasks/criteria, and resources (Biggs & Tang, 2011; Kouwenhoven, 2009; Morcke, Dornan, & Eika, 2013; O'Farrell, 2009). A recent study demonstrated the utility of alignment for increasing both the effectiveness of teaching methods and student engagement (Al Husban, Al Husban, & Al Betawi, 2016).

Alignment may be even more relevant and fruitful in online education (Lawrence & Snyder, 2009; Raeburn, Muldoon, & Bookallil, 2009), where students learn autonomously. It can help guarantee that courses are student-centered and competence-oriented, and students are informed about the actions they need to carry out to achieve their goals. Unfortunately, while researchers stress the benefits of alignment in course design, it is unclear how this procedure is put into practice. Many studies have shown that curriculum alignment can be very challenging for teachers who lack expertise in assessment design and advanced pedagogy; this explains why there can be difficulties understanding and developing these kinds of processes (Dilmore, Moore, & Bjork, 2013; Ebert-May et al., 2011; Holt, Young, Keetch, Larsen, & Mollner, 2015; Kennedy, Hyland, & Ryan, 2012; O'Neill, Birol, & Pollock, 2010).

This literature review's discussion of the challenges regarding implementation of SCL and CBC highlights the need for guidelines for online course design, to enable true adaptation to the student-centered and competence-based learning advocated by the EHEA. This paper describes a model for aligning assessment with competences and learning activities in online course design. The model proposes a prototypical assessment design process in which teachers select and create the most appropriate e-assessment activities for the previously defined competences and the desired learning outcomes. These elements are combined coherently with assessment criteria, indicators and feedback, and defined by the preferred type of assessment.

A range of approaches to competences, learning activities and assessment will be discussed in the following sections. Section 2 gives a brief overview of the relationship between teaching goals, competences and learning outcomes. Section 3 examines the learning activity concept and various classifications of e-assessment activities. Section 4 summarizes different types of assessment and analyzes the impact of online technologies on assessment practices. Section 5 presents a model for aligning assessment with competences and learning activities in online scenarios, including a classification of e-assessment activities. The final section puts forward a number of conclusions.

2. The relationship between goals, competences and learning outcomes
Traditional modes of assessment mainly focus on learning products instead of learning processes and do not fit the needs of current job demands in which individuals need to be able to apply their knowledge. The EHEA promotes competence-based learning with the aim of better responding to job market demands. Instead of simply paying attention to content, current graduates are trained to be reflective practitioners and to develop higher order thinking (Myyry & Joutsenvirta, 2015).

To understand the concept of competence and to redefine the learning process based on competences has been – and still is – a challenge in higher education. “Competence” means “the proven ability to use knowledge, skills and personal, social and/or methodological abilities in work or study situations and professional and/or personal development” (European Commission, 2008, para.1). It represents a combination of attributes relating to knowledge and its application, attitudes, skills, and responsibilities, and it describes the degree of capability for performing them (González & Wagenaar, 2003). Two types of competences can be distinguished: generic (at bachelor's degree level) and specific (at course level). Generic competences are those that many different bachelor's degrees can have in common (e.g. the ability to communicate in a second language, the ability to plan and manage time). Specific competences, on the other hand, are those that are unique to each field (e.g. in Mathematics, the ability to comprehend problems and abstract their essentials; in Earth Sciences, the capacity for observing and understanding the environment).

The level of competence attained by the student and verified by assessment is the “learning outcome”. They are statements of what students are supposed to know, understand and/or be able to do on completion of a learning process (European Commission, 2015; González and Wagenaar, 2003, González and Wagenaar, 2005). They are set by academic staff and are student-centered, achievement-oriented, and measurable (i.e. they need to be verifiable). Competence-based education can be considered an example of outcome-based education (Biggs & Tang, 2007). The distinction between competences, learning outcomes, and goals can lead to confusion. For the purpose of this paper, goals are conceived from the teachers' perspective and express what teachers expect to teach (e.g. content, approach, purpose); competences are the abilities to use knowledge, skills, attitudes and responsibilities in academic or professional contexts; and learning outcomes are the level of competence acquired by students.

At present, curriculum design at European universities is oriented less towards teachers' goals and more towards students' learning outcomes through the development of competences. Consequently, teachers are encouraged to design authentic tasks and align assessment with the development of competences to better guide students towards achieving the learning goals (Avargil, Herscovitz, & Dori, 2012; Calenda & Tammaro, 2015). For online universities, the demonstration of competences, especially with regard to procedural (Anderson & Krathwohl, 2001) and strategic knowledge (Muldoon & Lee, 2007), may be more challenging (Admiraal et al., 2014; Fitó-Bertran, Hernández-Lara, & Serradell-López, 2014; Molinari, 2013). Therefore, it is critical, when designing the assessment process, to select the most appropriate types of assessment and the most suitable learning activities so that students can develop the competences and fulfil the desired learning outcomes. Universities need to go beyond the common traditional practices and demonstrate how technologies can enhance the assessment process.

3. Selecting learning activities in line with competences
3.1. Defining learning activities
In the current educational paradigm, even the concept of “learning activity” has evolved. Learning activities are no longer simply ‘teacher-guided instructional tasks’; learning activities now have a stronger relation to students' performance (Wandberg & Rohwer, 2010). By way of illustration, Penzo et al. (2010) considered learning activities to be a tool to acquire knowledge and to acquire it in a functional and applied manner. Likewise, Goñi (2005) defined activities as the work that a student performs to develop a learning process. This performance is increasingly linked to the acquisition of skills. For example, the European Commission (2006, 9) described learning activities as “any activities of an individual organized with the intention to improve his/her knowledge, skills and competence”.

The boom in online technologies use in the educational sector has also affected the meaning of “learning activity”. A generic view of learning activities supported by online technologies is given by Cabero and Román (2006:25) who defined them as “diverse actions that students do with the contents and information that have been offered to them. If these activities are presented, carried out or delivered through the net, thus, they can be considered as e-activities.” From a course design perspective, Melton (2002) argued that learning activities in virtual training should be designed to help students monitor their progress, check their understanding, develop specific skills, apply what they have learned in real-world situations, and reflect on what they have done. Delgadillo (2012) stated that learning activities are experiences that bring students' prior knowledge into play, and that they need to be well-planned and take into account the feasibility of the technological tools available and the time required to complete them. Presumably, any assessed learning activity can be converted into a digital format, even if not all types of assessment are valid for all learning outcomes (Gil-Jaurena & Kucina Softic, 2016). From our point of view, learning activities must be designed to fit the characteristics of online learning and be pedagogically consistent with the types of assessment.

Traditionally, the term “e-assessment activity” has been used to designate those activities that use online technologies (Crisp, 2010; JISC, 2007). In this paper, e-assessment activities are defined as intentional and organized sets of actions designed for online learning situations. In these situations, students actively and dynamically build knowledge and perform and demonstrate the acquisition of competences through their use of digital media. E-assessment activities can be designed for grading or non-grading purposes. Non-grading activities are usually proposed to students as a guide to help them advance their knowledge through practice (e.g. exercises completed with automatic correction tools) or reflection (e.g. general forum discussions). These activities are typically complementary to the grading activities, do not require a grade and are not mandatory. Grading activities aim to assess students' acquisition of learning and competences, and students receive a grade and/or feedback after performing the task. These activities are usually mandatory and more complex than non-grading activities.

3.2. Types of e-assessment activities
The selection of learning activities is vital for the acquisition and assessment of competences. Bearing in mind the premises of the EHEA, learning activities must help students develop competences. As discussed in Section 1, the selection of learning activities needs to be aligned with the type of assessment and the competences established for the course. The most widespread classification of learning activities is Bloom's taxonomy, which links learning activities to learning goals and abilities – i.e. knowledge, comprehension, application, analysis, synthesis and evaluation (Bloom, Engelhart, Furst, Hill, & Krathwohl, 1956). Several authors have redefined these categories by incorporating new activities and tools related to digital resources (Anderson & Krathwohl, 2001; Churches, 2008; Conole, 2008; Noriega, 2014; Schrock, 2013). Others have evolved Bloom's taxonomy by including performance abilities, such as communicative, productive and/or experiential performance (Marcelo, Yot Domínguez, Mayor Ruiz, Sánchez Moreno, & Murillo-Estepa, 2014; Penzo et al., 2010). These revisions have brought Bloom's taxonomy more into line with the leading learning approach, which is competence-based, student-centered and technology-enhanced.

The literature on e-assessment activities (also called “e-assessment tasks”) does not share the aforementioned emphasis on abilities, but instead classifies learning activities based on their delivery format. These classifications include questions (e.g. closed, open, multiple-choice, matching, ordering), e-portfolios, essays, online discussions, concept maps, personal response systems, badging, online role playing or scenario-based activities (Guàrdia, Crisp, & Alsina, 2017; Stödberg, 2012). Despite the wide variety of e-assessment activities, it is fairly common for the learning activities implemented in e-assessment to replicate traditional approaches (e.g. multiple-choice tests, short answer, fill-in-the-blanks, true-false, matching). E-assessment activities should be designed considering the characteristics of digital media and go beyond testing declarative learning to capture more sophisticated skills, knowledge and competences (Crisp, 2010).

The above-mentioned attempts to classify e-assessment activities tend to concentrate on declarative learning (“knowing that”) and fail to take advantage of online technologies to design complex activities that facilitate the acquisition of higher order competences. SCL and CBC in online education require e-assessment activities that make students put into practice and demonstrate their competences by applying the knowledge and abilities they have acquired. Although activities that help develop information management and comprehension competences are fundamental, new classifications must emphasize experiential and applied activities where online technologies are inherent in the design. Bloom's taxonomy and the other classifications discussed above can serve as a basis for creating new classifications that reinforce competence-based, student-centered and technology-enhanced learning. Section 5 of this paper proposes a classification of e-assessment activities that takes into account different competences, formats, knowledge areas and digital media to complement the e-assessment alignment model.

4. Online technologies as an opportunity to enhance assessment
4.1. Defining e-assessment
Formative assessment practices have proliferated since the launch of the EHEA, but despite this, traditional types of assessment such as summative assessment are still commonly used. The fact that university bachelor's degrees are generally organized in semesters contributes to the assessment of learning (summative assessment) rather than assessment for learning (formative assessment) (Ferrell, 2013). The prevailing institutional emphasis on summative assessment contrasts with the formative strategies professionals use to advance their careers. Graduate employability is a major issue for higher education institutions, so it is necessary to force assessment and feedback to evolve in order to promote employability (Ferrell, 2013). In addition, the Standards and Guidelines for Quality Assurance in the European Higher Education Area (ESG, 2015:25) now include a standard regarding SCL and assessment: “Institutions should ensure that the programmes are delivered in a way that encourages students to take an active role in creating the learning process, and that the assessment of students reflects this approach.”

Online technologies offer new opportunities for assessment to be more student-centered and for authentic e-assessment activities that help test complex cognitive skills and prepare students for the professional world, especially when it comes to formative practices (Crisp, 2009). And the European Commission (2012) stated that e-assessment brings added value and does not just involve the use of online technologies in assessment. There are several methods for using online technologies to enhance assessment (e.g. e-portfolios, augmented reality, immersive environments, learning analytics). Envisioning the future, Guàrdia, Crisp and Alsina (2017, 38) defined e-assessment as “the use of ICT to facilitate the entire assessment process, from designing and delivering assignments to marking, […] reporting, storing the results and/or conducting the statistical analysis”. Adopting e-assessment involves much more than introducing online technologies into the assessment process; it means supporting effective learning.

4.2. Predominant types of (e)assessment
The National Research Council (2000) stated that assessment and feedback are crucial for helping students learn. Students do not want to waste time on completing activities that do not contribute directly to their academic progress (Rust, 2002). For students, the real curriculum is what is assessed in examinations (Toohey, 2002). Therefore, it is essential to align assessment with learning outcomes to contribute to more constructive learning in which students easily perceive the usefulness of performing the learning activities and learn from the assessment (Biggs & Tang, 2011). Assessment influences the learning that takes place; indeed, different types of assessment inspire different categories of learning (Baleni, 2015).

Traditionally in higher education, the most common type of assessment is summative. Summative assessment usually comprises a final grading – the average grade for all the activities or exams conducted during the course. This may or may not be combined with a final examination or project. Mainly due to the Bologna process, formative assessment is now being widely implemented in European universities. In formative assessment, there is an iterative process where students receive information about their learning process, learn from it, and improve their learning products based on the feedback given (Crisp, 2014). Formative assessment can be based on the teacher's feedback, but it can be more productive if it is based on self-assessment and peer-assessment (Gikandi, Morrow, & Davis, 2011; Spector et al., 2016). Despite the fact that different forms of assessment can be distinguished and typified at a theoretical level, the truth is that in real educational contexts, these types of assessment are usually combined or they are not implemented exclusively. Table 1 summarizes the main differences between summative and formative assessment.


Table 1. Differences between the main types of e-assessment.

Summative	Formative
Aim	Judging	Improving
Driving question	What have you learned?	What are you learning?
What	Measures student's achievement and understanding of a subject at a point in time
Progression and certification purposes
Grades	Assesses student's development of competences and acquisition of knowledge during instruction
Students receive timely feedback on their learning with specific suggestions for improvement
When	After learning	During learning
How	Final exams
Midterm exams
Quizzes	Portfolio
Reflective essay
Rubric
Questioning
The same types of assessment are applied online as in face-to-face contexts (i.e. summative and formative). At present, online technologies are being used to transfer conventional types of assessment to online contexts. Technologies are also making these types of assessment evolve, as in the case of embedded formative assessment (Baleni, 2015). Online technologies are also facilitating the proliferation of more sophisticated approaches to assessment, such as integrative assessment, the primary purpose of which is to enhance future learning – in contrast to summative and formative practices that aim to test current learning. Integrative assessment consists of “providing activities that define and track strategies that students use to assess their own learning abilities and problem-solving capabilities, the quality and standards of student responses and how students might adapt their learning to future scenarios” (Crisp, 2012:39). In this approach to assessment, the alignment of learning objectives and assessments is fundamental for students to obtain clear guidelines on what will be rewarded in their e-assessment activities. Students are rewarded for the analysis of their approaches to learning, rather than the learning itself.

4.3. Helping students to learn from assessment: assessment criteria and feedback
All types of assessment require teachers to define a set of assessment criteria to evaluate student performance in learning activities. Assessment criteria are “descriptions of what the learner is expected to do and at what level, in order to demonstrate the achievement of a learning outcome” (European Commission, 2015:66). The assessment methods and criteria for an educational component should be appropriate and consistent with the learning outcomes that have been defined for it and with the learning activities that have taken place (European Commission, 2015). Davies (2010) stated that teachers must ensure that students engage with the assessment criteria to promote a suitable formative assessment. However, the results of research conducted by Gibbs and Dunbar-Goddet (2007) demonstrated that the assessment criteria had little effect on learning, and suggested that it is more helpful to offer students plenty of feedback.

Researchers are currently investigating the characteristics of effective feedback and exploring its different types. Feedback can be directed to various audiences (individual, group, whole class), can have different feedback-givers (teacher, peers, tools), and can be presented in diverse formats (text, audio, video). Guasch, Espasa, Alvarez, and Kirschner (2013) differentiated four types of feedback: corrective feedback (i.e. comments about assignment requirements and the adequacy of the content), epistemic feedback (i.e. requests for critical explanations), suggestive feedback (i.e. advice on how to proceed), and epistemic plus suggestive feedback (also called “dialogic feedback”). Current research is exploring the potential of dialogic feedback that pays attention to what students do with the feedback (Carless, 2015; Espasa, Rochera, & Guash, 2016; Nicol, 2010). In this approach, feedback is a reciprocal process in which students receive feedback (from teachers and/or peers), process it (discuss it with the teacher and/or peers), and implement it in a refined product (Guasch & Espasa, 2015). Recent research demonstrated that elaborated feedback, like dialogic feedback, is beneficial for higher order learning outcomes in computer-based environments (Van der Kleij, Feskens, & Eggen, 2015).

Quality, timely and personalized feedback positively impacted students' learning, except in the case of large class sizes, where it is hard for teachers to offer this feedback (Voelkel, 2013). In these cases, e-assessment is becoming a suitable solution for providing students with feedback without increasing the teachers' workload. This is the case of automatic feedback which lets students get feedback regardless of class size – for example, through online tests (Hepplestone, Holden, Irwin, Parkin, & Thorpe, 2011). Nevertheless, when automatic feedback is translated into information on performance, provided by grades or standard comments as in multiple-choice questions and computer-assisted grading, students may perceive it as unfair (Dermo, 2009). Some studies call for a combination of summative and formative e-assessments, where students can receive formative feedback by self-assessing their learning through online tests, getting immediate feedback (Angus & Watson, 2009; Voelkel, 2013). We agree with previous arguments in favor of combining diverse forms of e-assessment and e-assessment activitiesin accordance with the desired learning outcomes. The following section describes a conceptual model for aligning some core elements in the assessment design process.

5. A model for designing e-assessment processes
5.1. Related work on assessment design models
A number of researchers have developed models for sequencing the assessment design process. These methods often start by establishing course goals and/or learning aims, continue by defining competences and/or learning outcomes, and finish by detailing the assessment activities. Assessment criteria are sometimes taken into consideration, and they are integrated into the process after the definition of either the competences or the assessment activities (e.g. Cardona, Vélez, & Tobón, 2014). Some models also include assessment indicators and evidence to be presented at different points in the process (e.g. Joosten-ten Brinke et al., 2007). However, they often differ on the definitions of the indicators and evidence. A few include teaching methods and digital resources (e.g. Biggs & Tang, 2011; Centre for Academic Development and Quality, 2013). In a number of cases, the proposed teaching method is content-based and teacher-centered which usually results in a traditional view of assessment and use of online technologies (e.g. Gosling & Moon, 2002; Nikolov, Shoikova, & Kovatcheva, 2014).

The Quality Course Teaching and Instructional Practice scorecard (QCTIP) (https://onlinelearningconsortium.org/consult/olc-quality-course-teaching-instructional-practice/) developed by the Online Learning Consortium deserves special attention. It comprises a set of valuable rubrics to measure the quality of courses' teaching. Nevertheless, they are not informative enough when it comes to taking decisions on the process of alignment between competences and other elements of course design (i.e. activities, assessment, learning outcomes). Likewise, assessment (type and criteria) and integration of online technologies in course design are hardly mentioned. Even though it has indicators that reflect the need for alignment, no information is provided about how to conduct this process.

In terms of online assessment, there have been some attempts to help teachers select the best e-assessment activities and digital tools for the desired learning outcomes (e.g. Gil-Jaurena & Kucina Softic, 2016; The University of Exeter's Collaborate project http://as.exeter.ac.uk/tqae/projects/collaborate/designingwork-integratedassessments/). Both proposals represent progress when it comes to aligning e-assessment and learning outcomes; however, they do not cover other necessary elements for course design (e.g. assessment criteria, indicators).

Table 2 summarizes the two main focuses (competences and learning outcomes) in the alignment process for the models mentioned above and highlights their major weaknesses. The majority of these models belong to the second group: learning outcomes.


Table 2. Comparison of assessment design models.

Alignment focus	Representative model	Description	Weaknesses
Competences	Competence-based curriculum
(Nikolov et al., 2014)	The aim is to enable students to acquire and demonstrate their competences through learning activities. The competence is the starting point of the alignment process, followed by units of study, behavioral indicators and, learning activities. The learning outcome indicates the level of competence acquired. Competences and behavioral indicators are the main reference point for the assessment.	
•
Digital media not considered

•
Few guidelines about the types of assessment and teaching/learning activities

Learning outcomes	Constructive alignment approach
(Biggs & Tang, 2011)	The aim is to enhance student outcomes. The intended learning outcomes are defined, then aligned with the teaching and learning activities and the assessment criteria before teaching takes place. The learning activities engage students and give them opportunities to achieve the outcomes.	
•
Digital media not considered

•
No mention of competences

•
Indicators not considered

The aforementioned models offer different approaches to assessment design. All of them represent an improvement in the ordering and sequencing of the elements that affect the process of assessment design. Nevertheless, from our point of view, there is still the need for a model describing the assessment design process from the perspective of competence-based online courses and with particular emphasis on e-assessment activities. This is especially necessary for online education, where it is fundamental that teachers design the assessment aligned with competences and learning activities.

5.2. The e-assessment alignment model
With the aim of improving the process of aligning assessment with competences and learning activities, we propose a model to guide teachers. Unlike previous models where the design process starts by defining learning activities or curriculum aims (e.g. Gosling & Moon, 2002; Morcke et al., 2013; Nikolov et al., 2014; O'Farrell, 2009), the purpose of our proposal is to help teachers make decisions on curriculum design, starting with competences and putting the student at the center of the learning process. This is in line with the student-centered constructive alignment model (Biggs & Tang, 2011) where learning outcomes, teaching and learning activities, and assessment tasks are mutually reinforced. Our model benefits from that approach and adds emphasis to the “e-” nature of learning activities. It is a cyclical model composed of four steps of definition: competences, e-assessment activities, assessment criteria, and indicators and feedback. All these elements are determined by the types of e-assessment that the teacher selects for the course. Below the four suggested steps of definition and decision-making are described.

Step 1: Generic and specific competences

The process begins when the teacher selects the generic and specific competences (González & Wagenaar, 2003) to be developed during the course. Generic competences should be distributed and assigned to bachelor's degrees using curriculum mapping (Arafeh, 2016) or selected from those defined at bachelor's degree level. Specific competences are linked to the subject area and field of study. They have to be defined in relation to the course goals. The generic competences should be shown in the syllabus, while the specific competences should be indicated for each e-assessment activity so that they are clear to students. Once both types of competences are set, the learning outcomes that students will fulfil during the course must be created. The learning outcomes reflect the expected level of competence that students will achieve doing the learning activities. Learning outcomes must be specific, precise, measurable and student-oriented (Al Husban et al., 2016).

Step 2: E-assessment activities

Based on these competences, the teacher designs a set of e-assessment activities, selecting types that will help students achieve the desired learning outcomes based on their specific needs and characteristics. Inspired by some of the existing classifications of learning activities discussed in Section 3, we propose a classification of e-assessment activities organized into five competences (Table 3). For each competence, there are descriptions, characteristics and examples of the most suitable e-assessment activities. These activities may be classified differently depending on the learning objectives. The competences selected for this classification reflect the most common abilities that students are encouraged to develop on university courses. Some competences, such as critical thinking or collaborative learning, appear throughout the classification and can be developed in almost all the activities described below. For instance, critical thinking can be encouraged through activities involving problem-solving, discussion and/or role play. Different activities may strengthen either lower or higher order thinking skills. Similarly, the grouping of students (working individually or in groups) is defined by course design and not inherent or linked to any type of activity.


Table 3. Classification of e-assessment activities.

Competences	Characteristics of e-assessment activities	Examples of e-assessment activities
Ability to search for, process and analyze information	Input-oriented
Involve searching, selecting, analyzing, interpreting, synthesizing, and/or representing information
Require consulting different information sources
Entail using content curation tools
Short duration
Useful for testing declarative knowledge	
•
Social tagging, subscriptions and tracking information sources (bookmarking, RSS)

•
Visual and structured representation of information (blogs, concept maps)

•
Comparative study of scenarios, tables or data

Ability to apply acquired knowledge	Knowledge-oriented
Scenario-based
Involve solving problems and/or implementing procedures
Require using acquired knowledge
Might be ill-defined and open-ended
Short-medium duration
Useful for testing procedural knowledge	
•
Mathematical or statistical problem-solving

•
Resolution of online exercises based on models, theoretical principles or protocols

•
Study and resolution of cases

Ability to use language to communicate successfully	Communication-oriented
Involve listening, speaking, reading, and writing in different sociolinguistic contexts
Might require using communication tools
Might entail interacting with others
Short-medium duration
Useful for testing procedural and strategic knowledge	
•
Demonstration of speaking skills by recording video or audio

•
Demonstration of written skills in a virtual forum

•
Exposition of a point of view and written/oral discussion on a topic or issue (discussion, brainstorming seminar)

Ability to create learning products in diverse formats	Output-oriented
Involve structuring the acquired knowledge
Entail designing, developing and presenting
Require reflection
Require producing content in different formats and for different audiences
Medium duration
Useful for testing declarative knowledge	
•
Preparation and structuring of written contents in the form of argumentative essays, reviews, reports and specialized documents

•
Production of audiovisual information

•
Design and development of investigations and projects

Ability to apply knowledge in real or simulated scenarios	Practice-oriented
Based on real-world and professional situations
Involve first-person active experience
Require using acquired knowledge
Medium-long duration
Useful for testing procedural and strategic knowledge	
•
Participation in an immersive environment that virtually simulates a professional context

•
Video role play

•
Application of theoretical knowledge in an e-laboratory context

The type of assessment (i.e. summative and/or formative) determines the purpose of the selected e-assessment activity and its relationship with the competences and learning outcomes defined for the course. Once the learning activities have been defined, teachers decide which of them are for grading or non-grading purposes. Teachers then select the most suitable digital tools and resources to support students' performance.

Step 3: Assessment criteria

Once competences, learning activities, and digital tools and resources have been defined, assessment criteria come into play. For each e-assessment activity, a set of assessment criteria has to be established. In CBC, the use of assessment criteria is crucial to inform students about how to attain competences as learning outcomes (Nikolov et al., 2014). When students start working on an e-assessment activity, by looking at the description and the assessment criteria they should be able to see which competences they are going to achieve, how they should perform the activity and how they will be assessed.

Step 4: Indicators and feedback

The last step will help teachers – or students if they play the role of assessors – to correct and assess the work and to provide feedback to each student. Ideally, this entails indicators: a detailed list of actions that provide insight into what is considered a good learning product, how it is to be performed, and what the expected final output for the e-assessment activity is. In short, they are the “standard by which someone is judged to be competent” (Barman & Konwar, 2011). Traditionally, teachers created and used rubrics for this purpose, although it can be done by defining significant milestones and how these can be achieved.

Teachers must make some decisions about the feedback that will be provided after each e-assessment activity (i.e. type of feedback, audience, feedback-giver, format). This information should be shared with students. The purpose of grades and feedback is to inform students about the performance level to which the competences have been achieved through the e-assessment activities. After establishing grading and feedback, teachers can return to the initial element: the course competences. Iterations can be developed when updating courses each academic semester or year. Thus, if competences remain the same and the e-assessment activities change, the assessment type, criteria and indicators can be refined iteratively.

The model described above is summarized in Fig. 1, which shows the whole process. It includes the aforementioned core elements and the workflow to be completed when aligning the assessment with competences, learning outcomes (LO), e-assessment activities, assessment criteria, indicators, and feedback. The model covers the process of assessment design for competence-based learning scenarios.

Fig. 1
Download : Download high-res image (214KB)
Download : Download full-size image
Fig. 1. The e-assessment alignment model.

5.3. The e-assessment alignment model in a real context
The model defined and presented above was conceptualized and then tested in a real online course (this reference has been omitted in order to avoid compromising the double-blind review policy, as it contained the author's name). It was put into practice by researchers and teachers at the Universitat Oberta de Catalunya (a fully online university) in the co-designing of the Logic course for the Bachelor's Degree in Computer Engineering. Since the launch of the EHEA, both instructors and students have had difficulties understanding and implementing SCL and CBC. Specifically, practical demonstration of technical competences in online assessments has proved challenging. The e-assessment alignment model was tested in a first-year compulsory Logic course to help teachers increase coherence between assessment, competences and activities. The definitive aim was to ensure that learning activities helped develop and demonstrate the achievement of individual technical competences.

In the Logic course, students learn the language used in propositional and predicate logic and the fundamental structure needed to build sentences that can be successfully executed and verified (i.e. to prove that they are correct, that they work as expected). Propositional logic is a symbolic language that uses letters to symbolize propositions (i.e. sentences, statements) and that helps to establish the relationship between statements (Mendelson, 1997). Predicate logic incorporates variables and quantifiers to formulate propositions. The Logic course is the basis for acquiring competences that will be useful for later courses (e.g. students need to know programming languages to develop software or study databases). With this in mind, the Logic course was selected for a comprehensive redesign, because it is the foundation for later courses and could act as a catalyst for change.

Implementation of the e-assessment alignment model required redefinition of the existing competences in relation to the learning activities and the type of assessment. Fig. 2 shows the alignment conducted for two e-assessment activities as a representative sample of the process carried out for the entire Logic course (which comprised more activities).

Fig. 2
Download : Download high-res image (238KB)
Download : Download full-size image
Fig. 2. The alignment model applied in the Logic course.

Following the steps of the e-assessment alignment model described in Section 5, teachers on the Logic course were asked first to define generic and specific competences that students should progressively acquire to achieve the expected learning outcomes. Once competences were delineated, e-assessment activities were revised from the previous course taking into account the classification of activities presented in Section 5.2. Most of the new activities were of the ‘resolution of online exercises based on models, theoretical principles or protocols’ type. New activities encouraged active learning by prompting students to develop and demonstrate the acquisition of competences by applying their knowledge (i.e. verifying logical statements). After this step, the assessment criteria were defined. They were general descriptions of what students were expected to do and demonstrate.

Once the competences, learning activities and assessment criteria were defined, it was time to select the types of assessment. Teachers decided to combine summative and formative assessments and to incorporate diverse types of feedback. In terms of summative assessment, there were three compulsory e-assessment activities to be completed and passed during the course. They were complemented with an automatic e-assessment system that served both for self-practice (non-grading) activities and for the compulsory exercises in one of the e-assessment activities. These exercises were supported by the wizard tool – a set of self-learning exercises to practice sentence structure and appropriate use of predicate statements. This tool let students self-regulate their learning process by deciding the number of attempts and the time spent practicing, in accordance with their schedules and needs. They received automatic feedback for each attempt and only the best score was considered when grading the e-assessment activity. In terms of the formative assessment, the activities were designed to be interdependent and increasingly complex (the knowledge acquired and the competences developed in each activity are necessary to perform subsequent activities). Following submission of each e-assessment activity, students received personalized feedback provided by the teacher including detailed information for enhancing their learning (with indications about their errors and guidelines for solving them). This feedback was given via the institutional platform for assignment submission, which has a text box where the teacher can add comments linked to each assignment.

The final step in the alignment process was to define the indicators. They were designed to assess whether students fulfilled the expected learning outcomes. Based on these specific indicators, feedback could be determined and given to students. Defining the assessment criteria and indicators was the most laborious and challenging part of the alignment process. However, it also was the most rewarding step as it helped improve online feedback, making it more accurate and focused on enhancing students' competence-based learning.

Once all steps for course alignment were completed, a process of testing and refinement of the updated course began. The new design was tested over one semester in three classrooms. Four teachers and 178 students took part in the study. Before the start of the semester, teachers' perceptions were collected through individual interviews where they were asked about the process of alignment conducted. A questionnaire was sent to students at the end of the course. The questionnaire included 20 items referring to the learning activities, types of assessment, grading and feedback. Most of the questions had Likert scales, ranging from 1 to 5, and some were open questions. It was online and voluntary.

In broad terms, results from the interviews and questionnaire revealed that the e-assessment alignment model had apparently been useful in making the course truly focused on competences and centered on students. From the teachers' point of view, the alignment process was a laborious task that increased their workload. They needed to have a comprehensive view of the course to ensure the coherence of the e-assessment activities and progressive acquisition of the competences. Teachers considered the workflow helpful for aligning competences with learning activities and assessments. They felt that competences were better integrated through the learning activities and this relationship was better explained to students. These perceptions were consistent with the students' opinions.

From the students' point of view, the updated course provided detailed information about what was expected of them, how they were going to be assessed, and what learning outcomes they would achieve. The responses to the questionnaire showed that: a) they easily understood what achieving competences meant, b) they gained understanding of the expected learning outcomes to be achieved through each activity, c) they knew the process to be performed in advance, d) they were aware of how competences were going to be achieved and assessed for each e-assessment activity (through the assessment criteria and indicators), and e) at the end of the course, they knew their level of competence achievement. As a result, students stated that they felt comfortable because they could self-regulate their efforts during the course to achieve the learning outcomes. Furthermore, they knew which competences they had achieved and felt more confident about starting new courses. Based on teachers' and students' perceptions, it appeared that thanks to the alignment process the student-centered and competence-based principles of the EHEA were accounted for better than in the previous course design.

6. Conclusions
The study aimed to investigate the suitability of alignment for designing student-centered and competence-based learning scenarios in online higher education. The literature review provided theoretical reasoning on the advantages of competence-based education for adapting learning to students' needs, knowledge and styles. Few studies indicate how a curriculum can be effectively designed to be student and competence-centered, although a number of researchers acknowledge that alignment can be of help in this regard. In reviewing related work on assessment design models, it became evident that there is a need for a model that can take advantage of the potential of online technologies to align assessment with competences and learning activities.

This paper proposes a model for aligning competences with e-assessment activities bearing in mind online education in particular. A real example is provided to show how the components of the model can be aligned in an online course. The proposed model has promising implications in the field of competence-based learning, student-centered learning and e-assessment. First, it encourages use of developed types of assessment and authentic activities that can make the most of technology to test higher order competences. Second, it provides a classification of e-assessment activities organized by competences to help overcome the challenge of assessing students' application of knowledge in online contexts. Third, it gives guidelines for the alignment of elements that are frequently missing in assessment design models (i.e. assessment criteria, indicators, feedback) with other common elements (i.e. competences, learning outcomes, assessment activities). Fourth, it proposes combining different types of e-assessment and feedback. Summative assessment and automatic feedback are useful with large class sizes, although we encourage combining them with formative assessment and elaborated feedback to achieve improved learning outcomes and support students in their individual learning process. Fifth, it provides a sequence that can help teachers to effectively design the curriculum to be competence-based and student-centered. It forces teachers to start the assessment design by defining competences and learning outcomes, promotes active learning through performance-based activities, and encourages combining different types of e-assessment and feedback to support the individual achievement of learning outcomes.

The major challenges this model poses for practitioners are, first, the fact that the alignment process is cyclical and time demanding; course design has to be reviewed and improved iteratively. This requires a significant effort from teachers. Second, although some guidelines are given for the definition of competences and learning outcomes, describing them and defining ways to measure them is complex. Institutions may need to provide the necessary instructional support for teachers to accomplish this task. Third, although the literature advocates the student-centered approach to learning, it is hard to personalize assessment with large classes. In this regard, new policies on student-teacher ratios are required to reduce the number of students per class.

Some areas for further improvement in the implementation of the model stemming from the teachers' experience, are as follows. First, teachers encountered that orienting the course towards the acquisition of competences through e-assessment activities requires extensive pedagogical knowledge of all existing types of e-assessment activities and their characteristics. This can be a limitation, as they have neither the time nor the knowledge of educational technology to be confident about what activities are preferable for what competences. One improvement to the model that could address this criticism would be to provide more guidelines about the types of activities and their suitability for the acquisition of a wider range of competences. Second, the major limitation encountered by teachers was that the process proposed by the model requires the investment of an enormous amount of time and effort. The inclusion of pre-established e-assessment patterns or scenarios that take into account the predominant purposes of assessment and types of e-assessment activities – and the full range of elements considered in the alignment model – would improve the model. Such scenarios could be used as an example or a quick guide for shortening the alignment process. They could serve as a template and be adapted to fit the specific characteristics of other courses undergoing alignment.

The study has two main limitations in terms of research merit consideration. One limitation is that the model has been tested on just one course. As part of future work, the model will have to be extended to a number of courses, knowledge areas and bachelor's degrees in order to test whether it is applicable. The second limitation is that new technologies are constantly appearing and being adapted for educational use. Therefore, the model could be enhanced if novel approaches to e-assessment and learning emerge.

