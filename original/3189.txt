Planning course study is critical to facilitate strategic intervention in education. As a significant basis of planning course study, student performance prediction aims to utilize students existing relevant information to predict their future learning performance including course grades, course failure, grade point average, etc. We target course grade prediction for course study planning, provide reminders for students’ learning and teachers’ teaching. A student’s performance is usually influenced by a variety of factors, such as the difficulty of the test, personal performance, and learning conditions. Recent studies focus on the various factors that influence student performance. However, most of them ignore the differences in the impact of these factors on different students. Moreover, existing prediction models pay less attention to the impact of test complexity on students’ performance. To tackle these problems, we propose a novel Complexity-based Attentive Interactive Student Performance prediction model (CAISP) for personalized course study planning. In CAISP, the individual differences among students can be considered by assigning dynamically different importance using attention network to facilitate personalized planning. Especially, to effectively alleviate the student performance bias caused by test complexity, we fuse test complexity features to enhance the ability of feature representation via deep neural networks. Meanwhile, we combine factorization machines to develop a deep joint representation based on interaction learning and further boost the correlation between features, leading to optimal prediction results. Extensive experiments on two real-world datasets show that CAISP outperforms the state-of-the-art solutions.

Access provided by University of Auckland Library

Introduction
In recent years, data mining and machine learning techniques have been widely used in various fields. Educational data mining (EDM) aims to explore the internal relations and patterns from the massive data resources in the field of education (Romero and Ventura , 2007; Romero and Ventura , 2010; Bakhshinategh et al. , 2018; Injadat et al. , 2020). In this way, students in learning, teachers in teaching and education management are assisted to improve the quality of education. In general, EDM focuses on student-centered research and provides guidance for students to make course study plans. As a critical problem of EDM, student performance prediction (Khan and Ghosh , 2021) is a common basis for making a course study plan, and its purpose is mainly to use the relevant information of students to predict their future learning performance (Nahar et al. , 2021) including course grades, course failure (de Barros Costa et al. , 2017), grade point average, and so on. In this work, we study one important aspect of student performance prediction, namely course grades. In other words, we take advantage of data mining techniques to analyze student historical useful information and predict students’ course future grades. Based on the prediction results, personalized course study planning can be made for students’ learning and teachers’ teaching.

General pipeline Figure 1a shows our pipeline of planning course study based on student performance prediction and it is suitable for all of courses. More specifically, as illustrated in Fig. 1a, the student historical course performance is firstly obtained and analyzed using relevant techniques. Based on this, the student future performance can be predicted. According to the predicted results, we can discover two results (Red and Green). If a student gets a Green, it means that the student is probably good at this course. On the contrary, if a student gets a Red, it means that this student needs to pay more attention to this course. Therefore, a personalized course study planning will be made for the student (Red). This student then follows the plan (such as exercises or discussions) to learn purposefully. By this means, it can reduce or avoid the student’s risk of course failure. It is helpful for teaching administrators to intervene and guide the student in time, and provide appropriate suggestions for students to improve their overall performance (Lu et al. , 2021).

Prior works and limitations Most effective approaches are proposed to predict students’ performance. The task scenarios for these forecasting methods include classification, regression, and sorting (Pardos et al. , 2010; Morsy et al. , 2017; Hu et al. , 2018). For example, a cumulative knowledge-based regression method (Morsy et al. , 2017) was developed to model the structure of degree programs for score prediction, and the authors of (Hu et al. , 2018) captured the dynamic evolution of student’s knowledge state for next-term student performance. Despite most existing works have achieved good performance, we argue that it may have the following two problems. For one thing, many studies pay less attention to the influence of test difficulty coefficient on students’ performance. In fact, there is a student performance bias caused by test complexity. For another, individual difference is considered to improve model performance in many tasks such as recommendation, yet largely lags in student performance prediction. Most of them use a “one size fits all” strategy, however, the fact is not like this. To this end, we consider individual differences among students and test difficulty coefficientFootnote1 to tackle the above possible issues.

Motivations and rationales As shown in Fig. 1b, we visualize the different effects of different courses on different students and use some related ICONS to aid visualized expression of the diagram. In the Fig. 1b, C1 to C4 represent course 1 to course 4 and S1 to S5 denote student 1 to student 5. Each student has taken these four courses, a student’s historical grades will be available for each course, and each course corresponds to a historical record in order. The cold start problem (new students or new courses without a historical grades) is not considered. As the example in Fig. 1b, student 1 gets a reminder on course 1 and course 4, student 2 and student 3 get a reminder on course 3 and course 2 respectively, student 5 gets a reminder on course 3 and course 4, and student 4 gets no reminder on all courses by our analysis and predicted results. It is observed that different courses for different students have different effects and the personalized differences should be considered. Our goal is to predict student performance for personalized course study planning. Based on the results, different students have different course study plans. The specific course of students will be learned purposefully by making a personalized course study plan, contributing to progress together.

Intuitively, test difficulty coefficient plays a vital role in student performance prediction. Based on this, we explore the influence of test difficulty coefficient on student performance and fuse test complexity features to enhance the ability of feature representation. Based on this, we further consider that different feature combinations have different effects on different students, and propose an attentive interactive student performance prediction model to better improve prediction. The proposed method relies on the student’s performance in previous courses. For the dataset, we take special data, including the score proportion of test points in test papers and test difficulty coefficient. This allows the model to better predict student performance by identifying and using relevant information from test points and associating it with performance in each course. Technically speaking, inspired by the successful application of factorization machines in click-through-rate (CTR) (Guo et al. , 2017), we focus on the factorization machines model (Rendle et al. , 2010; Guo et al. , 2017; He et al. , 2017; Xin et al. , 2018; Injadat et al. , 2020) based on sparse matrix to predict students’ performance, and compared the performance of different deep factorization machine models.

Fig. 1
figure 1
Schematic diagram of planning personalized course study using attentive student performance prediction. (a) The pipeline of planning course study based on student performance prediction. (b) Illustration of the different effects of different courses on different students

Full size image
Methodologies and contributions In this paper, we propose a novel complexity-based attentive interactive student performance prediction model for personalized course study planning, named CAISP. First, the feature is learned by factorization machines (FM) and deep neural networks (DNN). We assign different weights to FM features using attention network (AN) and then get AN features. Based on the obtained features, we then develop a multi-feature fusion strategy. Finally, the fused results are input into logic regression (LR) for calculation, and the final prediction grades are obtained. Specifically, we unitize the mechanism of deep model and model parallel structure in the deep factorization machines. Meanwhile, the attention network (Xiao et al. , 2017; Wen et al. , 2021) is used to learn the prediction ability of different feature combinations in the shallow layer. Thus, the proposed model could describe more accurately the relationship between students’ history test scores and test points difficulty and other features. Besides, we analyze the influence of test difficulty coefficient on student performance by visualized analysis on real-world dataset. To summarize, this work includes three main contributions:

To the best of our knowledge, this is the first work to explore the influence of test difficulty coefficient for student performance prediction task. Specifically, we fuse test complexity features to effectively alleviate the student performance bias caused by test complexity and enhance the ability of feature representation.

We propose a novel Complexity-based Attentive Interactive Student Performance prediction model (CAISP), which considers test complexity and individual differences among students via deep joint representation based on interaction learning. It further provides support and decision for different students, enabling personalized course study planning.

We validate the the effectiveness of the proposed model on two real-world dataset, and demonstrate its advantage over the baseline models with extensive experimental results and analysis.

The remainder of this paper is organized as follows. The existing works are discussed related to our study in Section 2. In Section 3, we then introduce the proposed model. In Section 4, experiments are conducted to demonstrate the performance of our model. Finally, Section 5 gives conclusions and future work.

Related work
The core problem of educational data mining is to predict students’ performance in course activities, exams and final grades (Xu et al. , 2021). In this section, we investigate the related work of educational data mining. Besides, we target at student performance prediction to further review.

Educational data mining
Recently, educational data mining has become increasing a popular topic(Abu Amra and Maghari , 2017; Injadat et al. , 2020). It includes learning and content analysis, knowledge tracking, learning material strengthening and early warning system (Bakhshinategh et al. , 2018). In terms of content analysis, Lan et al. (2014) developed a novel algorithm based on machine learning. This algorithm can estimate learners’ understanding of a certain field, and content analysis evaluates the relationship between problem sets and different concepts. Subsequently, Lan et al. (2014a) proposed the SARFA tracking method, a machine learning-based framework for educational applications of time-varying learning and content analysis. Extracting course knowledge points from textbooks is also one of the main methods of learning content analysis. Agrawal et al. (2014) established the knowledge dependence relationship between courses by extracting concepts from textbooks based on Wikipedia knowledge. Furthermore, different data mining methods and techniques for predicting student performance are compared (Adekitan and Noma-Osaghae , 2019). Adekitan and Noma-Osaghae (2019) adopted six data mining technologies (Random Forest, Tree Ensemble, Decision Tree, Naive Bayesian, Logistic Regression, and Rprop. MLP) to investigate the first-year students in the summer semester of the School of Economics of Tuzla University in 2010-2011 academic year, and obtains the data of the enrollment period of the students. Previous research provided the basis for our work. Different from the mentioned studies, we focus on FM-based deep model (FM and its variants) for EDM and the data mining techniques we use are mainly neural network (NN) and regression.

Student performance prediction
The purpose of student performance prediction is to use the relevant information of students to predict their future learning performance (Meier et al. , 2015). According to the different types of tasks, students’ prediction tasks can be divided into classification task, regression task (our task) and sorting task. On the basis of the technologies and tasks involved in our work, we conduct research on student performance prediction from the following three aspects. (1) FM for student performance prediction. Relative studies based on factorization machines have been carried out for student performance prediction. Thai-Nghe et al. (2012) proposed a factorization machines model to combine the advantages of support vector machine and factor decomposition model to solve the problem of students’ academic performance prediction. A new regularization framework was proposed to predict student performance by adding the constraint of preserving locality to the weighted regularization non-negative factorization machines (Hwang and Su , 2015). Li et al. (2018) used a set of features collected from the first six weeks of the curriculum to implement a prediction model for the final achievement of students in the mixed curriculum. It compared five machine learning algorithms: support vector machine, support vector regression, decision tree, Naive Bayes and K-nearest neighbor, and found that support vector machine is superior to other models. (2) NN for student performance prediction. The natural advantages of neural network make it suitable for regression analysis and prediction tasks. For example, Lykourentzou et al. (2009) used three feedforward neural networks to progressively predict the final grades of students enrolled in an entry-level e-learning course. Feng et al. (2019) clustered students based on learning behaviors and used CNN to integrate students’ personal learning behaviors, others’ learning behaviors in the same category and course information to predict whether students could complete this course. (3) Deep learning for student performance prediction. Recently, with the rapid development of deep learning (Wen et al. , 2021), many effective models were proposed for student performance prediction. A general exercise-enhanced recurrent neural network framework (Liu et al. , 2021) was designed to incorporate the knowledge concepts of each exercise. Moreover, graph neural network was used to achieve better student performance prediction in interactive online question pools (Li et al. , 2020).

Through the above investigation and comparison, we can observe the following findings. First, FM-based model and neural network are two feasible and effective technical methods for student performance prediction. Second, deep neural networks are able to enhance the ability of student’s grade feature representation. Hence, we take advantage of factorization machines and deep neural network in our proposed model. Last, these studies ignored the influence of test difficulty, and our model can mitigate effectively the student performance bias caused by test complexity.

The proposed model
In this section, we first give notations and problem definition. We then present the architecture of our CAISP including overview of CAISP and components of CAISP. To show the details of model clearly, we then introduce the complexity-based performance interaction learning, course-based attentive student performance awareness, and prediction grade of CAISP.

Generally speaking, our CAISP designs three stages: feature learning, feature fusion, and prediction. To make it easier to understand our CAISP, before going into detail, a brief description of our design motivations for each stage is given. (1) Feature learning. The historical student performance contains various features (including complexity), which can reflect the characteristics of students. DNN has promising representation ability and we use it to learn the features of high order nonlinear student performance information. Besides, considering the interaction learning between features, FM, as a widely used high-order feature interaction model, is used to learn feature interaction relations. Meanwhile, individual differences are captured via attention mechanism. The design of AN mainly lies in the model to learn different weight values of different combinations of students’ performance characteristics. (2) Feature fusion. After obtaining the three features (DNN features, FM features, and AN features), we then design a feature fusion strategy to fuse the three features, so as to obtain the fusion features containing the three aspects of information. (3) Prediction. In this stage, the fusion features are fed into logistic regression model to get the final predicted grades. As an upstream task, our feature representation learning contributes to more effective prediction.

Preliminaries
In student performance prediction problem, we have a set of d student S={s1,s2⋯,sd}, a set of e course C={c1,c2⋯,ce}, and a set of p grade G={g1,g2⋯,gp}. We use sv and ct to denote an arbitrary student and course from the student and course set respectively. When a student sv gets a grade in a course cq on the kth test, we use gksv,cq to represent this grade. For generality, the student performance prediction problem can be defined as: Given student set S, course set C and the grade set G, predicts the student next performance. In this paper, the input of prediction model is student, course, and historical course grades of students. The output of prediction model is student’s future course grades.

Fig. 2
figure 2
Architecture of our complexity-based attentive interactive student performance prediction model. It contains three components: (a) FM component (b) DNN component (c) AN component. Note that S and R in this figure represent Sigmoid and ReLU activation functions, respectively. “+” denotes sum operation

Full size image
Architecture of our CAISP
Figure 2 shows the architecture of our complexity-based attentive interactive student performance prediction model (CAISP). From a model perspective, our CAISP consists of three components, which are factorization machines (FM), deep neural networks (DNN), and attention network (AN). For unity, they are called Com1 (FM), Com2 (DNN), and Com3 (AN), respectively. FM features and DNN features are learned by our Com1 and Com2. We assign different weights to FM features by attention mechanisms and then get NN features. Specifically, FM features and AN features take dot product and then summation, and the result is then spliced with DNN features to achieve multi-features fusion. Finally, the splicing results are input into logic regression for calculation, and the final prediction results are obtained.

Components of CAISP Our proposed CAISP is composed of three components, namely factorization machines (FM), deep neural networks (DNN), and attention network (AN). Figure 2a shows the illustration of FM component (Com1), after the embedded features interact in pairs, the features via FM can be obtained from Formula 2 (see Section 3.3). DNN component (Com2) is shown in Fig. 2b and it is a traditional deep feedforward neural network module in CAISP. CAISP uses the deep neural network component to learn the features of high order nonlinear student performance information. The embedded features are input into the neural network through full connection operation, and DNN features can be obtained by Formula 4 (see Section 3.3). Figure 2c denotes the AN component (Com3), which is essentially an attention neural network with only hidden layer added on the basis of FM component. AN can assign different weight values to different combinations of student performance features and AN features are obtained by Formula 5 (see Section 3.4).The details of these three components are described in the following sections.

Complexity-based performance interaction learning
FM component As shown in Fig. 2a, complexity-based performance interaction learning is presented to capture test complexity features and achieve interaction learning between features. The factorization machines (FM) (Rendle et al. , 2010) is used to capture linear interactions between student performance features. It allows parameter estimation under very sparse data and can be optimized in the primal.

In our model, we replace the inner product calculation method of the factorization machines with the dot product calculation method. Specifically, 1) Initialize the first-order parameter ω(1) and the second-order parameter ω(2), which are lookup tables and always exist in the iteration process. They always have the same size structure. After using the one-hot coding, the total number of their features is n. Inside the first-order lookup table, the weight of the j-th feature is stored in the j-th row. In the second order lookup table, the hidden factor vector of the j-th feature is stored in the j-th row, and the parameters in the two lookup tables are updated as the iteration goes on; 2) Before input, each feature vector is processed into a vector with index, and the index of the feature with value 1 is assigned to each element in each index vector. Because there is only one feature of value 1 in each field, each field vector corresponds to an element; 3) The model takes out the index in each field from this layer, uses the second-order lookup table and first-order lookup table obtained in Step 1), finds the corresponding ω(2) and ω(1) according to the index, and finally transforms the sparse feature into dense feature; 4) The dense features of different fields take dot product in pairs, and all the fields of first-order items are summed up; 5) Collect all the results of the dot product in Step 4), and then sum the results with the results of the first-order terms.

Based on the steps above, given a feature vector x∈Rn of student performance information, and n denotes the feature dimension, the second-order factorization machines pairs all the features, sums them up, and then adds the linear regression part to finally get the prediction of the target. Based on the original FM model (Rendle et al. , 2010), in our model, we replace the inner product calculation method of the factorization machines with the dot product calculation method. Thus, the model formula for a factorization machine of degree = 2 is defined as:

ΠCom1=<ω(1),x>+∑K=1K∑j1n∑j2=j1+1n(ω(2)j1⋅ω(2)j2)xj1xj2.
(1)
where K is the total number of hidden factors. According to our experimental experience, we set K = 6. n is the feature dimension and we set n = 64. ω(1) and ω(2) are first-order parameter and the second-order parameter separately. <ω(1),x> is the linear part of the model, that is, the logistic regression model. ω(2)j1 is the hidden factor vector of feature j1.

Above, we have introduced the complete form of the factorization machines model. In order to meet the feature input combination after CAISP is added to attention network, the output part of the factorization machines is defined as follows in next part during the actual combination of the model:

ΠCom1=(ω(2)j1⋅ω(2)j2)xj1xj2.
(2)
Under the new definition, the factorization machines output is converted to tensor form. When xj1xj2 is a non-zero term, the dimension is N∗(F∗(F−1))∗K, and F∗(F−1) is the dimension of combinatorial features.

DNN component As shown in Fig. 2b, CAISP uses deep neural network (DNN) to learn high-order nonlinear student performance information features. As illustrated in Fig. 2, the CAISP model uses the same parallel structure as the DeepFM (Guo et al. , 2017) model as the model body, and the same embedding layer is used to provide the neural network and the FM before the deep neural network input. Each student performance information feature will be processed by an embedding layer with a dimension of F∗K. Finally, all the features will be recombined into the implied vectors with dimensions of K.

Let a(0)=[ω(2)1,ω(2)2,⋯ω(2)F] denotes the output of embedding layer. The output of the embedding layer a(0) is connected to the deep feedforward neural network by means of full connection. The relation between the L layer and the L+1 layer in the deep neural network is as follows:

a(L+1)=ϕ(W(L)a(L)+b(L)).
(3)
where ϕ represents activation function, and a(L) is the output at layer L. W(L) is the parameter between layer L and layer L+1, and b(l) denotes bias. Finally, the output of DNN is shown below, where H is the number of hidden layers in the feedforward neural network.

ΠCom2=ϕ(WH+1aH+bH+1).
(4)
Course-based attentive student performance awareness
AN component As shown in Fig. 2c, course-based attentive student performance awareness is introduced to learn the prediction ability of different feature combinations. It is essentially attention network (AN) with only a hidden layer added to factorization machines. As illustrated in Fig. 1, the significance of this module is that the model learns that different students’ performance features have different weight values. ΠCom3 is represented by the following:

Π~j1j2Com3=hTReLU(Wj1j2ΠCom1+b),Πj1j2Com3=exp(Π~j1j2Com3)∑j1,j2≤nexp(Π~j1j2Com3).
(5)
where W∈Rt∗K, h and b are both t-dimensional vectors. t is the number of neurons in the hidden layer of the attention network. In the full connection layer, W is the parameter between the input layer and the middle layer of the attention network. We use ReLU function as the activation function of the model, where the parameter from the middle layer to the output layer is h, and the bias vector of the middle layer is b. In order to ensure that the weights of all feature combinations are within the interval of (0, 1), the second equation above is used to normalize the weights of all feature combinations.

We input each combination feature with the dimension of N∗K into the attention network. When the combination feature passes through the input layer of the attention network, the dimension of the feature can be converted into the total number of hidden layer factors. When the combined feature is transferred to the middle layer, the dimension of the feature can be transformed into the total number of neurons contained in the hidden layer. Finally, when it reaches the output layer, the dimension will be changed to 1.

Prediction grade of CAISP
Our proposed CAISP achieves multi-features fusion via a deep joint feature fusion strategy (FM features and AN features take dot product and then summation, and the result is then spliced with DNN features.). The result of feature fusion is input into logistic regression to calculate and the prediction grade of CAISP is gained.

As mentioned before, our CAISP is composed of three components (FM, DNN, and AN component) and the result of ΠCom1⊙ΠCom3 is spliced with the output of the last hidden layer in the neural network. Finally, the splicing results are input into logistic regression for calculation, and the final prediction results are obtained. The prediction grade of CAISP with deep fusion strategy is as follows:

y^=Sigmoid(ωT1(ΠCom1⊙ΠCom3)+ωT2ΠCom2).
(6)
where y^ is the output of the proposed model, y^∈(0,1), that is, the result of the prediction. For convenience, we use the normalization method to limit the predicted results to between 0 and 1. ω1 is a weight vector whose length is the same as the number of hidden factors of FM. ⊙ denotes the dot product of ΠCom1 and ΠCom3 and then sum. ω2 is a weight vector whose length is the same as the total number of neurons in the last hidden layer of the DNN model. ΠCom1, ΠCom2 and ΠCom3 are the results of the FM, DNN and AN respectively.

Discussion on CAISP
From model perspective, our CAISP firstly adopts DNN to automatically learn high-order combination features, which reduces the dependence on artificial features. Secondly, while learning the high-order features, we take advantage of FM to extract the first-order features and the second-order features combined by the first-order features in pairs. Thirdly, AN is introduced to reduce the interference of noise information and improve the performance of the model. The obtained FM features, AN features, and DNN features then are fused via a deep joint feature fusion strategy, that is, FM features and AN features take dot product and then summation, and the result is then spliced with DNN features. Finally, the fused results are fed into logistic regression to compute the predicted grades.

From task perspective, test complexity factor plays an important role in student performance prediction task and complexity features are considered in our feature learning. Besides, in order to solve the problem of feature combination in large-scale sparse data, our well-designed CAISP can learn the interaction between multidimensional features. Meanwhile, individual differences among students also are captured based on attention mechanism and AN is able to assign different weights to students’ performance features by removing the interference of noise information from a large amount of information, and achieve the effect of focusing attention on important information.

Experiment
In this section, we conduct extensive experiments on two real-world datasets to answer the following three research questions:

RQ1: How does our proposed CAISP perform as compared with other state-of-the-art competitors?

RQ2: How are the effects of parameters in the CAISP model?

RQ3: How are individual differences reflected in CAISP?

Table 1 Basic statistics of the datasets
Full size table
Experimental setup
In this subsection, experimental datasets, evaluation metric, and baselines are firstly introduced.

Dataset
To the best of our knowledge, there is no publicly available dataset for student performance prediction. We focus on two high-quality noiseless datasets in our experiment. The dataset 1 is from the junior high school of Hongshan high school, which is a model high school in Wuhan, China. We take the scores of a class for six tests in half a year for dataset 1. The dataset 2 is from China Telecom “Tianyi” cup competition, and this competition is an artificial intelligence competition hosted by Shanghai Telecom. Although the sources of dataset 1 and dataset 2 are different, both datasets are derived from the real world, and both reflect student performance in the form of scores. Meanwhile, our proposed method is general for student’ future grade prediction and it is not limited to data sources. Therefore, as long as student performance prediction is based on the historical performance obtained from the real world, our method is feasible.

The basic statistics of dataset are shown in Table 1. All student information in the dataset has been desensitized. It is worth mentioning that only dataset 2 has a difficulty coefficient. Thus, we focus on exploring the influence of difficulty coefficient on dataset 2. We give a complexity information of test points table for dataset 2, as shown in Table 2-2. Meanwhile, we also show the student grade information on dataset 1 and 2 as shown in Table 2-1 and Table 2-3. As for Table 2-4 and 2-5, the two tables describe the score information of test points and student information on dataset 2 respectively.

Table 2 Basic attribute information on two datasets
Full size table
Evaluation metric
Considering that this paper is a regression model, we choose to use the mean square error (MSE) and mean absolute error (MAE) to evaluate the prediction performance in this paper. Since the penalty for mean square error is squared, there will be a more sensitive response to outliers. These two metrics are widely used (Hu et al. , 2018; Khan and Ghosh , 2021) to evaluate the effectiveness of the model. The smaller the value, the better the result. The calculation methods are shown in formula 7 and 8. The MSE and MAE values of our experimental results are obtained by the following calculation formula:

MSE=1m∑i=1m(yi−y^i)2.
(7)
MAE=1m∑i=1m|yi−y^i|.
(8)
where m is the total number of samples, yi is the actual test value, and y^i is the model predicted value.

Baselines
In this work, we focus on the study of the student performance prediction model based on the factorization machines. In our experiment, we compare the following FM-based model to justify the effectiveness of our CAISP model on the whole. Since the FM-based model performs well in solving the feature combination problem under sparse data, they are used widely in prediction tasks. In this paper, we extend FM model and its variants to the task of student performance prediction. Among them, NFM (He et al. , 2017), AFM (Xiao et al. , 2017) and DeepFM (Guo et al. , 2017) are the state-of-the-art models based on neural networks. In model architecture, these three models both combine the neural network and factorization machines. Specifically, NFM adopts a combination of linear factorization machines and nonlinear neural networks. AFM adds an attention network on the basis of factorization machines. DeepFM incorporates deep neural network and factorization machines. The specific model design and implementation are different. The following is a detailed introduction to each baseline.

FM (Rendle et al. , 2010): This is a traditional factorization machine model. It is a machine learning algorithm based on the idea of matrix factorization. The purpose of factorization machine is to solve the problem of feature combination in large-scale sparse data. The FM algorithm is one of the recommended algorithms that have been proven effective in the recommendation field.

NFM (He et al. , 2017): It is a neural factorization machine model. It combines the effectiveness of linear factorization machines with the powerful representation capabilities of nonlinear neural networks for sparse predictive analysis. The core of NFM is to add the bilinear interaction pooling operation to the neural network. Based on this, the neural network can learn combined features that contain more information at a low-dimensional layer.

AFM (Xiao et al. , 2017): AFM is short for attentional factorization machine. AFM enhances FM by learning the importance of the interaction between features by attention network, and improves the ability of representation. It improves FM by introducing different importance to different features of FM, and the importance is learned through attention mechanism.

DeepFM (Guo et al. , 2017): Deep factorization machine is a factorization-machine based neural network for CTR prediction. It uses a neural network part and a factorization machine part to extract low-level features and high-level features, and these two parts share the same input. Deep FM has a wide and deep architecture. Wide and deep components share the same input raw feature vectors, which enables Deep FM to learn both low-order and high-order feature interactions from input raw features.

Implementation details
The compared baseline models and our CAISP model are mainly implemented using Tensorflow.Footnote2 Each dataset is randomly split into training and testing sets with the ratio of 70% and 30% respectively. The hardware configuration is as follows: Intel Xeon(R) CPU, GPU Nvidia GTX 1080TI, 128GB RAM, 11GB video memory. The batch sizes for the DeepFM, AFM, NFM and our CAISP models are all set to 256. The epochs and L2 regularization parameters are set to 200 and 0.00001 respectively. The ReLU activation function is employed in our model. To gain reliable results, all models are trained and tested for 10 times and we report the average performance.

Data processing and analysis
For dataset 1, after observation of the data set, we found that some students missed the test data in the data set. In order to eliminate the negative impact of inconsistent data on the experimental results, we cleaned up the data of students who missed the examination. We then processed the remaining student performance data for the experiment.

For dataset 2, we make a global observation of the data and found that the test paper set of students less than the set of all test papers given. In order to ensure the uniformity of the data, we cleaned up the test data not included in the test scope and kept all the test data used for the experiment. After the global analysis of dataset 2, we make the complexity-average score and complexity-standard deviation analysis by statistical visualization method as shown in Fig. 3. The standard deviation (std) is most commonly used in probability statistics as a measure of statistical dispersion, reflects the degree of dispersion of a dataset. The smaller the standard deviation is, the more aggregated the data is. The larger the standard deviation, the more discrete the data.

Thereinto, Fig. 3a represents the relationship between complexity and mean score, where the ordinate is the mean score of students’ performances and the ordinate is the total complexity (difficulty). As shown in Table 2-2, k:i means the knowledge_point i. We sum the complexity of all knowledge points to get the total test complexity. The total difficulty conversion formula is shown in Formula 9.

Complexity=∑i=0m(k:i)⋅complexity.
(9)
Figure 3b presents the relationship between complexity and standard deviation, where the abscissa is the total complexity (difficulty) and the ordinate is the standard deviation of students’ performances. The total difficulty transformation formula is the same as Formula 9. The standard deviation transformation formula is shown in Formula 10:

σ=(score1−score)2+⋯+(scorem−score)2−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−√m.
(10)
We can find the following observations from Fig. 3: (1) The higher the complexity, the lower the average. (2)The higher the complexity, the larger the standard deviation, that is, the larger the difference in student performance.

Fig. 3
figure 3
Visualization of data analysis on dataset 2.(a) Complexity-mean score. (b) Complexity-std score

Full size image
Table 3 Performance comparison on dataset 1
Full size table
Performance comparison (RQ1)
In this subsection, the performance comparison results and analysis are given. We first validate the advantages of our CAISP via overall performance comparison. To further indicate the importance of difficulty coefficient for student performance prediction, the ablation study is set.

Overall performance
To verify the effectiveness of the proposed CAISP, we conduct performance comparison experiments on the selected datasets. Table 3 shows the results of all the comparison methods on dataset 1. We use FM, NFM, AFM, DeepFM and CAISP (ours) on dataset 1 to conduct experiment, and calculate the values of MSE and MAE according to formula 7 and 8 of Section 4.1.2. The smaller the value, the smaller the error, the higher the accuracy, the more effective the model. It can be seen from Table 3 that MSE and MAE of our model are the lowest, which are bolded. Compared with other baseline methods, the effectiveness of our method is validated. Specifically, as shown in Table 3, comparing the models based on factorization machine, we can see the performance is DeepFM>NFM>FM>AFM, and the DeepFM model performs better. The reason might be DeepFM has an ability to learn both low - and high-order combinatorial features. In addition, its FM module and Deep module share student grade feature embedding so as to facilitate faster training and more accurate learning. Above all, our CAISP model is consistently better than all the baselines. More specifically, CAISP outperforms the best baseline by 9.9% and 1.3 % for MSE and MAE on dataset 1, respectively.

Table 4 Performance comparison on dataset 2. Note that “-complexity” denotes the result of removing complexity, and “+complexity” is the opposite
Full size table
Fig. 4
figure 4
Visualization of knowledge points difficulty analysis. We take the knowledge points difficulty of course 1 as an example on dataset 2

Full size image
Table 4 shows the performance of MSE and MAE for four baselines and our CAISP model. It is worth mentioning that “+complexity” means incorporating (adding) test complexity feature into the model and “-complexity” means removing (subtracting) the test complexity feature from the model. Since dataset 2 contains the difficulty coefficient (complexity) of knowledge points, we first analyze the result of integrating complexity (i.e. +complexity). Analysis of ablation experiments with respect to complexity will be presented in the next subsection. On dataset 2, the performance of the baseline method is DeepFM>AFM>NFM>FM, and the performance comparison results are different from those in dataset 1. The reason is that difficulty coefficient feature is added for representation learning, and variants of FM have greater advantages in handling multi-feature combinations. Especially, CAISP outperforms the best baseline, DeepFM, with a relative improvement of 14 % (MSE) and 3.1 % (MAE) on dataset 2. The reason behinds the advantage of CAISP over the baselines is that, we enrich features and enhance the correlation of features by deep feature fusion strategy, and employ attention mechanism to consider individual differences among students.

Effect of difficulty coefficient
Since only dataset 2 has the difficulty coefficient feature of the test paper, the ablation experiment is performed on dataset 2. To better understand the difficulty coefficient, we take course 1 of dataset 2 as an example to visualize the difficulty distribution diagram as shown in Fig. 4. We can observe that different knowledge points in the same course have different complexity. If all the knowledge points are treated with the same complexity, it may affect the judgment of student performance prediction. Therefore, it is necessary to consider the difficulty coefficient feature for student performance prediction to facilitate the formulation of study plans.

Because we consider the test complexity (i.e., test difficulty coefficient), to verify the impact of complexity, we design a comparison experiment (whether complexity feature is considered) with (+complexity) and without (-complexity) complexity, and calculate the MSE and MAE values respectively under the two conditions. Table 4 also exhibits the results of considering complexity and not considering complexity on dataset 2. Each data in Table 4 is the MSE and MAE values calculated by formula 7 and 8. We can find that the performance when complexity is considered is better than when complexity is not considered, and our CAISP beats all baselines in all cases. Moreover, when considering the complexity, the performance of CAISP is improved by 26.8% and 5.6% for MSE and MAE respectively than without considering the complexity.

Table 5 Performance of CAISP w.r.t. the number of hidden layers on dataset 2
Full size table
Fig. 5
figure 5
Performance of CAISP w.r.t. the number of epochs on dataset 2

Full size image
Parameter analysis(RQ2)
In this subsection, we investigate the accuracy of the proposed model with respect to different parameters. In particular, as shown in Fig. 5 and Table 5, we study the performance of the CAISP model with the number of epochs and hidden layers of deep neural network varied respectively. Figure 5 shows the performance of CAISP w.r.t. the number of epochs on dataset 2 and illustrates how different batch sizes affect the results. As shown in Fig. 5, with the increase of epoch, MSE gradually decreases (that is, the accuracy increases) and finally becomes stable. Based on the results, we take the size of epoch as 200. In Table 5, the regression effect of the CAISP model is the worst when there is only one hidden layer. When three hidden layers are used and each layer has 32 neurons, due to the advantage of deeper hidden layer, the regression effect is better than that of only one layer. The best regression effect is the two-layer hidden layer design with 256 neurons. It can be considered that most high-order nonlinear features can be learned in this design.

Fig. 6
figure 6
Graphical illustration of individual differences on dataset 2

Full size image
Visualization of individual differences (RQ3)
Considering the individual differences of students, our CAISP strives to treat students as individuals and to assist and guide each one to make personalized course study plans. To better understand this claim, we visualize the difference in the impact of different courses on different students based on attention mechanism as shown in Fig. 6. In this paper, since attention network is used in AFM and our model, we compare AFM with our model. We divide it into four levels (a, b, c, and d), according to color depth. The darker the color, the greater the impact of the course on the student. In dataset 2, we take the results of 8 courses of 6 students as examples. The 8 courses are marked as C1-C8 and the 6 students as S1-S6 respectively. Figure 6a and b are the visualization result of our model and AFM respectively. As illustrated in Fig. 6, by comparing Fig. 6a and b, we can make two observations. (1) Different courses have different effects on different students. (2) The results mentioned by AFM and our model are mostly the same, but there are also differences. For example, in Fig. 6a, C2 and C7 have greater influence on S2, while less on S1. In Fig. 6b, AFM can just judge that C2 has a greater impact on S2, but ignores C7. Therefore, our model performs well in in student performance prediction for personalized course study planning.

Conclusions
In this work, to effectively alleviate the student performance bias caused by test complexity and consider the individual differences on different students, we propose a novel complexity-based attentive interactive student performance prediction model to predict course grades for different students, enabling personalized course study planning. The experimental results have demonstrated the effectiveness of our proposed method and the optimal improvement is 14% compared with the baselines. In our CAISP model, we consider test difficulty and individual differences of students to improve the capacity of student performance prediction. Meanwhile, we develop a deep joint feature representation via interaction learning to enhance the correlation between features. Besides, we extend FM model and its variants to the task of student performance prediction, and the experimental results were compared and analyzed. In further work, we will take advantage of graph neural networks to explore the complex relations between course and different students in graphs.