Abstract
Approach-Avoidance Training (AAT) is a promising intervention for modifying automatic cognitive biases towards highly palatable, but unhealthy food cues. As AAT requires repetitive motor exercises in response to basic visual stimuli, users typically find the training unengaging. Virtual reality (VR) provides an innovative opportunity for delivering more engaging, and ultimately, effective training through presenting virtual sensory stimuli in the virtual environment that replace the user's sensory stimuli. In this study, we compared user experience (flow, immersion, engagement) and performance (accuracy, approach bias) of AAT delivered via three interfaces (computer, smartphone, and VR). Participants were 24 adults (50% female; n = 12) aged 20–45 years old (M = 31.05, SD = 8.18). Results showed that VR-delivered AAT received higher engagement, flow, and immersion ratings from users than AAT delivered via a computer or smartphone application. Participants also made fewer errors on the VR delivered AAT. Thus, in our experiment, VR was a more engaging and effective way to deliver the training. Future research should examine the potential of VR to further leverage gamification elements within more immersive environments.

Previous
Next 
Keywords
Cognitive bias modification

Approach-avoidance training

Gamification

Virtual reality

Immersion

Globally, obesity is a major public health issue (Hruby and Hu, 2015). In 2014, over 640 million adults worldwide were classified as obese and the prevalence rates have continued to increase (Vos et al., 2016). With the rising global obesity rates, the quality-of-life, social, and economic costs are inescapable. Obesity markedly increases the risk of developing a wide range of chronic diseases such as type 2 diabetes, cardiovascular disease, kidney and liver diseases, some cancers, as well as mental health disorders (Chooi et al., 2019). While obesity and subsequent health consequences are preventable, the available treatment options (e.g., diet, exercise, surgery) typically focus on modifying the surface behaviour rather than the underlying psychological processes that drive such behaviour (Marteau et al., 2012; Val-Laillet et al., 2015). Indeed, the struggle to lose weight is partly driven by a tendency to make impulsive food choices without conscious awareness; a major barrier to successful weight regulation (Friese et al., 2011). It is therefore imperative to identify and test more effective, low-cost, easily implementable, and safe strategies that target the underpinning mechanisms of unhealthy eating to enhance the effects of lifestyle interventions for obesity.

To target the cognitive mechanisms driving health behaviours, an innovative training paradigm known as Cognitive Bias Modification (CBM) has been developed. One of the most widely utilised types of CBM is Approach-Avoidance Training (AAT; Prior et al., 2020). AAT is designed to retrain a key cognitive mechanism underlying problematic health behaviours, namely, automatic approach biases for appetitive cues (e.g., alcoholic beverages, unhealthy foods). Specifically, an approach bias for unhealthy food refers to automatic, appetitive action responses resulting from the development of associative links between food cues (e.g., the sight of chocolate or a burger) and the rewarding experience of eating such foods; an important psychological driver of obesity (Mehl et al., 2018).

The link between unhealthy foods and automatic appetitive responses can be modified using AAT. The standard version of AAT is a computerised program that consists of repeated practice of avoidance movements in response to unhealthy food cues (pushing away a joystick), and approach movements in response to healthy food cues (pulling a joystick towards oneself). Importantly, the instructions are implicit such that participants are instructed to react to an irrelevant feature of the food cue (e.g., the image format or plate colour), rather than its content (e.g., healthy or unhealthy), to ensure that the task captures implicit (automatic) rather than explicit cognitive processing (Kakoschke et al., 2017b). For example, participants may be instructed to avoid/push away the picture when it is in portrait format, and approach/pull toward the picture when it is in landscape format. In this case, most, but not all portrait pictures will depict unhealthy foods and most, but not all landscape pictures will depict healthy foods to ensure that responses are not predictable (Kemps et al., 2013; Schumacher et al., 2016). Through repeated practice, participants learn to associate unhealthy food cues with avoidance responses and healthy food cues with approach responses (Kakoschke et al., 2017a).Despite its effectiveness, CBM paradigms such as AAT have often been critiqued for being tedious, repetitive and boring, and as a result, adherence to training can be low (Brosan et al., 2011). Thus, it is important to boost adherence by improving the aesthetic and motivational features of the training, while ensuring that adding such features does not distract from its effectiveness (Boendermaker et al., 2015). For example, gamification techniques (i.e., where tasks or activities contain game-like elements such as cumulative point-scoring, rewards for achievement, or competitive tasks with others) have been successfully used in weight-loss interventions (Slomski, 2019). Nevertheless, it is crucial to determine whether performance accuracy and reaction times can be maintained when motivating elements (e.g., feedback) and new interfaces are used to deliver the training (Boendermaker et al., 2015).

In this study, we designed and tested the feasibility of delivering AAT via virtual reality (VR) with the longer-term aim of improving the real-world validity and long-term effectiveness of the training. VR provides a highly immersive virtual environment that can make use of multiple sensory stimuli (i.e., sounds, visuals, haptics) to generate presence, namely, the perception that the environment is real and the user is there in the environment (Eichenberg and Wolters, 2012). Another key feature of VR is immersion, which refers to the illusion that the virtual sensory stimuli in the virtual environment replace the user's sensory stimuli (Park et al., 2019). Traditionally, AAT interventions in the eating domain have been delivered via a computer and involve the training of approach (pull toward) responses to healthy food and avoidance (push away) responses to unhealthy food images using image zooming via a joystick (Kakoschke et al., 2017b; Mehl et al., 2018).

Our new VR-based system enables users to perform real physical actions and physically manipulate food items in a virtual environment., VR tools are now readily available and offer a promising option for delivering existing interventions with the emergence of lower-cost head-mounted displays (HMDs) such as the Oculus Quest 2. Wireless HMDs are self-contained and have advanced Graphics Processing Units (GPUs) built into the headset itself and come with hand controllers and inertial motion detectors that allow precise and low-latency body-based interaction within the VR world. Self-powered, stand-alone HMDs are capable of delivering interactive content without needing tethered cables or expensive desktop PCs to provide the GPU and CPU resources to drive the headset. Software development tools allow the complexity and detail of scenes to adapt based on the graphics and performance capabilities of the headset in use, allowing developers to deploy VR applications on HMDs with different performance capabilities from a single development application. Thus, HMDs can be used easily at home and in clinical settings to maximise engagement with the training. The current research is an initial study to inform the basis of longer-term VR-based interventions that will be implemented in clinical settings as an adjunct to lifestyle interventions.

1. Reward-driven approach biases for unhealthy food
Approach biases for highly palatable, yet unhealthy, foods are automatic, appetitive responses resulting from associative links between food cues (e.g. the sight of chocolate or a burger) and the rewarding experience of eating such foods (Kemps et al., 2013). Once established, approach biases are involved in the development of unhealthy eating habits (e.g. eating chocolate snacks, stopping at a drive-in burger place on the way home) (Kakoschke et al., 2015). These habits are reward-driven action sequences that overrule conscious intentions (e.g., eating chocolate while on a diet; Watson et al., 2012). In support of this view, studies have consistently demonstrated an approach bias towards high-energy food cues, i.e. people are faster to approach than avoid unhealthy food cues (Brignell et al., 2009; Kemps and Tiggemann, 2015). Importantly, previous studies have shown that approach biases for unhealthy food cues are significantly stronger amongst overweight and obese than healthy weight individuals (Kakoschke et al., 2017b). Therefore, they may importantly contribute to explaining the high-calorie food choices that underpin obesity. In fact, these biases have been associated with increased intake of such foods and weight gain (Nederkoorn et al., 2010).

1.1. Using AAT to modify unhealthy food biases
Research has consistently shown that even a single-session of AAT reduces approach biases for unhealthy food cues and increases choice and intake of healthier food options amongst healthy-weight participants tested in laboratory settings (Forcano et al., 2018; Kakoschke et al., 2017b). More recent studies have shown that the beneficial effects of AAT extend to a smartphone application version, which was shown to improve healthy food choice in overweight and obese individuals (Kakoschke et al., 2018). Moreover, seminal studies in the context of alcohol use disorder found that the computerised joystick version of AAT improves relapse rates at 12 months follow-up (Eberl et al., 2013; Rinck et al., 2018; Wiers et al., 2011). These studies have established that AAT is a highly promising strategy for reducing adverse behaviour by modifying approach biases for appetitive cues and may also be beneficial in other cases of addictive behaviour such as drug use. However, participants have reported that the computerised training is tedious and boring due to its highly repetitive nature (Beard et al., 2012). As a result, participants may be easily distracted and disengage from the training, which could reduce its effectiveness in the long-term (Brosan et al., 2011; Salemink et al., 2010).

1.2. Virtual reality methods
One way to improve engagement with the training is through the use of virtual reality (VR), an innovative therapeutic approach for delivering psychological interventions (Birckhead et al., 2019; Garrett et al., 2018; Park et al., 2019). VR provides a high degree of immersion and interactivity, the ability to deploy 3D scenarios in real time, and the use of well-controlled sensory stimuli, which may allow for greater transfer of therapeutic effects to real world outcomes (Forman et al., 2018; Powers and Emmelkamp, 2008; Rizzo and Koenig, 2017). For example, in VR-delivered AAT, users would be able to repeatedly perform real physical approach-avoidance movements using realistic appetitive stimuli (e.g., a piece of chocolate cake), namely, by moving a range of 3D healthy and unhealthy foods towards and away from themselves using hand controllers that track movements and gestures with high precision. In addition, the 3D spatial environment of VR produces greater immersion and presence, which may result in improved treatment engagement, adherence and clinical outcomes in the context of changing behaviour (Freeman et al., 2017; Hone-Blanchet et al., 2014). Immersion refers to the illusion that the virtual environment replaces the user's sensory stimuli by the virtual sensory stimuli, while presence is defined as the user's sense of being there in the virtual environment (Garrett et al., 2018). While repetitive actions may often become tedious or boring, VR allows actions to be placed in contexts that are meaningful and interesting to the viewer – using enhanced environment, achievement goals, or narrative to sustain interest in an otherwise uninteresting task.

Research on social anxiety disorder has shown that a high level of presence in VR environments is positively associated with task performance and user experience, namely, enjoyment, flow, and motivation (Bordnick et al., 2011; Cummings and Bailenson, 2016; Hone-Blanchet et al., 2014; Krijn et al., 2004). In general, research has found that VR evokes higher ratings of presence and immersion than standard display screens (Van Dam et al., 2000). Finally, VR allows for complete control over auditory and visual information provided to individuals (Hone-Blanchet et al., 2014). Given that there are several distinct advantages of VR, it is proposed that VR-based AAT will enhance some of these features including higher adherence rates and generalisability to real life, which in turn, will produce superior behaviour change and ultimately, better health outcomes.

Emerging evidence suggests that VR-based interventions are feasible and can successfully improve cognition and behaviour across clinical disorders (Park et al., 2019). For example, research examining the feasibility of VR-delivered cognitive training techniques (e.g., attentional bias training; interpretation bias training) for social anxiety has shown that training effects were associated with higher enjoyment, flow, presence, and motivation scores (Urech et al., 2015) and improved cognitive biases and anxiety more than the standard computerised training (Otkhmezuri et al., 2019), indicating the acceptability and effectiveness of VR training. Similarly, previous studies in substance use disorders have shown that participants’ rated the VR training as more enjoyable and motivating, and they made fewer errors than on the computerised training (Eiler et al., 2019; Mostajeran et al., 2019).

Altogether, these findings support the idea that VR is a feasible and promising new method for delivering cognitive training interventions. However, no study to date has examined the effects of AAT delivered via VR nor examined feasibility and training effects in the context of eating behaviour. Importantly, a recent study compared weight control in patients who participated in a weekly clinic delivered Face to Face (FTF) or via VR (Sullivan et al., 2013). Weight maintenance was significantly greater for patients who attended the VR compared to the FTF clinic. However, the clinics provided general dietary education rather than cognitive training aimed at changing the mechanism driving unhealthy eating behaviour. Although there are other cognitive training programs and VR applications designed to control excessive appetitive behaviours, AAT is unique in addressing implicit biases that drive such behaviour.

1.3. Aims and hypotheses
The aim of this feasibility study was to examine user experience (i.e., sense of immersion, engagement, and flow), and validate performance (i.e., errors, response times) of VR technology to deliver a healthy eating AAT paradigm compared to a standard computerised and recently validated smartphone application training paradigm. We hypothesised that participants completing the VR-based AAT would report higher flow and engagement ratings. Furthermore, we hypothesized that participants engaging with the VR-based AAT would perform more accurately (i.e., lower error rates) compared with participants engaging the smartphone app or computerised AAT.

2. Methods
2.1. Design and development of the VR-interface
As VR provides a highly immersive multi-dimensional environment, the simple bi-directional push-pull, forwards-backwards action of the joystick and tilt-task action of smartphone-based interfaces needed to be reconsidered for the VR environment. It should be noted that these user actions are typically used for the computer and smartphone versions of AAT. Nevertheless, these more complex interactions make it more difficult to script the user's interaction with their environments in VR. Therefore, the environment needed to provide contextual clues to place the user within it, moving beyond the single image feedback of joystick-based AAT and smartphone and helping to script the users' approach to the food items. This immersive approach necessitated the design of a VR ‘serious game’, namely, the combination of a serious (e.g., AAT) and a fun element (i.e., game-related features) to establish an immersive and engaging, but effective experience (Boendermaker et al., 2015). The goal of this development was to enhance the engagement and enjoyment of AAT through these immersive and gamified approaches.

This design process was undertaken collaboratively through a co-design process (Sanders and Stappers, 2008), which included designers, psychologists, HCI researchers, VR game developers, and potential treatment recipients. This collaborative process was important to ensure that the game balanced the usability needs of recipients with the defined interactions and movements that are known to make AAT effective. Moreover, it was critical to achieve a balance between the game elements introduced for fun and engagement and the key serious aspects of the treatment, such as the push-pull response. This was undertaken through a series of evaluations. Initially, a simple VR prototype was developed by the HCI researchers to explore AAT delivered in a VR environment together with the larger co-design team, including potential end-users through a focus group. The focus group evaluated end-users' experience of using VR compared to the existing smartphone application for completing AAT. Following on from this, a series of concepts for gamified approaches to VR-AAT were produced through two co-design workshops. Lastly, a complete VR-AAT game was produced and evaluated in relation to existing interfaces.

Given that the current study focused on the initial design and feasibility testing of the different interfaces, we did not assess changes in approach bias toward unhealthy food cues over time. The latter meant that it was not possible to conclude whether VR changes users’ approach bias significantly more than the other two interfaces. It was also beyond the scope of the current study to include related measures such as subjective food craving, implicit associations for food, or actual eating behaviour, and thus, we were not able to assess far transfer effects of training.

2.2. VR-AAT initial prototype
The initial basic VR-AAT prototype presented a simple 3D room environment where participants could pick up food items and throw them at a target floating outside the room (push action) or pick them up and ‘eat’ them by bringing them closer to their mouth (pull action). To deploy this prototype, we used a wireless HTC Vive Pro-HMD with a pair of hand controllers. A physics simulation was used to ensure consistent object physical behaviour: giving food objects mass, momentum, etc. and ensuring appropriate collision detection and response, preventing objects from penetrating other objects. Simple sound effects, such as munching when eating, or soft thuds when food hit a surface, were used to reinforce actions and their completion. Representations were deliberately kept simple to focus attention on the possible actions rather than being distracted by the aesthetics or complexity of the environment. The scale of food items was also enlarged to simplify interactions.

2.3. Focus group pilot study
The usability of the VR-AAT initial prototype was explored through a focus group study conducted with community-recruited recipients with excess weight, namely, the target audience for engaging with AAT in the food domain (N = 9). The VR-AAT prototype was also compared to the existing smartphone AAT application. Focus group feedback on these interactions was used to establish a set of initial design goals for the development of the more complex VR-AAT application. Several important insights were gained from this focus group. First, in the open interaction of the VR environment participants tended towards dealing with only one type of food at a time, i.e., eating a series of ‘healthy’ foods or throwing away a series of ‘unhealthy’ foods. This open interaction with the environment contrasted with the ‘one-at-a-time’ food presentation of the two-dimensional interface of the smartphone application and computer joystick interfaces. This design choice was identified as an issue since AAT typically involves having participants interact with, and train on, a mix of both healthy and unhealthy food choices, ideally one at a time.

Second, in the VR environment, individuals responded to the food stimuli directly rather than implicitly. In the two-dimensional interfaces, the instruction was to ‘pull’ portrait images and ‘push’ landscape images. The designers and VR developers did not originally understand the importance of implicit instruction. This insight established the challenge of designing a game environment that directed recipients to perform the push/pull action while obscuring the idea of making the choice based on their own direct assessment of the food (i.e., healthy or unhealthy). Additionally, in the transition from two-dimensional photographs of real food to three-dimensional computer models, some participants were confused as to the identity of some of the food items. Participants also reported that they enjoyed receiving immediate feedback on whether they had correctly completed a task (e.g., provided by a chewing sound when they ate food), but disliked score-based feedback as it was perceived as judgmental. Lastly, the self-directed interaction with the environment led participants to take considerable time to respond to each food choice, rather than responding to the object quickly after it is presented to them. This fast response is important for training automatic responses.

The focus group participants were also asked to compare the VR and smartphone interfaces. Specifically, after using each interface, participants were asked to complete a series of Visual Analogue Scales (VAS), based on a 10-point scale (e.g., 1 = not at all enjoyable; 10 = highly enjoyable) to measure their perceived experience (e.g., enjoyment, difficulty) with the two interfaces based on a questionnaire used in previous research (Lumsden et al., 2016). The VR-delivered AAT received higher ratings for enjoyment and lower ratings for frustration, difficulty, boredom, and effort than the smartphone delivered AAT (see Supplementary Information; Table 1). At this point, the joystick interface version of AAT was not evaluated as the primary aim of the focus group study was to better understand the design and usability constraints for a VR version of AAT.


Table 1. Self-reported user experience (flow, engagement, and immersion) ratings for AAT delivered via the three interfaces (i.e., VR, computer, smartphone).

Interface
VR	Computer	Smartphone
User experience	M(SD)	M(SD)	M(SD)
Flow (FSS-2)	35.45 (4.31)	30.31 (4.72)	28.43 (5.38)
Engagement (UES)	4.03 (0.63)	2.76 (0.83)	2.47 (0.79)
Immersion (IEQ)	3.53 (0.55)	2.78 (0.56)	2.60 (0.56)
Note: M = Mean, SD = standard deviation.

Participants reported that they would be willing to spend a greater number of minutes per session using the VR versus smartphone delivered AAT, while the number of sessions per day or week that they would be willing to engage with AAT did not differ between the two interfaces (see Supplementary Information; see Table 2). We also measured presence, an important factor underlying the proposed therapeutic effects of VR. Participants rated their perceptions of two key aspects of presence: spatial (seven items) and food (four items), using 5-point Likert Scales (Li and Bailenson, 2017). Spatial presence was positively correlated with performance, i.e., greater spatial presence was related to higher self-perceived performance, while food presence was negatively correlated with boredom, i.e., higher food presence was related to lower boredom. Finally, spatial presence was positively correlated with willingness to engage in a greater number of weekly sessions (see Supplementary Information; Table S3).


Table 2. Performance (proportion of correct responses, approach bias for healthy and unhealthy food cues) for AAT delivered via the three interfaces (VR, computer, smartphone).

Interface
VR	Computer	Smartphone
Performance	M(SD)	M(SD)	M(SD)
Proportion correct	0.98 (0.01)	0.81 (0.07)	0.52 (0.03)
Approach bias HE	26.81 (234.68)	43.98 (146.84)	29.48 (174.50)
Approach bias UH	−86.75 (222.62)	37.05 (80.85)	−25.41 (179.04)
Note: HE = healthy food cues; UH = Unhealthy food cues; M = Mean, SD = standard deviation. It should be noted that we were not able to assess change in approach bias scores (i.e., from pre-training to post-training) in the current sample, however, the values in Table 2 indicate approach bias scores separately for healthy and unhealthy foods for each interface.

2.4. VR-AAT gamified concept development
In response to observations from the focus group, HCI researchers, VR developers, psychologists, and designers provided conceptual directions through a co-design process. After two co-design sessions, five distinct design concepts were developed. These conceptual design directions sought to constrain the food choices to one at a time (i.e., food moving along a sushi train and each plate stopping in front of you) within a context (i.e., in a restaurant) with a gamified goal (i.e., the sushi train is blocked up so you need to get food out of the way by pulling it towards you or pushing it toward the chef), with an implicit instruction not based on food type (i.e., food on the blue plate should come towards you, while you should push food on yellow plates toward the chef).In the River Boat example, participants would be instructed to pluck food from a tree into the boat to go forward and push food in the water out of the way to get to the end of the river as fast as possible (Fig. 1; bottom left:). These gamified elements helped to encourage the speed and quick interactions that were identified as important to the training. The Sushi Train concept (Fig. 2) sat users in-front of a sushi train that would present one food choice directly in front of them at a time. The sushi train was broken so users had to eat the food (pull it towards them) or throw it away to advance the train. The implicit instruction was provided by asking users to throw away blue plates and bring yellow plates towards them. Ultimately the Sushi Train concept was chosen for further development and implementation. The more complex environments and goals were then developed to the core game mechanic, which is evaluated in the remainder of this paper. This game mechanic tasked participants with pushing or pulling a plate of food away in a seated position in response to the plate ring colour. Our main experimental study was aimed at validating this new VR prototype of AAT against existing interfaces for delivering the training, namely, a computer with a joystick or a smartphone application. We compared both subjective user experience and objective measures of task performance.

Fig. 1
Download : Download high-res image (265KB)
Download : Download full-size image
Fig. 1. Early design sketches for the VR version of the AAT game developed through a user-centred design process. Clockwise from top left: Grab and throw; The Lever; Net ’em, bat ’em; River Boat. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

Fig. 2
Download : Download high-res image (243KB)
Download : Download full-size image
Fig. 2. Design sketch for the ‘Sushi Train’ interaction - the basis for the VR game design.

2.5. Participants
Participants were 24 adults (50% female; n = 12) aged 20–45 years (M = 31.05, SD = 8.18) recruited via community-based advertisements. More than half of the participants had previously used a VR headset (54.2%, n = 13). Participants had a body mass index (BMI) ranging from healthy to obese1 (18.37 to 33.75 kg/m2, M = 24.25, SD = 3.67) and none reported having been diagnosed with a DSM-V based eating disorder [1].

The sample size was determined a priori using G*Power software (v3.1.9.6; Faul et al., 2007). Based on previous research examining differences in user experience between VR and traditional interfaces (e.g., Otkhmezuri et al., 2019), it was calculated that we would need 22 participants to detect a small-medium effect (partial η2 = 0.04) using a one-way within-subjects ANOVA with three groups (alpha = 0.05, power = 80%).

2.6. Measures
2.6.1. Approach-avoidance training
On each trial, participants were presented with an image (computer, Fig. 3; smartphone, Fig. 4) or a 3D representation (VR, Fig. 5) of a healthy (20) or unhealthy (20) food. Each food was shown twice resulting in 80 trials. For the computer and smartphone versions, stimuli were selected from food-pics, an online database of food images (Blechert et al., 2014). The VR version used 3D models with texturing to improve the realism. Healthy and unhealthy foods were pulled (approached) and pushed (avoided) equally often. Participants are asked to respond as fast and accurately as possible. Median reaction times were calculated for the four combinations of pushing versus pulling healthy and unhealthy foods (Kakoschke et al., 2017b; Wiers et al., 2011). Reaction times on approach trials were subtracted from reaction times on avoidance trials, resulting in positive bias scores that indicate relative approach and negative bias scores that indicate relative avoidance for each of the food types. It should be noted that we were not able to assess change in approach bias scores (i.e., from pre-training to post-training) in the current sample.

Fig. 3
Download : Download high-res image (226KB)
Download : Download full-size image
Fig. 3. Approach-Avoidance training using a joystick and computer. The joystick is used to push food on the screen away and pull food towards you.

Fig. 4
Download : Download high-res image (309KB)
Download : Download full-size image
Fig. 4. Approach-Avoidance training using the smartphone app. Users tilt the image towards or away from themselves when using the app.

Fig. 5
Download : Download high-res image (227KB)
Download : Download full-size image
Fig. 5. (a) Annotated view of the developed VR environment showing an open cloche with a food item and the blue and yellow areas that the user matches to the plate ring colour; (b) first-person view of the game in the instructional stage, showing information pop-ups that guide players to correctly match the plate colour (blue or yellow) and action (approach or avoid). (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

2.6.1.1. VR interface
Participants were instructed to push or pull food items according to whether they were presented on yellow or blue plates (Fig. 6). These instructions were counterbalanced (i.e., half of the participants pulled yellow plates and pushed blue plates, and vice versa). An audio cue (small beep) signalled the completion of each trial. To present food items one at a time, we refined the sushi-train concept, locating the user in a futuristic sushi-train restaurant with a series of connected booths arranged in a circular fashion where food items were presented one at a time. Participants are seated in an open booth facing a video screen used for information and instructions. Their hands were represented as alien-like tentacles to enhance the fantasy aesthetic of the environment and reinforce the ludic continuity of the game-world. A hemispherical ‘cloche’ was used to present and serve a food item. When the user placed their hand near the cloche it opened and the food item appeared on a plate with a coloured ring. Users were asked to pick up the food and place it onto the yellow area, beyond the cloche, or the blue area in front of it. The correct area to place the food was based on the ring colour of the plate. Due to the strategic placement, the action of throwing/placing the food necessarily involved pushing/avoidance (yellow) or pulling/approach (blue; Fig. 5) .2 At the start, players were given instructions via pop-up information and guided through the process of picking up the food and placing it (Fig. 5, Fig. 6). Once five trials had been successfully completed, the game moved to the next stage We used the Unity game engine system. Interaction was provided using the Steam VR development environment and deployed on an Oculus Rift headset.

Fig. 6
Download : Download high-res image (164KB)
Download : Download full-size image
Fig. 6. Trial sequence from the initial closed cloche (left) to correctly placing the food (right).

2.7. Questionnaires
2.7.1. User engagement scale-short form (UES-SF)
This 12-item scale measured self-reported user engagement (O'Brien et al., 2018). Each item was scored on a 5-point Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree). The UES assesses four different dimensions of user engagement: aesthetic appeal (e.g., ‘This Application X was attractive.’), focused attention (e.g., ‘I lost myself in this experience’), perceived usability (e.g., ‘I felt frustrated while using this Application X.’), and reward (e.g., ‘Using Application X was worthwhile.’). The wording of the questions are intended to be modified to the context of use. In this study, we replaced references to ‘Application X’ with ‘Smartphone App’, ‘Computer Task’, or ‘Virtual Reality’ for each iteration of the scale (i.e., one administration per interface). An overall engagement score was calculated by summing the items and dividing by twelve. Higher scores indicate higher levels of user engagement.

2.7.2. Long flow state scale (FSS-2) general
This scale was used to measure the experience of state flow, or post-event assessment of flow in the context of a recently completed activity (Jackson et al., 2008). The FSS-2 comprises 36-items rated on a 5-point Likert Scale ranging from 1 (strongly disagree) to 5 (strongly agree). There are 9 subscales that assess nine dimensions of flow: 1) Challenge- Skill Balance (e.g., ‘I was challenged, but I believed my skills would allow me to meet the challenge.’); 2) Action-Awareness Merging (e.g., ‘I made the correct movements without thinking about trying to do so.’); 3) Clear Goals (e.g., ‘I knew clearly what I want to do.’); 4) Unambiguous Feedback (e.g., ‘It was really clear to me how my performance was going.’); 5) Concentration on Task at Hand (e.g., ‘My attention was focused entirely on what I was doing.’); 6) Sense of Control (e.g., ‘I had a sense of control over what I was doing.’); 7) Transformation of Time (e.g., ‘The way time passed seemed to be different from normal.’; 8) Autotelic Experience (e.g., ‘I really enjoyed the experience.’; 9) Loss of self-consciousness (e.g., ‘I was not concerned with how I was presenting myself.’). Items were summed for each dimension and then divided by four to obtain flow dimension item average scores. Total scale scores were obtained by summing the item average dimension scores with higher scores indicating higher levels of flow.

2.7.3. Immersion experience questionnaire (IEQ)
This 31-item scale measured participants’ experience of feeling immersion (Jennett et al., 2008). Each item is scored on a 5-point Likert scale, which assesses five different aspects underlying the immersive experience within a digital environment: (1) emotional (6 items; e.g., ‘To what extent did you feel that the scenario was something you were experiencing, rather than something you were just doing?’) and (2) cognitive (9 items; e.g., ‘To what extent did you feel you were focused on the scenario?’) involvement; (3) real-world dissociation (7 items; e.g., ‘To what extent did you feel as though you were separated from your real-world environment?’); (4) challenge (4 items; e.g.,. ‘To what extent did you find the training scenario easy?’); and (5) control (5 items; e.g., ‘At any point did you find yourself become so involved that you were unaware you were even using controls?’). The IEQ has demonstrated acceptable psychometric properties [13]. All game-related instances in the items were replaced with ‘involvement with the task’ to adapt to the context of the study.

2.7.4. Slate-Usoh-Steed (SUS) presence questionnaire
The SUS scale measured participants’ perceived experience of presence during use of the VR environment (Usoh et al., 2000). Each item in this 6-item questionnaire is rated on a 7-point Likert scale that evaluate three types of presence: (1) the sense of being there in the VR environment as compared with being in a place in the real world (e.g., ‘Please rate your sense of being in the VR environment, on the following scale from 1 to 7, where 7 represents your normal experience of being in a place. I had a sense of “being there” in the VR environment.’), (2) how much the VR environment became the dominant reality (e.g., ‘To what extent were there times during the experience when the VR environment was the reality for you? There were times during the experience when the VR environment was the reality for me…’), and (3) the extent to which a participant remembered the VR environment as a place visited, rather than as a computer-generated environment (e.g., ‘When you think back about your experience, do you think of the VR environment more as “images” that you saw, or more as somewhere that you visited? The VR environment seems to me to be more like. . . ’). The SUS was originally designed in the VR field and is shown to correlate with behavioural measures of presence (Slater and Steed, 2000).

2.8. Procedure
Interested participants were invited to take part in an online survey that assessed their eligibility to participate in the study. Eligible participants were then asked to nominate a time to participate in a single 1-hour study session. Upon arrival at the laboratory, the study procedures were explained to participants after which they provided written informed consent. Participants received specific instructions about AAT delivered via each interface before commencing its use. The order in which they used each interface (i.e., VR, smartphone application, computer) was counterbalanced within participants. The training lasted approximately 10 min for each interface. The training lasted approximately 10 min for each interface. The study was conducted in a large laboratory room with dim lighting and participants remained seated while using each interface. After using each interface, they completed the immersion (IEQ), engagement (UES), flow (FSS-2), and presence (SUS; only after VR) questionnaires. Finally, participants were debriefed about the purpose of the study and reimbursed with a $10 grocery gift voucher. The study was approved by the local Research Ethics Committee and was carried out in accordance with the Declaration of Helsinki.

2.9. Data analysis
Repeated measures ANOVAs were used to examine differences in flow, engagement, and immersion ratings across the three different interfaces (i.e., VR, computer, and smartphone application) and performance indices (i.e., proportion of correct responses, approach biases). All assumptions of the repeated-measures one-way ANOVAs were met. The post-hoc tests applied the Bonferroni correction to control for multiple comparisons. An alpha value of 0.05 was used to determine significant p values. Effect size measures were partial η2 for ANOVA and Cohen's d for t-tests. For η2, a value of 0.01 represents a small effect, 0.06, a medium effect, and 0.14, a large effect, while for Co- hen's d, 0.20 represents a small effect, 0.50, a medium effect, and 0.80, a large effect (Cohen, 1992).

3. Results
3.1. User experience: flow, engagement, and immersion
Mean flow ratings differed significantly between interfaces, F(2, 40) = 15.58, p < .001, partial η2 = 0.438. Post hoc tests revealed that the VR elicited higher flow ratings than the computer (p = .002, d = 0.99) and smartphone (p <0.001, d = 1.28) interfaces, but did not differ between the computer and smartphone (p = .622, d = 0.28). Similarly, mean engagement ratings differed significantly between interfaces, F(2, 46) = 46.26, p <0.001, partial η2 = 0.668. Post hoc tests revealed that the VR elicited higher engagement ratings than the computer (p <0.001, d = 1.42) and smartphone (p <0.001, d = 1.98) interfaces, but did not differ between the computer and smartphone (p = .331, d = 0.35). Finally, mean immersion ratings differed significantly between interfaces, F(2, 46) = 56.40, p <0.001, partial η2 = 0.738. Post hoc tests revealed that the VR elicited higher immersion ratings than the computer (p <0.001, d = 1.55) and smartphone (p <0.001, d = 2.08) interfaces, but did not differ between the computer and smartphone (p = .364, d = 0.38). Descriptive statistics are provided in Table 1.

3.2. Performance indices: accuracy and approach bias
Accuracy (i.e., proportion of correct responses) differed significantly between interfaces (F(1, 21) = 861.50, p < .001, partial η2 = 0.976; see Table 2 for descriptive statistics). Post hoc tests revealed that the VR interface elicited a higher proportion of correct responses than the smartphone interface (p < .001, d = 16.14). Similarly, the computer interface elicited a higher proportion of correct responses than the smartphone interface (p = .004, d = 3.83), while there was no significant difference between the computer and VR interfaces (p = .074, d = 2.37). The interactions between approach bias for healthy and unhealthy food cues (i.e., reaction times) and interface were not significant, all Fs <2.4, ps > 0.1. Descriptive statistics are provided in Table 2.

3.3. Correlations between user experience and accuracy
Self-reported immersion ratings were positively correlated with proportion of correct responses for AAT using the smartphone interface (r = 0.513, p = .021). No other correlations were significant. The correlation coefficients are provided in Table 3.


Table 3. Pearson correlation coefficients for relations between flow, engagement, and immersion ratings and proportion of correct responses on AAT delivered via VR, computer, or smartphone app.

Interface
VR	Computer	Smartphone
User experience	r	r	r
Flow (FSS-2)	−0.142	−0.136	.232
Engagement (UES)	−0.101	−0.122	.363
Immersion (IEQ)	.125	−0.033	.513
Note: bold denotes p <0.05.

3.4. User experience and accuracy based on prior VR experience
Given that half of our participants had not previously used VR, we conducted an exploratory analysis to examine whether user experience (i.e., flow, engagement, immersion, and presence) and performance on AAT with the VR interface differed between participants with and without prior experience. The results of a series of independent samples t-tests revealed that there were no significant between group differences in user experience (p = .278 to.781) or performance (p = .056 to 0.562). Similarly, correlation analyses between user experience ratings and performance (i.e., accuracy) for VR-delivered AAT were conducted separately as a function of participants’ previous VR experience. Results showed that accuracy (i.e., proportion of correct responses) was positively correlated with presence (r = 0.623, p = .030), immersion (r = 0.673, p = .016), and flow ratings (r = 0.594, p = .042) amongst participants who had previously used VR, but not amongst participants with no previous experience.

4. Discussion
This study was the first to show that VR-delivered AAT elicited significantly higher flow, engagement, and immersion ratings than computer or smartphone delivered AAT. In terms of performance, participants showed a higher proportion of correct responses on the VR compared to the smartphone delivered AAT, while there was no difference in reaction times (i.e., approach bias) for healthy or unhealthy food regardless of interface type.

These findings are consistent with previous research showing that VR delivered cognitive training techniques improved user experience (i.e., enjoyment, motivation, immersion and presence) and performance (i.e., accuracy) relative to standard computerised delivery (Eiler et al., 2019; Mostajeran et al., 2019; Otkhmezuri et al., 2019). The finding that VR was more immersive than computer or smartphone interfaces is not altogether surprising given the immersive nature of a 3D virtual environment relative to a computer or smartphone. In the current study, we showed this for the first time in the context of AAT delivered via VR in the food domain. We also found that user experience ratings for flow, immersion, engagement were not related to performance on AAT (i.e., the proportion of correct responses), except for a positive relationship between immersion and correct responses for the smartphone application delivered AAT. The finding that immersion and presence experienced during VR were not related to performance is not altogether surprising given that some prior research also found no such relationship (Otkhmezuri et al., 2019).

Finally, there were no differences in user experience ratings or performance between participants who had tried VR before and those trying it for the first time; however, previous users showed a positive relationship between user experience and performance. This latter finding is in line with previous research showing that user attributes, including previous VR experience, influence immersion (Rosa et al., 2016). Importantly, our findings show that VR was a more engaging way to deliver AAT than the existing computer and smartphone app interfaces, which were the focus of prior research (Kakoschke et al., 2018, 2017b). Furthermore, the finding that the engaging elements of the VR-delivered AAT boosted participants’ motivation to engage with the training, while also improving the quality of performance aligns with our design goal, namely, to ensure that the crucial features of the training were retained in a more immersive and engaging virtual environment.

4.1. Strengths and limitations
This study was the first to systematically compare user experience and performance on AAT, which was delivered via a new VR interface and two existing interfaces. Importantly, we applied an end-user design facilitated by focus groups to obtain a recipient perspective of the usability of the VR interface for delivering AAT. In our experimental feasibility study, we administered standardised questionnaires validated by prior research to assess key aspects of user experience, including flow, immersion, engagement, and presence.

The limitations of the study included the small sample size and that our updated VR prototype of AAT was tested in individuals with a healthy weight rather than with the target audience, namely, those with obesity. In relation to the AAT, it should be noted that the irrelevant feature to which participants were asked to respond differed between the three interfaces. Specifically, the smartphone and computer interfaces used the image format (i.e., portrait or landscape), while the VR interface used the image colour (i.e., yellow or blue) due to design constraints in the VR environment regarding the presentation of 3D images in portrait or landscape orientation. It is possible that differences in design elements between the user interfaces (e.g., 2D or 3D representations of images) could have impacted performance. Future studies should explicitly compare the effects of these design features on user experience and performance. In addition, it is not clear whether the current findings would generalise to more common user input techniques, such as swiping (smartphone) or using the mouse and arrow keys (computer). The affordability and accessibility of the technology employed here could also be a limitation (e.g., access to a joystick). Furthermore, we did not measure change in user experience with the different interfaces over time. It may be that the novelty of the VR interface initially boosts user experience, which may decline as they become more familiar with it similar to that of a computer or smartphone (Slater and Sanchez-Vives, 2016).

4.2. Future directions
While few previous studies using VR have included longer-term follow-ups, these have shown promising effects in the short-term. For example, Cognitive Behavioural Therapy delivered via VR improved body image in patients with eating disorders, which was maintained one year later (e.g., Marco et al., 2013). Thus, future research should comprehensively assess whether engagement and, importantly, clinical effects of VR-based AAT, persist in the longer-term. Finally, amongst the experienced VR users in our sample, we found significant correlations between the active ingredients of VR (e.g., user experience indices) and performance (i.e., accuracy). The latter finding suggests that future studies should include a pre-exposure or practice phase for the VR-delivered AAT to ensure that participants can optimally benefit from the training (Rosa et al., 2016).

Further improvements to VR-delivered AAT would create a more engaging training paradigm. For example, personalisation of the food stimuli used based on the dietary needs of the individual may improve engagement with the training due to increased relevance (Forman et al., 2018). Future research should also aim to improve users’ intrinsic motivation to train through gamification, where a diverse range of elements may be incorporated into cognitive training techniques to enhance motivation, including the use of richer environments (e.g., integrating a narrative), increasing difficulty levels, or social interaction (Boendermaker et al., 2015). Our current design was built with accommodating these elements in mind. For example, the use of multiple simultaneous participants seated around the restaurant who appear as avatars to other users. These features can increase feelings of competency, experience of autonomy, and social relatedness (Ryan and Deci, 2000). While it was beyond the scope of the current study, future research could examine whether the user's sense of immersion varies as a function of different gaming elements (e.g., increasingly difficult levels, points or scoring, realism and complexity of the simulated environment). As well as motivation to train, recent research has shown that adding gaming elements can enhance learning effects as indicated by improved performance (Gleich et al., 2017). However, it is also important to ensure that such gamification techniques do to not detract from the central training task (Boendermaker et al., 2015). Specifically, adding game-like elements in the form of real-time scoring has also been shown to hinder performance (Katz et al., 2014), which may be due to increased cognitive load during the training (Boendermaker et al., 2015). Future research should examine the degree to which different game-like elements influence training performance. Finally, it would be important to test whether it is the gamification or the interface-related elements (e.g., immersion) that are driving the effects on user experience and approach bias.

Practically, VR-delivered AAT has applications beyond improving eating behaviour in individuals with obesity. Specifically, the training could be applied to other clinical problems underpinned by automatic approach biases, including problematic gambling and substance use disorder, by substituting the 3D foods with disorder relevant cues (e.g., alcoholic beverages). Finally, it will be important to test the improved VR AAT paradigm in clinical settings to examine the therapeutic benefits. Specifically, future research should examine whether the results obtained in this study generalise to multiple training sessions, clinical groups (i.e., individuals with obesity or binge eating disorder), and long-term outcomes to validate VR-delivered AAT. Importantly, the widespread availability of low-cost headsets has increased accessibility to such immersive technology (Coburn et al., 2017; Park et al., 2019), which is important from the perspective of future dissemination of VR-based AAT as an intervention.

5. Conclusion
Our study provides preliminary evidence that VR can improve performance while increasing individuals’ experience of interacting with AAT; a promising intervention for improving approach bias and eating habits . Future research should examine the longer-term effects of VR-delivered AAT on modifying approach bias as well as promoting healthier eating behaviour.