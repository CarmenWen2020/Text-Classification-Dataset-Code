Current advances in the Internet of Things (IoT) and Edge Computing (EC) involve numerous devices/nodes present at both ‘layers’ being capable of performing simple processing activities close to end users. This approach targets to limit the latency that users face when consuming the provided services. The minimization of the latency requires for novel techniques that deliver efficient schemes for tasks management at the edge infrastructure and the management of the uncertainty related to the status of edge nodes during the decision making as proposed in this paper. Tasks should be executed in the minimum time especially when we aim to support real time applications. In this paper, we propose a new model for the proactive management of tasks’ allocation to provide a decision making model that results the best possible node where every task should be executed. A task can be executed either locally at the node where it is initially reported or in a peer node, if this is more efficient. We focus on the management of the uncertainty over the characteristics of peer nodes when the envisioned decisions should be realized. The proposed model aims at providing the best possible action for any incoming task. For such purposes, we adopt an unsupervised machine learning technique. We present the problem under consideration and specific formulations accompanied by the proposed solution. Our extensive experimental evaluation with synthetic and real data targets to reveal the advantages of the proposed scheme.

Previous
Next 
Keywords
Internet of Things

Edge Computing

Tasks management

Tasks allocation

Decision making

Uncertainty management

Machine learning model

1. Introduction
In the upcoming years, the Internet of Things (IoT) will become the infrastructure that offers the basis for delivering high quality services close to end users. IoT devices are able to interact with their environment, collect data and perform simple processing activities. This leads to the execution of numerous services to support applications increasing the efficiency and limiting the latency. The IoT infrastructure becomes huge while, in an upwards mode, data can be transferred to Cloud in order to increase the efficiency related to their processing. The Cloud offers an infrastructure with increased computational capabilities, however, with increased latency as well. Large-scale Cloud data centers are ‘centralized’ systems which implies a large average separation between devices and Cloud while increasing the average network latency and jitter (Satyanarayanan, 2015). At the middle between the IoT and Cloud, the research community proposes the adoption of the Edge Computing (EC) (Roman et al., 2018). EC can host some of the desired processing activities towards the goal of keeping them close to end users for minimizing the latency. All the above make us to understand that processing can be realized at three ‘locations’, i.e., the IoT devices, the EC nodes and the Cloud.

EC aims at the provision of a distributed model where numerous EC nodes can be the host of geo-distributed datasets and the recipients of requests for tasks execution. A significant characteristic of the EC is that it connects heterogeneous IoT devices while being capable of realizing interactions between EC nodes themselves to support the provision of efficient services. EC nodes should exhibit the necessary ‘intelligence’ to react in various requests and conclude the optimal line of actions for supporting real time applications. This means that the EC can exhibit Cloud-like capabilities to make nodes capable of autonomously managing any request. Recently, researchers have proposed the use of virtualization technologies at the EC nodes over their heterogeneous capabilities (Morabito et al., 2018). A comprehensive performance evaluation that aims to show the strengths and weaknesses of several low-power devices when handling container/virtualized instances is presented in Morabito (2017) while their suitability is reviewed by Pahl and Lee (2015). We can easily identify the vast ecosystem of EC nodes and IoT devices relying below the Cloud infrastructure. The orchestration of the discussed ecosystem and the efficient management of the heterogeneous resources is a key research challenge in the upcoming years. One significant aspect of this research field is the automated tasks management and execution.

EC nodes should be capable of efficiently executing the requested tasks generated by end users or applications. Nodes should efficiently decide the execution of the reported tasks limiting the time for returning the final response. The decision for tasks allocation to the available nodes should be concluded in real time. The turnaround time for delivering the final result consists of the time required to perform the allocation decision, the time for executing the task and the time for generating the response. If a task is to be executed in a peer, remote, node, we also have to take into consideration the migration time, i.e., the required time for sending the task to the selected peer and get its response. The challenge here is to minimize all parts of the turnaround time. Multiple research efforts deal with centralized approaches for tasks allocation suffering from the drawbacks reported in the literature for Cloud computing. Various technologies are adopted to solve the tasks offloading problem ranging from machine learning and game theory to the stochastic geometry and multi-agent approaches. Such models can be combined with caching mechanisms to limit the time for retrieving cached outcomes and use them in serving new offloaded tasks. In this paper, we depart from the relevant literature and our previous efforts in the domain proposing a distributed scheme for pushing the local optimum tasks allocation from centralized decision making to the network edge. In contrast to other research efforts, we consider that each task can be (i) executed in an edge node itself, or (ii) executed in a group of peer/neighboring nodes, or (iii) delegated to the Cloud. More specifically, we focus on the management of the uncertainty related to the status of peer nodes when an offloading decision should be concluded. EC nodes can exchange information related to their status, however, this cannot be done frequently to avoid the overloading of the network. The load and data present at each EC node are crucial for taking the correct allocation decision towards limiting the aforementioned time requirements. We adopt an unsupervised Machine Learning (ML) scheme (i.e., a clustering model) and a set of heuristics for the management of the detected uncertainty. Additionally, we incorporate a rewarding mechanism that delivers the best possible peer node for offloading a task. The aim is to estimate the status of peer nodes especially when no fresh information is present at the time when the allocation action is realized. Any decision is made over the contextual information related to the status/context of nodes, like the current load, speed of processing, remaining resources, collected data distribution, and every task’s characteristics like execution requirements, the load being added to the host node, the upper time limit for getting a response and so on and so forth.

This paper is organized as follows: Section 2 reports on the prior work and how our model departs from past efforts discussing the key contribution points. Section 3 presents the problem of pushing the task allocation to the edge and preliminary information. In Section 4, we describe the proposed model and give details on it. In Section 5, we present our experimental evaluation results realized over synthetic and real traces while in Section 6, we conclude the paper presenting our future research plans.

2. Prior work & contribution
Research on multiple application domains has focused on the problem of tasks allocation for providing novel solutions that facilitate and speed up the desired processing activities. In IoT and EC, the discussed subject has a significant impact due to the constraints that IoT and EC devices exhibit. For instance, devices are characterized by limited computational resources while applications ask for immediate responses and efficient services. Obviously, a careful management of the allocation of tasks becomes imperative. The adoption of intelligent techniques, mainly upon the use of ML, can provide novel solutions while performing the processing upon nodes and tasks characteristics that should be ‘matched’ to deliver the appropriate decisions.

The tasks allocation problem is widely studied in the domain of Wireless Sensor Networks (WSNs). Multiple research efforts present models on how to allocate tasks to constrained WSN nodes mainly focusing on the energy limitations (Bharti and Pattanaik, 2016, Tian et al., 2005). Minimizing the energy consumption when executing tasks maximizes the lifetime of the network. Usually, a task scheduler is responsible to conclude the final allocation trying to detect the energy requirements of tasks and ‘match’ them against the available resources. Such an activity requires the adoption of an energy monitoring module to gain fresh information about the available resources. Another approach is to study a fair energy balance among sensors while minimizing the delay using a market-based architecture (Edalat et al., 2009). In this approach, nodes interact to exchange a tasks deployment price and agree upon it. As nodes may have interactions among them, we can also rely on cooperative models (Awadalla, 2013). Examples are the adoption of unsupervised ML (e.g., clustering) for defining groups of tasks and allocations mechanisms that rely on tasks duplication and migration. All these schemes have the ultimate goal of minimizing the execution time (Dai et al., 2011). In Yu and Prasanna (2005), the authors propose the use of an Integer Linear Programming (ILP) mechanisms and a 3-phase heuristic to realize a task scheduler. Nodes are equipped with a discrete Dynamic Voltage Scaling (DVS) model while the time and energy costs of both computation and communication activities are considered. Swarm intelligence is the main technology adopted for solving the discussed problem in Yang et al. (2014). A modified version of binary Particle Swarm Optimization (PSO) is proposed in the framework of having a different transfer function, a new position updating procedure and mutation. Particles represent tasks allocations while their movements depict the exploration and exploitation of new solutions towards the detection of the optimal results. The adoption of PSO is also the subject of Razavinegad (2014). In Hu and Xu (2011), the authors present a task allocation mechanism of a dynamic alliance that is based on a Genetic Algorithm to acquire the balance between energy consumption and accuracy. In Coltin and Veloso (2010), the authors discuss three algorithms to solve the task allocation problem: a centralized, an auction-based, and a distributed algorithm. The distributed algorithm adopts a spanning tree over the static sensors to assign tasks.

Tasks can be separated into a number of sub-tasks. The aim is to execute lightweight sub-tasks compared to the generic tasks, thus, limiting the required execution time and getting benefits from their parallel execution. However, in such cases, we have to provide efficient mechanisms not only for tasks separation but also for the aggregation of ‘partial’ results. Previous efforts have already focused on the provision of allocation algorithms for a set of sub-tasks (Voinescu et al., 2010, Xu et al., 2017). Now, the envisioned allocations are performed for every sub-task, again, taking into consideration the availability and characteristics of nodes.

Previous approaches involve the Cloud as the intermediate between IoT devices and applications. Such solutions try to gain benefits from the increased computational capabilities of Cloud. However, relying on Cloud could increase the latency in the provision of responses. Hence, current approaches try to ‘migrate’ the execution of tasks (whenever is possible and appropriate) to the edge of the network. EC can provide the infrastructure where nodes can be assigned to execute tasks close to IoT devices and end users, thus, limiting the delay/latency in the delivery of responses. At the EC, we can adopt smart gateways and micro-data centers to perform the desired task processing (Aazam et al., 2014, Greenberg et al., 2008). A review of the relevant algorithms that fit on both the Cloud and the IoT is presented in Shanthan et al. (2017). Tasks and data could be transferred through the network for securing their efficient execution/processing. Data distribution in the IoT can be performed by taking into consideration bandwidth and storage constraints (Pasteris et al., 2017). An example model is simulated annealing (Moschakis and Karatza, 2015). In any case, optimization techniques can be incorporated into the provided systems to have the model aligned with load that tasks will add to nodes. Additionally, nodes and tasks heterogeneity imposes various restrictions in tasks scheduling (Zhang et al., 2014). Workloads can be clustered into different classes with the same characteristics through the adoption of a ‘typical’ clustering method (e.g., the k-means algorithm). JarvSis is a representative platform adopting a distributed scheduler capable of automating the execution of multiple heterogeneous tasks in IoT (De Benedetti et al., 2017). A swarm-based optimization scheme can support the exploitation and exploration of the solution space to deliver the most efficient allocation (Krishnapriya and Joby, 2015). Specific metrics are adopted to detect the appropriate solution, e.g., the time required for deciding the final allocation, the load balancing aspects and the final performance.

Offloading decisions can be also combined with a caching strategy as discussed in Fang and Wenzheng (2020). Tasks attributes/characteristics/processing needs can be identified by every edge node being cached for future access. Through this approach, the execution delay and energy consumption are reduced as nodes do not spend resources to re-process the same type of tasks or gain for the re-use of the already provided outcomes. In Lee and Lee (2018), the authors consider a heterogeneous mobile cloud computing (HMCC) system that consists of remote Cloud servers, local cloudlets, task offloading mobile devices (TMDs) and non-task offloading MDs (NTMDs). TMDs have the capability of offloading to Cloud servers or cloudlets. Upon the stochastic geometry, the outage probability of task offloading in the MCC is calculated and supports the offloading decision to Cloud or both Cloud and cloudlets. In Hossain et al. (2020), another model for offloading tasks from the network to the EC is discussed. The problem is considered as a sum cost delay model of the envisioned framework. Initially, the authors deal with the optimal binary computational offloading decision while reinforcement learning is adopted to conclude the final allocation. In Guo et al. (2020), the authors model the offloading problem as a double auction game and analyze the Bayes–Nash Equilibrium (BNE) for the optimal price. A Stackelberg game is adopted to model the interactions between nodes that desire to exchange tasks and conclude the optimal allocation of resources. The proposed model deals with tasks related to a blockchain scenario. Multiagent systems are also adopted for providing solutions in the management of tasks offloading (Mutlag et al., 2020). The authors detect the role of the multiagent system in the mapping between three decision tables towards the optimization of the problem. The proposed model relies on tasks’ priority, the load caused in the network, and resources availability. In Li et al. (2020), the authors present a mechanism for the allocation of data collection tasks in an application proposed for the agricultural domain. The correlation between tasks and the available sensors is modeled, then, a double selecting strategy is adopted to conclude the best node and sensor network that fulfills the desired quality of data and collection time constraints for each task. Game theory is another technique that can support an efficient approach in finding the appropriate hosts for each task. In Apostolopoulos et al. (2018), the authors focus on a Mobile Edge Computing (MEC) scenario and propose a model for tasks offloading based on a minority game combined with a distributed learning algorithm. Every node adopts the proposed approach to declare if it is active or not and mobile devices rely on a stochastic learning automata scheme to distributively select the appropriate active peer. In Apostolopoulos et al. (2020), the authors discuss a non-cooperative game between users and define the Pure Nash Equilibrium (PNE) referring in optimal data offloading. The performance and key principles of the proposed framework are demonstrated through modeling and simulation. Another work relying on the combination of game theory and machine learning (i.e., reinforcement learning) is presented in Ranadheera et al. (2017). The target domain is the distributed resource management in MEC for computation offloading. The proposed game theoretical model is dedicated to deal with energy-efficient distributed edge server activation. The problem of the distributed activation is also studied in Ranadheera et al. (2018). The authors solve it through the use of minority games guaranteeing energy-efficient activation together with the satisfaction of users as far as the quality-of-experience concerns.

The advent and benefits of virtualization techniques open new paths for maximizing the performance upon the available hardware resources. This can happen not only for Cloud resources but also for the EC infrastructure. In any case, we should incorporate the appropriate management techniques to keep the Quality of Service (QoS) at high levels. Service workflows can be built to be combined with dynamic algorithms that dictate the allocation of the virtualized resources to multiple processing points (Sun et al., 2018a). The aim is to map the requests defined in a workflow format to services offered by the EC. The Cloud-of-Things and Edge Computing (CoTEC) traffic in multi-domain networks is the research subject of Sun et al. (2018b). The proposed scheme aims at multi-topology routing and introduces a set of programmable nodes configured to ease the traffic.

Categorizing the research efforts in the domain of tasks management, we can easily detect their ‘centralized’ approach involving a unique entity responsible to conclude the allocation plan. Centralized systems are characterized by increased communication overhead and act as a single point of failure. In addition, when data migration is decided to be part of the tasks execution plans, usually, they conclude decisions over a single parameter, i.e., a univariate decision making scheme. Example parameters are energy, transmission requirements and the topology of the network. More importantly, data migration techniques suffer from the increased migration cost especially at the network edge due to the increased amount of data ‘circulated’ in the network. To the best of our knowledge, our scheme is one of the first attempts that focuses on a distributed, local ‘multivariate’ setup where the intelligence is pushed to the edge of the network. Local decisions are made over multiple parameters, e.g., the current load of nodes, their speed of processing, the communication cost, and data present at EC nodes. We do not rely on data migration techniques to avoid redundancies in the communication overhead. Our approach can be also combined with other schemes recently proposed for the management of tasks at the edge of the network, e.g., virtualized resources allocation (Sun et al., 2018a) or the deployment of network services into a set of programmable router nodes (Sun et al., 2018b) (both efforts focus on an allocation based on a ‘global’ view of the available nodes). Finally, the current work differs with our previous papers (Kolomvatsos and Anagnostopoulos, 2019, Kolomvatsos and Loukopoulos, 2018) in the sense that it extends the past models with an uncertainty management scheme upon the status of peer nodes. Nodes are ‘forced’ to send their status to their peers, however, the relevant messages should not flood the network. Obviously, there is a ‘gap’ in the knowledge about peers status between two consecutive reporting epochs. The following list summarizes the contributions of our paper:

•
we offer a distributed, ‘multivariate’ decision making mechanism for the optimal allocation of tasks;

•
our model ‘reasons’ over the status and data present in every EC node;

•
the provided mechanism manages the uncertainty related to peer nodes status when no fresh information is available;

•
we adopt unsupervised ML models for supporting the proposed local decision making aiming at avoiding the cost of a training process;

•
we support our conclusions with the outcomes of a large set of simulations.

3. Preliminaries and problem description
In the Table 1, we provide the basic notations adopted throughout the paper.


Table 1. Nomenclature.

Notation	Short Description
The th EC node
The th task
The th dataset
The multivariate vector with the reported data
The number of dimensions in data vectors
The th task vector
The load of the th task
Data requirements of the th task
The deadline of the th task
The number of EC nodes
The communication cost between the th and the th nodes
The contextual vector with an EC node’s characteristics
The load of the th EC node
The vector of the th EC node data statistics
The processing speed of the th EC node
The mean of the th dimension at the th EC node
The deviation of the th dimension at the th EC node
The information vector of the th peer node
3.1. High level description
We focus on a set of EC nodes capable of receiving tasks and manage them. Every node 
 is ‘hooked’ to a stream where tasks 
 are reported by end users, applications, IoT devices or peer nodes. 
 also owns a local dataset, 
, formulated over the data reported by the IoT devices being in direct connection with it. Data are multivariate vectors, i.e., 
 where  is the number of dimensions. 
s exhibit specific statistical information that is communicated in peer nodes at pre-defined epochs. For instance, nodes may exchange the mean and the standard deviation for their local datasets. This approach facilitates the decision making for tasks allocation as the statistics of datasets present in peers should be taken into consideration for concluding the final allocation. The rationale behind this approach is that tasks are usually asking for analytics, thus, they should be executed over the appropriate data. Having a view of the geo-distributed data facilitates the selection of the appropriate peer node to allocate any incoming task. It is useless to execute a task asking for temperature values in the interval [30,60] over a dataset containing values below 10. The specific processing activity consumes the resources of the corresponding node to deliver an empty set.

Apart from the data required by 
, a task may be accompanied by additional constraints, e.g., the maximum acceptable latency (i.e., a deadline), the required software to be adopted during the execution and so on and so forth. We consider that every 
 should be immediately managed to save time and deliver the final outcome as soon as possible. Moreover, 
 may have a priority for execution and complexity. The management of tasks priorities is beyond the scope of this paper and left for future work. In our previous research efforts, we propose a specific model for delivering the complexity of a task and how this complexity can be evaluated in terms of the load that can be added to a node (Kolomvatsos and Anagnostopoulos, 2018). Both characteristics (i.e., priority, complexity) are significant for the envisioned decision making as they depict: (i) the maximum time in which the processing should be initiated; (ii) the required resources for executing 
.

In Fig. 1, we provide an example of the envisioned architecture where IoT devices interact with end users and the edge infrastructure to deliver data and requests for tasks execution. After the reception of 
 at 
, the node should decide if the task will be executed locally or will be allocated to its peers/Cloud. Specifically, 
 should sequentially decide on the following actions: Action 1. Execute 
 locally; Action 2. Send 
 for execution to a peer node present in the same local network; Action 3. Send 
 to be executed in Cloud. Actually, these actions could be seen as the result of two sequential decisions, i.e., D1. Decide if 
 can execute 
; D2. If not, decide if there is a peer node to ‘host’ 
. Actions 2 and 3 are examined conditioned to the decision for Action 1. In our previous effort presented in Kolomvatsos and Anagnostopoulos (2019), we propose the use of ML and a multi-criteria utility model for taking the aforementioned decisions (Actions 1 & 2). In this paper, we focus on Action 2 and the management of the uncertainty related to the status of peer nodes, i.e., their load and the statistics of their local datasets. We depart from our previous efforts and provide a scheme for taking the decision D2 under uncertainty. Even if nodes exchange information about their status at pre-defined epochs, there is a ‘gap’ between two successive deliveries of the corresponding messages. In this ‘gap’, 
 does not have fresh information about the status of its peers, thus, there is uncertainty about the efficiency of the delivered selection. The proposed scheme considers a dynamic allocation process where, at consecutive ‘epochs’, data, their statistics and tasks characteristics change imposing new requirements in the decision making approach.

3.2. Tasks local management
When 
 receives 
, it concludes a Task Vector (TV), i.e., 
 which depicts the contextual characteristics of 
. In 
: (i) 
 is the load added in the node that will undertake the execution of 
 based on its complexity (as defined in Kolomvatsos and Anagnostopoulos, 2018); (ii) 
, i.e., 
 is the minimum value for the th dimension, 
 is the maximum value for the th dimension and 
 is the interval where 
 asks for results concerning the th dimension; (iii) 
 is the deadline, i.e., the upper limit of time till which the final outcome should be delivered. For instance, the 
 depicts that the corresponding task requires 15 steps to be completed (this can be easily represented in terms of the required load), it requests 3-dimensional data defining the corresponding intervals of values (one for each dimension) while the final results should be delivered in ten (10) time units (e.g., seconds or milliseconds). Without loss of generality, we consider that all parameters are normalized in the unity interval.

EC nodes are interconnected through the network forming a graph where  nodes are present. Each edge  represents the communication channel between 
 and 
 characterized by a communication cost 
. The network topology could be either mesh or hybrid, i.e., a variable number of communication channels can be present. We have to notice that, without loss of generality, we focus on the active communication channels of EC nodes without having the topology affecting the proposed model. Any EC node, when there is the need for offloading a task, it applies our scheme and decides the allocation to the peers with which it has an active communication in the network. At pre-defined epochs, nodes exchange messages about their status, i.e., their load  and local data. The discussed message has the form 
 where  refers to the th node. 
 is the load that a node exhibits at the time of the message creation, 
 is the speed of the node calculated over the number of tasks successfully concluded in a time unit (i.e., the throughput of the node). Finally, 
 is the vector of local data statistics, i.e., 
 (
: the mean of the th dimension; 
: the standard deviation of the th dimension). The epochs after which messages are delivered through the network should not be limited as the network will be flooded by them. Moreover, the discussed reporting epoch should not be high as EC nodes will not have an ‘fresh’ view on the status of their peers. In any case, in the time between two reporting epochs possible changes may happen in the status of nodes; it consists of a stochastic process, thus, nodes cannot have a view beforehand on the completion time of each task.

Tasks completion time is affected by various parameters. Let 
 be the time observed to get a response for a task, 
 be the waiting time and 
 be the completion time. These parameters are ‘combined’ through the simple equation 
. 
 and 
 are stochastic variables, e.g., 
 can be affected by the number of tasks waiting in the corresponding queue or 
 by the throughput of the node hosting the task. If we are able to estimate 
 no matter the place where the task is executed, then, 
 heavily depends on 
. Hence, any decision for allocation is taken upon 
 having the following choices: (i) execute it locally with 
 being the waiting time in the local execution queue; (ii) execute it in a peer with 
 being equal to the transmission time plus the waiting time in the peer’s execution queue; (iii) execute it in the Fog/Cloud with 
 being equal to the transmission time plus the latency for starting the execution of the task and getting the final result. Evidently, Cloud offloading almost always incurs an additional 100 to 200 ms latency compared to using EC solutions (Chen et al., 2017).

After receiving 
, 
 has the following options: (i) execute 
 locally with 
; (ii) allocate 
 in a peer node with cost 
; (iii) send 
 to Fog/Cloud with cost greater than 
. The decision making is made in a sequential manner, i.e., 
 tries to secure the execution of 
 in the closest possible distance. Any decision is concluded over , i.e., the information vectors depicting the status of each node. The entire set of nodes is participating in this process except 
. We assume that 
 decides to offload 
 based on the aforementioned sequential decision. Our focus is on how we should manage the uncertainty about the status of peers instead of presenting the sequential decision making that is fully covered by Kolomvatsos and Anagnostopoulos (2019). Noticeably, when nodes exchange their information vectors , they also conclude 
 with the ‘assistance’ of the aforementioned messages maintaining the calculated historical values for future use. Hence, 
 is capable of calculating the Peer Information Vector (PIV), i.e., 
 that is the basis for our decision making. Our decision making is actually a function 
 where 
 is the sorted list of per node in descending order for selecting the best possible to allocate 
. Our aim is to define  under the uncertainty about 
, 
 and 
. It should be noticed that we focus only on the local offloading decision and not in the protocol adopted to distribute tasks to the selected peer nodes. This approach is left for future work together with the study of a mechanism that detects if tasks are continuously offloaded in the network by multiple nodes leading to a ‘starvation’ event.

4. The proposed allocation scheme
We provide a decision making scheme for EC nodes that manages the uncertainty about their status. We try to estimate the load and possible updates in local datasets before we conclude the final allocation of a task. We apply an unsupervised ML model to deliver the realization of the uncertainty about the load and datasets and a rewarding model for providing the final rankings of peers.

4.1. Our methodology
The proposed methodology is depicted by Fig. 2. We adopt a ‘sequential’ approach with a set o modules devoted to manage every aspect of the behavior of an EC node. The first module is dedicated to the reception and the preparation of the reported/collected data. The module undertakes the responsibility of storing the data in the appropriate format and maintaining the necessary data structures for serving the remaining modules in the envisioned architecture. Noticeably, this module also refers in the management of the contextual and historical information of peer nodes being significant for the final decision making related to the allocation of every incoming task. Another module is devoted to the reception of tasks and the definition of the above described contextual vectors. The module is connected with the tasks queue, i.e., a data structure adopted to maintain the sequence of tasks directly connected with the corresponding stream. Two other modules refer in (i) the realization of the estimations for peers’ load and the statistics of the distributed datasets; (ii) the realization of the rewarding mechanism and the final tasks allocation to the selected nodes. This modular approach enhances the expandability of EC nodes by adding new functionalities at any part of the proposed architecture. Obviously, all these modules are concluded upon the networking part of and edge node, however, the topology and the adopted networking protocols do not affect our functionalities.

4.2. The clustering scheme and load estimation
 maintains the load historical values for each peer as reported by the above described messages. Let the set of these historical values be 
 with 
 be the time instances where status messages are delivered. 
s could be a number of time units, e.g., 10 s. We assume that only the latest  values are considered in our calculations. In the interval 
, we can easily detect the uncertainty about the true value of 
. At 
, we have ‘fresh’ information about 
, however, as the time passes, this information becomes obsolete. 
 adopts an unsupervised ML method to estimate the discussed uncertainty about 
.

We adopt a clustering technique over 
, i.e., the  latest 
 reports. Assume that, based on the adopted clustering method, we have concluded  clusters ( represents the set of clusters and  depicts its cardinality) with centroids 
. In addition, at each cluster we observe a number of points (i.e., 
 values) represented by 
. Based on this information, we can easily conclude the radius of each cluster depicted by 
. s and s represent the density/magnitude of each cluster. A cluster with a high  and a low  represents a ‘solid’ group of values. In terms of our scenario, a high  together with a low  can make 
 to confirm that the 
 of the corresponding peer is at levels close to the corresponding centroid . We have to notice that the latest 
 reported in 
 may be distant to the most solid cluster. Hence, we propose a methodology for delivering the 
 estimation for the interval 
 not only based on the latest report but also on the entire set of historical values.

We define the Magnitude of Uncertainty (MoU) to depict the uncertainty ‘amount’ that each cluster adds to our reasoning process. The ideal case is when we detect only one ‘solid’ cluster. Each cluster contributes with a specific value for the MoU. In Fig. 3, we present an example of the envisioned MoU. Actually, the MoU for a cluster can be quantified by the shaded area in a circle created with the assistance of . In numerical terms, MoU can be shrunk or expanded based on . In case we have , all points in the th cluster are concentrated very close to the centroid . MoU can be easily quantified as the area of a circle i.e., 
 (this approach is adopted for quantification purposes). The higher the  is, the higher the uncertainty becomes.  also affects the MoU as the higher the number of points in a cluster is, the lower the uncertainty becomes. When , the corresponding cluster involves the majority of the 
 reports. This means that the specific cluster is representative for all the historical load values for the th node. We consider the MoUs represented by  and  and deliver the final MoU for the each cluster as follows (1)
 
In the above equation, the index  depicts the th cluster, i.e., every cluster contributes to the uncertainty about 
. The ideal scenario is to have a single cluster with . The following incident matrix (see Table 2) depicts the combinations between 
 and 
 to derive the 
.


Download : Download high-res image (92KB)
Download : Download full-size image
Fig. 3. The envisioned MoU.

Based on the above analysis, we have to take into account  MoU values to deliver the final load estimation based on the available historical values. This is concluded as follows: (2)
 
Assuming that the current reported load is depicted by 
, the final estimated load is given by 
 where  is a calibration parameter.


Table 2. The incident matrix for calculating the .

High (
)
Low (
)
High (
)
Low ()
4.3. Uncertainty management for the available data
Recall that every EC node reports not only the current load but also the statistics of the local dataset through the use of 
. 
 conveys the mean and the standard deviation for each dimension. Again, in the interval 
, i.e., between two consecutive reports, we can detect the uncertainty about the statistics of the available data. The EC node deciding the allocation of a task cannot be sure if data statistics are updated and differ from the previous report. This is because EC nodes are connected with a number of IoT devices reporting values being collected by their environment or the output of simple processing activities. Our aim is to estimate the data present in peers before we decide where to allocate the incoming tasks.

Let us focus on a specific dimension (the same rationale stands for the remaining dimensions). The th peer node reports 
 for the th dimension. We consider the latest  reports, i.e., 
. In Fig. 4, we can see an example of the geometrical representation of  reports. The ideal case is when 
 and 
, i.e., we observe  overlapped intervals, which means that the th node reports the same statistics of the available data. In the ‘average’ case, the discussed means are distributed in the interval where data are realized (obviously, this depends on the data present in every dataset). We consider the MoU for data that the th EC node owns. The MoU depends not only on the mean but also on the standard deviation. 
 depicts the uncertainty aligned with the available data as a high 
 depicts that data are dispersed away from the mean. A low 
 represents a ‘solid’ dataset with the majority of values concentrated around the mean. Speaking in geometrical terms, 
 defines the entire interval that every report covers.


Download : Download high-res image (199KB)
Download : Download full-size image
Fig. 4. An example of determining the MoU related to the available data.

We conclude the MoU for data upon the ‘intervals’ defined by their statistics. The interval that the incoming statistics cover are defined as 
. We have to notice that it is not mandatory to have the minimum mean defining the upper or the lower part of the aforementioned interval. We can easily detect the overlay interval that covers all the sub-intervals as depicted by the  incoming statistics. The overlay interval has as a center (3)
 
and radius (4)
 
 
 
 
However, every report is associated with a specific MoU, i.e., it depends on . For delivering the final  and , we are based on a weighted function, i.e., (5)
and (6)
where (7)
 
For each report, the corresponding MoU is defined as 
 while the total MoU for all the reports is equal to (8)
 
 
 
 

Based on the above calculations, we can conclude the final  and  over the historical and current reports. The following equations holds true (9)
(10)
 Through 
, we can pay more attention on historical or the current reports. 
 is defined through an exponential function, i.e., 
 with  being a smoothing parameter. 
 is affected by the uncertainty we conclude when processing past reports. When 
 is high, 
, i.e., we face a high uncertainty, thus, we pay more attention on the current report. When 
, 
, i.e., past reports depict a very low uncertainty and the final result is mainly affected by them. We have to notice that the above described process is executed for each dimension, thus, we provide the two final vectors with the estimation for the mean and the standard deviation, i.e., 
.

4.4. The tasks’ allocation model
Having calculated 
 and 
, we are able to define a ranked list with the available nodes for hosting 
. We adopt a simple rewarding mechanism that builds upon tasks and peers characteristics. Actually, we match pairs between 
 and 
. We consider a constant  adopted to provide a reward or a penalty for each parameter taken into consideration. When 
, the th node gets a reward , otherwise a penalty. In the same way, when 
 
, we assign a reward otherwise a penalty (as mentioned above, steps can be easily calculated based on 
). We also take into consideration the communication cost and assign a reward to the th node when 
 is below a pre-defined threshold. Finally, we calculate the similarity between 
 and 
 and check if it is over a pre-defined threshold as well. We adopt findings presented in Haßler et al. (2017) and define the overlapping ratio between 
 and 
 as follows: (11)
where 
 and 
. For calculating , we adopt the following equations: (12)
 
and

 

Again, we adopt a threshold to examine if  is at an acceptable level to assign a reward to the corresponding node. The list of peer nodes is sorted based on the total collected reward and the winner is selected to host and execute 
.

4.5. The complexity of the proposed model
The complexity of the proposed approach is mainly affected by the calculations required to deliver the final estimation for the load of each peer node 
, the estimation for the mean and the standard deviation of each dataset and the conclusion of the final reward. We consider that these calculations are performed in epochs, i.e., at pre-defined time instances. For the calculation of the complexity of the proposed model, we focus on a specific epoch and the adoption of the k-means clustering algorithm (any desired clustering algorithm can be applied in our model). Then, the provision of clusters upon historical load data for each peer has a complexity equal to . This is because we try to evaluate the distance of all the available historical values upon all the envisioned data dimensions. For each cluster, we perform calculations to derive the MoU, then to realize the estimated load for the specific peer node with a complexity of . The delivery of the estimated mean and deviation for each dataset costs  as it is applied upon the historical reports and the envisioned dimensions. We can easily derive the complexity of the ‘pre-processing phase’ at every epoch upon data related to peer nodes, i.e., . After the pre-processing phase, we need additional time for delivering the allocation decision for each task, i.e., the outcome of the pre-processing phase is adopted for a batch of tasks. If we consider that  tasks should be allocated, the complexity of the decision making as exposed by the calculations related to the final reward has a complexity of  being mainly affected by the calculations required to result the overlapping ratio between 
 and 
. The final complexity of the proposed mechanism is . We have to notice that the frequency of the execution of the pre-processing phase is far less than the frequency of the execution of the rewarding mechanism and the allocation process. However, the worst case scenario is to execute the pre-processing epoch at every discrete time instance of the proposed algorithm. Finally, the space complexity is affected by , i.e., the number of historical values related to the load and the data of each peer node. In general, we need a set of lists (load, mean, deviation, etc.) in order to store the relevant data for further processing.

5. Experimental evaluation
In this section, we present our evaluation outcomes retrieved by a large set of simulations adopting different datasets. The main target is to detect if our approach is capable of detecting the appropriate node to offload a task, thus, to increase the efficiency and limit the total response time.

5.1. Simulation setup & performance metrics
The target of our evaluation process is to detect if the proposed approach appropriately manages to offload a sub-set of the incoming tasks (when tasks are not executed locally). Our strategic decision in the implemented experiments is to rely on synthetic traces that expose a very dynamic environment where the characteristics of nodes (i.e., load, speed of processing, data) change continually. We adopt random values for each parameter of our scenario, i.e., 
, 
 & data, having the opportunity to create numerous experimental scenarios. Additionally, with probability 30%, we consider that the statistics of data present at peers (as exposed by 
) are updated and sent to the node taking the decision for the offloading action of a task. The evaluation process targets to reveal the values for each parameter as follows. The best possible selection is realized by a low 
 and a high 
 (calculated over 
 and 
). It becomes obvious that it is very difficult to have a single node that achieves these target values for all parameters at the same time. We consider the mean for our parameters in a set of experiments dealing with specific tasks where we randomly produce their characteristics, i.e., 
. The following equations hold true (the index  represents the mean of the corresponding parameter): (13)
 
(14)
 
(15)
 
 where the indication  depicts the load, the speed and the overlapping ratio (similarity) of the selected peer that it is decided to host the task 
 and  is the number of the experiments/tasks. Moreover, we try to detect the ‘load balancing’ aspect of our mechanism by presenting performance outcomes for the average number of tasks allocated into peers, i.e., . The following equation holds true: (16)
 
where  is the total number of peer nodes and 
 is the selected peer for 
. The rationale behind the adoption of  is to check if our model is always selecting the same peers for offloading the incoming tasks. This is very significant if we consider that EC nodes are usually connected with many other peers, thus, they may receive requests from them as well.

Without loss of generality, we consider all parameters in the interval [0, 1] implementing a simple Java class to act as our simulator. For feeding parameters with data, we utilize the following synthetic datasets: (i) a dataset defined by the Uniform distribution that realizes a very dynamic environment where peers change their characteristics in a high rate. In this experimental scenario, we consider that peers are ‘connected’ with many other nodes and receive their requests/tasks together with data from the IoT infrastructure, thus, their characteristics are continuously updated; (ii) a dataset defined by the Gaussian distribution that tries to imitate a more ‘stable’ environment where abrupt changes in peers characteristics are rare. In this dataset, after each iteration, we update the discussed parameters by a small value either increasing or decreasing them. With this approach, we try to simulate a ‘smooth’ change in the realization of the load, the speed and data present in peer nodes. Additionally, we get , , , ,  and .

We compare our model, i.e., the Uncertainty-Driven Model (UDM) with other mechanisms found in the relevant literature, i.e.,

•
the Greedy Fast Processing (GFP) model presented in Mijumbi et al. (2015). The model selects the peer that offers the best processing time for each query. The model is also met in Jošilo and Dán (2019) named as the myopic best response selection algorithm and in Breitbach et al. (2019) named as the performance aware allocation scheme. We have to notice that the model presented in Breitbach et al. (2019) allocates tasks to the best idle nodes; if not any idle nodes are available, the model performs a random allocation (see the RTS model below). In our case, there are no idle nodes, however, we consider that the GFP selects the node with the highest speed. The GFP model represents the theoretical limit for our model concerning the speed of the selected node and exhibits a complexity of  (for a set of  tasks);

•
the Greedy Best Availability (GBA) model proposed in Mijumbi et al. (2015). This model allocates tasks to nodes exhibiting the shortest waiting time in the corresponding queue. In our case, this is translated into the nodes exhibiting the lowest load. The GBA model represents the theoretical optimal scheme (i.e., a performance limit) concerning the load of EC nodes and exhibits a complexity of ;

•
the Random Task Scheduling (RTS) model proposed in Breitbach et al. (2019). The model selects nodes without taking into consideration any contextual information. The RTS model randomly allocates the desired tasks in the available nodes and exhibits a complexity of .

5.2. Performance evaluation
Initially, we focus on the complexity of the proposed model and plot the number of the required actions/calculations performed to conclude the envisioned processing in the worst case scenario (we execute the pre-processing and the allocation phases every time a task is reported to a node). In this set of experiments, we consider ,  and present our results in Fig. 5. These results depict the linear complexity of the proposed mechanism with the number of nodes playing the most significant role to the final number of the required actions. This is natural as the aforementioned calculations are mainly devoted to the estimation of the load for each peer, the mean and deviation vectors for each dataset. Having these estimations in place, it is easy to conclude the final decision for the envisioned allocations as the proposed rewarding scheme and the realization of the overlapping ratio can be executed in a very short time. Taking into consideration that the estimation of the load and mean/deviation vectors is performed less frequently, we observe that the proposed model is efficient concerning the processing and the allocation of a high number of tasks reported to every EC node.

Initially, we present our performance evaluation results concerning the probability density estimate (pde) of each metric. The pde is extracted through our simulations for every task allocation. In Figs. 6 & 7, we present our outcomes for , respectively. In general, we observe similar results no matter the values of  and . The adoption of the Gaussian and a large window  leads to low 
 realizations. In any case, 
 remains at low levels which means that the proposed model is capable of detecting and allocating tasks to peers with a low load.

Trying to reveal more statistical information about 
, we provide a boxplot depicted by Fig. 8. In this set of experiments, we get . We confirm the previous results and see that 
 realizations greater than  are outliers for , respectively. Additionally, we observe a median value close to 0.10–0.15 which is a very significant result for our model. This depicts that our scheme selects nodes with a low load, thus, it increases the possibility for initiating the processing of the task as soon as possible. Another interesting observation is that the difference/interval between the 25th and 75th percentiles becomes limited as . The high number of the available peers gives more opportunities to our model for optimally selecting the most appropriate node for each task. The aforementioned results are related to the use of the Uniform distribution that feeds our parameters. The use of the Gaussian distribution leads to better results compared to the previous experimental scenario. When our model deals with a more ‘stable’ environment where no abrupt changes are present into nodes’ characteristics, it is capable of limiting the load of the selected peer. Now, 
 values above  are considered as outliers for , respectively.

In Fig. 12, we provide statistical details about  for . Recall that  represents the overlapping ratio between the data present in a node and the data requirements defined by a task. The median of  is close to 0.60 no matter the type of the distribution that is adopted to feed our datasets. The maximum  is observed to be very close to 0.80. The difference between the 25th and 75th percentiles is between 0.40 and 0.60. This means that our model pays more attention on the load and the processing speed of the available nodes. We have to notice that these results are retrieved for very dynamic environments without taking into consideration the types and frequencies of tasks’ demand for data.

Fig. 13 depicts our results for  and . Recall that  reveals the ‘load balancing’ aspect of our approach. The target is to keep the number of the allocated tasks to each peer as low as possible. The average number of tasks per node is 20, 10 and 2 for , respectively. We observe that, in the majority of the experimental scenarios, we achieve to have a number of tasks around the average. This reveals the good performance of our model that evenly distributes the incoming tasks while being adaptive to the updates in the load and the processing speed at the same time. In Fig. 14, we get , however, no significant differences in the performance are observed. Finally, the use of the Gaussian distribution seems to lead to better results compared to the use of the Uniform distribution. The proposed model seems to efficiently manage the very dynamic nature of the dataset produced through the use of the Uniform distribution.

We perform a set of simulations for revealing the realizations of 
, i.e., the mean 
. In Fig. 16, we present our outcomes. We observe that the increased number of nodes positively affects the performance of the proposed model. In this case, our model has more opportunities to detect the node with the lowest load. The use of the Gaussian leads to the best results and achieves a mean 
 below 0.10. Recall that  gets values in the unity interval. The aforementioned results can be combined with the boxplot of 
 presented in Fig. 8. We observe that the median is below the mean, thus, the 
 distribution is positively skewed (multiple values are below the mean). In any case, our results are below 0.20 which reveals the good performance of our scheme. In Fig. 17, we expose the performance of our model for 
, i.e., the mean of 
. We observe that 
 is around 0.60 which also depicts a good performance related to the selection of nodes with a high processing speed. These results combined with results presented in Fig. 11 can also reveal the skewness of 
 realizations. We observe that the median of 
 is above the mean, thus, the distribution is negatively skewed, i.e., multiple high values are above the mean.


Download : Download high-res image (191KB)
Download : Download full-size image
Fig. 15. The boxplot of  for .

Table 3 presents our results for the average similarity between the data requested by a task and the data present at the selected node. Recall that this similarity is depicted by 
. We conclude that 
 is not affected by the distribution or the number of nodes being around 0.50. The maximum 
 is retrieved for a high number of nodes, i.e., . We have to notice that an increased number of peers positively affects all the adopted performance metrics. This reveals the potential of the proposed model towards its scalability and its efficiency in large scale setups.


Download : Download high-res image (222KB)
Download : Download full-size image
Fig. 16. Our results for the 
 metric.


Download : Download high-res image (220KB)
Download : Download full-size image
Fig. 17. Our results for the 
 metric.

We proceed with the comparison of our UDM with other models found in the relevant literature. In Table 4, Table 5, we present our results for the 
 metric. Recall that the GBA model is the theoretical optimal scheme as it always selects the node with the lowest load. We observe that our model manages to reach the performance of the theoretical optimal model while it outperforms the remaining schemes. This is very significant taking into consideration that the UDM focuses on multiple parameters and not only one like the GBA or the GFP. We have to notice that the use of the Gaussian distribution leads to better results.


Table 3. Our results for the 
 metric.

N	Uniform	Gaussian
W  50	W  100	W  50	W  100
50	0.48	0.46	0.48	0.48
100	0.47	0.47	0.48	0.48
500	0.51	0.51	0.50	0.50
Similar results we get when focusing on the 
 metric (see Table 6, Table 7). Now, the theoretical optimal model is the GFP. Again, the UDM exhibits better performance than the GBA and the RTS while approaching the outcomes of the GFP. This reveals the potential of our scheme to deal with multiple parameters and achieve the best possible allocation. Recall that, in reality, it is very difficult to have an individual node exhibiting the best performance for all the adopted parameters at the same time. This is due to the dynamics of the environment where nodes act and their interconnection with multiple other entities sending data or asking for the execution of various tasks.


Table 4. Our comparison results for the 
 metric — Uniform distribution & .

N	
UDM	GFP	GBA	RTS
50	0.20	0.48	0.02	0.49
100	0.18	0.50	0.01	0.48
500	0.10	0.50	0.01	0.50

Table 5. Our comparison results for the 
 metric — Gaussian distribution & .

N	
UDM	GFP	GBA	RTS
50	0.15	0.28	0.01	0.53
100	0.12	0.22	0.01	0.48
500	0.08	0.15	0.01	0.50
In Table 8, Table 9, we present the outcomes of our comparative assessment for the 
 metric. Our UDM outperforms the remaining models no matter the distribution that is adopted to feed our parameters. The difference of the performance is higher in the Uniform case than in the remaining experimental scenarios. This means that the GFP, GBA & RTS models are negatively affected by the dynamic nature of the environment where nodes act and exhibit a ‘preference’ to more ‘stable’ experimental scenarios.


Table 6. Our comparison results for the 
 metric — Uniform distribution & .

N	
UDM	GFP	GBA	RTS
50	0.58	0.98	0.51	0.50
100	0.58	0.98	0.48	0.50
500	0.60	0.99	0.47	0.50

Table 7. Our comparison results for the 
 metric — Gaussian distribution & .

N	
UDM	GFP	GBA	RTS
50	0.62	0.99	0.58	0.50
100	0.60	0.98	0.57	0.50
500	0.61	0.99	0.58	0.51

Table 8. Our comparison results for the 
 metric — Uniform distribution & .

N	
UDM	GFP	GBA	RTS
50	0.48	0.37	0.36	0.36
100	0.47	0.36	0.37	0.37
500	0.51	0.38	0.37	0.38

Table 9. Our comparison results for the 
 metric — Gaussian distribution & .

N	
UDM	GFP	GBA	RTS
50	0.48	0.43	0.41	0.35
100	0.48	0.45	0.43	0.36
500	0.50	0.49	0.46	0.38
6. Conclusions
The IoT infrastructure provides a setting where novel applications can be developed upon a huge number of devices. IoT devices can interact with their environment and collect data transferring them, in an upwards mode, to Cloud. Recent advances in the IoT focus on the execution of processing activities at the edge of the network or at the IoT devices themselves instead of relying to Cloud in order to limit the time for retrieving results. The problem with this new approach is the computational limitations of IoT devices and edge nodes compared to the Cloud back end infrastructure. A solution is to incorporate an intelligent mechanism for processing tasks management at the edge. The target is to detect and allocate every task to the appropriate node, thus, to act efficiently and reduce the time for getting the final response. When tasks arrive, nodes should apply the discussed mechanism and deliver offloading actions when a local execution is not feasible. In this paper, we propose such a mechanism and try to model the uncertainty behind the decision making (the decision for an allocation). Nodes, in a distributed manner, sequentially decide where the incoming tasks will be processed. Our scheme applies a machine learning model and multiple heuristics to quantify the uncertainty about the status of edge nodes together with a rewarding mechanism. Finally, we are able to efficiently allocate the incoming tasks as exposed by our evaluation process. The advantages of our model are related to the maintenance of the autonomous nature of nodes avoiding to rely on a centralized approach as well as the detection of the most appropriate peer nodes where offloading actions take place. Additionally, the proposed scheme does not require extensive computational resources, thus, it can be easily applied in IoT and edge nodes. As a future research plan, we target to a more complicated scheme for modeling the uncertainty in our scenario with the involvement of fuzzy logic theory and advanced machine learning models.

