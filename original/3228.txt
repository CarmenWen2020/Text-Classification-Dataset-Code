Fog computing is an emerging computation technology for handling and processing the data from IoT devices. The devices such as the router, smart gateways, or micro-data centers are used as the fog nodes to host and service the IoT applications. However, the primary challenge in fog computing is to find the suitable nodes to deploy and run the IoT application services as these devices are geographically distributed and have limited computational resources. In this paper, we design the two-level resource provisioning fog framework using docker and containers and formulate the service placement problem in fog computing environment as a multi-objective optimization problem for minimizing the service time, cost, energy consumption and thus ensuring the QoS of IoT applications. We solved the said multi-objective problem using the Elitism-based Genetic Algorithm (EGA). The proposed approach is evaluated on fog computing testbed developed using docker and containers on 1.4 GHz 64-bit quad-core processor devices. The experimental results demonstrate that the proposed method outperforms other state-of-the-art service placement strategies considered for performance evaluation in terms of service cost, energy consumption, and service time.

Previous
Next 
Keywords
IoT

Fog computing

Multi-objective

Resource provisioning

Service placement

Containers

1. Introduction
The usage of the Internet of things (IoT) devices increased exponentially for all automated and smart applications. IoT enabled various devices such as cameras, sensors, and other mobile devices that are interconnected and communicating to achieve the goals collaboratively. It is predicted that over 75.44 billion IoT devices would be connected to the Internet by 2025, and these devices will generate an unprecedented amount of heterogeneous data called Big Data (Department, 2017) (Alavi et al., 2018). A centralized cloud is used for processing this big data where cloud can provide a substantial amount of computational and storage resources. But, using the centralized cloud for all IoT applications requires entire data to be transferred to the cloud for further processing, thus increases the network traffic and the service time for IoT applications (Simmhan) (Elazhary, 2019). The problems of using cloud computing for all real-time IoT applications are: high service delay, more resource requirement, and high service cost. Hence, cloud computing is not a feasible technique for delay sensitive IoT applications which require service in real-time (Varshney and Simmhan, 2017) (Hu et al., 2017). To overcome the problems of using a centralized cloud, Cisco developed a distributed computing platform called Fog computing or Fogging (Bonomi et al., 2012).

Nowadays, fog computing is the driving force for many delay-sensitive IoT applications such as smart health-care (Kumari et al., 2018), smart manufacturing industry environments 1 where a large number of IoT devices will be connected (Gheisari et al., 2020) (Rahimi et al., 2020). Fog computing is an intermediate intelligent layer between the cloud and IoT, thus ensures low latency for many delay-sensitive IoT applications by reducing the network traffic. Fog computing inherits most of the properties of cloud and provisions computational and storage resources at the edge of the network, thus provides the services for IoT applications in real-time. The devices such as a router, smart gateways (Aazam and Huh, 2014), or small independent server at the edge called Micro Data Center (MDC) are used as fog nodes for processing the data (Aazam and Huh, 2015). Therefore, the advantages of using the decentralized data processing by the network devices at the edge of the network are (Dastjerdi and Buyya, 2016) (Ray et al., 2019):

●
Reduces the processing time

●
Handles high volume of data

●
Provides the network heterogeneity, and

●
Reduces the network congestion.

The different virtualization techniques used for resource provisioning are Virtual Machines (VMs) and Containers. Resource provisioning using VMs is not adaptable in fog since VMs boot time is high, consumes more resources, and hosting more VMs in a single physical machine degrades the physical machine's performance. Thus using VMs in fog environment increases the service time for the delay-sensitive IoT applications. But, containers are the preferable lightweight virtualization technique used for resource management in a fog environment due to its fast startup time, reduces the resource management overhead and provides rapid and high scalability (Fayos-Jordan et al., 2020). Hence, docker and containers are used for developing the fog computing framework.

The smart manufacturing environment has heterogeneous sensors for monitoring the devices and generates vast data. We considered using fog in the industrial environment to process heterogeneous data to reduce the service time and avoid significant failures. Also, reducing the total energy consumption increases the lifetime of the battery-operated fog devices, increasing the reliability and availability of those devices in the industrial environment. This motivated us to formulate the service placement problem as the multi-objective optimization problem in the fog computing environment. But the primary challenge is to find suitable fog nodes (devices) that are distributed and vary significantly in terms of resource availability, data processing speed, and response/service time to host IoT applications and process the data. Hence, better service placement strategies are essential for the placement of IoT services in the fog computing environment such that the resource-constrained devices (fog nodes) are utilized efficiently (Chiu et al., 2018) (Lin et al., 2018). Therefore, the placement of application services on these resource constrained fog devices is referred to as an NP-hard problem (Brogi et al., 2020). Hence, we formulated the service placement problem as the multi-objective optimization problem to minimize the service time, service cost, and energy consumption in the fog computing environment. In this paper, we developed a two-level fog resource provisioning framework using docker and containers on devices with a 1.4 GHz 64-bit quad-core processor. Then, we consider a novel approach to solve the fog service placement problem.

The main contributions of our work in this paper are:

●
Designed a two-level fog resource provisioning framework using docker and containers to provide the resources and host the IoT application requests in the fog environment.

●
Formulated the service placement problem as the multi-objective optimization problem to minimize the service time, cost, and energy consumption in the two-level fog computing infrastructure and further ensure the Quality of Service (QoS) in terms of deadline and the service cost.

●
Solved multi-objective fog service placement problem using the Elitism-based Genetic Algorithm (EGA) in the fog computing environment and experimented on developed fog testbed using docker and containers on a cluster of 1.4 GHz, 64-bit quad-core processor devices.

The rest of the paper is organized as follows. Related Work is discussed in Section 2, Proposed Methodology is presented in Section 3, Experimental Results and Analysis is described in Section 4 and finally the paper is concluded with future directions in Section 5.

2. Related Work
In this section, the existing works on the fog infrastructure, service placement strategies are explained in detail.

Mahmoud et al. (2018) developed the fog enabled cloud of things architecture and then proposed an energy-aware based application module placement in the developed architecture for Smart Healthcare applications. The service placement decisions were made based on the energy consumption of fog devices. But, the service deadline and the service cost were not considered. Hassan et al. (2020) developed a heuristic approach for IoT service placement based on the network priority, energy consumption in the fog-cloud computing environment. They considered IoT applications with a maximum of two services and placed on fog and cloud. But, they did not consider the resources availability, service cost in the fog environment. Ramirez et al. (2017) presented the benefits of using the fog-to-cloud (F2C) continuum for servicing the IoT applications. F2C reduces service time, network congestion, and energy consumption. They proposed two resource allocation strategies (First-Fit and Random Fit) for solving the dynamic service placement problem in the fog-cloud environment. But, service cost and the QoS of the deployed applications were not considered.

Murtaza et al. (2020) developed an adaptive and intelligent task scheduling method on the fog-cloud environment to improve the QoS in terms of delay and energy consumption. They introduced a smart layer between the IoT and cloud to process the data using the learning-based policies. But, they did not consider the service cost and resources available in the fog computing environment for servicing the IoT applications. Kim and Chung (2018) designed the fog computing infrastructure referred to as the fog portal. Further, they proposed an optimal service instance placement in the fog computing environment based on user participation in the infrastructure. They formulated the service placement problem as a mixed-integer non-linear programming (MINLP) problem, and then it is linearized for optimizing the power consumption of the fog resources. But, they did not consider the available resource utilization and service latency. Zhang et al. (2018) formulated a controller placement problem as the multi-objective optimization controller placement to optimize network reliability, load balancing in the internet-oriented software-defined networking environment. Further, they developed an adaptive bacterial foraging optimization method to solve the optimization problem. But, they did not consider service placement in fog, service cost, and energy consumption in the fog computing environment.

Jia et al. (2018) developed a double matching strategy (DMS) for resource allocation in fog and cloud computing environments. The main objective of this approach is to allocate cost-efficient resources. But, they did not consider energy consumption, service time, and service deadline. Yang et al. (2018) developed a Lyapunov optimization technique for task scheduling in the fog networks to reduce energy consumption and the service delay. Further, they proposed the delay energy based task scheduling (DEBTS) to minimize the energy consumption in fog environment. But the heterogeneous fog nodes with resource constraints, service cost and QoS parameters were not considered. Yousefpour et al. (2018) developed a general architecture for cloud-fog-IoT. Further, they created a collaborative and offloading analytical model in the cloud-fog-IoT environment for minimizing the service delay. But, energy consumption, service cost, resource consumption, and QoS parameters were not considered.

Zeng et al. (2016) developed a software-defined embedded system for fog environment. They considered the workload balance on the computational server, task image placement on the storage server as the scheduling and resource allocation problems. They formulated these problems as the mixed-integer linear programming (MILP) models and thus solved the said problems by dividing them into subproblems. But, the energy consumption and service cost for IoT applications were not considered. Santoyo-González and Cervelló-Pastor (2018) proposed a heuristic-based simulated annealing method for solving the service infrastructure placement for 5G networks. They formulated the infrastructure placement problem as a MILP model. They solved the problem by using a hybrid simulated annealing approach to reduce the infrastructure deployment cost. But, the service placement and multi-objective optimization based service placement in the multi-level fog were not considered. Xavier et al. (2020) proposed a heuristic-based resource allocation strategy in the Cloud-of-Things environment. The proposed approach considers the heterogeneity of the devices at the edge and the cloud environment, collaboration between the edge and cloud for resource allocation to efficiently utilize the resources. But, they did not consider the multi-level fog, service cost, and energy consumption for servicing the IoT applications.

Souza et al. (2018) proposed algorithms for assessment of distributed service placement in the fog-cloud environment using the concept of service atomization. The services are atomized and distributed parallelly in both fog and cloud computing environments. They used the best-fit with and without queue for selecting the nodes in the fog-cloud environment to satisfy the service deadline. But, they did not consider the energy consumption and service cost in multi-level fog computing environment. Chen et al. (2020) developed a stackelberg game-based framework consisting of end-user and the mobile edge cloud as the follower and leader in the resource allocation framework, respectively. The resource allocation problem is decomposed into subproblems, and each subproblem considers the single type of resources for allocation and estimate the price. But, they did not consider the service delay, deadline, and energy consumption in the developed framework for resource allocation.

The key existing works are summarized in Table 1.


Table 1. Summary of key existing works.

Author	Optimization	ResourceAvailability	Service Time	Cost	Deadline	EnergyConsumption	Two-levelFog Testbed
Mahmoud et al. (2018)	Single objective	X	X	X	X	✓	X
Hassan et al. (2020)	Single objective	X	✓	X	X	✓	X
Ramírez et al. (2017)	Single objective	X	✓	X	X	✓	X
Murtaza et al. (2020)	Single objective	X	✓	X	X	✓	X
Zhang et al. (2018)	Multi-objective	X	✓	X	X	X	X
Yang et al. (2018)	Single objective	X	✓	X	X	✓	X
Yousefpour et al. (2018)	Single objective	X	✓	X	X	X	X
Xavier et al. (2020)	Single Objective	✓	✓	X	X	X	X
Chen et al. (2020)	Single objective	✓	✓	X	X	X	X
Souza et al. (2018)	Single onjective	✓	✓	X	X	X	X
Proposed EGA	Multi-Objective	✓	✓	✓	✓	✓	✓
3. Proposed Methodology
In this section, the Two-level fog computing framework, Multi-objective optimization problem formulation, and the Elitism based Genetic Algorithm for service placement in a fog computing environment are discussed in detail.

3.1. Fog computing framework
Fog computing is defined as the decentralized computing architecture for processing the data at the network level using smart gateways, router, and micro-data centers as the fog nodes combined with the advantages of cloud and virtualization techniques. We considered and developed the two-level fog framework for provisioning the resources using docker and containers. Thus, fog computing provides the computational and storage resources close to the data source node (Aazam et al., 2018).

Fig. 1 shows the fog computing architecture considered for provisioning the resources to process the IoT data. The lower layer consists of the physical sensor nodes and actuator devices. The middle layer contains the fog nodes generally considered as networking devices or independent servers such as MDC. We use this fog infrastructure to provide the resources and place the service on the fog nodes. The two-level fog infrastructure consists of Fog Master Node (FMN) and Fog Cell (FC). FMN is responsible for continuous monitoring of the topology and deciding the placement of the services based on the designed service placement strategies. FC is the independent node that provides the computational resources and hosts the service. Fog cells process the data and send back the response to actuators and transfer the data to the upper layer for further processing if required.

Fig. 1
Download : Download high-res image (475KB)
Download : Download full-size image
Fig. 1. Fog computing architecture.

FMN consists of Fog Cell Registry; it registers the fog cell once entered into the topology and also monitors the FC. The host monitor is responsible for continuous monitoring of the available and used resources in the fog nodes. The host monitor controls the status of available resources in FCs and helps to decide the placement of services. Fog Cell Controller is responsible for dynamic topology controlling and monitoring the FCs; therefore, any FCs can be added and used to deploy the services dynamically in the fog infrastructure. Fog service registry performs the registering of the services to be deployed and also responsible for the placement of services on the fog nodes based on the service placement algorithm.

Fog Cells: Fog Cells are the nodes that provide the computing resources and hosts the applications. The components of fog cells are shown in Fig. 2. The applications are decomposed into multiple independent services and these services are deployed on the fog cells based on the available computing resources. The controlling component present in the FC is responsible for managing the usage of resources and deployment of services. The IoT data is processed in the fog environment and then the decision control signals are transferred to the actuators to take the action based on the control signal. Thus, using the fog computing environment reduces the service time to service the IoT applications in real-time.

Fig. 2
Download : Download high-res image (220KB)
Download : Download full-size image
Fig. 2. Fog Cell architecture.

3.2. Service placement problem formulation
3.2.1. Resource constraints
The placement of services on the fog node depends on the dynamic usage and availability of computational resources in the fog nodes. The services hosted on a fog node consume resources such as CPU, RAM, and storage. Thus, the resource demands of the deployed services on these fog nodes must not exceed the fog nodes’ available computational resources since these fog nodes have limited computational and storage resources. The following equations give the resource constraints for the fog environment, and the placement of services on the fog nodes should satisfy the resource constraints of each service request, as defined by Eq. (1). Table 2 shows the list of mathematical notations used in this paper.
 (1) 
 (2)
 


Table 2. List of notations.

Notations	Description
SM	set of all services
FN	set of all fog nodes/devices
tpro	processing time in seconds
tcom	communication time in seconds
tav	service availability time in seconds
Tt	Total service time in seconds
Dd	service deadline in seconds
ssize	service size
size of service request
size of service response
γj	processing capability of a fog node j
βf	bandwidth between nodes in Mbps
λin	input rate/arrival rate of service requests on fog node
Ctotal	total service cost in $
Cmax	maximum service cost in fog given in $
Cec	energy consumption cost of fog node given in $
Cpro	processing cost in fog environment given in $
Csto	storage cost in fog environment given in $
required amount of processing resource (in mips per request)
unit cost in $ for processing resource in mips at fog node
unit cost in $ for storage resource at fog node (per byte per second)
unit cost in $ for energy consumption per joule in fog environment
amount of storage resource used in fog node (in bytes)
Emax	maximum energy consumption in joules
total energy consumption of fog nodes in joules
energy consumption of fog node j in joules
energy consumption during transmission in joules
energy consumption during processing in joules
power consumption of fog node in idle state in watts
Ptrans	maximum power consumption during transmission in watts
Pproc	maximum power consumption during processing in watts
time	total time duration in seconds
A set of all applications (services) SM requests for resources (RAM, CPU, storage) and to decide for placement of these services we should ensure that the total available resources on the fog nodes denoted by fj should be more than the resource requests by the IoT service. The allocation of the services on the fog nodes is indicated by Eq. (2), xij = 1 if service is placed on the fog node else, xij = 0.

3.2.2. Service time and energy consumption
The service time is defined as the sum of processing, communication, and service availability time for the services in the fog computing environment given by Eq. (3). The processing time tpro depends on the service size (data size) 
 and the processing capacity of the fog node γj given by Eq. (4).(3)
(4)
 
(5)
 

The communication time tcom is defined as the total time involved for transferring the service request to fog nodes and response back to the actuators. tcom depends on the service size (data size) and the link capacity βf connected between the nodes as shown by Eq. (5). The service availability time tav involves the time taken for selecting the fog node to deploy the services and data. Also, it depends on the total time of the service request in the waiting queue to get the selected fog nodes’ computational resources. Thus tav depends on the amount of time it takes for completing the current service request. The total service time calculated for each of the services should be less than the service deadline defined for the application requests, as given in Eq. (6).(6)

Let us assume that the fog node is in the idle state when it is not hosting any services but consumes some amount of energy during the idle state. The energy consumption of the fog node during active state while hosting/running some services is calculated (Tang et al., 2018) (Jalali et al., 2016) (Murtaza et al., 2020). The total energy consumption of the fog nodes for servicing the IoT application services is defined by Eq. (7). The fog node's energy consumption is defined as the sum of the energy consumption during the transmission of data and the energy consumption during the processing of the services defined by Eq. (8). Eqs. (9), (10) define the energy consumption during the transmission and processing of the application, respectively.(7)
(8)
(9)
 
(10)
 

The energy consumption depends on the maximum power consumed by the fog node per unit time for transmitting and processing the whole data defined by Eqs. (9), (10), respectively.

3.2.3. Service cost
The service cost for the IoT applications deployed on the fog node is defined as the sum of processing cost, storage cost, and energy consumption cost in fog infrastructure given by Eq. (11).(11)

The processing cost for the service depends on the amount of CPU/MIPS used for processing the application service request, and the arrival rate of the service request on the fog nodes is given by Eq. (12). The storage cost depends on the amount of memory used for storage and the size of the service request, as defined by Eq. (13).(12)
(13)

The fog infrastructure's energy consumption cost depends on the amount of energy consumed by the fog nodes and the time duration. The energy consumption cost is calculated as the product of total energy consumed and the cost of the unit energy consumption in the fog infrastructure as defined by Eq. (14).(14)

3.2.4. Problem formulation
Let us consider a set of available fog nodes denoted by FN = {f1, f2, …..fN} and a set of all services to be deployed on the fog nodes denoted by SM = {s1, s2, … … sM}. Our objective is to find the fog nodes for optimal service placement such that we can minimize the service time, service cost, and energy consumption for the IoT applications in the fog computing environment. Hence, in this work, we formulated the multi-objective optimization functions for placing the services in the fog computing environment. The formulated multi-objective optimization functions are given by Eqs. (15), (16), (17), (18).(15)
(16)
(17)
(18) 
 

The constraints defined for the said multi-objective functions are as follows:

●
Total service time for the IoT application should be less than the service deadline defined for the deployed IoT application.

●
The service cost should be less than the maximum service cost defined for the said application.

●
The energy consumption should be less than the maximum energy consumed by the fog nodes.

●
Each service request for the resources and placement decision should satisfy the resource requirement defined by Eq. (1). The service should also be placed only on one fog node in the fog computing environment.

3.3. Service placement algorithm
The service placement problem in the fog computing environment is solved by using the Elitism based Genetic Algorithm (EGA). Using Elitism based GA passes the first best or few best chromosome from the current generation to the next generation, thus it avoids random destruction of the best chromosome after crossover and mutation operation. Using elite chromosome we can preserve the degeneration of the population and the premature convergence. Hence, we considered Elitism-based GA over the traditional GA for service placement in the fog computing environment. The important operations involved in the Elitism-based Genetic algorithm are Fitness evaluation, Selection of Elite chromosome, Crossover, and Mutation. In this paper, we assumed that the length of the chromosome is equal to the number of services, and the values (genes) represent the fog node number.

Algorithm 1 shows the complete steps involved for service placement in the fog environment. The initial population is considered randomly, where each chromosome represents the possible solution of service placement in the fog computing environment. After generating the initial population, the fitness value is calculated for each of the chromosomes by using Eq. (19). We considered the fitness function as a fraction of the sum of the service time, cost, and the total energy consumed. These are multiplied with constant weights of 
 
, which depends on the number of objective parameters in the optimization model.(19)
 


Algorithm 1. EGA: Elitism-based Genetic Algorithm for Service Placement in the Fog Computing Environment

Input: Set of all Services SM = {s1, s2, …..sM}
Set of all Fog Nodes FN = {f1, f2, … … … … fN}
Output: service_allocation_list ← [ ]
1: Initialize: crosssover_probability (Pc) ← 0.5, mutation_rate (Pm) ←0.3
2: num_generation ←250, elitism_rate ← 0.08, population ←100
3: population ← Generate Population Randomly()
4: fitness ← Calculate Fitness(population) using Eq. (19)
5: elite_list ← Sorted(fitness, population,elitism rate)
6: service_allocation_list ← best individual
7: rem_population ← (population - elite_list)
8: while num_generation do
9: parent1, parent2 ← selection operation(rem_population)
10: child1, child2 ← crossover operation(parent1, parent2, Pc)
11: newchild ← mutation operation(child1, child2, Pm)  Apply Mutation operation on the new child chromosomes
12: new_population ← elite_list ⋃ newchild
13: fitness ← Calculate Fitness(new population) using Eq. (19)
14: elite_list ← Sorted(Fitness, new_population, elitism rate)
15: rem_population ← (new_population - elite list)
16: service_allocation_list ← best individual
17: end while
18: return service_allocation_list
3.3.1. Selection operation
We used the elitism concept to select the best individual to the next generation directly without performing the operations such as crossover and mutation. Using elitism avoids the loss of the best individual after crossover and mutation operations and speeds up the Genetic Algorithm's performance. The elitism rate for selecting the best individual to the next generation should be less thus it avoids the degeneration of the population. Hence, in this work, we initially sort the population based on the fitness value and select 8% of the population as the elite chromosomes and pass them to the next generation.

3.3.2. Crossover operation
The crossover operation is performed on the remaining population to obtain the offsprings for the next generation. We use a single-point crossover operation on the two-parent chromosomes to produce the new offsprings from the remaining population hence, find the best feasible chromosome for the next generation. The single point is selected on both the parent chromosomes and values (genes) after the point are swapped between the two parents to obtain the new offsprings. Fig. 4 (a) and (b) shows the chromosome before and after the single point crossover operation, respectively.

Fig. 4
Download : Download high-res image (235KB)
Download : Download full-size image
Fig. 4. Crossover operation.

3.3.3. Mutation operation
Mutation operation is performed on the new offspring chromosome to mutate the one or more genes in the original chromosome to obtain the new chromosome. Thus, the mutation operation on the chromosome preserve the diversity within the population and the premature convergence. In our work we replace the gene using random value within the range of number of fog nodes [1,N] to perform the mutation operation on the chromosome. The example for, the mutation operation on the chromosome, is shown in Fig. 5.

Fig. 5
Download : Download high-res image (164KB)
Download : Download full-size image
Fig. 5. Mutation operation.

The above procedure continues until the maximum number of generations considered and returns the best individual chromosome after that. The best individual chromosome represents the possible optimal solution for the placement of application service requests on the fog node to optimize the energy consumption, service cost, and service time, thus ensuring the QoS of IoT applications.

4. Experimental results and analysis
The details of the proposed algorithm's Time Complexity, the hardware, the software required for Experimental Testbed setup, the type of IoT applications considered for performance evaluation, the experimental results, and the statistical hypothesis analysis for the proposed algorithm are given in this section.

4.1. Time complexity analysis
Time complexity of the Elitism based Genetic algorithm (EGA) depends on the number of generations, population size and the operations: Fitness evaluation, elitism operation, Selection of elite chromosome, Crossover and Mutation. The time complexity is calculated as O(Generations∗(O(Fitness Evaluation) + O(sort operation to select elite list) + O(selection operation) + O(Pc∗Crossover Operation) + O(Pm∗Mutation Operation)), where Pc and Pm are the probabilities of crossover and mutation rate considered for the evaluation, respectively. For updating the elite chromosome, we initially sort the chromosome based on the fitness value and the time complexity for sorting algorithm used is O(NlogN). The time complexity for the Elitism-based Genetic Algorithm is represented as O(G∗(O(N) + O(NlogN) + O(NM) + O(Nm) + O(Pc∗Nm) + O(Pm∗m))), where, G is the number of generations, N is the size of the population, M is size of the chromosome and m is the subset of population chromosome selected after the selection operation. If the Pc and Pm values are considered as constant values then the overall time complexity of the Elitism-based Genetic Algorithm is O(G(N∗M + NlogN)).

4.2. Experimental Testbed setup
We used 1.4 GHz 64-bit quad-core processor devices to build the fog-testbed infrastructure and run the developed service placement strategies. All these fog devices run Hypriot 2 a lightweight operating system for low computing power devices that supports the built-in docker.3 Fig. 6 shows the fog testbed infrastructure developed for performance evaluation.

Fig. 6
Download : Download high-res image (489KB)
Download : Download full-size image
Fig. 6. Testbed for performance evaluation.

The different technologies used to develop the fog computing framework to provision the computational resources to host and run the IoT applications.

Redis Database: Redis 4 is open source, light weight, fast and easily deployable on the devices. Both the FMN and FCs runs the Redis database instances. In the fog nodes, two types of Redis database instances are used: local and shared. The local Redis instance is used in FCs. Both local and shared Redis database instances are used in the FMN. The local instance in both FCs and the FMN is used to store the fog node/cell configuration information, IP address, and also the total resource utilization statistics of the fog node. The deployable IoT service images and services output data are stored in the shared Redis database instance of the FMN.

Celery: We use Celery5 to monitor and get the heartbeats of the fog nodes in the topology to check whether the status of the node is alive or not. The resources’ usage is continuously monitored for both the fog master and cell nodes. In the fog framework, resource provisioning is decided based on the availability of the computational resources, and FMN avoids service placement if the available resources are insufficient to satisfy the service resource requests. The Celery worker instances are present in both the FMN and fog cell nodes. The Celery worker in FMN triggers fog cells to download data & service images from the shared database, and the Celery present in fog cell will execute the deployed service requests on the fog cells.

REST is the main factor which enables the communication in micro-services architecture due to various light software component footprint present in the docker. We used the Flask python framework in our developed testbed for communication purposes due to its minimalistic features. Power meter is used for measuring the energy consumption of the fog devices in the testbed with input capacity of 240 V, 50 Hz, 20 A.

4.3. Applications
The IoT applications such as the smart building, smart manufacturing industry (Industry 4.0) and smart healthcare (Kumari et al., 2018) deploy more number IoT devices to monitor and control the environment; which continuously sense and generate a huge data. Processing this vast data at the fog environment reduces the service time and provide service in real-time. We considered evaluating the performance of the proposed service placement algorithm in the fog computing environment for the master-worker IoT application model, which consists of a set of independent modules. We considered using fog nodes in the industrial environment to process heterogeneous data to reduce the service time and avoid significant failures. Also, reducing the total energy consumption increases the lifetime of the battery-operated fog devices thus, increasing the reliability and availability of those devices in the fog environment. An IoT application includes separate modules/services which perform some operation and then send back the response to the actuators. Based on the application scenarios, each IoT application is represented in the form of a directed graph (Mahmud and Buyya, 2019). We considered the sensor data from Melbourne city 6 which consists of sensor readings such as the temperature, humidity, and light. We continuously read these values and accordingly find the average, minimum, and maximum values of each data type and then decide to send the control signal information to the actuators.

4.4. Results and analysis
The performance of the developed EGA algorithm is compared with the existing state-of-the-art DMS (Jia et al., 2018), DEBTS (Yang et al., 2018), GAPSO (Yadav et al., 2019) and the two baseline algorithms, namely: First-Fit (FF) and Branch & Bound (BB) algorithms for service placement in the fog computing environment. We experimented on the developed testbed for these service placement algorithms and evaluated the performance of each algorithm. The First-Fit algorithm considers the availability of the computational resources and allocates the services on fog nodes. But, First-Fit does not consider the optimal allocation, and hence it reduces the efficiency by underutilizing the available limited computational resources. Thus it increases the service time, service cost, and energy consumption in the fog computing environment.

On the other hand, Branch & Bound algorithm allocates the services on the fog nodes. As the number of services and the fog nodes in the topology increases, the service time increases exponentially, thus maximizing the service cost and energy consumption in the fog computing environment for servicing the IoT applications. The service placement strategies such as DMS, DEBTS and GAPSO are not optimal as it takes more time to provide the service and thus not suitable for the delay sensitive IoT applications. Hence to overcome these problem, we formulated a multi-objective optimization problem and proposed EGA such that it allocates the services optimally to reduce the service time, service cost, energy consumption and thus utilizes the computing resources efficiently in the fog computing environment.

We varied the number of service requests from 200 to 1000. These service requests are generated using uniform distribution and then deployed on the developed two-level fog computing framework using different service placement strategies. The experimental results show that the proposed EGA approach minimizes the service time, service cost, and energy consumption for servicing the IoT applications in the fog computing environment.

The experimental parameters considered during the performance evaluation for the proposed EGA approach are given in Table 3. We experimented five times to evaluate the performance of the proposed EGA based service placement with state-of-the-art service placement algorithms, and the average results of the experiment are presented. We experimented with the proposed EGA approach for the different number of generations varying from 50 to 300 in steps of 50 and different mutation rate from 0.1 to 0.3 in levels of 0.05, and we found that the value of the fitness function unchanged after 250 generations as shown in Fig. 7 and for mutation rate of 0.3. Hence, we considered a mutation rate of 0.3 and the number of generations to 250 for the proposed EGA approach.


Table 3. Experimental parameters.

Parameters	Values
Number of Services	200–1000
Number of Generation G	250
Population Size N	100
elitism_rate	0.08
Crossover_Probability (Pc)	0.5
Mutation_rate (Pm)	0.3
Fig. 7
Download : Download high-res image (132KB)
Download : Download full-size image
Fig. 7. Fitness value vs Number of Generations.

We considered service time, energy consumption, service cost and the average CPU utilization of the fog nodes, as the metrics for evaluating the performance of the different service placement strategies on the developed fog infrastructure testbed. The service time for the IoT application in the fog computing environment is evaluated for different service placement algorithms. The performance of the different service placement strategies in terms of service time and the energy consumption is shown in Fig. 8. The service time for different service placement algorithms considered for performance evaluation is shown in Fig. 8 (a). From Fig. 8 (a), it is observed that the service time for EGA is very small as compared to other placement strategies for servicing the IoT applications in the fog computing environment.

Fig. 8
Download : Download high-res image (719KB)
Download : Download full-size image
Fig. 8. Performance Evaluation for proposed EGA on developed Fog Testbed.

Energy optimization in the fog computing environment is one of the significant issues as these IoT devices are battery-operated. Hence, reducing the total energy consumption will increases the reliability and availability of the fog computing infrastructure. The total energy consumed by the fog nodes depends on the service time of the deployed applications in the fog computing environment. The energy consumption of the fog nodes is measured using Power Meter connected to the infrastructure. The total energy consumption during the fog nodes’ idle and active states while hosting some services is measured for different service placement algorithms. The total energy consumed by the fog nodes in the testbed for various service placement algorithms is shown in Fig. 8 (b). It is observed that the EGA approach utilizes the resources optimally and thus reduces the total energy consumption of the fog nodes in the fog computing environment as compared to other service placement algorithms considered for performance evaluation.

Service cost and average CPU utilization of fog nodes for the different service requests are evaluated by considering the different service placement algorithms in the fog computing environment. We found that using EGA for service placement on the fog computing nodes to deploy the applications will reduce the service costs. Using fog nodes for deploying the applications which satisfy the resource requirement and the service deadline provides the service in real-time and thus reduces the service cost. Fig. 9 (a) shows the cost for the different service requests for the various service placement algorithms. It shows that the total cost for servicing the IoT application using the EGA service placement algorithm is less when compared to other placement algorithms considered for the performance evaluation. Fig. 9 (b) shows the average CPU utilization of fog nodes for different placement strategies in the fog environment. Among these placement strategies, it is observed that EGA considers the optimal allocation of the services on the fog node and the resources are efficiently utilized as compared to other service placement strategies.

Fig. 9
Download : Download high-res image (886KB)
Download : Download full-size image
Fig. 9. Performance Evaluation for proposed EGA on developed Fog Testbed.

4.5. Statistical hypothesis analysis
We carried out the statistical hypothesis testing for the proposed EGA algorithm compared with the other methods for the service placement in the fog environment. We considered the T-test analysis for the service placement in the fog environment. We carried out the T-test for the proposed EGA method and the other state-of-the-art methods for service placement in the fog computing environment. The results of the T-test analysis are shown in Table 4. For the null hypothesis, we consider the threshold value of p or the significance level denoted by α. The widely adopted arbitrary value of α = 0.05 is considered.From this hypothesis analysis, we found that the value of p for the benchmark methods is less than the threshold value of α, as shown in Table 4 and thus rejects the null hypothesis. Hence, our proposed EGA based service placement algorithm is found to be the better approach for IoT service placement in the fog computing environment as compared to the other state-of-the-art service placement strategies considered for the performance evaluation.


Table 4. p-values for T-test analysis.

Metric	Algorithms	p-Values
Service Time	First-Fit - EGA	0.0227
Branch & Bound - EGA	0.0325
DEBTS - EGA	0.0365
DMS - EGA	0.0256
GAPSO -EGA	0.0287
Service Cost	First-Fit - EGA	0.0268
Branch & Bound - EGA	0.0325
DEBTS - EGA	0.0315
DMS - EGA	0.0255
GAPSO -EGA	0.0373
Average Energy Consumption	First-Fit - EGA	0.0312
Branch & Bound - EGA	0.0365
DEBTS - EGA	0.0395
DMS - EGA	0.0315
GAPSO -EGA	0.0261
Average CPU Utilization	First-Fit - EGA	0.0241
Branch & Bound - EGA	0.0221
DEBTS - EGA	0.0253
DMS - EGA	0.0325
GAPSO -EGA	0.0365
5. Conclusion and future work
Fog Computing is the most suitable computing architecture for delay-sensitive IoT applications to process data at the edge of the network and provides service in real-time. In this work, we developed a docker and containers based two-level fog infrastructure to provide the resources. We then formulated the fog service placement problem as a multi-objective optimization problem to ensure the QoS of IoT applications. Further, we solved this optimization problem using the Elitism-based GA (EGA) service placement algorithm. We investigated different service placement strategies for IoT applications in the fog computing environment. We then experimented on the fog infrastructure testbed developed using the docker and containers on the cluster of 1.4 GHz 64-bit quad-core processor devices. The experimental results demonstrate that the proposed EGA performs better than the other state-of-the-art service placement algorithms conisdered for performance evaluation in terms of service time, energy consumption, service cost, and average CPU utilization of fog nodes. But, one of the limitations of the work is we have not considered the interdependent IoT applications to check the performance of the proposed EGA on the developed fog testbed. In future work, we address the limitations and combine evolutionary algorithms to build a hybrid approach for solving the fog service placement problem, load balancing, service migration, and handling device failures in the fog computing environment.

