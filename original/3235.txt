User trust is an important factor in the success of recommendation systems, including Internet of Things (IoT)-based recommendation systems. However, such trust can be eroded in many different ways (e.g., unauthorized data modifications). Several privacy-preservation schemes have been designed for specific data and/or require strict assumptions (e.g., a private/secure communication channel between client-server and third-party authentication). However, these may limit their application in practice. Hence, in this paper we propose the Reversible Data Transform (RDT) algorithm based privacy-preserving data collection protocol. Our protocol allows us to achieve privacy preservation against beyond the scope processing and does not require a private channel or rely on a third-party authentication. Due to group formation, the disclosure probability of the internal disclosure attack will not be greater than 1/. Similarly, the reversible privacy-preserving data mining approach protects beyond the scope processing. Findings from the experimentation demonstrates the utility of the proposed protocol and its potential to be deployed in a mobile app recommendation system.

Previous
Next 
Keywords
Mobile app recommendation system

Privacy-preserving protocol

Data collection

Social-influence

Reversible integer transform (RIT)

Internet of Things (IoT)

1. Background
Recommendation systems (RS), a sub-class of information-filtering systems, take as input data-owners’ data in order to inform service or product recommendation based on some predicted ratings and preferences. The task of recommendation systems becomes more challenging as the volume, variety, velocity, veracity of data, say from Internet of Things (IoT) devices, increase (Mohammadi et al., 2019, Felfernig et al., 2019; Costa-Montenegro et al., 2012, El Khaddar and Boulmalf, 2017). In this paper, we broadly define IoT devices to also include smartphones which are used to collect various information (e.g., user input information and information from the device's surroundings such as locations) to inform service or product recommendation (Frey et al., 2015, Twardowski and Ryzko, 2015, Ju et al., 2019).

There are a number of risks associated with RS, including the generation of fake or misleading data (Lam et al., 2006, Chamorro-Vela et al., 2017, Wang et al., 2015). In addition, there have been attempts by the platform operator, service or product providers, or some third-party entity, to collect more private data from the data holders than required, for various purposes (e.g., marketing and user profiling). Such private data include search terms, app installation log, app usage frequency, call detail record (CDR), and data holder's social and relationship information. There are security and privacy implications, such as data leakage and user profiling. Thus, existing recommendation techniques use different cryptographic approaches to protect against external adversaries. However, mitigating the risk from a malicious insider is generally less of a focus. Therefore, we need trust models to be corporated into such RS, for example to distinguish malicious or dishonest devices / nodes from honest devices / nodes (Mohammadi et al., 2019, Su et al., 2018, Kumar and Patel, 2014). Given the popularity of IoT devices (broadly defined to include mobile devices), we focus on mobile recommendation system (MRS) model in this paper.

1.1. Recommendation systems
The RS, including MRS, allows the platform operator is to make customized recommendations to targeted user groups (e.g., users searching for a specific product or service, or fit a certain profile) by employing the most efficient approaches on collected records (Twardowski and Ryzko, 2015). Fig. 1 depicts an example personalized RS, which comprises users (data holders) and recommender servers (data collectors). The data holders have some personal records on their local devices (e.g., mobile devices, IoT devices such as a smart home hub device) which indicate their interests / preferences. The recommender servers collect data holders’ records, process these records, and provide personalized recommendations. In this paper, MRS is loosely defined to include RS that involve the use of mobile devices, for example in RS that focus on movie recommendations, hotel recommendations, and points of interest (POI).

Fig. 1
Download : Download high-res image (217KB)
Download : Download full-size image
Fig. 1. An example recommendation system model.

Different MRS models use different recommendation algorithm, such as those based on social influence score. This influence score can be calculated using calls and SMS frequency, as discussed in Chamorro-Vela et al., (2017), which uses app usage frequency as user preferences. Assume that these MARSs collect data holders’ records with the schema: data holder Id, data holder friends Id, data holder-SMS frequency record, data holder call-record- frequency, data holder-app-install-log, data holder-app-usage frequency. Schema attributes can be classified into identifiers (ID), quasi-identifiers (QI), and sensitive information (SI). An example of a single data holder record is shown in Table 1.


Table 1. Single data holder record.

Data holder-ID: 03003400484
App-list (QI)	Frequency (SI)	Friends-id (ID)	C- frequency (SI)	SMS-frequency (SI)
Whatsapp	115	30010000000	23	34
Youtube	56	30034000000	32	44
Gmail	34	30015500000	45	32
Google	46	30010004400	23	12
Camera	57	30010000550	12	0
Video	37	30010066000	4	12
S Planner	22	30010003330	21	45
Email	26	30451000000	10	4
Phone	23	32110000000	6	1
Gallery	59	30210000000	14	66
Maps	23	03456777777	5	5
Play store	22	03456774444	3	2
1.2. Security and privacy concerns
The recommendation process is vulnerable to a broad range of security and privacy threats, partly because of the presence of sensitive information. Xu and Yan, (2016), for example, discussed phase-wise privacy and security risks associated with MRS. Table 1 also outlines some of these privacy breaches, which also include threats due to external and internal attackers (Kim and Chung, 2017). In an internal identity disclosure breach, the server can identify/relate the individual records, say by using the data holder's id. In the inference attack, a server can analyze information such as data holder's records, and identify different traits related to the data holders. For example, an analysis of the mobile app installation log can reveal many facts about data holders, including age, gender, income, religion, relationship status, spoken languages, countries of interest, whether the data holder is a parent, etc. Similarly, the final recommendation list, app usage, and interaction information (SMS and call frequencies) can be used to infer data holder preferences in terms of products and other contacts.

In external identity disclosure breach, network packet headers can potentially be used to identify data holder records. These headers are added as a payload when the network is used to deliver “data records” to the server (Kim and Chung, 2017). The header function can be attackers launching an attack on the transmission or storage medium. Here, we assume that the server is trusted but curious and due to this assumption, other privacy breaches during data collection (e.g., unauthorized data collection / provision / sharing) are less likely.

Other than the above-mentioned attacks, MRS may be vulnerableto attacks targeting the system or data holder, and the recommender can act maliciously or intentionally provide invalid content (Lam et al., 2006). The three main architecture styles for MRS are client-server, peer-to-peer, and distributed recommenders. The security concerns for classical client-server architecture include man-in-the-middle attacks, successful RS compromises , denial of service attacks, and so on. Similarly, other architectural styles have various and/or overlapping privacy and security concerns, such as those due to malicious data holders and dishonest server providing invalid data to sabotage the recommendation prediction (also known as shilling or profile injection attacks). In a shilling attack, the attacker injects positive (push) or negative (nuck) ratings against targeted items to achieve one of the following goals: to improve the prediction rate or reduce the prediction rate for targeted items. These attacks have been extensively studied in recent years and there are different types of bias attacks, but the common ones are random attacks, average attacks, power data holder attacks, and, bandwagon attacks (Lam et al., 2006).

To mitigate these privacy and security issues, the research community have presented different solutions (Polatidis et al., 2017, Zhang et al., 2017, De Cristofaro et al., , Liu et al., 2015, Xu et al., 2018, Zhang et al., 2016, Stirbys et al., 2017), and such techniques can be categorized into two classes (Wang et al., 2018). These two classes are 1) cryptographic-based privacy-preserving approaches (e.g., homomorphic encryption (Xu et al., 2018)) and, 2) data obfuscation-based privacy-preserving approaches (e.g., dummy insertion or third-party authentication / anonymization (Polatidis et al., 2017)). However, these existing techniques allow only very specific strategies to protect some specific data and strict assumptions are required between the data holder (clients) and data collectors (server) for establishing the private channel(s). Similarly, third-party authentication / anonymization is not a feasible solution for every scenario. In the case of direct communications between client-server, different cryptographic protocols have been proposed. Conversely, there is a paradox that the server must not distinguish the content of the individual record (Kim and Chung, 2017) where, in MRS, the recommendation process depends upon the content.

1.3. Our contributions
To mitigate the limitations in existing privacy-preservation models, we propose a Reversible Data Transform (RDT) based privacy-preserving data collection protocol that leverages the distributed and collaborative features in MRS. To the best of knowledge, the applicability of RDT based data collection protocol in the domain of IoT based recommendation has yet to be explored in the literature. Our proposed solution not only provides security against internal and external identity disclosures . breaches, but it also achieves privacy-preservation beyond scope processing.

We organized the rest of this paper as follows. In Section 2, we will discuss the related work. In Section 3, we will present the preliminaries, prior to describing our proposed approach in Section 4. In Section 5, we describe our evaluation setup and findings, followed by the conclusion in Section 6.

2. Related work
Existing privacy-preserving techniques can be categorized into cryptographic-based privacy-preserving approaches (e.g., homomorphic encryption and garbled circuits (GCs)) and, 2) data obfuscation-based privacy-preserving approaches (e.g., dummy insertion or third-party authentication / anonymization) (Wang et al., 2018, Seliem et al., 2018). Here, the application of these privacy models in existing MRS can be categorized into context-based (Chamorro-Vela et al., 2017), preferences-based (Cao et al., 2017), and social influence based (Wang et al., 2015) as discussed by Cao and Lin, (2017). We did not find any model related to privacy-preserving data collection in MRS.

2.1. Privacy solution in context-based MRS
Different solutions are available to cater to the privacy issues in context-based MRS especially; protection mechanisms against context and location-related privacy issues. In Polatidis et al., (2017), privacy-preserving using dummy insertion approach in context-based mobile movie recommendation have been discussed. In this technique, privacy-preserving data is prepared first at the client-side and then transmitted to the server for the recommendation process. At the client-side, dummy values are generated against each contextual variable and then the values are combined with the original ones at the time of recommendation request. At the server-side, the server processes dummy and original values both and generate relevant recommendations. When these recommendations are received at the client-side, dummy recommendations are omitted and the final original recommendations are prepared for the data holder.

In Stirbys et al., (2017), the authors categorized different social apps that utilized contextual information and then analyzed the trade-offs of privacy and functionality in terms of privacy-preserving location proximity (PPLP) protocols. In Zhang et al., (2017), they firstly calculate the temporal correlation between data holders’ contexts and then represent that problem as an optimization problem. Further, they optimized the running time by converting the original optimization problem to an approximate optimal problem. They tested the proposed method on the reality mining dataset (MIT reality mining dataset) and calculated a δ-privacy parameter for three different scenarios and generated better results than that of existing techniques. In Zhang et al., (2016), the authors discussed the context protection mechanism in which they used a time-homogeneous semi-Markov model. In their proposed method, they reduce the storage and computation consumption while capturing the temporal correlations among contexts of a data holder.

2.2. Privacy solution in preference-based MRS
Privacy-preserving techniques for preference class have been discussed in Xu et al., (2018). Data holders’ preference can be calculated based on the existing app-install log and from usage patterns. In Xu et al., (2018), the authors have proposed homomorphic encryption and Shamir threshold protocol based privacy-preserving approach for mobile app recommendation. In this, trust values (calculated based on app usage behavior) are used to prepare the relevant recommendation list for the target data holder. The trust values are calculated at the client-side and then send to the server. To send these values and other related information they proposed two privacy-preserving schemes. In their centralized privacy-preserving scheme, they introduced a third-party authentication server and used Homomorphic encryption to encrypt the trust values. In their distributed privacy-preserving scheme, they generated secrete (could be a password) using the Shamir threshold protocol. In their proposed scheme, they assumed a secure channel between client-server.

In Zhu et al., (2016), the authors discussed the privacy-preserving approach which combined both data holders' preference of mobile apps and privacy risks of the apps. Moreover, they recommended the apps; which posed the least privacy risks. They used app-usage frequency as the measure of data holders’ preferences. The permission requests before/during installing the apps are used to measure privacy risks. Similarly, a scheme for privacy level settings for app permission is discussed in Liu et al., (2015). In Liu et al., (2015), the authors used different kernel approaches to identify different privacy levels. It recommends those apps to the data holders which require a minimum level of permissions to achieve data holder-defined privacy.

2.3. Privacy solution in social-influence based MRS
In literature, we did not find any privacy-preserving scheme for social-influence class, but in a few studies (Jason Wiese et al., 2014, Banks and Wu, 2009), it was mentioned that interaction based friends' identification could provide privacy to some extent. These studies defined different friendship levels based on interaction frequency and then used these levels to provide different privacy settings in a social network environment.

2.4. Privacy-preservation schemes for mobile-enabled internet of things (IoT)
Recently, few privacy-preservation approaches for mobile-enabled IoT are discussed in Gai et al., (2018a), Zhang et al., (2019), Gai et al., (2018b). In Banks and Wu, (2009), the authors used dynamic programming to produce the optimal level of privacy protection for large data transmission even for resource-constrained devices. In this paper, the authors used selective data encryption (important information from which user privacy can be leaked) depends upon the requirements and constraints of the associated software/hardware. They define the content-oriented data pairs (CODP) and combine all the data or data packages into pairs that can leak user privacy after joining e.g.; user name and location are two data and when these two are combined then user privacy can be threatened. After identification of all CODP's, they used higher-level security mode on one pair at least and for others, they used lower-level security mode. They tested their proposed method on two mobiles and their results confirm the authenticity of the method.

In the study (Gai et al., 2018a), for privacy-preserving trust discovery (LPTD) in fog and cloud platforms, the authors used the homomorphic Paillier encryption and one-way hash chain technique. Their LPTD technique has two phases; in the first phase, they provide a mechanism to updates the weights and in the second phase they securely update the trust values. In the article (Zhang et al., 2019), a multilayer access control based privacy-preserving approach for fog computing is discussed. Their technique utilized the computations and storage benefits of the fog server and divides the main involvers into two parties known as trusted and untrusted parties. Fog server and edge devices are considered as trusted parties whereas cloud servers and running apps as untrusted parties. They used two-tuple which consists of data index number and level of privacy (weights) associated with it and configuration is performed by the edge devices. At fog server, ranking of data is done according to the privacy level (weights) and then encryption is performed in sequence, according to privacy weights value.

3. Preliminaries
In this section, we will describe players, data models, attack model, and trust assumptions.

3.1. Players
This system consists of two players;

•
Data holders (Data holder): N Smartphone data holders such as Data holder = {
 which hold private data. Here, we assume that N>3.

•
Recommendation-server (Data collector): it can be represented as S which collects data holder inputs and perform the recommendation process to generate a recommendation. These recommendations are sent back to the target data holders.

It is assumed that data holders can communicate with both data collectors and other data holders in a given network. Similarly, we also assumed that the record will be collected periodically from the data holder devices.

3.2. Data model
The record of the data holder contains various attributes, among them; we select three attributes to simplify the problem. In our proposed scenario we consider data holder ID and friend ID both as identifier attributes. We assume the app installation log as quasi-identifiers where app usage, calls, and SMS frequency are considered as sensitive information. Let us assume that 
 represents data holder id where i = {1, 2, 3 …. }, 
 represents data holder-friend id's where j = {1, 2 … x}. Call and SMS frequency between data holder and its friends are represented as 
. Let 
 be an app installation log and app usage frequency respectively where k = {1, 2, 3 … y}. The schema of personal record can be defined as;

3.3. Attack model
Existing privacy-preserving techniques protect one or few privacy risks because each human has a different perspective about privacy (Liu et al., 2015). So, in this paper, our protocol will protect the inference of sensitive information, and attribute disclosure breaches. Attribute disclosure is a privacy breach: if attackers distinguish and identify the exact sensitive information of each data holder. It should be noted that, here, we are not considering the internal identity disclosure (identification of mobile number) as the privacy breach when it involves the social influence concept. Our main focus is to protect data holder records from the inference of sensitive information and external identity privacy breaches as shown in Fig. 2. We want to eliminate the assumption that, the secure communication channel exists between client-server during data transmission.

Fig. 2
Download : Download high-res image (372KB)
Download : Download full-size image
Fig. 2. Attack model in MARS for the proposed system.

Here, we consider that an internal disclosure breach occurs when the server is enabled to distinguish the data holder app installation log using a data holder ID. In all existing privacy-preserving schemes data holder app installation log is not considered a privacy threat. But in recent studies (Seneviratne et al., 2014, Unal et al., 2017, Frey et al., 2017), the authors proved that many data holder's traits could be identified, if the machine learning algorithm had been applied to this data.

3.4. Assumptions
In this paper, we consider the following assumptions related to trust as discussed in (De Cristofaro et al., ).

•
In our model, we assumed that our server is semi-trusted. It will follow the protocol specification and does not collude with any of the data holders. So, the server cannot be trusted with any sensitive information.

•
Similarly, we assumed that our data holders are also semi-honest. They will also follow the protocol specifications but they will provide disrupted information.

•
Data holders' friends are assumed to be semi-honest because they have a minimum degree of knowledge among each other e.g., mobile number. Two data holders are considered to be in contact (direct contact) if they have a certain amount of interaction. The interaction will be measured in terms of SMS and call frequency. Friends will exchange quasi-identifiers attributes honestly but they can disrupt sensitive information.

Other assumptions are discussed as follows;

•
We assume that the mobile has a good detection mechanism to find and remove malware to avoid malicious data collection. Or it is equipped with the technology to reject malware installation as discussed in Yan et al., (2012).

•
In data holder-server communication, we do not consider the identification of mobile numbers as a privacy breach. If it is necessary, then the anonymous identities concept can be used as discussed in Xu et al., (2018).

4. Proposed privacy-preserving protocol
Catering different privacy risks, our anonymization process takes advantage of the distributed and collaborative nature of the friend's network. Anonymization process is performed by different data holders, before data being collected by the data collector. In our protocol, all data holders are organized into a group and through an elected representative; personal data is sent by group members to the data collector. With this strategy, direct communication with the data collector will be avoided. Our proposed protocols have two phases; initialization phase and a data-gathering phase. The details of each phase are given below.

4.1. Initialization phase
Data holders send disrupted influence score (IS) of their few selected friends to the server in the initialization phase. Here, the “IS” score is calculated based on call and SMS frequency as discussed in Chamorro-Vela et al., (2017). For simplicity, we modified the influence score equation from Chamorro-Vela et al., (2017). The social influence score between two friends can be calculated as;(1)
 

The variable  and ns represent the frequency of calls and SMS respectively. Using this formula, social influence scores of few friends at time T is calculated locally at the data holder's device. The value 0.2 represents the default value of proximity. However, we can utilize more parameters to calculate influence score as discussed in Erfan et al., (2015). In Xu et al., (2018), the authors used a method that calculated the data holder's trust for mobile applications based on app usage behavior at the client-side. Then, homomorphic encryption is used to encrypt the trust values to ensure privacy. However, in this paper, we calculate the influence score between contacts, and instead of homomorphic encryption, we disrupt influence score values using a reversible data transform (RDT) algorithm as discussed (Lin, 2016).

4.1.1. Reversible data transform (RDT) algorithm
For applying RDT, we need to transform influence score floating-point values (consider only three digits after the point) into whole numbers by multiplying with 1000. The algorithm of RDT for sensitive information is given below;

Input: an original dataset D, sensitive attributes S = (
, m = 1, 2, 3 …), an integer Seed, a group size g, a set of weights 
 (∈ [0, g − 1]), and a watermark w.

Step 1: “Let n
 
, and  = 1”.

Step 2: For each 
:

(1)
“Let 
be a group of g neighboring data values (j = (1, 1 ​+ ​(1×g), 1 ​+ ​(2×g)… 1 ​+ ​(n ​× ​g))).

(2)
Use Eq. (2) and Eq. (3), to perform difference expansion on 
 and obtain
.

(2) 
 
 
 (3)
(3)
“If  then for 
, we embed  of the watermark  respectively. 

(4)
Use Eq. (4) to generate corresponding perturb group data

(4) 
 
 
 
Step 3: Generate the |D| number of random values via Rand (Seed) function and then perturbed dataset  is arranged in an ascending or descending order based on these random numbers. The example of a disrupted influence score of a single data holder is shown in Table 2.


Table 2. Disrupted influence scores for a server using RDT algorithm.

Data holder Id: 03003400484
friends-id	Call- frequency	SMS-frequency	Total	I-score	w-number	RDT-score	f-score
30010000000	23	34	57	0.329	329	31	0.031
30034000000	32	44	76	0.372	372	118	0.118
30015500000	45	32	77	0.375	375	123	0.123
30010004400	23	12	35	0.279	279	188	0.188
30010000550	12	0	12	0.227	227	97	0.098
30010066000	4	12	16	0.236	236	116	0.116
30010003330	21	45	66	0.35	350	224	0.224
30451000000	10	4	14	0.231	231	105	0.105
32110000000	6	1	7	0.215	215	1	0.001
30210000000	14	66	80	0.381	381	128	0.128
03456777777	5	5	10	0.221	221	14	0.014
03456774444	3	2	5	0.210	210	248	0.248
Total	198	257	455				
Record representation for server
03003400484	{30010000000,0.031},{30034000000,0.118},{30015500000,0.123},{30010004400,0.188},{30010000550,0.098},{30010066000,0.166},{30010003330,0.224},{30451000000,0.105},{32110000000,0.001}, {30210000000,0.128}, {03456777777,0.014}, {03456774444,0.248}
In (Lin, 2016), authors discussed that their proposed technique had presented effective results in terms of privacy disclosure risk (PDR) and probabilistic information loss (PIL) when compared with the privacy difference expansion (PDE) algorithm. They tested RDT on six different datasets and proved that RDT had better execution time. After generating the disrupted values, the final score would be generated (dividing the RDT score by 1000) and sent to the server. The range of disrupted IS score would be between [0, 1], and only greater than 0 values will be sent to the server. The sending data was in the form of single attribute  in which two attributes friends-id and influence score were merged. So, the attribute values were represented as friend-id, influence score. F-score was received by the server for a definite time. The data collected from all the data holders would be used to initialize the group formation process when the period ends. The group formation process will be directed only once at the commencement of the whole anonymization process.

4.1.2. Group formation and leader selection
After the influence score collection, the server will generate a candidate list of  data holders and a list of  potential leaders to form groups. The idea of a leader selection process for privacy-preserving data collection is inspired by the article (Kim and Chung, 2017). In paper (Kim and Chung, 2017), the authors used two leaders' strategies in which the first leader sends the original and counterfeits values of sensitive information to the server and the second leader only sends the counterfeits values of sensitive information. This strategy avoids external and internal identity disclosure privacy risks. In this paper, we will use the single leader approach because of two reasons;

•
In Kim and Chung, (2017), the author's used the two leaders (first and second leader) concept with the assumption that both are two different data holders. This approach can be crumbled if we suppose that both first leader and second leader are attackers and they have a mutual agreement and can launch a coordinated attack as discussed in Sajjad et al., (2019). In a coordinated attack, both leaders can share their collected information and by comparing the data holder ids and counterfeits information, they can reveal a record of a specific person. This coordinated attack is formally presented in our recent work in Sajjad et al., (2019).

•
In this paper, data holders will share disrupted values of sensitive information. So, there is no need for the second leader in our proposed approach.

Using a single leader, we can avoid the risk of a coordinated attack and it also simplifies the proposed protocol. For the preparation of the candidate data holders list, the server will identify friends group (circle) using the disrupted influence score values of different data holders and friend identification number. Mutual friends (similar id count from the list of two data holders) and cosine similarity can be used. Using Eq. (5), the server can calculate cosine similarity:(5)
 

For each contestant list, around  or more data holders and for group formation, there must be  data holders in each group. After selecting the candidate data holder list, potential leaders are selected from the candidate list using the influence score. In the worst case, the potential leader's list could be equal to, if influence score is equal (in real-world communication, it is not possible, because, all friends are not equal “best friends” as discussed in the study (Jason Wiese et al., 2014). The selection of the top IS score based potential leader (best friend or global friends of the said group will run for the leader election only) will help to reduce the candidate list for the leader election. The server distributes both lists to the corresponding data holders. These lists will not only be used to verify the other data holders in the corresponding group but can help to reach other data holders in constant time. Then, the leader is selected through a leader election algorithm as discussed in Villadangos et al., (2005). According to the (Kim and Chung, 2017, Villadangos et al., 2005), “the election cost is  in the number of messages and latency, where  is the number of data holders in a network”. Leaders will collect the data holder records and send to the server. The data holder's record for the leader contains app installation log
, and app usage frequency 
, where k = {1, 2, 3 … } in which  represents a total number of apps used by the data holder in time . An example of a data holder's record for a leader is shown in Table 3.


Table 3. Collected records from the single data holder.

Data holder id: 03003400484
App list	App usage	RDT-App usage
Whatsapp	115	93
Youtube	59	63
Gmail	34	28
Google	46	52
HBL Mobile	57	59
Video	37	35
S Planner	22	15
Email	26	24
Phone	23	17
Gallery	59	63
Maps	23	17
Play store	22	15
Record representation for the leader
Data holder id	Applist-App usage
03003400484	{{Whatsapp,93}, {Youtube,63}, {Gmail,28}, {Google,52}, {HBLMobile,59}, {Video,35}, {S Planner,15}, {Email,24}, {Phone,17}, {Gallery,63}, {Maps,17}, {Play store,15}}
The leader collects records from the group members and appends these records in the form of a list and sends that list to the server. The example of a single leader record for the server is shown in Table 4.


Table 4. Collected records from a single leader.

Data holder-id	Applist - app frequency
03003400484,30010000000, 30034000000, 30015500000	{{Whatsapp,93},{Youtube,63}, {Gmail,28}, {Google, 52}, {HBL,59}, {Mobile, Video, 35}, {S Planner, 15}, {Email, 24}, {Phone, 17}, {Gallery, 63}, {Maps, 17}, {Play store, 15}, {Whatsapp, 22}, {Facebook,14}, {twitter, 56}, {Firefox, 52 }, {Play music, 34}, {Ufonefunkit, 43}, {ABL mobile, 11}, {Youtube, 23}, {Gmail, 21}, {Gtalk, 34}, {yahoo, 36}, {Instagram, 12}, {Tiktok, 15}, {imo, 16}, {Word Link, 17}, {Cooking Madness, 42}, {easypaisa, 76}, {tinder, 98}, {truecaller, 93}, {cream, 65}, {candy crush, 76},{weather, 87}}
The procedure of the initialization phase is shown in Algorithm 1 and 2. The leader and server can extract useful information from the app usage record e.g. product likeness which can be used for advertisement. So, to avoid such privacy risk, each data holder will send RDT-app usage score 
 instead of actual usage information as shown in Table 4.


Algorithm 1. initialization (data holder)

1. Let  be a set of data holders
2. Calculate 
 RDT-influence score
3. Send 
 RDT-influence score 
 to the data collector
4. Receive candidate list 
 and the leader nomination list 
 from the data collector
5. For all 
 do
6. If 
 is equal to 
 then
7. fue
8. Else
9. Terminate
10. End if
11. End for
12. Consent to consider 
 as a group 
 among all 
13. Participate in the leader election of 
Secondly, the leader and server can apply data mining approaches on the collected app installation log to identify traits of data holder as discussed in Seneviratne et al., (2015). Such type of knowledge inference from the app installation log is considered as a privacy breach. In the case of a leader, we assume that a leader has some knowledge about the data holders’ traits e.g., age, gender, religion, relationship status, country, spoken languages, and whether or not the data holder is a parent of young children. This assumption is valid because a leader belongs to the friend circle of the data holders and has direct communication in the form of SMS and calls.

To further prevent the record identification at the server-side, the leader will append the data holder's data randomly in the final list. Here, due to automatic data collection, one special kind of privacy risk can be triggered. There is a possibility that the user may not want to share certain apps with anyone even to their friends. Because it may invoke reputation problems among friends e.g. one friend does not want to share that he/she is using apps like dating app, dieting app or smoking quitting apps, etc. this situation falls under the category of personalized privacy as described in Xiao and Tao, (2006). However, it is beyond the scope of this paper.


Algorithm 2. initialization (data collector)

1. Receive 
 RDT-influence score 
 from the data holders
2. Calculate candidate list 
 and the leader nomination list 
3. For all N data holders do
4. Let  be a set of data holders who have direct communication in terms of call and SMS
5. Send candidate list 
 and the leader nomination list 
 to the corresponding data holders
6. End for
In the case of a server, traits identification for individuals is not possible because it has collected record list from the leaders. However, the server can identify the traits of the group if it applies data mining approaches. This privacy risk can be mitigated if the leader inserts dummy (counterfeits) information (app installation log and app usage) in the final list and also notifies about the counterfeits values to the corresponding group members.

4.2. Data collection/gathering phase
Our data collection phase is consisting of a single task called: data transmission. In this task, personal records of  data holders are collected. The procedure of the collection phase is shown in Algorithm 3.


Algorithm 3. data collection (data collector)

1. Let 
 be a set of anonymized collected records send from 
 group leaders
2. Let g be the number of all existing groups
3. For i = 1 to g do
4. Update values for each group record including app-usage 
 and app-install log 
5. End for
In our protocol, the data collection phase is very simple as compared to (Kim and Chung, 2017) because we have used a single leader strategy and not used counterfeits values which needed to be eliminated as in the protocol of Kim and Chung, (2017). Supposedly, if the leader adds some counterfeits app installation records in the final list, at the client-side, we just need to eliminate these values because the server does not know the existence of these counterfeits values. These values are used to deceive server analyzing capabilities, on the other side, each corresponding group members know about them.

4.3. Dynamic join and leave
In the anonymization network, data holders can leave or join and this fact has to be considered in the anonymization protocol. The protocol should satisfy the basic criteria of the joining process and that is a new data holder should join the appropriate corresponding group (Kim and Chung, 2017). In the same manner, the protocol should satisfy the criteria of the leaving process and that is data holders should leave the anonymization network without the privacy breach (Kim and Chung, 2017). To minimize information loss, both criteria are needed to satisfy because information loss is inevitable when the process of joining or leaving is initiated by the data holders. Here, in our protocol, we already used the disrupted values (RDT based values) of sensitive information, so, chances of privacy breaches are minimal. Secondly, groups are formed based on disrupted social influence scores, so, newly joined data holders must know at least two data holders who are present in the current anonymization network.

4.3.1. Join
Data holders, who intend to participate in the anonymization network, send friends ids and their respective influence scores to the data collector. After receiving the scores, the data collector will ensure that newly joined data holders must-have friend ids' which are present in the current network, and then data collectors send newly joined data holders ids to relevant friends in groups to verify their identity. After a friend's approval, the data collector will assign the relevant group to the newly joined data holders and notify the new data holder's information to the relevant group members and the respective leader. After that, leaders will update the member list because this list is needed to receive messages from.

4.3.2. Leave
Due to different reasons, data holders can leave the network such as network failure or device turn off (Kim and Chung, 2017). So, these disconnected states should be handled by the anonymization protocol. In our protocol, leaving the anonymization network does not affect the whole data collection process, if the group satisfies the minimum threshold k where k ≥ 3. When a member wants to leave the group permanently, it notifies the server and first leader. The first leader then updates the member list of the group, if a group member is less than a required threshold, then, it immediately notifies the server. The server initiates the joining process for each member and assigns respective groups to them based on their friend's presence in other groups. If there is no friend present in other groups, then the server will use the friend-of-friends approach. For other cases, like devices or network failures, each first leader will wait for the messages from the members until δ cycles before initiating the leaving notification. After the δ cycles, that member will be considered as permanent disconnection from the network and hence, the first leader will take respective measures against it.

5. Discussion and results
In this section, we will present how the proposed protocol can be extended to collect influence scores and contextual data for recommendation purposes. We discuss the possible attacks and the protection mechanism for the attacks. Furthermore, the performance evaluation of the proposed algorithm in terms of computational overhead for the RDT algorithm is discussed.

5.1. Data collection for app recommendation
In our protocol, the anonymization network is created based on friends' influence scores. So, our proposed protocol is most suitable for the social influence based mobile recommendation system. For influence based app recommendations, the server may require user app preferences, friend's app preferences, contextual data and friend's social influence scores. App preferences can be calculated based on app usage frequencies as discussed in Wang et al., (2015). Friend's social influence score can be calculated based on call and SMS log as discussed in Chamorro-Vela et al., (2017). To prepare the recommendation list for each group, the server requires recent data from each group and for that, it initiates the data collection. The server sends init-message to all data holders especially leaders who are responsible to collect the data from the group members. The data collection could be initiated using two ways; 1) initiate data collection from the specific group after receiving the request from the data holder of the corresponding group or 2) server collect data weekly because recommendation list will be more accurate if recent information is present. All group members prepare the relevant data includes disrupted friends influence scores, installed apps log and disrupted apps usage frequencies. In the case of contextual information, the data holder will combine counterfeit and actual values for each contextual variable. The concept of adding dummy values for contextual variables is presented in Polatidis et al., (2017). After preparing the required data, data is sent to the leader. Leaders collect the records from all the group members and send them to the server for further processing.

5.2. Possible attacks and defense mechanism
•
Internal identity disclosure. According to the article (Kim and Chung, 2017), the data collector can act as an adversary at the data collection phase for the said privacy breach because the data collector has both identifying (ID) and sensitive information of each data collector. In our protocol, we used RDT algorithm to disrupt the sensitive information. Furthermore, due to the grouping of data holders, the disclosure probability cannot be greater than 

•
External identity disclosure. In our protocol, the said privacy breach is avoided by employing the leader concept. Here, leaders are responsible to collect and transfer the data instead of direct communication between data collectors and data holders. Here, the leader can act as advisory because of collection authority and using external identifiers it can distinguish records in the same way. But due to the RDT algorithm, the leader cannot get actual information from the data holder's record.

•
Unauthorized data holders. Unauthorized data holders cannot participate in the anonymization network because we employed a verification scheme. In the joining process, the records of the new data holders should contain at least 2 friends id which is present in the network. Secondly, before the formation of the group and leader selection process, the data collector distributes the lists of candidate group members and possible leaders among corresponding data holders to verify the participants.

5.3. Experimental results
For evaluation, the computation overhead metric is used to compare the performance of the proposed protocol. The computation time of the anonymization protocol in Kim and Chung, (2017) is calculated based on two tasks; initialization (task A) and elimination of counterfeits values (task B). For task ‘A’ computation time, they consider that it is identical to the task of centralized anonymizing the whole dataset. The time required for task ‘A’ is equal to the time of the task of the centralized anonymizing method. The only overhead is the elimination of counterfeits values. In this paper, we used a similar initialization phase as in Kim and Chung, (2017), except we used the RDT algorithm to disrupt the sensitive attribute values at the initialization phase. Moreover, in our protocol, we do not use counterfeits values, so, the cost of the elimination process time is not valid here.

To evaluate the performance, we measure the computational time of the RDT algorithm. The experiments were conducted on a computer equipped with an Intel Core i5-3210 M CPU @ 2.50 GHz and 4 GB RAM. We used MATLAB 17 environment for the experiment. We set the variable values for RDT were as follows; group-size is set to 4, used a random number to generate weights and watermark bits. We generate the different sizes of a dataset having a length from 8 tuples to 1024 and run the RDT algorithm 10 times with different weights and watermark bits. The average computation time for one sensitive attribute of 1024 tuples dataset was 0.3184 s. The computation time of the RDT algorithm for one sensitive attribute of different size dataset is shown in Fig. 3.

Fig. 3
Download : Download high-res image (305KB)
Download : Download full-size image
Fig. 3. RDT algorithm computation time according to the size of the dataset.

The network costs between data holders and a data collector are not considered here. Secondly, in reality, the dataset length (number of record tuples) for each data holder may not exceed 64 tuples. Different statistic for app usage record shows that the average user may use 6 to 10 apps per day and up to 40 apps per month. 1, 2, 3 Similarly, according to Apennine statistics, the number of installed apps in a Smartphone may not exceed up to 256. According to the report (Jason Wiese et al., 2014), the maximum SMS and calls logs for the android phone may up to 200 SMS per contact and the call log to the last 500 calls. Lastly, the length of the contact list available in 128k mobile phone SIM card is more than 600 contacts but this number can vary depending upon the SIM card manufacturer and the device in which the card is used.4 The contact log for each data holder may not exceed up to 100 because according to a recent study (Banks and Wu, 2009), all friends are not equal and people have a tendency to contact fewer friends only. So, according to these statistics, our privacy protocol can be a feasible choice for MARS.

After that, we compare the computation time of our RDT algorithm with a so-called chaotic based homomorphic encryption scheme. The homomorphic encryption scheme for comparison is defined as follows5;(6)

We used the binary representation of plain-text and consider 
 as input binary sequence. Here, by using the process of (Wang and Gu, 2014), we generate a chaotic based binary sequence and represent that sequence as 
 (used as a key). Finally, we set the value of variable  and dataset-size ​= ​256. For fair analysis, we randomly generate a dataset of 256 decimal values in the range of [0–255] because we want binary representation in 8bits only. The number of chaotic binary sequences for 256 dataset size is 2048 (Database size ∗ the number of bits required to represent max value in the dataset) if the maximum value is 255 in the dataset then 256 ∗ 8 ​= ​2048. After 10 runs, the meantime of the homomorphic encryption procedure is 0.7785 ​s (max ​= ​1.0597 and min ​= ​0.6291) include both key generation time and encryption time where RDT-algorithm takes 0.1292 ​s as shown in Fig. 4.

Fig. 4
Download : Download high-res image (175KB)
Download : Download full-size image
Fig. 4. Computation time Comparison of RDT-algorithm and Homomorphic encryption on a single attribute.

6. Conclusion
In this paper, we presented an RDT based privacy-preserving protocol for data collection that does not rely on a private channel. In this paper, we also discussed the possible attacks and countermeasures for our approach. Finally, a performance comparative summary shows the potential of our approach in real-world deployment.

