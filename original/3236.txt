The right choice of features to be extracted from individual or aggregated observations is an extremely critical factor for the success of modern network traffic classification approaches based on machine learning. Such activity, usually in charge of the designers of the classification scheme is strongly related to their experience and skills, and definitely characterizes the whole approach, implementation strategy as well as its performance. The main aim of this work is supporting this process by mining new and more expressive, meaningful and discriminating features from the basic ones without human intervention. For this purpose, a novel autoencoder-based deep neural network architecture is proposed where multiple autoencoders are embedded with convolutional and recurrent neural networks to elicit relevant knowledge about the relations existing among the basic features (spatial-features) and their evolution over time (temporal-features). Such knowledge, consisting in new properties that are not immediately evident and better represent the most hidden and representative traffic dynamics can be successfully exploited by machine learning-based classifiers. Different network combinations are analyzed both from a theoretical perspective, and through specific performance evaluation experiments on a real network traffic dataset. We show that the traffic classifier obtained by stacking the autoencoder with a fully-connected neural network, achieves up to a 28% improvement in average accuracy over state-of-the-art machine learning-based approaches, up to a 10% over pure convolutional and recurrent stacked neural networks, and 18% over pure feed-forward networks. It is also able to maintain high accuracy even in the presence of unbalanced training datasets.

Previous
Next 
Keywords
Network traffic classification

Features extraction

Long Short-Term Memory

Recurrent neural networks

Convolutional neural networks

ConvLSTM

1. Introduction
Network traffic classification (NTC) is a topic of extremely deep interest for internet service providers (ISPs) and network operators in order to identify the typology of data flowing in the network and mapping them to their generating applications. This knowledge is important for many reasons, including monitoring network security and network applications behavior, performing traffic engineering or Quality of Service/service Level Agreement calibration, improving knowledge of users’ traffic demands for supporting policing and prioritization mechanisms, as well as performing data collection for marketing, accounting/billing or capacity planning purposes. Reliably classifying the network traffic is also crucial for automation of network operations, where the prediction of traffic demands and flow matrices, the development of realistic traffic models (Xu et al., 2005) and the detection of anomalous behaviors (D’Angelo et al., 2015, Palmieri, 2019) for triggering autonomous reactions, become core components of modern network management frameworks. Possible actions and countermeasures associated to traffic class monitoring may include filtering/blocking unwanted flows, starting lawful interception sessions, performing rerouting or resource reallocations in presence of specific overload conditions, menaces or activities contravening the network operator’s terms of service.

There are many use cases that can be taken as examples to demonstrate the need for NTC, ranging from the ability to provide different bandwidth or QoS guarantees to traffic from different applications (chat, bulk FTP/HTTP data transfer, Peer-to-Peer (P2P) file sharing Claffy et al., 1995, Sen et al., 2004, Karagiannis et al., 2004), to the identification (and eventually blocking) of specific frauds (Palmieri et al., 2013), copyright infringement (Cheng and Lai, 2010) or malicious activities (Palmieri et al., 2011) associated to properly obfuscated traffic flows.

More precisely, in order to know what kind of traffic is flowing through their network infrastructures, by avoiding, both for privacy and scalability reasons, the deployment of excessively granular controls at the end-users level, ISPs are obliged to adopt a data-driven approach (Alshammari and Zincir-Heywood, 2008). That is, they need to extract some relevant characteristics (features) from the traffic flows, and to use such features to associate any individual flow to its generating application. In modern NTC schemes, such association is usually performed by using Machine Learning (ML), often empowered by technologies coming from the Artificial Intelligence (AI) arena. These approaches have proven to be more fast and precise compared to traditional port-based and Deep Packet inspection (DPI)-based ones as well as more immune to obfuscation techniques. However, the right choice of features to be extracted from individual or aggregated traffic observations is an extremely critical factor for the success of ML-based NTC approaches. Indeed, the individuation of features that are representative enough for successfully discriminating between different traffic types and the design of methods to be used to extract and use them assumes paramount importance for the success of any NTC approach, as well as for its implementation/operating strategy and performance. This requires considerable skills and engineering efforts, which make such task essentially bound to human activities in charge of the designers of new NTC schemes. Due to the complexity of modern networks and applications, it is also considered one of the most challenging activities in networking research.

The main aim of this work is supporting this process by mining new and more expressive, meaningful and discriminating features from the basic ones without human intervention. Accordingly, we investigate the potentiality of an autoencoder-based neural network in extracting more meaningful features to be used in NTC. We start from some elementary statistical features (referred to as basic-features) obtained by sampling over time and functionally aggregating on a window basis several traditional header-based properties, resulting in new values obtained from processing multiple consecutive packets falling within the time window occurring between two sampling points. By leveraging a novel deep neural network architecture also involving convolutional and recurrent neural networks we derive new features (referred to as spatial and temporal features) which are able to express relevant knowledge existing among the basic-features (spatial-features) and among such features as they change over time (temporal-features). These new features are able to significantly improve the ML-based classification process by capturing more deep and discriminating traffic dynamics, often associated with temporal correlations and dependencies, recurrence phenomena as well as mixed spatial–temporal patterns and trends that are not easy to be perceived at a first glance. In detail, a typical Internet traffic flow associated to a service/application may exhibit a significant variance in its evolution over time, essentially due to burstiness, observable on multiple time scales, and depending on the specific characteristics of the involved application. Thus, some specific clustering properties between basic features as well as the presence of periodic structures that better characterize the traffic type do not emerge from observations strictly bounded in a single space or time but result from the superposition of several distinct, independent and almost hidden dynamics, each related to a different combination of basic features eventually analyzed over historical trends properly scaled over time.

Accordingly, we propose a network architecture making use of an autoencoder stacked with a fully connected neural network, where the encoding functions of the autoencoder are implemented with combinations of convolutional and recurrent networks in order to mine the aforementioned spatial and temporal features, respectively. This makes it possible to extract features without using a designed engineering process, but automatically starting only from the basic-features and eliciting relevant knowledge about their more or less evident correlations over space and time. Furthermore, the derived features are more powerful and expressive due to the presence of layers into the encode–decode function of the autoencoder, including combination of convolutional and recurrent neural networks. Finally, a fully connected neural network is used to classify the traffic by using the new features extracted.

In addition, a detailed mathematical description of the different neural network architectures that can be used for the aforementioned purpose is provided in order to clarify the understanding of how each network component affects the feature extraction process.

Ultimately, the main contributions of our work can be summarized as follows:

1.
A neural network based classifier is provided for near real time NTC.

2.
Spatial and temporal features are introduced for mining correlations among the components of a feature vector and among such vectors over time, respectively.

3.
These spatial and temporal features are mined by combining convolutional and recurrent neural networks with an autoencoder.

4.
A formal description of the overall architecture is provided in order to better motivate the approach from the theoretical point of view and improve the understanding of how each network component affects the feature extraction process.

The remaining of the paper is organized as follows. Section 2 presents the related works with particular attention to deep network solutions. A brief description of the typologies of deep neural networks employed in the proposal is given in Section 2. The description of the proposal and a detailed mathematical formalization of the proposed deep neural networks used to extract the spatial–temporal features from network traffic flows are described in Section 4. Section 5 is devoted to describe the experiments setting, results, discussion, and comparison with state-of-the-art models. Finally, conclusions and future works are the subject of Section 6.

2. Related works
In the last decades both academic researchers and industries have proposed and developed many NTC strategies (Goli and Ambika, 2018) based on a large number of features and technologies. However, the most common methods for NTC are based on Port numbers and Deep Packet Inspection (DPI), as well as on statistics-driven classification (Nguyen and Armitage, 2008).

The first approach uses the knowledge of port numbers information extracted from the transport layer headers to identify the different traffic types. Although this is the fastest and the simplest method for NTC, nowadays it is no longer reliable, since many recent applications do not use well-known port numbers and often they wrap the traffic by using ports associated to other protocols, such as HTTP, DNS, etc.

DPI relies on payload inspection in order to find out well-known patterns that are able to univocally characterize the different traffic types. Although this method can achieve high performance for some traffic typologies, such as HTTP, FTP, and SMTP, it implies significant processing efforts, usually requiring dedicated hardware, and often fails in identifying P2P, multimedia, and encrypted applications.

Finally, statistic-driven approaches rely on high-level information extracted from the packets header, such as packet-size, timestamp, TCP flags, window size, etc. Usually, a set of these information are gathered within a fixed temporal window and used to extract new meaningful and more powerful statistical information, such as inter-arrival times, packet rate, bit rate, and so forth. These new features are often used as input to ML-based algorithms to perform NTC (Shafiq et al., 2016). Nevertheless, the use of ML is now considered an extremely promising option, extensively explored in many research and industrial application fields (D’Angelo et al., 2019, D’Angelo et al., 2018, D’Angelo et al., 2020) by achieving very successful results.

Due to the huge amount of works available on NTC, which make use of different datasets, features, extraction methods, and evaluation metrics, it is very difficult, if not impossible to perform a complete comparison among them. For this reason, in this Section we report only some works, that for their similarity to our proposal, can be useful to better understand the potentiality of our approach. We remand to notable and well-known literature papers for a detailed survey (Nguyen and Armitage, 2008, Shafiq et al., 2016, Rezaei and Liu, 2019). In particular, we remand to Aceto et al. (2019), which through the introduction of a performance evaluation workbench offers a summary of the results obtained by deep learning and machine learning based solutions.

In Lopez-Martin et al. (2017) the authors propose several network traffic classifiers based on different combination of convolutional (CNN) and recurrent neural (RNN) networks. The coupling of convolutional and fully-connected networks (CNN–NN), and recurrent and fully connected networks (LSTM–NN) are first evaluated. Next the sequence CNN–LSTM–NN is considered. No autoencoder is used, and the experiment results show the CNN–LSTM–NN configuration to be the best with an accuracy of 96% when it is evaluated on the RedIRIS dataset.

An accuracy of 98% and 96% are achieved in Lotfollahi et al. (2020) for CNN and SAE (Sparse Auto-Encoder)-based configurations, respectively. The “ISCX VPN–nonVPN” traffic dataset was used in this case. The CNN-based configuration is modeled as a one-dimensional convolutional network including two CNN layers followed by a pooling, flattening, and a three-layered fully-connected network. A softmax classifier is used at the end. The SAE architecture includes five fully-connected layers of 400, 300, 200, 100, and 50 neurons, respectively. As in the CNN configuration, a softmax classifier terminates the network.

Two deep network solutions are shown in Yang et al. (2018). The former uses a 8-layer CNN configuration extracted by AlexNet (Krizhevsky et al., 2012). The first five layers are convolutional, while the remaining three ones are fully-connected neural networks. A softmax classifier is also used at the end. An autoencoder with different hidden layers is used in the second solution to reduce the features’ dimensionality, while a Random Forest is used as classifier. The best accuracy of 97.9% is achieved by the CNN configuration when evaluated on a proper dataset collected by using ChromeDriver (Google, 2008).

A novel feature set based on time-intervals is proposed in Höchst et al. (2017). A neural autoencoder and a softmax classifier are used to obtain an accuracy of 80% on the specific dataset chosen for performance assessment.

As noted, even though the reported configurations make use of different combinations of deep, CNN, and recurrent networks, none of them extracts the combination of spatial and temporal features from the network traffic to be used for performing NTC, which is the specific goal of our work.

3. Preliminaries
The approach presented in this paper makes use of different typologies of neural networks arranged to provide a powerful network traffic classifier suitable for most of the tasks characterizing modern ISP activities. For the sake of clarity, in this Section, the basic theoretical backgrounds of the employed networks are shortly presented.

3.1. Convolutional neural network
CNNs have been considered to be the most efficient kind of deep neural networks especially in the fields of image processing, object recognition, natural language processing (NLP) and autonomous driving. The use of CNNs for deep learning has become increasingly common mainly due to two important factors:

•
CNNs eliminate the need for manual extraction of features, as these are learned directly by the CNN.

•
CNNs can be re-trained for new recognition activities, allowing existing networks to be exploited.

CNNs are similar to other neural networks in terms of input and output layers. Their strength is the presence of multiple hidden layers, each of which, through specific mathematical operations, is able to learn relevant features. Basic features (Low-Level features) are learned by lower layers, while more sophisticated and abstracted features (High-Level features) are learned by higher layers by exploiting the features extracted by previous layers. Each layer typically includes the following three operations in sequence:

•
Convolution: is the main operation of a CNN. It applies to the input data several convolutional filters, each one responsible to detect specific typology of features from the data. For each filter, the sliding involved in the convolution operation is made by different artificial neurons sharing the same weights.

•
Rectified Linear activation fUnction (ReLU): is a function that gives as its output the value zero for negative input values, and the input itself otherwise. This function is applied to the output of each convolutional neuron as activation function. It has demonstrated to be a milestone in the field of deep learning, because, unlike the widely used sigmoid and hyperbolic tangent activation functions, it is able to overcome the well-known vanishing gradient problem (Hochreiter et al., 2001), and then to obtain better learning performance.

•
Pooling: is used as down-sampling function for two main reasons, namely to reduce the size of the output layers and, in turn, reduce the number of connections with the next layers, and to make the features location-insensitive. Consequently, pooling can drastically reduce the learning time enables CNN to recognize features regardless their location (local translation invariance). Max-pooling and average pooling are the most common pooling methods. The former emphasizes the most active feature, whereas the latter emphasizes the average value of the involved features.

The classification is the last step in implementing a CNN. This is accomplished by using a fully-connected feed-forward neural network involving as output a vector of dimension equal to the classes to be predicted. The softmax function is generally used to provide classification in terms of probabilities.

In this study, we use CNNs to extract repeating communication patterns in traffic data. We refer to them as spatial-features.

3.2. Recurrent neural network
Feed-forward neural networks return the same responses when they receive the same inputs. Although this aspect is desirable in many cases, in many others this could be a limitation. Indeed, there are situations in which the network should provide responses depending on past inputs. To this purpose, the network needs to keep memory of the past. This may be accomplished by providing to network a state and use it as part of the next operations.

The Recurrent Neural Network (RNN) is the model of neural network most widely used for this goal. It involves feedback loops which heavily affect the behavior of the network also for the same inputs. Indeed, the output depends on the network state. In its simplest form, presented for the first time by Elman (1990), the decision at time  is affected by the decision achieved at time . In such a way the input to Elman’s RNN includes two sources, namely present and previous input (the last also known as context unit). Consequently, RNNs are used to detect correlations over time, and to find out the so-called “long-term dependencies” in data. The training process of a RNN is performed by using a variant of the Backpropagation (BP) algorithm, that is the Backpropagation Through Time (BPTT) algorithm (Werbos, 1990, Werbos, 1988). The application of BPTT implies the unrolling of the RNN, that is, the network is seen as sequences of feed-forward neural networks, which can lead to a deep network with multiple hidden layers. The resulting network is, then trained through the BP algorithm, which is affected by the above-mentioned vanishing gradient problem. To overcome this issue, the Long Short-Term Memory (LSTM) network has been introduced (Hochreiter and Schmidhuber, 1997).

3.2.1. Long Short-Term Memory
The key of an LSTM cell is the presence of the “Internal Cell State” (
), which allows the cell to remember or forget past information. This state is updated through four internal activation layers called gates, implemented by a sigmoid neural network layer and a point-wise operation. Each gate is devoted to a specific goal, as described below and shown in Fig. 1:

•
Forget Gate (
): determines how much past information should be forgotten.

•
Input Gate: determines how much information of the actual input should be stored in the cell state. It is implemented by summing the output of two layers, namely a sigmoid (
) and a tanh (
) layer, respectively. The former is used for deciding which information has to be updated, whereas the latter is used for deciding how much of the chosen information should be added to the actual state.

•
Output Gate (
): determines which and how much data to provide as output (
) starting from the actual cell state (
).

3.3. Autoencoders
Autoencoders (AEs) are unsupervised artificial neural networks aimed at generating new data through the sequence of two processes, namely encoding and decoding, respectively. As depicted in Fig. 2, the former is implemented by an encoder which is devoted to compressing the input into a space of latent variables, whereas the latter is implemented by a decoder which is involved in reconstructing the input based on the information included in latent variables. For this purpose, the encoder–decoder pair is implemented by two symmetric neural networks. The main goal of the AE concerned in learning to copy its input as the desired output is to automatically capture the most relevant and representative features from the input data. Also, AEs are employed to get a latent space smaller than the original data dimension, similarly to the techniques used for data compression via dimensionality reduction, such as Principal Component Analysis (PCA), Linear discriminant analysis (LDA), Discriminant Function Analysis (DFA), and T-distributed Stochastic Neighbor Embedding (t-SNE) (Nguyen and Holmes, 2019). The main difference between AEs and these techniques is that AEs are able to represent the input also using non-linear combinations of the derived features. This confers to AEs the capability of representing more complex input data using a low-dimension latent space.

The type of neural network used within the encoder–decoder pair determines the functionality of the AE itself. Basically, there are seven types of AEs, namely: Denoising AE (Vincent et al., 2008), Sparse AE (Meng et al., 2018), Deep AE (Ye et al., 2018), Contractive AE (Rifai et al., 2011), Undercomplete AE (Thies and Alimohammad, 2019), Convolutional AE (Maggipinto et al., 2018), and Variational AE (Karamanolakis et al., 2018).

In the following we will use Sparse AE with a low-dimension latent layer for extracting relevant features from data. We remand to Charte et al. (2018) and D’Angelo et al. (2020) for major details on AEs theory and applications.

3.4. Stacked neural network
A Stacked Neural Network (SNN) configuration combines different pre-trained neural networks by concatenating intermediate layers (corresponding to the learned features) to obtain a more complex feature set (Milad and Subhasis, 2016). Its goal is to improve the trade-off between the classification accuracy and the training speed by taking advantage of the transfer learning (Pan and Yang, 2010). Recently, SNNs have become popular also in the framework of AEs. They are known as Stacked Autoencoders (StAEs) (Liu et al., 2018), and have proven to be very effective in deep learning with the presence of noise in the data (Vincent et al., 2010). A StAE is implemented by connecting in sequence several hidden layers of other pre-trained AEs, followed by a fully-connected network at the end. Consequently, the training of SNNs is performed first by training each involved AE separately (by using an unsupervised algorithm), and then by fine-tuning the whole network through a supervised approach, such as the backpropagation algorithm. This approach is able to avoid the aforementioned vanishing gradient problem.

3.5. Dropout
Although neural networks have been proven to be effective in numerous field of application, their learning activity remains challenging when the number of features is large compared to the observed data or in condition of over-learning. In such cases, the resultant model adapts to input data, and it is not able to generalize. This is known as “overfitting”. To prevent this issue, the Droput technique is commonly used (Srivastava et al., 2014). It can be realized by zeroing the output of some neurons in order to prevent them to be involved in the training process.

4. The proposed methodology
This section presents the details of the proposed approach for implementing a powerful network traffic classifier capable of exploiting spatial and temporal correlations and dependencies in traffic time series by “distilling” new features from basic ones. This is accomplished through two main steps, namely finding out the more representative features of the traffic, and then performing classification by using a stacked neural network. As depicted in Fig. 2, the former step is performed by using an AE whose encode–decode function is implemented by different deep neural networks (numerated in the figure from 1 to 4), that is CNN, LSTM, CNN–LSTM, and ConvLSTM. Whereas for implementing the classification step we use the latent layer of the AE as input to a fully-connected neural network. In this way, we combine the capability of AEs in searching compact features with the classification ability of a deep neural network.

The goal of our solution is to elicit knowledge by both observations made at specific time intervals and by the historical traffic behavior as it evolves over time. As it is widely known, network traffic observable at a specific tapping point results from the composition of many individual flows associated with different applications. Each flow is defined as the traffic characterized by having a unique bi-directional combination of a specific source IP address, destination IP address, source Port, destination Port, and transport protocol (TCP, UDP, SCTP, etc.). For example, a TCP flow is also identified by the handshake involved, while a UDP flow is terminated by using a properly chosen keep-alive interval time. Usually, a flow is sampled at different intervals where some useful features are extracted. Typical features include the number of packets, number of bytes, bit rate, inter-arrival time, etc. In the remainder, we refer to these features as basic-features. The direct usage of these features does not allow a classifier neither to detect the behavior of a flow over time nor to evidence relations among the different components of a flow.


Download : Download high-res image (411KB)
Download : Download full-size image
Fig. 2. A perspective of the proposed approach.

To address this, we use a CNN for retrieving relations among basic-features. We refer to these new features as spatial-features. Indeed, although the CNNs have been initially used in image processing, where the features mining is done automatically by the CNN which extracts location invariant patterns from the image, recently CNNs are involved in multiple research fields including NTC (Lopez-Martin et al., 2017). As well as the image pixels correlations are extracted by the network, similarly useful correlations can be extracted among the entries of the features-vector used, hence the name spatial-features.

Besides, we use LSTM to learn the behavior of the basic-features over time (temporal-features), and a Sparse AE to learn the most salient and compact features from data. In particular, as depicted in Fig. 2, the basic-features are fed to AE, while the CNN and LSTM networks are devoted to extracting spatial and temporal information.

In the following a brief mathematical formulation of the proposed NTC architecture is provided. We start from AE, and then we incrementally extend the discussion to five deep network combinations, as shown below.

4.1. Pure AE
In this configuration, with reference to Fig. 2, we consider only the AE, and we suppose AE includes three layers, that is, input, hidden and output, respectively.

Let 
 be the basic-features (the input of Fig. 2), and let 
 be the input of AE, then in the case of pure AE, 
, and then 
.

As described earlier, AE seeks to reconstruct the input, by mapping it to a hidden representation , which, in turn, is mapped to an output (
) expressed by: (1)
where  and 
 are the weights matrix and the bias vector of the encoder and decoder, respectively. While  is the activation function of the decoder.

Let  be the number of hidden neurons of AE, then 
, and 
. We remark that in this case (pure AE) 
.

Also, 
 is given by: (2)
where  is an activation function of the encoder.

AE is trained as a classic neural network by minimizing a loss function () (e.g. mean squared error). It is possible to add constraints (regularization terms) to this function, to give the AE specific capabilities. For mining compact and representative features from data, Sparse AEs (SAEs) are usually employed. They are characterized by having a small number of simultaneously active hidden nodes. It has been observed that sparsity improves the classification performance (Makhzani and Frey, 2014). SAEs are regularized by adding a penalty term to the loss function, that is: (3)
with  regularization term, and  expresses the degree of regularization. Sparsity can be achieved in different ways:

•
 regularization: It is also known as Lasso Regression (Least Absolute Shrinkage and Selection Operator). In this case , that is, the absolute value of the network weights are added as penalty terms to the loss function. This ensures zeroing of the hidden neurons weakly activated.

•
 regularization. In this case, the Kullback–Leibler (KL) divergence (Kullback and Leibler, 1951) is used as penalty term. For SAEs, it expresses the divergence existing between the average activation of the th hidden neuron (
) and a given sparsity parameter, 
 (close to ). Thus,  is defined by: (4)
 
 
with  the size of the hidden layer.

Once the training is completed, the output of the th hidden neuron (
) can be extracted by: (5)

We remark that the sparsity constraint forces the hidden layer to activate few neurons ( in theory) as response to specific features included in the input data. Thus, supposing the input data of SAE constrained by 
, each component (
) of the input data (
) activating the th hidden neuron is given by: (6)
 

That is, the encoder’s weights (
), scaled by the denominator of (6), represent the extracted features. This means that SAE is able to learn a number of different sets of features from data at least equal to the number of hidden neurons (i.e.  in this case).

As illustrated below, combining SAE with different deep networks, it is possible to extract more complex and meaningful features from data.

4.2. CNN–SAE
The aim of this configuration is to mine features (spatial-features) expressing relevant relations among the basic-features. With reference to Fig. 2, the encoder and decoder of SAE include a CNN (configuration marked as 1 in Fig. 2), thus the network follows the sequence: input (basic-features), CNN, SAE, fully-connected NN, output.

Let 
, and 
 be the CNN-input, and the th filter, respectively. The convolution operation between the CNN-input () and 
 filters is defined by: (7)
with 
 the components of the filtered input.

The size of  is explicitly defined through its row (
) and column (
) dimension, by: (8)
 
 
where 
 and 
 are the Strides on the row and column, respectively, which control the shifting of the filter on the input. In addition,  is the Padding, which controls the number of zeros around the border of . Padding is used to change the size of CNN-output without compromising the convolution result.

By assuming 
, it is possible to map any 
 to a point 
 in a two-dimensional array (that looks like a 
 matrix). Thus, with abuse of notation, we can assert that: (9)
with , 
, and 
.

By substituting 
 of Eq. (7) into 
 of Eq. (5), it yields: (10)
with 
, while (11)
and (12)
with  according to Eq. (9).

By analogy to Eqs. (5), (6), Eqs. (10), (11) indicate that 
 represent the new extracted features. Such features express a more complex knowledge because they are a linear combination of the original 
 (see Eq. (11)).

4.3. LSTM–SAE
In this configuration (marked as 2 in Fig. 2) LSTMs are used to form, together with SAE, a sequence-to-sequence (STS) architecture (Srivastava et al., 2015). In this architecture, the encoder function maps a sequence of basic-features (time-series of a multivariate input) into a fixed-length vector of new features (latent space), which, in turn, is converted to the same input sequence by the decoder function. This configuration is able to mine short and long-distance dependencies within the sequence of basic-features, and it is being expressed by a compact and powerful representation.

With reference to Fig. 1, we have: (13)
(14)
(15)
(16)
(17)
(18)
 with  and ＋ the element-wise product and addition, respectively. Matrices 
 are linear transformations. 
 is the cell memory state at time . 
 is the output at time .

Let 
 be a -length input sequence of basic-features at different timestamps , the STS-encoder after  recursive updates of the equations from (13) to (18) produces a synthesized output-vector (
) of a predetermined  dimension, which can be expressed by: (19)
with 
 a non-linear multi-variable vector-valued function gathering the work of the LSTM cell for  timestamps.

Let 
 be the th component of 
, then substituting 
 into 
 of Eq. (5), it yields: (20)

By analogy to Eq. (5), Eq. (20) indicates that the extracted features are a non-linear combination of  input ( vectors of basic-features). These new features express a compact representation of the behavior of the basic-features over time.

To give an idea of how the  basic-features are arranged to form the new features, in the following we approximate the 
 function to the first-order Taylor polynomial.

Let 
 be a column-vector of  basic-features taken at different timestamp , with reference to Eq. (19), the th component (
) of 
 is given by 
, where 
 can be derived from the th component of the equations from (13) to (18).

The application of Taylor’s theorem at 
 (Maclaurin’s expansion), stopped to the first-order, yields the following linear approximation of 
: (21)

By supposing both the initial conditions and the bias terms of LSTM as null, then it is: 
, 
, and 
. This leads to 
.

We remark that 
 is a multi-variable scalar-valued function whose gradient is given by: (22)
 
 
 

Thus, Eq. (21) becomes: (23)
 

Since 
 is a -dimensional column-vector, it yields: (24)
 

By substituting 
 of Eq. (24) into 
 of Eq. (5), it yields: (25)
 
which can be expressed as: (26)
 
 
 
 
 
 
 
 

As it is can be seen by Eq. (26), the inner summations express a modified version of Eq. (5) at different timestamps. The new features (
) (temporal-features) express more complex relations with respect to 
. The outer summation (on ) groups the entire history of  inputs into a unique result.

4.4. CNN–LSTM–SAE
In this configuration (marked as 3 in Fig. 2), spatial-features are first extracted, and then their behavior over time is evaluated through temporal-features extracted by the LSTM-cell. Thus, the -dimensional input-vector is first reshaped to form a two-dimensional array (
 matrix), next it is fed to CNN which give a 
 matrix as output (see Eq. (8)), and finally  CNN-outputs are combined by the LSTM-cell to produce a -dimensional vector (
). The inverse sequence acts as a decoder.

With reference to Eq. (7), and according to Eqs. (9), (12), the components (
) of the CNN-output (
) at timestamp  are given by: (27)
with , 
, and 
.

According to Eq. (19), the th component (
) of 
 (LSTM-output) is given by: (28)
which expresses a relation among  features (spatial-features) derived by the CNN.

Thus, with reference to Eq. (5), we have: (29)

Similarly to Eq. (20), Eq. (29) indicates that the extracted features are a non-linear combination of  spatial-features obtained by the CNN stage.

To give a look at the new features, as in the previous case, we use the first-order Taylor expansion to approximate Eq. (28).

We remark that 
 is a composite function, thus let 
 be a column-vector of  CNN-output, and considering null both the initial conditions and the bias terms of LSTM, it is 
, which leads to 
, according to Eq. (27).

Thus, we have: (30)
 

By substituting Eq. (27) into Eq. (30), it yields: (31)
 

Thus: (32)
 
which can be expressed as: (33)
 
 
 
 
 
 
 
 

By comparing the inner summation of Eq. (33) with those of Eq. (26) it is possible to observe the presence of spatial-features (summation on , , and ) in the new features (
). In addition, the outer summation (on ) groups  spatial-features into a unique result.

4.5. Stacked CNN–LSTM–SAE
In this configuration, two SAEs are stacked to form the encoder function. As described in Section 3.4, the hidden layers of these SAEs are connected in sequence after being separately trained. In particular, the first SAE is trained through the CNN–SAE configuration (see Section 4.2) from the basic-features input (configuration marked as 1 in Fig. 2), whereas the second one is trained by using the LSTM–SAE configuration (see Section 4.3) from the output of the first SAE-encoder. This last configuration corresponds to the one marked as 2 in Fig. 2, but its training data are the output of the CNN–SAE configuration previously trained on the basic-features.

According to the mathematical discussion of the previous Sections, and in particular with reference to the Eqs. (7), (12), and (19), the th component of the encoder-output (
) of the first SAE at timestamp  can be written as: (34)
with 
 the th component of the output of the convolution operation at timestamp , according to Eq. (27).

While the th component of the output of the LSTM-cell after  iterations is given by: (35)
and, finally, the th component of the encoder-output (
) of the second SAE at timestamp  is given by: (36)

The above equations show that the new features are a combination of the encoder-weights of both the first (
) and second (
) SAE.

Since Eq. (35) is a composite function, to obtain its Taylor expansion we first compute the Taylor expansion of 
 (Eq. (34)).

By substituting Eq. (27) into Eq. (34) and supposing to use a sigmoid activation function, we have: (37)
 
with (38)

Let 
 be a column-vector of the input at timestamp , and assuming 
, 
 , the Taylor expansion of 
 yields: (39)
 
 
 
with 
 given by Eq. (38).

Let 
, for 
 it yields the following initial condition 
.

Thus, the Taylor expansion of 
 is given by: (40)
 

By substituting Eq. (39) into Eq. (40), it yields: (41)
 
 

Finally, by substituting Eq. (41) into Eq. (36), we have: (42)
 
 
 which can be rewritten as: (43)
 
 
 
 
 
 
 
 
 

Thus, with reference to Eq. (38), the temporal-features at timestamp  are given by: (44)
 

As it can be seen, these new features (
) combine the spatial-features (summation on , , and ) with the weights of both SAEs, that is 
 and 
, respectively. Thus, these new features have an additional degree of freedom with respect to the temporal-features of Eq. (33). Indeed, 
 and 
 are derived by two separate training processes, that is the training of 
 and 
, respectively. In addition, they are not dependent on timestamp . The dependence on the timestamp is introduced from the presence of the partial derivative of 
 with respect to 
, which depends on . Ultimately, this configuration is capable to learn the behavior of the spatial-features over time.

4.6. ConvLSTM–SAE
This configuration is marked as 4 in Fig. 2. ConvLSTM (Convolutional LSTM) (SHI et al., 2015) is a LSTM recurrent neural network in which the matrix multiplications at both input-to-state and state-to-state transitions are replaced by convolution operations. This ensures of adding spatial information in the native cell. Thus, the equations from (13) to (18) become: (45)
(46)
(47)
(48)
(49)
(50)
 with  the convolution operation.

According to Eq. (20), the output of the ConvLSTM–SAE cell after  timestamps can be written as: (51)
with 
 a non-linear multi-variable vector-valued function gathering the work of the ConvLSTM cell for  timeSteps, according to equations from (45) to (50).

5. Experiments and results
The experiments and their results, shown in this Section are devoted to demonstrate the effectiveness of the above discussed configurations in extracting spatial–temporal features and classifying real network traffic. To this purpose, the experiments are conducted by using a recent real dataset of network traffic including traces generated by several workstations involved with different protocols and applications.

5.1. Dataset and basic-features
For this work, we used real traffic data from UNIBS-2009 (NTW group UniBS, 2005), which is a reference dataset used in a huge number of NTC related works. UNIBS-2009 includes traces collected on the campus network of the University of Brescia, Italy on days 2009/09/30, 2009/10/01, and 2009/10/02 together with a reliable ground truth. The traffic was captured by running Tcpdump on a dual Xeon Linux box connected to Internet through a dedicated 100 Mb/s uplink, and stored in three different .pcap files, one for each day. The traffic was generated by twenty workstations running the GT client daemon (Gringoli et al., 2009) to determine the application and protocol behind each generated flow.

The dataset includes around 27 GB of data corresponding to around 79 000 flows including TCP and UDP traffic. The traffic was generated by several applications and protocols, such as Web browsing (HTTP/HTTPS), Mail (POP3, IMAP, SMTP, SSL), Chat (Skype), and Peer-to-Peer (BitTorrent, Edonkey), and other protocols (FTP, SSH, MSN). As depicted in Table 1 the traffic was strongly unbalanced. Indeed, the number of flows varies considerably among different categories.

The pkt2flow utility (Chenxm, Shanghai Jiao Tong University, 2012) was used to extract all the flows from the three .pcap files, while the ground-truth provided by UNIBS was employed to associate any extracted flow to its corresponding application. After that, we considered  labeled flows grouped into four categories as reported below:


Table 1. UNIBS-2009 dataset composition.

Protocol	Flows
Web	61.2%
Mail	5.7%
P2P (BitTorrent)	9.3%
P2P (Edonkey)	18.4%
Skype (TCP)	1.4%
Skype (UDP)	3.8%
Other	0.2%
Total	78 998
•
Mail (5147 flows): This category includes the flows generated by applications that deal with mail through POP3, SMTP, IMAP, SSL, HTTP and HTTPS.

•
Chat (11361 flows): In this category, the instant-messaging applications (Skype and Messenger) are considered.

•
Browsing (45100 flows): This category includes flows generated by a web browser (Safari, Firefox) by using HTTP and HTTPS.

•
P2P (11075 flows): This category is used to identify the flows generated by P2P applications (BitTorrent, Edonkey, amule, Transmission).

Afterward, the Scapy framework (Philippe Biondi and the Scapy community, 2019) was employed to derive some statistical features from each flow. To this purpose, we sampled any flow in temporal windows spaced of 0.001 s, that is to say we used a flow sampling frequency of . For each window, we extracted the following six features (in the following referred to as basic-features):

•
numPKT: number of exchanged packets in the considered time window;

•
numBytes: amount of data exchanged expressed in Bytes;

•
pktAtsec: packets per second;

•
BitRate: bit-rate of the exchanged packets within the time window;

•
interTime: inter-arrival time, that is the time between two consecutive sent packets;

•
avgLenPkt: average length of the packets exchanged in the time window.

The resultant features were arranged to form our dataset. It includes four .csv files, one for any category. The whole dataset consists of  6-dimensional vectors (features) subdivided in , ,  and  for Mail, Chat, Browsing, and P2P categories, respectively.

The machines used to perform the tasks described in this Section came from Amazon Web Services (AWS Educate). We used four t2.xlarge Linux (64-bit)-based instances equipped with 4 vCPU Intel Broadwell E5-2686v4 @ 2.3 GHz, and 16 GB RAM. The task subdivision was accomplished by using PySpark under Amazon EMR (Elastic MapReduce) service. Also, the Simple Cloud Storage Service (S3) of AWS was used for the storage of the flows.

5.2. Pre-processing and experimental setting
As usual, an Exploratory Data Analysis (EDA) was first performed. The obtained results showed that no outliers, missing and zero data were found. Nevertheless, the basic-features were characterized by having different scales, as depicted in Table 2. Also, most of the flows were characterized by having few packets.

The different scales do not contribute equally to the analysis and could create a bias. Indeed, we remark that with reference to the learning update equation (see Eq. (52)) of a neural network, some inputs (
) could strongly affect the weights if they assume high values. (52)
with 
 the weight to update,  the learning rate, and  the th entry of the dataset.


Table 2. Exploratory data analysis.

Feature	Min	Max	Mean	StdDev
numPKT	0	574	3.352	9.281
numBytes	0	346 329	2372.22	8290.87
pktAtSec	0	57 400	335.23	928.14
BitRate	0	277 063 200	1 897 776.91	6 632 698.85
interTime	0	0.01	0.001	0.001
avgLenPkt	0	1500	327.25	462.48
To avoid this issue, we tried different rescaling approaches, such as simple rescaling, min–max normalization, and standardization. The result obtained with the standardization (or Z-score normalization) outperformed all the others. Accordingly, the whole dataset was rescaled to have the properties of a standard normal distribution with zero mean and standard deviation equal to 1 ().

The next step was to split the dataset in order to run the experiments. We remark that each of the network configurations discussed earlier has several hyper-parameters that need to be properly chosen, such as number of neurons, kernel size, activation function, optimizer, and so forth. To accomplish this, the whole dataset was subdivided into two datasets, namely learning and testing dataset. We used 70% of the entire dataset for learning and the remaining 30% for testing. Table 3 shows the exact data partitioning. The former was used to fine-tune the model hyper-parameters, whilst the latter was used to provide an unbiased evaluation of the final model fit on the learning dataset. More precisely, the k-fold cross validation, with k=10, was used to tune the hyper-parameters. To this purpose, the learning set was, in turn, equally partitioned in ten training and evaluation sets. Each model was trained on each training dataset and evaluated on the corresponding testing dataset. The hyper-parameters’ tuning and the model evaluation were programmed in Python by using the Talos library (Autonomio Talos, 2019) for Keras-based (François Chollet, 2015) Python programming on top of the TensorFlow framework with GPU support (Google Brain, 2015).


Table 3. Content of training and testing dataset.

Category	Learning	Testing	Total
Mail	50 950	21 835	72 785
Chat	111 770	47 902	159 672
Browsing	350 608	150 261	500 869
P2P	484 023	207 439	691 462
Total	997 351	427 437	1 424 788
5.3. Evaluation metrics
Once the hyper-parameters setting was performed, the entire learning set was used to fit the model with the found hyper-parameters. To appreciate the classification quality of the above-mentioned models and according to the definition of traffic flow defined in RFC 3272,1 we used the following metrics computed on the testing dataset and derived from the multi-class confusion matrix (Diez, 2018): (53)
 
(54)
 
(55)
 
(56)
 
(57)
 
(58)
 
 where for each category, TPs (True Positives) are the flows correctly classified, FPs (False Positives) are the flows incorrectly classified, FNs (False Negatives) are the flows incorrectly rejected, and TNs (True Negatives) are the flows correctly rejected.

The Python library scikit-learn (David Cournapeau, 2007) was used to compute these metrics. All the experiments were conducted with a PC-Desktop equipped with an Intel 4-Core I7-8565U CPU @ 2.00 GHz, 16 GB RAM, and NVIDIA GeForce MX150 GPU with 4 GB of memory. The parallelization was accomplished by using Numba JIT compiler (Anaconda, Inc., 2012).

5.4. Models description and results
As described earlier, for each architecture we tried different hyper-parameters to show the effectiveness of the proposal. More precisely, we varied the following:

•
numLayers: the number of layers in a network ();

•
numNeurLayer: the number of neurons for a layer ();

•
filters: the number of filters for CNN ();

•
kernel_size: the shape and dimension of the filter in CNN. We used , , ;

•
padding: how the filter size impact on the output. We used three cases, that is: valid, causal, and same;

•
activation: activation functions (relu, tanh, sigmoid);

•
pooling: pooling (nothing, MaxPooling, AveragePooling);

•
stride: the stride length of the convolution. We used  and ;

•
numLSTMcell: the number of cells in a LSTM layer ();

•
timeSteps: the number of observations used as input time steps for LSTM. We used , , , , and ;

•
optimizer: the optimizer used by Keras to compile the model. We used Adam, Adamax, and Nadam;

•
loss: the loss function used to fit the network. We used mse, categorical_crossentropy, focal_loss. We remark that focal_loss is useful for unbalanced dataset.

Ultimately, we considered over five millions of different combinations.

Accordingly, in this section only the network configurations that gave the better results are shown.

With reference to Fig. 2, each network configuration shown in Section 4 is followed by two fully-connected layers comprising  and  neurons, respectively. Two Dropouts of 0.5 were also added among layers. In order to obtain the classification results as probability distributions, the soft-max activation function was added at end of these two layers. The class corresponding to the maximum of these probabilities was considered to be the output of the classification. The network was trained for 100 epochs with the categorical-cross-entropy and Adam as loss function and optimizer, respectively.

In addition, any architecture was trained through the early-stopping technique (Prechelt, 1997), which stops the training process if the value of the loss function remains roughly unchanged for several epochs.

5.4.1. CNN–SAE–NN
The first model analyzed was the combination CNN-AE-NN. In this configuration, any 6-dimensional vector of the basic-features was considered as an image and, therefore, it was arranged to a  matrix according to Eq. (59) and fed as input to the CNN. (59)
 

According to Eq. (11), the derived features of the CNN–SAE–NN network can represent linear correlations of the input (numPKT, numBytes, pktAtSec, BitRate, interTime, and avgLenPkt), and then, with reference to the matrix configuration of Eq. (59), they express a spatial correlation of the input, namely: spatial-features.

The best architecture for the encoder, derived by the training step, was composed by two CNN layers of 4 and 13 -filters, respectively, with activation=relu, padding=same, and no pooling. The decoder side was built by using the inverse combination of these layers. Thus, the latent space was derived from the second CNN layer, which was first flattened and then fed into the fully-connected softmax neural network. We remark that the flattening layer was necessary in order to adapt the -dimensional latent space to the input of the NN.

Table 4, Table 5 show the confusion matrix and the evaluation metrics, respectively. The results were obtained by training the network with Adam optimizer and mse loss-function for 10 epochs.


Table 4. Confusion matrix for CNN–SAE–NN configuration.

Predicted
Mail	Chat	Browsing	P2P
Actual	Mail	18 971	400	2342	122
Chat	1474	42 473	1240	2715
Browsing	57	51	150 079	74
P2P	525	255	2803	203 856

Table 5. Metrics for CNN–SAE–NN configuration.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.988	0.869	0.995	0.902	0.932	0.885
Chat	0.986	0.887	0.998	0.984	0.942	0.933
Browsing	0.985	0.999	0.977	0.959	0.988	0.979
P2P	0.985	0.983	0.987	0.986	0.985	0.984
5.4.2. LSTM–SAE–NN
This model is composed of the combination LSTM–SAE–NN. As discussed earlier, LSTM needs a time series of dimensions defined by the timeSteps hyper-parameter as its input. The training step led to have the best timeSteps of  with a stride of 1. Most probably the reasons of this is that most of the flows are composed of few packets, as shown from the results of EDA. However, as it will be discussed in the next section, this is an important aspect for the NTC task, because this means that the classification can be performed by considering a very low number of packets.

The encoder was composed by the sequence of two LSTM layers of 16 and 136 cells, respectively. In the first LSTM layer, the return_sequence parameter was set to True, whilst for the second layer it was set to False. We remark that the return_sequence parameter set to True produces as much output-vectors as timeSteps (i.e. iteration number of LSTM), whilst the False value is used to consider the last iteration, only. Thus, the latent space was a 136-dimensional vector.

To build the decoder, a RepeatVector layer with timeSteps=5 was used, which copied the last vector timeSteps times. This allowed the latent space to be adapted to the first LSTM layer of the decoder.

Finally, the latent space, derived by the second LSTM layers, was fed into the fully-connected softmax neural network.

Table 6, Table 7 show the confusion matrix and the metrics, respectively. The LSTM–SAE sequence was trained with the Adam optimizer and the mse loss-function for 10 epochs. As depicted, according to Eq. (26), the more complex features extracted by this configuration allow gathering insights over time, which leads to an improvement in performance.


Table 6. Confusion matrix for LSTM–SAE–NN configuration.

Predicted
Mail	Chat	Browsing	P2P
Actual	Mail	21 519	89	65	161
Chat	403	47 275	41	181
Browsing	176	26	149 895	162
P2P	971	392	1173	204 901

Table 7. Metrics for LSTM–SAE–NN configuration.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.996	0.986	0.996	0.933	0.991	0.958
Chat	0.997	0.987	0.999	0.989	0.993	0.988
Browsing	0.996	0.998	0.995	0.992	0.996	0.995
P2P	0.993	0.988	0.998	0.998	0.993	0.993
5.4.3. CNN–LSTM–SAE–NN
This model exploits both the combinations CNN–SAE and LSTM–SAE in order to capture both the spatial and the temporal features from the basic-features, respectively. As described in Section 4.4, the basic-features were first reshaped to form a -matrix, next two convolutional layers including 16 and 6 filters, respectively, both with a kernel size of  were used. After that, a flattening layer was employed to create a one-dimensional vector to be sent to LSTM layers. A timeSteps of  was used for the LSTM layers, thus three TimeDistributed layers, with timeSteps=5, were used on the two convolutional layers and the flattening layer, respectively. Next, the resultant TimeDistributed flattened CNN-vector was fed to the first LSTM layer characterized by 16 cells and return_sequence parameter set to True. Next, a second LSTM layer including 136 cells and return_sequence=False was used. Thus, the latent space was represented by the output of this last layer, which is a 136-dimensional vector. The decoder was implemented by the reverse sequence of the described encoder.

The CNN–LSTM–SAE network was trained with the Adam optimizer and the mse loss-function for 10 epochs. Table 8, Table 9 show the confusion matrix and the evaluation metrics, respectively.


Table 8. Confusion matrix for CNN–LSTM–SAE–NN configuration.

Predicted
Mail	Chat	Browsing	P2P
Actual	Mail	19 964	445	1223	202
Chat	1574	43 598	2446	282
Browsing	947	2476	144 677	2159
P2P	944	1425	5619	199 449

Table 9. Metrics for CNN–LSTM–SAE–NN configuration.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.988	0.914	0.991	0.852	0.953	0.882
Chat	0.980	0.910	0.989	0.909	0.949	0.910
Browsing	0.965	0.963	0.966	0.940	0.965	0.951
P2P	0.975	0.961	0.988	0.987	0.975	0.974
5.4.4. Stacked-CNN–LSTM–SAE–NN
This configuration differs from the previous for the presence of different training steps. More precisely, the CNN-AE and LSTM-AE configurations were separately trained. The former was trained through the basic-features (3 × 2 matrix), while the latter was trained by using the encoder-output of the CNN-AE model. Next, the resultant latent spaces (corresponding to CNN-AE and LSTM-AE, respectively), were dislocated in sequence along with the fully-connected NN to form the stacked network. We remark that the LSTM layer needs a time series, thus, to accomplish this, timeSteps CNN-outputs were reshaped as the input for the LSTM layer. The hyper-parameters used in this configuration were the same as in the previously discussed configurations.

Table 10, Table 11 show the confusion matrix and the evaluation metrics, respectively.


Table 10. Confusion matrix for stacked-CNN–LSTM–SAE–NN configuration.

Predicted
Mail	Chat	Browsing	P2P
Actual	Mail	21 765	30	40	0
Chat	17	47 652	20	213
Browsing	22	93	150 146	0
P2P	120	300	148	206 871

Table 11. Metrics for stacked-CNN–LSTM–SAE–NN configuration.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.999	0.997	1.000	0.993	0.998	0.995
Chat	0.998	0.995	0.999	0.991	0.997	0.993
Browsing	0.999	0.999	0.999	0.999	0.999	0.999
P2P	0.998	0.997	0.999	0.999	0.998	0.998
5.4.5. ConvLSTM–SAE–NN
In this configuration two ConvLSTM layers were used in sequence with 16 and 6 filters of size , respectively. For both layers the activation functions was set to relu and padding=same. The return_sequence of the second layer was set to True, which means that the flattened version of the latent space was represented by a 180-dimensional vector. This because the 6 filters produced in output 6 -matrices, which combined with timeSteps=5, it is . By using the same hyper-parameter of the previous configuration, we have the outcomes shown in Table 12, Table 13.


Table 12. Confusion matrix for ConvLSTM–SAE–NN configuration.

Predicted
Mail	Chat	Browsing	P2P
Actual	Mail	21 735	55	44	0
Chat	383	47 274	149	94
Browsing	69	24	150 058	108
P2P	409	100	1519	205 409

Table 13. Metrics for ConvLSTM–SAE–NN configuration.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0,998	0,995	0,998	0,962	0,997	0,978
Chat	0,998	0,987	1,000	0,996	0,993	0,992
Browsing	0,996	0,999	0,994	0,989	0,996	0,994
P2P	0,995	0,990	0,999	0,999	0,995	0,995
5.4.6. Deep-SAE–NN
For the sake of completeness, we also provide the results for an architecture characterized by having only NN layers, without CNN and LSTM layers. We tried different combinations of layers and neurons for layers. Table 14, Table 15 show the results for the best one. It included the sequence of two fully-connected layers of 64 and 132 neurons, respectively.


Table 14. Confusion matrix for Deep-SAE–NN configuration.

Predicted
Mail	Chat	Browsing	P2P
Actual	Mail	13 677	120	613	7425
Chat	438	34 924	289	12 251
Browsing	2117	493	108 289	39 362
P2P	1636	947	3518	201 338

Table 15. Metrics for Deep-SAE–NN configuration.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.971	0.626	0.990	0.765	0.808	0.689
Chat	0.966	0.729	0.996	0.957	0.862	0.828
Browsing	0.891	0.721	0.984	0.961	0.852	0.824
P2P	0.848	0.971	0.732	0.773	0.851	0.861
5.5. Comparison and discussion
In order to show the effectiveness of the use of the spatial–temporal features, in this Section we compare the previous results with the ones obtained on the same data (i.e. the dataset including basic-features) by some classical and popular state-of-the-art machine learning-based techniques, such as Naive Bayes-based classifier (NB), J48 decision-tree classifier (J48), and Multi Layer Perceptron classifier (MLP). For better highlighting the advantages introduced by SAE, the results obtained by considering only the CNN and LSTM networks, followed by a fully connected NN, are also shown. Tables 16, 17, 18, 19, and 20 report the numeric values of the obtained metrics. In addition, in Fig. 3 a graphical representation of the performance metrics averaged across all classes for any configuration is depicted.

As depicted, all the machine learning-based classifiers were not able to correctly classify the different categories. Notice that the imbalance of the dataset strongly affected the performance of all classifiers. Indeed, maximum sensitivity/Fmea (i.e. , , and  associated with NB, J48, and MLP, respectively) was achieved by all classifiers only for the P2P traces, which include the maximum number of flows. In other words, these classifiers saw the traces of Mail, Chat, and Browsing as noise, and then they tend to neglect them.


Table 16. Metrics for Naive Bayes classifier.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.945	0.001	0.996	0.017	0.499	0.002
Chat	0.911	0.276	0.992	0.807	0.634	0.411
Browsing	0.703	0.214	0.968	0.786	0.591	0.336
P2P	0.588	0.965	0.234	0.543	0.599	0.695

Table 17. Metrics for J48 classifier.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.958	0.565	0.979	0.594	0.772	0.579
Chat	0.947	0.666	0.982	0.825	0.824	0.737
Browsing	0.811	0.547	0.954	0.865	0.750	0.670
P2P	0.761	0.912	0.619	0.693	0.765	0.787

Table 18. Metrics for MLP classifier.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.944	0.133	0.988	0.368	0.561	0.196
Chat	0.917	0.326	0.992	0.837	0.659	0.469
Browsing	0.763	0.521	0.895	0.729	0.708	0.607
P2P	0.690	0.888	0.503	0.628	0.696	0.735

Table 19. Metrics for pure CNN–NN classifier.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.957	0.394	0.987	0.637	0.691	0.487
Chat	0.964	0.711	0.996	0.958	0.853	0.816
Browsing	0.860	0.693	0.950	0.883	0.821	0.777
P2P	0.820	0.942	0.704	0.750	0.823	0.835

Table 20. Metrics for pure LSTM–NN classifier.

Acc	Sens	Spec	Prec	AUC	Fmea
Mail	0.965	0.834	0.972	0.615	0.903	0.708
Chat	0.960	0.907	0.966	0.770	0.937	0.833
Browsing	0.896	0.821	0.936	0.870	0.878	0.845
P2P	0.875	0.857	0.893	0.888	0.875	0.872
On the other hand, as shown in Table 14, Table 15, the only usage of SAE is sufficient to solve this problem. Indeed, the sensitivity and Fmea for Mail (), Chat (), and Browsing () achieved values higher than the ones obtained by J48 classifier (i.e. , , and  for Mail, Chat, and Browsing, respectively), which is the best among J48, MLP, and NB. On average, an improvement of around 17% was achieved.

Also, although the CNN–NN and LSTM–NN configurations scored slightly better than those based on machine learning (around 2% for CNN–NN and 26% for LSTM–NN with respect to J48 calculated on the average sensitivity), the introduction of SAE increased significantly the performance, as it is observable by the results shown in Table 5, Table 7, respectively. Indeed, on average, the accuracy achieved by CNN–SAE–NN and LSTM–SAE–NN increased of around 9% and 8% with respect to CNN–NN and LSTM–NN, respectively.

Besides, although the sensitivity for P2P achieved great values for all the classifiers, it is important to highlight that the specificity achieved low levels. This means that NB, J48, MLP, as well as CNN–NN and LSTM–NN classified almost all the traffic as P2P. This was confirmed by the low values of the precision, AUC, and F-measure metrics.

On the contrary, the SAE-based architectures achieved similar scores for all the metrics. Finally, the configuration that achieved the maximum performance was stacked-CNN–LSTM–SAE–NN, which on average achieved a score near to 100% for all the metrics, as depicted in Fig. 3.


Download : Download high-res image (524KB)
Download : Download full-size image
Fig. 3. Classification metrics averaged across all classes.

To provide a graphical interpretation of how the introduction of CNN and LSTM layers in the SAE affect the features transformation, we visualized the high-dimensional latent space of each architecture above studied in a two-dimensional plane. To accomplish this, we used the t-Distributed Stochastic Neighbor Embedding (t-SNE) (van der Maaten and Hinton, 2008). t-SNE is a widely used approach for non-linear data dimensionality reduction, which allows the data visualization on a two- or three-dimensional plane.

The representation of the basic-features and their pre-processed versions are depicted in Figs. 4, 5, and 6, respectively. As depicted, the basic-features (Fig. 4) have a unique well visible group corresponding to P2P, while Mail, Chat, and Browsing follow curves which in most cases are overlapped. On the other hand, the separability of data is more visible for the min–Max normalization (Fig. 5), and more and more evident for the standardization at zero-mean (Fig. 6). Indeed, even though Browsing and Chat remain overlapped, Mail and P2P are placed in separate regions.

As shown in Fig. 7, the introduction of the CNN layer leads to a major data separability. Indeed, Mail, Browsing, and P2P form three separate groups, which portends a good classification. However, some overlaps are present, which lead to incorrect classifications, as reported in Table 4, Table 5. Many entries of Chat are incorrectly classified as Mail (1474), Browsing (1240), and P2P (2715). A similar thing appears for Mail.

Fig. 8 depicts what happens when the LSTM layer is used. As shown, groups tend to expand. Although the result is the scattering of the data, it should be noted that data are not overlapped. This leads to a marked improvement in classification, as reported in Table 6, Table 7.

The expansion effect is more marked when the CNN–LSTM layer is introduced, as depicted in Figs. 9, 10, and 11. Nevertheless, as confirmed by the results reported in Table 8, Table 9, and with reference to Fig. 9, the CNN–LSTM configuration presents some overlaps, which lead to the presence of wrong classifications.

The maximum expansion is achieved with the Stacked-CNN–LSTM configuration (see Fig. 10), which achieves the best classification performance. Indeed, as shown in Table 10, Table 11, for this architecture all the metrics resulted in a value very close to .

Although the outcomes of the ConvLSTM are very good (see Table 12, Table 13), it tends to group the features, as depicted in Fig. 11. This, in turn, leads to a degradation of the performance.

Ultimately, the Stacked-CNN–LSTM–SAE–NN configuration appears to be the best architecture for extracting the spatial–temporal features from the basic-features.

6. Conclusion and future work
In this paper, we investigated the potentiality of novel self-learned spatial–temporal features in classifying real network traffic and provided a detailed description of several deep neural autoencoder network architectures for learning such meaningful features.

Starting from some statistical features (basic-features), extracted from traffic flows over a given temporal window, we derived new features able to mine relevant knowledge existing among such features (spatial-features) and among such features over time (temporal-features). Although such new features are based on the basic ones, such as packet size, number of packets, etc., they have proven to be more effective for NTC purposes.

To extract such features, we proposed a deep neural network architecture based on autoencoders (AEs) whose encode–decode functions could include several combinations of convolutional and recurrent network layers. In particular, we investigated the following combinations: CNN, LSTM, CNN–LSTM, ConvLSTM, and Stacked-CNN–LSTM. The convolutional network was employed for extracting spatial-features, while the LSTM recurrent network was used for extracting temporal-features. As confirmed by the experimental results, the introduction of CNN and LSTM layers into a Sparse AE (SAE) led to a significant improvement of the classification performance. Indeed, as shown through mathematical formalisms and t-SNE graphic representations of the results, each one of these layers introduced specific transformations to input data. More precisely, we found that the CNN–SAE tends to cluster data in their respective classes, while LSTM–SAE tends to expand data without introducing overlapping among the different classes. Consequently, both the architectures achieved good performance, around 98% and 99% on average accuracy, respectively. However, the best performances were obtained when both configurations were joint in a unique architecture, namely the Stacked-CNN–LSTM configuration. It was able to take advantage of both CNN–SAE and LSTM–SAE for extracting the spatial–temporal features from the basic-features. All the performance metrics achieved values very close to 100%. Besides, the features derived from the latent-space of the SAE demonstrated to be robust with respect to the unbalancing of class distribution present in the training dataset. The investigated state-of-the-art network architectures that do not use AE, such as Naive Bayes, J48 decision-tree, and Multi-layer Perceptron, as well as pure CNN and LSTM showed a very low capability in distinguishing the four traffic classes considered (i.e. Mail, Chat, Browsing, P2P). More precisely, the class imbalance in training dataset led the state-of-the-art approaches to incorrectly consider almost all the traffic as P2P, which included the maximum number of flows. On the contrary, the usage of AEs, more specifically of a SAE was sufficient to overcome this issue.

The ability of the proposal of obtaining excellent results in NTC without using neither payload inspection nor IP-addresses and port-numbers encourages us to plan several future works. First, we intend to extend the target application environments. For example, the proposal can be useful to differentiate encrypted traffic, such as distinguishing Skype activities, Tor traffic, etc. Second, we intend to use it within an Intrusion Detection System (IDS) to detect security vulnerabilities of several frameworks, such as automotive, Wi-Fi, IoT, Tunneling, Robust Fake News Detection, and so forth. Nevertheless, these are only some examples of the research fields that could benefit from the usage of the proposed NTC approach. Indeed, it can also be applied in many other research and industry fields in which it is necessary to extract spatial–temporal features.

