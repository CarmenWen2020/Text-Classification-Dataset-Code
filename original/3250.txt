Virtual data center (VDC) embedding is being regarded as a critical issue to provide performance guarantees for the future success of cloud computing. Most existing works neglected the embedding of virtual switches (VSs), especially, on the physical switches (PSs), resulting in low utilization of physical resources. Moreover, most works assumed that multiple virtual nodes in the same request cannot be embedded in the same physical node, leading to low embedding efficiency in data centers. To address the above two problems, in this paper, we first propose two fine granularity models to formulate the VDC embedding problem efficiently with the consideration of two possible embedding positions of VSs. Then traditional flow conservation law is modified to allow multiple virtual nodes to coexist on the same physical node. Finally, we propose multiple efficient embedding algorithms to solve two NP-hard problems. Comparing with existing methods, our algorithms employing heuristic information from the relaxed model can find sub-optimal solutions in polynomial time. Extensive simulation results show that our proposals outperform the existing methods in terms of acceptance ratio, revenue, and utilization.


Keywords
Cloud computing
Virtual data center
Virtual switch
Embedding
Heuristic algorithm

1. Introduction
Cloud computing is a pervasive paradigm with tremendous impacts on the IT industry. As the fundamental technology of cloud computing, virtualization is a key technology to the current and future success of cloud computing (Varghese and Buyya, 2018; DÃ­az et al., 2016). Nowadays, virtualization has been elaborately divided into computation virtualization, network virtualization (Cerroni et al., 2019; Chowdhury and Boutaba, 2009), and storage virtualization. The integration of three elements forms the concept of the virtual data center (VDC) (Bari et al., 2013). It refers to that virtual machines (VMs) are interconnected through virtual switches (VSs), virtual routers (VRs), and virtual links (VLs) with guaranteed bandwidth. The data center virtualization enables the physical data center (PDC) to operate multiple VDCs in an isolation environment and increases the utilization of hardware. In addition, the VDC scheme allows the third enterprise (refer as the tenant) to achieve better performance on Quality of Service (QoS) and security for their provided services, since VDC has been decoupled from physical resources.

Although the emergence of VDC solves the drawbacks of traditional data centers, such as low utilization, high operation cost, and lack of isolation (Schulz, 2016), the VDC requests (VDCRs) mapping problem, which is efficiently allocating multiple types of physical resources to multiple VDCRs, is still a challenge in modern data center operation (Bayless et al., 2020). The physical resource includes the CPU core, storage space, network bandwidth, switch port, etc. To reduce the operation costs and make more profits, the PDC providers, i.e., infrastructure providers (InPs), must carefully handle tenants' requests (tenants may submit one or more VDCRs). InPs must decide which VDCRs are accepted or rejected, and allocate corresponding resources to the accepted VDCRs. It is commonly known as the embedding problem.

Vdc planner (Zhani et al., 2013), Greenhead (Amokrane et al., 2013), and Venice (Zhang et al., 2014) are early works that have been putted forth to study VDC embedding problem. These previous works provided basic conceptions, mathematic formulations for the VDC embedding problem. Recently some references focus on improving the embedding efficiency (Bayless et al., 2020; Guo et al., 2019; Nam et al., 2017; Sun et al., 2017; Kaur et al., 2020; Liu et al., 2019, 2020), and others discuss the scalability (Bayless et al., 2020), survivability (Lo and Liao, 2017; Sun et al., 2019), or service level agreements (SLA) (Sun et al., 2019; Amokrane et al., 2015). In past years, Software-defined networking (SDN), as a new network paradigm, has attracted significant interests from both academic and industrial fields. Some researchers try to consolidate VDC embedding with SDN mechanism (Han et al., 2015; Miao et al., 2015; Kondepu et al., 2018; Huang et al., 2017), because it further optimizes traffic load during embedding. However, existing works have not fully considered all kinds of resources and the feature of data center networks (DCNs).

Generally, DCNs are equipped with various types of network devices, such as firewalls, switches, routers, caching devices, etc. Especially, to maintain the robustness of DCNs, there are abundant switches and links, which are used for load balancing or redundant. Few existing works consider the embedding of switches, especially on the physical switches (PSs). Although the physical switches (PSs) have fewer available resources compared with physical machines(PMs),1 as aforementioned, a large number of switches exist in DCNs. The utilization of these PSs certainly improves embedding efficiency and InPs's profit. The traditional virtualization technique is unapplicable for PSs due to resource restriction. However, in recent years, the lightweight virtualization technique â€“ â€œdockerâ€ (Bernstein, 2014), make the VSs embedding on PSs feasible. On the other hand, the software switches (Virtual switches) have been studied in SDN for the agility of controlling flows. The virtual switches (VSs), such as â€œopen vswitchâ€ (Pfaff et al., 2015), can be integrated into hypervisor which runs on PMs, or can be instantiated on hardware switches (Emmerich et al., 2018).

In this paper, we study the VDC embedding problem with the consideration of VSs, specifically, VSs can be embedded in either PMs or PSs. Fig. 1 shows an overview of our VDC embedding scene. Different from previous works, VM nodes and VS nodes in a VDC are treated to be different nodes. VMs can only be embedded in PMs. VSs are embedded in either PMs or PSs. The resources of PSs are fully utilized. In fact, the two possible embedding positions increase the agility and scalability of the VDC embedding problem as well as the acceptance ratio, further boosting the profits of InPs. To maximize InPs' profits, we propose two dedicated models: the online model and the batch model. Both models consider multiple types of resources. The online model handles VDCRs in real-time, however, the batch model can further improve VDCRs acceptance ratio in the long term. Two VDC embedding problems (corresponding to the online model and batch model) are proven to be NP-hard. Moreover, to further reduce the embedding cost, we consider the elements from one VDC to be embedded in the same physical nodes, such as VDC 3 in Fig. 1. To achieve this, we improve the traditional flow conservation law (FCL).

Fig. 1
Download : Download high-res image (675KB)
Download : Download full-size image
Fig. 1. A diagram denotes VDC embedding problem with the consideration of the VSs. VSs can be mapped on PMs or PSs. VMs can only be embedded in PMs.

To solve two embedding problems in polynomial time, we first design a group of algorithms that transfer the batch model to the online model, then propose a fast heuristic algorithm to solve the online model. The advantage in time complexity comes from the heuristic information of the relaxing model. Next, we analyze the complexity of two algorithms respectively. Finally, we evaluate the performance of two embedding algorithms. The main contributions of this paper are summarized as follows.

â—
Firstly, we formulate two precise mathematical models for VDC embedding with consideration of multiple type resources and embedding of VSs. To the best of our knowledge, this is the first effort to consider embedding VSs on both PMs and PSs.

â—
Secondly, we modify the traditional FCL to allow multiple virtual nodes (VNs) belonging to the same VDCR to be embedded in the same physical node (PN). The modified flow conservation law (MFCL) ensures the integrality of â€œvirtual pathâ€ and its reversed bandwidth when VLs are embedded in PLs.

â—
Thirdly, we propose multiple heuristic algorithms to solve NP-hard problems efficiently. Compared with other methods, our embedding algorithms take full advantage of heuristic information from relaxed solutions of our models, and achieve a good tradeoff between efficiency and quality.

â—
Finally, extensive simulation results show that our algorithms outperform most of existing methods in terms of acceptance ratio, revenue, and utilization.

The rest of the paper is organized as follows. In section 2, we survey the state-of-art related works. Some preliminary works, i.e., decision variables, virtual path, modified flow conservation law, are proposed in Section 3. In section 4, we first provide a mathematical formulation of realtime (online) embedding model, and propose a fast heuristic embedding algorithm to solve the online embedding problem in polynomial time complexity. In section 5, we propose the batch embedding model for further improving embedding efficiency. A transfer algorithm is designed to reduce computation complexity. The batch embedding problem is simplified as multiple online embedding problems. In section 6, extensive simulations are executed for evaluating the performances of our algorithms, and finally, Section 7 concludes this paper and discusses directions for future work.

2. Related work
â€œVDC Plannerâ€ (Zhani et al., 2013) is pioneer literature that proposed a migration-aware embedding framework, where VMs migrations can be utilized to flexibly and dynamically adjust the allocation of physical resources. However, the authors did not discuss the process of VLs rebuilding after VMs migration. Hardware failure characteristics are incorporated into the embedding framework for achieving high VDC availability in â€œVeniceâ€ (Zhang et al., 2014), The availability computing of PMs and PLs are introduced in their modeling. Similar works can be found in Xu et al. (2012), where backup VMs are created and synchronized during embedding primary VMs. To improve VDC availability, spreading replicas across a large number of physical nodes is a good strategy, however, it may go against the goal of minimizing embedding cost. Thus, the authors need to find a trade-off between these objectives. In Amokrane et al. (2013), a framework called â€œGreenheadâ€ is proposed to manage resources for VDC embedding across geographically distributed PDCs. Multiple goals including revenue maximization, operational cost reduction, and energy efficiency are discussed. To addresses the resource fragment which is caused by VDCRs' continuous joining and leaving, the authors in Nam et al. (2017) and Sun et al. (2017) proposed a VDCRs consolidation strategy to tackle the dynamic problem. For further improving embedding time efficiency and adapting to large-scale of VDCRs, Bayless et al. proposed a â€œnetsolverâ€ which supports multi-path bandwidth allocation for arbitrary DCNs topologies. They claim that the solver just requires seconds to allocate VDCRs with a dozen VMs on large-scale PDC.

The above research articles do not involve the embedding of the switch, which is a key device in DCNs. The authors in Lo and Liao (2017) analyzed the important role of switches in DCNs, and the failure impact of edge switch, aggregation switch, and core switch for VDC embedding. Finally, they established a linear programming model to optimally solve the embedding problem with the minimum total bandwidth consumption. Considering the inefficiency of using the unicast technique to transmit data for multiple ends, the authors in Guo et al. (2019) proposed a mixed VDC embedding approach, which employs the multicasting capability of switches to carry multicast sessions in VDCs. â€œSecondNetâ€ (Guo et al., 2010) pointed out that maintaining bandwidth allocation state at switches is a prohibitively expensive solution. The authors addressed the issue by distributing those states at the hypervisors of PMs and employing a port-switching based source routing. Although the PMs are stateless, each PM must maintain the whole network topology, in-band spanning trees, port-switching table, and encode route into each packet to ensure the correct routing. Obviously, their solution bring much burden to PMs.

Currently, many researchers try to introduce the SDN mechanism into the VDC embedding problem due to its agility of flow control. In Han et al. (2015), the authors proposed a SDN assisted embedding solution. It employs SDN based traffic engineering to further reduce the energy consumption during VDC embedding. In Miao et al. (2015), the authors investigated a SDN-enabled reconfigurable VDC embedding. By leveraging SDN, VDCRs can be flexibly reconfigured and managed, significantly improving the PDC's flexibility and controllability. Since the flow control is performed by VSs, some authors realized the importance of VSs and considered the embedding of VSs.

Although some related VDC embedding works consider the VSs or PSs, few works involve the embedding of VSs. Yang et al. (2017) considered virtual switches in VDCRs and selected servers as close as possible while embedding VMs and mapping VSs and VLs simultaneously so as to reduce both energy consumption and system cost. Rabbani et al. (2013) proposed a three-phase heuristic algorithm to embedding VMs, VSs, and VLs in VDCRs. Ghazisaeedi and Huang (2017) incorporated the embedding of VSs into their cost model, however, they treated VSs and VMs together as virtual nodes during solving their models. The authors in Ma et al. (2018) studied the cost-aware multi-domain VDC embedding problem and incorporated the energy consumption of the VSs embedding in their model. Furthermore, they proposed a two-step algorithm that solves inter-domain embedding and intra-domain embedding respectively. However, these works did not pay attention to two possible embedding positions (PSs and PMs) of VSs.

3. Prepare works and formulations
In this section, we first elaborate on the advantage of embedding VSs and introduce the decision variables for embedding VMs, VSs, and VLs. Then, we modify the traditional flow conservation law to ensure the correct embedding of virtual paths.

3.1. Benefits of VSs embedding on PSs
As aforementioned, VSs can be embedded in two positions: one is in PMs through integrated hypervisor and the other is in PSs. Compared with previous works (Rabbani et al., 2013; Yang et al., 2017; Ghazisaeedi and Huang, 2017) assuming VSs are only embedded into PMs, two embedding positions of VSs increase the embedding success ratio due to the following two reasons: i) the VDCRs acceptance ratio improves with the utilization of resources of PSs; ii) the cost of embedding VLs is reduced.

We provide two simple examples to illustrate.

Fig. 2 demonstrates the first reason. In Fig. 2(a), two VDCRs consist of 30 unit resource requests, i.e., CPU cores. The rectangle and circle represent switch and machine respectively. Only PMs in the physical network provide 30 unit resources. Although the available resource equal to the number of requests, two VDCRs can not be embedded simultaneously. In Fig. 2(b), both VDCRs are successfully embedded due to that one VSs is embedded in PSs.

Fig. 2
Download : Download high-res image (265KB)
Download : Download full-size image
Fig. 2. Two VDCRs consist 30 unit resource requests, PMs in the physical network provide 30 unit resource, However, two VDCRs can not be embedded simultaneously without the resource of PSs. The VDCRs acceptance ratio improves with the utilization of resources of PSs.

In VDC embedding, if VMs and VSs are embedded in different PMs, then all PLs between the two PMs must reserve corresponding bandwidth for VLs. Fig. 3 shows the comparison of embedding cost of VLs. Fig. 3(a)â€“(c) are solutions without VSs embedding on PSs. To satisfy the bandwidth requirements, we note that the solutions in these figures require high bandwidth allocation on two PLs especially in Fig. 3(c). The required bandwidth reaches to 280 on both PLs, which exceeds the available bandwidth. It ascribes to the inappropriate placement of VSs. In contrast, Fig. 3(d) shows a good solution by employing PS. This solution not only saves the resources of PMs, but also reduces bandwidth allocation greatly. Generally, the VLs between two VNs may be across multiple PLs, two ends of the VLs should be placed as close as possible to reduce the VLs embedding cost. So, as intermediate nodes between PMs, PSs are good embedding positions for VSs. We can conclude from the two simple examples are shown in Fig. 2, Fig. 3 that the embedding VSs on PSs can boost requests acceptance ratio of VDC embedding and further increase InPs' revenue.

Fig. 3
Download : Download high-res image (824KB)
Download : Download full-size image
Fig. 3. The example of embedding two VDCRs. (a), (b), and (c) are all possible embedding solutions of two VDCRs without employing PS and these solutions incur high bandwidth reservation due to improper embedding of VSs, while (d) shows a good solution with employing PS.

3.2. Network model, decision variables and profits
We model the PDC network as an undirected graph, denoted as Gp = (Mp, Sp, Ep) where Mp represents the set of PMs, Sp denotes the set of PSs including core switches, aggregation switches, and ToR switches, and Ep represents the set of all PLs. Each PM mp âˆˆ Mp provides resources, such as CPU, memory, and disk, etc. In this paper, three types of resources are primarily taken into account. Let Ac(mp), Am(mp) and Ad(mp) denote current available CPU, memory, disk resources on mp. Similarly, let Ac(sp) and Am(sp) denote the CPU and memory resources provided by physical switch sp âˆˆ Sp. Note that storage resources are neglected because switches are generally regarded as stateless, and the flash storage on switches is limited. The commonly used variables and notations are summarized in Table 1. A VDCR is denoted as 
, where 
, 
 and 
 are the set of VMs, VSs and VLs, respectively. Each VM 
 has its own resource requirements denoted as Rt(mv) where t âˆˆ{c, m, d}. The element in set {c, m, d} denotes the abbreviation of CPU resource, memory resource and disk resource, respectively. Similarly, resource requirements of each VS, 
, are denoted as Rt(sv) where t âˆˆ{c, m} and Rb(ev) represents bandwidth requirement of each VL 
.


Table 1. List of notations.

Notation	Definition
Specific VDC request
Gp	PDC and attributes of resources
Set of all VMs in 
Set of all VSs in a 
Set of all VLs in a 
t	Set of all resource type and t âˆˆ{c, m, d, b} where c, m, d, b
denotes CPU, memory, disk and bandwidth, respectively
Rt(mv)	requests of t type resource of VM m. t âˆˆ{c, m, d}
Rt(sv)	requests of t type resource of VS s. t âˆˆ{c, m}
Rb(ev)	bandwidth request of VL e
At(mp)	Available t type of resources provided by PM p
currently. t âˆˆ{c, m, d}
At(sp)	Available t type of resources provided by PS s
currently. t âˆˆ{c, m}
Ab(ep)	Available bandwidth resource provided by PL e
Without the embedding of VSs, most previous works (Nam et al., 2017; Sun et al., 2017; Lo and Liao, 2017) divide their embedding procedure into two stages: the first stage is the embedding of VMs, and the second is the embedding of VLs. Since we consider the embedding of VSs in this paper, technically, our embedding problem should incorporate three subproblems, the embedding of VMs, VSs, and VLs respectively. So the question is, which one should be solved firstly? VMs or VSs? Shall we consider the coordination of three subproblems? How can we efficiently coordinate them? In the previous two-stage strategies, no matter with coordination or without coordination, the final performance of VDC embedding degrades because neighboring VMs might actually widely separated in the physical topology. To achieve better performance, in this paper, we set up a single stage model, which implies that the three subproblems are solved at the same time.

Firstly, we introduce decision variables 
 indicating whether VM 
 is mapped on PM mp âˆˆ Mp.(1)
 Similarly, let 
 denotes whether a VS 
 is embedded in a PM mp âˆˆ Mp.(2)
 Since VSs can also be embedded in any PSs. Thus we introduce another decision variable 
 to denote whether VS 
 is mapped on PS sp âˆˆ Sp.(3)
 For âˆ€sv, it is only embedded in a PS or a PM, so we have the following constraint.(4)

For arbitrary VL 
, we employ variable 
 (ep âˆˆ Ep) to denote the bandwidth allocation for VL ev on PL ep. Technically, the embedding of VLs can be divided into two categories, the single path or multiple path corresponding to the type of 
. If 
 is a binary, the embedding of VLs belongs to the single path, otherwise, multiple path if it is a scalar. Considering DCNs have a lot of redundant PLs for robustness and load balance, in this paper, multiple paths strategy is utilized and 
 is scalar.

InPs' revenue is proportional to the total profit of all embedded VDCRs, The single profit of embedded VDCR is denoted as(5)
 denotes â€œGross Revenueâ€, which is calculated as follows.(6) 
 

where Î±t and Î²t are unit price of different resources corresponding to VMs and VSs. InPs have the ability to adjust the pricing strategy of different resources according to its infrastructure features by parameters t âˆˆ{c, m, d}, and Î³. For example, if the hardware configuration of PDC is abundant in memory of PMs, InPs could increase Î±m to encourage VDCRs with high memory requirements. Also, different VDCRs have different characteristics. Some are computation hunger, some are memory consumption, and some are storage oriented or high bandwidth required. The regulable parameters scheme enables InPs to be adapt to various VDCRs and PDCs.

 is the embedding cost of single VDCR 
.(7) 
 In Equ. (7), 
 and 
 denote the unit cost of t âˆˆ{c, m, d} type of resource on PMs, PSs and PLs. Because each virtual elements in a VDCR could be embedded in any physical devices, the calculation of embedding cost must traverse all physical elements.

3.3. Virtual path and modified flow conservation
Since a VL may across multiple PLs, the virtual path (VP) must be expressed to ensure the VL is correctly embedded. There are two methods to obtain the VP: one is traditional optimal (shortest) path search, i.e., BFS, DFS, Bellman-Ford, Dijkstra, Aâˆ—, etc, and the other is employing flow conservation law (FCL) and optimization methods to calculate the optimal path. However, we plan to solve the VMs, VSs and VLs embedding in one stage, the positions of the initial point and terminal point of VL are unknown in advance, so the first method is not applicable. In this work, we employ the method of FCL and modify it.

In FCL, the source â€œproducesâ€ flow, and the sink â€œconsumesâ€ flow. The input and output of intermediate nodes are equal. We define the initial point and terminal point of a VL as virtual initial point (vip) and virtual terminal point (vtp), respectively, and we call the two PNs where vip and vtp are mapped as physical initial point (pip) and physical terminal point (ptp). The multiple connected PLs between the pip and ptp are called the virtual path.

For arbitrary VL 
, its virtual vip and vtp may be VM or VS. To simplify expressions, we employ 
 and 
 to denote vip and vtp of ev respectively. Let 
 and 
 denote the pip and ptp, and 
 denotes the intermediate PNs for ev. According to traditional FCL, we get the following flow conservation equation on pip where vip is embedded:(8) 
ð“›
 The total traffic flowing out from pip equals to the bandwidth requirement on ev. Let ð“›
 represent the set of output links of a PN. Similarly, the flow conservation equation on pip is represented as:(9) 
ð“›
 Let ð“›
 be the set of input links of a PN. Except for pip and ptp, flow conservation equation on other intermediate PNs 
 is expressed as follows:(10) 
ð“›
ð“›
 Equs. (8), (9), (10) ensure that a VL is successfully embedded in multiple PLs and form a VP.

However, in our VDC embedding scenario, these three equations (8), (9), (10) cannot express the situation where adjacent VNs in VDCR are embedded into the same PN. In such a condition, no traffic about ev exists on output links of pip and on input links of ptp, which violates Equs. (8), (9). To satisfy the traditional FCL, the assumption of adjacent VNs must be mapped on different PNs (Zhang et al., 2014) is unreasonable. The VDC embedding problem should allow such a case if PNs have sufficient resources. It is beneficial to save the cost of link embedding and reduce transmission delay. Therefore, it is necessary to modify traditional FCL.

We analyze possible embedding cases of vip and vtp of a VL, and demonstrate them in Fig. 4. There are four scenarios for a directed VL. VMs only can be embedded in PMs while VSs can be embedded in PSs or PMs. So the combination of possible embedding Fig. 4 reaches 9. Take Fig. 4(b) as an example, directed VL ev points from a VS to a VM. If the vip, a VS, is embedded in a PM, we employ the following Equ. (11) to substitute Equs. (8), (9), (10).(11) 
ð“›
ð“›
 For âˆ€mp, if only vip of ev is mapped on it, then 
, 
, 
ð“›
. Equ. (11) reduces to Equ. (8). If only vtp of ev is mapped on it, then 
, Equ. (11) reduces to Equ. (9). If both vip and vtp are not mapped on it, 
 and 
, Equ. (11) reduces to Equ. (10). If both vip and vtp are mapped on it, 
 and 
, right side of Equ. (11) equals to zero and forces the left side being zero. This means that no input flow or output flow on PLs of mp where vip and vtp are embedded. To express modified FCL concisely, we employ variable Q to unify variables x, y, z, and symbol n to denote nodes which incorporate switch symbol s and machine symbol m. So the different embedding combinations in Fig. 4 are concluded by Equ. (12) as follows.

Fig. 4
Download : Download high-res image (366KB)
Download : Download full-size image
Fig. 4. Embedding cases of vip and vtp of a VL. Circles denote VMs or PMs. Rectangles represent VSs or PSs. Arrows represent flow direction. Red color represents virtual nodes, blue color represents physical nodes. Dashed line arrows show possible embedding. (For interpretation of the references to color in this figure legend, the reader is referred to the Web version of this article.)

Modified flow conservation law (MFCL):(12) 
ð“›
ð“›
 MFCL ensures the correct â€œvirtual pathâ€ and reversed bandwidth when VLs are embedded in PLs, no matter how many PLs or PNs it transverses.

4. Online embedding model and fast heuristic solution
This paper considers two ways of processing VDCRs, realtime (online) mode and batch (offline) mode, both models own its advantage. We provide mathematical formulations of two models respectively. In the following, we discuss the realtime mode and its fast solution firstly.

4.1. RealTime embedding model
In the realtime mode, the scheduler (i.e., SDN controller) processes the VDCRs immediately and one by one. Of course, the scheduler manages the global information of entire DCNs which include the embedded VDCRs, available physical resources, etc. For realtime mode policy, the scheduler accepts the arriving VDCR if available resources satisfy the required resources. The objective of single VDCR embedding is maximizing the InPs's profit. The realtime VDC embedding model (RVEM) is defined as follows: 
 
(13) 
 (14)
(15)
(16)
(17)
(18)
(19) 
ð“›
ð“›
 (20) 
 (21)
(22)
(23)
Equs. (13), (14), (15) ensure that resources of each PM are not violated, where Ac(mp), Am(mp) and Ad(mp) denote current available computation, memory and storage resource respectively. Because VSs can be embedded in PM and only computation, memory resource are accounted, variable 
 is incorporated into Equs. (13), (14). Similarly, Equs. (16), (17) are constraints about PSs. Equ. (18) shows that all aggregated bandwidth allocations of 
 can not exceed the available bandwidth of PLs. Equ. (20) guarantees that all VMs in 
 must be embedded. Similarly, Equ. (21) ensures that VS in 
 is either embedded in PMs or PSs. Equs. (22), (23) indicate that 
, 
, 
 are binary variables and 
 is non-negative scalar variable.

In RVEM model, the VDCR is accepted only if all elements are embedded. Otherwise, it is rejected or postponed. Although RVEM model aims to embed a single VDCR, we could construct a queue to store all VDCRs according to policy, i.e., the size of VDCR, the bonus VDC client provided, fairness, priority, and so on. Note that rejected VDCRs can be inserted into the queue for rescheduling. Next, we prove the hardness of RVEM. We fist give the definition of generalized assignment problem (GAP).

Definition 1

(GAP) Given m kinds bins b1 to bm, n kinds of items a1 trough an. Each bin is associated with a budget ti. The goal is to find a maximum profit assignment without exceeding the capacity ti of each bin.

Theorem 1

The RVEM problem is NP-hard.

Proof

In the following, we show how to reduce GAP to RVEM.

â—
Input translation: Let the profit and weight of each item ai be pij and wij. The input of GAP is pij, wij and ti. Simplify pij and wij to pi and wi when assign item ai to different bins. wi corresponds to required resource Rc(mv), Rc(sv), Rm(mv). pi corresponds to 
, 
, 
 in objective.

â—
Problem translation: Suppose that all ai items are divided into two groups corresponding to VMs and VSs. The decision variables of GAP are split into two group variables denoted as x and y. Then the constraints of GAP correspond to constraints (13), (14), (15), (16), (17).

â—
Output translation: The output of RVEM is the assignment of VMs and Vss, denoted as 
. Using variable substitution, 
 are combined into one group, that is the solution of GAP.

Above three-step translations operated in a polynomial-time complete the reduction from GAP to RVEM, so RVEM is NP-hard.

4.2. Variables relaxation and heuristic rounding
RVEM problem is NP-hard and belongs to mixed integer linear problem (MILP), the most challenge is computation complexity increasing at exponential growth w.r.t. the problem scale. Traditional solvers (Gurobi, 2015) (i.e., CPLEX, Gurobi, etc.) process the MILP problem by employing Branch&Bound, Cutting plane, Backtracking, etc. These methods search feasible solutions in the state space tree. However, in the VDC embedding problem, the state space can be tremendous due to thousands of PNs, PLs in PDC, and VNs, VLs in VDC. Some previous works (Rabbani et al., 2013) tried to relax the integer constraints and use randomized rounding, but randomized rounding easily causes resources violation and further leads to failure. So in this paper, we design a heuristic algorithm based on the relaxed LP model to solve RVEM. By analyzing the profit Equ.(5) of embedding single VDCR, we conclude the following theorem.

Theorem 2

For an accepted VDCR, the profit of InPs is inversely proportional to its VLs embedding cost.

Proof

Expanding Equ. (5), we find that, if a VDCR is accepted, the profit consists of three parts.(24) 
 The first part 
 is the profit of single VM and the second part 
 or 
 is the profit of a VS where 
 and 
 are the difference between revenue parameters and cost parameters, respectively. Obviously, the profit of these two parts is proportional to the number of requests and the parameter differences. In the third part, Î³Rb(ev) is the fix income for embedding a VL where 
 is varied part for the embedding cost. If vip and vtp of a VL are separated in two distant PMs, then the embedding cost will increase because â€œvirtual pathâ€ is across multiple PLs. Inversely, the VL embedding cost could reach to 0 when vip and vtp are embedded in the same PM. In brief, at the condition of fixed parameters, the embedding revenue of an accepted VDCR is fixing, the embedding cost is varied, especially, the embedding cost of VLs.

Based on the above analysis, we get two hints: to maximize the InPs's profit, the embedding algorithm should i) improve the embedding acceptance ratio and ii) reduce VL embedding cost. These two hints motivate us to develop the following fast heuristic embedding Algorithm 1, Algorithm 2.


Algorithm 1. Fast Heuristic Rounding Embedding Algorithm (FHRE) for Solving RVEM.

Input:
Gv, At(mp), At(sp), Ab(ep);
Output:
 of Gv or reject Gv;
1:Relax 
 to [0, 1], solve the relaxing RVEM-LP;
2: Put fractional solution 
 into set Î©, and put
all 
 into set F;
3: while Î©â‰ âˆ… do
4:  while Evâ‰ âˆ… do
5:  Choose ev with highest value of 
 from F;
6:  if both 
 and 
 are not embedded then
7: Search LP solutions of 
 and 
 in Î©, record corresponding physical nodes into set 
, 
;
8: Call RRVC;
9:  else
10: if (
 not embedded) or (
 not embedded) then
11: Search LP solutions of 
 or 
, record corresponding physical nodes into set 
 or 
. Find physical node np where 
 embedded,
 or 
;
12: Call RRVC;
13: else
14: Ev = Ev âˆ’ ev, 
;
15: Continue;
16: end if
17:  end if
18:  end while
19:  Update RVEM-LP according to Î©, remove fixed variables;
20:  if re-solve RVEM-LP = = success then
21:  Update Î©, F
22:  else
23:  Reject Gv
24:  end if;
25: end while
26: Update RVEM-LP, it is translated into MCF problem;
27: if solve RVEM-LP = = success then
28:  return 
 and accept Gv;
29: else
30:  reject Gv
31: end if;

Algorithm 2. Rounding and Resource Violation Checking Algorithm (RRVC).

Input:
, 
, 
, 
, Î©, F, Gv;
Output:
Î©, Ev, F;
1: Construct pair set 
 with elements 
, 
 from 
;
2: Sort T by ascending order according to shortest path between 
, 
 in pairs;
3: while Tâ‰ âˆ… do
4:  Choose first pair 
;
5:  if 
 and/or 
 are not embedded then
6:  Check 
 and/or 
 satisfy constraints (13), (14), (15), (16), (17);
7:  if all constraints are qualified then
8: 
, and/or 
;
9: 
, and/or 
;
10: label 
 and/or 
 as embedded;
11: 
 and/or 
;
12: Ev = Ev âˆ’ ev, 
;
13: Clear T, break;
14:  else
15: Remove pair 
 from T;
16:  end if
17:  end if
18: end while
4.3. Discussion and complexity analysis
Alg. 1 is our major embedding algorithm, Alg. 2 is the sub-function of Alg. 1. Compared with the random rounding method, Alg. 1 employs the heuristic information from the linear relaxing solution of RVEM, we called RVEM-LP. To reduce the embedding cost of VLs, the virtual path corresponding to a VL should be as short as possible. So we firstly consider VLs with high bandwidth requirement, embed vip and vtp of these VLs as early as possible in the shortest VP. In Alg. 1, the inner loops between lines 4â€“18 implement the above idea.

Our proposed heuristic embedding Alg. 1 can be divided into four steps. In the first step, we employ the heuristic information of 
 to find an ev and its vip and vtp. We also find the possible embedded PNs of vip and vtp, and record these nodes into set 
 and 
 respectively. If one of vip and vtp has been embedded, then the corresponding set equals its current embedding PN. If both vip and vtp of ev are embedded, then we delete ev and corresponding 
. In the second step, Alg. 2 RRVC is invoked to embed the best candidate VNs. In the RRVC, all pairs of pip and ptp of ev are constructed and sorted, and their corresponding embedding variables 
, 
 or 
 are rounded up. If the rounding up is successful, corresponding variables are set to 1, and other variables related to pip and ptp are set to 0. The process is repeated until embedding is successful or T is empty. The first step and the second step are repeated until all VLs are visited. However, some VNs may still fail to be embedded, because other already embedded variables do not release resources timely. In the third step, we remove embedded VNs and their corresponding variables from RVEM-LP, instead, update RVEM-LP and resolve it. Again, the resolved results are used to update Î© and F. Above three steps repeat until all VNs are embedded except the failure caused by solving RVEM-LP. In the fourth step, between lines 26â€“31, when all VNs are embedded and no binary variables are left, VLs embedding can be solved in polynomial time by classical multi-commodity flow (MCF) problem. If solving of RVEM-LP succeed, all embedding variables 
 return, Gv is accepted.

Next, we explain Alg. 2 in detail. For vip 
 and vtp 
 of ev, we construct the set of path pairs T by combining pip and ptp from 
 and 
 respectively and further sort T in ascending order according to length of VP of 
. Then we select the first shortest path pair, and round up the relaxing LP solution corresponding to this pair. Because 
, 
, 
, 
 may denote the switch or machine, we use 
, 
 or 
 to denote rounding up of corresponding relaxing solutions. Here | in Alg. 2 denotes one of chosen solutions. If both 
 and 
 are not embedded, then we round up both of their RVEM-LP solutions pair. If only one of them is not embedded, then we just round up the un-embedded one. After rounding up, we check up whether the rounding violates resource constraints Equs. (13), (14), (15), (16), (17). If all constraints are satisfied, it means the rounding is successful. Then we formally set these variables to 1 and other related variables to 0. The subscript âˆ—/i1 in variables 
 means that all PNs np where 
 is embedded except 
. In the meanwhile, we delete the variables related to 
 and/or 
 from Î©, and update Ev and F. If constraints are not satisfied, we remove the first pair and choose the next pair. The process repeat until embedding is successful or T is empty.

It is worth noting that we do not directly choose ev with the highest bandwidth, instead, we use 
 in RVEM-LP as an indicator in Alg. 1. This is because 
 not only implies the bandwidth information of ev, but also incorporates the shortest path information of ev. We explain it in detail. First of all, 
 denotes part of the specific VL is embedded in a PL because of flow split, the highest 
 in set F indicates that this VL ev has a high bandwidth requirement on this PL ep than others. If the sub-flow is greatest, the original flow also is greatest. Secondly, through optimization of RVEM-LP, the highest 
 imply that the VL ev's embedding on the ep, should be â€œshortâ€ path. Because â€œlongâ€ VP and high flow allocation 
 must lead to high costs of InPs, which is contrary to the optimization objective.

Algorithm 1, Algorithm 2 solve our RVEM in polynomial time, we analyze space complexity and time complexity in the following.

Theorem 3

Both the time and space complexity of Alg. 1 (FHRE) are polynomial and they are O(|Nvâ€–Npâ€–Ev|0.5(|Ep| + log|Np|)) and O(|Nvâ€–Np| + |Evâ€–Ep| + |Np|2), respectively.

Proof

FHRE algorithm invokes the RRVC algorithm, so we first analyze the RRVC algorithm. In RRVC, the number of pairs in the set T depends on the number of PNs where a VN is embedded. Suppose that the total number of PNs is |Np|, the worst case of solving RVEM-LP is that all VNs are evenly distributed on each PNs. So the sizes of both 
 and 
 are |Np|. Besides, the size of set T is |Np|2, so the loop executes |Np|2 times at most. Considering the quit from loop, the average complexity for loop should be |Np|log|Np|. In addition, the computation complexity of shortest path for all PNs in PDC is O(|Epâ€–Np|) (Thorup, 1999) if the weight of PLs is integer. So the total running complexity of RRVC is O(|Epâ€–Np| + |Np|log|Np|). Next, we suppose that the total number of VLs is |Ev| for a specific Gv. In lines 4â€“18, FHRE algorithm traverses all VLs of Gv. According to the relationship of edges and vertex of complete connected graph, this loop executes 
 times. As the outmost loop about Î©, the size of Î© is |Nvâ€–Np| in the worst case. However, we delete all related variables about embedded VNs in while loop, so the actual loop times of the outer layer are only related to the total number of VNs, |Nv|. Thus, the total time complexity of FHRE is 
 

The space complexity is determined by the scale of variables. The worst case of FHRE is that |Nv| VNs are distributed on |Np| PNs, and |Ev| VLs are distributed on |Ep| PLs. So total space size of variables is O(|Nvâ€–Np| + |Evâ€–Ep|). Then the size of T is |Np|2, so the total space of FHRE is O(|Nvâ€–Np| + |Evâ€–Ep| + |Np|2).â–ª

5. Batch embedding model and transfer algorithms
RVEM model processes requests in realtime. To maximize the profit of InPs, The RVEM model tends to embed elements of a VDCR on a single PN or several neighboring PNs so that minimize the embedding cost. However, without look ahead, it may not be the best embedding strategy for the long-term. Take Fig. 5 as an example, RVEM model performs the embedding at the arrival of VDCRs. VDCR 1 will be embedded entirely either on left PM with 15 units or right PM with 13 units, but InPs have to reject VDCR 2 because of the insufficient resource. However, two VDCRs can be well embedded if they are processed together. So the embedding of all elements of VDCR in a single PN is the best choice for RVEM model. However, it is not the best embedding strategy for long-term running.

Fig. 5
Download : Download high-res image (296KB)
Download : Download full-size image
Fig. 5. An example shows the flaw of RVEM model. VDCR 1 will be embedded entirely either on left PM or right PM. The second VDCR is rejected because of the improper embedding of the first VDCR. However, two VDCRs can be embedded successfully when they are processed together.

5.1. Batch embedding model
To solve this â€œmyopicâ€ problem, we propose the batch VDC embedding model (BVEM) where VDCRs are processed by a group rather than one by one. This strategy avoids unbalance utilization of resources and further improves InPs' profit. In the batch embedding model, InPs' service time is divided into time slots. In each time slot, a group of VDCR consisted k VDCRs (
) is submit to scheduler, where these requests are decided to accept or reject.

Since current available physical resources can not guarantee that all requests to be accepted, we introduce a decision variable Ï€i to indicate whether a request Gi is accepted.(25)
 Thus, BVEM is formulated as follows.

Capacity constraints:(26)
(27)
(28)
(29)
(30)
(31)

MFCL constraints:(32) 
ð“›
ð“›
 

Domain constraints:(33)
(34)
(35) 
 (36)
Ï€i = 0 means that InPs reject Gi, then all of its resource requests do not consume physical resources, the above constraints will not work. In fact, RVEM is a special case of BVEM.

5.2. BVEM relaxing and approximation
Mathematically, BVEM belongs to MINLP (Mixed Integer Nonlinear Problem) since Ï€i couple with other variables in constraints. The pursuit of an optimum solution of MINLP is more difficult than MILP, even if some commercial solvers (i.e., CPLEX, Gurobi, etc.) can solve MINLP, they only are applicable to small scale problem. The number and size of VDCRs increase quickly as today's PDC holds thousands of PMs connected by considerable links, it makes the computing time is intolerable to both customers and service providers. Thus, a polynomial-time method must be provided to solve BVEM.

Observing BVEM, we find a clue: If the physical resources are abundant to accommodate all VDCRs in a batch, then each Ï€i = 1. In other words, the variable Ï€i does not work. Based on the above fact, we have the following theorem.

Theorem 4

Under the assumption of adequate physical resources to accommodate all VDCRs in a batch, embedding multiple VDCRs in a batch is equivalent to embedding a larger VDCR whose requirements equal to the sum of all requests.

Proof

Since the physical resources are adequate to accommodate all VDCRs in a batch, the variable Ï€i in BVEM is equal to 1. We construct a larger VDCR by connecting all VDCRs together with virtual VLs whose bandwidth is 0. Embedding of a new VDCR is equivalent to embedding all VDCRs in the batch, which is easy to be verified by replacing all Ï€i in BVEM with 1.

With the guarantee of Theorem 4, we can simplify the BVEM problem to the RVEM problem through Alg. 3 called TABE (Transfer Algorithm for BVEM). The Alg. 3 is a heuristic algorithm for solving BVEM problem. The input of it is a batch of VDCRs 
 and current available physical resources At(mp), At(sp), Ab(ep). The output of Alg. 3 is the decision variable Ï€i corresponding to accepted VDCRs and decision variable 
, 
, 
, 
 denoting where virtual resources are embedded. We discuss Alg. 3 and its sub-algorithms as follows.


Algorithm 3. Transfer Algorithm for BVEM (TABE).

Input:
A batch of VDCRs 
, available physical resources At(mp), At(sp), Ab(ep);
Output:
Ï€i, 
, and 
, 
, 
, 
 of accepted VDCRs;
1: Run FRVA to check the feasibility of each 
, push unfeasible 
 to queue, and update Di = Di + 1, set Ï€i = 0;
2: Sort left 
 requests in a decreasing order according to 
, and put them in new group 
;
3: for j = 0 to 
 do
4:  Select 
 requests from 
 candidates, store 
 selections in set T, sort
T by aggregated scores 
;
5:  for p in T do
6:  Construct a new request 
 by connecting 
 VDCRs in p by VLs with 0 bandwidth;
7:  Run FRVA algorithm to check the feasibility of 
;
8:  if 
 is accepted then
9: Solving 
 by RVEM model and FHRE algorithm;
10: if RVEM return true then
11: Set Ï€i of 
 VDC equal to 1, return x, y, z, f of 
 VDC, return 
 as 
;
12: return success for BVEM;
13: end if
14:  end if
15:  end for
16: end for
5.3. Discussion and complexity analysis
In the three algorithms: Alg. 3(Alg. TABE), Alg. 4(Alg. FRVA) and Alg. 5(Alg. RFFV), Alg. 3 is the major algorithm, Algorithm 4, Algorithm 5 are sub-algorithms. Alg. 3 invokes Alg. 4, and Alg. 4 invokes Alg. 5. We discuss them respectively. Alg. 3 can be divided into 3 steps. In the first step, we aim to exclude unfeasible VDCRs which beyond currently available resources. The corresponding Ï€i of unqualified VDCR is set to 0. Di denotes its postpone times which is used for computing the weight score. Alg. 4 is invoked for resource checking which we explain later. The first step corresponds to the line 1â€“2 of Alg. 3.

The left VDCRs are sorted according to weight score 
 and put into a new group. In the second step, we select multiple VDCRs from the qualified 
 VDCRs shown in line 4. To maximize the number of embedded VDCRs, the selection starts from combination of all 
 VDCRs, and reduce the number of VDCRs gradually. This idea is expressed in line 3â€“4. Since there are 
 combine choices for select 
 VDCRs from 
 candidates, we sort these choice by aggregated scores 
 according to Equ. (37);(37)
Equ. (37) is the weight factor of each VDCR which is expressed as weight summation of all kinds of required sources and delay factor. 
, 
 and 
 are normalized resource requirements of all VMs, VSs and VLs in 
, and 
 is normalized as delay factor used for fairness. 
, 
, 
 and 
 are weights coefficient used for adjusting the weight scores according to the feature of PDC and VDC.


Algorithm 4. Fast Resource Pre-Verify Algorithm (FRVA).

Input:
VDCR Gv, Current available resources At(mp), At(sp);
Output:
Accept or reject Gv;
1:Initialize 
, 
, flag = 0;
2:Store all Rt(mv), At(mp), Rt(sv), At(sp) into array VMReq(), PMRes(), VSReq(), PSRes(), sort 4 arrays by descending order.
3:Union VMReq() and VSReq() as VReq(), Union PMRes() and PSRes() as PRes()
4: numVM = sizeof(VMReq()); numV = sizeof(VReq());
5: numPM = sizeof(PMRes()); numPS = sizeof(PSRes());
6: if 
 then
7:  return reject Gv;
8: end if
9: if 
 then
10:  return reject Gv;
11: end if
12: if ResVerf(1,numPM,numPS,VReq(),PRes()) = = 1 then
13:  return accept Gv;
14: else
15:  return reject Gv;
16: end if
The third step is the second loop which between line 5 and 15. The 
 VDCR are combined into single VDCR 
. If 
 passes the verification of Alg. 4, we solve the embedding of 
 by RVEM model. If the embedding of 
 is successful, we regard the results as the embedding results of the batch VDCRs. Otherwise, we process the next selection and reassemble the new selection, check again. We try to embed the selection with high scores preferentially, that is, VDCRs with the higher request are prefer to be chosen. It fit the fact which major tenants have higher priority. However, For fairness, we add delay factors 
 into Equ. (37).

Alg. 3 invokes Alg. 4 multiple times for available resources pre-verification to help InPs filter the unqualified VDCRs, so we analyze Alg. 4 and Alg. 5 here. Alg. 4 compares requests of VMs and VSs in a VDCRs with currently available resources of each physical node. In Alg. 4, we initialize all kinds of variables and arrays in lines 1â€“5. Then in lines 6â€“11, we firstly remove two obvious cases: (i) the total requests of all VMs exceeds all available PMs resources and (ii) the total requests of all VSs beyond the resources of all PNs subtract VMs's requests. Next, we invoke Alg. 5 to judge whether all VNs of this VDCR can be embedded into the current PDC's PN. If it returns 1, it denotes current PDC can embed this VDCR, otherwise, PDC can not. Please note that here the Gv maybe a combined VDCR which consists of multiple VDCRs in a batch. The output of Alg. 4 is whether the Gv is accepted or rejected. It is just a judge, not practical embedding.


Algorithm 5. Recursion Function for Fast verification (RFFV).

1: Fun bool ResVerf(int vIdx,int numPM,int numPS,int VReq(),int PRes())
2: {
3: if VReq(vIdx) is VM then
4:  numP = numPM;
5: else
6:  numP = numPM + numPS;
7: end if
8: for pIdx = 1 to numP do
9:  if VReq(vIdx) > PRes(pIdx) then
10:  continue;
11:  else
12:  PRes[pIdx] = PRes[pIdx]-VReq[vIdx];
13:  if vIdx = = numV then
14: flag = 1;
15: PRes[pIdx] = PRes[pIdx]+VReq[vIdx];
16: break;
17:  else
18: ResVerf(vIdx+1, numPM, numPS, VReq(),PRes());
19: if flag = = 1 then
20: break;
21: end if
22: PRes[pIdx] = PRes[pIdx]+VReq[vIdx];
23:  end if
24:  end if
25: end for
26: return flag;
27: }
Next, we explain Alg. 5. it is a recursion function, Alg. 4 invoke Alg. 5 for substantial verification. In Algorithm 4, Algorithm 5 parameters are passed to Alg. 5 in line 12. vIdx = 1 denote the recursion starting from the first VN. Next, we discuss the Alg. 5. It is a recursion function to verify available resources. From lines 3â€“7, we judge the type of VNs and set their embedding range, numP is upper bound in the loop. In the â€œforâ€ loop, we check whether current VN can be embedded in a PN, one by on. The expression VReq(vIdx) > PRes(pIdx) in line 9 denotes current PN cannot satisfy the VN, then we must skip to next PN. Otherwise, current VN is supposed to be embedded in this PN, corresponding available resources must be deducted. If the current VN is the last one, then the recursion procedure finish and sets the success flag, otherwise, recursion procedure continues to check the next VN in line 18. Alg. 5 is concise and efficient. Different from actual embedding, Alg. 5 checks fast. Once it finds a feasible solution for embedding all VNs, it returns immediately.

Theorem 5

The time complexity of Alg. 3(TABE) for solving BVEM is 
.

Proof

In Alg. 3, the solutions to BVEM depend on Alg. 4 (FRVA) and Alg. 5 (RFFV). We first analyze the complexity of FRVA. In FRVA, it invokes function 5 (RFFV) whose complexity is O(|Npâ€–Nv|) at the worst case, average complexity of break operation in the loop is O(|Np|log|Nv|) and other operations is O(1), so the average complexity of FRVA is O(|Np|log|Nv|), depending on RFFV. In TABE, the outer loop of lines 3â€“16 is 
 times and the inner loop is 
 times, and incorporates the time of invoking FRVA and FHRE. So its time complexity is 
 To express simply, we omit the log(âˆ—) items.

Although O(BVEM) contains an exponential item 
, where 
 is the number of qualified VDCRs filtered by FRVA in a batch. The time complexity of our proposed algorithm is greatly reduced compared with traditional solutions where search space is exponentially proportional to the number of VNs and VLs because 
.

6. Performance evaluation
In this section, we discuss the experiment setting and conduct extensive experiments to evaluate the performance of our proposed algorithms.

6.1. Evaluation settings
In the simulation, all algorithms have been implemented with Python 3.5 and executed on a server with a Xeon(R) 2.2 GHZ CPU and 64 GB RAM. We firstly invoke NetworkX library to customize physical/virtual nodes and links. Then a graph denoting the PDC is constructed according to network topology parameters in the following PDC resource capacities. Dozens of graphs which represent VDC are also constructed according to network topology parameters in the following VDCRs requirements.

Physical DC and Resource Capacities: Since the topology of most data centers is tree-like structure, such as Fat-Tree (Al-Fares et al., 2008) and VL2 (Greenberg et al., 2011), we also consider PDC as a tree-like topology in different types and different scales. VL2 is adopted for small and middle-scale PDC. The small-scale of VL2 is a four-layer structure, where 16 switches are divided into 4 racks and each rack contains 2 edge switches and 2 aggregation switches. 4 core switches are connected to each aggregation switch respectively. 120 PMs are connected to edge switches in 4 racks evenly. So there are total 20 PSs and 208 PLs. The middle-scale of VL2 is similar to the small-scale one, with 640 PMs, 8 rack of switches, and 8 core switches. So the total links reach 800, and the number of total switches is 40. Fat-Tree is adopted for middle-scale and large-scale topology. The Middle-scale of Fat-Tree employs 14-port PS as its fabric. According to the Fat-tree topology rule, there are 49 core switches, 14 pods where each pod contains 7 aggregation switches and 7 edge switches, 686 PMs, 245 PSs, 2058 PLs; Large-scale of Fat-Tree employs 24-port PS as its fabric. So the large-scale Fat tree consists of 144 core switches, 1024 PMs, 720 PSs, 10368 PLs. Compared with VL2, Fat-Tree owns more PSs and PLs at the same scale. We suppose the physical resources of two topologies are the same: each PM equips with 16 CPU units, 32 RAM units, and 200 disk units. Each PS has 2 CPU units and 1 RAM units. The bandwidth of PLs connecting machines to ToR switches is set to 1 Gbps, while the bandwidth of other links is set to 10 Gbps.

VDCRs and Requirements: To show our algorithm can be compatible with different topologies, we randomly generate VDCRs containing three types of topologies: tree, star, and mesh. Tree topology has 2 tiers of VSs and 1 tier of VMs. In the first layer, we randomly produce 1â€“5 roots VSs. In the second layer, we randomly produce 2â€“5 VSs and 10â€“15 VMs on the second tiers VSs. Star topology randomly produces 1 central VS and 15â€“20 VMs on this switch. In the mesh topology, we randomly produce 15â€“20 VMs and each VM randomly connects to several peers to guarantee topology is fully connected. The size of each VM for CPU, memory, and disk is generated randomly between 2â€“4 units, 2â€“8 RAM units, and 20â€“50 of disk units respectively. The size of each VS for CPU and memory is generated randomly between 0.5 and 1 units and 0.25â€“0.5 RAM units respectively. The bandwidth requirement between VMs and VSs is generated randomly between 10â€“100 Mbps while the bandwidth requirement between VSs is generated randomly between 50â€“100 Mbps. In a mesh topology, the bandwidth between VMs is generated randomly between 10â€“50 Mbps.

Similar to Greenhead (Amokrane et al., 2013), we suppose the arrival of VDCRs follows the Poisson process with the parameter Î» per time slot, In the meanwhile, we set the length of rent lease of VDCRs following the exponentially distributed with a mean 1/Î¼. After that, they release all the resources occupied. In practice, the value of Î» and 1/Î¼ can be obtained through experience and the scale of the PDC and VDCRs. To translate RVEM and BVEM models into programming code, the structures of PDC and VDCs graph are scanned, then all possible embedding position of all VM, VS, and VL are recorded as optimization variables 
, 
, 
 and 
. Finally, these variables are formulated into a huge matrix according to Equ. (13), (21) or Equ. (25), (33). After the above operations, models are ready to solve by solvers. To provide baselines, we employ Gurobi solver to solve RVEM and BVEM.

6.2. Performance metrics
Embedding Efficiency: Because the VDC embedding problem is NP-Hard, efficiency is an important performance metric. The response time of InPs processing requests is crucial for user experience, particularly when the scale of PDC enlarged, or the size and number of VDCRs increase. Here, embedding efficiency is measured by the time of solving RVEM and BVEM.

Profit and Revenue: Profit is the result of gross revenue subtracting embedding cost indicated in Equ. (5), which is different from existing references that used revenue as the metric. This is because even if the revenue is the same, different embedding algorithms may lead to different embedding cost. Particularly, when considering the embedding of VSs, the VLs embedding cost may be greatly reduced.

Acceptance Ratio: It measures the number of embedded VDCRs during a period of time and it is defined as: 
 
. In fact, our proposal can accept the more number of smaller VDCRs which can end up less revenue, so Ï can not replace profits.

Resource Utilization: Virtualization aims to improve utilization of PDC, so resource utilization is also a metric to reflects the performance of embedding algorithm and is defined as resources allocated to VDCRs divided by the capacity of PDC.

6.3. Comparison algorithm
We compare the embedding efficiency of Alg. 1 (FHRE) with baseline methods and other similar solutions: NSS-JSL (Yang et al., 2017) and GreenMap (Ghazisaeedi and Huang, 2017). Our baseline method includes Branch-and-Bound (B&B) (Morrison et al., 2016) and Gurobi solver (Gurobi, 2015). The Branch-and-Bound method is commonly used for solving the integer programming (IP) problem. Modified B&B algorithm can solve the mixed integer linear problem (MILP). Gurobi is an optimization solver which can be employed to solve our models directly. In Yang et al. (2017), the authors aimed to minimize energy consumption and embedding cost, and proposed two embedding approaches: NSS-JointSL and NSS-GBFS with consideration of VSs embedding. With the consideration of incast problem and VSs embedding, Ghazisaeedi and Huang (2017) proposed GreenMap framework and formulated the framework as a Mixed-integer disciplined convex program (MIDCP).

Since our algorithms employ heuristic information and deterministic rounding, we compare them with some randomized rounding works, NSS-GBFS (Yang et al., 2017) and Decomposition (Jarray and Karmouch, 2015).

6.4. Embedding efficiency
The computation time is related to two factors: the scale of PDC and VDCRs, the number of VDCRs. As the batch model, the arriving and leaving parameter, Î» and 1/Î¼, are also important factors. So we discuss our two major algorithms respectively.

(1)
Evaluation of FHRE algorithm (Alg. 1)

The online model is solved by FHRE algorithm, so we investigate our Alg. 1 firstly, and design two groups simulations. In the first group, we fix the scale of VDCRs and verify the embedding efficiency of different scales of PDC. RVEM aims to continuously resolve VDCRs in real-time, which is solved by FHRE Alg. 1, so we measure the average computation time of 30 randomly generated VDCRs. Each VDCR is set according to the parameters in Sec.6.1. We employ four different scales PDC for test. Different scale of topology adopts the parameters described in the Sec.6.1. The average results are given in Table 2.


Table 2. Average solving time of embedding a VDC: Different scale of PDC (Unit: Seconds).

PDC scale	B&B	Gurobi	NSS-JSL	GreenMap	FHRE (Alg. 1)
Small-scale(VL2)	4.36	2.65	0.47	0.55	0.42
Middle-scale(VL2)	11.55	6.83	1.06	2.08	0.93
Middle-scale(Fat-Tree)	14.55	9.83	1.96	2.46	0.84
Large-scale(Fat-Tree)	â€“	49.41	2.52	7.92	1.79
In Table 2, â€œ-â€ means the methods cannot find the solutions due to memory limitation. B&B and Gurobi solvers belong to traditional exact search method, and are just applicable to small or middle scale network. It can be observed from Table 2 that the time cost of B&B and Gurobi solver becomes intolerable once the PDC scales up to large size. In contrast, the computation time of NSS-JSL, GreenMap and FHRE which employ heuristic methods to solve VDC embedding is greatly reduced. However, we find that the result of GreenMap is not good enough for large-scale PDC. GreenMap divides its procedure into 3 steps: VSs embedding, VMs embedding and VLs embedding. The separated steps maybe lead to low utilization of resources and cause more computation costs. Our proposed FHRE has distinct advantage when the PDC scales up. Since our algorithm takes full advantage of results of relaxing RVEM-LP rather than embed elements in VDCRs blindly. The heuristic information from RVEM-LP helps us to properly round up relaxing results and avoid unnecessary repeated work. In addition, we have observed the fact that in the same scale (middle-scale), the solving time of Fat-tree based topology is still higher than that of VL2 based topo, except our FHRE algorithm. This is because Fat-Tree based PDC has more PSs and PLs, which brings more searching cost. Instead, the time cost of FHRE algorithm is slightly reduced, due to that it takes full advantage of PSs resources.

In the second group, we fix the scale of PDC to middle size (Fat-Tree), and verify embedding efficiency through small and middle scale of VDCRs. The topology of VDCRs adopts tree-like and star-like. Two small-scale topologies adopt the parameters in Sec. 6.1. Double VNs, VSs and VLs are generated in middle-scale VDCRs compared with small-scale.

Results in Table 3 demonstrate that our FHRE algorithm still outperforms other solutions. Of course, the time complexity of B&B and Gurobi solver is intolerable. Although time cost of NSS-JSL and our FHRE is similar, our FHRE algorithm still has slight improvement than NSS-JSL. In summary, heuristic algorithms fully outperform exhaustive searching method on the metric of time efficiency. B&B and Gurobi solver uses exhaustive way for finding optimal solutions, wasting lots of time. However, heuristic algorithms maybe just output the feasible solution instead of optimal one.

(2)
Evaluation of TABE algorithm (Alg. 1)


Table 3. Average solving time of embedding a VDCR: Different scale of VDCR (Unit: Seconds).

VDC scale	B&B	Gurobi	NSS-JSL	GreenMap	FHRE (Alg. 1)
Small tree topo.	14.94	10.89	1.93	2.52	0.81
Small star topo.	10.62	5.53	1.55	2.26	0.97
Middle tree topo.	30.32	23.71	3.93	9.08	1.94
Middle star topo.	28.45	23.54	3.54	7.89	2.11
Above simulations just consider single VDC embedding, next we verify the embedding efficiency of our TABE algorithm (Alg. 3) for solving batch embedding. The parameter Î» decides the number of VDCRs in a batch, so we also divide the simulations into two groups: fixed scale of VDCRs and varying Î»; fixed Î» and varying scale of VDCRs.

In the first group, PDC is set to middle-scale VL2 and Fat-tree. VDCRs are set according to small-scale in Sec.6.1. The time slot is set to 5 min and the arriving rate Î» varies from 8 to 30. Fig. 6(a) and (b) shows the computation cost versus arriving rate Î». As the Î» increasing, the number of VDCRs in a batch also increases. Obviously, for B&B and Gurobi solver, their computation delay increases very sharply as Î» increases, which leads to them are impractical in real scenario deployment. Please note that: to express the different results in one figure, the Y-Axis is set nonlinear. The time cost of the other three heuristic algorithms also increases with the Î», however, the computation time of FHRE and NSS-JSL are still under 60 s, even if Î» reaches 30. Both of these two results are good enough for practical deployment. GreenMap has higher a computation delay than our algorithms, the result of around 60-s embedding time is not good enough. We also have noticed the time cost of NSS-JSL and GreenMap is slightly higher than that of FHRE's in Fat-tree topology, compared to VL2 topology. The reason is that more PSs and PLs exist in Fat-tree topology, which causes bigger computation burden for NSS-JSL and GreenMap. However, the ability of VSs' embedding on PSs enables our models and algorithms superior to other heuristic algorithms.

Fig. 6
Download : Download high-res image (373KB)
Download : Download full-size image
Fig. 6. (a)(b) Time cost versus arriving rate Î». (c)(d) Time cost versus the number of VNs in VDCRs. Two baselines and another two related works are compared with our TABE algorithm (Alg. 3) in the batch model.

In the second group, we fix the VDCRs' arriving speed, i.e., set Î» to 10, and change the number of VNs and VLs in each VDCR. Fig. 6(c)(d) shows that the computation time of our TABE algorithm also increases slowly and it is almost linear. The results also correspond to the complexity analysis in Theorem 5: if the number of VDCRs is fixed in a batch, the complexity is proportional to the number of VNs in VDCRs. Although NSS-JSL and GreenMap also have a slow growing rate, their computation cost is still higher than our proposal. In addition, the computation time of baseline B&B and Gurobi solver still increases rapidly. Obviously, the time cost growth in Fig. 6(c)(d) is slower than Fig. 6(a)(b) since the total VNs are less than the case in Fig. 6(a)(b).

(3)
Evaluation of deterministic rounding

As aforementioned, we employ deterministic rounding in our FHRE algorithm instead of random rounding. Random rounding is widely used in many embedding heuristic algorithms, i.e., Decomposition (Jarray and Karmouch, 2015) and NSS-GBFS (Yang et al., 2017), however, random rounding may miss many feasible solutions or optimal solutions, and further reduce the acceptance ratio and InPs' profit. Fig. 7 shows the comparison results between random rounding and deterministic rounding for single VDCR. Fig. 7(a)(b) show the comparison of Alg. FHRE, Decomposition, and NSS-GBFS for a single VDCR embedding. Fig. 7(c)(d) show the comparison of Alg. TABE, Decomposition, and NSS-GBFS for a batch of VDCRs embedding. As the number of VNs and VLs increased in a VDCR, or the number of VDCRs in a batch increase, the computation time also increases. Our deterministic rounding spends some time on executing the sorting and selection from candidate VNs, however, these operations are beneficial to improving embedding quality. We have observed our time cost is lower than the other two random rounding methods, as the number of VNs beyond 35. Although Random rounding reduces the time cost at the initial stage, this blind rounding method misses some feasible solutions, and lead to much more attempts of failure VNs. So from long term perspective, the time cost of deterministic rounding is superior to that of random rounding.

Fig. 7
Download : Download high-res image (325KB)
Download : Download full-size image
Fig. 7. Embedding efficiency of our deterministic rounding vs. randomized rounding. (a)(b) investigate Alg. FHRE for the online model, computation time Vs. the Num. of VNs in a VDCR; (c)(d) investigate Alg. TABE for the batch model, computation time Vs. arrival rate Î» or the Num. of VNs in each VDCRs.

6.5. Acceptance ratio
Acceptance ratio Î» is a key metric to evaluate the performance of the VDC embedding algorithm. However, as the VDCRs are accumulated, some VDCRs will be rejected due to the fixed capacity of PDC or improper embedding of previous VDCRs. Since two parameters, arrival rate Î» and rent lease 1/Î¼, have an important impact on Ï, we study the Ï versus the combination of different Î» and 1/Î¼.

(1)
Acceptance Ratio for Online Model

Firstly, we investigate the acceptance ratio of online processing, Alg. FHRE. The acceptance ratio is measured based on a period, so we introduce the concept of time slot for the online model for easy computation and comparing with batch model. However, the scheduler still process VDCRs one by one, instead of a batch. Each time slot is set to 3 min and the simulation is executed for 200 time slots. The topology parameters of PDC are set according to the default value of middle Fat-tree described in Sec.6.1.

Fig. 8 shows the simulation results of acceptance ratio Ï. Generally, the value of Ï equals to 1 at the initial embedding stage due to sufficient physical resource. As new VDCRs constantly enter scheduler, the physical resource reduce and insufficient to accommodate all new incoming VDCRs. The drop or push delay of some VDCRs leads to decreasing of Ï. In the meanwhile, the scheduler also removes some VDCRs due to the lease expired. Finally, the accepted and removed VDCRs almost keep balance, and Ï stay around a certain value with slight fluctuation. The variation trend of Ï is determined by different combinations of Î» and 1/Î¼. For example, in Fig. 8(a), all algorithms have higher Ï than that in Fig. 8(b). The period of Ï decreasing is also shorter than that in Fig. 8(b). The period of Ï = 1 also depends on Î» and 1/Î¼. In Fig. 8(a) and (d), this period is much longer than that in Fig. 8(b) and (c).

Fig. 8
Download : Download high-res image (388KB)
Download : Download full-size image
Fig. 8. The influence of Î» and 1/Î¼ on Ï against different algorithms in the online model. The trend of Ï is related to the different combinations of two parameters.

Observing above four figures, we can find out that our FHRE Alg. 1 is superior to the other two heuristic algorithms, under different combinations of parameters. Although the authors in GreenMap proposed an MIDCP model, they did not solve the model and the proposed heuristic algorithm has nothing to do with their model. In NSS-JSL, the authors separated the embedding process of VMs, VSs, and VL into two stages. However, their embedding algorithm of VMs has been executed independently without coordination with VLs embedding. The reason that our heuristic algorithms outperform these two algorithms is summarized as follows: i) Both heuristic algorithms belong to the try-and-error category, and they did not fully employ the advantage of mathematic models. ii) Multiple separated embedding stages lead to less usage of physical resources.

Besides, we can draw the following two conclusions: i) The exact solution, B&B and Gurobi solvers have a greater accepted ratio of average 15%â€“20% than other three algorithms, due to their huge and precise searching space. Fig. 8(a) indicates that when Ï of our Alg. FHRE reaches around 53%, Gurobi solver can reach around 71%. ii) Greater Î» and 1/Î¼ lead to lower Ï, vice versa. In Fig. 8(a), the Ï of our FHRE algorithm and other two algorithms reaches around 49%â€“52% when Î» = 8 and 1/Î¼ = 6. In contrast, when the arrival rate Î» reaches 13 and keeps 1/Î¼ unchanged depicted in Fig. 8(b), the Ï of all algorithms decreased. The same situation happens to Fig. 8(c) where the length of rent lease 1/Î¼ reaches 13. Fig. 8(d) shows the opposite situation.

(2)
Acceptance Ratio for Batch Model

Fig. 9 shows the comparison results of our TABE algorithm (Alg. 3) with other methods for solving BVEM. Decomposition (Jarray and Karmouch, 2015) has the ability to process multiple VCDRs, so it can be applied for the batch embedding problem. For compared with our Alg. TABE, NSS-GBFS (Yang et al., 2017) is modified for solving multiple VDCRs embedding. Fig. 9(a)(b)(c) show the acceptance ratio against different combinations of two parameters. Similar to Fig. 8, the acceptance ratio Ï also declines with the VDCRs increasing. The variation trend of Ï is also determined by parameters Î» and 1/Î¼.

Fig. 9
Download : Download high-res image (367KB)
Download : Download full-size image
Fig. 9. (a)(b)(c) Acceptance ratio of different algorithms under the batch model. (d) Comparison results of our Alg. 3 for batch model and Alg. 1 for online model.

The Ï of our TABE algorithm is inferior to two baselines and superior to the others. However, our TABE algorithm has an average 8â€“11% improvement about acceptance ratio under the batch embedding model, compared with online mode. At the same time, other algorithms also have slight (3 âˆ’ 5%) improvement. Which shows that the idea of batch embedding indeed improves the acceptance ratio. In addition, we also observe that in Fig. 9(a)(b)(c), the curve of Ï is smoother than that in Fig. 8. Obviously, the batch embedding model helps to reduce the fluctuation of acceptance ratio. Compared with other algorithms, the reason that our TABE algorithm achieve a greater improvement is our original transfer strategy and elaborative tuning in Algorithm 3, Algorithm 5. Fig. 9(d) shows the 11% improvement of Alg. 3 versus Alg. 1. It shows the advantage of the batch model. Although the computation cost of the batch model is higher than that of the online model and the computation delay may affect tenant satisfaction, our batch model indeed boosts the utilization of the physical resource. So it is worth considering the balance of embedding efficiency and computation cost.

6.6. Instantaneous profit
Although the acceptance ratio indicates the embedding percentage, the number of embedded VDCRs can not fully represent the total embedded virtual sources due to different sizes of VDCRs. The objective of InPs is maximizing its resource utilization and incomings, so the Inps' profit is a key metric for evaluating an embedding algorithm. As we state aforementioned, different from previous works that use revenue as the metric, we employ profit as a metric. the revenue metric only depends on the number of embedded VDCRs, however, even if the revenue is the same, different embedding algorithms lead to different embedding cost. So the profit is a more exact metric for measuring Inps' profit. The InPs' profit equal to gross revenue subtracting the embedding cost indicated by Equ. (5).

Fig. 10 shows the instantaneous profits of different algorithms under the online model, batch model, and different scales of PDC separately. Fig. 10(a) and (b) show the results in the middle size PDC. Fig. 10(c) and (d) show the results in large size PDC. The instantaneous profits can generally be divided into three stages corresponding to their acceptance ratio. For example, in Fig. 10(a), the profits of all solutions increase sharply in the first 20th time slots, because of almost 100% acceptance ratio of newly incoming requests at the initial stage. After the 20th time slot, insufficient physical resources lead to the drop in acceptance ratio Ï and further lead to a slow increase in profits. The second stage lasts for a while until around the 120th round. In the third stage, the Ï is relatively stable because the PDC eventually reaches a saturation state. The number of accepted requests is almost equal to the number of expired requests. So the profits stop increasing.

Fig. 10
Download : Download high-res image (417KB)
Download : Download full-size image
Fig. 10. (a) The instantaneous profits of the online model in middle size PDC. (b) The instantaneous profits of the batch model in middle size PDC. (c) The instantaneous profits of the online model in big size PDC. (d) The instantaneous profits of the batch model in big size PDC.

Comparing Fig. 10(a) with (b), we find the instantaneous profit of all algorithms under the batch model is greater than that under the online model. It corresponds to the simulation results in the last subsection, where the value of Ï under the batch model is greater than that in the online model. Also, our Alg. TABE has the largest increase around 12%, compared with the increment of other algorithms about 3â€“5%. In Fig. 10(c) and (d), larger Fat-tree PDC can accommodate more VDCRs and produce higher profits. The average profit in large PDC is approximately double profit in the middle PDC.

Furthermore, Fig. 10(b) and (d) show our Alg. TABE achieves about 8â€“10% improvement for solving batch embedding, compared with Alg. FHRE for solving online embedding in Fig. 10(a) and (c). Other algorithms in the batch model also have slight improvement. In summary, on mater the type of algorithm and the scale of PDC, the batch embedding method indeed improves the acceptance ratio and InPs' profits, Our Alg. TABE is specially designed for batch embedding, so the larger improvement than other algorithms is reasonable.

The profit improvement under the batch model is ascribed to two factors: the improvement of accepted ratio and the reduction of VLs embedding cost. The first factor has been demonstrated in Fig. 8, Fig. 9. As for the second factor, in our algorithms, multiple VDCRs are integrated into one VDCR. VNs with high bandwidth requirements of this new VDCR are preferentially embedded into the best position, leading to the minimum VLs embedding cost. Fig. 11(a) presents the number of embedded VDCRs of different algorithms at different time slots. The pattern of the number of embedded VDCRs corresponds to the instantaneous profits shown in Fig. 10.

Fig. 11
Download : Download high-res image (695KB)
Download : Download full-size image
Fig. 11. (a) The number of embedded VDCRs of different algorithms VS. Time. (b) The influence of parameters 
, 
 on the embedding location of sv.

In this paper, we assume that the VSs can be embedded in PMs and PSs. The variables 
 and 
 represent the embedding location of sv. Fig. 11(b) shows the influence of parameters 
 and 
 on the embedding location of sv. The horizontal axis represents the ratio of 
, while vertical axis is the ratio of 
. When 
 approaches to 0, the ratio of 
 reaches about 0.86. That is, almost half of VSs are embedded into PSs because of the lower unit cost of PSs. As the ratio of 
 increases to 1, the ratio of 
 reduces to 0.28. This means that most of VSs are embedded into PMs. This is because the PS loses its price advantage. To minimize the VLs embedding cost, our TABE algorithm (Alg. 3) prefers to embed VSs into PMs to reduce the cost of VLs. Because a large number of PSs are deployed in data centers, i.e., Fat-tree topology, the InPs should carefully choose the price policy for parameters of VSs and VLs, and these parameters will finally affect the utilization of the physical resource.

6.7. Utilization
Maximizing physical resource utilization is the purpose of virtualization, so utilization is also an important metric for measuring the embedding efficiency of algorithms. To evaluate the utilization of physical resources, we randomly choose 20 PMs and 20 PSs to measure their average utilization. Since NSS-JSL and GreenMap do not involve the embedding on VSs in PSs, Fig. 12(a) only shows the CPU utilization of PMs. For our Alg. TABE, we can investigate the CPU utilization of PSs. Fig. 12(a) demonstrates that our TABE algorithm (Alg. 3) has about 10%â€“20% improvement than the other two solutions on the metric of PM's CPU utilization, because our TABE algorithm enables PDC to embed more VDCRs. On average, each PM supports more VMs, and further leads to higher CPU utilization. We also note that these PSs have about 40% utilization, which makes them indeed undertake some VSs' embedding and help PMs reserve more resources for VM embedding, and further improve the Ï and profits.

Fig. 12
Download : Download high-res image (406KB)
Download : Download full-size image
Fig. 12. (a) The utilizations of PMs and PSs. (b) The comparing of utilization of physical links, between core links and edge links.

Fig. 12(b)(c)(d) show the utilization of three types of PLs of three different algorithms. The first type is the edge links between PMs and ToR switches. They are abundant in PDC. The second type is aggregation links between ToR switches and aggregation switches, or between aggregation switches in a pod. The third type is the core links between aggregation switches and core switches, or between multiple core switches. From Fig. 12(b)(c)(d), we find the utilization of edge links is higher than other two types of links, and the utilization of core links is lowest. In our TABE algorithm, the utilization of edge links is higher than other two algorithms. However, the utilization of core links is lower than the other two algorithms.

We analyze the phenomenon as follows. In our model, PSs are allowed to embed VSs, according to the principle of minimizing embedding cost, and most of VSs connected to VMs are embedded either on PMs or ToR/edge PSs. Only a small amount of VSs are embedded on aggregation PSs or core PSs, unless the ToR/edge PSs run out of resources, so most of VLs are embedded on these edge PLs in our algorithm. On the contrary, other two algorithms do not allow the embedding of VSs in PSs, and insufficient resources on PMs must cause the separations of VSs and VMs in a single PM, and further engage multiple PLs. The situations of two VMs' embedding, or two VSs' embedding is similar. Thus the possible separated embedding position of two virtual nodes can be divided into three cases: (i) two PMs where two VNs are embedded connect to the same ToR PS, and double edge PLs are involved in the embedding procedure. (ii) two PMs where two VNs are embedded belong to the same pod (i.e., Fat-tree), and aggregation and edge PLs are involved. (iii) two PMs belong to the different pod, aggregation PLs and core PLs are involved in the embedding procedure. So the utilization of aggregation and core VLs of Alg. NSS-JSL and GreenMap are higher than our algorithm. In contrast, embedding most VLs on edge PLs in our algorithm leads to high utilization of these links. In summary, the PMs' CPU utilization metric directly reflects the total embedded virtual source. Of course, high utilization of PLs indicates more VLs are embedded, however, a different type of PLs should be analyzed and distinguished. From the perspective of minimizing embedding cost, the case of high edge PLs utilization and low core/aggregation PLs utilization is beneficial to reduce the VLs' embedding cost.

7. Conclusion
In this paper, we propose two granularity models to formulate the VDC embedding problem which is proved to be NP-hard. We consider the embedding of multiple types of resources, and the embedding of VSs on both PSs and PMs. To achieve multiple VNs in the same VDCR can be embedded in the same PN and further reduce the embedding cost, we modify the traditional FCL. At first, an online model called RVEM is proposed to solve the realtime VDCRs embedding. For solving the online model in polynomial time, a heuristic embedding algorithm is designed. Next, a batch model called BVEM is proposed to solve the shortcoming of RVEM, and further improve the embedding efficiency. Since BVEM is nonlinear mixed integer programming and hard to solve, we provide transfer algorithms to reduce the BVEM to RVEM. Since the computation delay is the most challenging in VDC embedding problem, the heuristic information from the relaxing model and deterministic rounding method are adopted for reducing computation complexity. Compared with random rounding and pure heuristic methods, our determinist rounding improves the acceptance ratio and InPs' profit and utilization. In the meanwhile, it solved RVEM in polynomial time.

In future research, we need to reduce the computation time of embedding batch VDCRs in large-scale PDC or VDC by employing parallel computation. In addition, we will consider the dynamical change of embedded VDCRs and the migration of embedded VMs, VSs, and VLs to reduce resource fragmentation, furthermore, propose the resource re-allocation or adjustment strategies.