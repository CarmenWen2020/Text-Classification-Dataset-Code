With the development of cloud services, many network fraudulent incidents have damaged the interests of transaction subjects and brought a great crisis to online service. To analyze and solve the key conditions for different participants to achieve mutual trust and win-win situations in the cloud computing, we propose a trust prediction game model composed of the supervisor, cloud service provider (CSP), and user. Firstly, we use the Bayesian formula to predict the behavior trust attribute and propose the trust service map function and weight algorithm by the principle of maximum dispersion. Secondly, based on the perspective of the user, we establish a two-party dynamic game model and discuss the existence possibility of game equilibrium. Thirdly, based on the perspective of CSP, we establish a tripartite game model, analyze several possible equilibria, and obtain the equilibrium strategy from a mixed perspective. Finally, the experimental results show that the supervision has a significant impact on the strategy selection of the players, verify the correctness and effectiveness of various game parameters, exhibition the better advantage than several articles under some different standards, and make a useful exploration for building a secure and trusted cloud service environment.

Keywords
Cloud service
Trust prediction
Bayesian formula
Tripartite game
Equilibrium strategy

1. Introduction
Cloud computing is one of the most popular information technologies. It is highly valued by the government, academia, and industry (http://www.cloudsecurityalliance.org/, 2017). However, cloud services have had many security problems (Sun., 2019), and many fraudulent incidents have damaged the interests of entities and brought a huge crisis of trust to online transactions (Huang and Zou, 2018).

The core mode of cloud computing is service, and the premise of service is to establish trust between users and the CSP (Ardagna et al., 2017). To run credibly, the CSP needs to prevent the illegal behavior of malicious users; similarly, users need to select the CSP (Mohsin and Hussain et al., 2017). Although the security of cloud center data can be effectively improved through watermarking, this does not mean that the CSP can obtain the trust of users. It is necessary to solve the problems of fraud and noncooperation between users and the CSP in the cloud environment and encourage the CSP to provide authentic services.

How to solve the mutual trust problem and establish a fair and trusting service network, maintain the interests of all parties, and reduce risks are key in the implementation of cloud service applications (Huang and Zou, 2018). In the cloud environment, mutual trust relationships among agents are formed in the process of continuous interaction, which not only depends on the credibility and quality of service but also is influenced by each party's strategy choice (Pawlick and Chen et al., 2019).

There are many factors involved in the quantitative evaluation of trust, and each factor plays a different role (Mashayekhy and Nejad et al., 2019). How to determine and calculate different weight is an important hotspot in trust research. Therefore, this paper proposes to study different trust attributes based on the Bayesian formula and entropy theory.

Game theory provides many mathematical frameworks for analysis and decision processes for network service (Jiang et al., 2018). In particular, the theoretical basis of the noncooperative game is the Nash equilibrium, which has been widely used (Darzanos and Koutsopoulos et al., 2019). Based on bounded rationality, the evolution game continuously improves the intrinsic force of behavior strategy (Ardagna and Ciavotta et al., 2017).

In the process of the long-term game, supervision is indispensable, and the supervisor chooses the related appropriate strategies to influence the game results (Mohsin and Hussain et al., 2017). The development of mutual trust is a dynamic process that is suitable for the evolution game theory (Ray and Saha et al., 2018).

Currently, many trust game methods lack a variety of perspectives (such as user and CSP) and rarely consider the influence of the supervisor. Aiming at the above problems, to describe the dynamic game competition and cooperation among supervisor, CSP, and user in the cloud service, this paper constructs a tripartite game model based on trust evaluation prediction, studies the dynamic evolution process of the party's behavior, seeks an equilibrium strategy for all parties, and makes corresponding suggestions to maintain the stable cooperative relationship among players. The main contributions of this paper are summarized as follows:

●
Because of the abstraction and subjectivity of trust concept, we give prediction methods of the trust level of multiple attributes based on the Bayesian formula and compute the weight factor by the maximum dispersion principle.

●
Based on the perspective of the user, we discuss the existence possibility of the game equilibrium and establish a payment matrix of two-party game model.

●
Based on the perspective of CSP, we introduce supervisor content, establish a tripartite game model, analyze multiple possible equilibrium points, and obtain the equilibrium strategy from the mixed perspective.

●
Our experiments verify that the supervisor has a significant impact on the strategic choice of the participants, and can effectively control the malicious behavior of users and CSP, provide an exploration for cloud service to achieve a win-win situation.

The remainder of this paper is structured as follows. In Section 2, we review some related work in game theory and trust evaluation in cloud services. In Section 3, we propose a method for trust prediction based on the Bayesian formula and calculate the weight by the maximum dispersion principle. In Section 4, based on game theory and trust, we establish a mixed strategy Nash equilibrium between the supervisor, user, and CSP. In Section 5, we design related experiments to verify the effects of various factors on trust game equilibrium. Finally, in Section 6, we conclude the current research and discuss future work.

2. Related work
When cloud service technology is applied to the market, trust has become a primary problem of servicing online transactions (Jiang et al., 2018). Yang and Shi et al. (2018) proposed a game model to observe the cooperative behavior of multiple stakeholders and studied the evolution stable strategy of multiple stakeholders, but it is difficult to resist the attack of malicious behavior. Yang and Chen et al. (2018) conducted a dynamic analysis of outsourcing services, deduced the evolution stability strategy, and proposed improvement measures. Kamhoua and Kwiat et al. (2018) considered the possible damage from indirect and cross-channel attacks and proposed a game model that has many possible Nash equilibrium, either pure strategy or mixed strategy. Helil and Helil and Halik (2017) constructed a nonzero-sum game model for access control, trust choice, and risk or cost as metrics in players’ payoff functions; however, the trust quantification is not objective and accurate.

The theory of finite cooperative game has developed rapidly in recent decades. Liu et al. (2017) used game evolution theory to analyze the cooperation and competition between commercial banks and e-commerce platforms and proposed some viewpoints to enhance mutual trust. Hu and Liu et al. (2018) constructed a network security model based on an evolution game and introduced a strategy adjustment mechanism to remedy the inadequacy of the replication dynamics. Abusitta and Bouillon and Anquetila (2017) studied the cooperative intrusion detection system in a multi-cloud environment and proposed the theoretical framework, but there is no credible proof process. Liang and Yuan et al. (2018) studied the system evolution relationship between regulation and enterprise behavior and analyzed the incentive effect and trust evaluation of management, but this scheme lacks comparison with other schemes.

To detect malicious users and prevent their feedback, Siadat and Rahmani et al. (2017) proposed a Bayesian game model that can identify and correct false feedback, but identify malicious users with a heavy burden. Li and Zhang et al. (2017) used interactive information to describe the correlation between software and hardware and then built a Bayesian network model to predict future services.

Privacy security is an important research object of cloud services. Li and Li et al. (2018) proposed a certificate verification framework to compensate for the disclosure of privacy certificates and operations. Yang and Lu et al. (2018) proposed a dynamic monitoring scheme for evidence collections that can achieve a compromise between network security and energy consumption. Yuan and Xia et al. (2019) studied the security of the cloud control system, used a Stackelberg model to construct the interactive game, and proposed the optimal solution. Jiang and Chen et al. (2018) discussed the evolution game of community structure, which can promote the protection of privacy in the social network, but the burden of communication is heavy.

Due to the complexity of cloud services, there are some weaknesses in the above research. So, we propose to integrate the game theory, Bayesian formula, trust model, reward and punishment strategy to get the equilibrium conditions under the common perspective, so as to realize a win-win and stable situation of multi-party trust and cooperation.

3. Trust model
In general, the evaluation of the trust attribute is based on past behaviors, so we use the Bayesian formula to combine the prior knowledge with the posterior data. Some important parameters are given in Table 1.


Table 1. Parameters and meanings.

Parameters	Meanings
Participants in the cloud service system
Trust attribute
Weight of trust attribute
Trust function between 
 and 
Service set of CSP
 level trust degree
Trust service map function
Action combination
Selection strategy set
Optimal strategy set
Transaction price
Cost of information collection
The gain of the transaction
Honest cost of CSP
Disguise cost of CSP
Compensation for user
Indirect loss of CSP
Cost of compensation commitment
Average benefit of supervision
Cost of active supervision
Benefit of nonsupervision
Cost of nonsupervision
Indirect loss of the supervisor
Interest rate per period
Discount factor
Honesty probability
Fraud probability
Supervision punishment probability
Probability of nonsupervision
3.1. Preparatory knowledge
Assume that set 
 express the relevant participants in the cloud service system. According to the different roles, these entities are divided into 2 types: CSP and user. According to the dynamics and complexity of trust, assume that the trust function 
 has several attributes 
 between 
 and 
, trust attribute set is 
. 
 Expresses the weight factor of 
, it satisfies the constraint condition formula (1):(1)

Assume that 
 represents the total trust degree evaluation between 
 and 
, it is expressed as follows (2):(2)

The service is provided by 
; the quality of service can be determined by 
, such that when the value of 
 is higher, the quality of service is better. In this paper,  is the number of trust attributes.

In the process of trust service, assume that 
 can be divided  levels 
 
, and the CSP can provide service set 
, so we definite the trust service map function 
 between 
 and 
 as formula (3) as follows:(3)
 
 is determined by the application requirement in cloud computing; when 
 requests service from 
, permission is determined by the trust degree.

3.2. Prediction of trust attribute
Trust comes from social science, it is regarded as a kind of dependence relationship, and the concept of interpretation is very subjectivity. Therefore, according to the practical application requirements of the network web, in this article, we decompose the trust concept into several quantifiable attributes, such as behavior attribute 
, security attribute 
, reliability attribute 
, business attribute 
, performance attribute 
, etc.

Trust attribute can be divided into 5 levels, high trust, trust, basic trust, doubt, and distrust, where 
 , 
 represents the trust level of the attributes.
,  represent the frequency of behavior attributes 
, security attributes 
, reliability attributes 
, business attributes 
, and performance attributes 
, respectively. The prior probability calculation of the behavior trust is the following formula (4):(4)
 
 is the total number of transactions, and after each transaction, the number of times increases by 1. The prior probability calculation process of the attribute level is like the behavior level. In addition to prior probabilities, their conditional probabilities also need to be calculated (Abdel Wahab, 2018). Taking conditional probability 
 as an example (Kumar and Iqba, 2018), when the service behavior level is , the probability of the trust level  is the following formula (5):(5)
 
 
 

Taking the security attribute as an example, according to the Bayesian formula, when the trust level is , the prediction probability of trust level  can be expressed by formula (6):(6)
 
 
 

The security attribute trust level is , the performance attribute trust level is , the reliability attribute trust level is , the business attribute trust level is , , and the probability of trust attribute grade  of the CSP is the following formula (7):(7)
 
 
 

3.3. Computing weight factors
In the above sections, the number of attributes in the trust function is , the effect of multiple attributes is different, so we propose a method to quantify the weight of different factors. Let 
 express the weight vector of the trust attribute (Fuller and Majlender, 2001). “Or metric method” is: 
 
; the dispersion degree is 
; further, , which meets these following three conditions:(8)
(9) 
 (10)

From (8), (9), (10) and the dispersion principle (Fuller and Majlender, 2001), we can obtain (11), (12), (13), (14) as follows:(11)
 
(12)
 
 
(13)
(14)
 

In practical applications, a participant can set a series of reasonable values  and calculate by (12), (13), (14). In the specific requirement of network web service,  is a certain value, and the key is how to determine . According to algorithm 1, as shown in Table 2, when , then 
, and 
; when , then 
, and 
; when , 
; and when , we can obtain different values of 
.


Algorithm 1. Weight of the trust attribute

1: if 
2: then 
,
3: 
;
4: if 
5: then 
,
6: 
 
;
7: for  to  do
8: 
;
9: when 
 
10: ;
11: End.

Table 2. The 
 for different values of .

Weight	α = 0	a = 0.1	a = 0.2	a = 0.3	a = 0.4	a = 0.5	a = 0.6	a = 0.7	a = 0.8	a = 0.9	a = 1 .0
ω 1	0.0	0.0050	0.0389	0.0715	0.1177	0.20	0.2483	0.3961	0.5116	0.7004	1.0
ω 2	0.0	0.7004	0.51 16	0.3961	0.2483	0.20	0.1177	0.0715	0.0389	0.0050	0.0
ω 3	0.0	0.0144	0.0436	0.0683	0.0840	0.20	0.0840	0.0683	0.0436	0.0144	0.0
ω 4	0.0	0.0601	0.1039	0.1572	0.14 19	0.20	0.1419	0.1572	0.103 9	0.0601	0.0
ω 5	1.0	0.2151	0.3020	0.4089	0.41 11	0.20	0.4111	0.4089	0.3020	0.2151	0.0
4. Dynamic game of trust participation in cloud computing
4.1. Game in cloud computing
Game theory is a mathematical theory and method to study the phenomenon of cooperation or competition (Von Neumann et al., 2007).

The user may choose to trust or distrust the CSP, and the provider can choose honesty or fraud after receiving the request. Game theory describes the decision scenario where each player chooses an action to obtain the best return, and a general game includes several basic elements (Cressman and Apaloo et al., 2016).

●
Player 
: It a basic entity in a game that is responsible for making choices for certain behaviors.

●
Action: This refers to the decision variables of the participants at a certain point in the game. Generally, 
 is used to represent a specific action of the participant 
, the order set 
 is the action combination.

●
Information: This refers to participants' knowledge about the game, especially about the virtual participants' choice of “nature” and other participants' characteristics and actions.

●
Strategy: This is the action plan that players can take during game. 
 represents a strategy of 
, and 
 is a strategic set.

●
Payoff: In game theory, payment can refer to the deterministic utility level obtained by the participants under a specific strategic combination or the expected utility level obtained by the participants.

●
Nash equilibrium: This refers to the combination of the best strategies of all participants, which is generally recorded as 
. 
 is the optimal strategy of participant 
 in an equilibrium state.

4.2. Game from the perspective of user
Assuming that the participants are expected to maximize revenue as the basis of choice strategy, each game only needs a user and a CSP. These two parties are not fully informed of each participant's information, and neither party can be informed of the complete information (Matsumoto, 2016). The honesty or fraud probability of the CSP is common knowledge, which can be obtained from the platform according to the Bayesian formula. The CSP gives the information, and the user corrects the prior information after accepting the information and chooses whether to trust the CSP. This process can be described by an incomplete information dynamic game (Cai and Chi et al., 2017).

Because of the problem of the structural characteristics of the dynamic game under the incomplete information, Harsanyi introduced a virtual participant “nature” that determined the characteristics of the participants, and each participant knows only his or her characteristics. At the beginning of the game, the type of CSP is honest or fraud and the game process of both parties is as follows:

(1)
, 
 represents the set of servers in the cloud environment, and  is derived based on formula (7) above.

(2)
After observing its service types, the CSP chooses a policy from the action set 
, where 
 and 
 correspond to “high service security commitment” and “low service security commitment”, respectively.

(3)
After knowing the action 
 of the CSP, the user obtains the posterior probability 
 by using the Bayesian formula and then chooses an action strategy. 
 is the action set of the user, and 
 correspond to “trust” and “distrust”, respectively.

(4)
The profits of the game's parties are 
 and 
. The payment matrix of both parties is shown in Table 3, and the extension formula of this model is in Fig. 2.


Table 3. Game payment matrix.

CSP
Honest 	Fraud 
User	
 	 
 	 
 	 
 
Fig. 2
Download : Download high-res image (214KB)
Download : Download full-size image
Fig. 2. A tripartite game tree for this article.

In Table 3, the payment matrix of the game has four pure strategy Bayesian equilibria: (1) just select 
; (2) just select 
; (3) the honest subject chooses 
, the deceptive subject chooses 
; and (4) the honest subject chooses 
, and the deceitful subject chooses 
. The possibilities of four equilibria are analyzed in the following sequence.

(1)
Just select 
: assuming that an equilibrium makes the CSP honest or deceitful, they will opt for a “high service security commitment”, which is a 
. The user cannot determine the type of CSP according to the information received, that is 
. At this point, the expected return of the user who chooses the trust strategies 
 and the expected return of the user who chooses the distrust strategy is 
. If 
, the advantage strategy of the user is trust, and the best strategy is (trust, honest). At this time, the benefit of the CSP is 
 or 
. To determine whether two types of CSP are willing to choose 
, it is also necessary to check the situation when they choose 
. If the user trusts 
, the benefit is higher than 
, and if the user does not trust 
, the benefit is also higher than 
. Therefore, there is no reason for either CSP to choose 
, and the mixed equilibrium 
 is not a perfect Bayesian equilibrium.

(2)
Just select 
: suppose that an equilibrium makes the service parties honest or deceitful; it will opt for a “high service security commitment”, which is a 
. At this point, the user's benefit is the same as the first case; when 
, the benefit is positive. At the same time, the choice probability of 
 is higher than that of 
. Therefore, there is a perfect Bayesian equilibrium.

(1)
 
(3)
The honest subject chooses 
, and the deceptive subject chooses 
. At this point, the inference strategy choice result of the user is 
, and the best strategy for the user is 
 . It can be seen from Table 3 that neither party has the motive to deviate from the strategy, so there is a perfect Bayesian equilibrium.

(2)
(4)
The honest subject chooses 
, and the deceptive subject chooses 
. The inference strategy choice result of the user is 
, and the best strategy of the user is 
. However, if the deceptive subject chooses 
, the revenue is higher than 
; therefore, this game equilibrium does not exist.

4.3. Game from the perspective of CSP
From the perspective of CSP, due to the huge pressure of profit, reputation and cost, short-term benefits are not the most important, but a stable and orderly service environment is more important to maintain the durability of transactions. Because of the different supervision probabilities, the supervisor can choose the active and negative strategy (Bouillon and Anquetila, 2017). Besides, honesty or fraud is not an inherent nature of the CSP but rather a strategy; the payoff matrix is in Table 4.


Table 4. Payoff matrix of the tripartite game.

Game participants	Supervisor
Active supervision	Nonsupervision
User	Trust 
CSP	Honest 	 
 	 
 
Fraud 	 
 	 
 
Distrust 
CSP	Honest 	
Fraud 	
Active supervision means a much higher punishment probability (Pawlick and Chen et al., 2019); because  is a variable, it is not necessary to set two probability parameters. Considering that the transaction between the CSP and the user has no definite end time, the process can be regarded as an infinitely repeated game. In the selection procession of different strategies, both the CSP and supervisor must consider the effect of the strategy on the long-term benefit. In the calculation of long-term benefit, it is impossible to add the benefit of each period; otherwise, the sum is infinite, which is contrary to common sense. A discount factor  is introduced in the paper, and  is the interest rate per period (Andiraja et al., 2016). The effect of a discount factor is to convert future income into present value.

The main purpose of a user is to seek better service; if the expected return is satisfied, he will choose to trust the CSP o facilitate the transaction. In the active supervision, the expected return of the user who chooses the trust strategy is the following formula (15):(15)

The benefit of distrust choice is 
; when the benefit of trust strategy is greater than distrust strategy, the user will always choose the trust strategy, and then it needs to meet formula (16) as follows:(16)
 

The 
 of formula (16) is to ensure that the condition is meaningful; if 
, the compensation may exceed the service price, but the phenomenon is not very common in practice. Therefore, it is not necessary to be discussed in this paper. For the situation of nonsatisfaction formula (16), the user always chooses the distrust strategy, and the transaction will not occur, which has no practical significance.

When the user chooses the trust strategy, the supervisor chooses the active supervision, and we can obtain formula (17) as follows:(17)

Further, we can obtain a convergent formula (18) as follows:(18)
 

Similarly, the long-term benefits of the supervisor's choice of nonsupervision can be expressed as formula (19) as follows:(19)
 

Therefore, the condition of the supervisor's choice of active supervision is 
, and a further deduction is 
.

When the user chooses the trust strategy, the supervisor chooses active supervision, and the CSP chooses an honest strategy, we can obtain formula (20) as follows:(20)
 

The benefit of fraud strategy is formula (21) as follows:(21)
 

Therefore, the CSP chooses the conditions of honesty: 
, and 
 
.

In the case of satisfying the above three conditions, there is a tripartite game equilibrium as follows:(3) 
 
 
 

In this case, if 
 
, the CSP has the incentive to choose a fraud strategy, and the benefit condition is 
; it does not satisfy the Nash equilibrium condition, so there is no equilibrium (trust, fraud, active supervision).

When 
, the supervisor chooses the nonsupervision strategy, and the CSP chooses an honest condition 
 
. Notice that the punishment probability  is much higher under the active supervision strategy, which conflicts with the assumption that active supervision corresponds to higher punishment probability, so there is no (trust, honest, nonsupervision) equilibrium.

These above three equilibria are analyzed from two perspectives. When the user and the CSP interact with their perspectives, it is a question worthy of analysis to achieve game equilibrium.

Notice: 
 is true in equilibrium 2. This means that full validation of the service type is hard to achieve in practice. Both equilibrium 1 and 3 have cross areas when the user chooses to trust strategy, CSP also chooses an honest strategy, and the cross common condition is (22), (23) as follows:(22)
 
(23)
 
 

Therefore, it is a perfect Bayesian equilibrium of a mixed perspective. Equilibrium 4:  
 
 
 
 .

Equilibrium 4 is a mixed strategy equilibrium, which can satisfy the conditions of three parties. Next, we construct a system dynamics model to understand this game model in Fig. 3, find the game equilibrium, and analyze the influence path on participants’ strategy with dynamic variables.

Fig. 3
Download : Download high-res image (889KB)
Download : Download full-size image
Fig. 3. The evolution game model under the dynamic supervision punishment scenario.

5. Simulation analysis
Experimental environment: 2 core CPU, clock 2.2 GHz, 8 GB memories, and storage 500 GB; soft environment: Windows 10 and 64 bit, MATLAB 2015b. Each user can have multiple choices, so the number of users and CSPs is 500 and 1000, respectively. The user can choose the CSP at any time, and the values of related parameters are in Table 5. According to the above sections, we define the trust probability of the user:(24)
 


Table 5. Values of experimental parameters.

Parameter	Value	Parameter	Value	Parameter	Value	Parameter	Value	Parameter	Value
200	
20		10	
2		
5	
50	
8		50		
100	
100		500		0.04		
40		2	
−5				
5.1. Simulation analysis under two-party game mechanisms
To explain the characteristics of different game models in this paper, in this section, we study the trend of the two-party game in different initial states without a supervisor.

5.1.1. Evolution track of CSP
In Fig. 4, when , because of the high trust probability of users, CSP will actively promote honesty and high-quality services if the users' enthusiasm for consumption is high and they are willing to trust the CSP and pay the corresponding prices. Both trust and cooperation are mutual, when the trust sincerity of users is more sufficient, the probability of the CSP choosing honest behavior is higher, and the speed of the system reaching the stable state is faster.

Fig. 4
Download : Download high-res image (373KB)
Download : Download full-size image
Fig. 4. The evolution track of CSP when 

In Fig. 5, when , because of the low trust probability of users, the system will quickly evolve to a nonideal state even if the probability of an honest strategy by the CSP is very high in a disorderly market, if the other party's sincerity is insufficient, it is useless to make more efforts on one's own. In this case, the probability of the trust strategy of a user is lower, the evolution speed of the system is faster. The trust cooperation strategy is the best choice.

Fig. 5
Download : Download high-res image (366KB)
Download : Download full-size image
Fig. 5. The evolution track of CSP when 

5.1.2. Evolution track of user
5.2. Simulation under the tripartite game mechanism
In this section, we simulate the model to examine how fast the equilibrium state of the service game transitions to a mutually cooperative strategy according to different levels of supervision and punishment.

5.2.1. Strategy trend of the tripartite game
5.2.2. Strategy selection of supervisor variables
In Fig. 11, it can be seen that under the initial probability , when the value of 
 is 4, 6 and 8, the system converges to the ideal stable state of the supervisor's active supervision strategy; when the value of 
 is 10 and 12, the system converges to the nonideal stable state of the supervisor's nonsupervision strategy.

Fig. 11
Download : Download high-res image (278KB)
Download : Download full-size image
Fig. 11. Impact of different 
 on the supervision.

5.2.3. Strategy selection of user variables
In Fig. 12, it can be seen that under the initial probability  and , when  takes 0.5, 0.6, 0.7, 0.8 and 0.9, the system converges to the ideal stable state of the user's trust cooperation behaviors, and when  takes 0.4, 0.3, 0.2 and 0.1, the system evolves to a nonideal state.

Fig. 12
Download : Download high-res image (355KB)
Download : Download full-size image
Fig. 12. The evolution track of the user when .         

In Fig. 13, under the initial probability , when  takes 150, 130 and 100, the system converges to the ideal stable state of the user's trust cooperation behaviors; when  takes 80 and 60, the system converges to the ideal stable state of the user's noncooperation behaviors. According to Table 5, we know that the value of  is not too low; otherwise, the CSP will not agree, and vice versa.

Fig. 13
Download : Download high-res image (290KB)
Download : Download full-size image
Fig. 13. Impact of different  on the user.

5.2.4. Strategy selection of CSP's variables
In Fig. 14, it can be seen that under the initial probability  and , when  takes 0.5, 0.6, 0.7, 0.8 and 0.9, the system converges to the ideal stable state of the CSP's honest behavior; when  takes 0.4, 0.3, 0.2 and 0.1, the system evolves to a nonideal steady state. Due to the dual roles of rewarding honesty and punishing fraud, the CSP eventually evolves an ideal stable state.

Fig. 14
Download : Download high-res image (376KB)
Download : Download full-size image
Fig. 14. The evolution track of CSP when .         

In Fig. 15, it can be seen that under the initial probability , when 
 takes 10, 12, 14 and 16, the system converges to the ideal stable state {trust, honesty, active supervision} in the cloud service market; when 
 takes 18, the system converges to the nonideal stable state (distrust, fraud, nonsupervision); when 
 increases, the system can evolve to a nonideal stable state more quickly.

Fig. 15
Download : Download high-res image (271KB)
Download : Download full-size image
Fig. 15. Impact of different 
 on the CSP.

5.3. Performance comparison
To study the impact of different supervision behaviors on related performance, we designed several comparison parts.

5.3.1. Success rate
In Fig. 16, the low supervision probability is related to the low success rate. From the variation of the 6 curves, the system can reach equilibrium quickly in the active supervision state. Therefore, the supervision has an obvious effect on the formation of game equilibrium.

5.3.2. Average trust of the user
5.3.3. Benefit of participant
5.4. Comparison of different schemes
Based on the parameters in Table 5, we compare this paper against Yang and Shi et al. (2018), Yang and Chen et al. (2018), LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018) and Abusitta and Bouillon and Anquetila (2017), under several standards.

In Fig. 23, with the advance of the experiment, the average cooperate rate of our scheme, LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018) Abusitta and Bouillon and Anquetila (2017) are stable in 0.938, 0.915, 0.898, 0.881, 0.861, respectively.

Fig. 23
Download : Download high-res image (440KB)
Download : Download full-size image
Fig. 23. Comparisons of average cooperate rate.

In Fig. 24, with the advance of the experiment, the average fraud rate of our scheme, LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018) and Abusitta and Bouillon and Anquetila (2017) is stable in 0.061, 0.084, 0.100, 0.116, 0.128, respectively.

Fig. 24
Download : Download high-res image (496KB)
Download : Download full-size image
Fig. 24. Comparisons of average fraud rate.

According to Fig. 23, Fig. 24, Fig. 25, compared with LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018) and Abusitta and Bouillon and Anquetila (2017), our research has better service success cooperation performance, and can better resist malicious fraud service environment.

5.5. Discussion and analysis
From the analysis of the tripartite game, we know that the initial value and changes of related parameters will lead to the convergence of the evolution system to different equilibrium points in the cloud service, and can obtain the following conclusions:

(1)
According to 
, to increase the probability of choosing a supervision strategy, the value of  and 
 can be increased appropriately, and the value of 
 and 
 can be reduced appropriately, so the system should punish nonsupervision and encourage active supervision.

(2)
According to 
 
, to increase the probability of choosing the trust strategy of a user, the value of , 
 and 
 can be increased, and the value of  can be reduced, so the system can increase supervision punishment appropriately and give some rewards to a user who chooses an active trust strategy.

(3)
According to 
 
 
, to increase the probability of choosing an honest strategy by the CSP, we can refer to the above methods. The values of 
, 
 and 
 can be increased, and the values of 
 and  can be reduced. Therefore, the system should increase punishment when the CSP can choose a fraud strategy.

(4)
The strategic choice of CSP and users depends on the strategy of the supervisor. Although a single variable can affect the strategic choice, the formation of the final stable state depends on the interaction of multiple variables. The supervisor should deal with the relationship among various players.

(5)
According to Fig. 4, Fig. 5, Fig. 6, Fig. 7, different initial states have a great influence on the evolution trend. Due to the lack of supervision, both parties need to have a high value of trust and honesty to achieve a successful interaction

(6)
According to Fig. 8, Fig. 9, Fig. 10, the CSP and users will increase the probability of final convergence to 1 under the high initial probability of supervision. A supervisor should make full use of the advantages of modern technology and play an important role in the tripartite game.

(7)
From Fig. 11, Fig. 12, Fig. 13, Fig. 14, Fig. 15, different initial states will affect the strategies choices of a supervisor, users, and CSPs in the game evolution.

(8)
From Fig. 16, Fig. 17, Fig. 18, the higher supervision will bring higher trust, higher service success rate, and more benefits, which also verifies the effectiveness of the best equilibrium stability point (trust, honesty, active supervision) of the tripartite game in this paper.

(9)
According to Fig. 19, Fig. 20, Fig. 21, Fig. 22, Fig. 23, Fig. 24, Fig. 25, our scheme is better than Yang and Shi et al. (2018), Yang and Chen et al. (2018), LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018), Abusitta and Bouillon and Anquetila (2017) under several different standards because we provide more reasonable model parameters, establish a more human-oriented model, and construct a more efficient, quick, and fair cloud service environment through appropriate rewards, punishment, and supervision strategies.

Therefore, it is necessary to take a positive and fair supervision strategy to restrict and guide consumers and CSPs, regulate the behavior of both sides, reward honest

1)
In terms of rationality, Yang and Shi et al. (2018), Yang and Chen et al. (2018), LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018), Abusitta and Bouillon and Anquetila (2017) assume complete rationality; however, players cannot accurately know the player's benefits, which reduces the operability of the research. This paper argues that players are influenced by the specific environment and personal interests and preferences, and the best solution can be found through strategic selection. Our paper significantly improves the science of competition and cooperative game modeling.

2)
In terms of the type and structure of the game, Yang and Chen et al. (2018), LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018) explore the Nash equilibrium to construct a  model, Abusitta and Bouillon and Anquetila (2017), Yang and Shi et al. (2018) and our paper construct a  model. These articles mainly study how to solve the solution of the game. This paper reveals the dynamic process of strategic evolution and analyzes the strategic choice in different evolution periods. In Liu et al. (2017), the game structure only abstracts two simple strategies of competition and cooperation, and relevant regulation lacks consideration of the regulatory role. Our paper constructs a general evolution game structure model with three participants to promote the efficiency of the cloud service.

3)
In equilibrium and strategy independence, Yang and Shi et al. (2018), Yang and Chen et al. (2018), LIANG and YUAN et al. (2018), Liu et al. (2017), Li and Li et al. (2018), Abusitta and Bouillon and Anquetila (2017) provide surveys of noncooperation and cooperation games, respectively. To study the stability of the alliance structure by using the Nash equilibrium concept. Because of the conflicting interest between CSPs and users, we construct a tripartite game model that fits the characteristics of cloud services. Yang and Shi et al. (2018) construct a  model but do not provide a concrete calculation process for the equilibrium solution; our paper provides details of the policy process in Section 4, shows the evolution trend of game parameters in various situations.

5)
In terms of application, Yang and Chen et al. (2018), LIANG and YUAN et al. (2018), Liu et al. (2017), and our paper focus on strategic choice. Yang and Shi et al. (2018), Li and Li et al. (2018), and Abusitta and Bouillon and Anquetila (2017) focus on security and privacy under network service. For wireless sensor networks, Abusitta and Bouillon and Anquetila (2017) established a game framework among multi-cloud, which revealed the evolution dynamics of trust decision-making, and introduced a strategic mechanism to compensate for the low efficiency. Li and Li et al. (2018) developed a certificate awareness framework for online service that compensated for the user's privacy certificate and operation. In other words, these themes are extensions of strategic choices, the research of our paper is more general.

behavior, and punish fraud, to guide both sides to the path of cooperation, mutual assistance and trust, and establish a prosperous, orderly, stable and credible cloud service environment, which is also the best strategy for a win-win situation for all parties.
To better demonstrate the characteristics of this paper, we compare several other schemes in Table 6, such as game structure, application, game type, and so on.


Table 6. Performance comparisons of several game schemes.

Name	Rationality	Strategic independence	Game type	Game structure	Equilibrium solution	Application
Yang and Shi et al. (2018)	Complete	Cooperation	Dynamic	3	Detailed	Security
Yang and Chen et al. (2018)	Complete	Cooperation	Dynamic	2	Simple	Strategy
LIANG and YUAN et al. (2018),	Complete	Non-cooperation	Dynamic	2	Detailed	Strategy
Liu et al. (2017),	Complete	Cooperation	Dynamic	2	Simple	Strategy
Li and Li et al. (2018)	Complete	Non-cooperation	Static	2	Simple	Privacy
Abusitta and Bouillon and Anquetila (2017)	Complete	Non-cooperation	Multi-stage	2	Detailed	Security
Ours	Incomplete	Cooperation	Dynamic	3	Detailed	Strategy
6. Conclusion
How to solve the trust problem of cloud services, safeguard the interests of all parties, and reduce risks is one of the key issues in cloud computing. Firstly, we use the Bayesian formula to predict the level of behavior trust and establish a trust weight model based on the maximum dispersion. Secondly, due to the different perspectives of users and CSP, we establish a two-party game model and a tripartite game model respectively, and analyze multiple possible Nash equilibrium, further obtain the equilibrium strategy under the common perspective through comprehensive derivation. The experimental results show that supervision has an important influence on the strategic choice of participants. Our research provides decision support for users to choose the honest CSP and makes a useful exploration for building a secure and trusted cloud service environment.

In short, it is a long-term project to establish a reliable cloud service system with mutual trust, which requires all social subjects to make full use of human, material, financial, and information resources.
