The fast growth of under developing internet-based technologies has been leading to propose promising methods to handle the heterogeneous massive volume of data produced by pervasive smart equipments such as handy mobile devices. Thanks to the mentioned technologies, these mobile devices can run critical business/entertainment applications such as Augmented Reality, Virtual Reality, vehicular networks, and media streaming. However, due to such devices' inherent limitations, some emerging computation environments such as Mobile Edge Computing have been introduced to achieve some essential requirements such as low latency, low energy consumption, and low cost. In the literature, offloading is a technique to transfer the burden of the mobile devices' work incurred by running applications' requests to these computation environments. On the other hand, exploring the computation environment to find the most efficient place to execute such requests is challenging work to achieve. In addition, different researches have been proposed to cope with the management problems of the offloading criterion. In this paper, an autonomous computation offloading framework is proposed to address some challenges related to time-intensive and resource-intensive applications. However, to the best of the authors’ knowledge, the proposed autonomous framework has not been explored as a control model for self-management in the computation offloading criterion. Besides, to cope with the large dimension of the offloading decision-making problem, different simulations including Deep Neural Networks, multiple linear regression, hybrid model, and Hidden Markov Model as the planning module of the mentioned autonomous methodology have been conducted. Simulation results show that the proposed hybrid model can appropriately fit the problem with near-optimal accuracy regarding the offloading decision-making, the latency, and the energy consumption predictions in the proposed self-management framework.

Previous
Next 
Keywords
Offloading

Mobile edge computing

Machine learning

Neural networks

Hidden markov model

Regression

1. Introduction
Despite numerous advantages of cloud systems, it suffers from some significant problems such as security, delay, and energy consumptions for executing user requests. Besides, heterogeneous massive volumes of data produced by pervasive smart equipments such as handy mobile devices running different applications such as Augmented Reality (AR), Virtual Reality (VR), vehicular networks, and media streaming incur extra demands of computation resources on such devices.

Because of such devices' inherent limitations, since the executing requests could be time and life-critical, Mobile Edge Computing (MEC) has been proposed to address these issues (Shahidinejad and Ghobaei‐Arani, 2020, Zhang et al., 2020a; Huang et al., 2019a; Li et al., 2019a). The European Telecommunications Standards Institute (ETSI) and OpenFog Consortium have presented standard definitions related to the MEC that has been later changed to Multi-access Edge Computing (European Telecommunicatio, 2020; OpenFog Consortium and acces, 2020). Later, they changed Mobile Edge Computing to Multi-access Edge Computing to cover a variety of other non-mobile access networks such as WiFi, Virtual Network Functions (VNF), and Software-Defined Networking (SDN) (Carvalho et al., 2020). In general, closer paradigms such as MEC have been considered as an environment to bring the cloud capabilities closer to the smart equipments' level where the data is generated. These environments are supposed to enhance the essential metrics such as delay, computation energy, and users’ satisfaction for those tasks. Resource and time limitations are challenging issues to achieve (Shahidinejad et al., 2020b, Shahidinejad et al., 2020a, Xiao et al., 2020; Liu et al., 2019; Ning et al., 2020).

Generally, the offloading approaches try to alleviate the inherent limitations of local mobile devices running life-critical‌ ‌applications that might be resource-intensive. Different approaches have been proposed to address related challenges; none of them is satisfactory. These approaches generally consist of game theoretic-based, machine learning-based, mathematical-based, or the combined form of these approaches. The heuristic-based algorithms mostly present these approaches with single/multiple objective(s) originated from biology and economics to solve planning/learning/behavioral/constraint-based decision-making problems. On the other hand, offloading optimizes challenging decision-making problems based on whether, where, when, and how much of the code to offload. Because of dynamism and heterogeneity in computation environments, classical approaches are not appropriate to solve the nonlinear characteristic of such problems.

Generally, computation offloading to the nearby MEC servers is the mechanism to enhance latency, energy consumption, and costs of the system and improve the offloading quality, specifically in the presence of 5G telecommunication networks (Lu et al., 2020). In the offloading literature, some research papers try to address the facing challenges jointly to achieve the user requirements for such a decision-making problem with its high complexity optimally (Diao et al., 2018; Huang et al., 2019b, 2020a; Peng et al., 2019; Wang et al., 2020; Ye et al., 2020). However, plenty of researchers have explored the offloading domain deeply to present new approaches to address the vital offloading issues and meet the mentioned requirements. These approaches are presented based on machine learning, game theory, stochastic models, and other mathematical-based models to resolve decision-making problems in the literature (Shakarami et al., 2020a, 2020b, 2020c).

The MAPE-K1 loop is a conceptual control model for self-management systems introduced in 2003 b y IBM's first autonomic toolkit (M and accessed 14 Nov. 202, 2020). This conceptual model has been used in various systems as a reference control model (Gill et al., 2018; Singh et al., 2016, 2017) and explicitly implemented in the cloud environment for efficient resource provisioning. Based on the definition, MAPE-K is constructed of four main components: Monitoring, Analyzing, Planning, and Executing that will be discussed later in more detail. ‌However, despite its comprehensive utilization in various computation environments such as cloud, the MAPE-K loop has not yet been exploited in the computation offloading process, which is applied in the present study.

Deep Learning (DL) is a type of machine learning that can handle architectures with unlimited heterogeneous numbers of a network's layers. On the other hand, Deep Neural Networks (DNN) is the parameterized implementation of deep learning in a traditional Artificial Neural Networks (ANN) with multiple layers' architecture. The intuitive behind the feature “deep” is the power of learning given to the artificial neural networks, making it extremely appropriate to predict, detect, and optimize complex problems. This approach explores optimal solutions among its training inputs by proper mathematical manipulations. Also, it extracts and selects the most suitable features of its input values to facilitate the learning in this multi-layered artificial neural network architecture. Some critical parameters, such as numbers of layers, initial weights, and learning rate, must be configured appropriately to avoid some common problems such as over-fitting and execution delay. Generally, these issues demand high computational resources and are in conflict with offloading purposes' goals (Shakarami et al., 2020a).

Hidden Markov Model (HMM), which is a type of unsupervised machine learning, is an extensively exploited probabilistic Markov model representing a series of discrete or continuous observations with time dependency/independency to predict the future behavior of the system. The HMM model is separated with its hidden states and observable states compared with the Markov Decision Process (MDP) model that is analyzed by its observable states. Besides, hidden states and observable states are connected by probability distribution (Shakarami et al., 2020b, 2020c).

In this paper, the MAPE-K loop concept has been explored as a conceptual approach in the computation offloading mechanism. In the proposed approach, we applied the DNN to predict the offloading decision-making, the delay incurred by local or remote execution of the requests, and the energy consumption of the execution of the ecosystem's requests. We also exploited the HMM model as the model to select uplink transmission media among the predefined ones. Since the incoming rate of the requests and the number of uplink media could be more than that of the supposition of the current study, flexibility and critical learning features of DNN and HMM models make it possible to override the mentioned concerns.

Additionally, to address some potential issues of offloading criterion, the main contributions of this study are briefly as follows:

Considering a multiple-user/multiple-server environment with heterogeneous services and edge colonies/cloud platforms to reply to the users' requested services;

Utilizing the concept of the MAPE-K loop to model the problem of offloading decision-making among different execution environments;

Applying deep learning on Neural Networks (DNN) to select the most appropriate place to execute the incoming requests from the lower levels among the edge colonies. In addition, multiple linear regression along with DNN modeling as the hybrid model to achieve the most-optimal predicting results is utilized;

Applying the Hidden Markov Model (HMM) to select the most appropriate uplink transmission media among the existing ones;

The rest of this paper is organized as follows: Section 2 reviews some essential related works. The proposed approach is provided in Section 3. Section 4 discusses the experimental results. Besides, Section 5 maps out discussion that includes a summary of simulations and some open issues as future work. Finally, we present the conclusions in Section 6.

2. Related works
As an emerging technology, MEC is provisioned to bring computational flexibilities for offloaded users’ requests considering energy and delay constraints. Despite its numerous advantages, because of the inherent stochastic behavior of its entities, MEC is still under development to address some related user-centric challenges (Shakarami et al., 2020b; Kuang et al., 2020).

In the offloading literature, various challenges limit the user's expectations that are generally in the form of Quality of Service (QoS) and Quality of Experience (QoE) and are collected under the umbrella of offloading metrics. Since some applications running on handy mobile equipments are life-critical, some metrics, such as delay and energy consumption of such resource-limited equipments become significant. Therefore, to get rid of such limitations and meet requirements of those critical metrics, decision-making ‌offloading approaches become incredibly significant. Generally, the mentioned challenges could be categorized into two main subsets: external challenges of offloading, internal challenges of offloading. The former is defined as those challenges that have mutual impacts on offloading decision-making. The latter is defined as those challenges that are related to the offloading itself that affect the external features (Shakarami et al., 2020c). Since there is a tight relationship between these two types of challenges, most researchers propose their approaches to presenting multi-objectiveness in their work.

2.1. External challenges of offloading
Concerning the external challenges, the MEC offloading problem's main challenges are summarized in observing metrics, profits, wireless channels, delay dependencies, and the type of links. These challenges lead to the questions where, when, and how much of the code to be offloaded efficiently to enhance some predefined metrics such as energy, latency, and costs incurred by devoting computation resources of such a close computation paradigm to the intensive part of the applications. Some researchers focused on the scenarios where single mobile devices try to offload their tasks to a single server to address these challenges. With this unrealistic hypothesis, the problem is hardly possible to implement (Wang et al., 2019; Yu et al., 2017; Eom et al., 2015; Li et al., 2019b; Zhang et al., 2019a; Meng et al., 2019; Aazam et al., 2018). In most of these scenarios, essential features of MEC environments, such as stochastic behaviors of entities and hardware and service heterogeneity, are neglected or weakly covered (Wu et al., 2018; Crutcher et al., 2017; Sangaiah et al., 2019).

Engel et al. (2020) presented a distributed context-aware DNN-based model for image processing in a 3D sensing system in the MEC offloading system. Although they presented an extensive model for their offloading approach‌ to offload real-time requests to different systems such as local mobile, edge, and cloud environment, the limited nature of rule-based models bound the learning for new requests with dissimilar historical data to predict near-real future behavior. Similarly, the authors of (Feng et al., 2020) applied the back propagation NN offloading approach in the presence of 5G communication links to tackle the energy consumption and delay incurred by offloading the computation. Although they presented an appropriate computing model, the system model is not practical to implement because of the limited numbers of users and servers. Some essential factors, such as transmission and propagation delay, are neglected in the communication model to calculate the energy and delay. Shin et al. (2019) partitioned a DNN model for the demanded offloading in resource-demanding devices to make DNN queries to the clouds where the peer DNN models are preinstalled. Although they presented an appropriate fine-grained offloading approach, their model suffers from high complexity and overloading in the case of high queries.

Zhao et al. (Zhao and Zhou, 2019) proposed a selective offloading by utilizing the ARIMA-BP concept to predict the computation capacity that considered energy optimization along with delay constraints. Although their model is appropriate in the sense of selective offloading, their model suffers from high complexity. Likewise, Jeong et al. (2018) utilized DNN but in an incremental dividing-based version for offloading purposes to offload multiple divisions to the edge server in sequence. Notably, the execution of the DNN divisions is started even before the DNN model is entirely offloaded. Although they presented an appropriate fine-grained offloading approach, their DNN model's limitations and single offloading can be the drawbacks of their proposed model. Xu et al. (2019a) considered the work as a joint problem, optimizing offloading utility and avoiding privacy leakage of user's information and making a trade-off between these two crucial metrics. Although they provided an appropriate mathematical proof for their proposed model, the proposed offloading method has high complexity. In addition, the provided transmission rates among different entities make the model unrealistic to implement.

Yang et al. (2019) applied a Hierarchical deep Machine Learning (ML)-based model to detect malicious activities of Industrial IoT (IIoT) to solve the offloading problem of the MEC system. Although they provided appropriate mathematical proof and problem formulation, the proposed optimal offloading strategy selection method suffers from high complexity. They also defined extra hidden layers for modeling devices’ surveillance, which degrades the performance of modeling. Zhao et al. (2019) applied deep learning to construct multi-Long Short Term Memory for traffic prediction of the WiFi access point for offloading to the MEC environment. Although their presented model has an acceptable level of complexity, it is not practical to implement. The authors of (Guo et al., 2019) presented a blockchain framework and applied Deep Reinforcement Learning (DRL) to solve it in the MEC system. Although their presented model has an acceptable system model, it is more theoretical and not practical to implement‌.

2.2. Internal challenges of offloading
Considering the internal challenges of offloading, the MEC offloading problem's main challenges are summarized in how to offload the code efficiently regarding the dynamicity of decision, applied algorithms, granularity, and scheduling. Some researchers presented their models with high complexity and low convergence algorithms, which leads to inefficient latency and energy consumption that does not meet the requirements of time-intensive and life-critical applications and is in contrast with the existential nature of MEC environments (Farahbakhsh et al., 2020, Guo et al., 2019, Jazayeri et al., 2020a, Jazayeri et al., 2020b; Xu et al., 2019b; Liu and Zhang, 2019; Wang et al., 2018; Tan and Hu, 2018; Lu et al., 2019; Zeng et al., 2019).

On the other hand, some other researchers proposed their scheduling model exploiting a kind of stochastic approach, such as MDP (Fu et al., 2020; Zhang and Zheng, 2019; Zheng et al., 2019; Zhang et al., 2019b, 2020b). Despite presenting the complementary approaches such as DRL to overcome drawbacks of such an approach, the action state will overgrow when there are plenty of uncertainties in the ecosystem that grow the computation complexity and make it unsuitable for IoT/IIoT systems.

Miao et al. (2020) used an LSTM-based prediction scheme by deep learning for scheduling an offloading strategy to reduce the latency of the task offloading process in the mobile-edge cloud environment. Although their model included the MEC intermediary computation paradigm to overcome delay-related shortages, since there are still direct transactions between the smart and cloud layers, energy consumption and delay might be violated. On the other hand, since their proposed model is based on LSTM, an extension of Recurrent Neural Networks, it cannot handle long-term dependencies based on what the paper claimed. Sacco et al. (2020) applied a deep learning-based planning strategy to provide persistent services and respond quickly to disastrous situations into their audio recognition model. Although their model is presented with the edge network's existence to control the applied Jackson's network queues model that estimates arrived tasks, the service time is followed by a first-come-first-service policy that is not a fair policy for offloading or execution purposes. Likewise, Alkhalaileh et al. (2020) proposed a Mixed Integer Linear Programming-based (MILP) scheduling task offloading scheme in the mobile-edge cloud environment. They formulated their problem as mixed-integer linear programming to optimize costs and energy consumption of the devices. Although they presented an appropriate application model, their task-scheduling algorithm suffers from high complexity and overloading in tasks' high arrival rates in real scenarios.

Instead of MDP, by exploiting Q-Learning (QL), Hossain et al. (2020) worked on a binary decision-making problem, and to solve this problem, they utilized Reinforcement Learning (RL); thereby, cost and delay of computation are improved. Although to get rid of local minimum, they applied Q-learning that addresses the dimensionality space challenges incurred by the proposed binary computation offloading decision. The curse of dimensionality is not removed by applying such a Q-learning approach, which is an off-policy method. Yang et al. (2020) focused on offloading optimization in industrial applications running on dedicated equipments and their related challenges to improve the latency and energy consumption of such equipments by presenting a linear programming algorithm, ASO, and an intelligent heuristic algorithm, Invasive Tumor Growth Optimization-based (ITGO) approach. Although they offered a suitable system model, their task-offloading algorithm suffers from high complexity and overloading in tasks’ high arrival rates in real scenarios.

Huang et al. (2020b) investigated a task scheduling for computation offloading to the MEC system to optimize the decision to offload, select the transmission media, and power allocation. Then, they ‌approximated their proposed method by infinite-horizon MDP, and to get rid of the high dimensionality of their applied method and to improve the performance of the system, they utilized reinforcement learning. Also, to model transmission power, they presented Stochastic Gradient Decent (SGD) in their model. Although they presented the applied reinforcement learning to address the dimensionality space challenges incurred by the proposed MDP, the mentioned curse of dimensionality is not removed by applying reinforcement learning.

Based on the above discussion in the field of offloading, a side-by-side comparison is presented in Table 1 in terms of strategy, applied metrics, evaluation tools, advantages, and weaknesses of each technical study.


Table 1. A side-by-side comparison of offloading strategies.

Reference	Strategy	Applied metrics	Evaluation tools	Advantages	Weaknesses
Engel et al. (2020)	DNN	Energ
Delay	Implementation (NA)	Extensive system model	Limited nature of the proposed rule-based model
Feng et al. (2020)	DNN	Energy
Delay	Simulation (MATLAB)	Appropriate computation model	Not practical to implement because of limited numbers of users and servers
Shin et al. (2019)	DNN	Delay	Implementation (NA)	Appropriate fine-grained offloading approach	High complexity
Overloading in high queries
Zhao and Zhou (2019)	ARIMA-BP	Delay
Energy	Simulation (NA)	Appropriate selective offloading approach	High complexity
Jeong et al. (2018)	DNN	Delay	Implementation (caffe)	Appropriate fine-grained offloading approach	Model limitations
Single offloading
Xu et al. (2019a)	NSGA-III	Energy
Delay	Implementation (NA)	Appropriate mathematical proof	High complexity
Unrealistic to implement
Yang et al. (2019)	DL	Delay	Implementation (TensorFlow)	Appropriate mathematical proof	High complexity of the offloading strategy selection method
Zhao et al. (2019)	DL	Throughput	Simulation (NA)	Acceptable complexity	Not practical to implement
Guo et al. (2019)	DRL	Cost	Simulation (Python)	Acceptable system model	Not practical to implement
Miao et al. (2020)	DL	Delay	Implementation (Alibaba cloud server)	Considering the appropriate intermediary computation environment	Violating SLA metrics
Capable of handling long-term dependencies
Sacco et al. (2020)	DL	Delay	Simulation (C++)	Appropriate arrival task's estimation	Inappropriate service time policy
Alkhalaileh et al. (2020)	MILP	Delay
Energy
Cost	Implementation (NA)	Appropriate application model	High complexity
Overloading in high arrival rates
Hossain et al. (2020)	QL	Cost	Simulation (NA)	Appropriate system model	High dimensional state space
Yang et al. (2020)	ITGO	Delay
Energy
Cost	Simulation (WorkflowSim)	Appropriate system model	High complexity
Overloading in high arrival rates
Huang et al. (2020b)	RL	Cost	Simulation (NA)	Acceptable system model	High dimensional state space
3. Proposed approach
In this section, the proposed framework is explained in more detail. Firstly, a MAPE-K-based control loop framework for computation offloading architecture in a tree layers methodology is introduced. Then, the computation offloading problem is formulated. Finally, to perform lower-level requests, an autonomic computation offloading algorithm is presented. Table 2 depicts some essential definitions of the utilized sets in this research work.


Table 2. Important definitions of the utilized sets.

Definition	Subset
Input requests	
Mobile devices	
Edge colonies	
Resource type	
Processor information (Utilization, Limitation, Rate)	
Storage information (Utilization, Limitation)	
Communication information (Utilization, Input Limitation, Output Limitation)	
Set of resources	
Resource utilization	
Incoming content	
Request's sensitivity	
Requirements of incoming Requests (Maximum acceptable Delay, Maximum acceptable consumed Energy)	
Request Information	
Hidden states of HMM	
Observable states of HMM	
3.1. The proposed framework
In this subsection, the computation offloading framework is introduced in a layered methodology. The computation-demanding part of the code can be executed locally or remotely in accordance with the intensiveness of the computation. The proposed framework for the methodology, as mentioned earlier, is defined as a three-layer computation architecture consisting of the smart devices layer, the edge layer, and the cloud layer. The general architecture of the proposed architecture is depicted in Fig. 1. In the following, the layers of this architecture are described briefly:

There are different devices in the smart devices layer, such as sensors, smart mobiles, tablets, etc., with heterogeneity in terms of storage, CPU, and communication capabilities, possibly interconnecting with each other.

In the edge layer, the APs and the edge servers with relatively small data centers are placed. The edge servers are categorized as the form of colonies in a distributed wide area to better management and cover all devices of the lower layer. These servers are usually accessed through optical channels by a colony of APs scattered in a distributed manner.

In the centralized cloud layer, robust data centers with unlimited resources are placed to serve appropriate services. Since this work is aimed to describe profoundly different responsibilities of the edge layer, we do not go deeper into the cloud layer's entities and responsibilities.

Fig. 1
Download : Download high-res image (456KB)
Download : Download full-size image
Fig. 1. Proposed computing architecture.

Since this research work studies the autonomic decision-making process of whether to offload the computation-demanding part of the application, we need to focus more on the main issues of the proposed architecture.

3.1.1. Smart gateways
The proposed model uses two types of gateways; Edge Smart Gateway (ESG) and Cloud Gateway (CG). ESG is responsible for deciding whether to offload the incoming requests or send back the request to the requester. Since the MAPE-K loop is executed in this smart device, it must be configured appropriately, and this configuration affects the optimization of the entire network. CG is responsible for managing the upcoming traffic to different cloud servers.

3.1.2. Edge colonies
The edge computation paradigm is modeled as colonies of the edge servers to better covering the requests in a reasonable time, energy, and costs. On the other hand, each colony is provided with some edge servers pre-located under the distance and a colony agent, as depicted in Fig. 2. The colony agent keeps some information, such as the overall utilization of each colony, and transacts with the ESG. If there is no free capacity to perform the request in the current colony, the colony agent negotiates with the ESG to choose another appropriate destination server. Since most time-sensitive and lightweight resource-sensitive requests are responded at the edge colony layer, appropriate pre-configuration of its resources and services, also running the suitable load prediction models for predicting the system's future behavior and requests are of high significance. Hence, the proposed DNN, regression, hybrid, and HMM models predict these resources' offloading destination in the presented autonomous system. Noteworthy, the colony agent that holds related general information will inform the autonomous system‌ to take the appropriate place to execute the incoming requests.

Fig. 2
Download : Download high-res image (432KB)
Download : Download full-size image
Fig. 2. Offloading decision-making problem.

3.1.3. Autonomic offloading manager
The autonomic offloading manager is comprised of a MAPE-K agent. As the brain of the decision-making process, the MAPE-K agent is considered to take responsibility. The MAPE-K agent is constructed in four main components: Monitoring, Analyzing, Planning, and Executing. All these components have a close data transaction with the Knowledge, which is the system's database. In Fig. 3, these components and their relationships are shown in more detail.

Monitoring: this module comprises an input queue, data type checker, and duplicate request checker.

Analyzing: As the second phase of the MAPE-K loop, the primary responsibility of this component is to analyze the inputs coming from the former component that comprised of splitting module, encoding module, noise injection module, missing value manipulation module, outlier manipulation module, and scaling module.

Planning: provided with the information of the former phases, the proposed algorithms of this phase, as the mastermind of the MAPE-K loop, are responsible for the final decision making whether to execute the request locally or remotely. As a result, this final decision making influences the total performance of the system. It is proposed to have DNN and HMM models as the decision-maker of this process. As it is planned, the following actions are considered in this phase (Fig. 3):

Planning for local execution of the request by one of the existing scheduling algorithms.

Planning for offloading the request in the case of lacking enough resources on the local mobile. Noteworthy, when the request is communication media, the request is offloaded in any case.

Planning for selecting the most appropriate uplink transmission media among the existing ones utilizing the HMM model.

Fig. 3
Download : Download high-res image (581KB)
Download : Download full-size image
Fig. 3. The MAPE-K loop structure.

If the decision violates the SLA, the request is sent back to the ESG to further investigation; else, it is handed over to the next phase.

Executing: this phase is the final step of the MAPE-K loop, responsible for executing the planned decisions. This component enqueues the incoming results of execution and visualizes them. Finally, the destination will be aware of the decision, and the request will be sent to that destination.

Knowledge: all the information needed to fulfill the related responsibility of MAPE is provided by Knowledge, which is the database for keeping track of all activities in the steps mentioned earlier. SLA DB sub-component is to keep user expectations in respect of predefined SLA. This sub-component is made up-to-date by the Analyzing module in which different metrics such as security, energy, latency, availability, reliability, utilization, fault detection and protection, and throughput could be considered to measure SLA based on user expectations. In this research work, energy consumption and delay of offloading are considered, and these two metrics are received to judge whether the decision meets the SLA or not. Resource DB module keeps track of resources' changes. It means that it has to gather and categorize any information related to resource (software and hardware) constraints and limitations.

3.1.4. Load balancer
The load balancer is another component that is provisioned to manage the load among different destinations. Using predefined strategies, this component tries to avoid network congestion, prevent resource contention, and fairly resource dedication in the ecosystem, where different components share resources for fulfilling different requests. It has been defined three different destinations for the local, edge, and cloud load balancing, respectively, to enhance the predefined metrics depicted in Fig. 4.

3.1.5. Software services (S/W) and hardware (H/W) resources
To answer the input requests appropriately, enough hardware resources and appropriate software services must be available. Provisioning suitably these resources and services leads to a general decrease in energy consumption and enhances the system's total latency.

3.1.6. Sequence diagram of the proposed framework
In this subsection, the interactions amongst different entities of the proposed framework will be discussed. As depicted in Fig. 5, the ESG will loop to sense incoming requests sent by smart mobile devices. Next, the ESG requests the latest status of the edge colonies from colony agent. This agent will be aware of any request coming from the ESG. Upon receiving the reply, the ESG will send the request to the Monitoring module. As the first step of the MAPE-K loop, the Monitoring module will be listening to its input queue's alarm to take the arrival requests. After fulfilling the job by Analyzing module, the Planning module will perform the prediction for one of four destinations of its decision-making process, including local mobile execution, edge colony execution, cloud execution, or sending the request to the input queue if there is no related time-constraint for the mentioned request. In addition, the components of MAPE-K loop have interactions with the Knowledge module. Finally, colony agent will send the information of execution results to the ESG.

Fig. 5
Download : Download high-res image (567KB)
Download : Download full-size image
Fig. 5. Sequence diagram of the proposed framework.

3.2. Problem formulation
In this section, we first present related equations to the current study's two essential metrics (i.e., delay and energy). Then, the proposed DNN and HMM models' equations for offloading decision-making and uplink selection decision-making are described. Also, the most critical variables that are used in the current study are depicted in Table 3.


Table 3. Description of the proposed framework's variables.

Abbreviation	Variable description
Computation delay of server 
 in time slot t for request 
Total delay of local execution
Total delay of remote execution
Available 
’s capacity of edge server e for the request 
Sending delay of the request 
Receiving delay of the request 
Total energy of local execution
Total energy of remote execution
The decision for the request 
 to be executed locally
The decision for the request 
 to be executed in colony c, edge e
The decision for the request 
 to be executed in the cloud
3.2.1. Delay model
For computation, the delay is defined as the time for executing the task. If the computation-intensive part of the task is planned to execute locally, the execution time is tied to the CPU frequency of the current server. Then, the computation delay of the server 
 in time slot t for request i, 
, is formulated as follows (Huang et al., 2019c):(1)
 
where 
 are computation size (in bits), computation intensity (in cycles/bits), and CPU frequency of server 
 (in cycles/seconds or HZ). Also, if the request is planned to execute locally by VMs, starting up the process of these VMs incurs an extra delay, 
, to the system, in which j denotes the number of started VM for request 
. As a result, the total delay is the summation of all delay of started VMs, as follows:(2)

Therefore, the total delay of local execution is formulated as follows:(3)

More specifically, if the goal is to have a delay-efficient system, the delay 
 of equation (3) must be minimized, and to fulfill this, 
 must be minimum, which means using appropriate VMs.

On the other hand, if the request is planned to execute remotely, the total delay is the summation of the delay incurred by sending the request, the delay incurred by remote server execution, and the delay incurred by receiving the response. Let 
 and 
 denote allocated bandwidth to send/receive i-th request to/from nearby servers, respectively, including neighbor edge servers or cloud servers. Then, 
 and 
 denote sending and receiving transmission delay of i-th request with data size of 
 and 
, could be formulated as follows:(4)
 
(5)
 

If the offloaded request is not replied to when the requester is in the range of that remote server, then the reply must be handed over to the requester's present location. This migration incurs an extra delay 
 to handover the request 
 from server 
 to server 
 which is the same as equation (3).

If it is planned to have partial offloading, the code i must be fractioned into n offloadable parts that this process incurs an extra delay of 
 to the system.

According to the above discussion, the total delay of service time is formulated as follows:(6)

Generally, to have a delay-efficient system, the strategy of execution requests must be minimized based on equations (3), (6), as follows:(7)

Noteworthy, the delay for incoming requests is predicted by applying the DNN model with three layers; the first layer is the input values, the hidden layer, and the result of prediction as the output value.

3.2.2. Energy consumption model
Based on the offloading problem in the MEC environments, if the request is planned to execute locally, the energy consumed locally, 
, is proportional to the power consumption per CPU cycle and required CPU cycle per bit of tasks for request 
, as follows (Gao and Moh, 2018):(8)

Also, if the request is planned to execute locally by VMs, starting up the process of these VMs incurs extra energy consumption
 to the system, in which j denotes the number of started VM. As a result, the total delay is the summation of all energy consumed by n started VMs to execute the request
, as follows:(9)

Therefore, the total energy consumption of local execution is formulated as follows:(10)

For remote execution, consumed energy in server 
 is formulated as follows:(11)
 
where 
, 
, 
 for node n denote transmission power, request data size, and transmission rate, respectively. Also, the transmission rate is formulated as follows:(12)
where  and  denote signal to noise ratio and bandwidth of the wireless channel, respectively. Noteworthy,  is defined as
.

Then, total energy consumption for request 
 is formulated as follows:(13)
where 
 
 and 
 are the energy consumed for sending, receiving, hand over, and fragmentation of the request, respectively.

Generally, to have an energy-efficient system, the strategy of execution requests must be minimized based on equations (10), (13), as follows:(14)

Noteworthy, the consumed energy for incoming requests is predicted by applying the DNN model with three layers; the first layer is the input values, the hidden layer, and the result of prediction as the output value.

3.2.3. DNN-based offloading model
The proposed DNN model offloading decision-making has three layers; the first layer is the input values, the hidden layer, and the result of the decision as the output value. The binary offloading decision-making for the request 
 could be denoted as
, in which
, 
, 
, and 
 are local execution, execution on colony 1, edge 1, execution on colony c, edge e, or execution on the cloud servers. The offloading decision aims to minimize total delay and total energy consumption of the executing requests, considering cost limitations, as mentioned in equations (7), (14). Therefore, under the decision
, energy consumption  and delay of computation  are considered as follows:(15)
(16)
(17)

Then, the optimization problem is presented as follows:(18)
 s.t.(19)
 (20)
(21)
where 
, 
, and 
 are the constraints of incoming requests, 
 is the constraint of edge servers, and 
 is the constraint of offloading decisions. Notably, since based on the constraint 
 the incoming requests could be sensitive, the general policy for handling these kinds of requests are offloading them to the cloud, even if the requests' size is in the range of local or edge capabilities. The reason is that sometimes the running application needs a couple of bytes of data to be stored in the cloud's safe environment. Obviously, these requests do not need any SLA assessments.

Since the objective function 
 is linear, and related variables are integer. Also, the decision to offloading among different choices is binary. Hence, the mentioned optimization function with mentioned restrictions first looks a particular case of mixed-integer programming (i.e., binary programming), which is inherently an NP-complete problem. To solve this problem, we first present the relaxation of the MIP problem, 
, as follows:(22)
 s.t.(23)
 (24)
(25)

Now, we apply the DNN model to solve this NP-complete problem. We first find the complexity of the applied DNN model for such problems‌.

Lemma1

Applying DNN on 
, the time complexity for the offloading problems is generally in the order of O(
).

Rational Proof: To describe the definition1, the DNN model is divided into its modules, and then the time complexity of each one will be discussed. The DNN model comprises a feedforward propagation algorithm, the activation function, and backward propagation to calculate the loss function. In the following, we will discuss each of these steps.

Feedforward propagation: Given the number of data training ‌(i.e., independent input values) n, the number of features p, the number of neurons of layer i 
, the number of layers m, and the number of output values o, the time complexity of neural networks is generally in the order of O(
), which is a cost-demanding operation for massive complex networks. Notably, since most case studies have a single output value, it is usually neglected in the mentioned complexity, o is usually neglected. On the other hand, the order of the propagation algorithm will be added to the order of the activation function that is O(), resulting in keeping the complexity as mentioned above (Serpen and Gao, 2014; scikit-learn and accessed 12, 2020).

Backward propagation: Given the number of iterations ‌(i.e., epochs) ‌e to calculate loss function, based on the above discussion‌, the time complexity of the backward propagation is O(
).

Noteworthy, we had the choice to select between CPU and GPU to soften the burden of the work, but, since the time of convergence was acceptable in the case of selecting CPU, it is selected as the processing resource of the DNN model.

Based on the above discussion, the total complexity of the DNN model is in the order of O(
).

3.2.4. HMM-based uplink selection model
The state of decision for selecting the transmission media is predicted based on the preliminary information collected by the Monitoring module. Because of the uncertain nature of incoming requests and the selection of appropriate uplink to transmit them, which are influenced by the uncertainties of wireless channels and the users’ mobility, there are many uncertainties in this decision-making process. Therefore, we apply HMM to predict the relationship between the observable states and the media's hidden states according to the historical information, then predict the following state to better resource management and achieve predefined goals of this work that are energy consumption and delay of the system.

Noteworthy, the incoming requests follow Poison distribution with an arrival rate of. Besides, the adding and releasing resources’ process follows an exponential distribution with the event rate of  and  and mean value of 
 
 and
 
, respectively.

Also, the sets 
 and 
 denote the observable and the hidden states, in which each hidden state is attached to an observable state. Observable states have been defined as the place to execute the requests that include local mobile, edge, and cloud environment. On the other hand, hidden states have been defined as the uplink transmission media that include Bluetooth version2, Bluetooth version3, and GSM. Fig. 6 depicts an ergodic model of HMM to show the hidden sequence of decision-making outcomes. It is also possible to navigate between hidden states by a probability distribution represented by the form of the transition matrix with three transition states as unknown parameters.

Fig. 6
Download : Download high-res image (160KB)
Download : Download full-size image
Fig. 6. Possible sequence of hidden states in the proposed HMM.

Based on the previous discussion, the transition matrix can be written as follows:(26)
 

Based on the equations mentioned in (Chatterjee and Russell, 2012; keras and accessed 13 Nov. 2, 2020) and Figs. 5 and 6, the emission matrix is as follows:(27)
 

According to the above discussion, the HMM model could be defined as the model  and the observation sequence 
 as follows:(28)(29)

In the HMM model, generally, three questions that are described in the following should be answered (Serpen and Gao, 2014):

-
Initialization: Having  and
, what is the efficient probability of? To calculate this probability, the Forward variable is applied.

-
Decoding: Having the observation sequence 
 and the model, what is the optimal sequence of
, ? To answer this question, the Viterbi algorithm is generally applied.

-
Training the model: How to find the parameters of the model  to optimize? The method to answer this question is Maximum Likelihood (ML), which is the probability of likelihood between observed sequences, . Generally, the Baum-welch algorithm is used to the optimal selection of the model's parameters, recursively. The way to describe this algorithm is the forward-backward algorithm, which needs extra variables to be defined, besides previously defined forward-backward variables.

Lemma2

The complexity of the proposed HMM model for selecting appropriate uplink media in the presented scenario is 
‌.

Rational Proof: To prove Lemma2, the HMM model is divided into its modules, and then the complexity of each one will be discussed. The HMM has three modules, including forward algorithm, Viterbi algorithm, and forward-backward algorithm. As it was shown in (Khreich et al., 2010; Chatterjee and Russell, 2012), the time complexity of each of these three algorithms is 
, in which H = 3 is the number of hidden states, and Q = 20 is the observation sequence 
.

3.3. Proposed algorithms
In this section, the proposed algorithms are discussed. As the main algorithm, the proposed autonomous offloading algorithm is comprised of the MAPE-K module, which will be described in more detail in the following subsections. Firstly, request i arrives at the input of Monitoring, and as the last step, the final results of Executing will be fulfilled. The Monitoring module's primary responsibility is monitoring incoming requests as the input of the computation paradigm and putting them into the input queue (i.e., line 4). Next, the input request will be checked in respect of data type, and if there is any type of mismatch, the handler will make the appropriate alarm (i.e., ‌line 8). Then, since the requests come from different ESG, the possibility of duplicated requests is checked (i.e., line 9). Finally, preprocessed data will be passed to Analyzing Phase (i.e., line 13).

Algorithm 1: Autonomous offloading algorithm
Autonomous-Offloading-Algorithm (
)
1: {
2: for i = 1 to n do
3: {
4: input = );//Monitoring phase
5: for i = 1 to n do//continue of Monitoring phase
6: {
7: Queue input data;
8: Check data type;//in respect of whether the fields of the incoming requests are correctly integer, float, or string
9: Check duplicated requests;
10: PreprocessedData = Send(the preprocessed dataset to Analysing_Algorithm)
11: TrKn(); //transact to the Knowledge
12: }
13: ProcessedData = Analysing_Algorithm (PreprocessedData);//Analyzing Monitoring Phase
14: Planinng_Algorithm (ProcessedData‌);//Planning Analyzing Phase
15: for i = 1 to n do//Executing phase
16: {
17: OutputQueue();
18: if (the request is planned to execute locally) then
19: Send back the request to the LocalLoadbalancer;
20: elseif (the request is planned to execute in the edge colonies) then
21: Send the request to the EdgeLoadbalancer;
22: else
23: Send the request to the CloudLoadbalancer;
24: TrKn ();
25: Visualize();
26: }
27: }
28:}
3.3.1. Analyzing
Preprocessed information resulted from the previous phase is handed over to the Analyzing module. Since incoming requests' rates follow poison distribution, this distribution is applied for predicting future requests to alleviate the system's overload and take full advantage of existing resources. The Analyzing algorithm is depicted in algorithm 4. In the first step (e.g., line 2), the input dataset is split into training data and test data in which the training data will be analyzed more, and the test data will be sent to the next phase. Next, the data are encoded to be better handled by the compiler (e.g., line 5). Since the input pattern might be simple for the compiler, some noise is injected by Sin and Gaussian functions (e.g., line 6). Then, missing value manipulation occurs in line 7 to fill any unfilled fields of the input requests. After, the outlier detection is taken place in line 8. Also, scaling is envisioned for better compilation (e.g., line 9). Finally, the results are saved in Knowledge for possible usage in the future (line 12).

Algorithm 2: Pseudocode for Analyzing
Analysing_Algorithm (ProcessedData)
1:{
2: Split(input dataset);//split the dataset into training data and test data
3: for i = 1 to n do
4: {
5: Encoding(training data);//to better handling, the fields are digitized
6: NoiseInjection(training data);//to make the input pattern more unlinear
7: MissingValueManipulation(training data);//to fill empty fields
8: OutlierManipulation(training data);//to remove outliers
9: Scaling(training data);//to better compiling
10: }
11: Send(training data and test data to Planning_Algorithm);
12: TrKn(training data);//Transaction to the Knowledge
13: Return(Analyzed data)
14:}
3.3.2. Planning
Planning for the best possible execution place for the input requests is the planning module's primary responsibility. As the system's brain, the DNN, the multiple linear regression, and the HMM models have been used in this phase as the decision-making model. Also, the multiple linear regression model has been utilized to enhance the results when needed. As is depicted in Algorithm 3, the algorithm calls these three models to fulfill its responsibility (lines 4, 5, 7, 9, 10 and 11).

Algorithm 3: Pseudocode for Planning
Planning_Algorithm (Analyzed data)
1: {
2: Get(training set);
3: Get(test set);
4: Create(DNN model based on (25) and optimize the problem based on equations (1), (2), (3), (4), (5), (6), (7), (8), (8), (9), (10), (11), (12), (13), (14));//run DNN modeling with training data
5: Create(the multiple linear regression model);
6: Calculate(the probabilities matrices of A and B as (26) and (27));
7: Create(HMM model as defined in (28));
8: Get(the observation sequence of (29));//run HMM modeling with training data
9: Prediction(by DNN);//predict delay, energy with test data
10: Prediction(by HMM);//predict the uplink media with test data
11: Create(the hybrid model);
12: Deviation();//calculate any deviation from SLA
13: Apply(equations (19), (20));
14: Create(hybrid model by equations (7), (14))
15: if (MeetSLA(based on equation (23))) then
16: Executing();//send to the next phase
17: else
18: InputData();//send it as the input request
19: TrKn ();//Transaction to the Knowledge
20: }
3.3.3. Discussion on the time complexity
In this section, the time complexity of the proposed algorithms is discussed. Since the algorithms are implemented in Python, some internal libraries such as Numpy, Pandas, and sklearn are utilized. These libraries‌ generally save the input data in a hash table. The time complexity for accessing the elements of the mentioned table is in the order of O(n), but adding and deleting operations have the complexity of O(1). On the other hand, since the request's arrival time follows a Poisson distribution with the linear time complexity, Monitoring and Analyzing modules have the total time complexity of O(n), and the main for command has the linear time complexity ‌.

Given the number of epochs e, the number of data training n, the number of features p, the number of neurons of layer i 
, and the number of layers m, the time complexity of neural networks is generally in the order of O(
). Also, as has been discussed in subsections 3.2.4, the proposed HMM-based prediction model has a time complexity of 
. Therefore, since the HMM-based prediction model‌ is more cost-effective than the DNN-based prediction model‌, it has been selected as the uplink media selection prediction method.

Besides, since the sklearn library has been exploited to model multiple linear regression, giving n as the number of observations and p as the number of weights, the time complexity of multiple linear regression is in the order of O(n0.72∗p1.3) (Serpen and Gao, 2014; scikit-learn and accessed 12, 2020). Therefore, the overall time complexity of the Planning module is in the order of O(
), which is a cost-demanding prediction model but still for overcoming the applications’ constraint is under consideration.

Finally, since the for command in the Executing module ‌is processed based on the request's arrival time, this module has general linear time complexity. Noteworthy, if the requests' arrival rate increases, since there is still the choice to select GPU and TPU that could be utilized in Python's supported libraries and are faster than CPU, the overall time complexity remains at an acceptable level for such a time-consuming problem.

4. Experimental results
In this section, the evaluation of the computation offloading problem's proposed method will be presented based on the conducted prediction. Then, the benefits and drawbacks of offloading are depicted by comparing these metrics in the case of “Pure Local Execution”, “Pure Edge Execution”, “Pure Cloud Execution”, and “Beneficial Offloading Execution”, as PLE, PEE, PCE, and BOE, respectively. Table 4 shows some essential experimental parameters applied in this study.


Table 4. Experimental parameters‌.

- Parameters	-Values
-Size of requests (Mb)	-Between 2 and 2 power 13
-Number of mobile devices	-N
-Number of colonies	−6
-Number of edge clusters	−9
-CPU rate of mobile devices (in GHz)	−1.2, 1.7, 2.2
-CPU rate of Edge servers (in GHz with the double processor)	−2.2, 2.6, 4.4, 5.2
-CPU rate of Cloud servers (in GHz with multiprocessor)	−5, 10, 20
-Unit transmission energy consumption (in J/Mb)	−0.142
-Unit receiving energy consumption (in J/Mb)	−0.142
-Unit execution energy consumption (J/Giga cycles)	−0.5
-Uplink/Downlink data rate of mobile devices (Mbs)	−5
-Uplink/Downlink data rate of Smart gateway (Mbs) for BluthoothV2, BluthoothV3, GSM	−5, 64, 72
-Intensity of mobile devices	−0.0732, 0.093, 0.12
-Intensity of edge servers	−0.2135, 0.2935, 0.31535, 0.3235
-Intensity of cloud servers	−0.556, 0.616, 0.7324
-Relay charge (Edge, Cloud)	−0.08, 0.13
-Acceptable CPU utilization	-Between 0.35 and 0.85
-SNR	−9
4.1. Simulation environment
In the current study, Python is utilized as the simulation tools in which some essential libraries such as Numpy, sklearn‌, keras, and Pandas are exploited to predict some essential metrics of this study such as the offloading decision-making, the uplink decision-making selection, the request's latency, and the request's energy consumption processes. Also, for visualizing the related offloading metrics, eighty percent of the input dataset is dedicated to training purposes, the remaining 20 percent is utilized to test the model's accuracy.

For visualizing the offloading decision-making problem, the ANN hidden layer and output layer's activation function is set to “ReLu,” and “sigmoid”, respectively, and the weight initializer is set to a uniform distribution, too.

Three “ReLu” activation functions are used for the input layer, hidden layer, and one output layer of the ANN model for visualizing the offloading delay and consumed energy analysis. Also, the utilized loss function is set to Mean Squared Error (MSE), and the optimizer is selected as stochastic gradient descent.

Noteworthy, since the behavior of various applied models are identical for energy and delay analysis, to avoid duplicated explanations, the results of modeling for delay analysis are discussed in subsection 4.3 in more details. Therefore, in subsection 4.4, only a short explanation will be sufficient for energy consumption analysis.

4.2. Offloading decision-making analysis
In this subsection, the decision-making analysis of the offloading problem is discussed. The result of accuracy is depicted in Fig. 8. As it is shown, the offloading accuracy is converged to one after a few iterations, which is promising for bigger and more complex input data. Fig. 9 shows the accuracy, which is 100%, and the loss of this initializer, converging to zero in an acceptable time. The early convergence of these two models is because of tuning the input data appropriately through different preprocessing methods presented in Monitoring and Analyzing modules and defining suitably the related parameters of the DNN model.

Fig. 8
Download : Download high-res image (157KB)
Download : Download full-size image
Fig. 8. Accuracy of offloading decision-making. -

Fig. 9
Download : Download high-res image (155KB)
Download : Download full-size image
Fig. 9. Loss of offloading decision-making.

4.3. Delay analysis
Fig. 13 depicts comparing the execution delay in different environments. As shown, the incurred delay depends on the type of the user's requested resource and the size of the request to be executed. Still, it is not necessarily the minimum possible delay among existing environments. To justify this, consider a scenario when a request with the appropriate size of local execution is received, but the required resource's type is ‘communication’. Based on the strategy, this request is sent to the cloud for further processing.

Fig. 13
Download : Download high-res image (204KB)
Download : Download full-size image
Fig. 13. Comparing the delay of execution in different environments.

- In addition, the simulation has been carried out by the multiple linear regression model. The results depict that, for some cases, the regression model outperforms the DNN model, and in some other cases, the outputs of simulations are identical. Therefore, a hybrid form is also considered to be the best-optimized simulation results. The simulation results comparing different models, including test data, DNN model, regression model, and the hybrid model is depicted in Fig. 14. Since the depicted results are compressed, for more clarity and better comparison, the data have been divided into three parts; between 0 and 200 μs, between 200 and 700 μs, and between 700 and 1700 μs, as they are illustrated in Fig. 15, Fig. 16, and Fig. 17, respectively.

Fig. 14
Download : Download high-res image (201KB)
Download : Download full-size image
Fig. 14. Comparing different delay's models.

Fig. 15
Download : Download high-res image (237KB)
Download : Download full-size image
Fig. 15. Comparing different models for the delays between 0 and 200 μs.

Fig. 16
Download : Download high-res image (251KB)
Download : Download full-size image
Fig. 16. Comparing different models for the delays between 200 and 700 μs.

Fig. 17
Download : Download high-res image (266KB)
Download : Download full-size image
Fig. 17. Comparing different models for the delays between 700-1700 μs.

- As is depicted in Fig. 15, various models performed differently in the predefined interval. Regression models consider the association between the mean values of dependent and independent variables. Also, they are incapable of modeling many fluctuations in the input data's trend. Because of the nature of regression modeling, for the values around zero, the results of modeling could be negative, with many fluctuations around the calculated line range that are not acceptable for the time-related metrics and time-critical applications. Besides, the regression model is incapable of presenting appropriate forecasting in sharp fluctuations in incoming requests. The mentioned challenges belong to the dynamic and heterogeneous nature of offloading environments. Consequently, knowing the extra-incurred execution costs by the DNN model, for the delay values below 200 μs, this model outperforms the multiple linear regression model, which is considered in the proposed hybrid model.

- For the delay between 200 and 700 μs, the comparison amongst different models is depicted in Fig. 16. As is depicted, the DNN and the regression models almost perform the same. After applying a trade-off between the execution costs and the delay, it is more appropriate to select the linear regression model in the mentioned interval, considered by the proposed hybrid model.

- For the delay between 700 and 1700 μs, the comparison amongst different models is depicted in Fig. 17. As depicted, for the values on the bottom of the chart, the regression model almost outperforms the DNN model. In contrast, for the top of the chart's values, the DNN model outperforms the multiple linear regression model considered in the proposed hybrid model.

- Fig. 18 depicts the total numbers of SLA violations in the multiple linear regression, the DNN, and the hybrid models, respectively, by conducting different simulations in the Python environment. Since the total numbers of test data are 4000, the pure multiple linear regression has the predicted accuracy of 56%, which is not selected as an appropriate model alone. On the other hand, the pure DNN model has the predicted accuracy of 88%, which is more appropriate than the multiple linear regression but needs more considerations, specifically for life-critical requests. Applying the hybrid model will improve the predicted accuracy of up to 94%, making it a suitable model for predicting the system's future behavior.

Fig. 18
Download : Download high-res image (529KB)
Download : Download full-size image
Fig. 18. Total numbers of delay's SLA violations in a. Regression, b. DNN, and c. Hybrid models.

4.4. Energy consumption analysis
In this subsection, the energy consumption analysis of the offloading problem is discussed. Fig. 19 depicts the results of a simulation comparing predicted and tested energy of computation for fifthly selected requests based on the predicted decision to execute the request locally or remotely. The accuracy of the energy model is depicted in Fig. 20 and Fig. 21. In the energy model's case, the logic of the delay model is provided for feature scaling. Fig. 22 depicts comparing the energy consumption of execution in different environments. As it is shown, the incurred consumed energy highly depends on the type of the user's requested resource and the size of the request to be executed. Still, it is not necessarily the minimum possible consumed energy among existing environments. As it is shown, the fluctuations highly depend on the type of demanded resource, but the minimum possible energy consumption is always selected. The intuitive behind the early convergence of these two models is similar to what has been presented in the previous subsections.

Fig. 19
Download : Download high-res image (220KB)
Download : Download full-size image
Fig. 19. Comparison between actual and predicted energy.

Fig. 20
Download : Download high-res image (181KB)
Download : Download full-size image
Fig. 20. Accuracy of the energy model without feature scaling.

Fig. 21
Download : Download high-res image (153KB)
Download : Download full-size image
Fig. 21. Accuracy of the energy model with feature scaling.

Fig. 22
Download : Download high-res image (197KB)
Download : Download full-size image
Fig. 22. Comparing energy consumption of execution in different environments.

- Similar to the delay analysis, the simulation has also been carried out by multiple linear regression model for the energy analysis. The results depict that, for some cases, the regression model outperforms the DNN model, and in some other cases, the outputs of simulations are identical. Therefore, a hybrid form is also considered to be the best-optimized simulation results. The simulation results comparing different models, including test data, DNN model, regression model, and the hybrid model is depicted in Fig. 23. Since the depicted results are compressed, for more clarity and better comparison, the data have been divided into three parts; between 0 and 200 J, between 200 and 700 J, and between 700 and 2300 J, as they are illustrated in Fig. 24, Fig. 25, and Fig. 26, respectively.

Fig. 23
Download : Download high-res image (196KB)
Download : Download full-size image
Fig. 23. Comparing different energy's models.

Fig. 24
Download : Download high-res image (265KB)
Download : Download full-size image
Fig. 24. Comparing different models for the consumed energy between 0 and 200 J..

Fig. 25
Download : Download high-res image (300KB)
Download : Download full-size image
Fig. 25. Comparing different models for the consumed energy between 200 and 700 J..

Fig. 26
Download : Download high-res image (285KB)
Download : Download full-size image
Fig. 26. Comparing different models for the consumed energy between 700 and 2300 J..

- As is depicted in Fig. 24, various models performed differently in the predefined interval. Similar to the delay analysis, the regression model is incapable of presenting appropriate forecasting outcomes because of simulated negative values and frequent fluctuations. Consequently, knowing the extra-incurred execution costs by the DNN model, for the delay values below 200 J, this model outperforms the multiple linear regression model, which is considered in the proposed hybrid model. -

- For the energy between 200 and 700 J, the comparison amongst different models is depicted in Fig. 25. As is depicted, the DNN and the regression models almost perform the same. After applying a trade-off between the execution costs and the delay, it is more appropriate to select the linear regression model in the mentioned interval, considered by the proposed hybrid model.

- For the consumed energy between 700 and 2300 J, the comparison amongst different models is depicted in Fig. 26. As is depicted, since the fluctuations of input data are high, although the DNN outperforms the regression models but not satisfactory. The hybrid model performs better in the predefined interval.

- Fig. 27 depicts the total numbers of energy's SLA violations in the multiple linear regression, the DNN, and the hybrid models, respectively, by conducting different simulations in the Python environment. Since the total numbers of test data are 4000, the pure multiple linear regression has the predicted accuracy of 57.5%, which is not selected as an appropriate model alone. On the other hand, the pure DNN model has the predicted accuracy of 85%, which is more appropriate than the multiple linear regression but needs more considerations, specifically for life-critical requests. Applying the hybrid model will improve the predicted accuracy of up to 89.9%, making it a suitable model for predicting the system's future behavior. -

Fig. 27
Download : Download high-res image (286KB)
Download : Download full-size image
Fig. 27. Total numbers of energy's SLA violations in regression, DNN, and hybrid models.

4.5. Uplink selection decision-making analysis
In this subsection, the uplink selection analysis of the offloading problem is discussed. The process of selecting uplink has been run by HMM ‌two times for all the training datasets, but for showing the results clearly, only the diagram has been plotted only for 50 observation sequences. Hence, the transmissions and emissions matrices are calculated based on the training dataset fed to the Forward, Viterbi, and Forward-Backward algorithms. Like the first run, there are total numbers of five mistakes in the prediction of uplink selection (e.g., the red vertical lines), as is depicted in the bar graph of Fig. 28. In the second run, the accuracy is 100%, as it is depicted in the bar graph of Fig. 29 and the linear graph of Fig. 30. In the y-axis, Bluetooth version 2, Bluetooth version 3, and GSM have been encoded with 0, 1, and 2, respectively.

Fig. 28
Download : Download high-res image (256KB)
Download : Download full-size image
Fig. 28. Uplink selection accuracy (first run).

Fig. 29
Download : Download high-res image (224KB)
Download : Download full-size image
Fig. 29. Uplink selection accuracy (second run). -

Fig. 30
Download : Download high-res image (286KB)
Download : Download full-size image
Fig. 30. Uplink selection accuracy.

4.6. DNN parameters’ analysis
To achieve the most appropriate prediction results in simulating the DNN model, some critical parameters must be defined and configured in the Python environment precisely‌. These critical parameters include optimization function, loss function, and learning rate.

For the DNN model, there are some predefined optimization functions‌, including Adadelta, RMSprop, Adam, Adagrad, Adamax, SGD, and Nadam. Besides, there are some predefined loss functions‌, including Mean Absolute Percentage Error, ‌‌Mean absolute error, Mean squared error, Mean squared logarithmic error, cosine similarity, Huber, and log cosh (keras and accessed 13 Nov. 2, 2020)‌. Table 5 depicts a side by side comparison amongst these functions‌ ‌resulted from various simulations. As is depicted, the most efficient optimization and loss functions are Adam and Mean squared error, respectively. In addition, Adadelta and Mean Absolute Percentage Error have been marked as the worst case for the two mentioned functions, respectively.


Table 5. DNN parameters'analysis.

1	Optimization function	Adadelta	RMSprop	Adam	Adagrad	Adamax	SGD	Nadam
Number of SLA violations	1489	1317	473	1998	1295	Uniform line (Not accepted)	1198
2	Loss function (Optimization function is Adam)	Mean Absolute Percentage Error	Mean absolute error	Mean squared error	Mean squared logarithmic error	cosine similarity	Huber	log cosh
Number of SLA violations	2793	1605	473	Uniform line (Not accepted)	Out of range prediction	1695	1282
As another important factor, which affects the DNN accuracy seriously for the proposed offloading approach, is the learning rate. Based on the simulations conducted on various learning rates, the most appropriate value for this parameter is 0.02, which has a total number of 473 violations, as is depicted in Fig. 31. The worst value for the learning rate is 0.08, which reduces the accuracy of offloading below 50%.

Fig. 31
Download : Download high-res image (191KB)
Download : Download full-size image
Fig. 31. Total number of SLA violations in DNN modeling while changing the learning rate.

5. Discussion
In this subsection, the simulation's results will be briefly discussed. Then, the open issues as the complementary of the current study will be presented.

5.1. Summary of simulations
As discussed in this study, since the offloading problem is generally an NP-Complete problem with its dynamic and stochastic environment, the best solution for this problem is exploiting heuristic and meta-heuristic approaches. Generally, these kinds of approaches attempt to find optimum solutions with reasonable and practical computational costs if their parameters are defined and initialized appropriately. In respect of the applied DNN in the current study, with an appropriate definition of such parameters, DNN could converge accurately with near-optimal results in the case of offloading decision-making prediction, delay prediction, and energy consumption prediction in a couple of iterations according to the results of simulations that were depicted in the corresponding figures. Also, to improve the results of simulations, a hybrid method in combining the DNN and multiple regression models has been proposed. Simulations showed that the proposed model could enhance the accuracy of predicting up to 94%.

Based on the discussion of the HMM model and its related initialization, since the available numbers of uplinks are generally limited, the complexity of calculated probabilities of historical data is linear for such a problem. It can be claimed that this complexity is near-optimal for bigger datasets and more extensive criteria of uplink selections. The results depicted in the corresponding figures show that HMM fits appropriately in our defined problem with an accuracy of 100%.

5.2. Open issues
In this subsection, some critical future research directions and open perspectives of offloading mechanisms are discussed. Generally, open issues of offloading criteria could be categorized into eight topics, including self-management, fault tolerance, heterogeneity, mobility, scalability, scheduling, partitioning, and communication uplinks.

Fault tolerance is a general concept that can hold security features in some respects. Since fault tolerance of a system is the ability to continue a specific service despite faults in the mentioned system, security threats play a critical role in endangering the system's tolerance against that security fault. Since this challenge is covered weakly in the literature, it is presented as an open issue in this subsection.

As it has been the critical attention of the proposed conceptual model in the current study, self-management can handle different system features without human interventions. Despite its significance, there is no related study in the offloading criterion covering the concept comprehensively.

Noteworthy, other open issues of the offloading criterion are discussed comprehensively in (Shakarami et al., 2020a, 2020b, 2020c) that are referenced for more information.

5.3. Future works
In real scenarios, since mobile users have mobility characteristics and can freely move from one place to another, it is possible to change their access points. Consequently, the effects and side effects of handover between different MEC systems that should be managed continuously become of high importance, which is neglected in the current study. This feature should be considered carefully to deliver stable services‌ to the users' requests that will be considered in the future version of the current study. As the second future work, the authors think that a hierarchical structure in the form of master/slave control methodology will help reduce the energy consumption incurred by executing the requests in the MEC system, knowing the management complexity of such structure. This feature is also under the consideration of the authors as future works.

6. Conclusion
Deep learning tries to simulate the human brain with its complex structure, exploiting different multi-layers of neural networks that are the appropriate solution for the current study scenarios' defined problem. Generally, exploring the computation environment to find the most efficient place to execute mobile users' requests is a challenging criterion to achieve. In addition, different researches have been proposed to cope with the management problems of the offloading criterion. To address some challenges related to time and resource-demanding applications, in this paper, an autonomous computation offloading framework based on MAPE-K loop methodology‌ has been proposed. Also, to reduce the dimensionality of the offloading decision-making problem, we applied the hybrid form of Deep Neural Networks (DNN) and multiple regression model as the planning module for offloading, delay, and energy consumption predictions and also Hidden Markov Model (HMM) as the planning module for uplink selection predictions in the mentioned MAPE-K loop methodology. Simulation results show that the proposed model can fit the problem for offloading decision-making, latency prediction, energy consumption prediction, and uplink selection prediction with maximum or near-maximum performance.