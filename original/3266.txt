In recent years, with the rapid growth in the demand for online streaming services, video streaming platforms are becoming more and more popular, and users' demand for low latency and high-quality services is increasing. Therefore, in order to be able to allocate caching resources reasonably to serve as many user requests as possible, and reduce latency and energy consumption, the edge cooperative caching method based on delay and energy consumption balance in SDN based mobile edge computing is proposed. In the proposed caching method, firstly, the multilayer perceptron neural network is used to predict the video content requested by the mobile user. Secondly, an objective function to minimize delay and energy consumption is established, and an edge cache optimization model is constructed. Finally, the branch-and-bound algorithm is used to obtain the optimal edge cache strategy. Meanwhile, to provide users with seamless service migration to ensure service continuity and high-quality services, the dynamic service migration method based on deep Q learning is proposed. In the proposed service migration method, firstly, the service migration problem is expressed as a Markov decision process. Secondly, the service migration process is analyzed and a service migration reward function is constructed. Finally, deep Q learning is used to obtain the optimal service migration strategy. In the experiment, the proposed edge caching algorithm can effectively improve the cache hit rate, reduce the backhaul traffic load, and control the average access delay and energy cost. Moreover, the proposed service migration algorithm can effectively reduce the number of service migrations and transmission cost, improve the success rate of service migration, and reduce the average traffic consumed by migration.

Keywords
Mobile edge computing
SDN
Edge caching
Service migration
Deep Q learning


1. Introduction
With the popularity of various smart mobile devices, users' demands for ultra-low latency and high-quality services are increasing. Because the computing power and storage resources of mobile devices are limited, the contradiction between computing-intensive applications and resource-constrained mobile devices has become increasingly prominent. One possible solution to overcome these limitations is to use mobile edge computing (MEC), which can minimize network congestion and improve resource optimization (Hu et al., 2015-). However, there are still many major challenges to increase the computing power of edge devices through MEC, such as mobility, heterogeneity, and privacy. To hide all the internal complexity of MEC to users, a Software-Defined Network (SDN) (Kreutz et al., 2015) can hide the complexity of the heterogeneous environment to the end-user and has network programming functions is considered. Therefore, the mobile edge computing system environment based on SDN is considered in this paper.

The introduction of SDN in the MEC can ensure efficient network operation and service delivery (Baktir et al., 2017). Meanwhile, SDN can overcome the deficiencies of existing MEC systems in terms of resource coordination and network orchestration, and reduce the complexity of the mobile edge computing architecture (Baktir et al., 2017). With the rapid growth of the demand for online streaming services, users' demand for low-latency and high-quality services is increasing (Li et al., 2021). The caching capacity of the edge server has the potential to significantly improve network resource utilization and energy efficiency. However, in the case of limited cache space, highly diversified content cannot be completely stored on the edge server. Therefore, how to allocate cache resources to serve as many user requests as possible, while further reducing delivery delay and bandwidth usage, and improving Quality of Experience (QoE), is a problem that needs to be solved (Li et al., 2020a, 2020b, 2021). Meanwhile, the limited coverage of edge servers, the mobility of users, and the high degree of uncertainty in request patterns pose new challenges to service deployment. Moreover, edge servers are connected to many different access points or base stations, whether to migrate the ongoing edge service and where to move the service are issues that need to be considered when any user moves outside the service area of the relevant edge server.

To reasonably allocate cache resources to serve as many user requests as possible, and reduce latency and energy consumption, the edge cooperative caching method based on latency and energy balance in SDN based mobile edge computing is proposed. In the proposed method, firstly, based on the static, dynamic, and user social characteristics of the video, the multi-layer perceptron neural network is used to predict the video content requested by the mobile user. Secondly, an objective function to minimize delay and energy consumption is established, and an edge cache optimization model is constructed. Finally, the branch-and-bound algorithm is used to solve the optimal edge caching strategy. In order to effectively migrate ongoing edge services to ensure service continuity, the dynamic service migration method based on deep Q learning is proposed. In the proposed method, firstly, the service migration problem is expressed as a Markov decision process. Secondly, the service migration reward function is constructed. Finally, deep Q learning is used to further obtain the optimal service migration strategy. The main contributions are summarized as follows.

(1)
In order to allocate cache resources more reasonably to serve more user requests, and reduce transmission delay and transmission energy consumption, an edge cooperative caching method based on delay and energy balance in the MEC environment based on SDN is proposed. In the proposed method, the multilayer perceptron is used to predict the video content requested by end-users. By considering the delay overhead and energy overhead of the video, an objective function to minimize delay and energy consumption is established.

(2)
In order to provide users with seamless service migration to ensure service continuity, a dynamic service migration method based on deep Q learning is proposed. In the proposed method, the service migration problem is expressed as Markov Decision Process (MDP), and the service migration reward function is constructed. Deep Q-learning is used to obtain the optimal service migration strategy.

(3)
The performances of the proposed algorithms are evaluated by experiments. The results indicate that the proposed caching algorithm can effectively improve the cache hit rate, reduce the backhaul traffic load, and control the average access delay and energy cost. The proposed service migration algorithm can effectively reduce the number of service migrations and transmission cost, improve the success rate of service migration, and reduce the average traffic consumed by migration.

The rest of this paper is structured as follows. Section 2 reviews related works and Section 3 presents the edge cooperative caching method based on delay and energy consumption balance. Section 4 presents the dynamic service migration method based on deep Q learning. Section 5 evaluates the implementation and validates the advantages of our approaches. Finally, the conclusion and future work is given in Section 6.

2. Related work
2.1. The edge cache
Edge caching is considered to be an extremely effective technique for balancing backhaul link load, reducing network latency, and improving user experience. How to achieve the optimal balance between user response delay and service provider cost is the main problem of research.

Considering the limitation of storage and bandwidth, a better caching scheme is needed to predict the content with high request frequency and make it cached before peak hours. As shown in Table 1, Emna et al. (2020) designed the Proactive caching Policy (PcP) and Caching replacement Policy (CrP) to cache only the video blocks with the highest probability. The cooperative caching problem is expressed as an NP Integer Linear Programming (ILP) problem. In the software-defined wireless network environment, Liang et al. (2017) proposed a Quality of Experience (QoE)-aware wireless edge caching scheme. This scheme can reduce latency and improve cache utilization. Wang et al. (2017) expressed the edge caching problem as a Markov decision process to minimize the transmission cost.


Table 1. Comparison of the related works about edge caching schemes.

Reference	Objective	Solution
Emna et al. (2020)	To maximize cache efficiency	Designed Proactive caching Policy (PcP) and Caching replacement Policy (CrP)
Liang et al. (2017)	To reduce latency and improve cache utilization	Proposed a wireless edge buffering scheme with Quality of Experience (QoE) perception
Wang et al. (2017)	To reduce the cost of data transmission	The edge cache problem was transformed into a Markov Decision Process (MDP)
Thar et al. (2019)	To intelligently manage the resource leasing and caching process	Proposed a prediction scheme based on deep learning
Pang et al. (2018)	To predict the popularity of content	Proposed a deep learning-based solution DeepCache
Liu et al. (2019)	To understand the request pattern in each base station to make intelligent caching decisions	Proposed a method for predicting content popularity based on deep learning
Qiao et al. (2020)	To optimize vehicle edge computing and content placement and content delivery in the network	Proposed a cooperative edge caching scheme
Our work	To ensure the cache hit rate, reduce the average access latency and energy cost, and reduce the backhaul traffic load	Proposed an edge cooperative caching method based on delay and energy consumption balance in SDN based Mobile Edge Computing
Deep learning is regarded as an ideal method for many complex and dynamic network problems and is also widely used in edge caching problems. Thar et al. (2019) proposed a prediction scheme based on deep learning. Besides, a model search scheme based on reinforcement learning is proposed to find the most suitable deep learning model. Pang et al. (2018) designed a learning framework that is helpful for intelligent caching. Meanwhile, a solution based on deep learning was proposed to understand the request mode in each base station. Zongkai Liu et al. (2019) proposed a mobile-aware pre-caching strategy based on deep learning for small cell networks. The base stations that the user may pass in the future are predicted, and a part of the file that the user is downloading is pre-cached on these base stations. Qiao et al. (2020) proposed a collaborative edge caching scheme. This solution can jointly optimize vehicle edge computing and content placement in the network. Besides, they proposed a natural heuristic method based on a Deep Deterministic Policy Gradient (DDPG) framework to obtain a suboptimal solution with lower computational complexity.

The above works have studied the problem of edge caching. Although most work has considered the user access delay and content supply cost, the factors they consider are not comprehensive enough. Therefore, an edge cooperative caching method based on delay and energy consumption balance in SDN based mobile edge computing is proposed. The proposed edge caching method considers many factors to make the edge caching more effective. Compared with previous research works, the advantages of the edge caching method proposed in this paper are shown as follows.

(1)
The proposed edge caching method comprehensively considers the user access delay, energy cost, and the high degree of uncertainty of user behavior and user request patterns in order to allocate caching resources more reasonably to serve as many user requests as possible. In the proposed method, the multi-layer perceptron neural network is used to predict the video content requested by mobile users based on the static, dynamic, and user social characteristics of the video, so that the set of videos read by each user can be quickly and accurately obtained.

(2)
In the proposed method, the objective function of minimizing delay and energy consumption is established to achieve the balance of delay and energy consumption and make full use of the resources of the edge server. The proposed edge caching method aims to obtain the optimal caching strategy under the premise of ensuring the cache hit rate. Meanwhile, the proposed method effectively reduces the average access delay, energy cost, and backhaul traffic load.

2.2. The service migration
In recent years, many scholars at home and abroad have studied service migration. Current works related to service migration can be roughly divided into two categories: the “Follow Me” cloud model and service migration based on the Markov decision process.

The “Follow me cloud” model is designed to seamlessly migrate ongoing services between the data center and another optimal data center. Follow me cloud (FMC) allows services to move across the federated data center (DC). When users move, the ongoing services hosted on the current edge server will be migrated to the best edge server. Taleb et al. (2019) proposed the FMC model. An algorithm based on the Markov decision process is adopted. Meanwhile, based on software-defined network technology, two alternative solutions to ensure service continuity and non-disruptive operation are proposed. Aissioui et al. (2018) introduced the concept of Follow Me Edge Cloud (FMeC). The FMeC framework ensures low-latency access by considering cloud services at the edge, making it possible to migrate services between edge clouds and ensure that users are always connected to the best edge cloud. In the FMC environment, Nadembega et al. (Nademnega et al., 2016) proposed a Mobility-based Service Migration Prediction (MSMP) method to solve the balance between overhead and Quality of Experience (QoE).

As shown in Table 2, the service migration strategy based on Markov Decision Process (MDP) includes a one-dimensional MDP and a two-dimensional MDP model. Wang et al. (2019) formulated the service migration problem as an MDP. A general cost model is described, and a mathematical framework is provided to design the best service migration strategy. Lee et al. (2018) proposed a QoS-aware service migration solution in the edge-centric cloud network. The service migration problem is modeled as an MDP. This solution can reduce migration costs and network traffic, while the required QoS is guaranteed. Ksentini et al. (2014) used the MDP to model the service migration process to solve the balance between cost and user-perceived quality. When the relevant user equipment is at a certain distance from the source data center, whether to migrate the service is considered and a service migration strategy is formulated.


Table 2. Summary of various service migration schemes based on MDP.

Reference	Consideration	Design objective	Mathematical Methods
Wang et al. (2019)	The distance between the user and the server location.	To overcome the complexity of obtaining the best service migration strategy	Transformed the service migration problem into a Markov Decision Process (MDP)
Lee et al. (2018)	Network cost, QoS, and resource utilization in servers	To choose the best target server	Transformed the service migration problem into a Markov Decision Process (MDP)
Ksentini et al. (2014)	Distance between user equipment and source data center	To achieve the balance between cost and user-perceived quality	Transformed the service migration problem into a Markov Decision Process (MDP)
Our work	Service migration cost, server load capacity, CPU utilization, memory capacity, network bandwidth, disk I/O rate, etc.	To ensure the success rate of service migration, ensure service continuity, and reduce service migration cost	Transformed the service migration problem into a Markov Decision Process (MDP)
The above work has done some research on service migration in the edge computing environment. Although some studies ensure the continuity of services to a certain extent and consider the cost of migration, the considerations of these studies are not comprehensive enough. The MDP model is a conventional model used to describe the problem of service migration. However, when using the MDP model in different studies, different factors and different solving processes are considered to solve related problems. In this paper, we also use MDP to describe the service migration problem and the goal is to design a control strategy that maximizes the long-term expected reward from the initial state. In SDN based Mobile Edge Computing environment, a dynamic service migration method based on deep Q learning is proposed, which considers many factors to achieve seamless service migration. Compared with previous research works, the innovations of the service migration method proposed in this paper are shown as follows.

(1)
The proposed service migration method comprehensively considers the server load capacity, transmission cost, migration cost and CPU utilization, memory capacity, network bandwidth, etc., to analyze the service migration process and construct a service migration reward function, thereby maximizing long-term expected rewards and ensuring service continuity.

(2)
Most studies do not consider the long-term impact of current decisions on resource allocation in the MEC system. In the highly time-varying MEC system, most optimization algorithms only obtain the optimal or approximately optimal results within a certain time slice. In Deep Q-learning, the agent perceives the environment and selects an action in each state, and the environment feedbacks a value as a reward after each action. Since the deep Q-learning algorithm considers the long-term impact of current decisions on resource allocation and the goal is to maximize the cumulative reward, deep Q-learning is used to solve the dynamic service migration problem in this paper.

3. The cooperative edge cache method
3.1. The system framework of MEC environment based on SDN
Fig. 1 shows the system framework of the MEC environment based on SDN. The system framework is mainly divided into infrastructure layer, edge computing layer, and cloud computing layer, including user terminal nodes, base stations, edge computing servers, SDN controllers, and cloud data centers. The system architecture of the MEC environment based on SDN can be divided into data plane, control/management plane, and application plane according to the function level. The data plane is the cornerstone of the framework, abstracting the underlying network resources as SDN switches. In the control/management plane, the global controller is mainly responsible for managing the local SDN controller. The SDN controller updates data plane matching and processing rules by exchanging operating status The application plane consists of many application instances and an application represents a client entity.

Fig. 1
Download : Download high-res image (828KB)
Download : Download full-size image
Fig. 1. Framework of the mobile edge computing system based on SDN.

The seven steps in the figure illustrate the relationship between the two research points in this paper. Firstly, to reduce latency and energy consumption, an edge-based collaborative caching method based on delay and energy balance in SDN based mobile edge computing is proposed. (1) The multi-layer perceptron is used to predict the video content requested by the user. (2) An objective function to minimize delay and energy consumption is established. (3) The SDN controller obtains network status, video content information, etc. (4) The optimal caching strategy is obtained, and an effective edge caching scheme is designed. (5) Through edge caching technology, the requested content is stored on the edge server. However, in mobile edge computing, user mobility is also a factor that cannot be ignored. As users move, the original service connection scheme may no longer be optimal, and service quality may drop sharply. Therefore, a dynamic service migration method based on deep Q learning in SDN based mobile edge computing is proposed. (6) The service migration problem is expressed as a Markov decision process, and the service migration reward function is constructed. (7) Deep Q learning is used to solve the optimal service migration strategy for this problem.

3.2. The method for the edge cooperative caching based on delay and energy consumption balance
In this section, the problem of limited access to the edge server cache and limited mobile device resources leading to access delays and excessive energy consumption are studied. The edge caching method based on the delay and energy balance in SDN based mobile edge computing is proposed. The method is divided into three steps. 1) Firstly, the multilayer perceptron neural network is used to predict the video content requested by the mobile user. 2) Secondly, an objective function to minimize delay and energy consumption is established, and an edge cache optimization model is constructed. 3) Finally, the branch-and-bound algorithm is used to obtain the optimal edge caching strategy. The model of edge caching method based on delay and energy consumption balance is shown in Fig. 2.

Fig. 2
Download : Download high-res image (996KB)
Download : Download full-size image
Fig. 2. Architecture diagram of edge cache method based on delay and energy consumption balance.

3.2.1. The user content reading behavior prediction method based on multi-layer perceptron
The Multi-Layer Perceptron (Zhang et al., 2018) neural network can be used to predict user content reading behavior. The input and output of the MLP can be described as follows.

•
Input: 
 represents the input vector of the mobile user 
, where each user includes  features. The input vector includes static features, dynamic features, and social features. The static features include the title, category, and description information of the videos. The dynamic features include video viewing time, playback times, and the number of video requests. The social features include user sharing, ratings, and comments on videos.

•
Output: For each mobile user 
, the input vector is 
 and the output vector is the video content 
 requested by the user 
. 
 represents the collection of video content requested by all users. In the output layer, the video content requested by the mobile terminal user 
 can be predicted to be 
.

In this paper,  is used to represent the number of hidden layers, 
 is the input vector, 
 is the deviation vector, 
 is the weight matrix of each hidden layer, and 
 is the output result. In addition to the output layer, the Rectified Linear Unit (ReLU) (Nair and Hinton, 2010) is used as the activation function, and the backpropagation algorithm (Rumelhart et al., 1986) is used to update the connection weight value.

3.2.2. The optimization model of edge collaborative cache
(1)
The transmission delay model of content caching

Mobile users wirelessly connect to edge servers and connect all edge servers to cloud data centers through backhaul links. When the user sends a content request to an edge server, if the content is stored locally on the edge server, the content is immediately sent to the user. Otherwise, the edge server will download content from the video provider in the cloud data center and send it to the requesting user. 
 indicates the  edge server and 
 denotes the limited storage capacity of the edge server 
, where there is 
 and  is the number of edge servers. 
 indicates the  end-user, where there is 
. The collection of user-requested video content can be represented as 
, which is the output result of the user content reading behavior prediction method based on the multilayer perceptron in Section 3.2.1.

It is assumed that a user 
 only reads one video content 
 in a time slice. The transmission delay 
 for the MEC server 
 to obtain video content from the video provider  can be expressed by formula (1).(1)
where 
indicates whether the video content 
exists on the MEC server 
. Especially, if the video content 
is stored on the MEC server 
, then 
; else 
.  is the average size of each video content. 
denotes the transmission rate from the video provider to the MEC server 
. The transmission rate (Ndikumana and Hong, 2019) downloading the content from the MEC server 
to the end-user 
can be expressed by formula (2).(2)
 
where the end-user 
connected to the edge server 
can be allocated a certain percentage of bandwidth 
. 
is the transmission power from the end-user 
to the edge server 
. 
 denotes the channel gain between the end-user 
and the edge server 
. 
 is the Gaussian noise power from the end-user 
to the edge server 
. The access delay 
downloading content from the MEC server 
to the end-user 
can be shown in formula (3).(3)
where 
 indicates whether the user 
 reads the content 
 from the edge server 
. Especially, if the user 
 reads content 
 from the edge server 
, then 
; else 
.  is the average size of each video content. Therefore, the total delay 
 can be expressed as the sum of transmission delay and access delay, shown in equation (4).(4)

(2) The energy consumption model of content caching

Downloading content from the video provider  in a cloud data center and caching it to an edge server will consume some transmission energy. The transmission energy consumption (Yan et al., 2019a) for the MEC server obtaining the video content from the video provider can be expressed as follows.(5)
where 
and 
represent the number of routers in the core network and the edge network respectively. 
, 
 , 
and 
represent the energy consumed for each bit of data transmitted on the core router, edge router, broadband network gateway, and Ethernet switch. 
indicates the total data size of the content that needs to be transferred.

The transmission energy consumption 
of downloading content from the MEC server 
to the end-user 
can be expressed as formula (6).(6)
where 
is the transmission power from the end-user 
to the MEC server 
. 
denotes the transmission delay downloading the content from the MEC server 
to the end-user 
.

The storage energy consumption of the MEC server depends to a large extent on how much content is cached. Assume that the energy consumption of the MEC server 
to cache each bit of data is 
. Then, the energy consumption of the MEC server 
caching content within a certain period can be expressed as shown in formula (7) (Yan et al., 2019b; Choi et al., 2012; Jia et al., 2017).(7)
where 
indicates whether the video content 
exists on the MEC server 
. is the average size of each video content. Therefore, the total energy consumption 
can be expressed as the sum of transmission energy consumption 
, 
and storage energy consumption 
.(8)

(3)
The edge cache optimization model

In this paper, the goal of the edge cooperative caching method based on the balance of delay and energy consumption is to provide a seamless video streaming service to mobile users by effectively caching content at the edge server. By designing an effective edge caching scheme to select the appropriate edge server to cache video content, the average delay, and energy consumption of user access to the content can be minimized. This problem can be expressed mathematically as formula (9).(9)
(10a)
 
 
(10b)
(10c)
(10d)
(10e)
(10f)(10g)where the constraint ensures that only users who read content from the edge server are allocated bandwidth, and the end-users connected to the edge server are allocated less than the total bandwidth. The constraint ensures that the content read by the user from the edge server has been cached on the edge server. The constraint ensures that the user can only read content from one edge server. The constraint ensures that the same content can only be cached on one edge server. The constraint ensures that the cache resource allocation must be less than or equal to the available cache resources in the edge server. The  constraint specifies the value range of the variable. In ,  and  are weight parameters that are used to balance the two goals of minimum delay and minimum energy consumption.

The objective function of the edge cache method based on the balance of delay and energy consumption in this paper is a mixed binary integer programming problem. The mixed binary integer programming problem is usually an NP-complete problem, and the optimal solution cannot be obtained in linear computing time (Saputra et al., 2019). The heuristic algorithm and branch-and-bound algorithm (Chiang and Wang, 2015) are usually used to solve the problem. However, as for the heuristic algorithms, there is high time complexity and low efficiency. Besides, it can usually only find a feasible solution to the problem, and the deviation of the feasible solution from the optimal solution cannot generally be predicted, and it is easy to fall into the local optimum. The branch-and-bound algorithm can find the global optimal solution with a fast average speed. As for the branch-and-bound algorithms, there is no provable time complexity (Quesada and Grossmann, 1992), and the algorithm time complexity required in each leaf is very low. The edge cache problem in this paper is very suitable for the branch-and-bound algorithm to solve. This is because, on each leaf of the branch-and-bound method, the resulting problem is a convex optimization problem which can be used by the Lagrange multiplier method to find the closed-formed solution with the low time complexity . Therefore, the branch-and-bound algorithm is chosen to solve the optimal solution of the edge cache problem in this paper.

3.3. The edge cooperative cache algorithm
In this section, the core pseudocode of the edge cache algorithm based on the balance of delay and energy consumption is introduced. The algorithm mainly includes two parts: the user content reading behavior prediction algorithm and a collaborative edge caching algorithm.

(1)
The user content reading behavior prediction algorithm based on multi-layer perceptron

The core pseudocode of the user content reading behavior prediction algorithm based on a multi-layer perceptron is shown in Algorithm 1. Firstly, the weight is initialized, and the BP algorithm is used to obtain the optimal weight 
, i.e., to obtain the optimal neural network 
. (Algorithm 1 lines 1–2). Secondly, the user's feature vector 
is used as the input of the obtained optimal neural network 
, and the video content 
requested by the user is predicted and obtained. (Algorithm 1 lines 3–6). Finally, the video content 
requested by the user is output. (Algorithm 1 line 7).


Algorithm 1. The user content reading behavior prediction algorithm based on multi-layer perceptron

Input: The feature vector 
 of the user's historical playback information
Output: The video content 
 requested by the user
1 The weight is initialized
2 BP algorithm is used to obtain the optimal weight 
, that is, the neural network 
 is obtained
3 for  do
4 
 //the user's feature vector is used as the input of the neural network
5 

6 end for
7 return The video content 
 requested by the user
(2)
The edge cache algorithm based on delay and energy consumption balance

The core pseudocode of the edge cache algorithm based on delay and energy consumption balance is shown in Algorithm 2. According to Algorithm 1, the content reading behavior of each user is predicted. Firstly, the  global next 
 and previous 
 are initialized. Then, each branch problem 
 is split into  branches (Algorithm 2 line 5–9). For each new branch problem, the total delay and total energy consumption are calculated according to the formula, respectively, and the problem 
 is solved using Lagrangian relaxation (Algorithm 2 line 10–23). Finally, the objective function value of the branch is checked, and the branch with the larger objective function value is clipped until the optimal solution is obtained, and finally, the content cache location set is obtained (Algorithm 2 line 26–42).


Algorithm 2. The edge cache algorithm based on delay and energy consumption balance

Input: The feature vector 
of the user's historical playback information.  and  denotes the number of MEC servers and video content. 
 is the cache list.
Output: The content cache location collection 

1 for  do
2 predict the content reading behavior for each user//according to algorithm 1
3 end for
4 obtain the user read video content collection 

5 initialize 
and 
to the global lower and upper bounds of the branch respectively.
6 while  and 
 do
7 Each branch problem 
in the branch list 
can be split into branches
8 for  do
9  obtain the new branch question 

10 switch (
):
11 case1 
:
12 

13 
 //calculate the total delay according to formula (4)
14 
 //calculate the total energy consumption according to formula (12)
15 solve the problem 
 using Lagrangian relaxation and use the result as the lower bound 
 of the problem 

16 add the solution of the problem 
 to the set 
17 break;
18 case2 
:
19 scale the range of undetermined variable 
 to 
20 
 //calculate the total delay
21 
 //calculate the total energy consumption
22 solve the problem 
 using Lagrangian relaxation and use the result as the lower bound 
 of the problem 

23 add the solution of the problem 
 to the set 
24 break;
25 endswitch
26 if all are integers then
27 let the upper bound be 

28 cut off the branch
29 

30 else
31 choose a set of random feasible solutions to get the upper bound 

32 endif
33 if 

34 cut off the branch
35 

36 endif
37 let 

38 end for 39 add the remaining video content to the branch list 

40 
41 end while
42 return the content cache location collection 
The proposed edge caching algorithm based on delay and energy balance in the MEC environment based on SDN can be divided into two parts. (1) The multi-layer perceptron is used to predict the video content requested by the user. The number of nodes in the input layer and final output layer of the MLP neural network is determined, which can be represented by constants and 1 respectively. Assuming that the number of hidden layers is and the number of training samples is . The time complexity of training a multilayer perceptron neural network model can be denoted by . Suppose the number of mobile users is . Therefore, the time complexity of predicting the reading behavior of users can be expressed as . (2) The branch-and-bound method is used to solve the edge caching algorithm based on user content reading behavior. Since the time complexity of the branch-and-bound algorithm is lower than the exhaustive method and there is no provable time complexity. People pay more attention to the time complexity of each leaf. On each leaf of the branch-and-bound algorithm, the resulting problem is a convex optimization problem. In this paper, the Lagrange multiplier method can be used to find the closed-formed solution with the time complexity .

4. The dynamic service migration method based on deep Q learning
In this section, the issues of the limited coverage of edge servers and user terminal mobility are studied. To ensure service continuity when users move, the dynamic service migration method based on deep Q learning is proposed in this paper. The method is divided into three steps. 1) Firstly, the service migration problem is expressed as a Markov decision process. 2) Secondly, the service migration process is analyzed and a service migration reward function is constructed. 3) Finally, deep Q learning is used to obtain the optimal service migration strategy. The architecture diagram of the dynamic service migration method based on deep Q learning is shown in Fig. 3. Besides, we have customized base station information table and mobility information table in flow table. The custom attributes in the base station information table include radio access load, computation load of edge servers, etc. Meanwhile, the custom attributes in the mobility information table include source address, destination address, and traffic class, etc (Chen and Hao, 2018; Nguyen et al., 2016; Addad et al., 2018).

Fig. 3
Download : Download high-res image (850KB)
Download : Download full-size image
Fig. 3. Architecture diagram of dynamic service migration method based on deep Q learning.

4.1. The migration model
4.1.1. The migration model based on markov decision process
In this paper, the service migration process is modeled as a Markov decision process. The overall goal of the proposed dynamic service migration method is to find an optimal strategy to maximize the total long-term reward. The specific decision-making process is described as follows.

(1)
The state space and action set

The state-space  includes location information of users and services, which can be defined as for formula (11).(11)where  and  represent the user location status and service location status respectively. 
 denotes the entire system state at the beginning of each time slot (before migration). The state 
 is the initial state of the time slot .

 represents a set of actions, which can be defined as . 
 represents the control actions taken when making migration decisions  based on the system state 
.

(2)
The control decision

 indicates the possible location for users and is assumed to be limited. The user positions remain fixed for the duration of a time slot and change from a one-time slot to the next according to the Markov mobility model. The slot model can be regarded as a sampled version of a continuous-time model, and sampling can be performed at equal or unequal intervals over time. Besides, it is assumed that each user location is associated with the MEC server. 
is used to calculate the distance between the location 
and 
. Note that this distance measure is not the Euclidean distance, but the number of hops from one cellular network to another. 
and 
represent the user location and service location at the time slot respectively.

At the beginning of each time slot, there are following two control strategies for the MEC server.

Migrating services from the location 
to other locations 
will incur a migration cost . It is assumed that is a non-decreasing function, where 
is the distance between 
and 
. After the migration is complete, the system status is 
. The migration cost can show the service interruption time of the migration process. This is because whenever the migration occurs, there is a non-zero interruption time (Kiryong et al., 2015). As the propagation and switching delay of data transmission increases, the interruption time will increase with the migration distance.

No migration service. In this case, there is 
and the migration cost is . In addition to migration costs, there exists data transmission costs when users connect to the currently active service instance. The transmission cost is related to the distance between service and user after migration. is a non-decreasing function, where there is 
and . The transmission cost can show the latency of data transmission, where high latency increases service response time. According to the reference (Ceselli et al., 2017), the delay is usually a function of the geographic or topological distance between two nodes and increases with distance. It is assumed that the transmission delay and service interruption time caused by migration is much smaller than the length of each time slot, so the cost does not change with the length of the time slot.

(3)
The reward function

The main goal of the proposed service migration method is to obtain the best service migration strategy in each system state, and maximize the server load capacity, while minimizing transmission costs and migration costs. As the stronger the server load capacity and the lower the cost is, the greater the instant reward is. Therefore, the instant reward function can be defined as formula (12).(12)
where  denotes the load capacity of the server.  represents the cost function. 
 and 
 denote the weights and there is 
.

The cost can be defined as the sum of migration costs and transmission costs after performing the action in the state , which can be expressed as . indicates the distance between the service in the state and the state 
. The state 
indicates the state after the migration action in the state . denotes the distance between the service and the user after performing the action in the state . The migration cost and transmission cost can be defined in the form of constant plus exponent, which is expressed by mathematical (13), (14).(13) 
 (14) 
 where 
, 
, 
, 
, and are real-valued parameters. and  are both non-decreasing functions.

As for service quality, considering the migration cost and transmission cost, the MEC server area where the user is located is the best choice. However, there may be insufficient storage space and excessive load for the target edge server. Therefore, the load capacity of the edge server is also regarded as an important factor affecting service migration decisions. The system will preferentially select the server with the stronger load capacity as the target edge server for service migration. The factors such as CPU utilization, memory capacity, network bandwidth, and disk I/O rate are comprehensively considered. The load capacity of the edge server can be expressed as formula (15).(15)
where there is 
 and  denotes the impact of various indicators on the server's load capacity. The CPU utilization 
 reflects how busy the server CPU is. The memory occupancy rate 
 denotes the percentage of memory used by running system processes to total memory. The lower the memory occupancy rate is, the smaller the memory load of the server and the stronger the memory load capacity. The network bandwidth occupancy rate 
 refers to the percentage of the current bandwidth size to the total bandwidth size. The lower the bandwidth occupancy rate is, the more idle the network is. The disk I/O rate 
 reflects the throughput of server data operations. The CPU utilization, memory occupancy rate, network bandwidth occupancy rate, and disk I/O rate of the edge server can be expressed as follows.(16)
(17)
(18)
(19)
where 
, 
, 
 and 
 represent the load status of the edge server, including CPU processing capacity, memory usage, network bandwidth consumption, and disk I/O read and write capabilities. 
, 
, 
 and 
are usually the fixed values, which denote the CPU processing capacity, memory capacity, network bandwidth, and disk I/O read and write capabilities of the edge server respectively.

4.1.2. The objective function of the service migration model
The goal of the proposed service migration method is to design a control policy that maximizes long-term expected rewards from the initial state, which can be expressed as mathematical formula (20).(20)
where the long-term expected rewards generated by the strategy starting from any initial state 
 can be shown as formula (21).(21)
 
where denotes the discount factor. is the instant reward function that performs the action at the state . The maximization problem can be solved by the Bellman equation (Puterman, 2009), which can be expressed as follows.(22)
 
where 
 denotes the transition probability from state 
 to state 
.

4.2. The method for the dynamic service migration
In this paper, the trained neural network is used to predict the profit of each action. In deep reinforcement learning, deep neural networks are used to obtain an approximate state-action value function 
, where the parameter vector  is the weight vector of deep neurons. Deep Q network (Mach and Becvar, 2017) is not a Q table update method using traditional Q learning, but to update by training a neural network. Therefore, to solve the problem of service migration in this paper, a method of service migration based on deep Q-learning is proposed.

In the service migration strategy based on deep Q-learning, we choose migration action 
to maximize future discount rewards. The deep Q network is used to find the approximate optimal action-value function, which can be expressed as follows.(23)
 
where 
 denotes the maximum reward after taking action in the state on time . 
represents the immediate reward function. is the discount factor and denotes the expectation function.

Deep neural networks are used to obtain approximate action-value function . In each decision cycle, the user first takes the state vector as the input of the deep Q network and obtains the Q value of all possible actions as the output. Then, the user selects an action according to the strategy. The loss function 
at a time can be expressed as formula (24).(24)
 

The loss function can be minimized by stochastic gradient descent. After iterating the deep Q network using the specified loss function, the weight is updated to 
. Besides, in deep Q learning algorithms, the empirical playback technology is used as a training method to solve the problem of instability of deep neural networks due to the use of nonlinear approximation functions.

4.3. The dynamic service migration algorithm
The core pseudocode of the dynamic service migration algorithm based on deep Q learning in the MEC environment based on SDN is shown in Algorithm 3. Firstly, the memory matrix , Q-target network parameter , etc. and the current state 
are initialized. The state  is input into the deep Q network, and the Q value output corresponding to all actions is returned (Algorithm 3 line 1–8). Then, the  greedy strategy is used to select the action with the highest Q value, the selected action is executed in the state , and the reward  is received. User experience information 
 is stored in the memory matrix  (Algorithm 3 line 9–19). Finally, the sample 
 is randomly taken from , and the neural network is trained to minimize the loss. And the current neural network weight value is copied to the target neural network weights at intervals, until the state space exploration is completed (Algorithm 3 line 20–38).


Algorithm 3. The dynamic service migration algorithm based on deep Q learning

Input:Number of iterations , action set , attenuation factor , weight 
and 
.
Output:The optimal service migration strategy 

1 Initialize memory matrix 
2 Initialize action-value function and random weight 
3 Initialize the target action-value function 
 and the weight can be 
.
4 //Initialize service migration path
5 for  do
6 Initialize state to the first state 
of the current state sequence
7 for  do//Iterate
8 Use the current state as input to get the Q value output corresponding to all actions of the Q network
9 //Choose the action 
based on strategy
10 if  then
11 
 //Choose the random action
12 else
13 
 //Choose the current optimal action
14 endif
15 //Calculate the reward function according to formula (12)
16 

17 Calculate 

18 Obtain the next state 

19 Save the user experience information 
 in the memory matrix
20 randomly take a sample 
from the memory matrix and calculate the current target Q value
21 if  terminate at step then
22 

23 else
24 
 

25 endif
26 //Calculate the loss function according to formula (24)
27 Train the neural network according to the loss function 

28 Update all parameters of Q network through gradient backpropagation of neural network
29 if  then
30 Reset 

31 
32 else
33 
34 endif
35 endfor
36 endfor
37 

38 return 
5. Performance evaluation
5.1. Experimental environment
5.1.1. Experimental setup
The experimental environment of mobile edge computing based on SDN in this paper is composed of the remote cloud servers, the SDN controllers, and three edge node servers. The hardware platform of the experimental environment includes mobile devices, control nodes, edge servers, and cloud servers. By running Open vSwitch software, network access devices and edge servers can parse the OpenFlow protocol. Open vSwitch 2.5.5 is installed and deployed on the Ubuntu 16.04 platform. Based on the Python 2.7 environment, the POX controller and Docker are installed and deployed on the Ubuntu 16.04 operating system, and the K8S Dashboard is installed to display the status information of the cluster. The experimental environment architecture is shown in Fig. 4, and the detailed configuration information of the main equipment is shown in the figure.

Fig. 4
Download : Download high-res image (650KB)
Download : Download full-size image
Fig. 4. Experimental environment architecture diagram.

5.1.2. Experimental benchmark data
In this paper, the 360° video viewing data (Lo et al., 2017) set is used as the benchmark test data for the proposed edge caching algorithm. The 360° video viewing data set is published in 2017 in head-mounted virtual reality. The data set contains ten 360° videos with different characteristics collected from YouTube (YouTube [EB/OL], 2017). The lengths of the videos are different. In this paper, videos with a duration of 1 min are selected for testing. All VR videos are 4K resolution, 30 frames per second (fps). Some sample information of the data set is shown in Table 3.


Table 3. Part of the VR video information table in the data set.

category	Video name	Video size (MB)	duration (min)	Video link
NI, fast-paced	Mega Coaster	312	1: 57	https://youtu.be/-xNN-bJQ4vI
Roller Coaster	526	3: 26	https://youtu.be/8lsB-P8nGSM
Driving with	1102	9: 25	https://youtu.be/LKWXHKFCMO8
NI, slow-paced	Shark Shipwreck	475	4: 10	https://youtu.be/aQd41nbQM-U
Perils Panel	243	4: 03	https://youtu.be/kiP5vWqPryY
Kangaroo Island	206	1: 38	https://youtu.be/MXlHCTXtcNs
SFR Sport	181	3: 32	https://youtu.be/lo5N90TlzwU
Hog Rider	167	1: 12	https://youtu.be/yVLfEHXQk08
CG, fast-paced	Pac-Man	91	1: 49	https://youtu.be/p9h3ZqJa1iA
Chariot Race	179	1: 12	https://youtu.be/jMyDqZe0z7M
Applying rich existing computer vision CV algorithms to the video can improve the viewing performance of video streams. To evaluate the performance of the service migration algorithm proposed in this paper, the face recognition application is used as the basic test application. YouTube Faces DB (YouTube Faces DB [EB/OL], 2019) is used as the data set of the face recognition application in this paper. The dataset contains 3425 videos of 1595 different people. All videos are downloaded from YouTube. Each topic provides an average of 2.15 videos. The shortest duration of the clip is 48 frames, the longest clip is 6070 frames, and the average length of the video clip is 181.3 frames.

5.1.3. Evaluation metrics and experimental parameters
(1)
Evaluation metrics

Cache hit rate, average access delay, backhaul traffic load, and energy consumption are selected as the performance evaluation indicators to evaluate the feasibility of the proposed cooperative caching algorithm. The cache hit rate is an important indicator to measure cache performance. It is defined as the ratio of the number of content hits at the edge server to the total number of content requests. The average access delay refers to the average delay of content from the edge server or origin server to the requesting user. The average access delay includes transmission delay and access delay, which is expressed by formula (4). Backhaul traffic load refers to the data traffic through the backhaul network when users cannot obtain content from the edge node and download the video from the original server. It reflects the resource consumption of the network. The energy consumption cost mainly includes transmission energy consumption and storage energy consumption, which is represented by formula (8).

The number of service migrations, cost, average traffic consumed by migration, and the success rate of service migration are selected as the performance evaluation indicators to evaluate the feasibility of the proposed dynamic service migration algorithm. The number of service migrations is the total number of service migrations between the time a user submits a request and the request is satisfied. The cost includes migration cost and transmission cost, they are expressed by formula (13) and formula (14) respectively. The average traffic consumed by migration refers to the network traffic consumed by each service migration. The service migration success rate is defined as the ratio of the number of services migrated before the required deadline to the total number of services migrated.

(2)
Experimental parameters

The experimental parameter list of the edge cooperative cache algorithm based on delay and energy balance is shown in Table 4. Among them, the video content library includes 500 virtual reality videos, a 360-degree virtual reality video with a duration of 1 min is randomly intercepted, and the average data size of each high-definition video content is 128 MB.


Table 4. Experimental parameter table.

Parameter	Ranges	Parameter	Ranges
Each video content size	[32,256] MB	Computing resources of user equipment	[0.5,1.0] GHz
Cache capacity of MEC	[16,128] GB	Number of mobile users	(Emna et al., 2020; Jia et al., 2017)
Computing resources of MEC	[2,2.5] GHz	Relative cache size	[10%,100%]
The experimental parameters of the dynamic service migration algorithm based on deep Q learning are introduced as follows: the user equipment moves within a range of , and three base stations are evenly distributed within the range. Each edge base station is associated with a unique MEC server. Multiple mobile users will move within the coverage of 3 edge servers according to the uniform one-dimensional random walk model (Wang et al., 2015). Meanwhile, if the user moves to another location after staying at a certain location for a period of time, the probability of moving to any location is equal. The experiment sets different numbers of users, network bandwidth, and user movement rate. Among them, the number of mobile users is set to , and the network bandwidth is .

5.1.4. Benchmark algorithms
In this paper, four different edge caching strategies, LRU, PBC, JOC, and Q-LCCA, are selected as comparison algorithms. The Least Recently Used algorithm (Hasslinger et al., 2018) (LRU) assumes that the currently requested content is likely to be requested within the next period. When new content needs to be cached, the least recently accessed content will be deleted from the cache list. Popularity-Based Caching algorithm (Nakayama et al., 2015) (PBC) takes into account user behavior and request patterns. High-request content is predicted and cached before peak hours. Joint Optimization Cache algorithm (Liang and Yu, 2017) (JOC) considers service quality and resource constraints. Bandwidth provisioning and caching strategies are optimized in software-defined mobile networks. The benefits gained from dynamically managing the cache and effectively using network resources are maximized. The Q-Learning based Collaborative Cache Algorithm (Chien et al., 2020) (Q-LCCA) uses the Q-learning design caching mechanism. The cache hit rate is maximized, and the transmission time and cache capacity are minimized. As a result, the return traffic and transmission delay from the remote cloud are reduced.

In this paper, three different service migration strategies, Always (Ma et al., 2017), Myopic (Saurez et al., 2016), and Mig-RL (Cao et al., 2017), are selected as comparison algorithms. Always is also called greedy strategy or minimum hop strategy. When the terminal device moves outside the service area of the base station, the service will always be migrated to the nearest edge server. Myopic is a myopic strategy to make migration decisions based on service quality observations. It selects the corresponding migration action to minimize the one-time slot cost. Mig-RL uses reinforcement learning algorithms to study service migration issues in a cloud computing environment. Service costs are minimized, and cloud service quality is improved.

5.2. Results and analysis
5.2.1. Experimental verification of edge cooperative cache algorithm based on delay and energy consumption balance
(1)
Impact of relative cache size on experimental results

The cache size is an important parameter to evaluate the efficiency of the cache system. In this paper, the relative cache size is introduced to reflect the scarcity of cache space. The relative cache size is defined as the ratio of the edge server's cache size to the total size of the video library content. Fig. 5 shows the effect of different relative cache sizes on different performance parameters. The experiment in this section uses the control variable method. The relative cache size range is set to [10%, 100%], the number of mobile users is set to 10. The result of the experiment is the average of 20 repeated experiments.

Fig. 5
Download : Download high-res image (759KB)
Download : Download full-size image
Fig. 5. Impact of relative cache size on experimental results.

Fig. 6
Download : Download high-res image (737KB)
Download : Download full-size image
Fig. 6. Impact of the number of mobile users on experiment results.

Fig. 5 (a)–(d) respectively show the process of the cache hit rate, average access delay, backhaul traffic load, and energy consumption cost as the relative cache size changes. As shown in Fig. 5 (a), the cache hit rate of different cache strategies increases with the increase of the relative cache size. As the relative cache size of the edge server increases, the cache capacity and the number of cached videos increase, the probability that the user requests to be served by the edge node is increased. Therefore, the cache hit rate is improved. When the relative cache size is 40%, the proposed algorithm is increased by 15.05% on average compared with the LRU algorithm, 7.53% on average compared with the PBC algorithm, and 2.15% on average compared with the JOC algorithm. However, the Q-LCCA algorithm has the highest cache hit rate. Because the Q learning design cache mechanism is used in the Q-LCCA algorithm, which aims to maximize the cache hit rate and minimize the transmission time and cache capacity. As shown in Fig. 5 (b)–(d), the average access latency, backhaul traffic load, and energy consumption cost of different cache strategies decrease with the increase of the relative cache size. As the relative cache size of the edge server increases, the edge server can store more requested content. Users can obtain content directly from the edge server without downloading video content from a remote cloud data center. Therefore, average access latency, backhaul traffic load, and energy consumption cost are reduced. When the relative cache size is 40%, as shown in Fig. 5 (b), the average access latency of the proposed algorithm is reduced by 32.76% on average compared with LRU algorithm, 29.09% on average compared with PBC algorithm, 11.56% on average compared with JOC algorithm, and 2.56% on average compared with Q-LCCA algorithm. As shown in Fig. 5 (c), the backhaul traffic load of the proposed algorithm is reduced by 69.26% on average compared with LRU algorithm, 48.29% on average compared with PBC algorithm, 24.89% on average compared with JOC algorithm, and 10.75% on average compared with Q-LCCA algorithm. As shown in Fig. 5 (d), the energy consumption cost of the proposed algorithm is decreased by 39.29% on average compared with LRU algorithm, 37.04% on average compared with PBC algorithm, 19.04% on average compared with JOC algorithm, and 29.17% on average compared with Q-LCCA algorithm.

(2)
Impact of the number of mobile users on experiment results

Fig. 6 shows the impact of different mobile user numbers on different performance parameters. The control variable method is adopted in the experiment in this section. The number of mobile users is set to 5, 10, 15, 20, and 25 respectively, and the other variable is controlled the same. In this paper, the relative cache size is set to 20% of the size of the video library. The result of the experiment is the average of 20 repeated experiments.

Fig. 6 (a)–(d) respectively show the process of the cache hit rate, average access delay, backhaul traffic load, and energy consumption cost with the number of mobile users. As shown in Fig. 6 (a), the cache hit rate of different caching strategies decreases as the number of mobile users increases. As the number of mobile users increases, the types of requested content increase. However, the relative cache size remains the same, and the edge server can only store a fixed size of the content. Therefore, the number of the cache hit contents and the cache hit rate are decreased. When the number of mobile users is 15, the algorithm proposed in this paper is increased by 19.58% on average compared with the LRU algorithm, 15.90% on average compared with the PBC algorithm, and 8.58% on average compared with JOC algorithm. Since the Q-LCCA algorithm aims to maximize the cache hit rate, the Q-LCCA algorithm has a higher cache hit rate than the algorithm proposed in this paper. As shown in Fig. 6 (b)–(d), the average access latency, backhaul traffic load, and energy consumption cost of different caching strategies increase with the number of mobile users. As the number of mobile users increases, the types of content requested by users increase. The number of cache hits is reduced, and it is necessary to obtain cache misses from the remote server. Therefore, the average access delay, backhaul traffic load, and energy consumption cost are increased. When the number of mobile users is 15, as shown in Fig. 6 (b), the average access latency of the proposed algorithm is reduced by 25.03% on average compared with LRU algorithm, 22.47% on average compared with PBC algorithm, 11.88% on average compared with JOC algorithm, and 1.43% on average compared with Q-LCCA algorithm. As shown in Fig. 6 (c), the backhaul traffic load of the proposed algorithm is reduced by 25.53% on average compared with LRU algorithm, 20.68% on average compared with PBC algorithm, 17.36% on average compared with JOC algorithm, and 4.13% on average compared with Q-LCCA algorithm. As shown in Fig. 6 (d), the energy consumption cost of the proposed algorithm is reduced by 31.92% on average compared with LRU algorithm, 29.33% on average compared with PBC algorithm, 6.23% on average compared with JOC algorithm, and 12.68% on average compared with Q-LCCA algorithm.

5.2.2. Experimental verification of dynamic service migration algorithm based on deep Q learning
(1)
Impact of the number of mobile users on experiment results

Fig. 7 shows the impact of different user numbers on different performance parameters. The control variable method is adopted in the experiment in this section. The number of mobile users is set to 10, 20, 30, 40, 50, the network bandwidth is set to 40 Mbps. The result of the experiment is the average of 20 repeated experiments.

Fig. 7
Download : Download high-res image (726KB)
Download : Download full-size image
Fig. 7. Impact of the number of mobile users on experiment results.

Fig. 7 (a)–(d) show the process of service migration times, cost, average traffic consumed by migration, and the service migration success rate with the number of mobile users. As shown in Fig. 7 (a)–(c), with the increase in the number of users, the number of service migrations, cost, and average traffic consumed by different migration strategies increase. As the number of users increases, the services that need to be migrated are correspondingly increased, and the amount of data migrated is increased. Thus, the number of service migrations, cost, and average traffic consumed by migration are increased. When the number of mobile users is 30, as shown in Fig. 7 (a), the service migration times of the proposed algorithm are reduced by 62.12% on average compared with the Always algorithm, 48.45% on average compared with Myopic algorithm, and 12.28% on average compared with Mig-RL algorithm. As shown in Fig. 7 (b), the cost of the proposed algorithm is reduced by 34.69% on average compared with the Always algorithm, 31.99% on average compared with the Myopic algorithm, and 19.26% on average compared with Mig-RL algorithm. As shown in Fig. 7 (c), the average traffic consumption of the proposed algorithm is decreased by 23.52% on average compared with the Always algorithm, 7.48% on average compared with Myopic algorithm, and 2.38% on average compared with Mig-RL algorithm. As shown in Fig. 7 (d), as the number of users increases, the migration success rate of different service migration strategies decreases. The increase in the number of users makes the application programs executed by the MEC server increase. However, due to resource limitations, some services have failed to migrate. Therefore, the success rate of service migration is reduced. When the number of mobile users is 30, the service migration success rate of the proposed algorithm is increased by 8.73% on average compared with the Always algorithm, 5.37% on average compared with Myopic algorithm, and 1.97% on average compared with Mig-RL algorithm.

(2)
Impact of network bandwidth on experimental results

Fig. 8 shows the impact of different network bandwidths on different performance parameters. The control variable method is adopted in the experiment. The network bandwidth is set to 20Mbps, 40Mbps, 60Mbps, 80Mbps, and 100Mbps, the number of mobile users is set to 30. The result of the experiment is the average of 20 repeated experiments.

Fig. 8
Download : Download high-res image (835KB)
Download : Download full-size image
Fig. 8. Impact of network bandwidth on experimental results.

Fig. 8 (a)–(d) respectively show the process of service migration times, cost, average traffic consumed by migration, and the success rate of service migration with network bandwidth. As shown in Fig. 8 (a)–(c), as the network bandwidth increases, the number of services migration times, costs, and average traffic consumed by different migration strategies decrease. As the network bandwidth increases, the transmission of data of the same size is faster. Therefore, service migration times and costs are reduced. The number of service migrations is reduced so that the average traffic consumed by migration is reduced. When the network bandwidth is 60Mbps, as shown in Fig. 8 (a), the service migration times of the proposed algorithm are decreased by 70.83% on average compared with the Always algorithm, 52.05% on average compared with Myopic algorithm, and 12.51% on average compared with Mig-RL algorithm. As shown in Fig. 8 (b), the cost of the proposed algorithm is reduced by 33.40% on average compared with the Always algorithm, 30.11% on average compared with the Myopic algorithm, and 20.15% on average compared with Mig-RL algorithm. As shown in Fig. 8 (c), the average traffic consumption of the proposed algorithm is decreased by 22.10% on average compared with the Always algorithm, 7.39% on average compared with Myopic algorithm, and 2.28% on average compared with Mig-RL algorithm. As shown in Fig. 8 (d), the success rate of service migration with different migration strategies increases as the network bandwidth increases. As the network bandwidth increases, the number of service migrations is reduced. Therefore, the success rate of service migration is increased. When the network bandwidth is 60Mbps, the service migration success rate of the proposed algorithm is increased by 7.02% on average compared with the Always algorithm, 3.53% on average compared with the Myopic algorithm, and 1.69% on average compared with Mig-RL algorithm.

6. Conclusion and future work
In SDN based mobile edge computing environment, in order to be able to allocate caching resources reasonably to serve as many user requests as possible, and reduce latency and energy consumption., the edge cooperative caching method based on delay and energy consumption balance is proposed. In the proposed method, firstly, the multilayer perceptron neural network is used to predict the video content requested by the mobile user. Secondly, an objective function to minimize delay and energy consumption is established, and an edge cache optimization model is constructed. Finally, the branch-and-bound algorithm is used to obtain the optimal edge caching strategy. In order to provide users with seamless service migration to ensure service continuity and high-quality services, the dynamic service migration method based on deep Q learning is proposed. In the proposed method, firstly, the service migration problem is expressed as a Markov decision process. Secondly, the service migration process is analyzed and a service migration reward function is constructed. Finally, deep Q learning is used to obtain the optimal service migration strategy. In future works, SDN and artificial intelligence methods will be further combined to research edge caching strategies and service migration. Meanwhile, the number of base stations and mobile users will be increased, and the scale of experiments will be further expanded.
