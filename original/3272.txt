As the mobile edge computing develops continually, many emerging and diversified edge applications, such as Internet of vehicles, virtual reality games and lightweight deep learning tasks, are emerged. These applications are latency sensitive and require a large number of network connections. As the data size and business requests processed per unit of time continue to increase, the pressure of edge cloud load increases so much that the edge cloud cannot provide timely and effective services for users. In order to meet the high requirement of delay sensitive application service, on the one hand, the energy consumption of edge devices should be reduced, and the modules with high computational load should be scheduled to the remote server for execution. On the other hand, the automatic scaling model is proposed to improve the total cost of the tenanted instances. In the dynamic replica management model, the response time and the energy consumption are reduced, moreover, the workload in the hosts are balanced. In the experiment of automatic scaling, the cumulative total cost and the power consumption of our proposed algorithm are lower than that of CAAS and MLC algorithm. Two hours after the experiment, the CPU utility of our proposed algorithm is higher than the CPU utilizations of CAAS and MLC. In the dynamic replica placement experiment, the average response time and load balancing value of the data migration algorithm in our paper are lower than that of BA and LA. The available storage space of our replica placement method is more balanced than both the DDD and WA.

Previous
Next 
Keywords
Edge computing

Automatic scaling

Data migration

Dynamic replica management

1. Introduction
In the development of communication technology and the growth of intelligent equipment popularization, data explodes. As the Mobile Edge Computing appears, many problems caused by the explosive data can be solved. With the diversified development of user demand, many emerging and diverse edge applications appear, such as Internet of Vehicles, virtual reality games and lightweight deep learning task.

These applications are sensitive to delays. When the data sizes and business requests processed by the core network per unit of time is so large that the edge nodes cannot process too many tasks quickly, the edge cloud cannot provide services for the users timely. Therefore, in order to meet the dynamic needs of the users, the resources need to be allocated flexibly. The instances need to be leased from the central cloud to fill the resource requirement. Moreover, the workload needs to be allocated evenly to the hosts to improve the utilization of the resources. When the workload is reduced, some instances are released and the data in theses instances need to be placed in the proper physical hosts. Furthermore, the response time and the power consumption of the proposed algorithms are also considered in this paper.

Of course, in the current studies, many automatic scaling and replica placement strategies are proposed. In terms of the automatic scaling, most prices of instances provided by the central cloud are imprecise, because the time granularity of billing is too large. The imprecise prices cause the waste of resources and add the overhead of users. In our paper, Aliyun provides billing services with small granularity of time, and charges by the hour. The proper instances can be tenanted, and the service quality can be improved. As for the replica placement, the heterogeneity of edge servers and the average response time are not simultaneously considered (Li et al., 2020a). The low server utilization is resulted (Charapko et al., 2018) (Fan and Ansari, 2019). In our paper, the average time to respond to user requests and the CPU utilization are taken as two of the performance metrices (Yang et al., 2015).

For solving the above problems, the novel findings of this paper are summarized in the following content.

(1)
For minimizing the total cost, the automatic scaling model is proposed, at the beginning, the historical workload is analyzed by the load prediction algorithm, then the workload in the next time is predicted. According to the forecasted workload, the automatic scaling model is built, and the formula of the total cost is denoted. When the tenanted instances are released or started, there will be an overhead cost. During this time, these instances are not working. Finally, according to the equation and the formulas of constraints, the optimal solution is obtained by the Tabu Search algorithm.

(2)
For reducing the average response time and the power consumption of the data migration, the replica placement model is built. According to the analyzation of the historical status data, the static utilization threshold is combined with the dynamic host utilization prediction to forecast the SLA violation and the timing of virtual machine migrations. In addition, considering a variety of factors, the replica placement issue is taken as the multi-objective optimization problem (MOOP).

The structure of this paper is as follows. Section 2 reviews related work. Section 3 describes the models of automatic scaling and dynamic replica management. Section 4 presents the implementations of these algorithms. Section 5 evaluates the implementation and verify the advantages of the proposed method. Finally, conclusions and future work are shown in Section 6.

2. Related work
2.1. Background
At present, many researches on resource allocation and replica management exist. In this section, some works related to these two topics are summarized. With the continuous development of the Internet, more and more data are produced, and we are gradually stepping into the era of big data from the information age in the past. Large amount of data, big change and fast speed are the three main characteristics of the Big Data. For coping with the huge amounts of data, large-scale cluster computing arises at the right moment, and many batch processing systems such as Hadoop (Gummaraju, Mcdougall, Nelson, et al.) have emerged to process data. As the cloud computing develops, various cloud service providers emerge. The resources provided by the central cloud are supposed to be infinite. The tenanted costs are calculated according to the quantity. Therefore, on the premise of ensuring the function and performance, minimizing the consumption of resources becomes an urgent problem to be solved.

If cloud computing has the capacity of automatic scaling, most computing scenarios are able to be handled. When the workload of the edge hosts rises steeply, enough resources are added to ensure the quality of service. As the workload decrease, the extra resources are released to save money. Toosi et al. proposed a dynamic auto-scaling algorithm to minimize the cost while meeting the end-to-end latency of the service chain (Toosi et al., 2019). For allocating the resources in advance, researchers concentrated on the load prediction method to forecast the host workload in the next time. He et al. proposed a novel Deep Neural Network architecture for short term load forecasting (He, 2017).

In addition, to guaranty the safety of data in the released instances, many researchers study data migration and replica placement. Any loss of data will cause incalculable and irreparable losses to enterprises, public institutions and government agencies. In our paper, the data reliability refers to avoiding data loss. In the process of data migration, for ensuring that the data is not lost, according to the data migration strategy, the data in the released tenanted instances is transferred to the remaining node. Iqbal et al. identified the key advantages and consequences of migrating data into the cloud through a multivocal literature review (Iqbal and Colomo-Palacios, 2019). Then, for reducing the response time of user requests, many studies focused on the replica placement method to determine the appropriate location for placing replicas. Dai et al. presented an improved replica placement policy for Hadoop Distributed File System (HDFS), which is specifically designed for heterogeneous clusters (Dai et al., 2017).

2.2. Automatic scaling
Nowadays, for reducing the resource waste and the tenanted cost of hosts, many researchers studied the automatic scaling. Some extensive papers are described as follows.

Before the resources are allocated, the workload in the next time is forecasted by the load prediction methods. Some references (Li et al., 2017; Duggan et al., 2017; Sheng et al., 2019) used a single load forecasting model to allocate the resources in advance. Li et al. (2017) presented a load balancing including a load forecasting model and algorithms based on BP neural network to achieve load balancing. Duggan et al. (2017) implemented a Recurrent Neural Network to predict CPU utilization, which predicted CPU utilization with greater accuracy when compared to traditional approaches. Sheng et al. (2019) proposed a load forecasting model based on neural network, analyze the existing problems of BP algorithm in power load forecasting and make improvements.

When the workload in the next time exceeds the capacity of the edge hosts, instances in the central cloud are tenanted. For the users in the cloud, the resources in the cloud is unlimited. Whenever the users apply for the resources, the needs are met by the cloud. To achieve this goal, adequate resources should be provided by the resource scheduling management center timely. In addition, as the predicted workload in the next time decreases, some instances are chosen to be released to save resources. In the references (Babu and Samuel, 2017; Rahman et al., 2018a; Sahni and Vidyarthi, 2017), the proposed methods focused on latency, actual performance requirements, heterogeneity and so on, and the cost of tenanted instances were not considered. Matteis et al. proposed a control-theoretic strategy to drive the elastic behavior of latency-sensitive streaming operators in distributed environments. By relying on a predictive model-based approach, the strategy takes scaling decisions in advance (Babu and Samuel, 2017). K.R. et al. an interference aware prediction mechanism for VM migration, with auto scaling. The automatic scaling policies help to handle sudden load changes with precise prediction and minimum VM migration (Rahman et al., 2018a). Sabidur propose a proactive Machine Learning (ML) based approach to perform auto-scaling of VNFs in response to dynamic traffic changes. And the proposed method improves QoS (Sahni and Vidyarthi, 2017) and saves significant cost for network owners as well as leasers. All the rental cost in references (Aslanpour et al., 2017a; Mohan Murthy et al., 2014; Smowton et al., 2017), are considered to an optimization goal, But the cost factor has not been fully considered and resulting in a certain deviation in the cost calculation. Jahrom et al. provides a cost saving super professional executor to improve the cost efficiency (Aslanpour et al., 2017a). Maakem et al. proposed threshold based auto scaling of virtual machines. This approach effective resource utilization can be achieved. (Mohan Murthy et al., 2014). Smowton et al. described how the Genome Analysis Toolkit (GATK) can be deployed to an elastic cloud, and defines policy to drive elastic scaling of the application. They improved the performance to achieve cost tradeoff in a simulated environment (Smowton et al., 2017).

From the above, the existing works have some deficiencies in the automatic scaling model. On the one hand, many previous load prediction models used single algorithm. The linear and nonlinear data cannot be considered simultaneously, then the workload cannot be forecasted accurately. On the other hand, some existing works do not take the total cost as the parameter to be optimized. Furthermore, although some studies consider the total cost, the definitions of the total costs are not comprehensive, some costs are not taken into account in the total cost. Compared with the existing works, the novel contributions of our automatic scaling scheme are shown in the following contents.

(1)
Before the resources is scaled, the proposed hybrid load prediction method is used to forecast the workload in the next time. The resource needs of users can be met in time.

(2)
the automatic scaling model is proposed to minimize the overhead of the tenanted instances. The costs of hardware, license and labor, reconfiguration and performance impact are considered in the total cost. And he total cost of consumption is an important performance metrics in the service of edge cloud computing Moreover, the time granularity of the billing services is hour. The precise charging mechanism can reduce rental costs.

2.3. Dynamic replica management
As the instances are released, to guaranty the safety of the data, many works focused on dynamic replica management. Several representative researches are described as follows.

In the first part of the dynamic replica management, the data in the released instances is migrated to the new instances by the proposed data migration algorithm. Some references (Mohiuddin and Almogren, 2019; Cao et al., 2020; Bogy et al., 2020; Xu et al., 2017; Li et al., 2021) concentrated on user movement, data availability, etc. The significance of the historical statue data is ignored. By analyzing the historical statue data, the SLA violation can be forecasted more accurately, and then the proper time of data migration can be confirmed. Mohiuddin et al. proposed workload aware virtual machine consolidation method. This unique classification approach is adopted to ensure load is balanced accordingly during allocation and their main contribution is on the VM migration technique (Mohiuddin and Almogren, 2019). Cao et al. proposed an approach consisting of offline and online stages. At offline stage, the integer linear programming is used to produce the optimal placement strategy of heterogeneous edge servers. At online stage, a mobility-aware game theory-based method is developed to deal with the dynamic characteristic of user movement (Cao et al., 2020). Brogi et al. offered a comprehensive overview on the currently employed algorithms. These algorithms are used to solve the application placement problem in the fog (Bogy et al., 2020). Xu et al. proposed a novel data replica placement mechanism with the adjustable replica deployment strategy (ARDS) for open heterogeneous data storage systems, which considers the data availability, the data access frequency and the storage capacity (Xu et al., 2017).

After that, the replicas are placed by the proposed replica method. In references (Aral and Ovatman, 2018a; Guerrero et al., 2018; Sun et al., 2018; Mahmud et al., 2020), the heterogeneity of the nodes is not taken into account in their studies. Aral et al. proposed a distributed data dissemination approach that relies on dynamic creation/replacement/removal of replicas guided by continuous monitoring of data requests coming from edge nodes of the underlying network (Aral and Ovatman, 2018a). Guerrero et al. presented an approach focused on virtualized Hadoop for a simultaneous and coordinated management of virtual machines and file replicas (Guerrero et al., 2018). Sun et al. proposed a Dynamic Adaptive Replica Strategy (DARS) based on the node's overheating similarity. DARS addresses the problem of replica creation time, including obtaining the replica creation opportune moment and finding the optimal replica placement node, by a decentralized self-adaptive manner (Sun et al., 2018). Mahmud et al. proposed a profit-aware application placement policy for integrated Fog–Cloud environments. The constraint Integer linear Programming model is used to simultaneously enhances profit and ensures QoS during application placement on computing instances (Mahmud et al., 2020).

Above all, the existing works ignore some crucial research points in the dynamic replica management model. Firstly, the importance of the historical status data is not reflected in their paper. After the historical status data is analyzed, the proper time of data migration can be forecasted more accurately. Next, many previous studies do not consider the heterogeneity of the nodes. The heterogeneity of the nodes has a great influence on the experiment. The problems mentioned above are taken into account in our paper. Compared with the exist studies on dynamic replica placement, the advantages of the proposed method are described as follows.

(1)
In the dynamic replica placement method, to forecast the host SLA violation more accurately and determine the time data migration, the historical status data is analyzed. The static utilization threshold is combined with the dynamic host utilization.

(2)
In the paper, the heterogeneity of the nodes is considered. The configuration of both edge nodes and tenanted instances is varied. The workload balance value is taken as the performance parameter to reflect the effectiveness of load balance.

3. System model
In Fig. 1, the architecture of automatic scaling and replica management in edge cloud system is shown. When the user uses the end devices, the requests are sent to the edge hosts. The history workload is analyzed by the proposed load prediction algorithm, then the workload in the next time period is forecasted. On the one hand, as the forecasted workload is overloaded (Fig. 1 ①), request for tenanting instances is sent to the central cloud (Fig. 1 ②), then enough resources of central cloud are allocated to meet the demand of the user. On the other hand, if the predicted workload decreases (Fig. 1 ③), for saving resources, some instances are chosen and released by the data migration scheme (Fig. 1 ④). Moreover, the data block is delivered to the hosts by the replica placement scheme. Next, the central cloud receives the requests of placing the replicas (Fig. 1 ⑤). The notations are listed on Table 1.

Fig. 1
Download : Download high-res image (462KB)
Download : Download full-size image
Fig. 1. The architecture of automatic scaling and replica management in edge cloud system.


Table 1. The notations in this paper.

Parameters	Description of parameters
The virtual machine scaling cost of the resource-level
The virtual machine scaling cost of the virtual machine level
The license cost for the virtual machine level
The number of requests
The number of resource units increased
The number of virtual machine types
The virtual machine of type 
Increased number of virtual machines of type 
The number of requests used to process virtual machines of type 
The number of resource units available
The cost of the type  virtual machine
The cost of a unit resource
The license unit cost
The energy consumed by the central cloud hosts
The average time rate of SLA violation
The average performance degradation
The comprehensive metric index
The expected total MIPS demand for the virtual machine on host 
The variance of the total MIPS demand of host 
The standard deviation of the total MIPS demand of host 
The dynamic threshold
The set of the edge nodes
The capabilities of the  node
The set of requested files
The probability of the requested file 
.
The data block size .
The number of file requests that the node 
 is received during the cycle .
The overall network transmission cost
the average of the resource utilization of the entire cluster
The performance of node 
The current load of the  node
The standard deviation of the  node
Euclidean distance from the  node to the  node
The number of the  required replica
The  required replica whether to be stored in the edge node 
3.1. The automatic scaling model based on service overhead in hybrid cloud environment
In this section, an automatic scaling strategy for hybrid cloud environment is proposed. In this model, the service overhead is considered. Before scaling, a hybrid Autoregressive Integrated Moving Average model (ARIMA) (Zhang et al., 2020) and Back Propagation (BP) neural network (Jiao et al., 2018) model is built as the load prediction model, and the workloads of the edge hosts are forecasted by the load prediction model. Then, according to the forecasted workloads, the following automatic scaling model is built. The minimum billing granularity for Aliyun based on volume is hours. So, the period of the automatic scaling is set as 1 h. One of the goals of resource scaling management is to achieve higher resource utilization and lower operating cost (Li et al., 2020b). Based on a given resource request, the most suitable elastic scaling scheme is selected. Elastic scaling comes in two forms, with different costs for unit prices and licensing cost. A combination of the two scales can avoid wasting resources and reduce computation. This section reduces operating costs to optimize objectives.

Assuming that at time 
, the workload is 
. At time 
, the application has a request for workload 
. For each component  of the application, a certain number of virtual machine instances 
 and resources 
 need to be allocated to better balance the optimization of application performance and cost. 
 indicates the set of the edge nodes. The resource costs used by the application include hardware costs and software costs. The hardware cost includes the cost of the CPU and memory used, denoted as 
. The license and labor cost increases with the number of tenanted instances, denoted as 
. When virtual machines are reconfigured, application downtime or reduced performance during application reconfiguration can result in reconfiguration cost. The reconfiguration cost is expressed as 
. The performance of the application can be affected by incorrect scaling and any other performance. The cost of the performance impact is denoted as 
. The total scaling cost is as follows.(1)

The workload at time 
 can be expressed as(2)

As the load increases, there are two ways of scaling. The first method does not add additional virtual machines and has no license cost. The second is to add fixed-size virtual machines. In the first approach, as server utilization increases, the consumption of Service Level Agreement (SLA) (Sharma and Kumar, 2019) may increase. In the second approach, the more virtual machine instances are added, the higher the license and labor cost are. The added cost of both scaling methods can be expressed as follows.(3)
(4)

The scaling choice depends on the relative increase in . When the value of  is small, choosing the second scale can result in a significant waste of resources. When the value of  is large, choosing the first scale incurs a lot of SLA cost. The purpose of cost scaling is to find a convergence of virtual resources at different resource levels. Minimal scaling costs and enough resources are required to handle the next increase in services at the next interval. And then the virtual resources are extended. Cost-optimized pre-scaling will be used for virtual machine level scaling and resource level scaling. The optimization can be translated into an analysis of scaling costs and constraints. The definition is as follows.(5)

In formula (5), the total cost  needs to be minimized.(6)
(7)
(8)

The data transmission time among nodes located in different geographical locations cannot be ignored (Alicherry and Lakshman, 2012). In this paper, it is assumed that Euclidean distance from the  node to the  node is 
(in ). Relevant literature shows that data transmission time has a linear growth relationship with geographic distance (Qureshi, 2010), and the slope of the transmission time function 
(in ) is defined as(9)
 

The transmission time is expressed as(10)
where the data transmission time in the same data center is constant . In data block , the cost of transferring data is expressed as(11)
where 
(in MB) is the size of data block . 
 denotes the transmission cost per bit of data per unit of time. The overall network transmission cost is expressed as(12)

To minimize running costs in cloud computing platform, the instances tenanted strategy problem can be regarded as the following optimization problem.(13) 
 (14)

In formula (5), the steps of optimization problem are described. In the cost optimization pre-scaling step,  is the sum of the three parts. The first part represents resource scaling, which is unit of product quantity resource and unit of resource cost. Each resource requested per unit resource consumes this service. The scaling of resource levels has no license cost. The second part is the virtual machine scaling cost of the virtual machine level, which is the sum of the system costs of each type. The cost of different virtual machine types varies with their capabilities and is usually expressed as a percentage of the cost. The third part of the license cost is a scaling of the virtual machine level, which is the sum of the license cost for each virtual machine. (7), (8) ensure that the resources required to meet user requirements can be increased. formula (14) indicates that the resource increase must be available in the cluster node. For minimizing the total cost, the Tabu algorithm (Vijayalakshmi and Anandan, 2019) is introduced. Finally, for solving this MOOP, the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) algorithm based on entropy-AHP weight is taken (Guang and Wenjie, 2009). And then the set of the instance that will be tenanted in the next time is obtained.

3.2. The dynamic replica management model in hybrid cloud environment
3.2.1. Data migration
In the data center model, a cluster of physical nodes in a cloud computing data center is denoted as 
.  is the number of hosts. Million Instructions Per Second (MIPS) measures the computing power of the hosts. The maximum computing power that the host 
 can provide is expressed as 
. The virtual machine running on the host 
 is denoted as 
. 
 is the number of virtual machines running on the host 
. The CPU computing power of the virtual machine 
 is 
. The utilization of virtual machine 
 is denoted as 
, then the number of MIPS required is 
. Servers in the data center are underutilized for most of the runtime (Qureshi, 2010). Therefore, according to the actual dynamic running status of the virtual host, to reduce the number of open servers, some virtual machines running on the host can be migrated through the integration of servers. And the energy consumption can be reduced.

The power consumption model is formulated as follows. Hosts running at different utilization rates will generate different power consumption. Therefore, in a period of time 
, the energy consumed by the data center hosts can be expressed as(15)

In formula (15), 
 represents the power consumption when the host utilization is .

In terms of the SLA violation, The Quality of Service (QoS) (Karakus and Durresi, 2017a) provided by the virtual machine is measured by SLA violation rate. When a host's demand for CPU MIPS exceeds the maximum computing power it can provide, an SLA violation will occur, and a certain policy is usually adopted for virtual machine migration. The SLA violation time average rate (SLAVTAR) of the host is used to measure the SLA violation degree. The SLAVTAR is defined as(16)
 
 

In formula (16), 
 is the total time that host 
 is in SLA violation state. 
 is the total time that host 
 is running.

As for the virtual machine migration overhead. To reduce and avoid SLA violation, virtual machines on high-load hosts can be migrated in advance. However, virtual machine migration requires a certain amount of overhead. Excessive migration will cause a significant reduction in system performance. The migration cost is measured in terms of the average performance degradation (APD).(17)
 
 

In formula (17), as for the virtual machine 
, 
 is the performance degradation caused by the migration. 
 is the MIPS demand. 
 and  reflect the impact of migration in terms of SLA violation and performance degradation. The two are combined to obtain a comprehensive metric index through (16), (17).(18)

In the following content, the theoretical derivation of data migration model is analyzed. Three key problems should be solved in data migration. (1) Determine the migration time: The physical host migrates the virtual machine at an appropriate time. (2) Virtual machine selection: The virtual machine suitable for migration on the physical host is selected. (3) Determination of target host: The virtual machine is migrated to the appropriate physical host for operation. In this paper, historical status data is analyzed. The static utilization threshold is combined with the dynamic host utilization prediction strategy. Host SLA violation and timing of virtual machine migrations can be more accurately predicted, resulting in lower SLA violation rates and improved overall energy efficiency. During the operation of a virtual machine, a period of utilization is sampled. The relevant statistics of the virtual machine MIPS demand are calculated, and then the running state of the host machine is predicted. The eigen number method was adopted. The sample characteristic number is used to estimate the corresponding population characteristic number. MIPS requirements during virtual machine operation is treated as a random variable. The mean and variance values of the samples are calculated to estimate the population mean and variance of the virtual machine MIPS demands. The population mean and variance of the virtual machine MIPS demands serve as the basis for the subsequent host running state prediction. When the algorithm is applied, according to the actual situation, the utilization rate of a certain day or period of a virtual machine can be randomly collected as a sample for statistical analysis. In the subsequent description, the overall expectation and variance of the MIPS demands for virtual machine 
 are denoted as 
 and 
.The expected total MIPS demand for the virtual machine on host 
 is(19)

In formula (19), 
 represents the MIPS demand random variable for 
 virtual machines on host 
. Since the total MIPS demand of 
 is the sum of MIPS demand of virtual machine running on the host. According to the definition of expectation, the derivation is as follows.(20)

Assuming the running state of each virtual machine is independent, the variance of the total MIPS demand of host 
 is(21)

In formula (21), 
 represents the MIPS demand random variable for 
 virtual machines on host 
. According to formula (15) and the definition of variance, the derivation is as follows.(22)

In formula (22), 
, 
, . Since the virtual machine health is independent, the random variables 
 are independent from each other, so the variables 
 are also independent from each other. When 
, 
, ,(23)

Thus, the second term value of formula (22) is 0, according to formula (21), the standard deviation of the total MIPS demand of host 
 can be obtained.(24)
 

In order to predict the dynamic MIPS threshold of the host, the control factor parameter  is introduced. The dynamic MIPS threshold is denoted as follows.(25)

3.2.2. Replica placement
To meet the diverse needs of users, the replica placement method is proposed. In edge cloud system, 
 indicates the set of the edge nodes. As each node differs in performance, 
 denotes the processing capabilities of the  node, i.e. the number of user requests that can be processed per second. 
 expresses storage space size of the  node. 
 indicates the set of requested files. 
 is indicates the probability of the requested file 
. 
 indicates the size of the requested file 
. The hybrid ARIMA and BP neural network model is used to predict the number of user requests. The number of hot data replicas can be computed according to the predicted result.

Assume that 
 indicates the number of file requests which node 
 is received during the cycle . The popularity of file 
 in next cycle  is 
.The optimal strategy of replica creation is that the number of replicas is proportional to 
 (Jin and Wang, 2005a). So, the number of hot file replicas is given by(26)
 
where 
 
 is the average value of node storage space,  is the number of edge nodes, is the number of requested files. In this paper, CPU utilization, disk I/O utilization, memory utilization, and network bandwidth utilization are obtained by Ganglia program in Spark system to evaluate the cluster workload. (Wei et al., 2016) The load status of the node is expressed by(27)
 
where 
 denotes the current load of the  node, 
, 
, 
, 
 indicate CPU utilization, disk I/O utilization, memory utilization, and network bandwidth utilization, respectively.  is the weight of each variable affecting the current load of cluster, and 
. It is assumed that 
 is standard deviation of the  node. The smaller value of  is, the better load balance of the whole cluster keep. The standard deviation of cluster is expressed by(28)
 
where 
 is the average of the resource utilization of the entire cluster In this paper, a dynamic load threshold is formulated as(29)
 
 
where  is dynamic threshold of cluster, 
 is overall performance of node.

The process of responding user requirement is shown as Fig. 2. Assume that there are ten edge servers in the edge computing system. The distance of network transmission between any edge server and a user is different. When a user submits a request, a replica of required file stored in the nearest node will be transmitted to the user. For example, the transmission distance between the edge server and a user gradually increases from ES1 to ES10. When a user asks for requirements, ES1 is checked whether to store the replica of required file. If ES1 has stored the replica of requested file, the replica will be used to respond user. Otherwise, ES2 is checked whether to store the replica for satisfying user requirement. The above method is used repeatedly until the file is found in 10 edge servers to satisfy the user requirement. If the required replica is not stored in all servers, the replica will be transmitted from the original server, which may lead to higher transmission overhead. Our optimization goal is how to make these edge servers cooperate with each other to determine which required file should be stored in each server. So that the final bandwidth cost is the lowest. The above process can be abstracted as a replica placement problem. This problem can be described by integer programming constrained to 0–1 values in our strategy. Just like the common resource placement problem, the replica placement problem in our article is also NP-hard (Hwang et al., 2012) (Kang et al., 2018).

Fig. 2
Download : Download high-res image (262KB)
Download : Download full-size image
Fig. 2. The process of responding user requirement in edge cloud system.

Storing replica of the requested file in the edge node is essentially a resource placement problem (Hwang et al., 2012). This model of integer programming constrained to 0–1 values can be formulated as follows(30) 
 
(31)
(32)
(33)
(34)
(35)
where 
 is the data transmission cost from edge node  to edge server (i.e., ), 
 is the number of the  required replica (i.e., ),. If , the value of 
 is 0, i.e. the required replica is stored in the local edge sever. 
 denotes the  required replica whether to be stored in the edge node (i.e., ),. 
 is the size of the  required replica(i.e., ),.
 denotes the  required replica will be obtained by cloud node(i.e., ). 
 is the capacity of the  edge node(i.e., ). In this article, the integer programming problem is NP-hard. So heuristic algorithm is used to solve this problem. formula (34) denotes the user demand for replica will be met. The replica requested by user can be obtained from edge node or cloud server. Finally, the storage capacity of edge node set is limited by formula (35).

4. Proposed algorithms for automatic scaling and dynamic replica management
In this section, the pseudo-codes of the automatic scaling algorithm and dynamic replica management algorithm are described in detail.

The pseudo-code of the automatic scaling algorithm is shown in Algorithm 1. Firstly, the historical workloads are processed by the proposed load forecasting algorithm. And then the workload in the next time is predicted (Algorithm 1 line 1). Next, according to formula (6) (7) and (8), the virtual machine scaling cost of the resource-level, the virtual machine scaling cost of the virtual machine level and the license cost for the virtual machine level are calculated (Algorithm 1 line 4–5). The increased virtual machine processing power is obtained (Algorithm 1 line 6). Subsequently, the total cost and the capacity to process requests can be obtained (Algorithm 1 line 8–9). And then according to the constraints, the optimal scheme is obtained by the Tabu Search algorithm (Algorithm 1 line 10). In the last step, the optimal instances tenanted strategy is selected by the entropy method, AHP and TOPSIS method (Algorithm1 Line 11–13).

In Algorithm 1, for the load forecasting method, the number of data block is set to , the number of hidden layers of BP neural network model is set to  and the number of training samples is set to . Then, for the line 1, the time expense is . The time expense of the for-loops in line 3–7 is . For the line 10, when the number of iteration times for Tabu method is  and the data size is , the time expense is 
. So, for the whole auto scaling method, the time complexity is calculated as 
.

Algorithm1: The automatic scaling algorithm
Input: The set of the historical workloads of the edge host: 

The number of requests: , The number of requests used to process virtual machines of type : 

The number of virtual machine types: 
, The virtual machine of type : 
, The number of resource units available:

Increased number of virtual machines of type : 
, The number of resource units increased: 

The cost of the type  virtual machine, a unit resource and the license unit: 
, 
, 

Output: The set of the instance that will be tenanted in the next time 

1 
 //The workload is forecasted.
2 
 //According to the number of resource units increased and the cost of a unit resource, the virtual machine scaling cost of the resource-level is calculated
3 for each 
 do
4 
 //The virtual machine scaling cost of the virtual machine level
5 
 //The license cost for the virtual machine level
6 

7 end for
8 
 //The total cost consists of these three parts
9 
 //The capacity to process requests
10  //The optimal scheme is obtained by the Tabu Search method.
11. The subjective weight is calculated by AHP for each tenanted instance
12. The instances tenanted strategy based on TOPSIS is proposed
13 return 
When the hosts are running, with the change of the running state of the host, the virtual machines can be migrated dynamically between hosts. According to (15), (20), the expectation and standard deviation of total MIPS demand can be obtained, and the statistics change dynamically (Algorithm 2 Line 1–5). According to formula (21), the data migration strategy predicts the dynamic threshold  that the MIPS demand of host 
 may reach (Algorithm 2 Line 6). If the estimated dynamic MIPS demand value exceeds the maximum computing power that the host 
 can provide, 
 is considered overloaded. Some virtual machines are selected from 
 and moved out to avoid SLA violation (Algorithm 2 Line 7–8). If  is less than the computing power of 
, then the ratio  of the sum of MIPS demands of all virtual machines running on 
 to the computing power of 
 is calculated (Algorithm 2 Line 9–14). If  exceeds the preset static threshold 
, 
 is considered overloaded, or host 
 is not overloaded. Some virtual machines need to be selected from an overloaded host and migrated to other hosts (Algorithm 2 Line 15–16). In the migration strategy, at each migration, the virtual machine with the minimum migration time is selected. After the virtual machines in the high-load host are migrated, the processing strategy of the low-load host is adopted, all virtual machines on the low-load host are migrated to other hosts for reducing the number of active hosts energy consumption.

In Algorithm 2, for the for-loops in line 1–4, the time complexity is . In terms of line 8 and 16, Assuming that the number of virtual machines to be migrated is  and the number of target hosts is , the time expense of this sentence is . For the for-loops in line 10–12, the time complexity is . So, the time complexity for the whole data migration algorithm is 
.

Algorithm 2: The data migration algorithm based on dynamic threshold
Input: The overall expectation of the MIPS demands for virtual machine 
: 
.
The overall variance of the MIPS demands for virtual machine 
: 

The maximum computing power that the host 
 can provide: 

The preset static threshold of the MIPS demands: 
Output: The optimal data migration strategy: 

1 for each 
 do //the expectation and standard deviation of total MIPS demand
2  
 
 //The expectation of 
 is the sum of virtual machine running on the host
3 
 //The variance of 
 is the sum of the virtual machine running on the host
4 end for
5 
 //The standard deviation can be obtained by the variance
6 
 //The dynamic threshold is calculated
7 if 

8 
 //The virtual machines 
 are chosen to be migrated to the host 
9 else
10 for each 
 do
11 

12 end for
13 
 //The ratio of the sum of MIPS demands to the computing power
14 end if
15 if 

16 
//The virtual machines 
 are chosen to be migrated to the host 
17 end if
18 return 
 //The strategy that some virtual machines on 
 are chosen to be migrated to the host 
The pseudo-code of the replica placement algorithm is shown in Algorithm 3. According to the historical access frequency of the data blocks, the hybrid ARIMA and BP neural network algorithm is applied to predict the popularity of the data blocks in the next time (Algorithm 3 Line 2 and 10). According to formula (26), in the next time period, the hot data replica number is calculated (Algorithm 3 Line 3–6). Then, the cost for transmission is calculated (Algorithm 3 Line 7–8). Finally, the optimal strategy is selected by the heuristic method. (Algorithm 3 Line 9–18). And all files are sorted in descending order of the number of requests. Then, considering the load balance, the optimal replica placement scheme is introduced. in line 8–15. (Algorithm 3 Line 19–20).

Algorithm 3: The replica placement algorithm
Input: The historical popularity of the requested files: 
,The number of accessed replica,
The configuration of the nodes.
Output: The optimal replica placement strategy: 

1. for each 
 do
2. 
 //The popularity of each requested file in next time is calculated
3. 
 
 //The number of replica in next time is calculated
4. 
 //
is the total number of required replica , 
 is the number of required replica  in the edge node 
5. 
6. end for
7.  is calculated. //The network transmission cost
8. 
 
 is calculated. //The relative workload
9. 
 //All files are sorted in descending order of the number of requests and the replica of the most popular required file is placed in 
11. for each 
 do
12. 

13. if 

14. 

15. 
 is placed in the 
 //The replica 
 will be placed in the local node 

16. 

17. end if
18. end for
19. The optimal replica placement strategy 
 is obtained according to heuristic algorithm
20. return 
5. Performance evaluation
5.1. Experiment environment
As shown in Fig. 3, the experimental environment is divided into the edge cloud and the central cloud. One control node and nine computing nodes is the configuration of the edge cloud. The configuration of the edge cloud is shown in Table 2. In the data center, Aliyun is the cloud service provider of this experiment ([40] www.aliyun.com). Aliyun is currently the largest cloud provider in China. Aliyun provides a variety of cloud services, such as cloud servers, load balancing and relational data storage. In this experiment, the cloud server Elastic Compute Service (ECS) in Aliyun is used. The machine configuration of ECS can be changed at any time. And from a cluster perspective, it is convenient to add and remove machines. Two elastic computing server charge patterns can be chosen in Aliyun. One is to charge users a yearly or monthly fee. In this billing model, users need to pay for several months at a time, servers can also be used for a long time. This billing model applies to services that need to run for a long time, such as a web server, database, as well as the core module of system. Another way is pay-as-you-go. In this billing model, the cost is charged according to the configuration of the server and the usage time. This billing model is suitable for verifying the automatic scaling algorithm in this paper. So, the leased instances in the central cloud are charged according to this billing model. In addition, Aliyun also provides a rich Software Development Kit (SDK) for this mode, Apache Spark 2.4.5, and Apache Hadoop 3.3.0. Users can control the application and release of server resources with their own programs directly. However, when resources are applied through the SDK, CPU and memory cannot be randomly matched as in the console, and only a few templates provided by Aliyun can be selected. The main configuration templates rented in this experiment are shown in Table 3.

Fig. 3
Download : Download high-res image (365KB)
Download : Download full-size image
Fig. 3. The experimental environment.


Table 2. The configurations of nodes in Edge Cloud.

Node Role	Name	IP	Operation System	CPU	RAM	Hard Disk
Control node	con	192.168.0.24	ubuntu-19.04	24	32	1024
Compute Node	com1	192.168.0.56	ubuntu-19.04	24	64	2048
Compute Node	com2	192.168.0.21	ubuntu-19.04	24	64	2048
Compute Node	com3	192.168.0.14	ubuntu-19.04	24	64	2048
Compute Node	com4	192.168.0.20	ubuntu-19.04	24	64	2048
Compute Node	com5	192.168.0.23	ubuntu-19.04	24	64	2048
Compute Node	com6	192.168.0.58	ubuntu-19.04	24	64	2048
Compute Node	com7	192.168.0.28	ubuntu-19.04	24	64	2048
Compute Node	com8	192.168.0.16	ubuntu-19.04	24	64	2048
Compute Node	com9	192.168.0.26	ubuntu-19.04	24	64	2048

Table 3. The configurations of instance templates in Aliyun.

The instance specification	vCPU	Memory (GB)	Price in QingDao (¥/h)
ecs.t5-lc1m1.small	1	1	0.083
ecs.t5-lc1m2.small	1	2	0.167
ecs.t5-c1m2.large	2	4	0.4
ecs.t5-c1m4.large	2	8	0.63
ecs.t5-c1m4.xlarge	4	16	1.25
ecs.t5.c1m2.2xlarge	8	16	1.6
5.2. Test case
In the online shopping scenario, when the click volume of goods increases sharply, the hosts in edge cloud do not have enough capacity to process a large number of data. Instances in the central cloud need to be rented in advance. When the predicted number of clicks decreases, the instances that are rented in the central cloud are released earlier to save resources.

In order to evaluate the automatic scaling model, the dataset from Tianchi (https://tianchi.aliyun.co) is taken as the workloads. From 00:00:00 December 7, 2018 to 23:59:59 December 23, 2018, this dataset includes more than 1.4 million clicks from 355 different scenarios in a 6-days promotion season. As for the experiment of the dynamic replica management method, the dataset comes from Baidu Statics from (https://tongji.baidu.com/) 00:00:00 March 1, 2018 to 23:59:59 May 31, 2018. The page view and the unique visitor are the parameters of the dataset.

5.3. Benchmark algorithms
For showing the advantage of our proposed automatic scaling method, the cost-aware auto-scaling algorithm (CAAS) (Aslanpour et al., 2017b) and ML classifier algorithm (MLC) (Rahman et al., 2018b) are compared with our proposed algorithm. As for the data migration algorithm, the buffer-aware data migration algorithm (BA) (Lin et al., 2018) and Load-Aware Data Migration algorithm (LA) (Gao et al., 2017) are used for comparing. For verifying the effectiveness of the replica placement algorithm, the distributed data dissemination algorithm (DDD) (Aral and Ovatman, 2018b) and the write-aware replica placement (WA) (Chang and Wang, 2019) are chosen for comparing.

5.4. Evaluation metrics
For evaluating the effectiveness of the automatic scaling algorithm, total cost, the mean value of CPU utilization and the energy are taken as the performance parameters.

The formula of the mean value of CPU utilization is as follows.(36)
 

In the formula above, 
 is the CPU utilization of physical server , 
 is the computational ability of CPU in physical server .

According to the relationship between the mean value of CPU utilization and time , the power consumption is calculated. When the server is at full load, the electric energy consumed by the server is set to 
.  is the proportion of the energy consumed when the server is idle to the energy consumed when the server is full.  is the function of CPU utilization and time . Then the electric energy consumed by the physical server  is expressed as follows.(37)

Therefore, the total energy consumed by the physical server in a time period 
 can be expressed as follows.(38)

Moreover, the workload balance (WB) (Storch et al., 2018) is added as an evaluation index.  is expressed as follows.(39)
 
 
 

In the formula above, 
 is workload of node , 
 
 is the average workloads and denoted as 
 
. The value of  is smaller, more balanced the load.

In terms of the replica placement method, the free storage space 
 is proposed as the parameter for comparing. 
, where 
 is the used storage space.  is the overall storage space.

5.5. Experimental results and discussion
5.5.1. The performance verification of the TOPSIS and tabu algorithm
The simulation experiments are carried out to study Tabu and TOPSIS algorithms. The TOPSIS algorithm is implemented through CloudSim2.1.1 (Zaidi, 2018). CloudSim is an extensible simulation tool that can model and simulate cloud computing environments. Cloudsim can simulate the creation of a virtual machine in a node in a data center. It supports system and behavior modeling of cloud system components, which can be data centers, virtual machines, resource deployment policies, and so on. It implements a common approach to application deployment and can be easily extended. It supports the modeling and simulation of cloud computing environments with individual clouds and clouds connected across networks. In CloudSim, a simulated cloud environment has three main components: a data center, a host, and a data center agent. The data center is the resource provider in CloudSim. The effectiveness and efficiency of the proposed method are evaluated mainly by average task response time.

The simulation environment is configured as follows. A block of 800 MB in size is placed in a storage node. A datacenter, datacenter(), acts as a computing cloud that includes five computing nodes. The bandwidth between the five compute nodes and the storage node is 10, 9, 5, 16 and 7.2, respectively, in Mbit/s.

In this section, the average task response time of the TOPSIS algorithm in the replica placement strategy is verified. To make the results more general, 16 virtual machines on the mobile host are created. Each virtual machine requests different CPU and memory resources. The representative experiments were designed, in which the number of tasks submitted to the virtual machine gradually increased from 10 to 50. The service response time results of TOPSIS algorithm are shown in Fig. 4.

Fig. 4
Download : Download high-res image (107KB)
Download : Download full-size image
Fig. 4. The average task response time of the TOPSIS algorithm varies from the number of tasks.

Tabu algorithm was tested in elastic provisioning experiments under CloudSim simulation environment. The overall completion time of the task is used as the evaluation index.

5.5.2. Comparison and discussion
The lease of Aliyun will cause costs. In Fig. 6, the cumulative total costs of the automatic scaling algorithm at different times are shown. After the tenth hour of the experiment, the cost of our method is 110.1, the cost of CAAS algorithm is 134.5, and the cost of MLC algorithm is 119.1. Overall, the total cost of our method is lower than the cost of CAAS and MLC. The Table 4 denotes the parameter settings.

Fig. 6
Download : Download high-res image (160KB)
Download : Download full-size image
Fig. 6. The comparison of the cumulative total cost for different automatic scaling algorithm.


Table 4. Parameter setting.

Type	Parameter	Value range
Cloud Task	The number of task	(100,4000)
Instruction length (MI)	Randomly generated from 1000 to 5000
Virtual Machine	The number of virtual machines	10
Processing capacity (MIPS)	Randomly generated from 200 to 400
Virtual machine memory	4 GB
Bandwidth	500 Mbps
Data center	The number of data center	1
The number of hosts	6
The values of the CPU utilization in different time periods is shown in Fig. 7. For the CAAS and MLC algorithms, the workload in the next time period is not accurately predicted. Therefore, after a period of experiment, the CPU utilization of our method is higher than that of CAAS and MLC.

Fig. 7
Download : Download high-res image (147KB)
Download : Download full-size image
Fig. 7. The comparison of the CPU utilization for different automatic scaling algorithm.

In Fig. 8, the comparison of the power consumption for the different automatic scaling algorithm is shown. As the task number increases, the power consumption increases. Obviously, when the task number is the same, the power consumption of our method is lowest in the comparison experiment. When the task number ranges from 5 to 10, the power of the proposed algorithm ranges from 0.25 to 1.1 kw/h.

Fig. 8
Download : Download high-res image (122KB)
Download : Download full-size image
Fig. 8. The comparison of the power consumption for the different data migration algorithms.

In Fig. 9, when the control factor parameter  is different, the performance variation trend of the proposed data migration algorithm in different aspects is shown. As  increases, the predicted host utilization increases, the migration frequency increases, and the migration cost becomes higher. When the value of  is 0.003, the comprehensive performance  is better. So, in the later experiments, the control factor parameter is set to 0.003.

Fig. 9
Download : Download high-res image (211KB)
Download : Download full-size image
Fig. 9. The performance of the proposed algorithm varies with the predictive factor.

In the following, the response times for different data migration algorithm are recorded and analyzed. The response time of hybrid cloud storage is the time from when a user storage request is issued to the end In the experiment, a total amount of test data is randomly generated. The random operation algorithm and the file random selection algorithm are called. In this way, the total amount of operational data set is not less than the total amount of test data. One count is recorded and counted every hour. The response times of all requests that occurred during the test are averaged. To better simulate the usage habits of the users, the test starts at 9, 15, and 19. For making the test data more real and reliable, each set of data are tested for several times and the representative data are selected for statistics and analysis. Fig. 10 shows the relevant test data at the three test time points respectively. The abscissa is the number of record groups, and the corresponding value on the ordinate is the average response time of all requests in the experiment.

Fig. 10
Download : Download high-res image (378KB)
Download : Download full-size image
Fig. 10. The comparison of the average response time at different time.

From the three figures above, the average response time fluctuates with different test time points. The network performance and the size of selected file cause this result. On the one hand, when the data is migrated, if the network performance is unstable, the speed of network upload and download will be seriously affected. Moreover, the network interruption will cause the same file to be uploaded or downloaded for many times, and the common cloud needs to be replaced. On the other hand, because the request is generated randomly by random algorithm, the average response time is affected by the limitation of random algorithm and the size of selected file. As for the experimental result, compared with other data migration algorithms, the average response time of the data migration algorithm proposed in this paper is 10%–20% less.

In Fig. 11, as the number of data size increase, the load balancing reduces. The workload balance values of the three data migration algorithms are very similar. As the number of data size increases to 20 and above, the difference of the load balancing values of the data migration algorithms is distinct, and the proposed algorithm has less workload balance than BA algorithm and LA algorithm. As the number of data blocks increases to 100, the workload balance of the proposed algorithm is 76.2% lower than that of the BA algorithm, and 61.5% lower than that of the LA algorithm. The performances of the replica placement algorithms are compared in Fig. 12. In the data blocks, 3000 replicas are transferred the nine nodes and the size of data block is 128 MB. In Fig. 11, the available storage space ranges from 1200 GB to 1500 GB. The available storage space of our method is more balanced than the DDD method and WA method.

Fig. 11
Download : Download high-res image (125KB)
Download : Download full-size image
Fig. 11. The load balancing varies with different number of data blocks.

Fig. 12
Download : Download high-res image (159KB)
Download : Download full-size image
Fig. 12. The available storage space of all the nodes.

The main novel findings of our proposals are summarized in Table 5, Table 6, Table 7 as follows


Table 5. The comparison between our proposed automatic scaling algorithm and the benchmark algorithms.

The cumulative total cost	The CPU utilization (%)	The power (kw/h)
(Three hours after the experiment)
Our proposed method	Low	High	Low
CAAS	High	Medium	Medium
MLC	Medium	Low	High

Table 6. The comparison between our proposed data migration method and the benchmark algorithms.

The average response time (s)	The Workload Balance
(When the number of data blocks is added to 50)
Our proposed method	Low	Low
BA	Medium	High
LA	High	Medium

Table 7. The comparison between our proposed replica placement algorithm and the benchmark algorithms.

The available storage space (GB)
Our proposed method	Range from 1300 GB to 1450 GB
DDD	Range from 1290 GB to 1650 GB
WA	Range from 1150 GB to 1490 GB
The cumulative total cost is optimized by considering the costs of hardware, license and labor, reconfiguration and performance impact. So, the cumulative total cost of our proposed automatic scaling method is lowest in the experiment.

Because the historical operation information of the virtual machine is considered, the MIPS demand of the hosts can be calculated dynamically. The set of the static threshold is taken as the key factor in our paper, the time of data migration is predicted accurately.

The relative workload and the overall cost are considered in the proposed replica placement algorithm. The dependent variables of MOOP are comprehensive. So, the workload is more evenly distributed.

6. Conclusion
In this paper, we mainly study the strategies of automatic scaling and dynamic replica placement. Firstly, for reducing the total cost and waste of scaling resources, considering the costs of hardware, license and labor, reconfiguration and performance impact, the automatic scaling model based on service overhead is proposed. Before the resources are allocated, a hybrid load forecasting method is used to predict the workload in the next time. According to the workload in the next time period, the formula of total cost is formulated. Considering the constraints, the optimization problem can be regarded as a linear programming problem. Then, the Tabu algorithm is used to obtain the optimal scaling strategy. As for the dynamic replica placement, the proposed data migration algorithm is used for reducing the average response time. Then, the replica placement problem is considered as a MOOP.

In the performance verification of the experiment, the total cost of the proposed automatic scaling algorithm is 110.1, 18.14% lower than that of the CAAS algorithm, 7.56% lower than that of the MLC algorithm. The CPU utilization of our method is higher than that of the other two benchmark algorithms. In addition, the average response time and load balancing value of the proposed data migration algorithm is lower than that of the BA and LA algorithms. Compared with the BA algorithm, the proposed data migration algorithm reduces the workload balance value by 76.2%. Compared with the LA algorithm, the proposed method reduces the workload balance value by 61.5%. Moreover, the available storage space of the proposed replica placement algorithm is more balanced than the DDD algorithm and WA algorithm.

