Reverse analyzing of unknown protocol behaviors keeps being a tough nut in Protocol Reverse Engineering (PRE), which infers specifications of unknown protocols by observable information, especially when only transmitted messages are available. This paper proposes a novel protocol state machine model Stochastic Protocol finite-state Transducer (SPT) to describe the message interaction rules between communicating terminals in a probabilistic way attempting to simulate behavior rules of unknown protocols in certain implementation. Together with a state related field recognition and compensation method, a progressive SPT learning algorithm of unknown protocols named Sptia-PL, is designed and implemented to reconstruct the SPT of target protocol with the ability to predict succeeding behaviors. By updating the SPT progressively, the proposed method is able to learn continuously in linear time and remain the established model in optimal condition during the whole learning process. This strategy thoroughly avoids the state explosion problem existing in most state machine learning methods of PRE. Experiments on two open and three local collected datasets of FTP, SMTP and POP3 prove the rationality of SPT model and effectiveness of Sptia-PL algorithm by an average Accuracy over 0.94 and a Coverage close to 0.99. The small computing cost O(N) of this method and high confidence of results outperforms all the known state-of-the-art methods significantly.

Keywords
Protocol reverse engineering
State machine learning
Finite state transducer
State explosion problem


1. Introduction
To deal with the absence of protocol specifications in scenes such as IDS (Intrusion Detection System) (Liang et al., 2020; Deka et al., 2015), vulnerability discovering (Chen et al., 2019) and malware analysis (Wang et al., 2020), researchers are paying increasing attention on Protocol Reverse Engineering (PRE) to infer specifications of unknown protocols by observable information. Numerous schemes have been proposed to enhance result quality of PRE-based on static traffic analysis, dynamic program analysis, or both of them (Narayan et al., 2015; Ládi et al., 2020; Kleber et al., 2019). Among present achievements in PRE, target of this process usually falls into three aspects which are syntax, semantic and grammar. While many technologies have been developed on the first two issues, fewer literatures have been found working on protocol grammar inference (Kleber et al., 2019).

Normally, protocol grammars refer to behavior rules of that protocol, and it is usually regularized by state machines so as to rule orders of different transmitted protocol messages (Kleber et al., 2019). Reverse analyzing of unknown protocol behaviors could assist the analysts to understand present interaction patterns of different messages supported by target protocol, which makes monitoring, verification, and other relative security measures on protocol transition status become more practicable.

1.1. Motivation
In the present research of PRE, there are generally two different routines to infer protocol state machines, depending on whether the target protocol entity is available. If the entity of target protocol is available as an oracle, then protocol grammar induction based on active learning (Cho et al., 2010; Zhang et al., 2012) could be applied using algorithms such as Angluin's L∗ algorithm (Angluin, 1987) and QSM algorithm (Dupont et al., 2008) (a Query-driven State Merging induction approach) by sending queries to the entity and generate fairly accurate and precise state machines. While in many situations, IDS for example, entities of unknown or proprietary protocols are probably unavailable, which increases the difficulty of traffic monitoring. In these cases, rebuilding of protocol state machines resorts to grammar inference based on traffic messages, namely, passive learning (Duchêne et al., 2018).

Wisdoms of contributions in recent years have greatly promoted the research on message-oriented unknown protocol behavior reversing. Among these researches, two major issues are worthy of attention, which are protocol behavior state machine modeling and learning methods of corresponding models.

In the aspect of state machine modeling, several descriptive models have been applied to formulate protocol message exchanging grammars including Finite State Acceptors(FSA) (Lan and Mo, 1995), Probabilistic FSA(PFSA) (Ambainis, 1996), and Finite State Transducer(FST) (Casacuberta, 2000). As illustrated in Fig. 1, compared with FSA model, probabilistic information, which is a kind of inherent property in the data-oriented protocol behavior reverse (Kleber et al., 2019), is included in PFSA. FST collects the message responding information from bi-directional messages. Although PFSA and FST are more advanced than FSA with stronger expression ability on probabilistic information and message responding relationship, not a comprehensive model integrating both of them has been developed to describe or applied to reverse analyze protocol behavior grammars.

Fig. 1
Download : Download high-res image (212KB)
Download : Download full-size image
Fig. 1. State machines applied in PRE.

In the aspect of protocol state machine learning, a generally applied routine includes building a prefix tree of target model collecting enrich behavior information firstly, and then simplify this behavior model by combining similar states (Kleber et al., 2019). In this process, scale of the behavior model typically gets rather huge after the prefix tree is built. This not only takes up much memory space, but also makes the simplification process easily cost much computing time or even get struck in worst case, which is the classical state explosion problem in state model learning (Wen et al., 2017). Besides, merging rules of similar states have an important influence on the degree of generalization of the result behavior models and permissive rules could easily lead to overgeneralization of result models.

The above problems limit the expression ability of protocol behavior models thereby impedes the increasing of unknown protocol behavior reverse analyzing performance.

1.2. Contributions of this paper
Work of this paper deal with the problems existing in current research in two ways. A new protocol behavior grammar descriptive model is proposed to contain more integrated information of protocol behaviors including behavior probabilities and message responding relationships. A progressive learning method is designed and implemented in linear time to analyze behavior grammars of unknown protocols with the ability of avoiding the state explosion problem in learning process and getting result models in proper scale without overgeneralization, thus more comprehensive and accurate information about the target protocol behavior is reversed. Contributions of this paper is mainly in the following three aspects:

•
By analysis on the communication mechanism of internet protocols, the data-oriented unknown protocol behavior inference problem is formalized as a stochastic transducer learning process, and a Stochastic Protocol finite-state Transducer (SPT) model is defined formally to describe the message interaction relationships and analyze behavior probability distributions in recorded sessions. Equipped with statistic information, this model is also capable of predicting succeeding behaviors (Section 3).

•
Based on the formalized model, a progressive learning algorithm SPT inference algorithm by Progressive Learning (Sptia-PL) is designed and implemented to reconstruct the SPT from transmitted sessions of target protocol under assistance of a state related field recognition method. With a blue tail as buffer zone, a transducer is established in manner of a prefix tree and the blue tail is reduced progressively according to rules of states compatibility test. In this process, states explosion problem is avoided and the learned model is kept in best shape (Section 4).

•
The proposed protocol behavior learning method is applied to several protocols from different datasets. Comprehensive SPT models are achieved depicting reasonable behaviors of target protocols in proper scale. In comparison with state-of-the-art achievements, the advantage of SPT is reflected on best Accuracy, MSE(Mean Squared Error) and scale, with similar Coverage. Computing cost and result scales also support for the preponderance of this work (Section 5).

The rest of this paper is organized as following. Background and related work are introduced in Section 2. Section 3 contains intuitions and definition of proposed model. Section 4 explains design and analysis processes of the proposed method, including strategy of state related field labels recognition and algorithm details of Sptia-PL. Experiments and evaluations are described in Section 5. Section 6 summarizes work of this paper and discusses some future work.

2. Background and related work
In this section, present researches working on message data-oriented protocol behavior grammar reverse are introduced and summarized by their behavior models and reverse analyzing methods. Major contributions of them are collected in Table 1. Taking the introduction in Section 1.1 into consideration, problems existing in previous researches are also explained and discussed together.


Table 1. Major contributions of protocol grammar learning oriented on message data.

Method	Model	Probability	Interaction	Generalization	State explosion
ScriptGen (Leita et al., 2005)	FSA	No	No		
PEXT (Shevertalov and Mancoridis, 2007)	FSA	No	No		
Prospex (Comparetti et al., 2009)	FSA	No	No		Yes
Whalen et al. (Whalen et al., 2010)	PFSA	No	No		
ReverX (Antunes et al., 2011)	FSA	No	No	Yes	Yes
Veritas (Wang et al., 2011)	PFSA	Yes	No	Yes	
PRISMA (Krueger et al., 2012)	PFSA	Yes	No		Yes
PREUGI (Xiao et al., 2017)	FSA	No	No	Yes	
PRETT (Lee et al., 2018)	FST	No	Yes		Yes
ReFSM (Lin et al., 2020)	FST	No	Yes	Yes	Yes
ScriptGen (Leita et al., 2005) is generally deemed as a pioneering work of rebuilding unknown protocol state machines from traffic messages which creates a state machine labeling edges with client request messages and states with server answers. Although it indeed makes a difference between messages transmitted in different directions, but still loses the relationship between requesting and responding messages because the labels on states and edges in its model are relatively independent. This kind of missing responding relationship also exists in many other contributions modeling protocol behaviors by FSA, such as Prospex (Comparetti et al., 2009) and Veritas (Wang et al., 2011), which only analyze unidirectional messages or bidirectional but separate data.

In recent years, PRETT (Lee et al., 2018) and ReFSM (Lin et al., 2020) update this research by recording matchup relationships of bidirectional messages in their resulting state machines. This progress is rooted in the adopted protocol behavior model which is actually an FST, with the ability of recording and analyzing message interaction information, as illustrated in Fig. 1.

Nevertheless, although indicated in literature (Kleber et al., 2019) that statistic analysis should also be considered in the data-oriented protocol behavior reverse as an inherent property, those newly proposed methods leave the probability information left. Veritas (Wang et al., 2011) introduces Probabilistic Protocol State Machine (P-PSM) to represent reversed protocol behaviors and reconstructs this model by calculating frequencies of serially occurred state type pairs. Similar results are achieved by introducing Hidden Markov Model (HMM) to analyze probabilistic transitions of target protocol in literatures (Whalen et al., 2010) and (Krueger et al., 2012). However, the interaction information of messages is missed in those endeavors based on models in form of PFSA, as shown in Table 1. A remarkable interactive tool of PRE, Netzob (Bossert and Guihéry, 2012), is enabled to build a behavior model taking both message interaction and statistic information into account, but the requirement of protocol entities as oracles to infer state machine actively limits its capacity when only protocol messages are available.

In ReverX (Antunes et al., 2011), a typical routine includes constructing a Prefix Tree Acceptor (PTA) from sequences of message types and then reducing the automaton by a state merging algorithm is adopted to analyze unknown protocol state machines. In the reduction strategy of ReverX, all destination states of transitions labeled by same symbols are merged. However, this intuition of state merging is somehow coarse-grained which leads to an overgeneralization problem in its result models. Similar problems of less reasonable reduction strategies also exist in Veritas (Wang et al., 2011), PREUGI (Xiao et al., 2017), and ReFSM (Lin et al., 2020), which make the result models less specified to distinguish behavior model diversity. Besides, in the widely adopted process of constructing and reducing a PTA (Comparetti et al., 2009; Whalen et al., 2010; Lee et al., 2018; Lin et al., 2020), the scale of PTA and searching of similar states in succeeding reduction process usually take exponentially increasing space and computation cost, which as well bother analysts a lot.

In this paper, the proposed protocol behavior model is able to take both of the message interaction and behavior probability information into consideration. By a carefully designed behavior model learning method, the state explosion problem is effectively avoided and the reversed model is concise but not overgeneralized.

3. A stochastic protocol finite-state transducer model
In this section, the architecture of protocol communications system is analyzed firstly and a SPT model is defined to formalize the target of unknown protocol behavior reversing.

3.1. Intuitions and analysis of protocol interaction process
In our analysis of the factors influencing protocol behaviors, the exchanging of different messages types is controlled by mainly three sources: input messages, entity inner mechanism, and context system environment, and they work together on the response of messages. The architecture of a network communication protocol between two terminal nodes is illustrated in Fig. 2.

Fig. 2
Download : Download high-res image (256KB)
Download : Download full-size image
Fig. 2. Illustration of protocol communication architecture between two nodes.

Among these three factors, the targeted protocol transducer formulating behavior of this protocol terminal plays a leading role of messages exchanges, and it takes information from upper and lower protocols together with host system as auxiliary reference information.

Inside the protocol entity, the input message acceptor parses the incoming message, checks its validity, extracts useful control or payload information and feeds to protocol transducer or host system. After processing of the incoming messages, relative responding messages would be constructed by the output message generator. This step is under the control of the protocol message transducer deciding the kinds of response i.e. type of response message, and at the same time, taking the feedback information from system environment as reference. At last, the output messages would be generated and send back to counterpart of this network conversation.

In survey of Kleber et al. (2019), PRE-analyses are cataloged into eight process steps, among which format and semantic of messages and behavior model reconstruction make up the central targets of PRE. If we relate the three targets of PRE to the components of a network protocol, the format and semantic serve as references of the acceptor and generator when they parse or structure a communication message, and the behavior model rules the transducer which controls the response message. As we introduced in Section 2, previous achievements on protocol behavior model reconstruction mostly reverse partial information leaving the message exchange rules or statistic information behind. In the following, a more comprehensive formal model, SPT, is proposed to describe the behavior rules of unknown protocols when reversing from network traffics.

3.2. Formal definition of SPT
After the extraction of state related fields, each transmitted message should be represented by a message label recording the transmitting direction and message type. Thus, the message sequence in a communication session could be represented as Eq. (1):(1)
where one of the message exchanges, or one message transition in this session is represented by 
, 
 represents a request message, and 
 a response one.

As a model reverse analyzed from collecting of transmitted messages, the information recording frequencies or probabilities is indispensable (Kleber et al., 2019). Therefore, we attach relative statistic information to transitions and states in the proposed protocol behavior model in forms of frequencies in the analyzing process and probabilities in the final output model. Obviously, the probabilities of transitions and relative operations form a semiring .

Based on the above introductions and discussions, an SPT model to formulate the message exchanging or responding behaviors of an unknown protocol when it is reverse analyzed from network traces is proposed, as shown in Definition 1.

Definition 1

The formal description of an SPT over a semiring  is denoted as 
, where:

–
Σ is the finite input alphabet of the transducer composed of the incoming message labels of a protocol communication terminal;

–
 is the finite output alphabet of the transducer composed of the outgoing message labels of a protocol communication terminal;

–
 is the finite set of states;

–
 denotes the initial state of the communication process;

–
 is a finite set of transitions describing the message exchange behaviors. Associate with  a transition function  for every , as well as two projections: 
 and 
, with 
;

–
 is the weight function of transitions mapping  to , for two projections of 
 and 
: 
, 
;

–
 is the weight function of states finishing message transition operation mapping  to .

 and  are functions such that (Eq. (2)):(2)

This definition of SPT is based on the classical formulation of Weighted FST (Mohri, 2004), but has two characteristics.

(a)
Omit final states. The case of finite set of final states  is similar. The existing of finishing weight function enable the collecting of finite set of finishing states by 
. To keep the concise of this SPT model, the final states  are omitted.

(b)
Non-determinacy of transitions. Definition 1 is indeed a non-deterministic transducer when modeling reverse analyzing results from net-traces. Its nondeterminacy comes from two factors: enquiring behavior nondeterminacy and responding behavior nondeterminacy. Take FTP for example, after a connection is established, a client might request a file from the connected server or want to delete one, which leads to the uncertain of input symbols (). Relative responses from the connected server could be success or fail after checking whether the requirement is satisfied, which leads to the uncertain of output symbols (
). With sufficient privileges available, the latter uncertainty could be removed by checking constrains of host system environments. If we note the constrains as , then the transition function could be settled to 
. The analysis of  depends heavily on protocol terminal entities which is out of range of this paper, and we leave this for future work. (the  here is similarly defined as “data guard” in ReFSM (Lin et al., 2020))

An example of SPT model describing TCP message exchanging behavior (Fig. 3(a)), together with a classical TCP state diagram (Postel, 1981) (Fig. 3(b)) is shown in Fig. 3, noting that the probabilities are omitted and only responding behaviors are specified. Terminal inner operations colored by grey and message constrained relationships in Fig. 3(a) are omitted in Fig. 3(b), because analysis of those kinds of information needs comprehensive reversing of message syntax under the assistance of oracles (Cho et al., 2011). As discussed above, work of this paper focuses on the transition logic of unknown protocol messages and leave oracle-oriented message syntax analysis for future improvements. Beside those internal terminal operations and message inner field constrains, all behaviors of message exchanging of TCP are expressed in this SPT model (Fig. 3(b)). In fact, illustrations in Fig. 3 are sorts of simplified representations, and an integrated TCP behavior model with state maintenance and error controlling is further more complicated.

Fig. 3
Download : Download high-res image (474KB)
Download : Download full-size image
Fig. 3. Behavior descriptions of TCP.

Based on the proposed SPT model, weights of these transitions could be used to compute the probabilities of succeeding behaviors as defined in the following equations (Eqs. (3), (4)), thus equip this model with the ability of behavior prediction.(3)
(4)
 

4. Design of learning method based on SPT
An SPT learning method named Sptia-PL is designed and explained in this section. As illustrated in Fig. 4, the analyzing process is mainly composed of two steps which are label generation (Section 4.1) and model learning (Section 4.2). The first step deals with the initial message session traces, extracts state related fields and makes up suitable label sequences to support for following model learning process. The second step reconstructs a SPT model from label sequences by a series of analyzes including model construction, states merging, and computing probabilities in a progressive learning process. At last, an SPT model describing behavior logic of an unknown protocol could be obtained and used to analyze its message interaction features or predict its forthcoming messages or behaviors.

Fig. 4
Download : Download high-res image (441KB)
Download : Download full-size image
Fig. 4. Process of Sptia-PL.

4.1. State related field extraction and label compensation
Recognition of state related field works as a preprocessing part to support the learning of protocol state machines. Although it has been covered in many literatures, a brief analysis is still necessary. A relative rigorous recognition method is designed under some postulates in this part.

(a)
Preliminaries and postulates

In previous studies on reversing protocol state machines, state related fields are extracted in different ways, including VDV (Variance of the Distribution of the Variances) in Trifilò et al. (2009), messages cluster indicated types in (Shevertalov and Mancoridis, 2007; Comparetti et al., 2009; Krueger et al., 2012), and predefined delimiters (usually space character) in (Antunes et al., 2011; Lee et al., 2018). Whether by statistic features or relation analysis, the substantive characteristics of state related fields are still not clearly studied in present research. Take the cluster indicated message types for example, when facing an unknown protocol, we could not make sure whether certain communication state contain unique message type, and whether multiple communication states share same message types, though in most literatures states are considered to be triggered by message types variation by default. The problem of those methods based on predefined delimiters is more obvious. The delimiters of an unknown protocol could actually be any specified character as long as it is used to separate neighboring fields.

To focus on the reverse analysis of protocol message exchange behaviors, and avoid overmuch discussion on extracting of state related fields or state labels of messages, we make the following postulates on unknown protocol message state labels to simplify this task.

Postulates on unknown protocol message state related fields:

(1)
The state related fields exist in the heads of target protocol messages, which contain important communication formats and are not encrypted.

(2)
There exist single state related field in message format whose values could trigger transitions of protocol communication states.

(3)
The data distributions in same message fields on neighboring offsets has strong statistical correlation, but weak for that between different message fields.

In above postulates, the first item enables the extraction of state related field values possible and limits the searching space of message state labels in heads of messages. Analyzing of encrypted messages are out of the range of this paper, and have to resort to decryption of messages or protocol terminal oriented dynamic analysis (Wang et al., 2009; Caballero and Song, 2013). Postulate 2 excludes some complicated situations, such as communication states triggered by multiple fields or by system environment conditions, which need much more comprehensive analysis. Postulate 3 follows a common sense of message field data distribution, excluding some freak arranged message formats.

(b).
State related field recognition

Extraction of state related field resorts to segmentation of fields in message heads, and the relative segmentation method used in ProSeg (Sun et al., 2019) is adopted in our work. In ProSeg, Information Entropy (IE) and Mutual Information Saturation (MIS) of message data on different offsets are defined as shown in Eq. (5) and Eq. (6), where 
 is the collected data values on offset  in all selected messages. In Eq. (7), we rescale IE to  and call it IES (IE Saturation), where  is set to 8 when taking byte as basic data unit.(5)
(6)
 
 (7)

According to postulate 3 which also serves as a factual basis of ProSeg, the neighboring offset data sets inside same fields probably share relatively high and close MIS values, and those between two fields would have relatively low or local minimum MIS values because of their independence of value distributions.

In practice, even though the above field segmentation method could find the approximate locations of field boundaries, sometimes it might not be precise enough. The reason is that ProSeg presumes the lengths of fields in protocol message head to be fixed and that might fail on some protocols with variable-length fields which actually occupy a large proportion in existing known protocols.

According to our observation and analysis, protocols with messages composed of variable length fields usually have delimiters to separate neighboring fields, otherwise the protocol entity itself could hardly locate field boundaries. For an unknown protocol, if its state related fields have variable lengths, there probably exists a delimiter serving as a boundary of state related fields and following fields or parameters. Based on this intuition, we collect the data on offsets near the potential field boundaries recognized by MIS and IES, and the delimiter could be recognized by its significant high frequency.

A test on dataset ftp-lbnl is taken as an example to illustrate this analysis. As shown in Fig. 5(a), the first significant valley of MIS shows up on offset 3, indicating the probability of a boundary of two different format fields. A valley of IES turns up on offset 4 right after a valley of MIS, which indicates that a delimiter might be used as a boundary between adjacent fields. The value of IES on offset 4 is close to but has not reached to 0, and this might be caused by variation of former field lengths or noise. By collecting messages data on this offset, percentages of frequent values are computed as shown in Fig. 5(b), where “0 × 20” takes a great proportion and it is reasonable to take this value as a delimiter to fine the boundaries of state related fields.

(c).
Label compensation

Fig. 5
Download : Download high-res image (193KB)
Download : Download full-size image
Fig. 5. Data distribution in ftp-lbnl.

In Section 3.2, message sequences in protocol sessions are formulated in form of 
, with 
 as basic input(request)/output(response) message interaction tuples. While in practice, elements in i/o interactions are usually incomplete, i.e. one of the two is missing, such as 
. We deal with this case by inserting a null character  to take place of the missing input or output message labels, and in this way, 
.

The process of message label compensation is expressed in Algorithm 1. Take an SMTP communication session for example as shown in Fig. 6. After the label compensation process, labels of the messages in one interaction session would be padded with  to indicate blank behaviors. In each turn of i/o interactions, there are at least one i/o label, with the missing one compensated by .


Algorithm 1. Label compensation

Require: 
Enquire: 
1: 
2: for do
3:, 
4: for  do
5: if  then
6: if  is  then
7: 
8: else
9: add  to , set new 
10: else
11:, add  to , set new 
12: if  then
13: add  to 
14: add  to 
15: return 
Fig. 6
Download : Download high-res image (143KB)
Download : Download full-size image
Fig. 6. An example of label compensation.

In this work, we only deal with bi-direction interactions 
, which means we only consider a main class of communication protocols each with two interactive terminals in one session.

4.2. SPT inference algorithm based on progressive learning
Taking the state related filed labels recognized in Section 4.1 as inputs, logical organizations of request and response behavior sequences could be established and analyzed by proper algorithms. This section describes an SPT learning algorithm in a progressive learning way together with supporting functions including compensation test, merging of states and computing of behavior probabilities, thereby behavior transition model of target protocol could be successfully learned and established.

(a)
Design of Sptia-PL

Typical protocol state machine learning algorithms usually establish a prefix tree of communication sessions first and simplify the learnt model afterwards (Comparetti et al., 2009; Antunes et al., 2011; Lin et al., 2020), but almost all of them suffer from the problem of states explosion. The proposed transducer learning algorithm Sptia-PL (Algorithm 2) is designed to learn transition session sequences in a way of progressive learning. In other words, Sptia-PL keeps the main part of established model to be simplified throughout the entire learning process, adds new transition behaviors to a tail in limited length, and merges the tail into main part of this model when necessary. In description of this algorithm, main part of the learnt model is collected into a “RED” set, the tail into “BLUE” and we name it “blue tail” standing for a small fraction waiting to be simplified.


Algorithm 2. Sptia-PL Progressive learning

Require: S
, 
Enquire: SPT of target protocol 
1: Initialize 
 with , , 
 , , 
, 
2: S Label Compensation (
3: 
4: for each S do
5:
, 
6: BLUE
7: for each  do
8:, 
9: if 
 then
10:
, 
11: else
12: set new state , , 
13:
, , 
14: add  to , 
15: if  of  is  then
16:  first state in 
17: if , Sptia-PL CompatibilityTest
 then
18: 
 Sptia-PL StatesMerge
19: BLUE
20: else
21:, remove  from 
22:  Sptia-PL LearnProbabilities
23: return 
For ease of explanation, data from the sequences containing three typical SMTP transition sections as shown in Fig. 7 are token as an example to rebuild a behavior model of SMTP in the light of Algorithm 2. According to the second line in above pseudocode, these sequences would be compensated by Algorithm 1. In line 4–21, the expended sequences are learned one by one, and the queue BLUE of blue tail works as a sliding window. Whenever the blue tail is full, according to line 15–21, the first state in BLUE would be checked to find a state in BLUE to merge. As shown in Fig. 8(a) and Fig. 8(b), merging of states occurs when learning sequence  and , with states filled in yellow recognized as compatible states  and. In this example, we take  for brevity.

Fig. 7
Download : Download high-res image (153KB)
Download : Download full-size image
Fig. 7. Sample sequences to learn by Sptia-PL.

a.
220 EHLO 250 RSET 250

b.
220 EHLO 250 AUTH 235 MAIL 250 RCPT 250 DATA 354 Data Data Data Data 250 QUIT 221

c.
220 EHLO 250 AUTH 535 AUTH 334 Data 334 Data 235 MAIL 250 RCPT250 DATA 354 Data 250 QUIT 221

Fig. 8
Download : Download high-res image (593KB)
Download : Download full-size image
Fig. 8. Sptia-PL learning process.

(b)
States compatibility test and merging

In Fig. 8(c), a counting SPT model of three sequences is established. The last step of Sptia-PL is computing transition and finishing probabilities (line 22), and the result of this example is illustrated in Fig. 8(d). Rules of compatible test and states merging, together with probability computing method, are explained in Algorithm 3, Algorithm 4, and Algorithm 5, as will be introduced in the following.

In the field of state machine simplification, the rules testing compatibility of states control the manner these states be merged, and influence the performance of simplifying greatly. In Lin et al. (2020), a K-Tail mechanism is adopted to simplify the built prefix tree acceptor by comparing whether two trees rooted in state  and  have same structure and transition labels.

In the proposed Sptia-PL method, the compared two states  and  are actually from the whole simplified tree and partial blue tail, which are roots of a subtree and head of a queue separately. Therefore, in this way, the compatibility test is conducted by checking whether an inclusion relation existed, i.e., whether the blue tail is a branch of  rooted tree, as described in Algorithm 3. In Fig. 8(a) and (b), the red states  happen to be subtree roots with single branch. A more general case is shown in Fig. 9(a).


Algorithm 3. Sptia-PL CompatibilityTest

Require: 
, red node , blue node 
Enquire: whether two nodes could be merged
1: while 
 exist do
2: if 
 then
3:
, 
4: else
5: return false
6: return true
Fig. 9
Download : Download high-res image (271KB)
Download : Download full-size image
Fig. 9. Sptia-PL compatibility and merge of states.

Algorithm 4 describes how state  is merged into state . The transition leads to  is redirected to  (line 1–4), and then counts of all states and transitions in blue tail is added to relative branch rooted in  (line 5–8). The first step in this process is illustrated in Fig. 9(b).


Algorithm 4. Sptia-PL CompatibilityTest

Require: 
, , 
Enquire: merge state  into state 
1: for  do
2: if  then
3: 
4: break
5:while 
, 
, 
 do
6: 
7:
, delete transition 
8:
, 
, delete state 
9:
, delete state 
10: return r % return the last merged state
(c)
Compute transition probabilities

The computing of transition behavior passing probability and state stopping probability are ruled by equations δτ
 and 
, where  is a transition out of . Details are explained in Algorithm 5, and the finial form of inferred SPT model is like shown in Fig. 8(d).


Algorithm 5. Sptia-PL LearnProbabilities

Require: Counted transducer 
, , 
Enquire: Probabilistic transducer 
δρ
1: 
2: while  not empty do
3: pick  from 
4: 
5: for 
 do
6: 
7: 
8: 
9: 
10: return 
5. Evaluation and analysis
In this section, the proposed Sptia-PL method is evaluated and analyzed to assess the quality of recognized state related fields and learnt behavior model of unknown protocols. The evaluation of state related fields takes the official RFC (Request for Comments) documents of tested protocols as reference and acquire the true state labels with the assistance of Wireshark 3.4.7 (Orebaugh et al., 2006) (a widely used network protocol analyzer). To avoid the deviation of protocol behavior model construction introduced by human analysis, evaluation of the learned SPT models adopt three behavior prediction quality metrics, Accuracy, Coverage and MSE to measure effectiveness of the result model via captured data produced by certain implementations of unknown protocol instead of comparing with manually generated models. Scales of established models are measured by number of states and transitions to evaluate compactness of result models.

To reduce the influence of abnormal train data distribution, k-fold cross validation is introduced in the evaluation process, and  is set 10 to make sure the reasonable of results and the model is sufficiently trained.

At last, cost on time and space, together with scale of result models are compared between Sptia-PL and ReFSM (Lin et al., 2020) which adopts similar behavior model and learning strategies so as to check performance of proposed method on behavior learning of unknown protocols.

5.1. Experimental environment and data preparation
Programs implementing the proposed method is coded by Python 3.9. Wireshark 3.4.7 is used to collect the source datasets, filter out control sessions of target protocols and fetch true labels of messages for evaluation. All packages are decoded by Scapy (Biondi, 2005) taking message data as unknown protocols to analyze potential state related fields.

The adopted datasets are composed of three sources: two public datasets from LBNL(Lawrence Berkeley National Laboratory) (Pang and Paxson, 2003) and UPC(Universitat Politècnica de Catalunya) (Bujlow et al., 2015), and a local collected SMTP dataset containing 164 K messages in 1003 sessions sized 51 MB in communicating with 3 SMTP mail servers (smtp.163.com(25), smtp.126.com(25), smtp.qq.com(25), respectively). Details of these datasets are shown in Table 2.


Table 2. Datasets of testing protocols.

Dataset	Protocol	Source	Packages	Sessions	Size
ftp-lbnl	FTP	LBNL	10,358,330	24,036	220 MB
ftp-upc	FTP	UPC	1149	13	133 MB
pop3-upc	POP3	UPC	125,489	26	182 MB
smtp-upc	SMTP	UPC	194,572	67	55.3 MB
smtp-126	SMTP	Local-126	34,494	271	8.24 MB
smtp-163	SMTP	Local-163	88,166	487	27.1 MB
smtp-qq	SMTP	Local-qq	41,420	245	24.8 MB
sum:7	3	5	10.34 M	45.75 K	519 MB
5.2. Results of state related field labels extraction
In experiments comparing the recognized state related fields  with those labeled by Wireshark according to open specifications of these protocols . Precision and Recall are adopted to evaluate the quality of extracted labels by Eqs. (8), (9):(8)
 
(9)
 
where 
 is the collection of truth positive labels, 
 is the collection of false positive labels, 
 is the false negative labels, and 
 is the label of message 
.

The Precisions and Recalls of FTP and POP3 are all 1.0. For SMTP, the results are 0.9998 and 0.9992. These results prove the validity of the proposed unknown protocol state related field recognition method.

The recognized state related field labels ( set) are listed in Table 3 coded by ASCII (American Standard Code for Information Interchange). For the messages taking pure data as payload and have no significant state related fields, we label them “data” and omit this label in this table for simplicity. During the recognition process, four delimiters in total are found, which are: 0 × 20, 0 × 0d, 0x0a, 0 × 2d.


Table 3. Recognized state related labels.

Protocol	State related fields	No.
FTP	request: ABOR, ALLO, CDUP, CWD, DELE, HELP, LIST, MKD, MODE, NLST, NOOP, PASS, PASV, PORT, PWD, QUIT, REST, RETR, RMD, SITE, STAT, STOR, STRU, SYST, TYPE, USER, FEAT, OPTS, MDTM, MLSD, SIZE, EPRT, EPSV, LPRT, XCWD, XPWD, CLNT, MACB	38
response: 125, 150, 200, 202, 211, 213, 214, 215, 220, 221, 225, 226, 230, 250, 257, 331, 350, 421, 425, 426, 450, 451, 500, 501, 502, 504, 530, 550, 553, 400, 533	31
POP3	request: AUTH, CAPA, LIST, PASS, QUIT, RETR, STAT, UIDL, USER	9
response: ERR, +OK	2
SMTP	request: AUTH, EHLO, ehlo, DATA, data, MAIL, mail, QUIT, quit, RCPT, rcpt, rset	12
response: 220, 221, 235, 250, 334, 354, 451, 501, 535, 550, 553, 554	12
Among the recognized 69 state related fields of FTP, 36 request commands and 31 response codes are defined in different RFC documents including 3 obsoleted commands, “CLNT” and “MACB” are not defined officially but supported by some servers. Similar situation exists in recognized labels of POP3 and SMTP but no unofficial ones.

In recognized labels of SMTP, 5 request commands have both uppercase and lowercase, which in fact are recognized from datasets smtp-upc and smtp-126/163/qq respectively. As shown later in Fig. 11, similar transition behaviors exist in result models of different datasets with these two kinds of commands. This proves the case insensitive feature of this protocol which consists with the official specifications of SMTP.

Among the tested datasets, ftp-lbnl is also tested in ReFSM (Lin et al., 2020) to generate keywords as labels of state related fields, in which 26 keywords are extracted and 24 of them are included in Table 3. Beside these common labels, more 45 state related labels are recognized in this paper (results are same when only FTP of lbnl is tested). This verifies the powerfulness of this state related field labeling method on analyzed protocols.

From the above analysis we could find that this recognition method is able to find out all state related field labels of unknown protocols successfully under our postulates. For the tested three protocols, the recognized labels are completely consisting with those labeled by Wireshark which parses these protocols by open specifications.

5.3. Results of SPT model reconstruction
Fig. 10 shows the SPT models of FTP and POP3 reconstructed from dataset of upc. Obviously, the behavior model of FTP is more complicated than that of POP3, and this is in line with practical situation that FTP supports more operations.

Two SPT models of SMTP revised from smtp-upc and smtp-126 are illustrated in Fig. 11, with their common paths colored in red. In common sense, the implementation of same protocol should be consistent with its official definition, but some delicate differences might exist in different implementations in process of updating and iteration of this protocol. Although the differences presented in these results are more likely to be caused by differences of data distribution, these examples prove the ability of Sptia-PL to compare behavior rules between protocol entities. This analysis is supported by formal operation (Definition 1) and could be intuitive expressed in state graphs.

5.4. Evaluation of inferred model
As introduced in Section 1, the message sequences produced in protocol transition process is a kind of “outputs” generated by communicating terminals. In this process, all successfully transmitted messages and their orders should be regarded as effective whatever happens next. Even an incorrect message or a cancel request would also push the communicating process forward into different results. This is because a basic truth of network communication is that the already sent message cannot be withdrawn. Therefore, in this work, evaluation of a protocol behavior model is implemented on whole sequences of target protocol communication sessions to measure the behaviors of inferred model in a sufficient and reasonable way.

In this research, as the learned SPT model is probabilistic equipped with the ability to speculate possible succeeding behaviors, the evaluation of referenced model is regarded as a prediction problem on each transition of next possible behaviors. Accuracy and Coverage are adopted to measure the performances of inferred models, i.e. how good the learned SPT models could simulate the message exchange behaviors of target protocol by checking the ratio of accurately predicted behaviors and the ratio of covered behaviors. To measure the probabilities of possible behaviors in a higher confidence, MSE (Mean Squared Error) is introduced to evaluate the behavior prediction error loss between the inferred behavior probabilities and their true distributions. Details of these metrics are shown in the following (Eqs. (10), (11), (12)):(10)
 
 
(11)
 
(12)
 
 
where  is the sequence of behaviors truly composing the tested sessions,  is the collection of behaviors predicted by learned behavior model in each transition, and  is the set of all possible behaviors (including requests and responses). 
 stands for the distribution of 
 predicted by the learned behavior model. 
 is the true distribution of the i-th behavior in testing data which could be represented by 
. For each transition, the distance between behavior prediction and its true distribution is defined as the Euclidean norm of these two vectors as shown in Eq. (12). Among these equations, 
 is an indicator function and it gets value 1 when , else 0.

For the SPT model designed in this paper, when predicting the i-th behavior and the next one in behavior sequence 
 where 
 and 
, according to Definition 1, if the present state is 
, 
 and 
 could be computed by Eqs. (13), (14):(13)
(14)

For other behavior models, probability distributions of the predicted behaviors could be computed in similar way, as long as the transition function and its weight or probability function are available.

5.5. Influence of blue tail length
In Sptia-PL, the length of blue tail  is an important parameter which needs to be determined before practical applications. In the model learning process,  actually controls how precisely this model is simplified. When , all new states would be merged into the initial start state and get an extremely generalized result which transmit all behaviors back to . As  grows, the generalization degree of inferred model decreases and becomes increasingly specialized. When  is bigger than the longest message transition sequence, the result model becomes a prefix-tree of all learnt sequences with low generalization ability and could only be used to analyze those sequence included in the training set. In process of  growing, the variation of result model quality could be reflected in distributions of adopted metrics.

To balance the generalization and specialization abilities of learnt model,  is taken in this paper to build the behavior models of targeted protocols.

5.6. Evaluation result and comparison analysis
Three state-of-the-art probabilistic protocol state machine models and their inferring methods, P-PSM in Veritas (Wang et al., 2011), HMM in (Whalen et al., 2010; Krueger et al., 2012) and EFSM in ReFSM (Lin et al., 2020) are taken as comparisons to analyze the effectiveness and performance of proposed method. As the difference of datasets and work procedures, only the related state machine rebuilding parts of Veritas (Wang et al., 2011) and ReFSM (Lin et al., 2020) are re-implemented in this work for contrastive analysis. Although HMM has been used in Whalen et al. (2010) and (Krueger et al., 2012) to simulate protocol message sequences, we find it a tough work to reimplement their work for the absence of implementing details. As a compromise, the python library hmmlearn (https://pypi.org/project/hmmlearn/) implementing the parameter learning function, which is Baum–Welch algorithm (Tabar et al., 2018) actually, is adopted as an alternate.

In the testing results as shown in Table 4 and Table 5, Sptia-PL outperforms the compared methods greatly in Accuracy, MSE and scale, with comparable Coverage. With an average of 0.9414, Sptia-PL increases the behavior prediction ability more than 20%. The result of MSE is in similar situation and the average is 0.0922 which is pretty close to 0 and much smaller than those of other methods (0.3442 best), and so is the result of scale. Even though the result of Coverage is not always the highest, an average of 0.9890 is still good enough to ensure sufficient coverage of learned models.


Table 4. Testing result of Accuracy & Coverage.

dataset	Accuracy	Coverage
Sptia-PL	Veritas	HMM	Sptia-PL	Veritas	HMM	ReFSM
ftp-lbnl	0.8985	0.5209	0.6229	0.9949	0.9730	0.9901	0.9103
ftp-upc	0.9033	0.5712	0.5967	0.9463	0.9953	1.0000	0.8612
pop3-upc	0.9565	0.9024	0.8272	0.9911	0.9079	0.9992	0.4089
smtp-upc	0.9524	0.7643	0.8709	0.9967	0.9865	0.9883	0.9483
smtp-126	0.9335	0.6936	0.7942	0.9985	0.9992	0.9997	0.9014
smtp-163	0.9678	0.7325	0.8518	0.9963	0.9926	0.9985	0.9130
smtp-qq	0.9775	0.7438	0.8953	0.9992	0.9941	0.9983	0.9841
Average	0.9414	0.7041	0.7798	0.9890	0.9784	0.9963	0.8468

Table 5. Testing result of MSE & scale.

dataset	MSE	scale (
)
Sptia-PL	Veritas	HMM	ReFSM	Sptia-PL	ReFSM
ftp-lbnl	0.1602	0.7076	1.3490	0.5009	177/906	725/4037
ftp-upc	0.1450	0.4976	0.7203	0.3087	13/25	20/43
pop3-upc	0.0497	0.0924	0.5320	0.6969	11/18	17/23
smtp-upc	0.0854	0.3066	0.3085	0.1589	14/16	17/29
smtp-126	0.1078	0.3730	0.5271	0.3100	17/21	24/46
smtp-163	0.0542	0.3188	0.4951	0.2565	20/29	30/69
smtp-qq	0.0429	0.3036	0.3598	0.1777	16/19	21/41
Average	0.0922	0.3714	0.6131	0.3442	−/−	−/−
On all datasets, Accuracy of Sptia-PL keeps its advantage over other methods (more than 0.16 higher in average) and this superiority is more significant on datasets ftp-lbnl (0.28 higher) and ftp-upc (0.3 higher), even though the result drops a little bit but still around 0.9 when others are no more than 0.63. The result of MSE and scale is in same case. This feature in these comparisons reflects that the more complicating of target protocol and the larger the amount of data, the stronger learning ability this method has and better results could get.

In our research, the good performance of Sptia-PL could be contributed mainly to the introducing of SPT model to describe protocol behaviors which corresponds with actual interaction mechanisms of protocols, as explained in Section 3.2. The progressive learning process and states merging method according to “inclusion relation” promotes the performance of Sptia-PL a step further by loosening the merging gist from identical (K-Tail merging in Lin et al., (2020)) to similar (blue tail inclusion in Algorithm 3). Although this merging strategy introduces the problem of overgeneralization in some degree, the length of blue tail () could be set in a proper range as discussed in Section 5.5 to find a balance between generalization and specialization.

In short, Sptia-PL shows its significant advantage on Accuracy, MSE and scale in evaluation of all datasets with comparable Coverages, which proves that the rationality of introduced SPT model and effectiveness of Sptia-PL learning method, and that the smaller scaled inferred models of tested protocols are capable of predicting possible behaviors by probability distributions pretty close to reality.

5.7. Computation cost and result scale
For the similarity of Sptia-PL and ReFSM, and their close performances, computing cost on time and space, together with the scale of reversed models learned by these two methods are analyzed and compared in detail in this section.

(a)
Time cost

In the label compensation and Sptia-PL learning process, messages labels are searched in  where  is the number of messages. The state merging process takes 
 in best case and  in the worst-case scenario, where  is the number of states in SPT. As , the complexity of Sptia-PL could be approximated to , which is better than ReFSM (
).

Fig. 14(a) shows the time cost of the two compared methods in a workstation consists of an Intel Core i9-9820× @ 3.30 GHz (20-core) CPU with 128 Gbyte of system memory, on dataset ftp-lbnl with sessions sorted by length to keep the growth of tested message number at a constant speed. In the results, Sptia-PL keeps taking very little time as data quantity increases while growth rate of ReFSM keeps increasing in this process. When learning 2000 sessions, the proposed method takes only about 0.5s, while the other takes 55s, nearly 4 times of 14s when learning 1000 sessions.

(b)
Space cost

Fig. 14
Download : Download high-res image (239KB)
Download : Download full-size image
Fig. 14. Cost comparison.

The greatest advantage of Sptia-PL comes from the progressive learning strategy which completely avoided the tough nut of state explosion problem existing in almost all state machine learning methods based on prefix tree in PRE.

For methods based on prefix tree building (like ReFSM), the number of states in learned state machine reaches its maximum when building the prefix tree model and gets a huge state machine. When building a prefix tree of  session sequences in average length of , with each message in sequence having  possible state related labels, the number of nodes (states) could be  if no prefix exists and reach to 
 (number of messages) at most when enough sessions collected (). On the contrary, Sptia-PL learns sequences progressively and keeps the behavior model in most simplified condition with space cost of , and this strategy prevents the generation of superfluous states, thereby avoids the states explosion problem from the very beginning of this process.

Fig. 15(a) shows the maximum number of states in learning process of ReFSM and Sptia-PL which are also the equivalents of their space costs. When the curve of ReFSM keeps increasing as the number of learned messages grows, the curve of Sptia-PL only rises a little and keeps stable in a small value. The apparent discrepancy between these two methods proves the preponderance of proposed method in space cost.

(c)
Scale of result models

Scales of reversed models are compared in Fig. 15(b). Although ReFSM reduces off numerous redundant states, the optimal state number keeps growing as the number of learned sequences increasing, while the result of Sptia-PL stays less than 100 after a quick growing and is significantly less than that of ReFSM. In fact, the maximum state numbers in Fig. 15(a) are pretty close to those in Fig. 15(b) and the difference on same session number is no more than the length of blue tail , thanks to the progressive learning strategy of Algorithm 2.

Fig. 15
Download : Download high-res image (286KB)
Download : Download full-size image
Fig. 15. Model scale comparison.

The difference of result scales is mainly caused by the state compatibility test method. In Sptia-PL, a state inclusion compatibility evaluation method is adopted to decide whether two states could be merged as explained in Algorithm 3 which is a kind of approximate equivalence between states. The K-Tail mechanism adopted by ReFSM is an evaluation of equivalence relation and is stricter. Taking the result of Table 4, Table 5 into consideration, it can be amply demonstrated that Sptia-PL is capable of simplifying similar states (not just equal states) and making the result model specified and generated in appropriate extent.

6. Conclusion and discussions
This paper works on the message data-oriented behavior reverse analyzing of unknown protocols. Based on the proposed protocol probabilistic behavior model SPT which can reflect the interaction relationships of request and response behaviors, a progressive state machine learning method Sptia-PL is designed and implemented to reconstruct the SPT model of target protocol in linear time with the ability to predict succeeding behaviors accurately and efficiently.

In comparison experiments of related state-of-the-art achievements, Sptia-PL outstrips all compared methods by significantly higher Accuracy (0.94) and lower MSE (0.09) on behavior prediction with comparable Coverage (0.99). The model learning efficiency of Sptia-PL greatly outperforms the compared method by terser result models with smaller scale and linear complexity in both time and space. Analysis comparing with both probabilistic and non-probabilistic methods all proves the rationality of proposed behavior model SPT and effectiveness of designed learning method Sptia-PL.

In this work, the transition of states in process of protocol communicating is assumed to be triggered by state related field in each message, while this is a more complicated mechanism in practice as discussed in Section 4.1. Further comprehensive analysis could be made taking more message formats or system environment information into consideration. Combining Sptia-PL with the wisdom of data guard used in Lin et al. (2020) might be a nice try.

As a progressive learning algorithm, Sptia-PL could also be applied to analyze or compare different implementations of certain protocols, or behavior situations in different periods by variations of transition probabilities. This means the potential ability of this method in implementation verification of protocols and anomaly detection from the perspective of message interactions. We are working on these promising applications in prospect of more outcomes.