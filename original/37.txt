Abstract
Early diagnosis of mild cognitive impairment (MCI) is critical for reducing the incidence of serious neurodegenerative diseases. However, current diagnostic solutions, such as biomarkers and cognitive screening tests, are expensive, time-consuming, or not user-friendly. In this study, we designed cogSYS to explore the feasibility and accuracy of detecting MCI through one-minute hand motor function assessment. Inspired by a clinically validated screening test, cogSYS contains a series of touchscreen-based colorful block “drag & drop” tasks, including four unilateral gross manual dexterity single-tasks and three language function related dual-tasks for each single-task. We study how to design and optimize these interactive tasks, and evaluate them through three user studies (i.e., effectiveness verification, cortical activation analysis, and user experience feedback). Experimental results show that cogSYS can detect MCI effectively, with a mean accuracy of 82.4%. Furthermore, by statistical comparison on features, we discover that the velocity and time-based features of failure circumstance are the most effective among all the features. These discoveries can provide insights for follow-up research and clinical applications. Cortical activation analysis shows that bilateral prefrontal cortices, bilateral motor cortices, and the occipital lobe are involved in “drag & drop” tasks, proving the effectiveness of cogSYS in specific cognitive functions. User experience feedback shows that the subjects evaluate highly to cogSYS and provide valuable information for further improvements.

Previous
Next 
Keywords
Mild cognitive impairment

Hand motor function

Dual-task

Touchscreen

1. Introduction
Mild cognitive impairment (MCI), which involves problems with memory, logical thinking, judgment, and language, is an intermediate stage between the cognitive decline of healthy aging and severe pathologic decline of dementia (Burns and Zaudig, 2002). A recent study reveals that the incidence of MCI is 6.7% for ages 60–64, 8.4% for 65–69, 10.1% for 70–74, 14.8% for 75–79, and 25.2% for 80–84 (Petersen et al., 2018). Approximately 20% of the entire population of the United States may have some forms of MCI (Luck et al., 2017). In addition to the high prevalence rate, the dementia conversion rate of MCI is also alarming. According to the study of Ewers et al. (2007), patients with amnestic MCI progress to dementia at an annual rate of approximately 16%, whereas the conversion rate may be as high as 41% after one year and 64% after two years. MCI is also associated with many other neurodegenerative diseases, such as Lewy body disease, frontal lobar degeneration, and other disorders, known to impair cognitive function, such as Parkinson’s disease and stroke (Mentis et al., 2019).

Dementia still has no well-known cure. The alleviation of specific symptoms, especially in the early stage of the disease, is the only possible treatment (Fang et al., 2017b). Therefore, effective MCI diagnosis and paying attention to patients in this stage are considered fundamentally important (Zhou et al., 2014). However, in clinical environments, practical diagnosis is usually delayed for two reasons. First, many early signs of MCI are mild. Patients may confuse normal aging and cognitive impairment and not undergo clinical examinations during the early stages. Moreover, although several MCI screening tests target early detection, such as dementia filter tests (e.g., mini-mental state examination and clock drawing) and other diagnostic tools (e.g., positron emission tomography and magnetic resonance imaging), current diagnostic solutions are usually expensive, invasive, time-consuming, or not user-friendly. Effective MCI diagnosis is still one of the most difficult challenges in gerontopsychiatry (Gosztolya et al., 2019).

Several studies seek to detect MCI with motor function and cognition assessment. For instance, Montero-Odasso et al. assessed the gait of MCI individuals while doing a secondary task (dual-task paradigm), which could reflect their performance in basic daily activities (Montero-Odasso, Bergman, Phillips, Wong, Sourial, Chertkow, 2009a, Montero-Odasso, Casas, Hansen, Bilski, Gutmanis, Wells, Borrie, 2009b, Montero-Odasso, Muir, Speechley, 2012, Muir, Speechley, Wells, Borrie, Gopaul, Montero-Odasso, 2012). Through automatic speech recognition and natural language processing methods, Fang et al. attempted to identify the cognitive changes (e.g., attention, short-term memory, and word-finding) of MCI with linguistic analysis (Fang, Janwattanapong, Martin, Cabrerizo, Barreto, Loewenstein, Duara, Adjouadi, 2017, Fraser, Fors, Kokkinakis, 2019, Gosztolya, Vincze, Tóth, Pákáski, Kálmán, Hoffmann, 2019). Garre-Olmo et al. analyzed the handwriting of older adults with MCI to reflect their motor planning, dexterity, manual skills, and other cognitive-related abilities (Garre-Olmo, Faúndez-Zanuy, López-de Ipiña, Calvó-Perxas, Turró-Garriga, 2017, Kawa, Bednorz, Stepien, Derejczyk, Bugdol, 2017, Schröter, Mergl, Bürger, Hampel, Möller, Hegerl, 2003, Werner, Rosenblum, Bar-On, Heinik, Korczyn, 2006). MCI patients usually have difficulties in the instrumental activities of daily living (iADLs, i.e., using the telephone, mopping, or cooking) (Marshall, Rentz, Frey, Locascio, Johnson, Sperling, Initiative, et al., 2011, Perneczky, Pohl, Sorg, Hartmann, Komossa, Alexopoulos, Wagenpfeil, Kurz, 2006). Related research proves that the pathological disorders of cerebral cortex and neural pathways cause these kinds of motor function deficiency (Scherder et al., 2008a). Subtle motor function decline can be observed in iADLs over 10 years preceding the diagnosis of dementia (Peres et al., 2008). Therefore, the functional performance of older adults is an essential indicator that could promote the early detection of MCI (Patel and Holland, 2012).

In this paper, we aim to explore the feasibility and efficiency of assessing MCI through one-minute hand motor function assessment under the dual-task paradigm. Inspired by the commonly used and clinically validated screening test, box and block test (BBT) (Mathiowetz et al., 1985), we designed an interactive system cogSYS, which contains a series of “drag & drop” tasks. Specifically, cogSYS simplifies traditional MCI detection tests, such as handwriting and trail making tests, and replaces the detection process with repetitive blocks “drag” and “drop” movements. Furthermore, we enrich cogSYS with four varieties of unilateral gross manual dexterity single-tasks and three language function related dual-tasks for each single-task. A set of hand movement trajectory and language function related features are extracted automatically to capture the motor and cognitive symptoms of users. The hand movement trajectory related features include number, time, velocity, angle, and drop-point-based features. The language function related features include number and correct rate of number counting, animal names enumeration and seven subtraction. We conduct three user studies to evaluate the effectiveness of cogSYS. The first one is effectiveness verification, which aims to explore the detection accuracy of different tasks. Experiments on 61 subjects (including 20 MCI patients, and 41 healthy controls) show that cogSYS achieves satisfactory detection results, with the highest results on four metrics (i.e., accuracy, precision, recall, and F1 score) of 82.4%, 84.1%, 91.4%, and 87.5%, respectively. In addition, we also analyze the discriminated features through statistical comparison and find that the velocity and time-based features of failure circumstance are the most effective among all features. The second one is cortical activation analysis for researching the hand movement related brain network changes with functional near-infrared spectroscopy (fNIRS). We analyze the cortical activation patterns of 37 subjects (including 25 MCI patients and 12 healthy controls) on five main brain areas, namely, bilateral prefrontal cortices, bilateral motor cortices, and the occipital lobe. Experimental results demonstrate the effectiveness of “drag & drop” on specific cognitive testing and training. The last one is user experience study, which aims to explore the users’ subjective evaluation of our detection tasks. This study has 20 participants (including 10 neurologists, 10 engineers, and 10 older adults). Through semi-structured interview, the participants provide a positive evaluation of cogSYS. Meanwhile, the participants also provides some valuable feedback for further improvement.

The contributions of this paper are three-fold: 1) CogSYS, a MCI detection system, including various cognition assessment tasks, was designed, optimized, and developed in this study. 2) Through a machine-learning-based auxiliary diagnostic method, cogSYS achieves a comparable mean accuracy of 82.4%. In addition, through statistic-based key features analysis, we explored the most significant features to provide insights for further research and clinical applications. 3) Furthermore, we discuss the influences of “drag & drop” tasks on the cortical activation pattern, demonstrating the consistency of our designed goals and the involved brain areas.

The rest of this paper is organized as follows: Section 2 gives the research background of MCI detection. Section 3 reports the design and optimization of “drag & drop” tasks following three user studies to verify the effectiveness of our design in Sections 4, –6. Section 7 and Section 8 are discussion and conclusion of our research, respectively.

2. Related work
Our research is mainly related to hand motor function assessment, the dual-task paradigm, and MCI detection. In this section, we discuss these areas and their intersections.

2.1. Hand motor function assessment in MCI detection
Studies have proven that a relationship exists between cognitive decline and hand motor function (Scherder et al., 2008b). In a four-year longitudinal user study, Curreri et al. found that older adults are at high risk of developing cognitive decline once they begin to spend more time in simple hand motor function tasks, such as putting on and buttoning a shirt (Curreri et al., 2018). Changes in hand motor function are essential indicators of MCI and other neurodegenerative diseases (Carment, Abdellatif, Lafuentelafuente, Pariel, Maier, Belmin, Lindberg, 2018, Tian, Fan, Fan, Zhu, Gao, Wang, Bi, Wang, 2019). Health monitoring based on convenient and objective hand motor function measure is of great significance in evaluating chronic diseases and improving people’s life quality. This kind of assessment can potentially provide a glimpse of a patient’s health situation beyond that usual diagnosis method can provide (Lee et al., 2016).

Many researchers seek to find more effective approaches for MCI diagnosis. Among all related studies, analyzing the kinematic character of handwriting has been proven a valid method. In addition to the velocity and acceleration of hand movement, even subtle motor abnormalities can be detected with handwriting analysis. In 2003, Schröter et al. used kinematic handwriting analysis to compare the fine hand motor function of four groups of subjects, including patients with dementia, MCI and depression and a healthy control group (Schröter et al., 2003). Their experimental results reveal that patients with dementia and MCI show poor fine hand motor performance. However, Schröter et al. only designed one kind of task (i.e., concentric circle drawing task) and extracted limited features (i.e., velocity) in their study. To explore further, Werner et al. enriched the design tasks and the extracted features (Werner et al., 2006). Specifically, Werner et al. designed five different functional tasks and measured the hand motor function of older adults in terms of three kinds of characters (i.e., temporal, spatial, and pressure features). Afterward, Kawa et al. used both dynamic and spatial features to realize a reliable, inexpensive, and fast MCI detection system (Kawa et al., 2017). They found that effective feature extraction could promote MCI diagnosis. Meanwhile, Garre-Olmo et al. also extracted several kinds of kinematic handwriting and drawing features to discriminate patients with MCI and dementia from healthy controls (Garre-Olmo et al., 2017). Furthermore, they discovered that the qualitative combination of features rather than the dimension of features were relevant to discrimination accuracy.

Researchers also studied other upper extremity function assessment methods and their relation to MCI (Aggarwal, Wilson, Beck, Bienias, Bennett, 2006, Franssen, Somen, Torossian, Reisberg, 1999, Hebert, Bienias, Mccann, Scherr, Wilson, Evans, 2010). Aggarwal et al. used the 30-s Purdue Pegboard Test to measure the manual dexterity of MCI patients (Aggarwal et al., 2006). This test requires subjects to place as many pegs in the right place as possible, and their performance is scored according to the number of correctly placed pegs. Similarly, Hebert et al. evaluated the upper extremity function with the Purdue Pegboard Test (Hebert et al., 2010). They also used another manual dexterity assessment test, named finger tapping, was used simultaneously, which required the participants to tap a button with their index finger. The duration of finger tapping was ten seconds. Franssen et al. examined the coordination of the lower and upper limbs among healthy controls patients with MCI and mild dementia (Franssen et al., 1999). The function of the upper limb was assessed with two movements, namely, alternating pronation and supination, and sequential finger to thumb tapping. The function of the lower limb was assessed with the parametric measurements of foot tapping.

However, many hand motor function assessment tasks, such as handwriting, drawing, and limb coordination, are complex and non-unitary human activities. The performance in these tasks is influenced by multiple factors, like educational level, intelligence, and personality (Lemke and Kirchner, 1971). Hence, simple and easily used hand motor function assessment tasks must be designed to detect MCI effectively.

2.2. Dual-task paradigm in MCI detection
The dual-task paradigm is a commonly used experimental procedure that requires individuals to perform two different tasks simultaneously. It is an encouraging procedure for estimating the cognitive status and may also be used to reduce cognitive decline (Aoki et al., 2019). In real experimental scenarios, the performance under the dual-task paradigm is usually compared with that in single-task conditions. Dual-task related cognition assessment is promising because it is sightly influenced by educational level, and this kind of task is fast, practical, and easy to apply through clinical practice (Ansai et al., 2016).

Some studies suggest that the gait performance under the dual-task paradigm is associated with cognitive impairment (Aoki, Thanh, Mitsugami, Okura, Niwa, Makihara, Yagi, Kazui, 2019, Montero-Odasso, Bergman, Phillips, Wong, Sourial, Chertkow, 2009a, Montero-Odasso, Casas, Hansen, Bilski, Gutmanis, Wells, Borrie, 2009b, Montero-Odasso, Muir, Speechley, 2012, Muir, Speechley, Wells, Borrie, Gopaul, Montero-Odasso, 2012). Montero et al. recruited 11 older adults with MCI and evaluated their performance under single-task and dual-task conditions (Montero-Odasso et al., 2009b). Through the analysis of six gait features, including gait velocity, stride length, step length, stride time, double support time, and step time, Montero et al. found that the mean gait velocity decreases significantly and the time-related features are less regular under the dual-task condition than under the single-task condition. Furthermore, Montero et al. also researched the relationship between gait velocity and specific cognition ability (Montero-Odasso et al., 2009a). They designed one walking task and two dual-tasks (i.e., walking while counting backward and walking while naming animals). Through a user study covering 55 subjects, they found that working memory and executive function have an identifiable effect on gait performance. Afterward, in 2012, Montero et al. conducted a research to explain the reasons for the high risk of falls (Montero-Odasso et al., 2012). By comparing the gait performance of patients with MCI and the healthy controls under two different dual-tasks, they found a significant between-group difference in terms of gait variability. Muir et al. also considered the influence of dual-task among older adults without cognitive impairment, patients with MCI, and patients with dementia (Muir et al., 2012). From clinical validation, they found that dual-task could expose the imperceptible gait impairments under single-task. All the studies above used an electronic walkway to quantify the gait variables. Recently, Aoki et al. improved the movement performance capture method with a Kinect camera to extract more substantial gait features (Aoki et al., 2019). Using a complete feature set, they obtained results in dual-task condition that are superior to those in the single-task condition.

The existing MCI detection method based on the dual-task paradigm mainly concentrates on lower limb motor function assessment. However, upper extremity weakness and ataxia are also common in cognition-related diseases (Kluger, Gianutsos, Golomb, Ferris, George, Franssen, Reisberg, 1997, Scherder, Dekker, Eggermont, 2008b). Furthermore, measures of the upper extremity or hand motor function under dual-task conditions may provide more alternative MCI detection methods.

2.3. MCI detection techniques
With the development of monitoring sensor and computing technologies, numerous studies are using the intelligent approach to detecting MCI automatically. In addition to the aforementioned automatic approaches, some researchers try to detect MCI by speech recognition and in-home monitoring.

Spontaneous speech is a complex production involving multiple cognitive domains, such as language ability, attention, working memory, and planning. Thus, subtle changes in speech can be observed a few years or even decades before the diagnosis of dementia (Ahmed et al., 2013). Recent works have proven that the analysis of speech ability may promote the discovery of sensitive behavioral symptoms of MCI (Fang, Janwattanapong, Martin, Cabrerizo, Barreto, Loewenstein, Duara, Adjouadi, 2017, Fraser, Fors, Kokkinakis, 2019, Gosztolya, Vincze, Tóth, Pákáski, Kálmán, Hoffmann, 2019). To realize automatic MCI assessment system, Fang et al. attempted to use natural language processing technology to extract effective features in linguistic ability (Fang et al., 2017a). Their study supports the signification of linguistic complexity changes as a biomarker for MCI diagnosis. Gosztolya et al. went further, and they exploited two kinds of features, namely, acoustic and linguistic features, to build a machine learning model. Their recognition methods can differentiate healthy controls from patients and MCI from dementia simultaneously. Fraser et al. improved the discriminant accuracy with multilingual word embedding (Fraser et al., 2019). They found that diagnosis models trained with data from different languages are more effective than those trained on monolingual data. Their study proved the hypothesis that speech can detect subtle language changes, even at the early stage of MCI.

Direct and real-time monitoring of the behaviors of older adults can promote the diagnosis of MCI and provide a critical time window for early interventions. According to a recent systematic review, real-life MCI detection based on smart home sensors could help identify and clarify the functional performance difficulties of older adults in daily life (Lussier et al., 2018). For this review, 13 studies based on real home environments and four studies based on scenario assessments were investigated, with the conclusion that smart home technologies have a promising potential for the early screening of MCI. However, these kinds of assessment methods are still limited by some factors. First, related experiments are usually conducted in the presence of evaluators in an unfamiliar environment, which may influence the experimental results. Second, current research could only assess sporadic and rapid movements and not the entrenched deficits in the everyday routine of older adults.

2.4. Existing cognitive assessment system
In addition to the published literature, we are also concerned with the commonly used and commercial cognitive assessment systems:

•
Box and block test (Mathiowetz et al., 1985): The BBT is a clinically validated test developed for measuring hand dexterity. It is a quick, simple, and inexpensive test and can be used on a wide range of patients, including those with hand function deficits caused by cognitive aging. The BBT uses a wooden box divided into two compartments by a partition in the middle, and 150 blocks are placed at one side of the partition (Fig. 1). During the test, the subject has 60 s to move, one by one, as many blocks as possible from one compartment of the box to the other of equal size using his/her test hand. The number of displaced blocks is a measure of hand dexterity. A high number indicates good hand dexterity.

Fig. 1
Download : Download high-res image (324KB)
Download : Download full-size image
Fig. 1. The components of box and block test, including wooden box, partition, stopwatch and wooden cubes.

•
Trail Marking Test (Ashendorf et al., 2008): The Trail Marking Test (TMT) is also a commonly used neuropsychological test that is sensitive to impairments in multiple cognitive domains, particularly in visual attention, visual search speed, mental flexibility, executive functioning, and task switching. In the test process, subjects are required to connect 25 discrete dots, and they will be scored from the accuracy and speed aspects. In the test process, subjects are required to connect 25 discrete dots and scored in terms of accuracy and speed.

•
66nao Brain Training (Tang et al., 2016): 66nao is a digital platform for brain assessment and training, which provides scenario simulation and interactive games for cognitive assessment. It is characterized by intelligent computing and powerful data statistics. Specifically, 66nao can customize training tasks for different users and provide statistics of the training results in a timely manner.

•
RehaCom (An et al., 1997): RehaCom is a psychological test that aims to assess cognitive performance and improve cognitive capacities. RehaCom can evaluate and train various cognitive abilities of users, including attention, memory, executive functions, visual field, and visuo-motoric coordination. Moreover, RehaCom can satisfy the training need of users in all phases of cognitive rehabilitation.

2.5. Summary of the existing primary studies
The previous four sections (i.e., 2.1 Hand motor function assessment in MCI detection, 2.2 Dual-task paradigm in MCI detection, 2.3 MCI detection techniques, and Section 2.4) review existing studies. Here, we present a summary. Table 1 summarizes 45 primary studies, including their main contributions and limitations. Table 1 indicates that various factors usually limit the existing studies. Researchers, neurologists, patients, and caregivers share an eager passion for developing convenient and accessible systems that can provide automatic and objective MCI assessment. This kind of system can promote timely diagnosis and valid improvement of a potential patient’s life quality through early intervention.


Table 1. Summary of 45 existing primary studies, including their main contributions and limitations.

Studies	Main contributions	Limitations
Scherder et al. (2008b), Curreri et al. (2018), Carment et al. (2018), Tian et al. (2019), Lee et al. (2016)	Prove the relationship between cognitive decline and hand motor function.	Usually complex, non-unitary human activities.
Schröter et al. (2003), Werner et al. (2006), Kawa et al. (2017), Garre-Olmo et al. (2017)	Analyze the effect of handwriting on cognitive assessment.
Aggarwal et al. (2006), Hebert et al. (2010), Franssen et al. (1999)	Analyze the effect of the upper extremity function on cognitive assessment.
Ansai et al. (2016), Aoki et al. (2019), Montero-Odasso et al. (2009a), Montero-Odasso et al. (2009b), Muir et al. (2012), Montero-Odasso et al. (2012)	Validate the relationship between cognitive status and gait performance under the dual-task paradigm.	Mostly concentrated on lower limb motor function assessment.
Ahmed et al. (2013), Fang et al. (2017a), Gosztolya et al. (2019), Fraser et al. (2019)	Explore the influence of speech on cognitive decline.	Only significant to certain types of cognitive decline.
Lussier et al. (2018) and the 17 related studies in Lussier et al. (2018)	Explore MCI detection based on in-home sensors.	Usually in unfamiliar environments and only assess sporadic and rapid movements.
BBT (Mathiowetz et al., 1985)	Provide a quick, simple, and inexpensive detection method.	Need the participation of neurologist.
TMT (Ashendorf et al., 2008)	Sensitive to multiple cognitive domains.
66nao (Tang et al., 2016)	Characterized by intelligent computing and powerful data statistics.	Complex cognitive assessment system.
RehaCom (An et al., 1997)	Evaluate and train various cognitive abilities.
3. Design of “Drag & Drop” tasks
Hand motor function assessment plays an essential role in MCI detection. Although existing methods (e.g., handwriting and drawing feature analysis) provide some insights, most of them are complex and easily influenced by personal factors. To design easy-to-use assessment tasks on hand motor function, we must understand the clinical MCI detection procedure and the psychology of potential older adults with cognitive decline better. In the design process, we focused on the following: 1) current MCI diagnosis methods in the clinical environment, their issues, and how people evaluate them; 2) psychology of older adults, their preferences, and cognitive limitations, which are the key points that should be given more attention. Fig. 2 presents the key stages of the design, which underwent five main iterations and took 14 months. Every stage involved different stakeholders, as indicated by colorful squares. The development team was composed of four neurologists, four nurses, and seven engineers, who participated in the entire design process. In addition to the development team, we also invited 29 MCI patients, nine healthy older adults, and 15 caregivers to participate in the design process and elucidate the needs of MCI patients and test our prototypes. With these stakeholders’ participants, we determined our overall design, enriched the designed tasks, and optimized our design. Specifically, we designed a series of easy-to-use interactive tasks based on touchscreen, which was inspired by the traditional BBT. These tasks can be completed by just “drag” and “drop” of colorful blocks, named “drag & drop”. In the following section, the design process, the basic “drag & drop” task, the enriched detecting tasks, and tasks optimization are discussed in detail.

Fig. 2
Download : Download high-res image (923KB)
Download : Download full-size image
Fig. 2. Key stages of the design process, including the timelines, the main works in every stages (explain with simple text and colorful rectangles), the main participants in every stages (indicate with colorful squares), and the interface of four prototypes.

3.1. Design process
As an introduction, we classify the design process into symposium, programming, and interview, and indicate these processes with different rectangles in Fig. 2. Here, symposium mainly involves the communication between neurologists, nurses, engineers, MCI patients, and caregivers; interview involves the semi-structured communication with MCI patients, healthy older adults, and caregivers; programming expresses the development process, which is mainly the work of engineers. The participant older adults and caregivers were mostly from the Rehabilitation Hall of National Research Center for Rehabilitation Technical Aids1 and Aging-Friendly Nursing Home2. In addition to the participants in the pilot study (I4 in Fig. 2) and the field study (I5 in Fig. 2), every older adult and caregiver received a gift in return, such as a towel, a thermometer, and a shoehorn. Given that the pilot and field studies took a relatively long time, we paid every participant 100 RMB. All the participants provided informed consent before the interview.

•
Choose BBT for further exploration. D1 (i.e., the first symposium in Fig. 2) was our initial design exploration, which aimed to analyze the current primary studies and determine the direction of our exploration. Four neurologists, four nurses, seven engineers, five MCI patients, and five caregivers participated. We surveyed approximately 200 previous studies and selected 45 of them for detailed analysis, including 41 published works and four commonly used tests. Their main contributions and limitations are summarized in Table 1. Five MCI patients were invited to test the existing cognitive assessment systems (i.e., BBT, TMT, 66nao, and RehaCom), which were evaluated in terms of effectiveness, whether the subject can complete the test, and the subjective assessment of the subject. Only two subjects completed all the basic tests of 66nao and RehaCom, four subjects completed the TMT, and all subjects complete the BBT. Here are some frequent conversations: Experimenter: “Do you understand the rules?”

Subject: “I am healthy. I do not want do this task.”, or

Subject: “I am tired. I cannot continue.” Subject: “What are the scores of others?”, or

Subject: “Are other people doing better than me?”

Through this pilot study, we found that older adults prefer easy tests and like to compare with others. Thus, considering the above factors, we decided to develop an automatic, convenient, and time-consuming cognitive assessment system based on the BBT.

•
Determine the touchscreen-based solution. D2 (i.e., the second symposium in Fig. 2) compares five possible solutions for the automatic BBT:

1) Digital BBT using a deep camera to recognize the BBT components (Zhao et al., 2013);

2) Motion-sensor-based automatic system, which uses infrared, force, and accelerometer signals to measure the movement of users (Lee et al., 2018);

3) Wearable system, which uses wearable sensors on the wrist of users to recognize their movements (Zhang et al., 2019);

4) Automatic system that is integrated into virtual reality and gesture recognition (Alvarez-Rodríguez et al., 2018);

5) Touchscreen-based block drag and drop system. Four neurologists, four nurses, and seven engineers participated in the investigation and discussion, and the fifth solution was the most popular for its convenience and generality.

•
Develop basic “drag & drop” task and enrich the detecting tasks. [C1, I1], [C2, I2], and [C3, I3] are three interactive development processes. Four neurologists and 15 MCI patients participated in the interviews. The MCI patients in every interview were from the Rehabilitation Hall of National Research Center for Rehabilitation Technical Aids. In [C1, I1], we developed the first version of the touchscreen-based “drag & drop”. We recruited five MCI patients to test prototype I, with a semi-structured procedure to introduce the test rules, asked them to use it, and inquired about their experience. All MCI patients in I1 could understand the test rules and finish our test. They think this test is easy to use and user-friendly. The neurologists interviewed think that cognition is associated with multiple abilities, such as attention, memory, executive functions, and the visual field. Prototype I must be enhanced, and we attempted to in [C2, I2] and [C3, I3]. [C2, I2] was a failed attempt that obtained negative feedback from both MCI patients and neurologists. In [C3, I3], a mature version was initially formed. Details about the design motivation are presented in Section 3.3.

•
Design optimization. After completing the first mature version (i.e., prototype III), we conducted another interview in the Aging-Friendly Nursing Home with four MCI patients, four healthy older adults, and 10 caregivers. The members here are generally older, and the MCI patients have more pronounced symptoms. We also employed a semi-structured interview procedure, in which we introduced the test rules, asked subjects to use the prototype III, and inquired about their experience. In the assessment process, we found the subjects often confused different blocks and target areas and found all the tests difficult to finish. Thus, we decided to optimize prototype III further, and details about the optimization are presented in Section 3.4.

•
Pilot study to prepare for three field studies. Prototype IV is the optimized version. Then, we conducted a pilot study (I5 in Fig. 2) to prepare for the field study. Five MCI patients and five older adults without cognitive impairment from Rehabilitation Hall of National Research Center for the Rehabilitation Technical Aids and nearby communities were recruited in I5. The pilot study aims to explore whether older adults can finish the test and need tips. Study results show that all participants could finish the test, while some minor deficiencies still influence their user experience, such as an accidental touch on the virtual key of the equipment. Therefore, we further fixed the bugs discovered in P5 (Fig. 2). S4 is the symposium for discussing the field study plan, and I6 is the user study presented in Sections 4–6.

3.2. Basic “Drag  Drop” task
Referring to the clinically validated BBT, we designed the basic “drag & drop” task. As shown in Fig. 3(a), the “drag & drop” task is composed of the start area, the target area, the partition, and 100 colorful blocks (25 blocks for each color). In the testing process, the users must “drag” the blocks from the start area and “drop” them to the target area one by one within 60 s without restrictions on block selection. In 60 s testing process, users may drag multi-blocks to the target area. If users drop a block to the target area, this block is moved successfully. Otherwise, if users hit the partition or drop a block to the wrong area, this block is moved unsuccessfully. When the test started, the colorful blocks were generated randomly in the start area, and the blocks cannot cross the partition. In addition, the relative position ⟨x, y⟩ of the blocks and time information ⟨t⟩ were recorded during the test.

Fig. 3
Download : Download high-res image (468KB)
Download : Download full-size image
Fig. 3. Interactive interface of “drag & drop” task. (a) Basic “drag & drop” task, named single-task I; (b)–(d) Three varieties of single-task I, named single-task II, single-task III and single-task IV respectively. (For interpretation of the references to color in this figure, the reader is referred to the web version of this article.)

3.3. Enrich detecting tasks
Cognitive decline encompasses the changes of many intellectual functions, such as executive function, spatial visualization, language, attention, logical thinking, short-term memory, and working memory (Nasreddine et al., 2005). Basic “drag & drop” retains the benefits of the traditional BBT (Mathiowetz et al., 1985) in assessing the executive function and spatial visualization. To increase the validity of our system and satisfy multiple detection needs, we enriched our design with three single-tasks and 12 dual-tasks. These three single-tasks are varieties of the initial one, as shown in Fig. 3(b)–(d). To describe each task conveniently, we named the basic “drag & drop” task as single-task I, and its three varieties as single-tasks II, III and IV. In single-task II (Fig. 3(b)), users must “drop” the blocks according to their colors. Specifically, the blue blocks should be placed in the blue area, the red blocks in the red area, the yellow blocks in the yellow area, and the green blocks in the green area. Single-task II enhances the detection of spatial visualization and could test the information extraction and classification maintenance abilities, like the wisconsin card sorting test (Chelune and Baer, 1986). In single-task III (Fig. 3(c)), users must “drop” blocks on the gray area orderly. For example, if the first gray area is empty, users cannot drop a block to the second gray area. The design of single-task III was motivated by the targeted box and block test in Kontson et al. (2017), which requires users to place blocks on specific positions to increase the control over the entire movement. Furthermore, this kind of setting needs users to remember the places of previous blocks, thus placing higher demands on attention and short-term memory. In single-task IV (Fig. 3(d)), users must “drop” blocks on a fixed position, further increasing the limitation of movement. This setting reduces the variability of the employed trajectories, which is beneficial to the comparison of different users.

In addition, we designed three language function related tasks for every kind of single-task, namely, series 1s (low load: counting backward out loud starting from 100), animal names (middle load: enumerating out loud as many animal names as possible), and series 7s (high load: subtracting seven starting from 100 and speaking the result out) (Beauchet et al., 2005). These three language function related tasks can be combined with every single-task to form a dual-task, that is, 4 3 dual-tasks in total. In dual-tasks, users must complete two tasks simultaneously, one single-task (I, II, III, or IV) and one language function related task (series 1s, animal names, or series 7s). Series 1s is used to detect basic language function, while the other two focus on memory and logical thinking abilities, respectively. In isolation, neither task (series 1s, animal names, series 7s, nor the four single-tasks) is difficult to perform, but the relative ease of each task may change when coupled. An underlying hypothesis for the dual-task based hand motor function estimation is that when users perform “drag & drop” and an attention-demanding task simultaneously, the performance in either or both tasks can decline because the brain’s processing power is limited.

3.4. Design optimization
To control the degree of difficulty and fit the spatial visualization ability of older adults, we focused on optimizing the height of the partition and the appearance of the blocks and the target area. All members of our development team and the four MCI patients and four healthy older adults in I4 (Fig. 2) participated in the design optimization.

•
If the partition is high, the users must “drag” the block very high and cross the narrow space over the partition. The higher the partition is, the harder the task is. To find a suitable height for older adults, we selected five different heights, namely, 80%, 70%, 60%, 50%, and 40% of the touchscreen’s height respectively, as shown in Fig. 4(a). We invited eight older adults (including four MCI patients and four healthy older adults) and four neurologists to experience the “drag & drop” task with different partition heights. Each subject performed the test of four single-tasks on five different partition heights, that is, 20 different tests. Experimental results show that user performance was negatively correlated with the partition height. Few subjects performed well when the heights were 80% and 70%, and most of them finished the test when the heights were 60%, 50% and 40%. The neurologists involved think that 60% is a trade-off choice between the degree of difficulty and discrimination. Thus, we selected 60% as the final height of the partition.

Fig. 4
Download : Download high-res image (852KB)
Download : Download full-size image
Fig. 4. Design optimization. (a) Partition height; (b) Target area of single-task II; (c) Target area of single-task III.

•
As for the appearance of the blocks and the target area, the design of single-task I and IV is simple and deterministic, whereas the design of single-task II and III is relatively complex. In single-task II, users must “drop” block to the target area of the same color. The design of the block and its corresponding target area is a challenge. If the colors of the block and the target area are similar, users can have difficulty in distinguishing the block from its background. However, if their colors are totally different, users will confuse the target area of the block. In single-task III, the background color and number of target areas influence the performance of older adults. Specifically, the light-colored target areas are not easy to spot, and too many target areas are confusing. With the participants of our development team and eight older adults, we optimized single-task II and III progressively, as shown in Fig. 4(b) and (c). In every interactive process, we employed a semi-structured interview procedure to invite subjects to test our system and inquire about their experience (including which blocks and target areas are difficult to distinguish and the degree of their satisfaction). We gradually optimized the single-task III and IV until most of the subjects think they are visually distinguishable.

4. User study 1: effectiveness verification
We implemented the cogSYS prototype on Dell Precision 7510 (Intel Core i7-6820HQ/16 GB DDR3) with Android Studio platform 2.2.2. The introduction video for our system can been seen here3. The cogSYS prototype has two modes: the practice mode that lasts 15 s, and the test mode that lasts 60 s. Furthermore, the prototype has four different single-tasks and three kinds of dual-tasks for each single-task and supports the operation with both right and left hands. In the test mode, the coordinates of screen touch point ⟨x, y⟩ and time information ⟨t⟩ are recorded at a sampling rate of 50 Hz for further analysis. In the following part of this section, we introduce the experimental procedure, the extracted feature, and the classification ability of our designed tests. Finally, we further analyzed the most discriminated circumstances and features, which could provide neurologists with diagnosis guidance.

4.1. Procedure
We recruited two groups of participants. The MCI group consisted of 20 subjects selected by the MoCA scale and the Apolipoprotein E genetic test. These 20 subjects were diagnosed with MCI (with MoCA scores lower than 25 or an Apolipoprotein E gene type of ϵ4). The control group included 41 healthy subjects without any sign of cognitive decline. The MCI and healthy groups matched in terms of age, gender, education level, hand preference, and years of using smart devices. Table 2 summarizes the clinical and demographic information of the 61 participants. Nearly all the participants have used smart devices (e.g., smartphone, personal computer, and smartwatch), with an average using time of approximately four years. This popularizing rate is higher than the reported figure of 64.5% for all Chinese people in CAC (2020). The possible reason for this inconsistency is that this study was conducted in an urban area, and place and educational background influence the popularity of smart devices.


Table 2. Clinical and demographic information of the 61 participants in this user study.

MCI	Controls
n (total n = 61)	20	41
Demographics
Women/Men (#/#)	12/8	20/21
Right/Left hand (#/#)	20/0	41/0
Age avg(std)	68.25(6.15)	67.36(4.76)
Age range	60-81	50-76
Education yrs avg(std)	11.14(1.46)	12.22(3.38)
Smart device yrs avg(std)	3.71(1.60)	4.11(0.93)
Clinical characteristics
MoCA avg(std)	22.88(3.55)	/
ApoE ϵ3 (%)	25%	/
ApoE ϵ4 (%)	70%	/
Considering the subjects’ cognitive state, we selected seven tasks from the 16 detection tasks. These seven tasks include four single-tasks and three dual-tasks (i.e., series 1s, animal names, and series 7s while doing single-task I). Only single-task I related dual-tasks were selected because the extended tasks based on single-task II, III, and IV are difficult for some older adults, especially the MCI patients, to finish. The “drag & drop” prototype was run on a Huawei M5 tablet (Android 8.0, 4GB/64GB, with a 10.1-inch, 1920 × 1200 pixels touchscreen). The experiment was conducted in the presence of experimenters whose main job was to clarify the experimental rules and procedures and observe the subjects’ performance. They cannot interfere with the specific process, and the subjects should finish the seven “drag & drop” tasks independently. At the beginning of the experiment, the experimenter explained the entire procedure, and each single-task and dual-task. The subjects were permitted to explore the prototype at will until they were ready to start the data collection process. Subsequently, the subject started with single-task I without any simultaneous task. He/she had 15 s to practice. Then, he/she took the real test using their dominant hand for 60 s. Between two tasks, the subject was permitted to rest for any length of time until he/she is not tired. The real data collection scenarios are shown in Fig. 5. After finishing single-task I, the other three single-tasks (i.e., single-task II, III, IV) and three dual-tasks (i.e., series 1s, animal names, and series 7s while doing single-task I) followed successively. The time ⟨t⟩, the fingertip position ⟨x, y⟩, the block information ⟨i⟩, and the audio information (dual-task only) were recorded for further analysis.

Fig. 5
Download : Download high-res image (1MB)
Download : Download full-size image
Fig. 5. Real data collection scenarios.

4.2. Features extraction
We converted the audio information to text first and then extracted the number and correct rate features of number counting, animal names enumeration and seven subtraction with the Baidu automatic speech recognition platform4. The feature extraction for trajectory information was complicated. We extracted five categories of trajectory related features and investigated whether they can capture the characteristics of MCI. These five categories of features include number, time, velocity, angle, and drop-point-based features. All these features were extracted from all blocks and blocks with blue, green, red, and yellow blocks in both success and failure circumstances (i.e., the block was moved successfully and unsuccessfully). Taking the number-based feature as an example, we calculated the number of blocks and the numbers of blue, green, red, and yellow blocks. We present the details of these five categories of features in the following part.

•
Number-based feature (10 dimensions):This feature refers to the evaluation criterion of the traditional BBT (Mathiowetz et al., 1985). We counted the total number of successfully and unsuccessfully moved blocks. We also counted the numbers of the different color blocks, which is unfeasible in the traditional BBT.

•
Time-based feature (50 dimensions): Slow motor performance is common in people with cognitive impairment (Camicioli et al., 1998). Montero-Odasso et al. (2009b) attempted to detect MCI with time information. We counted the time that the subjects consumed to move the blocks, including both successful and failed attempts and calculated the summary statistics, such as the average, standard deviation, median, maximum, and minimum values.

•
Velocity-based feature (130 dimensions): Like the time-based feature, the velocity-based feature is also used to measure slow motor symptom and widely used in many MCI related research (Montero-Odasso, Bergman, Phillips, Wong, Sourial, Chertkow, 2009a, Montero-Odasso, Casas, Hansen, Bilski, Gutmanis, Wells, Borrie, 2009b). For every moved block, whether successful or unsuccessful, we calculated the velocity. The definition of velocity for the i-th block is: 
 
 where ti is the time used to move block i. 
 is the trajectory (Fig. 6(a)), and xi,j, yi,j are the x and y coordinates of the screen touch point of a finger, respectively. N is the length of the trajectory. We calculated the average, standard deviation, and median of velocity. We also calculated the average, standard deviation, median, maximum, and minimum values for both the straight path and curve trajectory lengths (Fig. 6(a)).

Fig. 6
Download : Download high-res image (405KB)
Download : Download full-size image
Fig. 6. Trajectory and distribution of drop points. (a) Coordinates of trajectory; (b) Angle of trajectory; (c) Distribution of drop points. (For interpretation of the references to color in this figure, the reader is referred to the web version of this article.)

•
Path-based feature (60 dimensions): In some MCI detection related research (Garre-Olmo, Faúndez-Zanuy, López-de Ipiña, Calvó-Perxas, Turró-Garriga, 2017, Kawa, Bednorz, Stepien, Derejczyk, Bugdol, 2017), features based on the hand moving trajectory angle are often used to distinguish MCI patients. We hypothesized that the hand motor function in MCI can affect the angle of the blocks moving trajectories (e.g., zigzag path vs. smooth path). Here, we used the path angles under three thresholds 
 to measure the smoothness of the path (Fig. 6(b)). A small threshold can measure the sharp angle change, and a big threshold can measure the gentle angle change. We calculated the average of angle change and the number of angle changes that exceeded 120∘.

•
Drop-point-based feature (35 dimensions): Fig. 6(c) shows the distribution of drop points, where a “red” point represents the drop point of a block and a “black” point represents the center of all drop points. To characterize the distribution feature of a drop point, we calculated the maximum and minimum distances between every two drop points, and the average, stand deviation, median, maximum, and minimum distances from the center of the drop point. In addition, drop-point-based features were not extracted in the failed attempts for their complex and insignificant distribution characteristics.

4.3. Classification results
MCI detection was challenged by two main problems: 1) the available data tended to be imbalanced (20 vs. 41), and 2) the size of the data labeled by neurologists was small (20 MCI patients and 41 controls). Inspired by the MOCA framework proposed by Chen et al. (2018), we first used a feature selection method based on random oversampling iterative random forest to reduce the dimensionality of the feature space and then added the oversampling strategy to the random forest algorithm to achieve a good generalization ability when processing an imbalanced small-sampling dataset. Experimental results show that the detection accuracy of our classification method is obviously superior to traditional machine learning methods, such as decision tree, support vector machine, and k-nearest neighbor. Thus, we only report the technical details and classification results of our method in the following part.

In the feature selection process, we measured the importance of each feature fj by two factors. This first one is the number of random forests where fj occurs, which is denoted as Nj, and the second one is the frequency at which fj appears in the random forest, which is denoted as Fj. Nj can be counted directly. Fj is computed as 
 where 
 is the number of internal nodes splitting with feature fj, and 
 is the number of total internal nodes in the bth tree of the sth random forest. S is the number of random forests, and B is the number of individual classifiers in each ensemble random forest. After feature selection, we used the random forest algorithm with a synthetic minority oversampling technique (SMOTE) (Chawla et al., 2002) strategy to build an accurate evaluation model with imbalanced data. SMOTE is an oversampling method where the minority class is oversampled by creating “synthetic” examples rather than by oversampling with replacement.

We employed four metrics to measure the classification performance, including accuracy (i.e., the percentage of subjects who were correctly identified as healthy or having MCI), precision (i.e., the percentage of correctly predicted MCI patients to the total predicted MCI patients), recall (i.e., the percentage of correctly predicted MCI patients to the real MCI patients) and F1 score (i.e., the harmonic mean of precision and recall, which takes both false positives and false negatives into consideration). We leveraged the leave-one-out cross validation to validate the effectiveness of our method. Specifically, the data of one subject was used as the test data set, and the data of the remaining 60 subjects were used as the training data set. In addition, we repeated this leave-one-out cross validation process 100 times to avoid the randomness of feature selection and classification model building. In the following, we show both the average values and standard deviation of these 100 repetitions.

We compared the classification results of seven different detection tasks, as summarized in Table 3. The results show that the detection accuracy varied among different tasks. Single-task II achieved the best detection accuracy of 89.5%. In terms of precision, the results of single-task II are also the best. In single-task II, 91.8% of all predicted MCI patients were real MCI patients. Animal names while doing single-task I achieved the best recall 96.3%, indicating that 96.3% of all real MCI patients can be detected correctly by this task. The F1 score considered both precision and recall. Single-task II achieved best result of 92.2% in this metric, proving that single-task II is comprehensively better. In contrast, the classification results of single-tasks I and III were the worst in all four metrics. Their classification accuracies were 73.4% and 75.4% respectively, which were only slightly better than that of random guess. Our explanation for the result above is that relatively complex tasks (e.g., single-task II) are helpful in cognitive assessment. Single-task II is related to comprehensive cognitive abilities, including executive function, spatial visualization, information extraction, and classification maintenance abilities, and thus more likely to detect the deficits of cognition. However, the detection accuracy of single-task III is not ideal, and it is evident that more complex tasks will not always lead to better results. In the data collection process, we observed that even some normal subjects cannot find the right target areas, causing the low classification accuracy of single-task III. We also calculated the combination results of four single-tasks and all seven tasks by majority voting. Specifically, for the majority voting of four single-tasks, one subject will be judged as MCI if this subject is judged as a MCI patient in at least three tasks; for the majority voting of all seven tasks, one subject will be judged as MCI if this subject is judged as a MCI patient in at least four tasks. The accuracy, precision, recall, and F1 score of these two majority voting methods are shown in Table 3. The combination results show a better classification ability than the results of seven separate detection tasks because long test time and various test tasks will improve the detection results. The combination results show a better classification ability than the results of seven separate detection tasks because long test time and various test tasks will improve the detection results. Furthermore, we compared the two majority voting methods, namely, the combination result of four single-tasks and the combination results of all seven tasks. Compared with the previous one, the combination results of all seven tasks increased by 0.1% in accuracy and 0.2% in F1 score, showing the effect of dual-task in cognitive assessment.


Table 3. Classification results of different detection task and their combination. T1-T4: single-task I, II, III and IV, T5-T7: series 1s, animal names and series 7s while doing single-task I, V1: combination results of four single-tasks by majority voting, V2: combination results of all seven tasks by majority voting.

Tasks	Acc	Pre	Rec	F1
T1	0.734 ± 0.022	0.768 ± 0.017	0.866 ± 0.017	0.814 ± 0.015
T2	0.895 ± 0.012	0.918 ± 0.017	0.927 ± 0.000	0.922 ± 0.008
T3	0.754 ± 0.017	0.782 ± 0.015	0.880 ± 0.016	0.828 ± 0.011
T4	0.817 ± 0.018	0.833 ± 0.014	0.911 ± 0.016	0.870 ± 0.013
T5	0.839 ± 0.016	0.849 ± 0.019	0.927 ± 0.000	0.886 ± 0.010
T6	0.839 ± 0.021	0.852 ± 0.022	0.922 ± 0.019	0.885 ± 0.014
T7	0.890 ± 0.025	0.884 ± 0.027	0.963 ± 0.017	0.922 ± 0.017
V1	0.900 ± 0.013	0.833 ± 0.009	0.927 ± 0.002	0.927 ± 0.005
V2	0.901 ± 0.010	0.907 ± 0.011	0.951 ± 0.000	0.929 ± 0.006
4.4. Insights on discriminated circumstance and feature
The classification results in Section 4.3 indicate whether “drag & drop” can detect MCI patients from the healthy controls. In this section, we further explore to what extent the designed tasks and extracted features can capture the characteristic patterns caused by MCI, and the key circumstance and features that are special between different groups of subjects. In other words, in addition to whether “drag & drop” can assess the cognitive status, the key characters for cognitive assessment are also important. These further explorations can provide insights for related follow-up research and guidance for clinical application. Specifically, we want to explore the following further:

Question 1: For the traditional BBT, the number of moved blocks within a certain time is the most commonly used index. Is the number-based feature the best feature, and do the “drag  drop” tasks have other significant features?

Question 2: “Drag  drop” involves different tasks. Are the key features different from task to task?

Question 3: “Drag  drop” is composed of colorful blocks. How much does color play in diagnosis? Does color selection for MCI patients exhibit an interesting pattern, such as color preference?

Significant features: Table 4 exhibits the results of group-level (MCI patients vs. healthy controls) statistical comparisons (two-sided Mann–Whitney–Wilcoxon test, MWW) with respect to representative features. We highlight the p-values of the null hypothesis tests that MCI and control subjects come from the same population. Given the high dimension of the original features (291), we present the p-values of part of them (30) with better distinguished results here, and these features were selected through the feature selection strategy in the previous subsection. Evidently certain features differed significantly (p-value  <  0.05) between groups. Specifically, these 30 features exhibited significant differences on at least three types of detection tasks. In terms of feature type, 20 of the 30 selected features were extracted in failure circumstance, indicating that the performance of subjects in the failure circumstance was more distinguished. In addition, according to the number of selected features, the time and velocity-based features are superior to the numbers, angle and drop-point-based features. This result is inconsistent with our priori knowledge, indicating the necessary to find more significant features.


Table 4. Statistical comparisons of five categories of features between MCI patients and the healthy controls. The results of significance is computed using the non-parametric two-sided Mann–Whitney–Wilcoxon test and the marks represent: p > 0.05(∘), p < 0.05(*), p < 0.01(⋆), and p < 0.001(•).

Num feat	Time-based feature	Velocity-based feature	Ang feat	Drop-point-based feature
T1	*	⋆	*	*	∘	*	∘	*	∘	⋆	⋆	⋆	⋆	∘	*	∘	*	*	∘	⋆	∘	∘	∘	*	•	⋆	⋆	•	•	*
T2	∘	⋆	*	⋆	⋆	*	*	*	*	*	*	*	⋆	∘	∘	⋆	∘	∘	∘	*	∘	∘	∘	∘	∘	∘	∘	∘	∘	•
T3	∘	∘	∘	⋆	∘	∘	∘	⋆	∘	∘	∘	*	*	⋆	∘	∘	*	*	*	*	*	*	*	⋆	⋆	⋆	*	*	∘	∘
T4	∘	∘	*	•	⋆	*	*	*	*	*	*	*	⋆	⋆	⋆	*	∘	∘	⋆	*	⋆	•	*	∘	⋆	∘	∘	⋆	•	∘
T5	•	*	∘	*	•	•	•	•	⋆	*	*	*	∘	*	•	•	*	•	*	∘	⋆	⋆	∘	∘	⋆	⋆	⋆	⋆	⋆	⋆
T6	*	∘	∘	∘	•	*	*	*	*	∘	∘	∘	*	•	•	•	*	*	•	∘	•	•	•	⋆	•	•	•	•	•	⋆
T7	•	*	*	⋆	⋆	•	•	•	•	*	*	*	*	⋆	⋆	⋆	⋆	*	*	*	*	⋆	*	*	⋆	⋆	⋆	⋆	•	*
1	2	3	4	5	6	7	8	9	a	b	c	d	e	f	g	h	i	j	k	l	m	n	o	p	q	r	s	t	u
T1: single-task I	T2: single-task II	T3: single-task III	T4: single-task IV	T5: series 1s while doing T1
T6: animal names while doing T1	T7: series 7s while doing T1
1: num_BF    2: num_GF    3: num_YF    4: time(max)_AF    5: time(std)_AF    6: time(avg)_BF    7: time(med)_BF
8: time(max)_BF    9: time(min)_BF    a: time(med)_GF    b: time(max)_GF    c: time(std)_GF    d: time(max)_YF
e: curve length(max)_AS    f: straight length(std)_AF    g: curve length(std)_AF    h: straight length(std)_BS
i: curve length(std)_BF    j: curve length(max)_GS    k: curve length(std)_GF    l: curve length(med)_RS
m: curve length(max)_YS    n: corner(thres1, avg)_AS    o: corner(thres3, avg)_YS
p: distance between two drop points(max)_AF    q: distance with center(avg)_AF    r: distance with center(med)_AF
s: distance with center(max)_AF    t: distance with center(std)_AF    u: distance with center(med)_BS
The suffixes B, G, R and Y represent that this feature is extracted from block in blue, green, red and yellow color respectively.
The suffixes S and F represent that this feature is extracted in success and failure move circumstance.
Key features in different tasks: Fig. 7(a) presents the statistical comparisons (MWW) of each category of features between the MCI patients and the controls in different tasks, where the y-axes on the left and right sides of every subfigure are the index of the task and the number of features with p-value less than 0.05. For example, the number of time-based features with a significant p-value in task 1, 2, 3, 4, 5, 6, and 7 are 3, 24, 13, 22, 4, 11, and 8, respectively. Fig. 7(a) shows that the number of effective features differs in different tasks. The number of effective features in single-task I is the minimum in every feature category. In contrast, the number of effective features in single-task II is relatively large in every feature category. Furthermore, we can also know that the category of the most effective feature differs in different detection tasks. For example, the time-based feature was the most effective feature for single-task II, and 24 of all 50 features have significant p-value. However, for the dual-task series 1s while doing single-task I, the most effective feature category is velocity-based feature, and 45 of all the 130 features have significant p-value.

Fig. 7
Download : Download high-res image (474KB)
Download : Download full-size image
Fig. 7. Statistical comparisons between MCI patients and controls in (a) different tasks; (b) different block color. Significance is computed using the non-parametric two-sided Mann–Whitney–Wilcoxon test. The y-axis on the left side of every sub-figure presents different detection task or block color. T1-4: single-task I, II, III and IV, T5-7: series 1s, animal names and series 7s while doing single-task I; T: all; B: blue; G: green; R: red; Y: yellow. The y-axis on the right side of every sub-figure presents the number of features with p-value less than 0.05. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

Influence of color: Fig. 7(b) presents the statistical comparisons (MWW) of each feature category between MCI patients and the controls in the different block colors. The y-axis on the left side of every sub-figure is the block color, where T, B, G, R, and Y stand for all, blue, green, red, and yellow blocks, respectively. The y-axis on the right side of every sub-figure is the number of features with a significant p-value. As Fig. 7(b) shows, the numbers of significant features in different block colors (blue, green, red and yellow) are relatively close, indicating that block color has little effect on the result, and not obvious tendency in color selection for different groups of subjects can be observed.

5. User study 2: hand motor related changes in cortical activation
5.1. Motivation
In addition to the basic experiment for evaluating the detection accuracy of cogSYS, we conducted another experiment to explore the hand movement related changes in cortical activation within a functional brain network by using fNIRS. fNIRS is a neuroimaging technique for the non-invasive detection of relative changes in cerebral oxygenated hemoglobin (delta HbO2) and deoxygenated hemoglobin (delta HHb) at the cortical surface (Toronov et al., 2000). fNIRS is more robust to the subjects intentional or unintentional motion than many conventional functional imaging tools, such as positron emission tomography, electroencephalography, and functional magnetic resonance imaging. fNIRS is also a low-cost, portable, and safe method for monitoring brain activity (Strangman et al., 2002).

Cortical activation aims to analyze the activity of the cerebral (or cerebellar) cortex during cognitive tasks or sensory stimulation. These kinds of research for exploring the relationship between brain response and external stimuli are significant and plays an essential role in clarifying the cortical activation patterns induced by various stimuli (Chang et al., 2014). Using fNIRS, Huo et al. (2018) analyzed the influence of posture on the effective connectivity of the brain. At two different states, namely, sitting and standing, they recorded the fNIRS signals of different cortex areas. Their findings deepen the understanding of age-related brain changes and provide insights into the cognition decline of older adults. Furthermore, Teo et al. (2018) explored the changes in the prefrontal cortex during six sensory orientation tests. Their findings demonstrate the involvement of the prefrontal cortex in postural control during complex tasks. Some studies also focused on analyzing the changes in cortical activation during upper limb movements. To explore the effect of hand-arm bimanual intensive therapy (HABIT), Surkar et al. (2018) assessed the hand function with both fNIRS and the BBT. By analyzing the cortical activation during a hand motor function test, they demonstrated the effect of HABIT in improving the prefrontal cortex. Pierce (2018) also researched the influence of upper limb movement on brain activity with the BBT and fNIRS, providing significant insights for prosthetic design.

5.2. Procedure
A total of 37 subjects, including 25 MCI subjects and 12 healthy individuals, participated in this study. Four subjects in the MCI group have participated in previous effective verification study, and none of the subjects in the healthy group has participated in the former study. The members of MCI group were selected by the same method as the former user study, that is, through MoCA scale and Apolipoprotein E genetic test. These 25 subjects were diagnosed with MCI by neurologists (with MoCA score lower than 25 or an Apolipoprotein E gene type of ϵ4). The 25 MCI subjects included 16 males and nine females, and their average age was 65.08 ± 9.68. The MoCA and MMSE scores of these 25 subjects were 20.83 ± 3.46 and 24.48 ± 1.53, respectively.

Fig. 8 (a) presents the experimental procedure. Before the experiment began, the subjects were permitted to rest for five minutes in a dimly lit and quiet environment. After resting, they were asked to perform two detection tasks sequentially, including one single-task and one dual-task. The single-task was single-task II, which achieved the best classification result in the previous study, and the dual-task was series 1s while doing single-task II. At the begin of both the single-task and dual-task, the subjects were guided to sit in a comfortable position, remained still and awake, and relaxed with eyes closed for three minutes in a dimly lit and quiet room (resting state, i.e., task_SR and task_DR). After the resting state, the subjects were asked to perform the detection task with their handedness for three minutes (tasking state, i.e., task_ST and task_DT). The lasting time of “drag & drop” program was modified to three minutes rather than the original one minute to obtain a steady brain functional network. During the experimental process, the block “drag & drop” and fNIRS data were collected simultaneously. The real data collection scenarios are shown in Fig. 8(b). The block “drag & drop” data were collected using a fixed touchscreen (ViewSonic TD2230, 21.5 inch, 1920  ×  1200 pixels) to avoid unconscious motion, and the detection application was run on a NanoPi M4 board (Android 7.1, 4GB/16G). The sampling rate of the fNIRS system is 13 Hz, with wavelengths of 740 and 840 nm. The fNIRS system we use in this research was produced by NirScan Danyang Huichuang Medical Equipment Co.Ltd., China. A total of 32 channels were built by 14 light sources and 14 detectors for fNIRS measurement. The locations of these channels cover five areas of the cerebral cortex (shown in Fig. 8(c)), including the left prefrontal cortex (LPFC), the right prefrontal cortex (RPFC), the left motor cortex (LMC), the right motor cortex (RMC), and the occipital lobe (OL). The values of delta HbO2 were calculated from the raw data of detected light intensity according to the modified Beer–Lambert law (Sakatani et al., 2006). After calculating the HbO2 from the raw fNIRS data, we preprocessed the obtained HbO2 by the moving average, motion artifacts remove, and six-order Butterworth bandpass filter methods (Huo et al., 2019).

Fig. 8
Download : Download high-res image (882KB)
Download : Download full-size image
Fig. 8. (a) Experimental procedure, including four states, task_SR, task_ST, task_DR and task_DT. S: single-task, D: dual-task, R: resting state, T: tasking state; (b) Real data collection scenario with NanoPi M4 broad; (c) The distribution of fNIRS channels. Red dots represent the sources of light and green dots represent the detectors of light. 14 detectors and 14 sources build 32 fNIRS channels, which covers five cerebral cortex of brain, including RPFC, LPFC, RMC, LMC, and OL. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

5.3. Results
Fig. 9 shows the patterns of cortical activation in view of the average value of delta HbO2 in the healthy controls and MCI patients during two resting and two tasking states. The letters in Fig. 9 specify the positions of the detector and the source of light. Moreover, the color bar on the right indicates the color depth. The observations can be drawn from the experimental results:

•
In the comparison of the tasking states with the resting states of both single-task and dual-task, such as task_ST vs. task_SR and task_DT vs. task_DR, an increase in delta HbO2 was observed in the left and the right motor areas, and these kinds of increases are obvious in both healthy control and MCI groups. Motor cortex is the primary brain area that relates to body movement. The activation of “drag & drop” to the LMC and the RMC is consistent with that of the traditional BBT (Shin et al., 2008), proving the effectiveness of this touchscreen test on hand dexterity and the specific cortex.

•
In addition, an increase in OL areas was also observed during task states. Given that the OL is the visual processing center of human-beings, the activation of the OL supports our design goal to exercise users’ spatial visualization ability. Briefly, multiple areas of our brain, such as the LMC, the RMC, and the OL, were all involved during the simple “drag & drop” test. Users can exercise these related areas.

•
We also compared the brain activation in the single-task and dual-task states. For the healthy controls, the concentration of delta HbO2 in the task_DT state is higher than that in the task_ST state in both MC (LMC and RMC) and PFC (LPFC and RPFC) areas. This phenomenon may be attributed to the difficult of dual-task that requires the subjects to count backward out loud from 100 while performing the basic block “drag & drop” task. Thus, the prefrontal cortex that mainly relates to executive function, logical thinking, problem solving, and language was activated.

•
However, for the MCI group, the cortical activation during task_DT was beyond our expectation. Compared with the result in task_ST state, the concentration of delta HbO2 during task_DT decreased in both the bilateral motor areas and the OL areas. Furthermore, compared with the result in the task_DR state, the concentration of delta HbO2 during task_DT increased slightly. Intuitively, the dual-task composed of hand movement and counting backward is complex, and the concentration of delta HbO2 during task_DT was high. Meanwhile, the actual results are inconsistent with our inference (Fig. 9(b)). The three main related brain areas, namely, both prefrontal cortices (which relate to executive function and language), both motor cortices (which relate to body movement), and the occipital lobe (which relates to spatial visualization ability), were only mildly activated during the dual-task. We have two explanations for this phenomenon. First, the MCI patients’ error rates of performing this dual-task (e.g., series 1s while doing single-task II) are high. They often dropped colorful blocks to wrong target areas or missed a number during the test, and they reduced their brain resource consumption by ignoring the test accuracy. Second, the attention needed during the dual-task exceeded the brain resource limit value of the MCI patients. Our brain tries to allocate the resource in other areas to compensate for the insufficiency in the MC and OL areas (Becker et al., 1996).

Fig. 9
Download : Download high-res image (877KB)
Download : Download full-size image
Fig. 9. Cortical activation of delta HbO2 during different conditions. (a) Cortical activation in healthy controls; (b) Cortical activation in MCI group.

The analysis of cortical activation provides two insights. First, cortical activation analysis visually demonstrates which brain areas are involved when performing assessment tasks. This analysis proves the effectiveness of “drag & drop” on related cognitive functions. Furthermore, users can select suitable tests according to their needs for specific cognitive testing and training. Second, the results of cortical activation analysis, especially the results of series 1s while performing single-task II in the MCI group, indicates that assessment tasks with an appropriate level of difficulty must be selected. Some of the relatively difficult assessment tasks were not helpful for cognitive testing and training.

6. User study 3: user experience
We also conducted an experiment to research users’ experiences of “drag & drop” through a semi-structured interview, including a structured questionnaire and verbal communication. The structured questionnaire aims to compare “drag & drop” with three commonly used cognition assessment methods, namely, traditional BBT (Mathiowetz et al., 1985), DBBT (Zhao et al., 2013), and 66nao (Tang et al., 2016). For every detection system, we focused on whether it is easy to use, whether it is user-friendly, and whether it could motivate users to keep using it. Thus, we designed four choice questions to assess each system. The score range of these four questions is 1–5, and a higher score indicates good performance in this aspect. The designed choice questions cover the following:

•
Q1: From 1 to 5, where 1 is strongly disagree and 5 is strongly agree, how much do you agree with the following statement: The test is easy to use.

•
Q2: From 1 to 5, where 1 is strongly disagree and 5 is strongly agree, how much do you agree with the following statement: The test is interesting.

•
Q3: From 1 to 5, where 1 is strongly disagree and 5 is strongly agree, how much do you agree with the following statement: You feel inspired after using this test.

•
Q4: From 1 to 5, where 1 is strongly disagree and 5 is strongly agree, how much do you agree with the following statement: You want to keep using this test often in your daily life.

Verbal communication aims to gather more user feedback on the “drag & drop” test in a relaxed way. We communicated with each subject verbally to understand their subjective opinions, and the communication mainly revolved around the following two essay questions:

•
E1: What do you think about the “drag  drop” test?

•
E2: What aspects of “drag  drop” must be improve?

For the user experience study, we recruited 10 neurologists, 10 older adults, and 10 engineers. None of these 30 participators participated in the first two user studies. To ensure that the subjects can fully understand the tests, we built the test environment for these four tests (i.e., “drag & drop”, BBT, DBBT, and 66nao) in our laboratory setting, where “drag & drop” and 66nao were installed in a tablet computer, the BBT was a physical test (Fig. 1), and the DBBT involved the BBT, a computer-based graphical interface, and a Kinect sensor. We introduced the main functions of each test, how the test works, and how to use this test to each subject during the experiment. We also asked the subjects to experience these tests until they fully understand how to use these tests. After preparing, each subject filled out the structured questionnaire. We guided the neurologists and related engineers in answering the questionnaire from the older adults’ perspective. We also talked with the subjects to understand their subjective opinions about “drag & drop”, including what they think about “drag & drop”, and the aspects of “drag & drop” that need further improvement.

Fig. 10 shows the experimental results with the structured questionnaire. All 30 participators evaluate our system highly from all aspects. The average score of Q1 (4.67) is the highest among all the questions, indicating that our system is easy to use. However, the score of Q2 (4) is the lowest of all the four questions. Given that the current version is lacking in interaction with users, this test was not very interesting, with repeated block “drag” and “drop” movements. The current version of “drag & drop” is more like a serious game (Zyda, 2005) designed for cognitive assessment other than pure entertainment. We took advantage of an easy and convenient way of realizing professional cognitive assessment and rehabilitation. Most of the subjects felt inspired when they finished “drag & drop” test (Q3: 4.17), and expressed their willingness to use “drag & drop” later (Q4: 4.33). Meanwhile, valuable feedback was also obtained from verbal communication. All the participants gave “drag & dro” positive evaluations. They thought “drag & drop” is a very convenient and creative design, and some older adults said “drag & drop” is a good test to kill their boredom in their spare time. Some subjects, especially the neurologists and the related engineers, also gave valuable suggestions for further improvement. First, our system can only generate a fixed number of colorful blocks, and the height of the partition is also fixed currently. The subjects suggested adjusting the number of blocks and the partition’s height automatically (or manually) according to the ability of the users and the detection requirement. Second, although this system was designed for older adults with MCI, this technique can potentially benefit patients with other chronic neurological disorders, such as Parkinson’s disease. Future works should investigate the effectiveness of “drag & drop” on more patients with other disorders and design more interesting varieties of the “drag & drop” test. Third, some subjects suggested adding a social function to the “drag & drop” system to increase the loyalty of users.

Fig. 10
Download : Download high-res image (2MB)
Download : Download full-size image
Fig. 10. User experience results with the structure questionnaire.

7. Discussion
7.1. Design motivation behind “Drag  Drop”
According to our perennial studies on older adults and our early explorations in S1 and S2 (Section 3.1), we find that older adults tend to be emotional (Phares, 1992). On the one hand, they do not want to admit they perform awkwardly or worse than others, and they think that unsatisfactory performance may prove that they are not healthy enough. On the other hand, they will give up easily when encountering difficult tasks and think tricky tasks may expose their inability. Older adults are not very accepting of difficult detection tests in the clinical environment, such as 66nao, more so of using these tests in daily life. These observations motivated our design of cogSYS. CogSYS aims to realize convenient and efficient cognitive assessment with different “drag & drop” tasks. Compared with the existing cognitive assessment methods in Table 1, the advantages of cogSYS are evident. First, cogSYS simplifies the cognitive assessment process with repetitive, unitary, and simple movements, such as “drag” blocks and “drop” blocks. These two movements are sightly affected by other interference factors, such as educational level and intelligence (Garre-Olmo, Faúndez-Zanuy, López-de Ipiña, Calvó-Perxas, Turró-Garriga, 2017, Hebert, Bienias, Mccann, Scherr, Wilson, Evans, 2010, Kawa, Bednorz, Stepien, Derejczyk, Bugdol, 2017). Second, cogSYS has 16 different kinds of “drag & drop” tasks, including four single-tasks that relate to manual dexterity and 12 dual-tasks that relate manual dexterity and language ability, covering various aspects of cognition, such as executive function, spatial visualization, logical thinking, memory, language, and attention. These settings expand the assessment ability of cogSYS, increasing its potential application in detecting various cognitive impairments. Third, cogSYS is time-saving. Each “drag & drop” task take only one minute. In contrast, existing cognitive assessment systems with complex tasks, such as 66nao and RehaCom, usually take hours; the time consumption of TMT depends on the users, usually taking a few minutes. Fourth, cogSYS is easy to use, and the end user can easily learn how to use it independently. The participant subjects in the three user studies performed “drag & drop” tasks in the presence of the experimenter, whose main job was to record the experiment process and observe the subjects’ performance. However, cogSYS was potentially performed by users without the help of others. We set the instructional videos on the main interface of cogSYS to teach new users the using rules. In addition, cogSYS records tasks related data and automatically uploads these data to a remote cloud server, where data will are analyzed and visualized by a machine learning algorithm, and the neurologists can also see the user data.

7.2. Predictive accuracy and interpretability to results
Regarding the cognitive assessment results, a mean accuracy of 82.4% and a maximum accuracy of 90.1% were achieved, which are comparable to the results of other state-of-the-art methods, such as Garre-Olmo et al. (2017) and Aoki et al. (2019). In addition, this study also analyzed the key features of cognitive assessment. We investigated the five categories of features, including the number, time, velocity, path, and drop-point-based features, and analyzed the most significant features by the statistical hypothesis test. The analysis results provide three-fold insights: 1) In addition to the number of moved blocks, the time and velocity-based features also play an important role in cognitive assessment. 2) The key features vary in different tasks. 3) Among the MCI patients and the healthy older adults, no particular pattern of color selection can be observed.

For the auxiliary medical diagnosis based on computing technology and artificial intelligence, providing a number with predictive accuracy is not the only goal. Interpretability of the induced results is also essential to determine the most influential factors and provides guides for clinical application and follow-up research. As an expert said in Bratko (1997), “When I investigate a system, I want to find out how the system works”. Domain experts express their interest in understanding the working theory behind artificial intelligence systems, which should not be treated as a black box that only provides correct predictions. Extra attention should also be given to understanding how the system works and what new explorations the system can provide in the light of domain knowledge.

7.3. Visualize cortical activation pattern
The cortical activation analysis in Section 5, which is based on functional near-infrared spectroscopy (fNIRS), verifies the effectiveness of “drag & drop” from another view. In Section 5, we record the fNIRS signal of the participants when they performed different tasks and visualized the corresponding changes in HbO2 to show the involvement of specific cognitive areas. Experimental results show that the activation patterns in the brain cortex are consistent with our design goals for “drag & drop” in most cases. For example, the motor cortex and the occipital lobe were involved when the subjects moved colorful blocks, proving that the executive function and the spatial visualization ability were activated in this process; the prefrontal cortex was involved when counting numbers, proving that the memory and logical thinking abilities were activated in this process. Furthermore, cortical activation analysis also revealed another interesting phenomenon that is inconsistent with our intuition. For the MCI group, the related brain areas were only activated mildly when performing complex tasks. One explanation for this abnormity is that some complex tasks were too tricky for the MCI group, and their brain resources were relocated when performing these kinds of tasks. The involved brain areas and the difficulty level of assessment tasks are significant, affecting the effectiveness of cognitive assessment. In this study, we conducted a preliminary exploration with fNIRS. Furthermore, more works for quantitative analyses are needed to determine the precise tasks combination and difficulty level.

7.4. Interestingness of “Drag  Drop” tasks
For the user experience in Section 6, 30 participant subjects evaluated positively to the degree of easy to use, with an average score of 4.67 (score range: 1–5). On the contrary, the average score for the interestingness of “drag & drop” is 4, which is a relatively negative result. Our explanation is that “drag & drop” was not designed for pure entertainment, and it is more like a serious game. As professor Michael Zyda defined in Zyda (2005), a serious game is “a mental contest, played with a computer in accordance with specific rules, that uses entertainment to further government or corporate training, education, health, public policy, and strategic communication objectives”. Serious games usually apply game-related factors, such as story, art, and software, to other non-entertainment domains to realize particular objectives. The scoring results of the subjects and the understanding of a serious game indicate that the current version of “drag & drop” tasks is not ideal. Future work should pay more attention to improving the plot design and the interface of “drag & drop” tasks to make it look more like a real game thus promoting the cognitive testing and training process.

7.5. Limitations and future work
In addition to those discussed in the previous sections (i.e., Sections 7.3 and 7.4), other limitations exist, and several future directions can be taken. First, this study mainly focused on verifying the effectiveness of “drag & drop”, and three user studies were all conducted in laboratory environment with the participant of experimenter. Though the feasibility of the independent usage of “drag & drop” is demonstrated in Section 7.1, home environment-based experiments are still necessary to prepare for the widespread practical application of this designed system. In the future, we will conduct longitudinal studies, such as the experiments in Peres et al. (2008), to track users’ performance in the home environment. Second, cogSYS is motived by the traditional BBT (Mathiowetz et al., 1985) and inherited one shortcoming of the traditional BBT of not being very friendly for users with visual impairment. Although users with visual impairments can finish most of the “drag & drop” tasks, except for single-task II and three dual-tasks related single-task II that must place blocks in the target area with the same color, their spatial visualization ability cannot be trained. In the future, we will further optimize single-task II and its related dual-tasks, with different textures or vibration feedback, to make them accessible for users with visual impairment. Third, the controlled study was conducted on a tablet with 10.1-inch touchscreen tablet and a NanoPi M4 board with 21.5-inch touchscreen considering the sight of older adults. Thus, whether the experimental results can be generalized to smartphones with a smaller screen size in unclear. In the future, we will use smartphones to conduct home environment-based experiments to verify the effectiveness of cogSYS. Finally, our detection model was built based on tablet data and it is difficult to generalize for data collected by different screens. Bridging the detection gap between different equipment or environments is another challenge. In Zhang et al. (2020), we preliminarily explored the transfer learning algorithm for cross-tasks and cross-environment adaptation. In the future, we will further improve the domain adaptation algorithm with richer datasets.

8. Conclusion
We present a user-friendly MCI detection system based on simple “drag & drop” tasks by assessing older adults’ hand motor function under the dual-task paradigm. This interactive system is composed of four single-tasks and 12 dual-tasks. We report how these 16 tasks are designed, optimized and, evaluated through three user studies, including effectiveness verification, cortical activation analysis, and user experience feedback. Results indicate that the proposed method can detect MCI effectively, activate related brain cortices, and be accepted by a wide range of users. Moreover, our design can expose the most discriminated circumstance and features. Specifically, we discovered that the time and velocity-based feature of failure circumstance are the most effective among all feature categories. In a broader sense, this research proposes a novel idea of designing user-friendly detection tasks and provides practical support for related detection system designs.