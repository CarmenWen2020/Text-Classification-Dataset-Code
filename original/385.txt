The evolution of 5G network service ecosystems raises the need for the discovery of services among multiple (edge) clouds with potentially heterogeneous resources and features. Besides 5G service deployment, such a service discovery architecture could provide the means for cross-service communication (CSC), that is, the consumption of a network service (NS) by another NS, empowering the service capabilities of the latter. This article presents a distributed service discovery framework for network service marketplaces (NSMs) in edge computing. We exemplify the operation of a new distributed service discovery mechanism that relies on a cache-based protocol for the discovery of NSs among edge clouds. We also present a multi-criteria ranking mechanism, which identifies the most suitable edge cloud according to the client's functional, performance, and cost requirements. Our evaluation results indicate that the proposed service discovery mechanism (SDM) yields service discovery effectiveness on par with other approaches, while drastically reducing the communication overhead.

The authors present a distributed service discovery framework for network service marketplaces (NSMs) in edge computing. They describe the operation of a new distributed service discovery mechanism that relies on a cache-based protocol for the discovery of NSs among edge clouds. They also present a multi-criteria ranking mechanism, which identifies the most suitable edge cloud according to the client's functional, performance, and cost requirements.
Introduction
Innovative 5G verticals are composed of various time- and mission-critical applications that are developed as end-to-end services over heterogeneous distributed computing and network infrastructures. Toward network delay minimization and increased reliability and bandwidth savings, infrastructure providers offer computing, network, and storage resources at the edge of the network. To this end, edge computing has become the emerging service delivery paradigm [1], raising various service management and orchestration challenges. The edge clouds (ECs) are small-sized computing facilities in the vicinity of end users. Under this setting, the dominant network architecture concepts of network function virtualization (NFV) and software-defined networking (SDN) continuously evolve to fulfill the various (non-) functional requirements for service orchestration of 5G verticals.

The deployment of 5G verticals in ECs is based on the concepts of network slicing and network services (NSs), which provide the desired isolation among tenants. However, the co-hosting of such service ecosystems creates opportunities for cross-service interactions within the same EC infrastructure, where an NS can consume an NS of a different tenant. Cross-service communication (CSC) enhances the overall performance in terms of throughput, latency, and potentially other key performance indicators (KPIs), and creates opportunities for financial rewards through service leasing. In a similar manner, service components may be shared among different service operators (i.e., a service orchestration aspect, known as inter-service operability). These emerging trends pave the way toward a next-generation network service marketplace (NSM), where users are able to compose custom service chains, while a service will be empowered to consume other co-located services in a controlled and secure manner [2]. The NSM should provide several automated functionalities to both service providers and consumers, while supporting the entire life cycle of the NSs, including service registration, discovery, instantiation, and termination. Furthermore, it must provide secure and automated mechanisms for CSC establishment.

Every user can act as either service provider or consumer. Thus, the NSM should provide the essential mechanisms for service registration and discovery. The service registration should allow users to specify the features and requirements of their NSs in a consistent and open manner that can be used by the participating heterogeneous ECs. In this context, the European Telecommunications Standards Institute (ETSI) NFV data model describes analytically the structure and parameters of the network services [3].

This model can be further enriched with application descriptors that provide quality of service (QoS) requirements. Upon service registration, the service discovery empowers users to identify the appropriate NSs for CSC. An NSM consists of geographically dispersed ECs for maximized footprint, with each one locally maintaining information about the CSC-enabled NSs. The service discovery is performed in either a centralized or distributed manner. A centralized approach commonly entails scalability limitations, while the efficiency of a distributed discovery mechanism is strongly affected by the underlying EC infrastructure.

Under this complex setting, the ECs of a single provider may have heterogeneous resources, which implies different features (hardware acceleration, optimized CPU instruction sets, etc.), which in turn can lead to performance differentiation between ECs. Furthermore, the resources of ECs are limited, while resource allocation must be carried out such that service KPIs are met. Thus, prior to service component (e.g., virtual network function) placement, the candidate ECs, assessed and proposed by the service discovery mechanism, should be evaluated based on multiple performance, cost, and support criteria [4]. Thereby, the final EC selection problem can be formulated as a multi-objective optimization problem based on well-defined KPIs that are common for every EC.

In this respect, we propose a distributed service discovery and multi-criteria EC selection mechanism for enabling 5G network slicing and CSC at the network edge. We assume that a service embedding request can be handed onto any EC, which is held responsible for the discovery and evaluation of candidate ECs based on a multitude of criteria. The contribution of our work is twofold. First, we design a cache-based discovery protocol aimed at discovering the required services for CSC with fast convergence and controlled communication overhead. Second, we employ a multi-criteria decision making (MCDM) approach to rank the candidate ECs based on the individual requirements of each service request. The distributed service discovery framework is evaluated using realistic EC-level topologies. In comparison with both centralized and distributed service discovery solutions (i.e., flooding), our proposed approach yields significant reduction in the communication overhead without any perceptible penalty in terms of discovery efficacy. Our evaluation results show that the proposed ranking mechanism is scalable with the number of ECs.

Related Work
Recently, several projects have focused on the establishment of NSMs, which provide service registration and discovery functionalities, and enable CSC. Aligned with ETSI NFV architecture [5], T-NOVA introduces the notion of the Network Function Store, which empowers clients to compose services out of individual network functions, supplied through this store [6]. Similarly, the FENDE Marketplace enables developers to onboard services as virtual network functions (VNFs) in a service catalogue, whereas users can select among the available VNFs and plug them into an instantiated slice on the underlying infrastructure [7]. Based on the Resource Broker concept, the NECOS Marketplace facilitates the resource discovery for instantiating network slices across multiple resource providers [8]. MESON advocates CSC between co-located slices in an EC with respect to the requirements of both slice tenants [2]. Based on open source management and orchestration (MANO) (OSM) [9], MESON orchestration provides CSC-enabled service discovery, EC selection, and slice placement. Considering the distributed service discovery across multiple providers or points of presence (within a single provider), the 5GEx hierarchical architecture of multi-domain orchestrators enables the exchange of high-level information with clients, service discovery, and mapping, as well as VNF configuration and monitoring [10].

Distributed EC Selection Mechanism
For the proposed EC selection approach, we consider an EC infrastructure comprising geographically dispersed and heterogeneous ECs, as shown in Fig. 1. Furthermore, the ECs are clustered in availability zones within specific areas, while each node in Fig. 1 represents an EC. Each EC's resources are controlled by a virtualized infrastructure manager (VIM), which instantiates the services and assigns resources to them. A new network service embedding (NSE) request can be submitted to any EC, which selects the appropriate EC for hosting the NS. For the final selection, various functional, quality of service (QoS), and cost requirements, as well as a set of desired CSC-enabled services are taken into account. Within each EC, several components are deployed to realize the service discovery and EC selection. In particular, all services of the NSM are stored in the Service Catalogue of each EC, whereas the Service Cache contains the CSC-enabled services in the adjacent ECs. The service discovery mechanism (SDM) is responsible for sending query messages to its neighbors for CSC service discovery. Finally, based on the MCDM method, the EC ranking mechanism (ECRM) evaluates the candidate ECs and selects the most appropriate one for NS deployment. The following sections describe in detail the functionality of the above components.

Figure 1. - Distributed service discovery.
Figure 1.
Distributed service discovery.

Show All

Service Catalogue and Service Cache
The Service Catalogue and Service Cache are the key components of the NSM, containing all essential information of the network services that are available for CSC. In particular, each EC holds a Service Catalogue, which is a list of CSC-enabled service instances deployed at its edge infrastructure. Following the MESON architecture, the service specification is described via ETSI NFV NS descriptors and extended ETSI MEC application descriptors [2]. Based on this information, the matching between the requested services and the available CSC service instances is performed.

The Service Discovery Mechanism is responsible for the query message forwarding to discover the ECs that provide the desired CSC-enabled services. The message forwarding is based on the ECs' Service Cache content, which contains the id of the EC neighbour with the most recent advertised CSC-enabled services. The message contains the requested CSC-enabled services and information about the forwarding policy, such as the previously traversed ECs and the TTL value.
In addition to the Service Catalogue, the EC's Service Cache holds the most recent information about the available CSC-enabled services of the neighboring ECs. As shown in Table 1, for each entry, the Service Cache has a fixed size and first-in first-out (FIFO)-based updating policy.

Table 1. EC service cache example.

Service Discovery Mechanism
The service discovery mechanism is responsible for the query message forwarding to discover the ECs that provide the desired CSC-enabled services. The message forwarding is based on the ECs' Service Cache content, which contains the id of the EC neighbor with the most recent advertised CSC-enabled services. The message contains the requested CSC-enabled services and information about the forwarding policy, such as the previously traversed ECs and the time to live (TTL) value.

An NSE request can be submitted to any EC, which is called a Search Node, and the forwarding policy is based on the cache content of the Search Node. If one or more desired CSC-enabled services match one or more cache entries, the query message is forwarded to these ECs. Otherwise, the Search Node forwards the message to all of its neighbors. In both cases, TTL is decremented by one. These forwarding rules are applied to any EC that receives a query message until TTL becomes zero. As mentioned, the already traversed ECs are encapsulated in the query message to avoid repetitive messages on the same nodes. Also, each EC that has received a query responds to the sender EC with its most recent CSC-enabled services to update the respective cache entry. Finally, whenever at least one service match occurs, the EC sends a response to the Search Node, which contains information about the EC evaluation in the ECRM component.

Figure 1 illustrates an example of the SDM with three availability zones, namely Zone 1, Zone 2, Zone 3. Table 1 shows the cache entries of the ECs (2.a), (1.a), (1.c), (2.b) and (2.c). For this example, the TTL value is set to 3, and each cache entry contains up to three services for each neighbor EC. An NSE request is submitted to EC (2.a) (Search Node) that requires the CSC-enabled service s1. This service is hosted in the (1.a), (1.b), (2.b), (3.a), and (3.d) ECs. Based on its cache entries, the Search Node (2.a) forwards the request to the (1.a) and (2.b) ECs, as the s1 matches its corresponding entries for these ECs. Also, the (1.a) and (2.c) ECs forward the request based on the s1 record in their caches. The ECs that are flooding the request are (1.c) and (2.b), as their caches have no matching entry for s1. As shown in Table 1, the entry in the cache of (1.a) is out of date, as s1 is no longer hosted in EC (1.c). When ECs (1.b), (3.a), and (3.d) are reached, they do not forward the request further, as the TTL has zero value, so their caches are not included in Table 1. Every traversed EC sends two response messages. The first one is an update message to the neighbor EC that has sent the request, and contains the three most recent CSC-enabled services to be cached. The second is a response message to the Search Node about the requested service(s). The ECs hosting the requested service(s) are the candidate ECs and include in their responses to the Search Node the necessary information for the evaluation process.

Edge Cloud Ranking Mechanism
An NSE request can be submitted to any EC, which has a dedicated functionality for EC selection. In each EC, the ECRM selects the most appropriate EC for NS deployment and CSC establishment based on a set of functional, performance, and cost criteria and the set of desired CSC-enabled services. Extending the ranking mechanism of [11], the proposed ECRM is based on an analytic hierarchy process (AHP), which handles various types of numerical criteria. This provides the following enhancements:

The hard requirements are included in the structure of AHP in order to provide a more fine-grained evaluation regarding the hard requirements of the NSE request.

The virtual EC (VEC) is defined to express the set of a user's hard and soft requirements in terms of ranking data.

VEC profiles are defined based on the weight assignments and are used as a point of reference in the ranking process. For the technical details of AHP, the interested reader may refer to [11]. In the following, for completeness, we provide an overview of the ECRM.

Ranking Criteria – Hierarchical Structure
The AHP is based on a hierarchical structure, which consists of (technical) KPIs and (non-technical) attributes, as shown in Fig. 2. In our approach, the ranking is based on two sets of service requirements, namely hard requirements and soft requirements. Contrary to a simple filtering solution, the hard requirements (i.e., the availability zone of the EC and the CSC-enabled services) are included in the AHP model. This allows the ECRM to evaluate more EC candidates, which can be in different availability zones of the user's request. On the other hand, the soft requirements refer to performance, cost, and technical support criteria [11].

Figure 2. - Hierarchical model of the ranking mechanism.
Figure 2.
Hierarchical model of the ranking mechanism.

Show All

Weight Assignment – User's Requirements
As shown in Fig. 2, the weights on the edges of the hierarchical structure correspond to the relative importance of each KPI and attribute in the ranking computation and represent the individual requirements of every service request. Toward the customization of the user's requirements, the ECRM allows the user to assign the corresponding weight values for specific attributes and KPIs. In particular, the weights between the hard requirements, soft requirements, performance, and their descendants are user-defined. For each group of sibling attributes or KPIs, the sum of their weight values must be equal to one. Users are not allowed to define other weights in the structure in order to avoid misconceptions in the ranking process. Thus, a consistency ratio is computed for each group of sibling KPIs or attributes to avoid inconsistencies in the weight assignments [11].

AHP Ranking
After the discovery process, each candidate EC, in its response message to the Search Node, has advertised its data for the corresponding KPIs of the hierarchical structure, which are taken into account in the ranking process. At any level of the hierarchy, for each attribute, a relative ranking vector is computed, which provides a normalized score for every candidate EC for the specific attribute. Starting from the bottom level of the hierarchy, the upper-level vectors are computed. The top-level attribute corresponds to the overall ranking of the ECs. Eventually, the highest-scored EC is selected for service deployment.

VEC Candidate
Since the AHP provides a relative ranking of the EC candidates, we introduce the concept of the VEC as a point of reference that quantifies the distance between the user's requirements and the candidate ECs' offerings. Therefore, the appropriate values in the respective KPIs must be defined according to the user's requirements. Thus, based on the user-defined weight assignments, a specific VEC profile is selected automatically. Using a k-means algorithm and datasets of alternative weight assignments and KPI values, we define various VEC profiles. The cluster's parameters are the weight values of the attributes Cost (relative to the Performance), Computing Performance, and Network Performance, which prioritize the importance between the competitive criteria. As such, six different clusters of VEC are computed: Low Cost – High Computing Performance, Low Cost –High Network Performance, Low Cost – General Performance, Indifferent Cost – General Performance, Indifferent Cost – High Computing Performance, and Indifferent Cost – High Network Performance. Each VEC profile has predefined values for the KPIs to better reflect the user's requirements. Especially, the KPIs of the hard requirements are set equal to the user's desired values. The VEC is evaluated as a candidate EC, and its relative score implies that ECs with higher ranking satisfy the user requirements.

Evaluation
In this section, we evaluate the efficiency of the proposed EC selection mechanism. To this end, we consider a network of 300 ECs, subdivided into three availability zones (Zone1, Zone2, and Zone3). Based on real network topologies of regional providers [12], the sizes of these availability zones are set to 50, 100, and 150 ECs, respectively. A pool of 20 services for enabling CSC is available at every EC. Each EC can host from 5 to 15 CSC-enabled services. Furthermore, each EC advertises its values on the KPIs of the AHP model. These values are randomly selected using a uniform distribution. In order to highlight the impact of the important system parameters on the results of discovery and ranking, TTL varies from 1 to 8, while the size of service cache ranges from 3 to 5. In the following experiments, for each TTL value, 90 NSE requests with random values of hard and soft requirements are generated and uniformly assigned to the ECs of the three availability zones. Each of those requests is handled by the proposed mechanism for the different cache sizes. Furthermore, one or two CSC-enabled services are required in every NSE request.

The first experiment aims at assessing the SDM efficiency. In particular, the SDM is compared against a standard discovery technique, flooding, which broadcasts the query message to every neighbor of the sender EC. Flooding relies on the Breadth-First-Search (BFS) approach [13], which prevents repeating queries on an EC. In the following, we compare these two techniques in terms of generated communication overhead and network utilization. Also, we compare our solution with the NECOS centralized approach for discovery in a cloud resource marketplace [8] in terms of the total number of exchanged messages. The NECOS centralized broker is responsible for sending the NSE request to every EC and processing the corresponding responses.

Regarding the ECRM evaluation, we demonstrate a ranking of three ECs in order to quantify the potential gains from the use of the hard requirements in the AHP (instead of employing a simple filtering solution). We further assess the influence of the VEC on the ranking results. Finally, we provide additional remarks about the overall performance of the proposed mechanism.

SDM Evaluation
In this experiment, we compare the efficiency of the SDM against the flooding technique with diverse values of TTL and Service Cache size. In this respect, we measure the communication overhead as the percentage of utilized links. As shown in Fig. 3, the proposed SDM severely reduces the utilized links in the search-tree compared to flooding. More precisely, SDM yields a communication overhead of 9.5 percent on average, whereas the respective value for flooding is 23.2 percent. This low communication overhead is also reflected by the number of messages exchanged. In particular, the SDM generates 138 messages, as opposed to flooding in which 220 messages are exchanged (i.e., 38 percent reduction for SDM). We note that in SDM, each EC generates two messages, the cache update message and the response to the Search Node, while the flooding approach generates only one response message. Regarding the comparison with NECOS, we conduct experiments by setting the TTL equal to 8 to measure the generated messages in a search depth equal to the centralized approach. For different cache sizes (3–5), 30 requests are submitted from each of the availability zones. The centralized broker approach overall requires 600 request/response messages, while SDM generates an average of 304 messages, which further corroborates the efficiency of SDM compared with centralized solutions in terms of communication overhead.

Figure 3. - Generated communication overhead.
Figure 3.
Generated communication overhead.

Show All

Figure 4 illustrates the discovery capability of SDM (with a range of TTL values and cache sizes) and flooding. We use the cache hit rate as a metric, which corresponds to the ratio of the discovered ECs with at least one required CSC-enabled service over the total number of queried ECs. The average cache hit rate for SDM and flooding across all conducted tests are 56 and 47 percent, respectively. Furthermore, 76 percent of the candidate ECs evaluated by the ECRM are in the availability zone of the Search Node. Due to more queried ECs, this percentage is lower for the flooding approach. Regarding the cache size, the larger the cache is, the hit rate is slightly better (2–3 percent). From our tests, we infer that an efficient cache size is approximately 20 percent of the total available CSC-enabled services.


Figure 4.
Cache hit rate.

Show All

ECRM Evaluation
The first two columns of Table 2 include the name, weight, and type of KPIs of the AHP model. The following three columns contain the values of these KPIs for three ECs, whereas the last column contains the KPI values of the VEC, according to the chosen profile and the user's hard requirements. Following a bottom-up approach, a ranking vector is computed for the ECs, including the VEC. Due to lack of space, the rest of the attributes of the upper levels are omitted. All attributes and values of the weights are shown in Fig. 2.

Table 2. Advertised EC KPI data – VEC data.

As a point of reference, the VEC profile of Indifferent Cost – High Computing Performance is used in the ranking process. Following the AHP method, the overall ranking result is [0.322, 0.244, 0.196, 0.236], which means that the EC ranking from the best to the worst is EC1, EC2, VEC, EC3. As such, EC3 is considered as an unacceptable solution, since it is ranked below the VEC. The inclusion of the hard requirements in the AHP model and the addition of the VEC profile in the evaluation lead to a more fine-grained ranking, promoting the candidate ECs that better satisfy the user's requirements.

Also, a comment on the overall performance can be made. For all experiments, evaluating the candidate ECs discovered by the flooding technique provides at least one solution with higher ranking than the VEC. For the candidate ECs discovered by the SDM, the ECRM provides at least one solution that satisfies the user's requirements for 99.5 percent of the experiments. This result implies that most of the selected ECs for NS deployment are within the availability zone of the Search Node and that the proposed mechanism achieves identical efficiency to that of the greedy flooding approach with significantly lower communication overhead.

Conclusions
Enabling network service marketplaces is crucial for reaping the benefits of 5G network technologies. To this end, efficient CSC at the network edge can pave the way for service provisioning and cross-service interactions. In this article, we present a distributed EC selection framework toward 5G network service marketplaces. The proposed framework encompasses:

A service discovery mechanism, which yields low communication overhead and fast convergence, stemming from caching and the efficient reduction of search space

A multi-criteria ranking mechanism, which evaluates candidate ECs in terms of service deployment

Our future work will focus on extending our solution for multi-domain network service embedding in a distributed manner. Toward this direction, except for finding the CSC-enabled services, the distributed service discovery mechanism will build candidate multi-domain service chains for the final evaluation by the source node.