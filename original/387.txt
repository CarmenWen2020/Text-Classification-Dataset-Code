Telecommunication operators are increasingly integrating computational infrastructure into their networks at different location levels, including the network edge. This makes a highly distributed processing environment a reality, which is expected to enable next-generation services. This article proposes a novel and efficient algorithm to determine the best service execution locations through the “service edge,” a concept that groups services in categories according to their requirements and benefits from the flexibility of distributed cloud resources. The article is focused on describing the algorithm so that it can be integrated into the telco operators' management and orchestration systems. Simulation results underpin the practical feasibility of the proposed algorithm.

Introduction
Telecommunication operators are increasingly integrating computational infrastructure into their networks at different location levels, including the network edge. This makes a highly distributed processing environment a reality, which is expected to enable next-generation services. The authors propose a novel and efficient algorithm to determine the best service execution locations through the “service edge,” a concept that groups services in categories according to their requirements and benefits from the flexibility of distributed cloud resources.
Traditionally, telco networks (including both fixed and mobile networks) were designed following a hierarchical structure, with a precise function of traffic aggregation, having as a principal purpose the distribution of contents from the peering and transit points. This conventional design is being questioned due to the need to support different advanced services compelling a wide variety of performance requirements, traffic profiles, and connectivity types. Future telco networks will integrate cloud computing infrastructure [1] within several types of sites or points of presence (PoPs) of the operator's network, creating a topology that can satisfy service level objectives (SLOs) such as throughput, delay, and processing capacity. In that context, the objective for the telco operator will be to facilitate efficient distribution of the workload in the network, improving the overall network efficiency at the time of provisioning the services, accomplishing the expected user's service experience, and maximizing its profit. We understand profit here as the numerical expression of a given business policy. These PoPs will be distributed across different locations of the network [2], such as the operator's core network, central aggregation offices, base stations, and even on-premises or on-device. Figure 1 sketches the envisaged network. In the horizontal axis, we show the order of magnitude of the number of available cloud computing facilities quantified in three distinct domains. In the vertical axis, we show the order of magnitude of latency, expressed in milliseconds, that some services may require, hence being constrained to be deployed in edge, regional, or centralized computing facilities.

Figure 1. - Potential placement options depending on the type of service.
Figure 1.
Potential placement options depending on the type of service.

Show All

Nevertheless, latency is not the only SLO that can impact the location of services at deployment time. We are considering 3rd Generation Partnership Project (3GPP) service scenarios [3], [4], with the three types of 5G service categories, namely enhanced mobile broadband (eMBB), ultra-reliable low-latency communications (uRLLC), and massive machine type communications (mMTC). Services in these categories are characterized through different latency, jitter, or traffic density. All these performance parameters can be considered as constraints for deciding where to instantiate a given service. In addition, minimization of energy consumption, balancing network and cloud workloads, maximization of profit, and geographic or regulatory constraints are examples of complementary decision criteria. The adoption of a specific subset of these criteria is up to the telco operator.

Without lack of generality, the work presented in this article considers that services are characterized by the following four technical dimensions:

Throughput (T), as the data rate at which the service generates or consumes data

Latency (L), characterized by the end-to-end delay of the data transmission

Computation (C), associated with the processing needed by the number of sessions to be established

Storage (S), identified by the memory size of the data to be stored

The motivation to select these four dimensions is that they are key differentiating parameters of the three types of 5G service categories mentioned above, and, at the same time, they are directly related to the capabilities of the hosting infrastructure (both cloud and network infrastructures).

Moreover, in line with 5G, we assume that services are deployed on top of cloud-network slices. A cloud-network slice is constituted of slice parts, where each slice part is a bundle of computing and/or networking resources [5]. For illustrative purposes, a slice part could be represented utilizing the picture of Fig. 1; that is, a set of different types and locations of computing and networking resources that are shared among several isolated slice parts. On the other hand, a 5G service is usually deployed as a bundle of microservices, on top of the computing resources of one or several slice parts, to satisfy specific computation and storage requirements, being connected through network-slice parts, guaranteeing throughput and latency bounds. It is worth noting that different microservices of a given service can have different requirements, and therefore may need to be placed on different service edges. In that framework, the problem faced by the telco operator that we deal with in the article can be sketched as follows: given a set of services or parts of services (i.e., microservices), each specified by a set of requirements in terms of throughput, latency, computation, and storage needs, find the computing resources to host them, satisfying these requirements and maximizing the associated profit. In other words, our problem consists of finding the service edge, as described in our former work [6], for each one of these services or microservices. The grouping of microservices into deployment units to be deployed jointly in the same computing facility is service-specific and falls outside the scope of this article.

Having a service orchestration tool to solve, fully automated, the above problem will become a must for telco operators aiming to rationalize the investment needed to support a high number of computing facilities on the network. Selecting the most appropriate execution environment for each service is, in essence, an exercise of efficiency and optimization. This article describes an efficient mechanism for service deployment on computational infrastructures, taking into consideration parameters like throughput, latency, computation, and storage. With that aim, it extends and complements the work in [6] by modeling the problem as a multidimensional flow problem and proposing a new heuristic technique to solve it. This heuristic leverages realistic assumptions on the number of service and infrastructure types that can be encountered, addressing the typically intractable problem of optimally allocating multi-requirement services on hosting infrastructure. Its principal characteristic is that the time needed to solve the problem is short enough to be used in practical decision-aided systems in operational networks with results very close to the optimum. We envisage the proposed mechanism as part of the service management and orchestration system used by telco operators for the deployment of services when transitioning toward a softwarized network approach.

The article is organized as follows. The section after this brings the necessary background to pave the way to describe our proposed heuristic; then we present the first contribution of the article, which consists of an extension of the conventional Successive Shortest Path algorithm (SSP) to a multidimensional space, which is called the Vectorial Successive Shortest Path (VSSP) algorithm, setting the ground of the following section, where we show how the proposed VSSP algorithm can be used to decide the allocation of services on the existing computing environments. That is the second contribution of the article. Later, we provide a simulation-based evaluation comparing the results of the proposed heuristic with the optimum solution given, when possible, by a mixed integer linear programming (MILP) solver. The final section concludes the article and presents some future steps.

The Problem of Assigning Services to Hosting Infrastructure
As stated in the previous sections, our contribution is an algorithm that maximizes the profit of telco operators deploying services, or microservices, in their respective optimal service edges. As described in [6], the concept of service edge is an extension of the physical network edge. In fact, a service edge is characterized by a set of characteristics, which in this work are materialized as the throughput at which the service will be working, its end-to-end latency, and the computation and storage capabilities offered to that particular service. Services hosted in their optimal service edges will also fulfill their respective service level agreements (SLAs) in terms of the above mentioned four characteristics.

The problem we are solving by means of the proposed algorithm is a particular case of the well-known Assignment Problem [7]. Although later in the article we address more complex versions, we start the description of our proposal with a simple version of the problem; in it, services require only one type of resource (e.g., storage).

A common way to solve this kind of problem is through a modeling strategy that uses flow networks. Flow networks are used in [8] to minimize the cost of virtual switching induced by a network function virtualization (NFV) service chain deployment. This is a different problem, albeit related to ours, showing the power of that modeling instrument.

A flow network is a graph constituted by a set of nodes and a set of edges; on this graph, a hypothetical flow emerges from one of the nodes (the source), flows through the edges passing through intermediate nodes, and disappears in the sink node (see [9] for more details). Following a common way of using this abstraction, the Assignment Problem can be modeled as a flow network with four layers, as in Fig. 2: one layer composed of a single source node s; a layer of nodes, each representing a different type of service; another layer of nodes representing types of computing infrastructure; and finally, a layer corresponding to the sink node t. Nodes representing service types and infrastructure types are interconnected through a full mesh of graph edges. Please note that to avoid confusion with the edges of the telco network or even its communication links, we refer to the edges of the flow network graph as graph edges. Each graph edge is characterized with a weight and a capacity whose roles are described hereafter.


Figure 2.
The assignment problem modeled as a network flow problem.

Show All

Essential to understand how a flow network works are the flows between service type nodes and resource type nodes. A flow between a given service type and resource type is an integer that accounts for the total amount of resources needed by services of this type. These flows are indeed determined by the algorithm adopted to solve the problem. The flow conservation property must hold at each node, meaning that the flow entering into a service type node must be equal to the sum of flows leaving that node. It is also worth mentioning that the flow leaving a given infrastructure type node toward the sink node, representing the total amount of resources needed of that type of infrastructure, cannot exceed the resources available in that specific type of infrastructure. The weight of a graph edge linking a service type with an infrastructure type (i.e., from layer 2 to 3) is the one minus the normalized profit the telco operator obtains deploying that service type in that infrastructure type. Graph edges where either the source or sink nodes are involved have no weight assigned. This way, looking for the minimum weight flow from source to target is equivalent to looking for the flow that maximizes the profit.

A well-known algorithm to compute the minimum weight flow is SSP [10]. SSP looks for the maximum flow with the minimum weight that can be injected from the source node to the sink node on a flow network graph, as represented in Fig. 2.

This algorithm aims to iteratively look for the path of minimum aggregated weight between the source and the sink and then “send” as much flow as possible through that path. Observe that the weight of a graph edge can also be seen as a distance from one end to the other of that edge; this is the reason to talk about “shortest path” as synonymous with minimum weight path. This is exemplified by the red flow shown in the first step of Fig. 3, which carries a maximum flow of two units through a path whose accumulated weight is 1+1+1=3 units. This maximum flow reduces the capacity of the graph edges that constitute the path to support other flows. In the following iteration, to allocate the subsequent flow, we can realize that it would be better to send the initial flow through a higher weight path and avoid blocking the second flow, which is a stream that shares some links of the path mentioned above. To solve that, the idea is to allow the algorithm to “push backward” some already established flow to make space for a new one that would add more flow. Observe that allowing a higher flow means allocating more resources and therefore get a higher profit. That is represented in the second step of Fig. 3, where the green flow of two units is pushing back the red flow to leave the solution, as represented in the third step of Fig. 3.


Figure 3.
Three consecutive steps solving the assignment problem utilizing SSP. labels are pairs (w,r) where w is the weight of the graph edge and r is its capacity.

Show All

The advantage of this algorithm is in terms of its complexity from the point of view of the runtime, which has been demonstrated to be the lowest among the set of known approaches to solve the minimum weight maximum flow problem. A detailed description of the algorithm can be found in [10].

Vectorial Successive Shortest Path
The one-dimensional (only one type of resource) assignment problem is not enough to model our 5G scenarios because they require specifying several simultaneous service requirements and the availability of different resources. Elaborating a similar idea, but for multidimensional flows (each flow is characterized by a vector of flows), it is not straightforward. Those different dimensions of the flow must be conveyed together. A key contribution of this article is to extend the solution described for a one-dimensional flow network to a multidimensional one.

To highlight our approach, let us consider the main differences of the model with respect to the one-dimensional case. We depart, as before, from a graph constituted by a subset of nodes representing service types, another subset representing resource types, a source, and a sink. Flows are also from the source to the sink going through different links in the graph. One difference is that now, flows are vectors with as many components as dimensions we consider. Recall that such dimensions are related to throughput, latency, computation, and storage, as described above. In addition, another difference is that now, as the flows injected into the graph network are vectors, the graph edge's capacity is a vector with components in each of the dimensions.

Similar constraints to the one-dimensional case can be formulated. In particular, flows have to be routed through the graph so that those passing through a given graph edge must carry an accumulated flow that is lower than or equal to the graph edge capacity in each dimension. In addition, the incoming flow at each node must be equal to the flow leaving it, except for the source and sink nodes.

The idea to extend the SSP algorithm to a multidimensional setup and thus the base of a novel algorithm, VSSP, is that as in SSP, VSSP successively searches for the path of minimum weight between the source and the sink, and then “sends” as much flow as possible through that path, this is, as much flow as can pass through the thinner path's edge.

To illustrate how VSSP works, let us consider a simplified example, with vectors of only two dimensions. Any graph edge will look like the one represented in Fig. 4 with two different pipes, namely, the red and green ones. These two pipes have capacities as thoseshown in the cut highlighted in the top right. The figure also shows two different types of services to be allocated, the yellow and turqoise types; each type has red and green requirements and a number of service instances each. As in SSP, VSSP has to pass through this graph edge some flows corresponding to service instances selected so that the maximum number of instances is taken without exceeding the capacities of both pipes. That is a well-known combinatorial optimization problem called the multi-knapsack problem [11]. This combinatorial problem is known to exhibit non-polynomial (NP) time complexity; however, as the size of the problem is bounded by the number of dimensions of each infrastructure type, the problem can be solved in practice as MILP [11] utilizing a solver like Matlab's intlinprog, among others.


Figure 4.
At each graph edge, accommodating different services to optimize the use of the different resources is equivalent to solving a multi-knapsack problem.

Show All

As in SSP, we can realize that it would be globally better to send part of the previous flow through a higher weighted path and avoid blocking a more significant stream at each iteration. In this case, we proceed as the SSP does “pushing” backward some flow that is already passing through some graph edges and make space for a new one that would add more flow. The particularity in VSSP is that this flow retraction has to be performed for all dimensions in the proportions defined by the services represented by those flows. In the pictorial representation of Fig. 4, the amount of red flow and green flow retracted from the graph edge must be equal to the amounts used by some combination of the yellow and turqoise services crossing that graph edge.

Contrary to SSP, we cannot guarantee that VSSP ends up with the optimum solution. In addition, the complexity of VSSP is higher than SSP, but as shown in the evaluation section, the time needed for computation in practical scenarios is short enough to be considered a feasible solution.

Solving the Edge Assignment Problem with VSSP
5G infrastructures, such as those considered in this article, might be potentially sized in some thousands of nodes, and the number of services to be allocated can be of a similar order. To reduce the size of the problem and make it computationally tractable, we assume that each infrastructure element (i.e., computation server) belongs to a type, like those in Fig. 1, with common characteristics in terms of storage capacity, computation power, and available throughput. Hence, we have a set of different infrastructure element types, each constituting what we call a service edge [6]. Each of these infrastructure element types will be characterized by a three-dimensional vector of available resources corresponding to its maximum bandwidth, computation, and storage capacity (the delay dimension is accounted for differently, as explained later). In addition, we also assume that each service or service component to be allocated belongs to a type with common requirements such as bandwidth, computation power, storage, and delay. Consequently, we have a set of different service types. We also assume that when a service of a particular type is deployed on a particular type of infrastructure element, it generates a given profit for the operator. Hence, we model the service edge selection as a vectorial, minimum-weight, maximum-flow problem, suitable to be solved employing the proposed VSSP heuristic.

Therefore, we build a graph organized into four layers as in Fig. 2. Layers 1 and 4 contain just the source and sink nodes, s and t. The flow generated by s consists of a vector with integer components, each representing the total resources in each dimension. The sink node t at layer 4 absorbs the vector flow generated at the source. Layer 2 has as many nodes as service types, whereas layer 3 has as many nodes as different infrastructure element types.

All the graph edges have the same format, namely, a scalar representing the weight of that edge and a three-dimensional vector with the flow capacities of that edge in each of the three dimensions. In the following paragraphs, we describe the values adopted for each graph edge.

Each graph edge between layers 1 and 2 is assigned a zero weight and a capacity vector that allows carrying the total aggregated flows of the service type this graph edge connects. The reason to assign a zero weight to those graph edges is that the routing of a given amount of flow to a particular service type node is dictated by the number of services of that particular service type and therefore does not have to be decided by the optimization algorithm.

The graph edges from layer 2 to layer 3, between a given service type and an infrastructure type, are weighted with a scalar that is the profit induced by deploying that service type on that infrastructure type with a negative sign. In this way, we play with weights derived from telco operator profits and leave the algorithm to select the graph edges that minimize weights (maximize profits). The capacity vector, in this case, is infinity in each of the three dimensions; that is, the capacity is not constrained here because the constraints posed by the infrastructure types in each dimension are better represented by the subsequent graph edges, as explained hereafter.

Graph edges between layers 3 and 4 have assigned zero weight and a capacity vector representing the total capacity in each dimension, supported by the infrastructure type at which each graph edge is connected. Observe that in this way, we include the resource capacity constraints in our model. On the other hand, the reason to assign zero weight to these graph edges is similar to assigning zero weight to graph edges between layers 1 and 2.

Finally, to model the delay constraints, we remove all graph edges between services and those infrastructure element types not fulfilling the delay requirements. It is worth noting that our approach would allow the modeling of more fine-grained delay specifications, but for that case, it would be necessary to create additional infrastructure element types quantifying the delay attribute.

Service Allocation at Service Request Time
As the reader may have noted, the process described above works for allocating a complete set of services at the same time (e.g., all services requested within a given time window are deployed together at a given time). Nevertheless, in a more realistic scenario, services have to be allocated as soon as requested by their customers. It would be service-disruptive to re-allocate all the services every time a new request arrives; however, the method presented here permits assigning a new service request by just recomputing the flow of its particular service type. VSSP permits doing that very fast because it requires only a single iteration to compute the augmented flow. The same idea and complexity are valid for removing a service. The reader may notice that just recomputing a restricted number of flows may end up with results that may not be as good as if we were running the algorithm from scratch again. Nevertheless, the accuracy of that approximation is out of the scope of the article and left for future work.

Evaluation
In order to compare the performance of our approach, we selected a ground truth reference provided by a well-established solver of MILP problems. By ground truth we refer to an ideal value or gold standard that might not be found with the available resources of a real deployment. With this purpose, we use Matlab's intlinprog [12], which uses a sequence of strategies that have been accepted as very effective at solving MILP problems [13]. Although this solver might find the optimum solution (when it does not, it can detect and inform this situation), it does not scale well with the problem's size. Therefore, the comparison we present in this section was made in the problem size range where intlinprog was able to find a solution in a reasonable time.

This evaluation aims to show that VSSP finds the service edges acceptably close to the actual optimum (given by our ground truth) in a period of time that is compatible with the management and orchestration processes of cloud-based telco networks. Thus, we present the results of two experiments:

A comparison between the time spent by VSSP and MATLAB's intlinprog to solve problems of the same size

A comparison between the profit obtained through the solution of VSSP and this solution

The experiments made for this evaluation were performed on a synthetic network where only relevant aspects of topology and resources were simulated. The setup was configured to have always 10 service types with 100 service instances each. Service types ranged from 3 to 30 normalized units of storage, throughput, and computing requirements in intervals of three units. The number of infrastructure types was swept from 5 to 15. Infrastructure types range from 240 to 430 normalized available units of storage, throughput, and computation, in intervals of at most 25 units. The number of infrastructure elements inside each infrastructure type is set such that all their resources together can support 90 percent of the total service demand.

For this evaluation, we avoided lineal profit schemes to stress the edge selection method's time complexity; lineal schemes would make the problem easier to solve. Thus, the telco operator profit scheme is logarithmic in the number of resources required by a service type and inversely logarithmic in the size of the resources available in a particular infrastructure element.

The tests were run on an Intel® Core™ i7-8550U CPU, at 1.80 GHz, with 16 GB of RAM.

Figure 5 depicts in logarithmic scale the running time to achieve the solution for VSSP and Matlab's intlinprog solver as a function of the number of infrastructure types. The plots are the mean of 10 experiments, and the error bars represent the 95 percent confidence interval. The circles correspond to cases in which the intlinprog solver gives up timing out before reaching the optimum, which is normal behavior for this solver.


Figure 5.
Running times for VSSP and matlab's intlinprog solver in a logarithmic scale. Green circles correspond to cases in which the intlinprog solver gave up per time before reaching an optimum.

Show All

In this graph, it is possible to appreciate the significant runtime difference between solving the problem using the MILP solver and VSSP. As mentioned, the 15 infrastructure types boundary was set to let the MILP solver finish in a reasonable time, but VSSP can deal with a much larger problem size. Although not included among the results for the sake of brevity, VSSP scales well, as inferred from the trend of the figure's plot.

Figure 6 shows the total profit induced by the solutions computed by VSSP and Matlab's intlinprog solver. Again, the plots are the mean of 10 experiments, and the error bars are the 95 percent confidence interval. The number of service instances per service type is always 100, and the number of servers per infrastructure type changes to keep a ratio demand/offer of 0.9.

Figure 6. - Total profit induced by VSSP and Matlab's intlinprog solver.
Figure 6.
Total profit induced by VSSP and Matlab's intlinprog solver.

Show All

From this graph, we conclude that VSSP computes a sub-optimal solution close to the optimum computed by MATLAB's MILP solver; however, this is made in a time that in some cases is several orders of magnitude shorter, enabling its use in cloud-network orchestration systems.

Concluding Remarks
This article proposes a technique for allocating services to computational resources spread over all network domains to fulfill heterogeneous service requirements in the context of 5G and beyond.

We formulate this service allocation problem and elaborate on how to solve it by extending the solution of a similar but simpler problem. This extension is called Vector Successive Shortest Path (VSSP), a heuristic derived from the well-known Successive Shortest Path (SSP) algorithm, which constitutes a contribution of the article to the state of the art. In addition, as a second contribution, we describe how to use VSSP to solve the allocation problem when services are characterized by four requirements: throughput, latency, computation, and memory storage.

Simulations have been conducted to compare the results obtained with VSSP against a conventional mixed integer linear programming solver, which gives the optimum allocation. Results show relatively close telco operator profit for both but with orders of magnitude less computation time when obtained by VSSP. This shows that our solution approach is precise enough and scalable to be used in more complex scenarios. The impact of incrementally assigning/de-assigning services as soon as these services are requested or terminated is also addressed without disrupting those already deployed. However, its accuracy analysis is a significant challenge that is left for future work.

Our solution approach is precise enough and scalable to be used in more complex scenarios. The impact of incrementally assigning/de-assigning services as soon as these services are requested or terminated is also addressed without disrupting those already deployed. However, its accuracy analysis is a significant challenge that is left for future work.
Solutions like our approach are needed to efficiently select the execution environment for services on distributed cloud facilities of different characteristics. This is a challenging problem that is going to be faced soon by telco operators. Even for delay-sensitive services, the service location is not necessarily the physical edge of the network but some other location convenient for respecting the committed SLOs, which is called the service edge. The performance of the VSSP algorithm reported in this article makes it a firm candidate to find the service edge and therefore to be integrated on cloud-network orchestration systems (e.g., [14]).


