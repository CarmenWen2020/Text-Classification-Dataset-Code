Acoustic propagation is characterized by three major factors: attenuation that increases with signal frequency, time-varying multipath propagation, and low speed of sound (1500 m/s). The background noise, although often characterized as Gaussian, is not white, but has a decaying power spectral density. The channel capacity depends on the distance, and may be extremely limited. Because acoustic propagation is best supported at low frequencies, although the total available bandwidth may be low, an acoustic communication system is inherently wideband in the sense that the bandwidth is not negligible with respect to its center frequency. The channel can have a sparse impulse response, where each physical path acts as a time-varying low-pass filter, and motion introduces additional Doppler spreading and shifting. Surface waves, internal turbulence, fluctuations in the sound speed, and other small-scale phenomena contribute to random signal variations. At this time, there are no standardized models for the acoustic channel fading, and experimental measurements are often made to assess the statistical properties of the channel in particular deployment sites.

Introduction
Underwater acoustic channels are generally recognized as one of the most difficult communication media in use today. Acoustic propagation is best supported at low frequencies, and the bandwidth available for communication is extremely limited. For example, an acoustic system may operate in a frequency range between 10 and 15 kHz. Although the total communication bandwidth is very low (5 kHz), the system is in fact wideband, in the sense that bandwidth is not negligible with respect to the center frequency.

Sound propagates underwater at a very low speed of approximately 1500 m/s, and propagation occurs over multiple paths. Delay spreading over tens or even hundreds of milliseconds results in frequency-selective signal distortion, while motion creates an extreme Doppler effect. The worst properties of radio channels — poor physical link quality of a mobile terrestrial radio channel and high latency of a satellite channel — are combined in an underwater acoustic channel.

In this article we take a tutorial overview of the channel properties, aiming to reveal those aspects of acoustic propagation that are relevant for the design of communication systems.

The article is organized into three sections that address attenuation and noise, multipath propagation, and the Doppler effect. Implications of acoustic propagation extend beyond the physical layer, and we conclude the article in the final section by considering their impact on the design of future underwater networks.

Attenuation and Noise
A distinguishing property of acoustic channels is the fact that path loss depends on the signal frequency. This dependence is a consequence of absorption (i.e., transfer of acoustic energy into heat). In addition to the absorption loss, signal experiences a spreading loss, which increases with distance. The overall path loss is given by
A(l,f)=(l/lr)ka(f)l−lr,(1)
View SourceRight-click on figure for MathML and additional features.where f is the signal frequency and l is the transmission distance, taken in reference to some lr. The path loss exponent k models the spreading loss, and its usual values are between 1 and 2 (for cylindrical and spherical spreading, respectively). The absorption coefficient a(f) can be obtained using an empirical formula [1]. Figure 1 illustrates its rapid increase with frequency.

Figure 1. - Absorption coefficient, 10 log a(f)in dB/km.
Figure 1.
Absorption coefficient, 10 log a(f)in dB/km.

Show All

Noise in an acoustic channel consists of ambient noise and site-specific noise. Ambient noise is always present in the background of the quiet deep sea. Site-specific noise, on the contrary, exists only in certain places. For example, ice cracking in polar regions creates acoustic noise as do snapping shrimp in warmer waters. The ambient noise comes from sources such as turbulence, breaking waves, rain, and distant shipping. While this noise is often approximated as Gaussian, it is not white. Unlike ambient noise, site-specific noise often contains significant non-Gaussian components. Figure 2 shows the power spectral density of ambient noise for several values of wind speed (wind drives the surface waves) and several levels of distant shipping activity (which is modeled on a scale from 0 to 1). The power spectral density of ambient noise decays at a rate of approximately 18 dB/decade, as shown by the straight dashed line in Fig. 2 [1].

Figure 2. - Power spectral density of the ambient noise.
Figure 2.
Power spectral density of the ambient noise.

Show All

The attenuation, which grows with frequency, and the noise, whose spectrum decays with frequency, result in a signal-to-noise ratio (SNR) that varies over the signal bandwidth. If one defines a narrow band of frequencies of width Δf around some frequency f, the SNR in this band can be expressed as
SNR(l,f)=Sl(f)/A(l,f)N(f),(2)
View SourceRight-click on figure for MathML and additional features.where Sl(f) is the power spectral density of the transmitted signal. For any given distance, the narrowband SNR is thus a function of frequency, as shown in Fig. 3. From this figure it is apparent that the acoustic bandwidth depends on the transmission distance. In particular, the bandwidth and power needed to achieve a prespecified SNR over some distance can be approximated as B(l)=b⋅l−β,P(l)=p⋅lψ, where the coefficients b,p and the exponents β∈(0,1),ψ≥1 depend on the target SNR, the parameters of the acoustic path loss, and the ambient noise [2]. The bandwidth is severely limited at longer distances: at 100 km, only about 1 kHz is available. At shorter distances, the bandwidth increases, but will ultimately be limited by that of the transducer. The fact that bandwidth is limited implies the need for bandwidth-efficient modulation methods if more than 1 b/s/Hz is to be achieved over these channels.


Figure 3.
Signal-to-noise ratio in an acoustic channel depends on the frequency and distance through the factor 1/A(1, f)N(f).

Show All

Another important observation to be made is that the acoustic bandwidth is often on the order of the center frequency fc. This fact bears significant implications for the design of signal processing methods, as it prevents one from making the narrowband assumption (B<<fc) on which many radio communication principles are based. Respecting the wideband nature of the system is particularly important in multichannel (array) processing and synchronization for mobile acoustic systems.

Finally, the fact that the acoustic bandwidth depends on the distance has important implications for the design of underwater networks. Specifically, it makes a strong case for multihopping, since dividing the total distance between a source and destination into multiple hops enables transmission at a higher bit rate over each (shorter) hop. The same fact helps to offset the delay penalty involved in relaying. Since multihopping also ensures lower total power consumption, its benefits are doubled from the viewpoint of energy-per-bit consumption on an acoustic channel.

Multipath
Multipath formation in the ocean is governed by two effects: sound reflection at the surface, bottom, and any objects, and sound refraction in the water. The latter is a consequence of the spatial variability of sound speed. Figure 4 illustrates the two mechanisms. Sound speed depends on the temperature, salinity, and pressure, which vary with depth and location; and a ray of sound always bends toward the region of lower propagation speed, obeying Snell's law. Near the surface, both the temperature and pressure are usually constant, as is the sound speed. In temperate climates the temperature decreases as depth begins to increase, while the pressure increase is not enough to offset the effect on the sound speed. The sound speed thus decreases in the region called the main thermocline. After some depth, the temperature reaches a constant level of 4°C, and from there on, the sound speed increases depth (pressure). When a source launches a beam of rays, each ray will follow a slightly different path, and a receiver placed at some distance will observe multiple signal arrivals. Note that a ray traveling over a longer path may do so at a higher speed, thus reaching the receiver before a direct stronger ray. This phenomenon results in a non-minimum phase channel response.


Figure 4.
Multipath formation in shallow and deep water. Below, sound speed as a function of depth and the corresponding ocean cross-section.

Show All

The impulse response of an acoustic channel is influenced by the geometry of the channel and its reflection and refraction properties, which determine the number of significant propagation paths, and their relative strengths and delays. Strictly speaking, there are infinitely many signal echoes, but those that have undergone multiple reflections and lost much of the energy can be discarded, leaving only a finite number of significant paths.

To put a channel model in perspective, let us denote by lp the length of the pth propagation path, with p=0 corresponding to the first arrival. In shallow water, where sound speed can be taken as a constant c, path lengths can be calculated using plane geometry, and path delays can be obtained as τp=lp/c.

Surface reflection coefficient equals ‡1 under ideal conditions, while bottom reflection coefficients depend on the type of bottom (hard, soft) and grazing angle [3]. If we denote by Γp the cumulative reflection coefficient along the pth propagation path, and by A(lp,f) the propagation loss associated with this path, then
Hp(f)=ΓpA(lp,f)−−−−−−√(3)
View SourceRight-click on figure for MathML and additional features.represents the frequency response of the pth path. Hence, each path of an acoustic channel acts as a low-pass filter, which contributes to the overall impulse response,
h(t)=∑php(t−τp),(4)
View Sourcewhere hp(t) is the inverse Fourier transform of Hp(f).

Figure 5 illustrates the multipath properties for a system operating near the bottom of a 1 km long, 15 m deep channel, with a spreading factor k=1.5, and a 3 dB loss associated with each bottom reflection. Results are shown for the first seven paths: the individual path transfer functions Hp(f) and responses hp(t) are in the top row, while the overall transfer function and response (magnitudes) are below. The total multipath spread is governed by the longest path delay, which is on the order of tens of milliseconds, a value typically observed in shallow water experiments. The individual path dispersion is much less than the total multipath spread, and can be ignored for systems whose maximal frequency lies well below the channel cutoff (several tens of kilohertz in our example). This is normally the case in systems that are in use today; however, as transducer technology advances and higher bandwidths become available, this effect may become non-negligible. Any approximations that may result from the general model depend on the spectral occupancy of the signal.

Figure 5. - Channel response functions.
Figure 5.
Channel response functions.

Show All

Time Variability
There are two sources of the channel's time variability: inherent changes in the propagation medium and those that occur because of the transmitter/receiver motion. Inherent changes range from those that occur on very long timescales that do not affect the instantaneous level of a communication signal (e.g., monthly changes in temperature) to those that occur on short timescales and affect the signal. Prominent among the latter are changes induced by surface waves, which effectively cause the displacement of the reflection point, resulting in both scattering of the signal and Doppler spreading due to the changing path length.

It is beyond the scope of the present treatment to summarize what is known about statistical characterization of these apparently random changes in the channel response. Suffice it to say that unlike in a radio channel, where a number of models for both the probability distribution (e.g., Rayleigh fading) and the power spectral density of the fading process (e.g., the Jakes' model) are well accepted and even standardized, there is no consensus on statistical characterization of acoustic communication channels. Experimental results suggest that some channels may just as well be characterized as deterministic, while others seem to exhibit Rice or Rayleigh fading [4]. However, current research indicates K-distributed fading in other environments [5]. Channel coherence times below 100 ms have been observed [6] but not often. For a general-purpose design, one may consider coherence times on the order of hundreds of milliseconds. In the absence of good statistical models for simulation, experimental demonstration of candidate communication schemes remains a de facto standard.

As an illustrative example, Fig. 6 shows the results of a recent experiment that took place in Narragansett Bay near the coast of Rhode Island. The transmitter and receiver were mounted on fixed tripods at 4 and 2 m above the bottom, at a distance of 1 km, with the channel depth ranging between 9 and 14 m. The sea condition was calm. A pseudo-noise (PN) sequence of length 4095, binary phase shift keying (BPSK) modulated onto a 13 kHz carrier, was transmitted repeatedly at a rate of 10 kb/s. The received signal was digitally downconverted, decimated to 2 samples/bit, and correlated with the replica of the PN signal in the baseband. These figures reveal a channel consisting of multipath arrivals, whose amplitude varies in time in such a manner that there is no clearly defined strongest arrival. The phase (not shown) exhibits random behavior around a constant slope, corresponding to a small but different Doppler shift on each of the arrivals. Some histograms resemble a Ricean distribution; however, more measurements need to be made before firm conclusions can be drawn. These analyses will have a major impact on the design of future systems, particularly on assessing the capacity improvement available from adaptive modulation methods and multi-input multi-output (MIMO) communications.

Figure 6. - Multipath intensity profile, time variation of the amplitude and the corresponding histograms of the arrivals marked a, b, c, d.
Figure 6.
Multipath intensity profile, time variation of the amplitude and the corresponding histograms of the arrivals marked a, b, c, d.

Show All

The Doppler Effect
Motion of the transmitter or receiver contributes additionally to the changes in channel response. This occurs through the Doppler effect, which causes frequency shifting as well as additional frequency spreading. The magnitude of the Doppler effect is proportional to the ratio a=v/c of the relative transmitter-receiver velocity to the speed of sound. Because the speed of sound is very low compared to the speed of electro-magnetic waves, motion-induced Doppler distortion of an acoustic signal can be extreme. Autonomous underwater vehicles (AUVs) move at speeds on the order of a few meters per second, but even without intentional motion, underwater instruments are subject to drifting with waves, currents, and tides, which may occur at comparable velocities. In other words, there is always some motion present in the system, and a communication system has to be designed taking this fact into account. The only comparable situation in radio communications occurs in low Earth orbiting (LEO) satellite systems, where the relative velocity of satellites flying overhead is extremely high (the channel there, however, is not nearly as dispersive). The major implication of motion-induced distortion is on the design of synchronization and channel estimation algorithms.

These analyses will have a major impact on the design of future systems, and in particular on assessing the capacity improvement available from adaptive modulation methods and multi-input multi-output (MIMO) communications.
The way in which these distortions affect signal detection depends on the actual value of factor a. For comparison, let us look at a highly mobile radio system. At 160 km/h (100 mph), we have a=1.5⋅10−7. This value is low enough that Doppler spreading can be neglected. In other words, there is no need to account for it explicitly in symbol synchronization. The error made in doing so is only 1/1000 of a bit per 10, 000 bits. In contrast to this situation, a stationary acoustic system may experience unintentional motion at 0.5 m/s (1 knot), which would account for a=3⋅10−4. For an AUV moving at several meters per second (submarines can move at much greater velocities), factor a will be on the order of 10−3, a value that cannot be ignored.

Non-negligible motion-induced Doppler shifting and spreading thus emerge as another major factor that distinguishes an acoustic channel from the mobile radio channel, and dictates the need for explicit phase and delay synchronization in all but stationary systems. In multicarrier systems, the Doppler effect creates particularly severe distortion. Unlike radio systems, in which time compression/dilation is negligible and the Doppler shift appears equal for all subcarriers, in an acoustic system each subcarrier may experience a markedly different Doppler shift, creating nonuniform Doppler distortion across the signal bandwidth.

As the history of underwater acoustic communications testifies, major advances in signal processing were made when the physical nature of propagation was taken into account through proper channel modeling. Examples that illustrate this fact include combined modeling of multipath and phase distortion for equalization in single-carrier wideband systems [7], a method used in a real-time acoustic modem [8]. More recently, detection of multicarrier signals has been shown to benefit from explicit Doppler shift modeling [9], while sparse channel estimation, which recognizes the fact that underwater multipath is not contiguous but consists of isolated signal arrivals, is being used to improve the performance of both single-carrier [10], [11] and multicarrier systems [12]. Research is currently active on assessing the improvements available from MIMO acoustic communication channels [13], [14].

System Constraints and Implications on Network Design
In addition to the fundamental limitations imposed by acoustic propagation, there are system constraints that affect the operation of acoustic modems. The most obvious of these constraints is the fact that acoustic transducers have their own bandwidth limitation, which constrains the available bandwidth beyond that offered by the channel. The system constraints affect not only the physical link, but all the layers of a network architecture.

In an acoustic system, the power required for transmitting is much greater than that required for receiving. Transmission power depends on the distance, and its typical values are on the order of tens of watts.1 In contrast, the power consumed by the receiver is much lower, with typical values ranging from about 100 mW for listening or low-complexity detection, to no more than a few watts required to engage a sophisticated processor for high-rate signal detection. In sleep mode, from which a node can be woken on command, no more than 1 mW may be needed.

Underwater instruments are battery-powered; hence, it is not simply the power, but also the energy consumption that matters. This is less of an issue for mobile systems, where the power used for communication is a small fraction of the total power consumed for propulsion, but it is important for networks of fixed bottom-mounted nodes, where the overall network lifetime is the figure of merit.

One way to save energy is by transmitting at a higher bit rate. For example, the WHOI modem [8] has two modes of operation: high rate at 5 kb/s and low rate at 80 b/s. This modem will require about 60 times less energy per bit (18 dB) in high-rate mode. The receiver's energy consumption will also be lower, although it requires 3 W for detection of high-rate signals as opposed to 80 mW for detection of low-rate signals (the difference is about 2 dB).

Another way to save the energy is by minimizing the number of retransmissions. In random access networks, which are suitable for serving a varying number of users that transmit in a bursty manner, this task is made difficult by high channel latency. For example, the basic principle of carrier sensing multiple access — that a node should transmit only if it hears no ongoing transmissions — is compromised in an acoustic channel where the packets propagate slowly, and the fact that none are overheard does not mean that some are not present in the channel. Interestingly, increasing the bit rate makes the packets shorter, thus reducing the chances of collision, which in turn reduces the energy spent in retransmissions. The low speed of sound further challenges the throughput efficiency of any data link control scheme that requires automatic repeat request (ARQ), because current technology supports only half-duplex operation.

At this time, it is not certain how underwater networks will develop as possible applications depend on network capabilities, which are still in the domain of research. For both ad hoc and infrastructure-based networks, acoustic propagation implies design principles that may be quite different from those used in radio networks [15], while the harshness of the environment dictates systems that are neither small nor easily deployable, and certainly not inexpensive or disposable.