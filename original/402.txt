The emerging advances in personal devices and privacy concerns have given the rise to the concept of Federated Learning. Federated Learning proves its effectiveness and privacy preservation through collaborative local training and updating a shared machine learning model while protecting the individual data-sets. This article investigates a new type of vehicular network concept, namely a Federated Vehicular Network (FVN), which can be viewed as a robust distributed vehicular network. Compared to traditional vehicular networks, an FVN has centralized components and utilizes both DSRC and mmWave communication to achieve more scalable and stable performance. As a result, FVN can be used to support data-/computation-intensive applications such as distributed machine learning and Federated Learning. The article first outlines the enabling technologies of FVN. Then, we briefly discuss the high-level architecture of FVN and explain why such an architecture is adequate for Federated Learning. In addition, we use auxiliary Blockchain-based systems to facilitate transactions and mitigate malicious behaviors. Next, we discuss in detail one key component of FVN, a federated vehicular cloud (FVC), that is used for sharing data and models in FVN. In particular, we focus on the routing inside FVCs and present our solutions and preliminary evaluation results. Finally, we point out open problems and future research directions of this disruptive technology.

Introduction
Machine learning (ML) algorithms are used in various industries; however, standard algorithms generally require training and data storage in a single machine, a cluster, or a datacenter. Recently, a new paradigm of distributed machine learning, named Federated Learning, has been proposed and has gained increasing interest and popularity. Federated Learning has several performance advantages such as lower communication overhead and stronger privacy guarantee, because devices do not need to transmit the complete dataset. Lower communication overhead also often results in lower latency for completing the training and lower power consumption in communication if the communication bandwidth is constrained. For example, Google has built a Federated Learning framework on top of mobile phones [1].

Google's paradigm enabled mobile phones to collaboratively learn a shared prediction model, while keeping all the training data on each device; hence, there is no need to store data in the cloud, and there are fewer privacy concerns.

Unfortunately, there are a few drawbacks to building a data- and computation-intensive framework on top of uncoordinated mobile/edge nodes:

Limited storage and computation capability

Limited battery

Lack of communication bandwidth

Efficiency loss due to the high degree of decentralization

Vulnerability to malicious players (e.g., a malicious agent provides polluted data or computation).

To address these issues, this article envisions the idea of Federated Vehicular Network (FVN), which is an intelligent stationary vehicular network, i.e., vehicles stay in a fixed location, for example, parking lots, so that the connection is stable. Moreover, an FVN has centralized components and utilizes both DSRC (dedicat-ed short-range communications) and mmWave (millimeter wave) communication. These unique design choices allow FVN to provide more predictable performance leading to a multitude of new applications, such as virtual infrastructure for entertainment at sport venues, and distributed machine learning. More importantly, we propose an architecture of FVN so that it can effectively act as the computation backbone for Federated Learning.

The proposed FVN architecture utilizes high-tech vehicles which are expected to have more storage and computation resources, larger battery, and better communication than mobile phones. Furthermore, our unique centralized design allows efficient coordination among vehicles and collaborative learning. Finally, we use auxiliary Blockchain-based systems to facilitate transactions and mitigate malicious behaviors.

The goal of this article is to enumerate opportunities, challenges, potential solutions, and point out future research directions of using FVN to support Federated Learning. The following section discusses the enabling technologies for an FVN. We then propose the high-level architecture of FVN for supporting distributed machine learning and Federated Learning. Then we discuss the key component of FVN, namely federated vehicle cloud (FVC), and a preliminary study of FVC. We conclude the article in the final section.

Enabling Technology of FVN
Today's smart vehicles are equipped with a rich set of computing and communication resources in their on-board units (OBUs). One recently emerging concept resulting from this is the idea of “connected and autonomous vehicles” [2]. This concept has brought the mobile cloud computing model to vehicular networks. Compared to Internet clouds (e.g., AWS), vehicular clouds bring new opportunities due to benefits such as lower cost to deploy the system due to negligible infrastructure investment, high mobility, autonomy, and flexibility.

Another emerging concept is the more general idea of “vehicular networks.” For example, in recent years vehicular ad-hoc networks (VANETs) have gained popularity in the aim to reduce traffic accidents and road congestion [3]. However, despite their benefits, traditional vehicular networks are often unstable due to reasons such as vehicles constantly moving in and out of the network, and intermittent connectivity [4]. Unstable performance has limited the usage and applications of traditional vehicular networks. Recent works such as QoS-OLSR [5] improved communication throughput, packet delivery ratio, and end-to-end delay in VANET, compared to traditional vehicular networks; however, we are not aware of any prior systems in VANET that tackle data- and computation-intensive tasks like machine learning.

Motivated by our observations, we propose a new type of vehicular network, FVN, for supporting emerging applications such as Federated Learning. In this section, we first enumerate observations on the technical advancement that is critical for FVN. In essence, usage of these technologies allows FVNs to support applications that cannot be supported by traditional vehicular networks. In the next two sections, we describe our high-level design that integrates these components seamlessly.

Communication
Each participating vehicle in an FVN is equipped with both DSRC and mmWave communication, which will be the standard for almost all autonomous vehicles in the near future. Characteristics of each protocol are summarized below:

DSRC: data rate of a few KB/s, 200m communication (without obstructions), and omni-directional communication.

mmWave: data rate of a few Gb/s, limited range (<10m), and uni-directional communication.

Most prior works did not distinguish the communication protocol used. In general, we use DSRC for control messages and frequent communications of small-size messages, and mmWave for larger-scale communication in FVN. This allows FVN to be scalable and have the capability to handle data-intensive applications.

High-Tech Vehicles
In an FVN, vehicles are equipped with one mmWave antenna, which can rotate freely in any direction to send information to a single destination. Due to the typical design of parking lots, a vehicle is assumed to be able to communicate with its immediate neighbor. Additionally, since vehicles are in such close range, propagation loss is negligible. Each vehicle is also assumed to have much greater computation and storage capabilities than a typical mobile device. While it is naturally inferior than a highly-optimized server, FVN provides stable performance via aggressive parallelism and coordination.

The proposed FVN architecture utilizes high-tech vehicles which are expected to have more storage and computation resources, larger battery, and better communication than mobile phones. Furthermore, our unique centralized design allows efficient coordination among vehicles and collaborative learning.

The OBUs of these smart vehicles are very resourceful and highly specialized for machine learning tasks. For example, the current Tesla models are equipped with 12 ARM Cortex A72 64-bit CPUs in the chip running at 2.2 GHz, and a GPU running at 1 GHz, and is capable of 600 GFLOPS. Other vehicle manufactures (e.g., Toyota, Ford, Mercedes-Benz, and so on) and smart vehicle chip providers (e.g., Intel, Qualcomm, NVIDIA, and so on) all build similar or better computation resources.

Venue Infrastructure
FVN is best deployed at large venues with large parking lots and existing venue infrastructure. In the modern era, there has been a huge spike in expectations for connectivity at any major venue. For example, in 2018, the average number of in-stadium Wi-fi users was around 30,000 per NFL game. In order to meet such demand, most stadiums or malls are equipped with the necessary communication infrastructure. To reduce deployment cost and increase performance, FVNs utilize such existing infrastructure. To reduce the adoption barrier, our design only makes minimal assumptions on such an infrastructure; it acts as the “entry point” for clients to connect to the network and has the capability to communicate with vehicular networks using technology like mmWave and/or V2X (Vehicle-to-everything) communication. For smaller parking lots without such physical infrastructure, FVN relies on more powerful vehicles (such as Toyota's e-Pal-ette) to coordinate, that is, a virtual infrastructure. Throughout this article, we will refer to such (physical or virtual) infrastructure as the “venue infrastructure” for brevity.

Similar to prior work [6], we assume that the OBU of a participating vehicle is always-on, even when the vehicle is parked. Note that many venues provide the infrastructure to charge vehicles' battery. We address the battery draining issue by assigning tasks to vehicles with enough battery power. Moreover, our target use cases (e.g., a concert or a sport event) typically complete in a few hours, which would not completely drain the battery power of high-end vehicles.

Blockchain
One key component of FVN is to use Blockchain for membership management and transactions. Since FVN is naturally a type of peer-to-peer computing, a malicious or selfish party may cause severe negative impacts. FVN relies on two Block-chain-based systems for security. The first system keeps track of vehicles participating in the FVN overtimes and records their history of behavior. Then we compute the reputation score for each vehicle using the data. Such a reputation score allows FVN to exclude malicious parties. We are developing an approach based on the concept of failure detectors that can be used to identify faulty behaviors based on the recorded history. Similar to other Byzantine-tolerant frameworks, our approach works only if at most 1/3 of participants are malicious. Our second system [7] is a reliable and secure payment platform that enables transactions among clients, venues, and vehicles. This provides enough incentives for vehicles to participate in FVC.

Table1. Comparison of different paradigms of federated learning (Fl).
Table - Comparison of different paradigms of federated learning (Fl).
Federated Learning Using FVN
Federated Learning: an Overview
Distributed Learning
It is important to first look at the broader scope of distributed learning and its advantages. Machine learning for complex applications requires a substantial amount of training data, and the input for larger models grows exponentially with the number of parameters. Further, since the demand for processing training data has grown faster than the increase in computing resources, the need for distributing machine learning across multiple machines has become necessary [8]. Several computing paradigms and architectures have been proposed such as TensorFlow, Apache Spark, parameter server, all-reduce, peer-to-peer, and so on.

Federated Learning
Federated Learning is a distinct type of distributed learning, which is ideal for problems in which either training on the device itself provides a distinct advantage over training on proxy data at a datacenter, or the data is privacy sensitive or large compared to the size of the model, so it is preferable not to log such data to the data center [9], [10]. The idea is to have machines collaboratively learn a shared prediction model while keeping all the training data on the machines themselves, so there is no need to store large amounts of data into a centralized server or cloud [1].

Most successful applications of deep learning have relied on variants of Stochastic Gradient Descent (SGD) for optimization [9], a highly iterative training algorithm. However, such algorithms require low latency and high bandwidth between machines. For the use of Federated Learning with mobile phones, Google has instead proposed their Federated Averaging Algorithm, which can train deep networks using 10-100× less communication compared to SGD [1].

High-end vehicles are equipped with various sensors to collect data about surrounding environments and drivers/passengers. These data may be used to train models for personalized virtual assistants (for vehicle's infotainment) or even self-driving capability. These types of data are private and sometimes sensitive; hence, Federated Learning is highly appealing for such vehicle-related applications.

FVN Architecture
As described earlier, FVN has several distinctive components: venue infrastructure, high-tech vehicles, and Blockchain-based systems for reputation and transaction. For supporting Federated Learning in an FVN, a high-level workflow would be as follows. First, the venue infrastructure downloads the current model from some datacenter, cloud, or simple client, which is then copied and distributed to participating vehicles in the network. Then, each vehicle in the network improves the model by learning from its local dataset. For example, the vehicle will use its OBU to apply SGD to compute the parameter using its local data and the downloaded model. This update (or learned parameter) is sent back to the venue infrastructure, and sent back to the datacenter; only the update is sent, and nothing else. These updates are averaged together with other updates (using algorithms similar to Federated Averaging) in order to improve the model in the datacenter.

While this high-level model provides a basic idea of applying Federated Learning to the concept of FVN, we look to further analyze the architecture of such an implementation. In particular, our FVN for Federated Learning architecture can be broken up into the exact machine learning algorithm used, parallelism, and the high-lev-el design. Due to the space constraint and the nature of the magazine, we focus on the discussion of the later two elements.

Parallelism focuses on how to split up the problem during the training phase: we may either parallelize the data or the model, or can apply both simultaneously. We present briefly both ideas, and then discuss parallelism in the context of FVN and Federated Learning.

Parallelism
The Data-Parallel approach works by machines applying the same algorithm to different partitions of the original data set. The original data is partitioned into as many chunks as there are machines in the system, and each machine applies the machine learning (ML) algorithm separately to their own partition. The same model is available to all worker nodes through centralization or replication, and the aggregation of all changes leads to a single coherent output [8]. In contrast, the Model-Parallel approach uses exact copies of the data sets that are sent to worker nodes. Each worker node is responsible for a unique part of the model, rather than a part of the data set. However, it can only be applied to some ML algorithms, since it is not necessarily true that the model parameters can be split up [8]. Due to the greater computation power of vehicles than that of mobile phones, we have more flexibility to choose our ML algorithm so that we may parallelize the data, model, or both.

Depending on the ML algorithm chosen, there are many different options for parallelism for federated learning in FVN. Different from Goo-gle's prior solution on mobile phone-based learning, federated learning in FVN combines both data-parallelism and model-parallelism. For example, vehicles can be split into clusters (worker groups), where each cluster follows a model-parallel approach, but the data is partitioned among the clusters. Table 1 presents the differences between the proposed approaches.

FVN-Data-Parallel Approach
There are two different ways we may design our network depending on the parallelism chosen. Here, we present the high-level design from the bottom-up for the strict data-parallel approach; later we outline the main differences needed in design when using data-parallel and model-parallel approaches simultaneously.

Figure 1 illustrates our design and flow. The client communicates with the venue infrastructure (cell tower icon) to share the data, task, and model. Each vehicle in the system acts as a worker node (purple or blue car icon). Each worker node receives a partition of the data set, and each worker performs a computation using some ML algorithm where it improves the model by learning from data in its OBU. It summarizes the changes and sends these changes back to the manager, where the manager (red car icon) is a designated vehicle that behaves as a parameter server (e.g., aggregating and averaging updates in distributed stochastic gradient descent) with respect to ML algorithms and as a proxy between each worker vehicle and venue infrastructure.

Most ML algorithms require workers to iteratively update models (or even data). We store the data and model in a separate component, called a Federated Vehicular Cloud (FVC), for the reasons of faster recovery, simple management, and durability. Roughly speaking, FVC (yellow car icon) can be treated as a cache and external storage systems for workers, manager, and venue infrastructure to communication with each other. We will discuss FVC in more details later. Recall that we are presenting the data-parallel approach here; hence, the data is split into smaller pieces, and each worker gets a different piece of data. Moreover, each worker uses exactly the same ML algorithm to train the model.

The venue infrastructure acts as a resource manager which makes sure that each vehicle is assigned a partition in the data set. It keeps track of vehicles that are currently participating using a Leave/Join protocol. At the start of each iteration, it checks the number of vehicles participating, and then sends out exactly that many partitions across the system, using mmWave. At the end of the iteration, vehicles in the network respond with an updated model, also using mmWave. The resource manager aggregates all of the changes (or learned parameters) and then sends the averaged changes to the client that initiates the learning task.

FVN-Combined Approach
The main difference in the combined approach is that it splits up vehicles into “worker groups.” Each worker group is responsible for a partition of the dataset. Within each worker group, using the dataset partition given, a model-parallel approach is used to train the model. That is, exact copies are made of the dataset partition, and each worker operates on a different part of the model. Each worker group behaves and is managed similarly to an FVC as will be discussed in next section. Figure 2 illustrates the combined approach. Each vehicle is responsible for the computation related to a different part of the ML model.

Figure 1. - Data-parallel approach: each worker gets a partition of the dataset and applies the same ML algorithm.
Figure 1.
Data-parallel approach: each worker gets a partition of the dataset and applies the same ML algorithm.

Show All

Key Innovations and Advantages of FVN
We briefly argue how FVN addresses the issues raised above and why our design for FVN is suitable for Federated Learning. Our key innovation is the seamless integration of several advanced technologies to enable vehicular clouds for data-and computation-intensive tasks. First, as shown in Fig. 1, we adapt the parameter server model so that it fits the vehicular cloud framework with heterogeneous communication mechanisms. Second, we demonstrate how to use Blockchain and venue infrastructure to manage vehicle workers so that Federated Learning can be conducted in a distributed and peer-to-peer fashion. Finally, in the next section, we also present solutions to support efficient communication and storage in the pro-Dosed architecture.

FVN has several desirable advantages. First, high-tech vehicles are more resourceful and have a larger battery than typical mobile devices. Using them as a basic computing and storage unit greatly improves the capability of our framework. Second, compared to prior vehicular clouds/net-works, FVN uses heterogeneous communication for high-bandwidth transmission of data, and introduces the concept of FVC to exchange/update data efficiently. Third, integrating venue infrastructure not only allows us to provide seamless interaction with clients, but also incentivizes different parties (venue, clients, vehicles) to participate in FVN. We will discuss more on incentivization in the next section. Fourth, FVN is more appropriate compared to edge-based or fog-based solutions (i.e., off-loading training tasks to edge or fog devices). In FVN, vehicles can keep the sensitive data at their OBUs. They can complete the training without sharing the data with third parties. Fifth, compared to the recent concept of fog learning that focuses mainly on the communication perspective, FVN provides a more complete architecture that uses a combination of heterogeneous communication, venue infrastructures, and Blockchain to enable federated learning [11]. Finally, the integration of Blockchain-based systems allows FVN to mitigate malicious behaviors and enable transactions between different parties.


Figure 2.
Combined approach. Each worker group gets a larger partition of the dataset; workers are responsible for a unique part of the model, but each worker group applies the same overall ML algorithm.

Show All

Federated Vehicular Clouds
One key component in FVN is using a cluster of vehicles for cloud technology, in particular, the use of a Federated Vehicular Cloud (FVC). In this section, we briefly present the design and an application of using FVC as an information-centric network (ICN). Then, we present our preliminary study on routing in FVC.

High-Level Design
An FVC consists of two main components: source/proxy node(s) and worker nodes.

Worker and Proxy Nodes
Each vehicle in the FVC is equipped with a cache which can store data content and a computation unit that can execute computation tasks. The vehicles designated as worker nodes utilize these features in order to cache and deliver content.

We also designate certain vehicles to be special, known as “proxy nodes.” The point of a proxy node is to be aware of each item that is cached within the network, and where it exists. Content is not static in each cache, so when a vehicle has updated its cache to accommodate for new content, it notifies the proxy node using a data content renewal protocol. Proxy nodes are chosen using multiple instances of leader election protocols [12]. Proxy nodes are also responsible for synchronizing with venue infrastructure.

Communication
FVC uses both the DSRC and mmWave protocols. We use the DSRC protocol for control messages between close vehicles. For a smaller FVC and parking lot, where no two vehicles are greater than 200m apart, broadcasts can be sent to the entire network. For larger networks, these broadcasts are only sent to nearby vehicles. These control messages can be used to optimize routing and caching in an FVC. Since mmWave can support such high data rates, it is used for data transmission in the network, where data packets can be sent between vehicles. In addition, mmWave is also used for proxy nodes to communicate with venue infrastructure.

FVC Application
Information-Centric Networking
One motivation for the use of an FVC is to serve as an ICN for entertainment at sports events, which are now working on new technologies (such as 5K video cameras and 360-degree replay) to enhance fans' experiences. More importantly, in FVN for federated learning, we use FVC-ICN as the storage and communication backbone which allows workers or worker groups to efficiently exchange data and update large-scale datasets and ML models.

Design and Workflow
We illustrate how FVC behaves as an ICN in Fig. 3. The green arrows indicate the forward direction of the content (or data) request. The thick blue arrows represent the path the actual content takes back, which is sent strictly via mmWave. The flow of serving a client reauest for a data item is as follows:

A client has a content request for some content i. • The request is sent to the nearest available venue infrastructure.

If i is stored within the FVC, the venue infrastructure forwards the request to the nearest proxy node; otherwise it is handled using previously existing protocols, for example, contacting Internet cloud or CDN.

The proxy node forwards the request toward vehicle v which stores i using the DSRC protocol.

Vehicle v, acting now as a source, finds a path back to the proxy using some routing protocol.

The content is then sent back toward the proxy using the path obtained via mmWave.

The proxy sends the content back toward the venue infrastructure, which then forwards it to the client.

Clients, venues, and vehicles use Block-chain-based systems for transactions (e.g., service fee, and computation/storage reward). The component is not shown in Fig. 3 for brevity.

While the workflow is similar to a typical ICN, it has many unsolved puzzles. As we will discuss later, we need to investigate new routing protocols to enable FVC, which may be of independent interest for other designs that use both DSRC and mmWave.

Leave/join Protocol
Vehicles may leave or join the network through a DSRC-based communication. A vehicle joining the network needs to notify a proxy node that it has entered the FVC along with its location. The proxy node then assigns this vehicle a vehicular ID, and notifies the other proxy nodes. Similarly, if a vehicle leaves, it also sends a message to a proxy node, which removes the vehicle from the network, and then notifies the other proxy nodes. Using a DSRC-based gossip protocol, proxy nodes will have the most up-to-date directories of the current vehicles and contents in the FVC. FVC also consults with the reputation Blockchain to “block” those vehicles with suspicious past behaviors from joining.

FVC Vs. Traditional VC
Cloud computing has already been proposed in vehicular networks, namely traditional VCs (e.g., [13]). Moreover, cloud federation is being used for forming highly profitable federated clouds [14]. As seen in Table 2, FVC is fundamentally different in multiple aspects. FVC's centralized management (from proxy nodes and venue infrastructures), static use cases, and heterogeneous communication mechanism allow it to provide more stable communication and performance. Incentive is another important difference. Consider the case when FVC is applied at a mall, concert, or sport event; each of these have large parking lots that can facilitate such FVCs, as well as a multitude of opportunities for incentivizing both parties, such as reducing parking costs for consumers and providing advanced entertainment technology and extra ML capabilities for the venues. Finally, we are not aware of any VC-based solutions that target data- and computation-inten-sive tasks without relying heavily on infrastructures.

Preliminary Study
Auxiliary Blockchain-Based Systems
There is increasing interest in Blockchain supported Federated Learning technology for the trustworthiness of vehicular networks [15]. We are developing a Blockchain-based system [7] to process transactions among different parties in FVN based on Ethereum. Since the FVN is relatively stable, our preliminary Blockchain transaction system is not a bottleneck. In other words, it is not on the critical path on the main task of FVN or FVC. The next step is to develop a Blockchain-based system that can be used to manage the reputation of each vehicle, and support failure detection for distributed machine learning algorithms.

Routing
One fundamental technical component is routing in a large-scale FVC. This is essential not only in cloud computing, but also in applications where FVC is an integral part of the design, such as in distributed machine learning or federated learning. While the routing problem is well-studied in the literature, we are not aware of any relevant study that fits our scenario:

DSRC (omni-directional) + mmWave communication (uni-directional)

Dynamic membership

Large-data transmission (through DSRC)

Fixed location/position

A large number of vehicles (ranging from 200 to 30,000)

Latency introduced by rotating (mmWave) antenna.

In our solution, we model FVN as a dynamic and directed graph. We briefly discuss three rout- ing algorithms for FVC here. However, our model and solutions are generic and can be adapted for various applications of FVN.

Figure 3. - High-level design of utilizing FVC for ICN. Green arrows the forward path of the content request. Blue arrows denote the path of the content back to the client.
Figure 3.
High-level design of utilizing FVC for ICN. Green arrows the forward path of the content request. Blue arrows denote the path of the content back to the client.

Show All

Table2. Comparisons Of different paradigms of cloud computing.
Table - Comparisons Of different paradigms of cloud computing.
We represent an FVN as a directed, dynamic graph Gt = (V, Et), where Gt is the state of the graph at discrete time t. Each vehicle is represented as a node. In our model, a vehicle has one mmWave antenna which implies one outgoing edge directed at one of its neighbors at any time t. For any edge (u, v), it has an associated weight which represents the latency in transmitting data from node u to node v via mmWave.

Each node also has an associated flow capacity and flow, which represents bandwidth on its antenna.

We propose three routing algorithms:

Optimal (OPT): a vehicle uses DSRC to exchange its state with all other vehicles, and the source uses Dijkstra to find an optimal path in any given time step.

Lowest Local Cost (LLC): a vehicle uses DSRC to exchange its state with local neighbors; vehicle uses greedy local rules to find a route to the destination.

Divide and Conquer (DC): we split the parking lot into sections, and within each section, we use the OPT algorithm to find a route.

Each solution has its own limitations. For example, the OPT algorithm only works when there are infrequent data requests, and vehicles can obtain up-to-date information in a short amount of time. LLC may choose a long route but incur only low cost. DC requires a higher degree of coordination.

Simulation and Results
We have simulated an FVC using Python and NetworkX, a network simulator library in Python. For simplicity, each item in the item catalog takes up the same bandwidth: flow on an antenna increases by 1 any time data is transmitted across it. Since we are only analyzing routing in the system, we record latency in routing content from a single source to random destinations within the network. This represents a vehicle in the network responding to content requests for some content i which it has stored in its cache, and sending to a proxy node. We have that content requests arrive according to a Poisson Distribution with a rate parameter λ = 10 requests per second. Simulations are run for a total of 100 seconds.

Figure 4. - Average latency vs. The number of nodes.
Figure 4.
Average latency vs. The number of nodes.

Show All

Figure 4 shows the average latency for each algorithm as the number of nodes are increased. For the Divide and Conquer algorithm, the original problem is usually broken up into about two or three sub-problems, and sometimes four or five sub-problems when there are 400 or 500 nodes in the network. Our simulation shows a promising result.

Summary and Future Work
In this article, we proposed novel concept in vehicular networks, namely FVN, which provides more stable performance than a standard vehicular network and supports data- and computation-intensive tasks. It also supports new applications previously unable to be supported by traditional vehicular networks. We focused our discussion on using FVN to support Federated Learning, and then presented the architecture of FVN. We then dove into one key component that enables FVN, namely Federated Vehicular Cloud (FVC). We also presented our preliminary study on routing in FVC. We are in the process of developing FVN, including adapting solutions from [7] to provide Blockchain-based reputation and payment support, conducting a more fine-grained study of the routing and caching algorithms, and creating a simulation framework for evaluating different Federated Learning algorithms in FVN.

We enumerate several interesting and exciting open problems below:

What are the best routing algorithms in our model under different scenarios (workload, parking lot, number of vehicles, users, data allocation, and so on)?

How do we optimize both caching and routing algorithms simultaneously?

Can these algorithms be made energy-aware?

How do we adapt ML algorithms to fully utilize the Federated Learning in FVN?

What is an appropriate scheduling algorithm in FVN to best distribute datasets and computation tasks?

Data transmission for ultra-large dataset still poses a problem even with high-bandwidth mmWave communication. Will solutions like AWS Snowmobile (exabyte-scale data transfer using trucks loaded with data) fit in FVN?

