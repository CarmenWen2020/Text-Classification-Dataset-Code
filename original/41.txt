Abstract
Context: Motor Imagery based Brain-Computer Interfaces (MI-BCIs) enable their users to interact with digital technologies, e.g., neuroprosthesis, by performing motor imagery tasks only, e.g., imagining hand movements, while their brain activity is recorded. To control MI-BCIs, users must train to control their brain activity. During such training, experimenters have a fundamental role, e.g., they motivate participants. However, their influence had never been formally assessed for MI-BCI user training. In other fields, e.g., social psychology, experimenters gender was found to influence experimental outcomes, e.g., behavioural or neurophysiological measures. Objective: Our aim was to evaluate if the experimenters gender influenced MI-BCI user training outcomes, i.e., performances and user-experience. Methods: We performed an experiment involving 6 experimenters (3 women) each training 5 women and 5 men (60 participants) to perform right versus left hand MI-BCI tasks over one session. We then studied the training outcomes, i.e., MI-BCI performances and user-experience, according to the experimenters’ and subjects’ gender. Results: A significant interaction between experimenters and participants’ gender was found on the evolution of trial-wise performances. Another interaction was found between participants tension and experimenters gender on the average performances. Conclusion: Experimenters gender could influence MI-BCI performances depending on participants gender and tension. Significance: Experimenters influence on MI-BCI user training outcomes should be better controlled, assessed and reported to further benefit from it while preventing any bias.

Previous
Next 
Keywords
Brain-Computer Interfaces

Mental imagery

User training

Experimenter influence

Gender

1. Introduction
Motor Imagery based Brain-Computer Interfaces (MI-BCIs) enable their users to send commands to external digital devices by performing motor imagery tasks only, e.g., imagining hands or feet movements, while their brain activity is being recorded Clerc et al. (2016). The system has to estimate the motor imagery task that the users perform from the variations occurring in their brain activity, often recorded using electroencephalography (EEG).

The MI-BCI technology has promising medical applications. For instance, BCIs based on motor imagery and motor attempt were used for motor rehabilitation after stroke Biasiucci et al. (2018); Vourvopoulos et al. (2019). They can also be used to control interfaces of communication Birbaumer (2006), which is particularly useful for patients with limited or complete loss of the functional ability to communicate caused by a severe loss of voluntary muscular control Birbaumer (2006). MI-BCIs are also used for non-medical applications. For instance, they represent a new tool to control video-games Lécuyer (2016).

1.1. Brain-Computer Interfaces user training
Before being operational, MI-BCIs require that both the computer and the user learn during dedicated training phases Clerc et al. (2016). On the one hand, the computer must learn to recognize the variations occurring in users’ brain activity while they perform the different mental-imagery tasks. On the other hand, the users must learn to produce a stable and distinguishable pattern of brain activity for each of the commands that they wish to send to the computer McFarland and Wolpaw (2018). Both the computer training and the user training are highly interdependent but the user and the computer are generally trained separately, which probably partly explain the lack of reliability of the system Pfurtscheller and Neuper (2001).

This current lack of reliability of the system limits the development of MI-BCI applications. Indeed, 10 to 30% of naive users cannot control MI-BCIs, even after some training Neuper and Pfurtscheller (2010). There are several lines of research aiming at improving the efficiency of MI-BCIs. Most focus on the improvement of machine learning methods, see, e.g., Jin et al. (2019); Lotte et al. (2018). A few also focus on the improvement of the user training. Indeed, it has been shown both theoretically and experimentally that current user training approaches may not allow all users to acquire the skills necessary to use MI-BCIs Jeunet et al. (2016b); Lotte et al. (2013).

During their training, users train to control a feedback representing what the computer recognizes of the mental task that they are performing. A feedback is an information which is provided to a learner regarding aspects of the performance or understanding of the task/skills to learn Hattie and Timperley (2007). It is a fundamental component of the MI-BCI training Lotte et al. (2013). Several research were led in order to improve the feedback Pillette (2019), for instance by using more realistic cues Ono et al. (2013); Sollfrank et al. (2016).

Users could need specific feedback characteristics depending on their profile Pillette (2019). For instance, previous results indicate that “tensed” and “non-autonomous” people (based on the dimensions of the 16PF5 psychometric questionnaire Cattell and P. Cattell (1995)) are disadvantaged when controlling BCIs Jeunet et al. (2015). Interestingly, “non-autonomous” people are persons who rather learn in a social context Cattell and P. Cattell (1995). “Tensed” people might also benefit from a reassuring social presence and emotional feedback.

In a previous BCI experiment, we analysed the influence of a learning companion, i.e., a type of educational agents which can provide a complex form of social presence and emotional feedback in a controlled environment. During this last experiment, we designed, implemented and tested the first artificial learning companion dedicated to BCI user training Pillette et al. (2020). This learning companion was called PEANUT for Personalized Emotional Agent for Neurotechnology User Training (see Figure 1). In between two trials, PEANUT provided the learners with social presence and emotional feedback through interventions that were composed of both spoken sentences and displayed facial expressions. The interventions were selected based on the current and previous performances of the learner. We found that such learning companion had a differential impact on the participants’ performances depending on their autonomy. Also, the presence of a learning companion influenced how the participants felt about their ability to learn and memorize how to use a BCI, which is a dimension of the user experience that we assessed. Thus, we found that a learning companion providing a complex form of social presence and emotional feedback could influence BCI user training outcomes, i.e., performances and user-experience.

Fig. 1
Download : Download high-res image (389KB)
Download : Download full-size image
Fig. 1. A participant training to perform mental tasks on the right with PEANUT, the first learning companion dedicated to MI-BCI user training, on the left.

1.2. Role of experimenters
Very little is known regarding the most prevalent and complex source of social presence and emotional feedback during experiments which originates from the human supervision (e.g., experimenter or caregiver). In experimental settings, experimenters present BCIs to the learners, ensure the smooth progress of the experiment and might also have an influence on users’ states. For instance, in a clinical study, Hammer et al. report “we tried to keep the subjects motivated and attentive by providing non-alcoholic beverages, sweets and fresh air” Hammer et al. (2012). It has been shown that users’ states (e.g., motivation, attention) can influence the accuracy of MI-BCI classification Hammer et al. (2012). However, the influence that experimenters might have on users’ states and BCI training outcomes remains unknown and was not formally investigated. Only very few studies in clinical BCI-based motor rehabilitation post-stroke acknowledge and explicit the role of the therapists, without formally assessing their influence Morone et al. (2015); Pichiorri et al. (2015); Sexton (2015).

Rosenthal, who was part of the first in social psychology to stress the importance of studying the influence of experimenters, describes experimenters as “imperfect tools” Rosenthal (1963). Indeed, the literature from different fields states that experimenters may consciously or unconsciously affect their results. Experimenters can influence participants’ responses, behaviour and performances via direct and/or indirect interactions Rosnow and Rosenthal (1997). There are several types of possible experimenter-related influence, one of them being psychosocial factors. Stereotyped people tend to behave in a stereotype-consistent way Wheeler and Petty (2001). For example, elderly people tend to walk more slowly or to have impaired memory performances if they feel stereotyped Wheeler and Petty (2001). The “experimenter demand effect” is another example of experimenter-related influence. It can occur when participants unconsciously try to fit the appropriate image reflected by the experimenters behaviour and therefore want to please and assist the experimenters in obtaining their expected results Rosenthal (1963). These different influences can be modulated through the experimenters’ own characteristics (e.g., gender, age, ethnicity and professional status) and/or behaviour (e.g., gaze, touch and verbal interactions) Rosenthal (1963).

Among experimenters’ characteristics modulating their influence, one of the most prevalent seems to be the gender. Previous experiments often report a simple effect of the experimenters’ gender or an interaction between experimenters’ and participants’ gender on experimental outcomes Levine and De Simone (1991); Rosenthal (1963); Spencer et al. (1999). Indeed, many cultural stereotypes are gender-based. One of which is that women have weaker math abilities than men. In previous experiments, Spencer et al. found that depending on women being told that difficult maths tests were respectively gender-dependent or independent, they did underperform or not compared to men participants Spencer et al. (1999). In the neurofeedback field where users are trained to control their brain activity, Wood and Kober found that experimenters could have a differential impact on neurofeedback training depending on three parameters : experimenters’ gender, participants’ gender and participants’ level of locus of control in dealing with new technologies Wood and Kober (2018). They relate this difference of performances to psychosocial factors.

An interaction between the experimenter’s and the participant’s gender can also modulate the experimenter demand effect. For instance, when participants are instructed by an experimenter from the opposite sex, they seem more likely to act in ways that confirm the experimenters hypothesis Nichols and Maner (2008). Also, neurophysiological responses associated with defensiveness, i.e., the aim to avoid being criticised, is associated with greater relative left frontal activation in the presence of experimenters from the opposite sex compared to experimenters from the same sex Kline et al. (2002). Thus, an interaction of experimenters’ and participants’ gender can influence experimental outcomes, including neurological responses measured using EEG Chapman et al. (2018); Kline et al. (2002).

1.3. Research hypotheses
Literature in the field has identified direct factors that affect user learning (e.g., motivation, attention), although there influence is still understudied. In order to improve BCI reliability, it is thus highly relevant to identify, control and manipulate the factors affecting users’ states. Among these many factors (e.g., instructions, feedback or exercise design) our literature review presented above suggests that the experimental environment may have a major influence, notably experimenters Roc et al. (2020). Despite the central role that experimenters have in BCI experimental process and the literature regarding the impact of social presence and emotional feedback, no studies had yet been led to evaluate their influence on MI-BCI experimental outcomes, i.e., performances and user-training.

Experimenter’s profile includes many aspects such as age or personality. As described in Section 1.2, literature from other fields suggests that one of the most prevalent characteristics modulating experimenters’ influence seems to be the gender. Indeed, experimental outcomes (including neurological responses) may be significantly influenced by gender-related factors. Such impact might differ depending on the profile of the participants and experimenters.

Therefore, based on the literature, we formulated the following hypotheses:

•
(H1 - MI-BCI performances) MI-BCI performances undergo a gender-related influence of experimenters, possibly modulated by users’ gender.

•
(H2 - User experience) User experience undergo a gender-related influence of experimenters, possibly modulated by users’ gender.

•
(H3 - Experimenters’ and participants’ profile) These effects are modulated by experimenters’ and participants’ profile.

The remainder of this paper is organized as follows. In Section 2 -Materials & methods-,-, we provide information regarding the implementation of the experimental protocol that enabled us to test these hypotheses. Then, in Section 3 -Results- and in Section 4 -Discussion-, we respectively report and discuss the results from our experiment2. Finally, in Section 5 - Conclusion and Prospect-, we offer a conclusion on the matter as well as ideas and recommendations for future research.

2. Materials & methods
2.1. Participants
Sixty healthy MI-BCI naïve participants (29 women ; age 19-59, M = 29, SD = 9.32) completed the study. None of them reported a history of neurological or psychiatric disorder. Six experimenters conducted the study (3 women ; age 23-37, M = 29.2, SD = 5.6) among whom two (1 woman) were experienced in BCI experimentation, having conducted more than 100 hours of EEG-based BCI experiments, and four were beginners (2 women) who were trained to perform a BCI experiment beforehand. All beginner experimenters were trained in a reproducible way by the experienced experimenters. Each experimenter was randomly assigned to 10 participants (5 women and 5 men) that they had never met before the session. All experimenters had the same ethnicity, i.e., Caucasian white native french, and were asked to wear their usual work clothing (casual, not extravagant, not sexualized). This choice was made in order to investigate the potential influence of experimenters in usual BCI experimental settings.

Our study was conducted in accordance with the relevant guidelines for ethical research according to the Declaration of Helsinki. Both participants and experimenters gave informed consent before participating in the study. In order to avoid biased behaviour, this study was conducted using a deception strategy, partially masking the purpose of the study. Participants were told that the study aimed at understanding which factors (unspecified) could influence BCI outcomes, i.e., performances and/or user experience. Experimenters were aware of the goal of the study. The study has been reviewed and approved by Inrias ethics committee, the COERLE (Approval number: 2018-13).

2.2. Experimental protocol
Each participant completed one session of 2 hours with a MI-BCI. During this session, participants were first asked to read and sign the consent form and complete several questionnaires (see the following Subsection 2.3 -Questionnaires-), which took around 20 min. Once the EEG cap (see Subsection 2.4 - EEG Recordings & Signal Processing-) was placed on their head, the participants performed six 7-minutes runs during which they had to learn to perform two MI tasks with the BCI, i.e., imagine right or left hand movements (around 60 min, including breaks between the runs). Finally, the participants were asked to fill the post-session questionnaires, the EEG cap was uninstalled and a debriefing was made (around 15 min).

The Graz training protocol was used Pfurtscheller and Neuper (2001). It is divided into two steps: first, the training of the system and second, the training of the user. The first two runs were used as calibration in order to provide to the system examples of EEG patterns associated with each of the MI tasks. During the first two runs, as the classifier was not yet trained to recognize the mental tasks being performed by the user, it could not provide a consistent feedback. In order to limit biases with the other runs, e.g., EEG changes due to visual processing differences between runs, the user was provided with an equivalent sham feedback, i.e., a blue bar randomly appearing and varying in length. These two steps and their respective runs are visually depicted in Figure 2.

Fig. 2
Download : Download high-res image (123KB)
Download : Download full-size image
Fig. 2. The BCI session included 6 runs divided into two steps: (1) data acquisition to train the system (2 runs) and (2) user training (4 runs). After Run 2, the classifier is trained on the data acquired during the two first runs.

During each run, participants had to perform 40 trials (20 per MI-task, presented in a random order), each trial lasted 8s. At t = 0s, a cross was displayed on the screen. At t = 2s, an acoustic signal announced the appearance of a red arrow, which appeared one second later (at t = 3s) and remained displayed for 1.25s. The arrow pointed in the direction of the task to be performed, namely left or right to imagine a movement of the left or right hand. Participants are instructed to start performing the corresponding MI-task as soon as the arrow appeared, and to keep doing so until the cross disappeared. Finally, from t = 4.25s, a visual feedback was continuously provided in the shape of a blue bar, the length of which varied according to the BCI classifier output. Only positive feedback was displayed, i.e., the feedback was provided only when the instruction matched the recognized task. The feedback was provided for 3.75s and was updated at 16Hz, using a 1s sliding window. After 8 seconds, the screen turned black again until the beginning of the next trial. The participant could then rest for a few seconds. The timeline of a trial is shown in Figure 3.

Fig. 3
Download : Download high-res image (80KB)
Download : Download full-size image
Fig. 3. Timeline of a trial.

Following the recommendations from the literature, the participants were encouraged to perform a kinesthetic imagination Neuper et al. (2005) and to choose their own mental imagery strategies Kober et al. (2013), e.g., imagining waving at someone or playing the piano. Participants were instructed to find a strategy for each MI task so that the system would display the longest possible feedback bar. Instructions were written in advance and read by the experimenters so that all the participants started with the same standardized information. As they would have been in any standard BCI experiment, the experimenters were free to interact with the participants before, during and after the experiment, e.g., seating and/or standing. They were in charge of welcoming participants in the lab, showing them the way to the experimental room, making them sign the consent form, explaining them what would happen during the whole experiment, setting up the EEG cap on them, asking them to fill-in various questionnaires, calibrating the BCI system and making it run for the participants, answering questions that the participants may have, providing them with water if they required some, removing the cap and debriefing with the participant at the end of the experiment. Experimenters were only asked not to reveal the aim of the experiment before its very end.

2.3. Questionnaires
As stated in the introduction, the personality and the cognitive profile of participants and experimenters can respectively influence BCI performances and the experimenter bias Pillette (2019). Therefore, we assessed the personality and the cognitive profile of both the participants and the experimenters. The 5th edition of the 16 Personality Factors (16PF5), i.e., a validated psychometric questionnaire to assess different aspects of people’s personality and cognitive profile was filled by both experimenters and participants Cattell and P. Cattell (1995). This questionnaire identifies 16 primary factors of personality, including tension and autonomy. Participants also completed a mental rotation test measuring their spatial abilities Vandenberg and Kuse (1978).

The participants also filled pre and post experiment questionnaires especially developed for BCI purpose by Hakoun et al. These questionnaires assessed the participants’ states and the user-experience Bismuth et al. (2020); Jaumard-Hakoun et al. (2017). Based on validated questionnaires, it determines five dimensions of the user-state and/or the user-experience. Three dimensions, i.e., the mood, mindfulness and motivational states, were assessed pre and post training. The evolution of the participant’s states provides an information regarding the user-experience. Two dimensions, i.e., the cognitive load (amount of cognitive process required to control the MI-BCI system) and the sense of agency (feeling of control of the participant over the feedback provided by the MI-BCI) assessed the user-experience post-training.

2.4. EEG Recordings & Signal Processing
To record the EEG signals, 27 active scalp electrodes, referenced to the left earlobe, were used (Fz, FCz, Cz, CPz, Pz, C1, C3, C5, C2, C4, C6, F4, FC2, FC4, FC6, CP2, CP4, CP6, P4, F3, FC1, FC3, FC5, CP1, CP3, CP5, P3, 10-20 system). The electromyographic (EMG) activity of the hands was recorded using two active electrodes located 2.5cm below the skinfold on each wrists. The electrooculographic (EOG) activity of one eye was recorded using three active electrodes. Two of them were located below and above the eye and one was located on the side. They aimed at recording vertical and horizontal movements of the eye. Physiological signals were measured using a g.USBAmp (g.tec, Austria), sampled at 256 Hz, and processed online using OpenViBE 2.1.0 Renard et al. (2010). To classify the two MI tasks from EEG data, we used participant-specific spectral and spatial filters. To do so, we used the now standard algorithms proposed by Blankertz et al. in Blankertz et al. (2008). More precisely, from the EEG signals recorded during the calibration runs, we first identified a participant-specific discriminant frequency band using the heuristic algorithm proposed in Blankertz et al. (2008) (Algorithm 1 of that paper). Roughly, this algorithm selects the frequency band whose power in the sensorimotor channels maximally correlates with the class labels. Here we used channels C3 & C4 after spatial filtering with a Laplacian filter as sensorimotor channels, as recommended in Blankertz et al. (2008). The algorithm selected a discriminant frequency band within the interval from 5 Hz to 35 Hz, with 0.5Hz large bins. Once this discriminant frequency band automatically identified, we filtered EEG signals in that band using a Butterworth filter of order 5.

Then, still has recommended in Blankertz et al. (2008), we used the Common Spatial Pattern (CSP) algorithm Ramoser et al. (2000), in order to optimize 3 pairs of spatial filters, still using the data from the two calibration runs. Such spatially filtered EEG signals should thus have a band power which is maximally different between the two MI conditions. We then computed the band power of these spatially filtered signals by squaring the EEG signals, averaging them over a 1 second sliding window (with 1/16th second between consecutive windows), and log-transforming the results. This led to 6 different features per time window, which were used as input to a Linear Discriminant Analysis (LDA) classifier Lotte and Jeunet (2018). As mentioned above, this LDA was calibrated on the data from the two calibration runs. These filters and classifier were then applied on the subsequent runs to provide online feedback. It should be noted that this BCI design and EEG signal processing is a rather standard approach, that has been used in numerous previous experiments by various laboratories, see, e.g., Blankertz, Sannelli, Halder, Hammer, Kübler, Müller, Curio, Dickhaus, 2010, Blankertz, Tomioka, Lemm, Kawanabe, Muller, 2008; Jeunet et al. (2016a).

2.5. Variables, Factors & Statistical analyses
As presented in the introduction, our experiment aimed at testing three different hypothesis. In the following Subsections we present the variables, factors and statistical analyses used to test each of these hypotheses. The statistical analyses mostly consist of ANOVAs, that are considered as robust against the normality assumption. To the best of our knowledge, no other non parametric test enabled to perform the analysis that we were interested in. Spearman or Pearson correlations were also obtained depending on the distribution of the data collected (assessed using Shapiro-Wilk tests).

2.5.1. H1 - MI-BCI performances
To test our first hypothesis (H1), i.e., MI-BCI performances undergo a gender-related influence of experimenters, possibly modulated by users’ gender, two measures of performance were used.

The first performance metric we used is the online Trial-wise Accuracy (TAcc). This metric is computed by first summing the (signed) LDA classifier outputs (distance to the separating hyperplane) over all epochs (1s long epochs, with 15/16 s overlap between consecutive windows) during the trial feedback period. If this sum sign matched the required trial label, i.e., negative for left hand MI and positive for right hand MI, then the trial was considered as correctly classified, otherwise it was not. The TAcc for each run was estimated as the percentage of trials considered as correctly classified using this approach. TAcc is the default accuracy measure provided online in the MI-BCI scenarios of OpenViBE, and the only performance metric that the experimenters were seeing online. It should be noted that this metric takes into account the classifier output and is thus also related to the feedback bar length as it is proportional to the classifier output. Our participants were instructed to train to obtain not only a correct classification, but also a feedback bar as long as possible, the TAcc metrics thus take into account both aspects. Offline, we also computed the Epoch-wise Accuracy (EAcc) as the percentage of epochs (1s long time windows) from the feedback periods that were correctly classified. Thus, this metric only considers whether the classification was correct, but not the feedback bar length as it does not take into account the classifier output. However, it does reflect how often EEG epochs were correctly classified, and thus how often the subjects received correct positive feedback. It is also a rather standard classification performance metrics in BCI Machine Learning Thomas et al. (2013), we thus also provide it for reference.

These two measures of MI-BCI performances over the series of 4 user-training runs, i.e., “Run”, were then used in two 3-way repeated measures mixed ANOVAs with “ExpGender”, “ParGender” and “Run” as independent variables and the repeated measures of performance over the runs, i.e., TAcc or EAcc, as dependent variable. The results are reported in Subsection 3.1 - H1 - MI-BCI performances-.

2.5.2. H2 - User experience
Second, we wanted to assess the potential impact of the experimenters’ and participants’ gender on the user experience (H2). The user experience is defined by the two percentages provided by the questionnaire of Hakoun et al. Bismuth et al. (2020); Jaumard-Hakoun et al. (2017) regarding the amount of cognitive load and sense of agency felt during the training. It is also defined by the evolution of mood, mindfulness and motivation of the participants between the beginning and end of the training. This evolution is assessed by subtracting the measure post training to the measure pre training, both assessed in percent. The higher the percentages are, the more participants increased their reported levels of positive emotions and calm, mindfulness, motivation, cognitive load and sense of agency.

These five measures of user experience were then used in five 2-way ANOVAs or ANCOVAs, one per dimension, with “ExpGender” and “ParGender” as independent variables and either the measure of cognitive load, sense of agency, mood, mindfulness or motivation as dependent variable. Performances averaged over all runs, i.e., TAcc or EAcc, were used as covariate if they were correlated to the dependent variable. The results are reported in Subsection 3.2 -H2 - User experience-.

2.5.3. H3 - Experimenters’ and participants’ profile
Finally, we wanted to know if other characteristics of the experimenters’ and/or participants’ profile than the gender could provide first elements of comprehension regarding the potential difference in MI-BCI performances or user-experience (H3). We focused on characteristics of the profile that were shown to have an influence on BCI performances in previous studies, i.e., mental rotation scores (MRS), tension and autonomy Jeunet et al. (2015). Participants with low MRS Vandenberg and Kuse (1978), tensed and/or non-autonomous (both measured using the 16PF5 questionnaire Cattell and P. Cattell (1995)) were shown to have lower BCI performances than the others Jeunet et al. (2015).

The groups formed by experimenters’ and participants’ gender did not have similar MRS and autonomy. Thus, we assessed the influence of these two measures on the results obtained for H1 using the same ANOVAs that were used to test the hypothesis (two 3-way repeated measures mixed ANOVAs with “ExpGender”, “ParGender” and “Run” as independent variables and the repeated measures of performance over the runs, i.e., TAcc or EAcc, as dependent variable) and the autonomy, i.e., “Autonomy”, or the mental rotation score, i.e., “MRS”, of the participants as covariate. The results are reported in Annex Appendix C –Details regarding the analyses on the potential influence of MRS and autonomy differences in participant groups-.

Then, we focused on the potential influence of the tension. We separated the participants into two groups depending on their tension “ParTension”. The threshold between high and low tension was defined using the median tension score (i.e., median of 6, low and high tension respectively corresponding to scores of [1, 5] and [6, 10], 10 being the maximum). We performed two 3-way ANOVAs with “ParTension”, “ExpGender” and “ParGender” as independent variables and one of the measures of performance averaged over all runs, i.e., TAcc or EAcc, as dependent variable. The results are reported in Subsection 3.3 - H3 - Experimenters and participants profile-.

3. Results
Among the 60 participants, 1 participant did not complete all of the four runs of participant training due to a technical issue and 3 outperformed the others (by more than two SDs) both in term of TAcc (respectively, outliers Ms1 = 98.13, Ms2 = 98.13, Ms3 = 99.38 ; Mgrp = 62.78%, SDgrp = 16.2) and EAcc (outliers Ms1 = 88.94, Ms2 = 90.36, Ms3 = 94.51 ; Mgrp = 59.33%, SDgrp = 12.3). Thus, the following analyses are based on the results of 56 participants (27 women).

The automatically selected and subject-specific discriminant frequency bands used to classify the two MI tasks from EEG data were in the range of 16.4  7.78 Hz to 19.58  7.44 Hz with an average length of 3.17  2.99 Hz (see Subsection 2.4 - H3 - Experimenters and participants profile-).

Before it all, we verified that groups formed by participants’ gender, i.e., “ParGender”, and experimenters’ gender, i.e., “ExpGender”, had comparable profiles. To check that groups were comparable, we ran 2-way ANOVAs with “ExpGender” and ”ParGender” as independent variables and either MRS, tension or autonomy as dependent variable.

Results indicate that groups are comparable in terms of tension. Though, participants’ gender influence their MRS [F(1, 52) = 17.47, p    =.25]. Men (Mmen = 0.07, SD = 0.02) had higher MRS than women (Mwomen = 0.05, SD = 0.02), which is in accordance with the literature Linn and Petersen (1985). Furthermore, participants training with men or women experimenters did not have the same level of autonomy [F(1, 52) = 4.01, p =.05,  =.07]. Participants training with men experimenters (MmenExp = 6.35, SD = 1.74) were more autonomous than participants training with women experimenters (MwomenExp = 5.67, SD = 1.66). As the autonomy and MRS of participants was found to influence their BCI performances Jeunet et al. (2015), we controlled for the potential influence of these variables in our subsequent analyses (see Appendix Appendix C -Details regarding the analyses on the potential influence of MRS and autonomy differences in participant groups-).

In the following sections, we report the results of the analyses presented in Section 2.5 that we performed to test each of our hypotheses.

3.1. H1 - MI-BCI performances
We started by testing the H1 hypothesis, i.e., MI-BCI performances undergo a gender-related influence of experimenters, possibly modulated by users’ gender. As stated in 2.5.1 -H1 - MI-BCI performances-, we performed two 3-way repeated measures mixed ANOVAs with “ExpGender”, “ParGender” and “Run” as independent variables and the repeated measures of performance over the runs, i.e., TAcc or EAcc, as dependent variable.

First, we performed such ANOVA using the TAcc. After correction of sphericity using the Huynh-Feldt method ( = 0.92), the results revealed no simple effect of “Run” [F(2.8, 144) = 1.81, p =.15,  =.03], “ExpGender” [F(1, 52) = 0.54, p =.47,  =.01] nor “ParGender” [F(1, 52) = 0.09, p =.76,  =.01]. They also revealed no interaction of “Run*ExpGender” [F(2.8, 144) = 0.08, p =.96,  = ] nor “ParGender*ExpGender” [F(1,52) = 0.60, p =.44,  =.01]. Though, the “Run*ParGender” interaction was significant [F(2.8, 144) = 5.98, p =.001,  =.1]. Figure 4 represents the evolution of the participants’ TAcc depending on their gender.

Fig. 4
Download : Download high-res image (180KB)
Download : Download full-size image
Fig. 4. TAcc evolution depending on participants’ gender.

Next, we performed this same analysis using the EAcc. After correction of sphericity using the Huynh-Feldt method ( = 0.8), the results revealed no simple effect of “Run” [F(2.4, 125) = 1.53, p =.22,  =.03], “ExpGender” [F(1, 52) = 0.26, p =.61,  0.01] and “ParGender” [F(1, 52) = 0.23, p =.64,  0.01]. They revealed no interaction of “Run*Par- Gender” [F(2.4, 125) = 1.92, p =.14,  =.04], “Run* ExpGender” [F(2.4, 125) = 0.23, p =.83,  = 0.01] nor “ParGender*ExpGender” [F(1, 52) = 0.92, p =.34,  =.02]. Finally, the interaction of “Run*ParGender*ExpGender” [F(2.4, 125) = 1.38, p =.26,  =.03] was not significant either.

We controlled for the potential influence of the most common artefact sources, i.e., electrooculography (EOG) and electromyography (EMG) Fatourechi et al. (2007), on our performances measures, i.e., TAcc and EAcc, in additional analyses that are presented in Appendix Appendix B -Details regarding the analyses on the potential influence of artefact sources-. These analyses did not reveal an influence of EOG or EMG artefacts that could have affected the EEG-based BCI performances.

We also controlled for the potential influence of MRS and autonomy differences in participant groups formed using the participants’ and experimenters’ gender. These analyses are presented in Appendix Appendix C -Details regarding the analyses on the potential influence of MRS and autonomy differences in participant groups- and did not reveal any potential bias from MRS and autonomy differences in participant groups.

3.2. H2 - User experience
Then, we tested the H2 hypothesis, i.e., user experience undergo a gender-related influence of experimenters, possibly modulated by users’ gender. As stated in 2.5.1 -H1 - MI-BCI performances-, we analysed the influence of participants’ and experimenters’ gender on five indicators of user-experience, i.e., mood, mindfulness, motivation, cognitive load and sense of agency.

First, we checked if the performances had an impact on the reported user-experience measures. We found that the sense of agency post training was positively correlated to both the TAcc [Spearman correlation, r(56) =.38, p < ] and EAcc [Spearman correlation, r(56) =.34, p =.01] metrics.

Then, we performed five 2-way ANOVAs or ANCOVAs, one per dimension, with “ExpGender” and “ParGender” as independent variables and either the measure of cognitive load, sense of agency, mood, mindfulness or motivation as dependent variable. Performances averaged over all runs, i.e., TAcc or EAcc, were used as covariate if they were correlated to the dependent variable.

We did not find any significant single effect or interaction including the experimenters’ gender for the cognitive load, sense of agency, mood, mindfulness or motivation (see Appendix Appendix D). We only found a significant influence of “ParGender” [F(1, 52) = 6.23, p =.02,  =.11] on the difference of mindfulness post and pre training. Overall, men participants had a decrease of mindfulness (MmindfulnessMen = -8.33  3.01) whereas women participants had an increase of mindfulness (MmindfulnessWomen = 2.5  3.12) over the session.

3.3. H3 - Experimenters’ and participants’ profile
As presented in the introduction, a previous study has shown that participants’ autonomy and tension both respectively correlate positively and negatively with BCI performances Jeunet et al. (2015). As there were differences in autonomy between the participant groups formed by experimenters’ and participants’ gender, we analysed the potential influence of participants’ autonomy in specific analyses whose results are presented in Appendix Appendix C -Details regarding the analyses on the potential influence of MRS and autonomy differences in participant groups-. These analyses did not reveal any potential influence of the differences in autonomy and MRS on our results. Thus, in this Section, we only focused on the tension to perform analyses related to the psychological profile of the participants and experimenters. High tension scores computed from the 16PF5 questionnaire indicate highly tensed, impatient and frustrated personalities whereas low scores indicate relaxed, patient and composed personalities.

3.3.1. Assessing the influence of participants’ tension
We checked if an influence of participants’ tension could be found in our results by performing an analysis of correlation between participants’ tension and our measures of performance. It revealed a negative correlation between participants’ tension and both the TAcc [Spearman correlation, r(56) = -.39, p < ] and EAcc [Spearman correlation, r(56) = -.29, p =.03] metrics, which is in accordance with previous results Jeunet et al. (2015).

Therefore, we investigated if the tension could explain the differences of performances’ depending on the participants’ and experimenters’ gender. As stated in 2.5.1 -H1 - MI-BCI performances-, we performed two 3-way ANOVAs with “ParTension”, “ExpGender” and “ParGender” as independent variables and one of the measures of performance averaged over all runs, i.e., TAcc or EAcc, as dependent variable.

When using the TAcc as a measure of performance, we did not find any simple effect of “ExpGender” [F(1, 48) = 1.51, p =.23,  =.03], nor “ParGender” [F(1, 48) = 1.72, p =.2,  =.04]. Though, a trend toward a weak impact of “ParTension” was found [F(1, 48) = 3.8, p =.06,  =.07]. No interactions were found for “ExpGender*ParGender” [F(1,48) <  p = 1,  < ], “ParTension*ParGender” [F(1, 48) = 0.18, p =.67,  < ], “ParTension*Exp- Gender*ParGender” [F(1, 48) = 0.47, p =.5,  =.01]. Though a significant and strong interaction was found between “ParTension*ExpGender” [F(1, 48) = 18.94, p <   =.28].

When using the EAcc as measure of performance we did not find any simple effect of “ExpGender” [F(1, 48) = 1.12, p =.3,  =.02], nor “ParGender” [F(1, 48) = 2.59, p =.11,  =.05]. Though, a weak but significant impact of “ParTension” was found [F(1, 48) = 4.43, p =.04,  =.08]. No interactions were found for “ExpGender*ParGender” [F(1, 48) = 0.02, p =.89,  < ], “ParTension*ParGender” [F(1, 48) = 0.1, p =.75,  < ], “ParTension*ExpGender* ParGender” [F(1, 48) = 0.72, p =.1,  =.02]. Though, a significant interaction was found between “ParTension*ExpGender” [F(1, 48) = 21.98, p <   =.31].

Figure 6 represents the average performances of participants with tensed and non-tensed personalities when taking into account the gender of their experimenters. Non-tensed participants seem to have higher performances, i.e., TAcc and EAcc, when training with women experimenters while tensed participants seem to have higher performances, i.e., TAcc and EAcc, when training with men experimenters.

Fig. 6
Download : Download high-res image (294KB)
Download : Download full-size image
Fig. 6. Estimated mean performances depending on participants’ tension and experimenters’ gender.

3.3.2. Assessing the influence of experimenters’ tension
Previous results found that a similarity between participants’ and experimenters’ profile could lead to higher bias in experimental results Rosenthal (1963). As participants’ level of tension had a significant impact on their results, we analysed the potential influence of the level of tension of our experimenters. The tension score in the personality of the three men and three women experimenters were respectively of [5, 5 and 7] and [3, 4 and 5], indicating a higher level of tension among men experimenters than among women experimenters. Therefore, we investigated further to know if the influence of the experimenters’ came from a psychosocial factor related to their gender or from their level of tension which was higher among men experimenters than women participants.

We checked if, independently of gender, there was of correlation between the tension of the experimenter and the performances of the participants. We did not find any correlation of the experimenters’ tension with the TAcc [Spearman correlation, r(56) =.03, p =.83], nor with the EAcc [Spearman correlation, r(56) =.11, p =.44].

3.4. Table 1 - Summary of the results

Table 1. Summary of the significant results per hypothesis.

Hypothesis	Analyses	Significant results
H1- MI-BCI performances	3-way repeated measures mixed ANOVA with “ExpGender”, “ParGender” and “Run” as independent variables and the repeated measures of TAcc performance over the runs as dependent variable	“Run*ParGender” [F(2.8, 144) = 5.98, p =.001,  =.1] “Run*ParGender*ExpGender” [F(2.8, 144) = 3.46, p =.02,  =.06]
H2- User experience	2-way ANOVA with “ExpGender* ParGender” as independent variables and the measure of mindfulness as dependent variable	“ParGender” [F(1, 52) = 6.23, p =.02,  =.11]
H3- Experimenters’ and participants’ profile	Spearman correlation	Negative correlation between participants’ tension and both TAcc [Spearman correlation, r(56) = -.39, p < ] and EAcc [Spearman correlation, r(56) = -.29, p =.03]
3-way ANOVA with “ParTension”, “ExpGender”, “ParGender” as independent variables and the TAcc measures of performance averaged over all runs as dependent variable	“ParTension*ExpGender” [F(1, 48) = 18.94, p <   =.28]
3-way ANOVA with “ParTension* ExpGender*ParGender” as independent variables and the EAcc measures of performance averaged over all runs as dependent variable	“ParTension” [F(1, 48) = 4.43, p =.04,  =.08] “ParTension*ExpGender” [F(1, 48) = 21.98, p <   =.31]
4. Discussion
In the following Subsections, we discuss the results obtained for each of our hypothesis.

4.1. H1 - MI-BCI performances
To test the H1 hypothesis, i.e., MI-BCI performances undergo a gender-related influence of experimenters, possibly modulated by users’ gender, we used two metrics of performances. The TAcc, which represented what the participants were instructed to improve during training, and the EAcc, a traditional measure of BCI performances. We did not find a single influence of the experimenters and/or participants gender on these performances. Though, we found a significantly different evolution across runs of the TAcc between men and women participants (see Figure 4). Women participants seemed to start the training with already good TAcc, which decreased during the second run and increased again during the last run. Men participants, however, started with rather low TAcc and then drastically improved during the second run and then stagnated to reach slightly higher final TAcc than women.

In addition, experimenters gender seemed to have an influence on this previous interaction. Indeed, the evolution of the TAcc appears to depend on participants and experimenters gender (see Figure 5). We found the same tendency for men participants to start with lower TAcc at the beginning of the session independently of the experimenters gender. However, men seemed to start with drastically lower TAcc when they were training with men experimenters. They also seemed to have higher TAcc throughout the session when they were training with women experimenters. Women participants seemed to start with higher TAcc when training with men experimenters, though their TAcc tended to drop throughout the session. However, when training with women experimenters, they seemed to have a great increase in TAcc during the last run. In social psychology, Nichols and Maner found that participants who are instructed by an opposite-sex experimenter tend to confirm the experimenters expectation regarding the experimental results Nichols and Maner (2008). The initial performances (during R3) are consistent with their findings. However, this does not seem to hold true for the evolution of the participants’ performances.

Interestingly enough, our results regarding the impact of participants’ and experimenters’ gender do not match those of a recently published neurofeedback study Wood and Kober (2018). We do concur on the fact that an interaction of participants’ and experimenters’ gender influences performances. Though, Wood and Kober found that the combination of women participants training with women experimenters hampered the training outcomes of the participants Wood and Kober (2018). They observed no learning effect in this group. The influence of the participants’ tension found in our results might partly explain this difference of results. In their article, they found a strong and significant positive correlation between the locus of control in dealing with technology, i.e., the level of control that people feel that they have over the control of a technology, and the performances of women participants training with women experimenters. We did not assess this trait of our participants, thus the difference in results might also arise from a difference in the locus of control of our women participants. Even though the locus of control of our participants was not assessed, we assessed the sense of agency they felt toward the feedback that their were provided with during the training. We did not observe any gender influence over the sense of agency reported by our participants. Overall, our analysis of the user-experience metrics only revealed an influence of participants’ gender on the evolution of the mindfulness metric. Men participants tended to have a decrease of mindfulness over the session, when women participants tended to increase their level of mindfulness. Also, Wood and Kober do not report controlling for the prior acquaintanceship between their participants and experimenters Wood and Kober (2018). Rosenthal found that this could modulate the bias induced by experimenters mostly between men experimenters and women participants Rosenthal (1963). Another explanation of the differences found between our two studies would be that, as stated by Wood and Kober, by asking their participants to fill a questionnaire regarding their locus of control in dealing with technology, they might have activated a stereotype bias Wood and Kober (2018). Such stereotype was not activated in our study. Finally, the protocol used by Wood and Kober was a neurofeedback one aiming at up-regulating the sensorimotor rhythm, and not a two-commands MI-BCI training. This most possibly also contributes to the differences of results obtained.

Current results do not seem to be biased by the mental rotation scores nor the autonomy of the participants. Indeed, the same analysis that led us to these conclusions were run with these variables as covariate. Results do not reveal any impact of these variables, and revealed the same significant effect as mentioned above. Artefacts potentially arising from eye or hand movements did not seem to bias of our results either.

4.2. H2 - User experience
Our results did not indicate any influence related to the gender of the experimenter on the participants’ user experience. Such influence could have been expected based on previous results indicating that a social presence and an emotional feedback provided through the use of a learning companion impacted one dimension of the user experience, i.e., how the participants felt about their ability to learn and memorize how to use a MI-BCI. Further experiments using different metrics of the user experience might provide more insight on the potential influence of experimenters on the user experience.

4.3. H3 - Experimenters’ and participants’ profile
When investigating the influence of the tension of the participants on these results, we found results that tend to be in accordance with the ones of Jeunet et al. Jeunet et al. (2015). Participants with tensed personality trait tend to have lower performances than non-tensed participants. An influence of participants anxiety was already found in early researches on regulation of alpha Tyson (1982). Our results revealed that the influence of the participants’ tension on MI-BCI performances seems to be modulated by the gender of the experimenter. Tensed and non tensed participants had better performances when training respectively with men experimenters and women experimenters. This result might provide a first lead toward understanding the interaction between experimenters’ and participants’ influence on MI-BCI performances. We did not find any significant influence of experimenters’ tension on participants’ performances. In the future, testing whether a similarity of experimenters’ and participants’ psychological profiles could lead to higher potential bias in the results would be of interest. In studies on social psychology, Rosenthal found that participants were more likely to respond to experimenters’ expectancy when their level of anxiety was similar to their experimenter’s level of anxiety Rosenthal (1963). He hypothesised that a similarity of experimenters’ and participants’ psychological profiles could lead to higher potential bias in the results. We can make the same hypothesis as Rosenthal to explain our results as men experimenters in our study had higher scores of tension than women experimenters Rosenthal (1963). Non-tensed participants might have been more inclined to respond to women experimenters’ expectancy, i.e., to have high MI-BCI performances, who also tended not to be tensed. Tensed participants, however, might have been more inclined to respond to men experimenters’ expectancy who also tended to be tensed. The number of participants did not enable to perform an analysis of both the experimenters’ and participants’ gender and tension at once, as the number of participants per group would have been too low. Furthermore, experimenters’ level of tension was highly dependent on their gender. Larger scaled experiments with a greater number of experimenters would provide insight on this hypothesis.

4.4. Limitations
While this study does provide first insights on the interaction between experimenters’ and participants’ gender, future studies are needed to further explore it and explore its unknown long term influence. Studies with a larger number of experimenters and participants might provide more information regarding the underlying factors of this gender influence. For instance, it could confirm or disprove the interaction between experimenters’ gender and participants’ tension. If confirmed, our hypothesis regarding the beneficial similarity between the level of tension in participants’ and experimenters’ personality could be assessed.

Furthermore, our results might be explained by other factors. Indeed, inter-experimenter variability other than gender (e.g., teaching competence), intra-experimenter variability (e.g., appearance and outfit, fatigue, expectations), inter- and intra-participants variability (e.g., attractiveness, or motivation) - plus the interaction’s characteristics (e.g., physical proximity, use of humour, familiarity, verbal and non-verbal communication, quantity of interaction, etc.) were not analysed. Indeed, many of these variables are very difficult to measure formally and objectively. Moreover, we were already measuring various aspects of the users and experimenters personality and states, using validated questionnaires, and the experiment was already long. Thus, measuring these additional factors would have required to remove some of the factors actually measured (to keep a reasonable experiment duration), which, according to the literature, were the one with the most influence, at least theoretically. In summary, our study shows an interaction between experimenters and participants on the evolution of MI-BCI performances. This interaction seems related to the experimenters’ and participants’ gender. However, future experiments should confirm and provide more insights regarding this interaction.

5. Conclusions and Prospects
In this paper, we investigated the presence of an experimenters’ and participants’ gender interaction on MI-BCI training outcomes, i.e., performances and user-experience. We led this work in response to the fact that previous BCI experiments indicated an influence of social presence and emotional feedback on BCI user training. Experimenters are the main source of such presence and feedback during BCI user training. Though, their impact on the MI-BCI user training outcomes remained unassessed. Also, results from different fields indicate that an interaction between experimenters and participants gender is likely to influence experimental outcome. Therefore, we asked 6 experimenters to each train 5 women and 5 men (60 participants in total) to perform right versus left hand motor imagery-BCI control over one session.

We did find an interaction between experimenters and participants gender on the evolution of trial-wise accuracy over a session. Furthermore, participants mean performances were influenced by an interaction of the experimenters gender and level of tension in participants personality. No single effect or interaction related to the experimenters could be found on the user-experience.

Our results highlight the need for research methods that formally take into account a greater amount of influencing factors (such as the experimenter) emerging from the experimental protocol and its context. For instance, the instructions that participants are provided with regarding the strategies they should adopt to perform mental-imagery tasks, are rarely formalized or mentioned in papers. Furthermore, most published experimental studies do not report taking into account the potential influence of experimenters. Both the literature and experimental results indicate that experimenter-related factors might explain part of the between-subject and/or between-study variability and contribute to the improvement and adaptation of MI-BCI training.

We argue that in the future the influence of experimenters should be considered carefully while designing and reporting experimental protocols. Such consideration would benefit many fields, in particular the Human Computer Interface and the BCI ones. A better understanding of the experimenters’ influence could particularly lead to an improvement of MI-BCIs as they rely on a long and tedious user training during which experimenters have an important role. Other BCIs paradigms, such as P300-based BCIs3, do not have such user training. However, regardless of the BCI paradigm or even field, during experimental studies assessing experimenter-unrelated factors and while experimenters’ influence is not well understood, the bias that can arise from experimenters should be limited and controlled. Double-blind methods, in which neither the experimenters nor the participants know the group in which the participant is included, do limit the experimenter related bias. They are already used in clinical research. It would be worth applying similar methods in non-clinical experiments. It should be noted that hiring research assistants to perform the experiments might not be a solution to limit experimenter-related bias. Indeed, it was shown that experimenters can unconsciously transmit their bias to their research assistants Rosenthal (1963). The literature suggests several other solutions to limit and control the potential bias arising from the experimenter Miyazaki and Taylor (2008); Rosnow and Rosenthal (1997). These methods include: monitoring participant-experimenter interaction, increasing the number and diversity of data collectors, pre-testing the method and controlling expectancy, providing an extensive training for administrators/ data collectors, monitoring and standardizing the behaviour of experimenters with detailed protocol and pre-written instructions for the participant, and statistically controlling for bias. The use of learning companions, such as PEANUT (see Figure 1) Pillette et al. (2020), could also limit the experimenters’ role while providing the important social presence and emotional feedback in a more reproducible form Pillette et al. (2018).

In conclusion, social presence and emotional feedback are meant to increase the effort, motivation and engagement of the participants throughout the learning. As any feedback, they must be carefully studied as they can be double-edged. On the one hand, they can benefit the learning outcome, depending on the participants’ profile Bonnet et al. (2013); Mathiak et al. (2015); Nijboer et al. (2008); Pillette et al. (2020). On the other hand, as any feedback, they can have a detrimental impact on the user training and the reliability of experimental results when they are incorrectly designed and assessed Wood and Kober (2018).

Funding information
This work was supported by the French National Research Agency (project REBEL, grant ANR-15-CE23-0013-01) and the European Research Council with the Brain-Conquest project (grant ERC-2016-STG-714567).

Declarations of interest
None.

CRediT authorship contribution statement
Léa Pillette: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Supervision, Validation, Visualization, Writing - original draft, Writing - review & editing. Aline Roc: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Resources, Validation, Visualization, Writing - original draft, Writing - review & editing. Bernard N’Kaoua: Conceptualization, Methodology, Supervision, Validation, Writing - review & editing. Fabien Lotte: Conceptualization, Funding acquisition, Investigation, Methodology, Supervision, Validation, Writing - original draft, Writing - review & editing.

Declaration of Competing Interest
The authors whose names are listed immediately below certify that they have no affiliations with or involvement in any organization or entity with any financial interest (such as honoraria; educational grants; participation in speakers bureaus; membership, employment, consultancies, stock ownership, or other equity interest; and expert testimony or patent-licensing arrangements), or non-financial interest (such as personal or professional relationships, affiliations, knowledge or beliefs) in the subject matter or materials discussed in this manuscript.

Acknowledgements
We would like to thank all the participants and the experimenters, i.e., Aurélien Appriou, Camille Benaroch and Damien Caselli, for dedicating the time to conduct some of the experiments.

Appendix B. Details regarding the analyses on the potential influence of artefact sources
Because brain signals are really small in amplitude and EEG suffers from very low signal to noise ratio (SNR), i.e., high vulnerability to artefact sources, we controlled for the most common artefact sources, i.e., electrooculography (EOG) and electromyography (EMG) Fatourechi et al. (2007). The aim was to check if specific patterns could be found in EOG or EMG signals that could have affected MI classification by the BCI. The presence of such task-specific patterns could have confounded the measured MI-BCI performances. We thus wanted to assess how much EMG or EOG artefacts could have affected the recorded EEG signals and influenced the MI-BCI classification output and accuracy. To do so, we computed two metrics per source of potential artefacts.

First, we looked at left vs right MI classification accuracy, i.e., TAcc and EAcc, based on EOG or EMG signals, using a classifier built on the calibration runs. This was computed using CSP/LDA calibrated on the EOG or EMG signals only from the two calibration runs, filtered in the participant-specific discriminant frequency band. Note that we used the same frequency band as for the online experiment since only task-related EMG and EOG variations occurring in the same frequency band as the one used by the EEG-BCI classifier could have affected this classifier output, and therefore the resulting BCI accuracy. The resulting classifier was then applied on the subsequent runs to obtain a measure of EOG or EMG accuracy per run. The accuracies based on such calibration run can reflect the presence of task-specific EMG or EOG artefacts in EEG signals, during both the calibration and the training phases, which might have influenced online EEG-based BCI performances.

Second, the run-specific left vs right MI EOG or EMG accuracies were computed using a cross-validation method. EOG or EMG data only from each run, filtered in the participant-specific discriminant frequency band, were divided into five subsets of data. The CSP and an LDA were successively calibrated on four sets and tested on the remaining one. The run-specific EOG or EMG metric is the mean classification accuracy obtained for the five subsets for each of the runs. The run-specific accuracies reflect the presence of task-specific EOG or EMG artefacts that could have affected online EEG-based BCI performance, during each run.

The results of these analyses are presented in the sections below.

B1. Checking the influence of EMG artefacts
We first assessed whether EMG artefacts, or real unsolicited hand movements from our participants, could have had an impact on our main results, i.e., the interactions we found between the evolution of trial-wise accuracy and experimenters’ and participants’ gender that we obtained with an EEG-based classification accuracy.

We inspected the potential relation between mean EEG-based classification accuracies, i.e., TAcc and EAcc, and EMG-based classification accuracies, i.e., calibration runs based and run specific, by performing analyses of correlation. We did not find any correlation between the mean calibration runs based EMG accuracy and the mean TAcc [Spearman correlation, r(54) = -.2, p =.15] nor with the mean EAcc [Spearman correlation, r(52) = -.15, p =.29]. No correlation could be found either between the mean run specific EMG accuracy and the TAcc [Spearman correlation, r(53) = -.1, p =.49] nor the EAcc [Spearman correlation, r(51) = -.86, p =.55].

B2. Checking the influence of EOG artefacts
Similarly to the previous section, we inspected if EOG artefacts or eye movements performed by our participants could have had an impact on our main results that we obtained with EEG-based classification accuracies.

We inspected the potential relation between mean performances, i.e., TAcc and EAcc, and EOG-based classification accuracies, i.e., calibration runs based and run specific, by performing analyses of correlation. We did not find any correlation between the mean calibration runs based EOG accuracy and the mean TAcc [Spearman correlation, r(54) = -.23, p =.11] nor with the mean EAcc [Spearman correlation, r(52) = -.17, p =.22]. Though, a significant correlation could be found between the mean run specific EOG accuracy and both the TAcc [Spearman correlation, r(56) =.31, p =.02] and the EAcc [Spearman correlation, r(54) =.36, p < ].

We hypothesized that these significant correlations resulted from EEG acquisitions from the electrodes positioned to measure EOG. Indeed, when the same analysis was performed using cross-validation on data filtered on EOG frequency band, i.e., 0.5-4Hz, we did not find any correlation with the mean TAcc [Spearman correlation, r(54) =.05, p =.73] nor with the mean EAcc [Spearman correlation, r(52) =.12, p =.39].

Appendix C. Details regarding the analyses on the potential influence of MRS and autonomy differences in participant groups
As stated in Section 3 -Results-, the groups of participants formed using the participants’ and experimenters’ gender had differences in terms of mental rotation scores and autonomy. Therefore, we studied the potential impact of these differences on the results presented in Section 3.1 -H1 - MI-BCI performances-.

We ran our same main analyses than in this section (two 3-way repeated measures mixed ANOVAs with “ExpGender”, “ParGender” and “Run” as independent variables and the repeated measures of performance over the runs, i.e., TAcc or EAcc, as dependent variable) using the autonomy, i.e., “Autonomy”, or the mental rotation score, i.e., “MRS”, of the participants as covariate. When performing the analysis on the TAcc we found no impact of the autonomy (“Autonomy” [F(1, 51) = 0.26, p =.61,  < ], “Autonomy*Run” [F(2.48, 126.6) = 0.81, p =.47,  =.02]) nor of the mental rotation score (“MRS” [F(1, 51) = 1.75, p =.19,  =.03], “MRS*Run” [F(2.47, 125.79) = 1.52, p =.22,  =.03]). When investigating the EAcc we did not find any single effect or interaction of the autonomy (“Autonomy” [F(1, 51) = 0.44, p =.51,  = ], “Autonomy*Run” [F(2.1, 107.14) = 1.46, p =.24,  =.03]) nor of the mental rotation score (“MRS” [F(1, 51) = 1.05, p =.31,  =.02], “MRs*Run” [F(2.18, 111.18) = 1.35, p =.27,  =.03]) either.

Appendix D. Details regarding the analyses on the potential influence of experimenters’ gender on the user-experience
We analysed the influence of experimenters’ and participants’ gender on the five dimensions of the user-experience, i.e., mood, mindfulness, motivation, cognitive load and sense of agency.

First, we checked if the performances had an impact on the reported user-experience measures. We found that both the TAcc [Spearman correlation, r(56) =.38, p < ] and EAcc [Spearman correlation, r(56) =.34, p =.01] metrics were positively correlated to the sense of agency post training.

Therefore, we performed five 2-way ANOVAs or ANCOVAs, one per dimension, with “ExpGender*ParGender” as independent variables and either the measure of cognitive load, sense of agency, mood, mindfulness or motivation as dependent variable. Performances averaged over all runs, i.e., TAcc or EAcc, were used as covariate if they were correlated to the dependent variable.

No influence was found on the cognitive load reported post training of “ExpGender” [F(1, 52) = 1.65, p =.2,  =.03], “ParGender” [F(1, 52) = 2.89, p =.1,  =.05] nor “ExpGender*ParGender” [F(1, 52) = 0.05, p=0.95,  < ].

No influence was found on the sense of agency of “ExpGender” [F(1, 52) = 0.03, p =.85,  = ], “ParGender” [F(1, 52) = 0.01, p =.92,  < ] nor “ExpGender* ParGender” [F(1, 56) = 0.44, p =.51,  < ] using the TAcc as covariable. Neither was there any influence found with the EAcc as covariable of “ExpGender” [F(1, 56) = 0.08, p =.78,  = ], “ParGender” [F(1, 52) =  p =.97,  < ] nor “ExpGender* ParGender” [F(1, 52) = 0.52, p =.47,  =.01].

No influence was found on the difference of mood reported post and pre training of “ExpGender” [F(1, 52) = 0.06, p =.81,  = ], “ParGender” [F(1, 52) <  p =.93,  < ] nor “ExpGender*ParGender”[F(1, 52) = 0.13, p =.72,  < ].

No influence was found on the difference of mindfulness reported post and pre training of “ExpGender” [F(1, 52) = 0.04, p =.85,  = ] or “ExpGender*ParGender” [F(1, 52) = 0.92, p =.34,  =.02]. Though, a significant impact of “ParGender” [F(1, 52) = 6.23, p =.02,  =.11] was found. Overall, men participants had a decrease of mindfulness (MmindfulnessMen = -8.33, SD = 3.01) whereas women participants had an increase (MmindfulnessWomen = 2.5, SD = 3.12) of mindfulness over the session.

No influence was found on the difference of motivation reported post and pre training of “ExpGender” [F(1, 52) = 0.63, p =.43,  =.01], “ParGender” [F(1, 52) = 0.78, p =.38,  =.02] nor “ExpGender*ParGender” [F(1, 52) = 0.97, p =.33,  =.02].