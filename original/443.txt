Satellite networks can provide Internet of Things (IoT) devices in remote areas with seamless coverage and downlink multicast transmissions. However, the large transmission latency, serious path loss, as well as the energy and resource constraints of IoT terminals challenge the stringent service requirements for throughput and latency in the 6G era. To address these problems, technologies including space-air-ground integrated networks (SAGINs), machine learning, edge computing, and energy harvesting are highly expected in 6G IoT. In this article, we consider the unmanned aerial vehicles (UAVs) and satellites to offer wireless-powered IoT devices edge computing and cloud computing services, respectively. To accelerate the communications, Terahertz frequency bands are utilized for communications between UAVs and IoT devices. Since the tasks generated by terrestrial IoT devices can be conducted locally, offloaded to the UAV-based edge servers or remote cloud servers through satellites, we focus on the computation offloading problem and consider deep learning techniques to optimize the task success rate considering the energy dynamics and channel conditions. A deep-learning-based offloading policy optimization strategy is given where the long short-term memory model is considered to address the dynamics of energy harvesting performance. Through the theoretical explanation and performance analysis, we discover the importance of emerging technologies including SAGIN, energy harvesting, and artificial intelligence techniques for 6G IoT.

Introduction
Inspired by the development of wireless communications in terms of capacity, coverage, and latency, the Internet of Things (IoT) is attracting increasing attention since it enables remote access, control, and monitoring [1]. It has been reported that the number of IoT connections will grow 2.4-fold to 14.7 billion by 2023. As we know, a huge number of IoT devices are connected to the Internet via different access technologies, among which satellites play an important role due to seamless coverage and limited expense [2]. With the widespread placements of IoT devices to realize remote monitoring and control, satellites have been regarded as a critical alternative to cellular base stations, especially in rural and sparsely populated areas. Moreover, the developments in satellite manufacturing and launch technologies have significantly lowered the threshold of civilian use.

However, the inherent shortcomings of satellite communications, which include the enormous transmission distance, significant path loss, and exposed communication links, challenge the quality of provided services. In 6G networks, the diversified and stringent requirements mean that prompt response and reliable connections are also important for many IoT services. To meet these requirements, researchers have considered the aerial infrastructure including unmanned aerial vehicles (UAVs), balloons, and airships to complement satellite communications. Thus, the integrated networks, space-air-ground integrated networks (SAGINs), have been regarded as the paradigm for 6G to provide heterogeneous services [3], [4]. Moreover, the transmit power of IoT devices should be large enough to overcome the significant path loss, which can reduce the lifetime of sensing terminals as they are difficult to charge. To address this problem, energy harvesting is highly promising since it enables IoT devices to be wirelessly powered by environment sources including solar, winding, and radio frequency (RF) signals.

In this article, we study -satelfite-UAV-served 6G IoT networks, as shown in Fig. 1, and focus on the computation offloading problem. The considered heterogeneous terrestrial IoT terminals generate different tasks and require the results after processing within definite time periods. The UAVs fly in a predefined trajectory periodically and hover in several positions for fixed times to provide communication and computation services for the covered IoT devices. Different from the discrete connections provided by UAVs, the considered low Earth orbit (LEO) satellites in the space layer can provide continuous services [5]. To alleviate the computation overhead for IoT devices, UAVs are enabled by edge servers, while satellites are connected to cloud servers through ground stations. We assume the IoT devices generate some computation tasks and need to offload to the UAV-based edge servers or remote cloud servers through LEO satellites. To optimize the computation offloading and resource allocation, the remaining batteries of IoT devices, transmission environments, and computing hardware heterogeneity should be jointly analyzed, which requires massive iterations to reach a global optimum using traditional methods [3]. Moreover, 6G IoT devices are expected to harvest energy from the environment to alleviate the battery constraints, of which the dynamics and uncertainty further complicate the problem.

Since artificial intelligence (AI) can efficiently address the dynamics and avoid the time-ag-gressive iterations of traditional mathematical methods, it has been regarded as one of the key technologies for 6G [4], [6], [7]. In this article, we utilize deep learning to optimize the computation offloading policy. Specifically, the long short-term memory (LSTM) model is adopted to predict the harvesting power in the near future. Then the information of available energy in the next time slot can be utilized to optimize the computation offloading policy for different IoT devices. Through the proposed deep-learning-based strategy, we further explain the existing challenges and future directions for intelligent SAGIN-based 6G IoT networks. Thus, the contributions of this article can be summarized as follows:

We discuss the limitations and developments of the emerging technologies for future IoT services in remote areas. Specifically, an overview of key technologies including the THz regime, energy harvesting, edge computing, and machine learning are introduced for satellite-UAV-served 6G IoT systems.

We analyze the computation offloading for the considered satellite-UAV-served 6G IoT system. Then we propose a deep-learning-based computation offloading approach, which can improve the system computation performance considering the energy dynamics and different communication conditions.

We further introduce some problems and challenges, which we believe can provide some inspiration for future researchers.

The remaining article includes six sections. We first discuss the existing satellite-IoT networks and related research. We mainly focus on the problems that need to be solved in 6G. The following sections introduce potential 6G key technologies and propose the satellite-UAV-served 6G IoT networks. Then we focus on the computation off-loading optimization and propose an AI-based strategy to improve the task success ratio as well as system computation rate. Finally, we discuss several prospective research directions and conclude the article.

Development and Limitations of Satellite-Served IoT
Compared to the terrestrial cellular and WiFi-based access technologies, satellites have the advantages of seamless coverage and flexible service provision. Moreover, the limited ground infrastructure and remote maintenance further increase the cost efficiency of provided IoT services. On the other hand, the utilization of 5G New Radio (NR) in millimeter-wave (mmWave) frequency bands significantly shrinks the coverage of cellular base stations. Satellites have been regarded as the most important alternative to provide high throughput connections for sparsely populated areas, and the global market for satellite-served IoT services will grow to $5.9 billion in 2025. Inspired by the promising market, many companies including SpaceX and Amazon have started their projects to construct commercial satellite constellations for seamless coverage, especially for users in remote areas [8]. These projects are expected to significantly drive the development and improve the provided IoT services. For instance, the Starlink plan of SpaceX is projected to construct a low Earth orbit (LEO) satellite network with Ku, Ka, and even V bands to provide high-speed connection up to 1 Gb/s, which is more than 2000 times the current link rate provided by Inmarsat [8].

Figure 1. - The considered satellite-ua V-served 6G lot system.
Figure 1.
The considered satellite-ua V-served 6G lot system.

Show All

There is no doubt that the satellite constellations constructed by the above projects will meet the requirements of most 5G IoT services in rural areas. However, more endeavors and further developments are still needed to meet the requirements of 6G IoT. Even though the 6G architecture is still unclear, some basic common sense has been widely acknowledged. Khaled's research [7] has pointed out the utilization of THz frequency bands, and the required end-to-end latency may reach as low as 1 ms. It has been envisioned that the target is to allow users in remote areas to enjoy similar access to today's in many urban areas. Moreover, the lifetime requirements of IoT devices would demand more than 40 years of continuous operation [9]. It can be found that all of these targets are nearly impossible for current satellite-served IoT devices in remote areas due to the lack of terrestrial infrastructure and inherent limitations of satellite communications. The serious signal attenuation along the long transmission path requires large transmit power, while the dynamic channel condition affects service stability. Furthermore, the required service awareness and intelligence in 6G IoT will produce more computation overhead, which challenges the resource-constrained IoT devices. Even though the satellite can help offload the generated tasks to the cloud servers, the total round-trip latency is not acceptable for many future 6G IoT services.

To increase service awareness and even realize automatic network management in remote areas, AI has been regarded as the only solution. In recent years, academia and industry have conducted extensive research on AI-based network optimization. However, an overview of these technologies for 6G IoT systems in remote areas is still required.

To solve the above problems of IoT services in rural areas, several key technologies have been widely acknowledged as paradigms, including SAGINs, energy harvesting, and edge computing [7]. There is no doubt that the three technologies can satisfy the diverse service requirements, address the energy constraints, and reduce the latency in 6G IoT. However, these research works focus on the whole picture of 6G and neglect the detailed analysis in 6G IoT. Reference [4] analyzes security problems in 6G networks and utilizes blockchain AI-based approaches. Reference [10] studies SAGIN-served IoT networks and discusses space/aerial-assisted computation offloading. Moreover, to increase service awareness and even realize automatic network management in remote areas, AI has been regarded as the only solution [6]. In recent years, academia and industry have conducted extensive research on AI-based network optimization. However, an overview of these technologies for 6G IoT systems in remote areas is still required.

Promising Technologies Toward Satellite-UAV-Served 6G IoT
In this section, we discuss four key techniques: THz regime, energy harvesting, AI, and edge computing. We focus on their applications in satel-lite-UAV-served 6G IoT systems.

Utilization of Thz Regime
Researchers have envisioned extending the utilized spectrum from mmWave (30–300 GHz) to THz regime (0.3-3 THz) to further improve the data rate up to 1 Tb/s [7]. The utilization of the THz spectrum can significantly enlarge the application range of IoT to data-rate-intensive scenarios such as holographic video transfer, 3D imaging, and sensing, which will also become urgently needed for users in remote areas. The challenge of transistor design has been studied to be addressed by utilizing new hardware technologies including silicon-germani-um (SiGe) to enable broader spectrum utilization. However, the serious path loss and environment absorption of the THz frequency bands [12] means that only UAVs can provide THz connections to terrestrial IoT devices in remote areas. This means that to enable THz communications, the IoT devices and UAVs should be carefully designed [13]. Moreover, since the transmission quality of THz signals can be seriously affected by physical surroundings and weather, the trajectory and hovering positions of UAVs should be carefully analyzed to guarantee the received signal-to-interference-plus-noise ratio (SINR). More details on THz transmission modeling can be found in [12], [13].

Energy Harvesting
For IoT devices in remote areas, it is usually difficult to charge the batteries due to the lack of grid electricity. Researchers have proposed many energy-saving strategies to minimize the consumption at the sacrifice of sensing and communication performance, meaning a trade-off between lifetime and service quality. To meet the stringent requirements of increasing IoT services in 6G, the battery constraints for IoT devices in remote areas are receiving growing attention. Thus, energy harvesting has been widely studied to enable IoT devices to totally get rid of the shortage and lack of grid electricity. Moreover, these energy harvesting techniques can easily be applied for the IoT devices in remote areas since many of them are exposed and surrounded by various resources such as solar, wind, and radio signals. Therefore, to drive the application of this technology, what we need to do is enable IoT devices' harvesting functions that are mature and low-cost. One of the problems is the dynamics of the energy harvesting process, which affect functions including resource allocation, transmission scheduling, power management, and so on. In any case, it is still valuable to construct a sustainable communication system powered by environmental energy.

Edge Computing
Edge computing enables supplementing the computing and caching resources near the IoT devices and provides the service in a near-real-time manner. In the satellite-UAV-served IoT systems, the edge servers deployed on UAVs are responsible for conducting tasks that are beyond the local computing capacity of the ground sensing terminals and have stringent latency requirements. The edge servers can also help conduct small or not very urgent tasks when the resource is available, which can save the energy of IoT devices. Another advantage for the satellite-UAV-served 6G IoT is that edge servers can process the data around sensing devices, meaning less exposure of private information compared to satellite communications. As data privacy and safety bring more attention in 6G, edge computing can provide users with customized services.

Machine Learning
Machine learning is critical for the satel-lite-UAV-served 6G IoT as the intelligence can enable system improvement in at least three aspects. First, the complex meteorological conditions and climate dynamics of the environment may cause unexpected changes for the transmitted signals and harvesting process, which can be predicted by machine learning. Thus, the necessary network adjustment can be conducted. Second, machine learning can utilize the network trace to map the complex relationships among multiple network factors [3]. Compared to traditional iteration and loop-based searching methods, machine-learning-based network optimization strategies are more efficient and powerful. Third, the long-term target of network optimization is to realize automatic management, which is critically important for satellite-UA V-served 6G IoT systems in remote areas. Machine learning can help operators reduce human interventions.

The Considered Satellite-UAV-Served 6G IoT System and Problem Formulation
After introducing the potential technologies, we introduce the considered satellite-UAV-served 6G IoT system and explain how every part cooperates to provide diversified services. We discuss the computing-related performance metrics and formulate the problem to optimize the computation offloading policy.

System Model
As shown in Fig. 1, the considered network is a three-layer hierarchical structure: the satellite layer, UAV layer, and terrestrial layer including IoT devices, ground stations, and cloud servers. The satellite layer is composed of LEOs, which can also be scaled to include geostationary Earth orbit (GEO) and medium Earth orbit (MEO) satellites. The satellites provide full coverage for the IoT devices and connect the Internet or cloud servers through the ground stations. The UAVs hover over the IoT devices and provide edge computing assistance. We assume the connections between IoT devices and UAVs utilize THz frequency bands. Due to serious attenuation, the UAVs need to hover near the IoT devices. Moreover, since each UAV needs to be charged due to the battery constraint, it can only periodically hover at several positions and serve the covered IoT devices within a limited time period. The hovering positions and time can be optimized, which have been studied by many researchers [10]. Here, we can assume that the trajectories and hovering time are decided and optimized according to the work scheduling of covered IoT devices. In the terrestrial layer, the considered IoT devices generate some tasks and require the processing results for further action. For example, the smog sensor in a forest collects a series of data and judges whether generating a fire alarm is necessary. In remote areas, there are usually heterogeneous IoT devices offering diversified services, which means that the generated tasks have different sizes and latency requirements. Since IoT devices usually have limited computing capacity and batteries, it is reasonable to assume the generated tasks can be conducted locally or offloaded to UAVs and satellites. Additionally, to alleviate the energy constraint, the considered 6G IoT devices can harvest energy from various sources, including solar, wind, vibration, radio signals, and so on [14]. Also, many natural energy sources including solar and wind are predictable, while some are even controllable, such as radio signals.

In this article, we focus on the computation offloading policy to optimize the provided services. Some of the generated tasks are offloaded to the cloud or edge servers via the satellites or UAVs, respectively. To meet the latency requirement, which is measured from the task generation to receiving results, we need to analyze both the task transmission and processing. Before presenting the studied problem, we introduce the concerned transmission model, computation off-loading model, and cost model in the following paragraphs.

Since the UAVs fly very near the IoT devices, we can assume that both line-of-sight (LoS) and non-line-of-sight (NLoS) links exist. The NLoS links include the reflected, scattered, and diffracted paths. However, as THz communication is very sensitive to the blockage of obstacles, the received power via NLoS links is very limited if an LoS link exists at the same time. For THz communications, the path loss consists of the spreading loss and molecular absorption loss, which cannot be neglected. For simplicity, the THz path loss model is not introduced and can be found in [12]. For the satellite-IoT links, we can utilize the free-space path loss model. Once we get the value of path loss, we can calculate the received power, which is further utilized to find the transmission rates of satellite-IoT links and UAV-IoT links, denoted as Rs,d and Ru,d, respectively.

To alleviate the energy constraint, the considered 6G IoT devices can harvest energy from various sources, including solar, winding, vibration, radio signals, and so on. Also, many natural energy sources including solar and winding are predictable, while some are even controllable, such as radio signals.

The considered IoT services are assumed to be offered at fixed time slots when the UAVs are arranged to provide computing assistance. The tasks generated by different services require various computing cycles and have different latency tolerance. Once the tasks are generated, we assume that the IoT devices inform the corresponding UAVs of the necessary computing cycles, latency requirements, local computation resource, and recent energy records. Then the UAVs first estimate the latency to execute the task locally or through the cloud/edge servers. Next, the available energy and required energy of each computing policy need to be calculated according to the energy records. Finally, the UAVs need to choose a computing policy to optimize the system performance according to the estimated latency and energy.

To estimate the computation latency, we need to introduce how the cloud servers and edge servers work in the considered scenario. The cloud servers are assumed to offer each task fixed computation resource and conduct them in a parallel manner. Then the computing latency for the cloud servers depends on the required cycles, which is similar to local computing. On the other hand, the edge servers execute the offload-ed tasks according to the first in first out (FIFO) rule. Since each UAV has knowledge of its task queue and computation resource, it can get a reasonable estimation of the queuing latency and computing delay. We further assume the size of processing results for each kind of task is fixed; then the communication latency of task offloading and result feedback can also be calculated. We only consider the energy consumption of IoT devices. Therefore, the energy consumption of local computing can be calculated by the product of processing power and latency. For the cloud and edge computing policies, the energy consumption is mainly for transmitting the tasks and receiving the results, of which the working power is usually available while the time can be calculated according to Rs,d and Ru,c.

Problem Formulation
Due to the resource constraint and latency requirement, the IoT devices are assumed to offload the generated computation tasks to UAV-as-sisted edge servers or cloud servers through satellites. We utilize Ii,j to denote whether task j generated by IoT device i is finished successfully. Then the binary metric Ii,j is equal to 1 when the task is finished within the required time; otherwise, it has the value of 0. Next, one of the research goals is to maximize the sum of Ii,j which means to finish as many tasks as possible. The computation offloading aims to provide qualified service. However, it can cause some problems if we only focus on the number of finished tasks. For example, when the computation overhead is not huge, the IoT devices may offload as many tasks as possible to the edge servers and neglect the available cloud servers since the satellite communication costs more energy. However, the UAV-based edge servers usually have limited computation capacity, and the uploaded tasks may not be processed in time, which means a waste of energy during the communication process. The remote cloud computing solution through satellite links has high communication cost in terms of end-to-end latency and energy. Moreover, for different wireless-powered IoT devices, the harvesting power is dynamic, while the generated tasks have different latency requirements, which further complicates the computation offloading process. Furthermore, the diversified and dynamic channel conditions in SAGINs are also challenges in scenarios where cooperative transmissions among satellites, UAVs, and ground infrastructure are considered. In this research, we consider that the considered IoT devices directly upload the computing tasks to remote cloud computing servers via satellites or UAV-based edge computing servers. The UAVs are also assumed to decide the offloading policy for the covered IoT devices. Therefore, the research goal is to maximize the successfully finished computation tasks with the energy and latency constraints for the IoT devices considered.

Figure 2. - The proposed AI-based computation offloading strategy
Figure 2.
The proposed AI-based computation offloading strategy

Show All

The Proposedai-Basedapproach and Performance Analysis
To optimize the computation offloading for optimizing system performance, we propose an AI-based approach as shown in Fig. 2, where a deep learning model is adopted to predict the harvesting power. It should be noted that the deep neural network (DNN) shown in Fig. 2 just represents a general deep learning model and can be replaced by any other AI model accordingly. In the following paragraphs, we introduce our proposal and analyze its performance.

Ai-Based Computation Offloading
To maximize the number of finished computation tasks, we need to design the offloading policy for each IoT device according to its available energy, communication conditions, and available computation resource. In this proposal, we consider that the UAV-equipped edge servers are capacity-constrained, while the cloud servers have enough threads to conduct all the tasks uploaded by the considered IoT devices in a parallel manner. Moreover, the UAVs decide the offloading policy for the covered IoT devices, for which each IoT device needs to upload the task information to the corresponding UAV. In this example, we consider the communication condition to be fixed, which means that the energy cost of the task uploading process just depends on the task size. As the IoT devices are wireless-powered, the energy dynamics challenge the offloading decision process. In this proposal, we adopt the LSTM model to predict the harvesting power in the near future with the history trace as the LSTM is efficient in sequential variable predictions [15]. Thus, the UAVs adopt an LSTM model for each covered IoT device to predict the harvesting power. Then the UAVs calculate the available energy and choose the offloading policy. It should be noted that if the available energy is not enough to upload the tasks to the UAV or satellites, the tasks are dropped once the latency requirement cannot be satisfied.

Performance Analysis
We conduct simulations to illustrate the performance in terms of the task success ratio and system computation rate. We consider one LEO satellite and three UAVs to serve an area of 800 m × 800 m, where 50 IoT devices are evenly distributed. The UAVs fly at a fixed altitude, and the trajectories have been predefined. To guarantee the received power of the THz signals, the distance between the hovering positions and the corresponding covered IoT devices should be kept within 10 m. The computation capacity for the edge server and cloud server are 3 GC/s and 10 GC/s. The size of the generated task by the IoT devices is 0.5 MB. The values of some other parameters are given in Table 1.

To illustrate the performance of our proposal more clearly, we analyze two benchmark off-loading strategies: random offloading strategy and greedy offloading strategy. For the random off-loading strategy, the IoT devices randomly upload the tasks to the UAVs or satellites if the available energy is enough. For the greedy offloading strategy, the offloading policy is chosen in the order of UAV-based edge computing and remote cloud computing via satellites. Once the computing resource for the former choice is not enough, the IoT devices turn to the latter one. We change the task generation rate and analyze the task successfully finished ratio and system computation rate.

As shown in Fig. 3, the three strategies have nearly the same strategies, and the task success ratio is more than 90 percent, which means that nearly all the tasks are successfully finished in time. However, when the task generation rate increases, the success ratio decreases, while the increasing tendency of the system computation rate tends to slow for the three strategies, as shown in Figs. 3a and 3b, respectively. This means that the energy is not enough to support the increasing communication and computation overhead. On the other hand, the proposed AI-based offloading strategy can still achieve better performance than the other two methods, meaning that the proposal can select the most energy-efficient offloading policy. This is because the proposed strategy can estimate the energy of three offloading solutions, which can be further used to decide whether to drop the tasks or upload them to the UAVs or satellite. Furthermore, we analyze the share of the tasks dropped and processed by edge servers and cloud servers, as shown in Fig. 4. It can clearly be found that the edge servers equipped on UAVs process most of the tasks.

Future Research Issues
The above introduction and analysis of satel-lite-UAV-served 6G IoT illustrate the advantages of the potential architecture. To advance the development of 6G IoT, we need to further delve into the outlook of future applications and analyze the potential problems that do not exist in or have not been solved for current cellular communication systems. Here, we discuss four directions in the following paragraphs.

Intelligent UAV Management
For UAV communications, trajectory control is an important topic that has attracted a great deal of attention. However, in the 6G era, the UAVs will not only act as mobile base stations, but also provide computation service. Moreover, for intelligent 6G IoT in remote areas, the UAVs also act as mobile platforms to provide AI assistance. The broadcast radio signals of UAVs are also an important energy source, which can be utilized to meet the green communication requirement of 6G. Therefore, the multiple roles of UAVs make it complex and important to manage the trajectories, select the hovering positions, and allocate the resources. For UAV communications, on one hand the mobility increases flexibility. On the other hand, it complicates UAV management. To meet 6G IoT service requirements, the UAV management requires more attention.

Table1. Parameters of the satellite-lot and UAV-lot links.
Table - Parameters of the satellite-lot and UAV-lot links.
Ai Algorithm Design and Practical Deployment
Since 6G is expected to realize ubiquitous intelligence, AI-based research should aim at practical applications. Thus, besides the high prediction accuracy that is the main goal of current research, the required computation resource, learning efficiency, and necessary data also need to be considered. Moreover, the design of AI algorithms should consider the available computing resource and deployment. For instance, if there are only edge servers located at different network parts, federated learning may be a good choice. Some other important factors including regulation and law can significantly affect the AI algorithm design. As many IoT services are related to personal information, the data usage should consider the privacy requirement [4], [11]. Also, how to avoid possible harm from the intelligent devices will be an important research topic.

Cooperation for Diversified Service Requirements
Performance optimization should be conducted from a systematic point of view, meaning that the analysis should consist of the networking-related and non-networking-related operations. For example, the weather forecast can be utilized to analyze the energy harvesting performance, which affects the working time of some IoT devices. As the satellite-UAV-served IoT system consists of diverse environments, more environmental factors should be analyzed and utilized to improve the performance in a proactive manner, which is totally different from traditional research focusing on the communication parts. Moreover, the advantages and disadvantages of satellites, UAVs, and even terrestrial infrastructure should be paid more attention. More advanced network slicing technology should be developed to divide the networks to meet the diverse service needs. Satellites and UAVs can also cooperatively work to achieve performance improvement that cannot be realized by only satellites or UAVs.

Figure 3. - Comparison of AI-based strategy and benchmark methods in terms of task success rate and system computation rate: a) successfully finished ratio of computation tasks; b) system computation rate.
Figure 3.
Comparison of AI-based strategy and benchmark methods in terms of task success rate and system computation rate: a) successfully finished ratio of computation tasks; b) system computation rate.

Show All

Figure 4. - The share of computation tasks finished by different parts under various task generation rates.
Figure 4.
The share of computation tasks finished by different parts under various task generation rates.

Show All

Sustainable Intelligence
According to our introductions, an emerging paradigm in 6G is to provide intelligent services that have more detailed quality of service requirements. This means that more data and information need to be collected, transmitted, and analyzed, which further generates increasing communication and computation overhead. For the satellite-UAV-served IoT systems, the required intelligence means more energy cost for the IoT devices, UAVs, and satellites since all of them cannot be charged via the electric network. How to alleviate energy consumption and manage energy harvesting is critical to support sustainable intelligence.

Conclusion
In this article, we study 6G IoT services in remote areas and consider the satellite-UAV-served IoT system. We introduce the development and limitations of IoT systems in remote areas. After explaining the potential service requirements, we introduce four key 6G techniques including THz, energy harvesting, edge computing, and machine learning. Then we discuss how these technologies improve the performance of satellite-UAV-served 6G IoT. We formulate a computation offloading problem and propose an AI-based offloading strategy. The simulation results illustrate the performance improvement in terms of task success ratio and system computation rate. We also discuss some future research directions with the new characteristics and service requirements considered.