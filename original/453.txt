Cloud offloading is an indispensable solution to supporting computationally demanding applications on resource constrained mobile devices. In this paper, we introduce the concept of wireless aware joint scheduling and computation offloading (JSCO) for multi-component applications, where an optimal decision is made on which components need to be offloaded as well as the scheduling order of these components. The JSCO approach allows for more degrees of freedom in the solution by moving away from a compiler pre-determined scheduling order for the components towards a more wireless aware scheduling order. For some component dependency graph structures, the proposed algorithm can shorten execution times by parallel processing appropriate components in the mobile and cloud. We define a net utility that trades-off the energy saved by the mobile, subject to constraints on the communication delay, overall application execution time, and component precedence ordering. The linear optimization problem is solved using real data measurements obtained from running multi-component applications on an HTC smartphone and the Amazon EC2, using WiFi for cloud offloading. The performance is further analyzed using various component dependency graph topologies and sizes. Results show that the energy saved increases with longer application runtime deadline, higher wireless rates, and smaller offload data sizes.

SECTION 1Introduction
Cloud offloading has become a recognized solution for delivering computationally intensive applications (e.g., video-intensive games, computer vision-based applications [1], and real-time visual information reporting) on resource-constrained mobile devices [2], [3]. Typically, energy and time (or delay) constraints have played a strong role in determining offloading policies. Recently, we argued that the burden placed on the wireless networks supporting this offloading must also be taken into consideration [4] when developing offloading strategies. In [4], we proposed an optimal offloading policy for applications with sequential component dependency graphs and multi-radio enabled mobile devices, that minimizes the energy consumed by the mobile device such that overall execution time of the application will be below a given threshold while simultaneously determining optimal percentage of data (associated with computation offloading) to be transferred via each of the multiple wireless interfaces. In this paper, we address the problem of cloud offloading for mobile applications with arbitrary dependency graphs rather than sequential dependencies or pre-determined compiler generated schedule order. To this end, we must consider wireless-aware scheduling of the application components jointly with the offloading strategy. We optimally maximize a net utility function, which trades-off the energy saved at the resource constrained device with the time and energy costs involved in offloading while meeting the precedence constraints and execution deadline of the application in single radio enabled mobile devices. To the best of our knowledge, this is the first work that proposes joint scheduling–offloading for mobile applications. By optimizing the scheduling of the individual components along with cloud offloading decisions, taking into account the wireless parameters, allows for an overall better solution compared to optimizing only the offloading decisions using a pre-determined compiler-generated schedule order of execution for the individual components. Besides, using the general dependency graphs (without imposing a sequential ordering for processing) and an optimal joint scheduling-offloading scheme can potentially allow for parallel scheduling of components in the mobile and cloud at the same time, thus reducing time to completion for the application.

Cloud offloading can be interpreted as data flow offloading in networking applications [5] or offloading computationally intense tasks to the cloud [6] or cloudlet [7], which is a self-managing data center in the layer of network infrastructure [8]. In this paper, we refer to computation offloading to the cloud. Existing work on computation offloading to cloud resources can be classified into three types: (i) ones that offload all of the application to a cloud [9], [10]; (ii) those in which all or nothing offloading is applied where either the entire application is offloaded to the cloud or executed locally, typically depending upon which is more energy efficient for the mobile device [11]; and (iii) partial offloading strategies where some of the component tasks are offloaded while the others are executed locally [4], [12], [13], [14], [15]. In partial offloading, the application can be coarsely partitioned into components [4], [12], [16], [17] or a more fine-grained offloading can be achieved [18] by using method-level partitioning as in MAUI [13], ThinkAir [14] and CloneCloud [19].

Compared to the related work in Section 3, this paper has several contributions. This is the first work, to the best of our knowledge, that combines offloading and scheduling decisions in the presence of arbitrary component dependencies (precedence constraints of components). To enable capturing this multi-dimensional decision aspect of this problem, a mathematical formulation is best suited. Hence a key technical contribution of this paper is the mathematical formulation of the component offloading problem that arises in real mobile applications as an optimization problem using integer linear programming formulations. The resulting mathematical formulation is non-trivial. Specifically first, we model the required joint offloading–scheduling decision variables, latencies and the energy saved by cloud offloading. Then, we provide a mathematical analysis for the optimization problem for joint wireless-aware scheduling of the mobile application and cloud offloading. Note that the optimization problem is linearized in order to take benefit of linear programming (LP) for obtaining the optimal solution. Third, real data are measured from an HTC smartphone using real and random generated mobile applications, WiFi radio interface for computation offloading, and Amazon Elastic Compute Cloud (EC2) for remote execution. We identify the optimal solution under these real data measurements using IBM CPLEX optimizer [20]. Finally, we derive a comprehensive performance analysis of this work compared with upper and lower bounds for dependencies of applications, the number of application components, topology of application component dependency graphs (CDGs), application runtime, and wireless parameters such as rates, latencies, and data sizes.

The rest of this paper is organized as follows. The CDGs of mobile applications and related work are respectively expressed as two important backgrounds of the paper in Sections 2 and 3. Then, we model the Joint Scheduling and Computation Offloading (JSCO) scheme and formulate the optimization problem regarding to the constraints for scheduling, delay, runtime and completion deadlines in Section 4. In Section 5, we present experiments and simulations to evaluate the performance of the proposed optimal strategy. Finally, Section 6 presents the conclusion and future work of the paper.

SECTION 2Background: Component Dependency Graphs
All of the prior work discussed above on partial cloud offloading consider mobile applications with sequential component dependencies or component scheduling order that is predetermined by a compiler. In general, components in a real life application can have arbitrary dependency graphs and potentially, an overall better solution can be obtained by designing a joint scheduling–offloading policy for the components where the scheduling order of the components is also cognizant of the wireless network supporting the offloading.

Component dependency graphs (CDGs) of mobile applications must satisfy these general properties: (i) each component should have at least in-degree of one (except the first component, which has in-degree of zero); (ii) components should have at least out-degree of one (except the last component N, which has out-degree of zero); (iii) all of the components should have at least one direct or indirect path from component 1 so that they are dependent on the common starting point of the application (typically executed on the mobile); (iv) all of the components should have at least one direct or indirect path to component N (the last component) and (v) in the adjacency matrix (M) of the CDG, all the diagonal elements are zero, because there is no self-dependency.

Fig. 1 presents different types of CDGs for an N-component application (N=14): (i) sequential dependency graphs where all the components are sequentially dependent (Fig. 1a); (ii) parallel dependency graph where only component 1 must be executed before components 2 to N−1. In addition, these components are only required to transfer their output data to component N (Fig. 1d); (iii) random Layer-by-Layer graph (Figs. 1b, 1e); and (iv) random Fan-in/Fan-out graph (Figs. 1c, 1f) [21]. In Layer-by-Layer CDGs, a random number of nodes is generated for each of the layers and edges are added with a probability p going from a node in an earlier layer to a node in one of the successive layers. In Fan-in/Fan-out CDGs, the Fan-in/Fan-out ratio of each node is constrained to the given threshold. Since usually mobile-initiated applications must start on the mobile device and have an output display on the mobile device, the first and last components are processed in the mobile device. Note that the parallel and sequential dependency graphs show the lowest and highest dependencies between components respectively and can be used to obtain the lower and upper ranges for the cost of offloading on applications exhibiting these extremes of CDGs.

Fig. 1. - 
Examples of various CDGs for the mobile applications ($N=14$N=14).
Fig. 1.
Examples of various CDGs for the mobile applications (N=14).

Show All

SECTION 3Related Work
Time scheduling of the application components is studied in eTime [9] and [22] in which a pre-determined compiler-generated order of execution for the application components is considered and all the component tasks are offloaded for remote execution. eTime explores an energy-delay trade-off in scheduling the required data transmissions for offloading (entire computations of application) such that the queue stability of the wireless interface is satisfied and offloading is done when the wireless connectivity is sufficiently good. A scheduling policy for partially offloading the sequence of fine-grained tasks with serial CDG (as in Fig. 1a) is proposed in [15] such that the application execution time is guaranteed. While these works that use fine-grained method partitioning for partial offloading are limited in input/environmental conditions in the offline pre-processing and need to be bootstrapped for every new application, our work, which uses component scheduling, does not involve this problem. Existing component-based mobile cloud offloading strategies, such as DOA [17] and MACS [23], are not designed for parallel processing simultaneously via the mobile device and cloud because they use a pre-determined order of traversal of the application CDG. Our proposed scheme has this flexibility. Another scheduling scheme to minimize the total energy consumption in a multi-user network is studied in [24] where a centralized broker partially offloads sequential tasks to the cloud. Thus, a centralized strategy is required to perform a two-hop offloading where the broker is an intermediary between the mobile user and the cloud. However, using scheduling strategies based on arbitrary CDGs extends the number of applications to be used for partial cloud offloading. In [16], sequential scheduling of the computational tasks is considered in both single-channel and multi-channel communications. The objective is to minimize the energy consumed while simultaneously meeting the delay constraints of the application. However, wireless-aware scheduling of the application components provides higher energy and spectrum efficiencies in cloud offloading strategies.

SECTION 4Proposed Scheduling Model for Mobile Cloud Offloading
In the mobile cloud offloading model considered in this work, the mobile device has access to a cloud server for computation offloading, and the cloud server is endowed with parallel processing capabilities. We additionally make the following assumptions: (i) the multi-component mobile application that is utilized by the mobile user is also installed on the cloud server; and (ii) mobile broadband connectivity does not change during the application processing time while the wireless interface may provide different rate and delay values. Note that in the second assumption, we consider that application processing time is not large, and most of the related works have also assumed this condition [13], [14], [16], [17], [23], [24]. Following these assumptions, we show a mobile cloud offloading model example of a 14-component application in Fig. 2b. Note that this 14-component topology is the same as one of the applications we used in the performance analysis section.

Fig. 2. - 
Scheduling model for cloud offloading in a 14-component mobile application with a general CDG.
Fig. 2.
Scheduling model for cloud offloading in a 14-component mobile application with a general CDG.

Show All

4.1 Multi-Component Application Example for the Scheduling-Offloading Model
Here we used a video navigation application, which involves graphics [25], face detection [26], camera preview, and video processing [27], running on an HTC Vivid smartphone. Fig. 2a shows the dependency graph for 14 components of the application. The link connection between components i and j shows that the output data from component i is required as input by component j, and dij represents the required data size for transferring from i to j. We observe that this dependency could be either sequential (like the dependencies between components 1-2-3-5-14) or parallel (like the component dependencies between 1-11-14, 1-12-14, and 1-13-14). In Fig. 2b, an example of joint scheduling–offloading of the components based on time, place of processing, and dependency among the components is illustrated. If a component is scheduled for offloading to the cloud, the energy consumption for processing will be saved by remote execution. In addition, the time for processing the component decreases significantly by remote execution (compare the times taken to process components by the mobile device and the cloud in Fig. 2b). Moreover, some components can be processed in parallel by the cloud (components 2, 6 and components 3, 10). However, the cost of cloud offloading should also be considered in the scheduling–offloading decisions: (i) the costs of delay and energy consumed by offloading as a function of data size for transferring (e.g., component 11 has very large data for transferring so it takes a longer time for communication); and (ii) the cost of the idle state as the mobile waits to receive the required output data from the cloud (between components 4 and 7). Thus, a smart scheduling strategy for mobile offloading based on energy-time trade-off is required.

4.2 Proposed Optimal Joint Scheduling & Computation Offloading Scheme (JSCO)
In this section, we present the formulation of our problem as an integer linear program. The notations used to describe the proposed JSCO and other parameters in this paper are defined in Table 1. For each time period (t−1,t] denoted by time slot index t, we define decision variable, xljt, which indicates whether component j completes processing at time slot t on the mobile (l=0) or on the cloud (l=1). This decision variable captures the multi-objective requirement of mobile communication applications to provide “anywhere, anything, anytime” service.

The processing indicators in the mobile and cloud are respectively given by mj=∑Tt=1x0jt, cj=∑Tt=1x1jt, ∀j, where T is the number of time periods to complete processing the application. Also τcmij denotes the time (the number of time slots) to transfer data from component i to j when i≺j, and j is processed on the mobile and i is processed on the cloud. τcmij includes the product mjci where i is processed on the cloud and j is processed on the mobile. In order to make the optimization problem linear, this quadratic term of two binary decision variables is replaced by a new variable zji where zji is the component transferring indicator. zji gets 1 if the output data of component j (component j is executed in the mobile) is offloaded from the mobile device to the cloud where component i (i≺j) will be executed. Otherwise, it gets 0. This parameter must satisfy the following four constraints [28]: zji≤mj, zji≥0, zji≤ci, zji≥ci−(1−mj), ∀i,j. Thus, the quadratic term of two decision variables is converted to a new decision variable so that the optimization problem still remains linear. Similarly, τmcij denotes the time (the number of time slots) to transfer data from i to j when i is processed on the mobile device and j is processed on the cloud and includes micj which is denoted by the variable zij. Now the times for transferring from mobile to cloud and cloud to mobile are respectively given as τcmij=αijzjidijRd, τmcij=αijzijdijRu, ∀i,j, where αij is the dependency indicator, and gets 1 if component i must be processed before j and 0 otherwise. dij is the size of data required by component j from component i, and Ru (Rd) is the average uplink (downlink) rate of the wireless radio interface. Note that τcmij, τmcij will be zero if i=j, or if i does not precede j, or if i and j are both processed on the cloud, or both processed on the mobile device. In addition, the energy consumed for communication due to cloud offloading the components is modeled by
Ecom=PTx∑i=1N∑j=1Nτmcij+PRx∑i=1N∑j=1Nτcmij.(1)
View SourceRight-click on figure for MathML and additional features.

The objective function in the optimization problem over decision variables (xljt, zij, l∈{0,1}, i,j=1,…,N, t=1,…,T) for the mobile cloud offloading scheme is mathematically formulated as
max{∑j=1NPaccjqmj−Ecom}.(2)
View SourceEqn. (2) shows the maximization of the energy saved through remote execution. This energy saved is essentially the energy cost if the offloaded components had been executed locally minus the cost of communication energy.

Besides the constraints for quadratic parameter, the following constraints should be satisfied in the optimization problem with the objective function given by Eqn. (2):

Runtime deadline constraint: The multi-component application has a time deadline, which should be satisfied. This constraint is given by 0<∑Tt=1tx0Nt≤T, ∀t, where ∑Tt=1t.x0Nt denotes the completion time slot for processing the last component (N) on the mobile (l=0). This time slot should be equal or less than T.

Each component be processed only once: Each component is processed either in the mobile or cloud, which can be written as
mj+cj=1∀j.(3)
View Source

Precedence constraint: This constraint shows that component k is required to begin processing no earlier than the completion time of component j where j≺k. The constraint is expressed as
∑l=01∑s=1t+νk+τcmjk+τmcjkxlks≤∑l=01∑s=1txljs, if j≺k,t=νj,…,T−νk−τcmjk−τmcjk,(4)
View Sourcewhere νk is the time to process component k either on the mobile or cloud, and is given by νk=mkqmk+ckqck. Based on Eqn. (3), νk will include either the cloud processing time slots for component k or the mobile processing time slots for component k, but not both. Here in constraint 4, in order for k to be completed after the time t plus the time for possible data transferring from j to k (τcmjk+τmcjk), plus the time for processing component k (νk), component j must be completed by time t, ∀t.

Serial computation at the mobile device: The processed components in the mobile are required to be executed in serial. Thus, for each time interval [t−1,t) we can have at most one component for processing in the mobile, which can be written as ∑Nj=1∑min{t+νj−1,T}s=tx0js≤1, ∀t.

Completion deadline: Each component k must be completed only after the completion of each of its precedent components like j, plus the time (slots) to process component k itself, and the time slots to transfer required data to the execution site of k if j is not on that same site. This constraint is given by ∑1l=0∑Tt=1txljt+τcmjk+τmcjk+νk≤∑1l=0∑Tt=1txlkt, if j≺k, k=1,…,N. Also, decision variables should be 0−1, xljt∈{0,1}, l∈{0,1}, ∀j,t, and get zero values while the coordinated component has not been processed yet, which is written as xljt=0, l∈{0,1}, ∀j,t=1,…,νj−1.

4.3 Scheduling Overhead
Since we have a linear optimization problem, the number of constraints plays the important role in scheduling overhead because number of constraints affects memory usage more than the number of variables [29]. In this work, the number of constraints is (6+T)N2+4N+T+2, which is a function of application runtime and number of components (order of complexity is O(TN2)). Also, the number of variables is N2+2TN (order of complexity is O(TN). However, we do not experience schedule overhead in the offloading scenario because (i) the strategy will be executed in the cloud server where the RAM is high enough, and (ii) JSCO is not required for a real-time scenario while we assume fix wireless parameters.

SECTION 5Performance Analysis
In this section, we first discuss the performance of the proposed JSCO scheme in comparison with the related works using an application in [30], and also based on a real application for which we made real data measurements. This is the 14-component application whose CDG was presented in Fig. 2a. To further the understanding of our model's adaptability and scalability, we considered some randomly generated CDGs whose layered structure and Fan-in/Fan-out ratio could be controlled.

5.1 Real Data Measurements and Simulation Setup
An HTC Vivid smartphone with a 1.2 GHz dual-core processor and WiFi radio interface were used to gather real data. To test the performance of the proposed optimal scheme, a multi-component video navigation application was used where video processing, face detection, graphics, and clustering were the main features. In all, 14 components were used, four of which are related to the graphics feature, three are for the face detection feature, six are for video processing, and one is for clustering. Note that the first and last components are executed locally so that the input-output of the application is accessed by the mobile user. In addition, graphics library tools from the OpenGL mobile Android applications were used [25]; face detection was taken from [26]; and all the video processing features were obtained from [27]. The CDG of this application is illustrated in Fig. 2a. The execution times of the components in the HTC phone and the cloud, uplink and downlink rates, delay at the WiFi interface were measured. The Amazon Elastic Compute Cloud (Amazon EC2) was used as the cloud computing server. The average transmission and reception power levels of the mobile device for WiFi service were 257.83 and 123.74mW, respectively. The active and idle power levels of the phone were 644.9 and 22mW, respectively. The power consumption of the last component in the mobile device was 55mW. These power measurements were obtained using the “CurrentWidget: Battery monitor” application [31]. The average wireless service rates for WiFi, obtained using the TCPdump tool, were 0.80 Mbps for the uplink transmission and 1.76 Mbps for the downlink transmission, respectively. The local execution time for the 14 components were measured as [30 340 345 125 30 80 70 30 185 125 650 571 904 56] ms. Because processing of the components in the mobile device is performed in serial, application runtime in the local execution equals the sum of the processing times for the 14 components (3541 ms). Also note that here each time period (t−1,t], ∀t, is set to 1ms.

The obtained real data measurements were used in the linear programming proposed in Section 4.2 with the objective function as shown in Eqn. (2) subject to the expressed constraints. We used the IBM CPLEX optimizer [20] to solve the integer linear problem, which is known to be NP hard. Also, the JSCO strategy is scheduled at the cloud server.

5.2 Comparison of JSCO with State of Art
We compare our proposed optimal work (JSCO) to (1) no offload (local) execution where all the components are executed locally; (2) all offload (remote) execution where all the components are offloaded to the cloud; (3) the dynamic offloading algorithm (DOA) in [17], which uses an energy efficient partial offloading strategy; (4) HELVM algorithm from [32], which provides runtime offloading services; and (5) a heuristic algorithm that is the revised HEFT [33] for joint scheduling (RHJS) tasks on multiple cores used in [34]. In the simulations for this section, a face recognition application with 10 sequential components was utilized [30]. The wireless network parameters in [35] are used such that exactly the same parameters used for the simulation of DOA in [17] were used for all the other schemes.

In Fig. 3, we compare the total energy consumption of the proposed scheme (JSCO) with the 5 schemes. This comparison is normalized to the scheme with local execution of all the components. It is observed that JSCO consumes 54 percent, 37 percent, 16 percent, 30 percent, and 11 percent less energy in comparison to the schemes using local execution, remote execution, DOA, HELVM, and RHJS, respectively.


Fig. 3.
Total energy consumed by the mobile device for the proposed and classical schemes, normalized to the energy consumed by local execution (using the face recognition application in [30]).

Show All

Fig. 4 shows the time to run the application [30] for the six schemes. This comparison is also normalized to the scheme with local execution of all the components. We see that by using the optimal JSCO scheme, the application will be executed 25 percent, 49 percent, 32 percent, 19 percent, and 5 percent faster in comparison to the schemes using local execution, remote execution, DOA, HELVM, and RHJS, respectively. Thus, JSCO is a joint energy and time efficient scheme in comparison to the other 5 schemes.


Fig. 4.
Total execution time of the application for the proposed and classical schemes, normalized to the execution time by local execution (using the face recognition application in [30]).

Show All

5.3 Simulations for the Real Mobile Application
In this section, we analyze the performance of the proposed JSCO scheme using the real 14-component application (referred to as “applied CDG”) w.r.t the critical parameters of rate, time, and data size. We compare and contrast the performance of our strategy on the real 14-component application with arbitrary dependencies (Fig. 2) against a 14-component application with fully parallel dependencies (Fig. 1d) and a 14-component application with fully sequential dependencies (Fig. 1a). Since the parallel and sequential dependency graphs show, respectively, the lowest and highest dependencies between components, lower and upper bounds for the cost of offloading could be obtained for the applied CDG.

Rate plots: Fig. 5 shows the total energy values for several uplink and downlink rates of the WiFi interface provided for cloud offloading. Fig. 5a presents the total energy saved through remote execution (the objective function in Eqn. (2)) versus wireless rates. We see that while rates increase, more energy is saved by the mobile device with cloud offloading. This is expected, because with higher rates, data communication is no longer a bottleneck and it is more energy efficient to offload as many components as possible to the cloud. More energy is saved in the parallel dependency graph, while less energy is saved in the sequential dependency graph. We observe that in the sequential dependency graph, no energy can be saved by cloud offloading for lower ranges of rates, and the application cannot be processed with these low rates in three seconds (the time for local execution is 3541 ms). However, in the higher ranges of rates (uplink (downlink) rate= 9200 (20240 Kbps)), most of the components are offloaded to the cloud for computations in all three CDGs. Thus, the performances of these three are closer to each other when the wireless rates increase. In Fig. 5b, the total energy consumed by the mobile device (summation of active energy while the mobile device is executing components locally, communication energy, and idle energy while the mobile's processor is not executing any component) is plotted. We see that less total energy is consumed by the mobile device when WiFi rates increase. Moreover, Fig. 5c illustrates the energy consumed by communication, Ecom (given in Eqn. (1)), versus wireless rates. It is observed that the energy consumed by communication decreases with an increase in rates for the sequential and parallel dependency graphs. Although this is true for the applied CDG in higher rate ranges, more energy is consumed by offloading while rates increase in the lower ranges. The reason is that more computations are offloaded when rates increase so more energy is required for offloading, while in the higher ranges of rates, the time to offload decreases thereby decreasing the communication energy. Note that the application with sequential dependency cannot be executed until rates reach 1440/3168 Kbps. In the lower rate ranges, wireless delay is high, and offloading is not preferred. On the other hand, local execution takes 3541 ms when the application deadline, T, is set to 3000 ms in the simulations for this figure. Therefore, the scheme using sequential dependency graph is not plotted at lower rates because the application cannot be executed in T=3000 ms.

Fig. 5. - 
Total energy for the 14-Component application versus uplink and downlink rates in WiFi while $T$T=3s, $P_{\mathrm {Tx}}$P Tx =257.83mW, $P_{\mathrm {Rx}}$P Rx =123.74mW.
Fig. 5.
Total energy for the 14-Component application versus uplink and downlink rates in WiFi while T=3s, PTx=257.83mW, PRx=123.74mW.

Show All

Figs. 6 and 7 depict the offloaded data size and the time span for communication versus uplink and downlink rates for the applied CDG. It is observed in Fig. 6 that while rates increase, more data is transferred for cloud offloading. More components for offloading leads to the consumption of more energy and time for offloading, as shown in Figs. 5 and 7c, respectively. For rates higher than 1600 Kbps uplink and 3520 Kbps downlink in Fig. 6, we observe that the data size for offloading does not change much; however, the time for offloading decreases. This results in a corresponding decrease in the energy consumed for communication.


Fig. 6.
Offloaded data size of the application components versus rates of the WiFi link while T=3s, PTx=257.83mW, PRx=123.74mW.

Show All


Fig. 7.
Time consumed for offloading versus rates of the WiFi link while T=3s, PTx=257.83mW, PRx=123.74mW.

Show All

Time plots: Figs. 8a, 8b, and 8c respectively plot the total energy saved, total energy consumption, and the energy consumed by communication versus execution time of the application for the three different CDGs considered–sequential, applied and parallel. When more time is allotted for the execution of the application, cloud offloading is preferred and leads to a decrease in energy expenditure by the mobile device.


Fig. 8.
Total energy versus execution time (T) while Ru=0.8Mbps and Rd=1.76 Mbps.

Show All

Figs. 5 and 8 show that using the JSCO scheme (the scenario where the applied CDG is used) works better than using an optimal offloading scheme that uses a compiler pre-determined sequential traversal of an arbitrary CDG (the scenario where the sequential dependency is used). Examples of sequential traversals of arbitrary CDGs include [13], [36]. Specifically, we see from Fig. 8 that the processing of an application with sequential traversal CDG can be completed in no less than 3300 ms, while the application with applied CDG can be processed in 2400 ms and the application with parallel CDG can be processed in 2000 ms (rates are set to 800/1760 Kbps). In addition, the application with sequential dependency cannot be executed until rates reach 1440/3168 Kbps, whereas the applied CDG is processed at much lower rates, 640/1408 Kbps, while T is set to 3000 ms (Fig. 5).

We consider another metric, the number of transitions, where a transition is a data transfer between the mobile device and the cloud. In Fig. 9, the number of transitions between the mobile device and the cloud is plotted against the execution time for the applied CDG. We see that for the simulations where T≥2900 ms, the number of transitions between the mobile and cloud decreases from six to four. Moreover, Fig. 10 illustrates that the size of offloaded data decreases while the application execution time increases. These two figures show that computation offloading decreases while the execution time increases. Therefore, the communication energy decreases while the execution time increases, as shown in Fig. 8c for the applied CDG.

Fig. 9. - 
Number of transitions between the mobile and cloud for offloading in correspondence with execution time ($T$T) while $R_{\mathrm {u}}$Ru=0.8 Mbps and $R_{\mathrm {d}}$Rd=1.76 Mbps.
Fig. 9.
Number of transitions between the mobile and cloud for offloading in correspondence with execution time (T) while Ru=0.8 Mbps and Rd=1.76 Mbps.

Show All


Fig. 10.
Allocated data size for cloud offloading in correspondence with execution time (T) while Ru=0.8 Mbps and Rd=1.76 Mbps.

Show All

The data plot: We next look at the impact on energy consumption and savings when the amount of data to be transferred increases. Here the required data transfer for face detection components is increased from 21.4 KB to 2.2 MB to consider the performance of total energy as a function of the data size required for transition. In Fig. 11, we see that, as expected, while the data size for transferring increases, more energy is consumed for communication, less energy is saved, and more energy is consumed by the mobile device.

Fig. 11. - 
Total energy versus required data size for transition of components while $T$T=3 s, $R_{\mathrm {u}}$Ru=0.8 Mbps and $R_{\mathrm {d}}$Rd=1.76 Mbps using the applied CDG.
Fig. 11.
Total energy versus required data size for transition of components while T=3 s, Ru=0.8 Mbps and Rd=1.76 Mbps using the applied CDG.

Show All

5.4 Simulations for Variety of Component Dependencies
So far, the system performance was analyzed based on the fixed CDG from the 14-component video navigation application shown in Fig. 2, as well as the two extreme cases of fully sequential CDG and fully parallel CDG. In this section, we consider the performance of the proposed system based on two different categories of random CDGs: (i) Layer-by-Layer, and (ii) Fan-in/Fan-out, as explained in Section 2. Since we use random CDGs in this section, the simulations for each data point are run over three CDGs and the average of these three values is plotted. Each CDG that we generate is constrained to have only 14 components for comparison purposes.

Figs. 12 and 13 show the performance of the proposed JSCO scheme for randomly generated Layer-by-Layer CDGs. In Fig. 12, the average total energy saved through remote execution, the average total energy consumed by the mobile and the average total energy for communication are plotted against the size of data transferred. These bar graphs are compared as a function of the probability of edge connections (p). When this probability increases, more components are dependent on each other, and the density of the CDG increases. Therefore, the energy consumed by cloud offloading increases (Fig. 12c), and the energy saved through remote execution decreases (Fig. 12a). Moreover, it can be observed that when data size for transferring the components increases, the total energy consumed by the mobile device and the energy consumed for communication increase (Figs. 12b, 12c), and the energy saved through remote execution decreases (Fig. 12a). Also note that for high values of p and size of data transfer, the energy costs of offloading are so high that the energy saved through remote execution gets closer to zero (as shown in Fig. 12a).

Fig. 12. - 
Average total energy versus required data size for transferring each component in the apps with Layer-by-Layer CDG ($s=5$s=5) and 14 components while $T$T=3 s, $P_{\mathrm {Tx}}$P Tx =257.83 mW, $P_{\mathrm {Rx}}$P Rx =123.74 mW.
Fig. 12.
Average total energy versus required data size for transferring each component in the apps with Layer-by-Layer CDG (s=5) and 14 components while T=3 s, PTx=257.83 mW, PRx=123.74 mW.

Show All

Fig. 13. - 
Average total energy versus uplink and downlink rates in WiFi for the apps with Layer-by-Layer CDG ($s=5$s=5) and 14 components while $T$T=3s, $P_{\mathrm {Tx}}$P Tx =257.83 mW, $P_{\mathrm {Rx}}$P Rx =123.74 mW.
Fig. 13.
Average total energy versus uplink and downlink rates in WiFi for the apps with Layer-by-Layer CDG (s=5) and 14 components while T=3s, PTx=257.83 mW, PRx=123.74 mW.

Show All

In Fig. 13, the average total energy saved through remote execution, the average total energy consumed by the mobile, and the average total energy for communication are plotted against uplink and downlink rates. These bar graphs are also compared as a function of the probability of edge connections. We can observe that while the wireless rates increase, the energy consumed by offloading decreases (Fig. 13c), the energy saved through cloud offloading increases (Fig. 13a), and the total energy consumption decreases (Fig. 13b). Moreover, we see that while the probability and rates increase, the energy saved through remote execution decreases.

Figs. 14 and 15 show the performance of the proposed JSCO scheme for randomly generated Fan-in/Fan-out CDGs. In Fig. 14, energy saved, energy consumed by the mobile, and energy consumed for communication are respectively plotted versus the average data size for each transfer. Our results indicate that the performance of the JSCO scheme is independent of the Fan-in/Fan-out ratio of these graphs but dependent on the total Fan-in plus Fan-out degrees. When the in+out degree increases, the dependency and offloading costs increase such that the energy saved through cloud offloading decreases and the energy consumed by the mobile device increases (Figs. 14a, 14b). Also when the data size for transferring increases, the energy consumed by the mobile increases (Fig. 14c). Fig. 15 presents the energy as a function of the uplink/downlink rates. While rates increase and the in+out degree decreases, the energy consumed for communication decreases (Fig. 15c). Therefore, the energy saved through remote execution increases (Fig. 15a), and the energy consumed by the mobile decreases (Fig. 15c).

Fig. 14. - 
Average total energy versus required data size for transferring each component in the apps with Fan-in/Fan-out CDGs and 14 components while $T$T=3s, $P_{\mathrm {Tx}}$P Tx =257.83 mW, $P_{\mathrm {Rx}}$P Rx =123.74 mW.
Fig. 14.
Average total energy versus required data size for transferring each component in the apps with Fan-in/Fan-out CDGs and 14 components while T=3s, PTx=257.83 mW, PRx=123.74 mW.

Show All

Fig. 15. - 
Average total energy versus uplink and downlink rates in WiFi for the apps with Fan-in/Fan-out CDGs and 14 components while $T$T=3s, $P_{\mathrm {Tx}}$P Tx =257.83 mW, $P_{\mathrm {Rx}}$P Rx =123.74 mW.
Fig. 15.
Average total energy versus uplink and downlink rates in WiFi for the apps with Fan-in/Fan-out CDGs and 14 components while T=3s, PTx=257.83 mW, PRx=123.74 mW.

Show All

5.5 Scalability of the JSCO Scheme
In this section, we discuss the scalability of our JSCO scheme. Specifically, we want to address the largest application that the JSCO scheme can handle in terms of the number of components and total execution time. In our discussions so far, we have used only a 14-component application (either real or randomly generated). In order to maintain the same probability distribution of our measurements when scaling up the application, we calculate the histogram of the current real data measurements (qmk, qck, Pac ∀k) from the 14-component video navigation application. Using the obtained distribution, we generate the new data for applications with a greater number of components (25, 45, 65, 85, and 105 components). Increasing the number of components requires a corresponding increase in the runtime deadline (T); for example, for a 25-component application T=6500 ms; for N=45, T=13500 ms; for N=65, T=14250 ms; for N=85, T=17100 ms; and for N=105, T=21000 ms.

Table 2 shows the program runtimes using the proposed scheme for the two types of randomly generated CDGs– Layer-by-Layer and Fan-in/Fan-out. In this table, we consider the total execution time in accordance with the number of components (N). We see that while the number of components and total execution time increase, the runtime of the proposed scheme increases. The JSCO scheme is capable of handling over 100 components with a mobile-only execution time of 28 seconds. Our simulations were done on a single server machine with an Intel Xeon(R) E7340 processor @ 2.5 GHz CPU and 60 GB of RAM. Although the runtime to solve the associated integer linear program increases with the number of components to over 2 hours, this time can be reduced through parallel implementation using more powerful processors.

TABLE 1 Parameter Definitions
Table 1- 
Parameter Definitions
TABLE 2 Program Runtimes of the CPLEX Optimizer for the Proposed LP Using Layer-by-Layer and Fan-in/Fan-out CDGs
Table 2- 
Program Runtimes of the CPLEX Optimizer for the Proposed LP Using Layer-by-Layer and Fan-in/Fan-out CDGs
Three scenarios are considered in this part: (A) the scenario where the average data size to transfer is fixed at 1220 KB and the uplink/downlink rate is fixed at 1.28/2.816 Mbps; (B) the scenario where the average data size to transfer is fixed at 1220 KB (the same as A) and the uplink/downlink rate is fixed at 4.96/10.912 Mbps (more than A); and (C) the scenario where the average data size to transfer is fixed at 2196 KB (more than A) and the uplink/downlink rate is fixed at 1.28/2.816 Mbps (the same as A). In Fig. 16, the Layer-by-Layer CDG with a larger number of components is considered. In this figure, the energy saved, total energy consumed, and energy consumed for communication are respectively shown as a function of the number of application components for the three scenarios, A, B, C. Note that here, p=0.2 and s=5 (which is the number of layers). When the number of application components increases, the edges between components increase and therefore the costs of offloading increase. Thus, all the energy values increase. We can see that while the rates increase in Scenario B in comparison to Scenario A, the energy saved through remote execution increases, energy consumed for offloading decreases, and the total energy consumed by the mobile device decreases. On the other hand, while the data size increases in Scenario C in comparison to Scenario A, the energy saved decreases, communication energy increases, and the total energy consumed by the mobile device also increases, which is all as expected.

Fig. 16. - 
Total energy versus the number of application components with Layer-by-Layer CDG ($p$p=0.2 and $s=5$s=5), presented in Scenarios A, B, and C.
Fig. 16.
Total energy versus the number of application components with Layer-by-Layer CDG (p=0.2 and s=5), presented in Scenarios A, B, and C.

Show All

Fig. 17 plots the energy values in accordance with the number of application components for the applications with Fan-in/Fan-out CDGs in the three scenarios, A, B, C. Here maximum in-degree is set to 3 and the maximum out-degree is set to 2 for the corresponding CDGs. Similar observations as in Fig. 16 are made here as well.

Fig. 17. - 
Total energy versus the number of application components with Fan-in/Fan-out CDGs (maximum in-degree is 3 and maximum out-degree is 2), presented in Scenarios A, B, and C.
Fig. 17.
Total energy versus the number of application components with Fan-in/Fan-out CDGs (maximum in-degree is 3 and maximum out-degree is 2), presented in Scenarios A, B, and C.

Show All

SECTION 6Conclusion and Future Work
In this paper, we proposed the first energy-efficient JSCO scheme for mobile devices using applications with arbitrary component dependency graphs. Existing work considers either sequential ordering of the components or a pre-determined ordering, leading to less adaptability with wireless conditions. This was cast as an optimization problem, and the results using real data measurements show that the proposed JSCO reduces consumption by 54 percent compared to local execution and up to 37 percent compared to other existing schemes. Future work includes devising polynomial-time heuristics to reduce the runtime for the optimization problem.