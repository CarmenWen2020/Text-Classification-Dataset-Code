In this paper, we focus on request migration strategies among multi-servers for load balancing. Different from the general load balancing problem, we consider it under a distributed, non-cooperative, and competitive environment. Due to the mentioned characteristics, we view our problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple servers, in which each server is informed with incomplete information of other servers. For each server, we define its expected response time as a disutility function and try to minimize its value. We also take into account server availability, which impacts the processing capacity of a server and thus its disutility. We solve the problem by employing variational inequality (VI) theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm (IPA) to compute a Nash equilibrium solution. The convergence of the IPA algorithm is also analyzed and we find that it converges to a Nash equilibrium. Finally, we conduct some numerical calculations to verify our theoretical analyses. The experimental results show that our proposed IPA algorithm converges to a Nash equilibrium very quickly and significantly decreases the disutilities of all servers by configuring a proper request migration strategy.

SECTION 1Introduction
1.1 Motivation
Cloud computing is the delivery of resources and computing as a service rather than a product over the Internet, such that accesses to shared hardware, software, databases, information, and all resources are provided to consumers on-demand [1], [2]. Usually, the provided services mainly refer to Infrastructure as a Service (IaaS), Platform as a Service (PaaS), and Software as a Service (SaaS), which can all be accessed by the general public on demand [3]. However, due to the more and more users, the portal server of a cloud center can be heavily loaded. Furthermore, many lightweight jobs can bring a lot of interferences to other computation-intensive jobs and thus significantly degrade their performances. To improve the overall service quality (e.g., response time) of a cloud center, recently, some works (such as [4]) propose to deploy certain edge servers in front of a cloud center. As shown in Fig. 1, user applications (demands) first arrive at edge servers, which are interconnected through a network. If an application is lightweight, then it is immediately processed by one of the edge servers. Otherwise, it is uploaded to the cloud center for processing. Obviously, this can mitigate the interferences brought by lightweight jobs and significantly improve the overall performance of a cloud center.


Fig. 1.
Motivation illustration.

Show All

In this work, we focus on load balancing for edge servers layer. Due to the differences in the computing capacities and uneven request arrival patterns, the workload on different servers can vary greatly [5]. It can often be seen that many servers are underutilized while the others are overloaded. Or on the other hand, the cloud providers do not take into account server availability, which refers to the percentage of time that it is running in a given time interval [6]. All of these situations can lead to high response time and low service availability, which are two import quality measures for a cloud provider to appeal more users to use cloud service [7]. Therefore, it is important for a cloud provider to design an appropriate load balancing scheme involving server availability. In this work, we try to configure a proper request migration strategy for the edge servers layer. Specifically, we try to simultaneously optimize the response times of all servers involved in the connected multi-server system. In addition, we take server availability into account.

Load balancing concerns the distribution of requests among diverse servers in a given environment such that no server is overloaded or underutilized [8], [9]. It is one of the most important factors that should be seriously considered by both a cloud provider and its multiple users. For a cloud provider, an appropriate load balancing strategy helps in making use of the available resources most favourably and thus ensures that no server is overloaded or underutilized. It can improve the aggregated performance and increase the revenue of the cloud provider. Specifically, an appropriate load balancing scheme improves the request service rate of the cloud provider. Therefore, the cloud provider can charge more from its users for more accomplished work and thus increase its revenue. Cloud-based applications depend even more heavily on load balancing and optimization than traditional enterprise applications [1]. On the other hand, it improves service quality (e.g., task response time) and appeals more users to use cloud service. For multiple cloud users, appropriate load balancing will be seriously considered when they select a cloud provider. The same task, such as running an online voice recognition algorithm, is able to generate more utility for a cloud user if it can be completed within a shorter period of time [10].

Server availability refers to the probability that a server is found to be in the running state at a given point in time. It can also be defined as the percentage of time that it is running in a given time interval [6]. Server availability is an important factor that should be taken into account by a cloud provider for designing appropriate load balancing scheme. The reason behind lies in that server availability is also related to the profit of a cloud provider and the appeals to more cloud users in the market. Specifically, if availability level of servers is low, it impacts the service availability of servers and thus decreases the total processing rate of the cloud provider. Obviously, the cloud provider charges less from cloud users due to its less accomplished work during certain time interval. On the other hand, low server availability also impacts the service quality (e.g., task response time) of the cloud provider, which is seriously considered by most cloud users. When more requests are allocated to the servers with low availability, even though their ideal processing capacities are high, the overall response time can be long and thus dissatisfies its current users even the potential users in the market. Therefore, it is important for a cloud provider to design appropriate load balancing scheme which also involves server availability.

1.2 Related Work
Load balancing is one of the most important factors that should be taken into account in scheduling, and in literature, many works have been done on it for various considerations [1], [5], [11], [12], [13], [14], [15].

Specifically, in [1], Cao et al. studied the tradeoff between an aggregated performance (system response time) and energy consumption in cloud centers. Specifically, the tried to optimize system response time under energy constraint and energy consumption under response time constraint, respectively. In [11], KASSAB et al. addressed load balancing (makespan) for scheduling independent tasks under power constraints. They proposed several heuristics for the case of multi-core architecture and assessed their performances on synthetic workloads and power envelopes. In [12], Zhao et al. proposed a Bayes theorem based heuristic, and tried to optimize the standard deviation to achieve load balancing. However, as shown in Table 1, all these works refer to one single objective (makespan, overall system response time, or standard deviation of response time), i.e., they focus on load balancing metric.

TABLE 1 Load Balancing Comparison Between IPA and the State-of-the-Art Schemes

TABLE 2 Notations

TABLE 3 System Parameters

There are also some works referring multi-objectives which incorporate load balancing, i.e., load balancing is one of the multiple objectives. Siavoshani et al. [13] combined load balancing (average waiting time) with communication cost and tried to configure a scheduling scheme by optimizing a weighted sum of them. In [15], Shen studied load balancing by migrating virtual machines (VMs), and she aimed to optimize the number of overall VM migrations. She also incorporated communication cost, bandwidth, and proposed a heuristic to try to optimize all of them. In [14], Thant et al. proposed a heuristic for the purposes of minimizing the overall makespan and machine instance deployment cost during workload execution. For this kind of scheduling, the main techniques are usually heuristic and weighted sum method (see Table 1). However, as shown in Table 1, all the previously mentioned works are from the central perspective. Different from their considerations, we address load balancing under distributed environment.

When considering load balancing under distributed environment, the problem becomes more complex. The reason behind lies in that the relationships among servers are non-cooperative and competitive. Few works can be found for this in the literature. In [5], Penmatsa and Chronopoulos proposed a non-cooperative game based NCOOPC algorithm, in which they tried to minimize the average response time of each cloud user. In this work, we also use non-cooperative game to formulate our problem. However, due to the different models and problems. The general game methods (such as NCOOPC in [5]) can no longer be applied in our situation. In this work, we leverage variational inequality (VI) theory to solve our problem.

Game theory is a field of applied mathematics that describes and analyzes scenarios with interactive decisions [16], [17]. It is a formal study of conflicts and cooperation among multiple competitive players [18], and a powerful tool for design and control of multiagent systems [19]. There has been a growing interest in adopting cooperative and non-cooperative game approaches to modeling many problems [20], [21], [22]. In [20], the authors presented a game-theoretic approach for the provisioning and operation of the infrastructure under uniform cost models. Xu and Yu [21] proposed a game theoretic resource allocation algorithm which considers the fairness among cloud users and resource utilization. However, to obtain game solutions, there are not standard methods, and we must address game problems on a case by case basis. In this work, we try to leverage variational inequality theory, which is a framework suitable for investigating and solving various equilibrium models and optimization problems in nonlinear analysis [16], [23]. We try to obtain a Nash equilibrium for our non-cooperative and competitive load balancing. For more works on game theory, the reader is referred to [24], [25], [26], [27], [28].

Server availability is another important metric in scheduling. It refers to the percentage of time that it is running in a given time interval [6]. Obviously, it impacts the actual processing rates of servers and thus the aggregated performance in cloud.

During the past decades, the vast majority of researches in load balancing assume that all servers are continuously available for processing throughout horizon [29]. This assumption may not be true in all cases, since a server may become unavailable due to breakdown, preventive maintenance, tool change during a certain period [30], [31], [32]. Some works have been done to investigate load balancing schemes with availability constraints [29], [33]. In [29], Qin and Xie proposed an algorithm SSAC, in which they tried to maximize system availability while minimizing average response time at the same time. In [33], Liao and Sheen studied a polynomial time binary search algorithm to solve the parallel server scheduling problem with availability constraints. However, rare of above listed researches have considered the impacts of workload on server availability. Nevertheless, according to surveys in [6], [34], [35], a server is more likely to fail if it is heavily loaded.

Therefore, we also involve load-dependent server availability in our non-cooperative and competitive load balancing scheme.

1.3 Our Contributions
In this paper, we focus on request migration strategies on multi-servers for load balance. Different from the general load balancing problem, we consider it under a distributed, non-cooperative, and competitive environment. The goal is to minimize the average response time for each server as much as possible. The main contributions and differences of this paper are listed as follows.

We consider load balancing under a distributed and non-cooperative environment. Furthermore, we try to find a request migration strategy which simultaneously optimizes the expected response times of all servers rather than a single objective (such as makespan).

We consider the problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple servers. Specifically, each server is informed with incomplete information of other servers. We define its average response time as the disutility function and try to minimize its value.

We also take into account server availability, which impacts the processing capacity of a server and thus its disutility function value.

We solve the problem by employing variational inequality theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm (IPA) to compute a Nash equilibrium solution.

The convergence of the IPA algorithm is also analyzed and we find that it converges to a Nash equilibrium.

We conduct some numerical calculations to verify our theoretical analysis. The experimental results show that our proposed IPA algorithm converges to a Nash equilibrium very quickly and significantly decreases the disutilities of all servers by configuring a proper request migration strategy.

1.4 Organization
The rest of the paper is organized as follows. Section 2 describes the system models of the system and presents the problem to be solved. Section 3 formulates the problem into a non-cooperative game and solves the problem by employing variational inequality theory. Some analyses are also presented in this section. Section 4 is developed to verify our theoretical analyses and show the effectiveness of our proposed algorithm. We conclude the paper with future work in Section 5.

SECTION 2System Model and Problem Formulation
To begin with, we present our system model in the context of a cloud provider with m heterogeneous servers, which are connected by a communication network. We denote the set of servers as M={1,…,m}. The processing capacity of server i (i∈M) is represented by its service rate μi, which is also impacted by the workload on the server. The external request arrival rate at server i (i∈M) is assumed to follow a Poisson process. Similar to [5], [36], we also assume that each of the servers and the communication network are modeled as M/M/1 queuing systems.

We summarize all the notations used in this section in the notation Table 2.

2.1 Request Migration Model
We consider the request migration model motivated by [5], [36], where the request migration profile at server i (i∈M) is formulated as the following probability vector
pi=(pi1,…,pim)T,(1)
View Sourcewhere pij (j∈M) is the probability that a request at server i is migrated to server j and it is subject to the constraint ∑mj=1pij=1. Then, the request migration strategy set of server i (i∈M) can be expressed as
Pi={pi∣∣∣∣∑j=1mpij=1andpij≥0,∀j∈M}.(2)
View Source

At each server, there are randomly arrived external requests. Denote ϕi as the external request arrival rate at server i (i∈M), and λij as the request flow rate from server i to server j (i.e., the expected number of requests sent from server i to server j per unit of time). Then
λij=pijϕi,(3)
View Sourceand the request migration profile can also be expressed as
λi=(λi1,…,λim)T.(4)
View SourceCorrespondingly, the request migration strategy set can be written as
Qi={λi∣∣∣∣∑j=1mλij=ϕiandλij≥0,∀j∈M},(5)
View SourceRight-click on figure for MathML and additional features.and the joint individual strategy set of all servers is given as Q=Q1×⋯×Qm.

Denote μj as the processing rate of server j (j∈M). Then, the aggregated requests at each server cannot exceed its processing capacity, i.e., βj=∑mi=1λij<μj, where βj is the workload of server j (j∈M). Then, when given the others′ request migration strategies λ−i=(λj)mj=1,j≠i, the request migration strategy λi of server i (i∈M) also satisfies ∑mi=1λij<μj.

2.2 Server Availability Model
Server availability refers to the probability that a server is found to be in the running state at a given point in time [6]. It can also be defined as the percentage of time that it is running in a given time interval. A relationship between the average load intensity and the failure rate does exist [6], [35]. If the workload intensity increases, the more failures will be expected.

To take server availability into account for appropriate load balance, we model the server availability in our work motivated by [6], where the processing capacity (i.e., the available service time) of a server linearly decreases with the increase of its workload. Specifically, the expected service rate of server i (i∈M) is given as follows:
μi=μ¯i−αiβi,(6)
View SourceRight-click on figure for MathML and additional features.where μ¯i is the maximum processing rate of server i, αi (αi<1) is the corresponding availability deteriorating factor, and βi is its workload (i.e., the aggregated requests at server i), which satisfies βi<β¯i with β¯i=μ¯i1+αi. In this work, we assume that the total external request arrival rate is less than the total expected processing rate of all servers, i.e., ∑mi=1ϕi<∑mi=1β¯i.

2.3 Cloud Service Model
There are m heterogeneous servers, which are connected by a communication network. Each of the servers is modeled as an M/M/1 queuing system, serving the requests aggregated at this server.

A request at server i (i∈M) may be either processed at server i or transferred to another server j (j∈M) through the communication network for remote processing. The response time of a request in above system consists of queuing delay and processing delay at the service server, and also some possible communication delay incurred due to request transfer. Denote D~i(βi) as the delay incurred at the server i (i∈M), then the probability that D~i(βi) is greater than T (T≥0) is equal to e−(μi−βi)T, i.e.,
Pr[D~i(βi)>T]=e−(μi−βi)T,T≥0,(7)
View Sourceand the expected delay is expressed as
Di(βi)=1μi−βi,(8)
View Sourcewhere βi is the aggregated requests at server i, i.e., βi=∑mj=1λji, and μi is the service rate of server i as in (6).

As mentioned earlier, the communication network is also modeled as an M/M/1 queuing system [5], [36], in which the expected communication delay from server i to server j is independent of the source-destination pair (i, j) but may depend on the total traffic through the network denoted by γ, where γ=∑mi=1∑mj=1,j≠iλij. Denote C~(γ) as the communication delay for one request and C(γ) as the expected value, respectively. Then, with referring to [5], [36], we obtain
Pr[C~(γ)>T]=e−(1t−γ)T, T≥0,(9)
View Sourceand
C(γ)=t1−tγ,(10)
View Sourcewhere t (t<1γ) is the mean communication time for sending or receiving a request.

Denote R~ij(λ) as the delay of a request incurred at server i and been processed at server j (i,j∈M). Then
R~ij(λ)={D~j(βj)+C~(γ),D~j(βj),if j ne i;if j=i,(11)
View Sourceand
Pr[D~j+C~>T]=Pr[D~j>T]+∫T0∫∞T−D~jαje−αjD~jαC~e−αC~C~dD~jdC~=αjαj−αC~e−αC~T−αC~αj−αC~e−αjT,(12)
View SourceRight-click on figure for MathML and additional features.where αj=μj−βj and αC~=1t−γ. We can further obtain its probability density function as
F(T)=∂∂TPr[D~j+C~≤T]=αjαC~αj−αC~(e−αC~T−e−αjT),(13)
View SourceRight-click on figure for MathML and additional features.and the expected value of R~ij(λ) as
Rij(λ)={Dj(βj)+C(γ),Dj(βj),if j ne i;if j=i.(14)
View SourceRight-click on figure for MathML and additional features.

2.4 Architecture Model
In this section, we model the architecture of our proposed framework for load balance in cloud with load dependent server availability. Each of the servers can make appropriate request migration decision through the information exchange model connected by a virtual communication player. As shown in Fig. 2, each server i (i∈M) is equipped with a maximum processing capacity (μ¯i) with corresponding availability deteriorating rate (αi), a disutility function (Ui), and the request migration strategy (λi). Let λΣ be the aggregated request vector on all servers, then we have λΣ=∑i=1mλi. Denote μ¯=(μ¯i)i∈M as the maximum processing capacity vector of all servers, α=(αi)i∈M as the corresponding deteriorating rates, and U=(Ui)i∈M as the disutility functions of all servers. The cloud provider consists of m heterogeneous servers, which are connected by a communication network, and a virtual communication player, that is, the player can be a daemon running on a host rather than a real player. It communicates some information (e.g., current aggregated request vector on all servers λΣ, and the communication requests through the network γ) with multiple servers through the information exchange module. When multiple servers try to make request migration decisions, they first get information from the communication player by the information exchange module, then configure appropriate request migration strategies (λ) such that their own disutilities (U) are minimized. After this, they send the updated strategies to the communication player. The procedure is terminated when the request migration strategies of all servers are kept fixed.


Fig. 2.
Architecture model.

Show All

2.5 Problem Formulation
Denote R~i as the response time of a request at server i (i∈M), i.e., the time interval of a request from its arrival at server i until its service completion. Then, R~i=R~ij, if the request is allocated to server j∈M.

In this work, we try to minimize the response time (R~i) of each server for load balance. Specifically, given a cloud provider with m heterogeneous servers, denoted by M={1,…,m}, which are connected by a communication network, and the external request arrival rate ϕi at server i (i \in \mathcal{M}), and the maximum service rate \bar{\mu }_i with availability deteriorating factor \alpha _i (i \in \mathcal{M}), we try to find a migration strategy profile for each of the servers such that its response time is minimized.

Notice that, a request at server i (i \in \mathcal{M}) is randomly migrated to server j (j \in \mathcal{M}) according to a request migration profile \boldsymbol {p}_i. Hence, we configure its expectation \begin{equation*} {R_i}\left(\boldsymbol {\lambda } \right) = \sum \limits _{j = 1}^m {{p_{ij}}{{\tilde{R}}_{ij}}\left(\boldsymbol {\lambda } \right)}, \tag{15}\end{equation*}
View Sourceand try to minimize its value. We may further notice that the value of {{\tilde{R}}_{ij}} is also random and there is not an equation form to represent it. However, we depict its density function and probability function, and find that \tilde{R}_{ij} does not deviate its average value (R_{ij}) enough (see Fig. 3). Hence, we use R_{ij} to replace \tilde{R}_{ij} and obtain \begin{align*} {R_i}\left(\boldsymbol {\lambda } \right) & = \sum \limits _{j = 1}^m {{p_{ij}}{{R}_{ij}}\left(\boldsymbol {\lambda } \right)}\\ & = {\sum \limits _{j = 1}^m {{p_{ij}}{D_j}\left({{\beta _j}} \right)} + \sum \limits _{j = 1,j \ne i}^m {{p_{ij}}C\left(\gamma \right)} }\\ & = \frac{1}{{{\phi _i}}}\left({\sum \limits _{j = 1}^m {\frac{{{\lambda _{ij}}}}{{{\mu _j} - {\beta _j}}}} + \sum \limits _{j = 1,j \ne i}^m {\frac{{{\lambda _{ij}}t}}{{1 - t\gamma }}} } \right). \tag{16}\end{align*}
View Source


Fig. 3.
Illustration for response time.

Show All

Our goal is to find a request migration strategy such that the expected response times of all servers can be optimized, i.e., we try to find a solution to the following non-linear optimization problem ({\mathrm {OPT}}_i): \forall i \in \mathcal{M} \begin{align*} \hbox{minimize} \quad & {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right), \;{\boldsymbol {\lambda } _i} \in {\mathcal{Q}_i},\\ \hbox{s.t.} \quad & {\lambda _{ij}} + \Lambda _{ - i}^j < {\bar{\beta }_j}, \;\forall j \in \mathcal{M}, \tag{17}\end{align*}
View Sourcewhere \boldsymbol {\lambda }_{-i} = (\boldsymbol {\lambda }_j)_{j=1, j \ne i}^m denotes the request migration strategy of all other servers except that of server i, {\bar{\beta }_j} = \frac{{{{\bar{\mu }}_j}}}{{1 + {\alpha _j}}}, and \Lambda _{ - i}^j = \sum \nolimits _{l = 1,l \ne i}^m {{\lambda _{lj}}} for all j \in \mathcal{M}.

Remark 2.1.
In finding solution to ({\mathrm {OPT}}_i), the request migration strategies of other servers are kept fixed. So the variable in ({\mathrm {OPT}}_i) is the request migration strategy of server i, i.e., \boldsymbol {\lambda }_i.

SECTION 3Game Formulation and Analyses
In this section, we formulate the request migration problem among multiple servers as a non-cooperative game. By employing variational inequality theory, we analyze the existence of Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm to compute a Nash equilibrium solution. We also analyze the convergence of the proposed algorithm.

3.1 Game Formulation
Game theory studies the problems in which players try to maximize their utilities or minimize their disutilities. As described in [5], a non-cooperative game consists of a set of players, a set of disutility functions, and a set of strategies. In this paper, each server is regarded as a player, i.e., the set of players is the m servers. The disutility function of each player i (i \in \mathcal{M}) is its average response time, i.e., R_i. The individual strategy set of player i is the request migration set of server i, i.e., \mathcal{Q}_i. Then, the joint individual strategy set of all players is given as \mathcal{Q} = {\mathcal{Q}_1} \times \cdots \times {\mathcal{Q}_m}.

In our work, we ignore the constraint in (17), because there exists one optimal solution to the optimization problem (17) without violating the constraint in (17), when given the feasible strategies of others {\boldsymbol {\lambda } _{ - i}} = \left({{\boldsymbol {\lambda } _j}} \right)_{j = 1,j \ne i}^m. The details are discussed in the following theorem.

Theorem 3.1.
Given two servers j, k \in \mathcal{M} such that their remain processing capacities {\hat{\mu }_j < \hat{\mu }_k} with {\hat{\mu }_l} = {\bar{\mu }_l} \;- \left(1 + \alpha _l \right)\Lambda _{ - i}^l (l = j, k), there exists an arrival rate \phi _i^{\ast } > 0 such that it is optimal to migrate all requests to server k for all requests \phi _i < \phi _i^\ast. Otherwise, it is optimal to migrate requests to both servers.

Proof.
To improve the overall readability of this manuscript, the complete proof of this theorem is given in the supplementary material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org.ezproxy.auckland.ac.nz/10.1109/TCC.2018.2790404.

Theorem 3.2.
Reorder the servers in \mathcal{M} such that they are numbered in non-increasing order of their remaining processing rates, i.e., {\hat{\mu }_1} \leq {\hat{\mu }_2} \leq \cdots \leq {\hat{\mu }_m} with {\hat{\mu }_j} = {\bar{\mu }_j} - \left({1 + {\alpha _j}} \right)\Lambda _{ - i}^j (j \in \mathcal{M}). There exists a set of threshold request arrival rates \phi _{i1}^{\min },\phi _{i2}^{\min }, \ldots, \phi _{im}^{\min } = 0, such that in the optimal migration policy {\lambda _{ij}} = 0 if {\phi _i} \leq \phi _{ij}^{\min } and {\lambda _{ij}} > 0 if {\phi _i} > \phi _{ij}^{\min }.

Proof.
To improve the overall readability of this manuscript, the complete proof of this theorem is given in the supplementary material, available online.

Based on the results of Theorems 3.1 and 3.2, we conclude that there exists one optimal solution to the optimization problem (17) without violating the constraint in (17), when given the feasible strategies of others {\boldsymbol {\lambda } _{ - i}} = \left({{\boldsymbol {\lambda } _j}} \right)_{j = 1,j \ne i}^m. Therefore, in our work, we ignore the constraint in (17), and reduce the problem (17) to the following optimization problem: \begin{equation*} \hbox{minimize} \quad {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right), \;{\boldsymbol {\lambda } _i} \in {\mathcal{Q}_i}. \tag{18}\end{equation*}
View SourceThe above formulated game can be formally defined by the tuple G = \left\langle {\mathcal{Q},\mathbf{R}} \right\rangle, where \mathbf{R} = \left({{R_i}} \right)_{i = 1}^m. The aim of player i (i \in \mathcal{M}), given the other players^{\prime } strategies \boldsymbol {\lambda }_{-i}, is to choose a strategy {\boldsymbol {\lambda } _i} \in {\mathcal{Q}_i} such that its average response time {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right) is minimized.

Definition 3.1 (Nash equilibrium).
A Nash equilibrium of the formulated game G = \left\langle {\mathcal{Q},\mathbf{R}} \right\rangle defined above is a request migration profile \boldsymbol {\lambda }^\ast such that for every player i (i \in \mathcal{M}) \begin{equation*} \boldsymbol {\lambda } _i^\ast \in \mathop {\arg \min }\limits _{{\boldsymbol {\lambda } _i} \in {{\mathcal{Q}}_i}} {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right),\;{\boldsymbol {\lambda } ^\ast } \in \mathcal{Q}. \tag{19}\end{equation*}
View Source

At the Nash equilibrium, each player cannot further decrease its average response time by choosing a different request migration strategy while the strategies of other players are fixed. The equilibrium strategy profile can be found when each player^{\prime }s strategy is the best response to the strategies of other players.

3.2 Nash Equilibrium Existence Analysis
In this section, we analyze the existence of Nash equilibrium solution for the formulated game G = \left\langle {\mathcal{ Q},\mathbf{R}} \right\rangle, and prove the existence problem by employing variational inequality theory. Before addressing the problem, we first show three import properties presented in Theorems 3.1, 3.2, and 3.3, which are helpful to prove the existence of Nash equilibrium for the formulated game.

Theorem 3.3.
If both matrixes \mathcal{M}_1 and \mathcal{M}_2 are positive definite, then the matrix \mathcal{M}_3 and \mathcal{M}_4 and are also positive definite, where \begin{equation*} {\mathcal{M}_3} = {\mathcal{M}_1} + {\mathcal{M}_2}, \;{\mathrm {and}} \;{\mathcal{M}_4} = \left[ {\begin{array}{cc}{\mathcal{M}_1}&\mathbf{0}\\ \mathbf{0}&0 \end{array}} \right]. \tag{20}\end{equation*}
View Source

Proof.
As mentioned above, both matrixes \mathcal{M}_1 and \mathcal{M}_2 are positive definite. Then, we have \forall \boldsymbol {x} \begin{equation*} {\boldsymbol {x}^T}{\mathcal{M}_1}\boldsymbol {x} > 0 \; {\mathrm {and}} \; {\boldsymbol {x}^T}{\mathcal{M}_2}\boldsymbol {x} > 0. \end{equation*}
View SourceWe obtain \forall \boldsymbol {x} \begin{equation*} {\boldsymbol {x}^T}{\mathcal{M}_3}\boldsymbol {x} = {\boldsymbol {x}^T}{\mathcal{M}_1}\boldsymbol {x} + {\boldsymbol {x}^T}{\mathcal{M}_2}\boldsymbol {x} > 0. \end{equation*}
View SourceTherefore, we can conclude that the matrix \mathcal{M}_3 is positive definite. On the other hand, if matrix \mathcal{M}_1 is positive definite, then we obtain \forall \boldsymbol {z} = ({\begin{array}{c}\boldsymbol {x}\\ y \end{array}}) \begin{align*} {\boldsymbol {z}^T}{\mathcal{M}_4}\boldsymbol {z} & = \left({{\boldsymbol {x}^T}{\mathcal{M}_1} + y\boldsymbol {0},0} \right)\left({\begin{array}{c}\boldsymbol {x}\\ y \end{array}} \right)\\ & = {\boldsymbol {x}^T}{\mathcal{M}_1}\boldsymbol {x} + y\boldsymbol {0}\boldsymbol {x} = {\boldsymbol {x}^T}{\mathcal{M}_1}\boldsymbol {x} > 0. \end{align*}
View SourceThus, the matrix \mathcal{M}_4 is also positive definite and the result follows.

Theorem 3.4.
For each cloud player i (i \in \mathcal{M}), the set \mathcal{Q}_i is closed and convex, and each disutility function {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right) is continuously differentiable in \boldsymbol {\lambda }_i. For each fixed tuple \boldsymbol {\lambda }_{-i}, the disutility function {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right) is convex in \boldsymbol {\lambda }_i over the set \mathcal{Q}_i, given that the condition t \leq \bar{t} holds, where \begin{equation*} \bar{t} = \frac{m}{{\left({\left({m - 2} \right){\phi _{\max }} + m\gamma } \right)}}, \tag{21}\end{equation*}
View Sourcewith {\phi _{\max }} = {\max _{j \in \mathcal{M}}}\left({{\phi _j}} \right).

Proof.
To improve the overall readability of this manuscript, the complete proof of this theorem is given in the supplementary material, available online.

Theorem 3.5.
If the condition (21) holds, then every solution of the variational inequality problem, denoted by {\mathrm {VI}}\left({\mathcal{Q},\mathbf{F}} \right), is an equilibrium solution of the game G = \left\langle {\mathcal{Q},\mathbf{R}} \right\rangle, where \begin{equation*} \mathbf{F}\left(\boldsymbol {\lambda } \right) = \left({{\mathbf{F}_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right)} \right)_{i = 1}^m, \tag{22}\end{equation*}
View Sourcewith \begin{equation*} {\mathbf{F}_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right) = {\nabla _{{\boldsymbol {\lambda } _i}}}{R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right). \tag{23}\end{equation*}
View Source

Proof.
According to Lemma 4.2 in [37], we know that the above claim holds if two conditions are satisfied. First, for each player i (i \in \mathcal{M}), the strategy set \mathcal{Q}_i is closed and convex. Second, for every fixed \boldsymbol {\lambda }_{-i}, the disutility function {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right) is twice continuously differentiable and convex in {\boldsymbol {\lambda } _i} \in {\mathcal{Q}_i}. By Theorem 3.2, it is easy to know that both the two conditions are satisfied in the formulated game G. Thus, the result follows.

Recall that the objective of this section is to study the existence of Nash equilibrium for the formulated game G = \left\langle {\mathcal{Q},\mathbf{R}} \right\rangle in (18). In the next theorem, we prove that if (21) holds, the existence of such Nash equilibrium is guaranteed.

Theorem 3.6.
There exists a Nash equilibrium solution set for the formulated game G = \left\langle {\mathcal{Q},\mathbf{R}} \right\rangle, given that the condition (21) holds.

Proof.
Based on Theorem 3.3, the proof of this theorem follows if we can show that the formulated variational inequality problem {\mathrm {VI}}\left({\mathcal{Q},\mathbf{F}} \right) in Theorem 3.3 possesses a solution set. According to Theorem 4.1 in [37], {\mathrm {VI}}\left({\mathcal{Q},\mathbf{F}} \right) admits a solution set if the mapping \mathbf{F} is monotone over \mathcal{Q}.

To prove the monotonicity of \mathbf{F}, it suffices to show that for any \boldsymbol {\lambda } and \boldsymbol {s} in \mathcal{Q} \begin{equation*} {\left({\boldsymbol {\lambda } - \boldsymbol {s}} \right)^T}\left({\mathbf{F}\left(\boldsymbol {\lambda } \right) - \mathbf{F}\left(\boldsymbol {s} \right)} \right) \geq 0, \end{equation*}
View SourceRight-click on figure for MathML and additional features.that is \begin{equation*} \sum \limits _{i = 1}^m {{{\left({{\boldsymbol {\lambda } _i} - {\boldsymbol {s}_i}} \right)}^T}} \left({{\mathbf{F}_i}\left(\boldsymbol {\lambda } \right) - {\mathbf{F}_i}\left(\boldsymbol {s} \right)} \right) \geq 0. \tag{24}\end{equation*}
View SourceWe can observe that if \begin{equation*} {\left({{\boldsymbol {\lambda } _i} - {\boldsymbol {s}_i}} \right)^T}\left({{\mathbf{F}_i}\left(\boldsymbol {\lambda } \right) - {\mathbf{F}_i}\left(\boldsymbol {s} \right)} \right) \geq 0, ~ \forall i \in \mathcal{M}, \end{equation*}
View Sourcethen inequality (24) holds.

After some algebraic manipulation, we can write the (j, k)th element of {{\mathrm {J}}_{{\boldsymbol {\lambda } _i}}}{\mathbf{F}_i}\left(\boldsymbol {\lambda } \right) as \begin{align*} & {\left[ {{{\mathrm {J}}_{{\boldsymbol {\lambda } _i}}}{\mathbf{F}_i}\left(\boldsymbol {\lambda } \right)} \right]_{jk}} = \frac{{{\partial ^2}{R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{ - i}}} \right)}}{{\partial {\lambda _{ij}}\partial {\lambda _{ik}}}}\\ & \qquad = \left\lbrace \begin{array}{ll}\frac{{2\left({1 + {\alpha _j}} \right)\left({\left({{\mu _j} - {\beta _j}} \right) + \left({1 + {\alpha _j}} \right){\lambda _{ij}}} \right)}}{{{{\left({{\mu _j} - {\beta _j}} \right)}^3}}}, & {\mathrm {if}} \;i = j = k;\\ {\frac{{2\left({1 + {\alpha _j}} \right)\left({\left({{\mu _j} - {\beta _j}} \right) + \left({1 + {\alpha _j}} \right){\lambda _{ij}}} \right)}}{{{{\left({{\mu _j} - {\beta _j}} \right)}^3}}}}\\ \qquad \qquad { + \frac{{2t\left({t\left({1 - t\gamma } \right) + {\lambda _{ij}}{t^2}} \right)}}{{{{\left({1 - t\gamma } \right)}^3}}}}, & {\mathrm {if}} \; i \ne j, j = k;\\ {\frac{{{t^2}\left({1 - t\gamma } \right) + 2{\lambda _{ij}}{t^3}}}{{{{\left({1 - t\gamma } \right)}^3}}}}, & {\mathrm {if}} \; i \ne j, i \ne k;\\ 0, & {\mathrm {otherwise}}.\\ \end{array}\right. \end{align*}
View SourceBy the derivations in Theorem 3.2, we can conclude that the jacobian matrix {{\mathrm {J}}_{{\boldsymbol {\lambda } _i}}}{\mathbf{F}_i}\left(\boldsymbol {\lambda } \right) is positive definite. The result follows.

3.3 Nash Equilibrium Computation
Once we have established that the Nash equilibrium solution for the formulated game G = \left\langle {\mathcal{Q},\mathbf{R}} \right\rangle exists, we are interested in obtaining a suitable algorithm to compute one of these equilibria.

Notice that, we can further rewrite the optimization problem (18) as follows: \begin{equation*} \hbox{minimize} \quad {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{\Sigma }}, \gamma } \right), \; \forall i \in \mathcal{M}, \tag{25}\end{equation*}
View SourceRight-click on figure for MathML and additional features.where \boldsymbol {\lambda }_{\Sigma } denotes the aggregated requests of all servers, i.e., {\boldsymbol {\lambda }_\Sigma } = \sum \nolimits _{i = 1}^m {{\boldsymbol {\lambda }_i}}, and \gamma = \sum \nolimits _{i = 1}^m {\sum \nolimits _{j = 1,j \ne i}^m {{\lambda _{ij}}} }, is the total traffic through the network. From (25), we can observe that the calculation of the disutility function of each individual player only requires the knowledge of the aggregated requests of all servers (\boldsymbol {\lambda }_\Sigma) and the total traffic (\gamma) rather than that the specific individual strategy profile (\boldsymbol {\lambda }_{-i}), which can bring about two advantages. On the one hand, it can reduce communication traffic between the virtual communication player and the m players. On the other hand, it can reduce storage for each player to calculate its own strategy.

Since all players are considered to be selfish and try to minimize their own disutilities while ignoring the others. It is natural to consider an iterative algorithm where, at every iteration k, each player i (\forall i \in \mathcal{M}) updates its strategy to minimize its own disutility function R_i\left(\boldsymbol {\lambda }_i, \boldsymbol {\lambda }_{-i} \right). However, following [37], it is not difficult to show that their convergence cannot be guaranteed in our case if the players are allowed to simultaneously update their strategies. To overcome this issue, we consider an iterative proximal algorithm, which is based on the best response Algorithm 4.1 [37]. The proposed algorithm is guaranteed to converge to a Nash equilibrium under some additional constraints on the parameters of the algorithm. With reference to [37], we can find a solution to the optimization problem (25) by solving the regularized game in which each of the m players tries to solve the following optimization problem: \begin{align*} \hbox{minimize} \quad & {R_i}\left({{\boldsymbol {\lambda } _i},{\boldsymbol {\lambda } _{\Sigma }}, \gamma } \right) + \frac{\tau }{2}\left\Vert {{\boldsymbol {\lambda } _i} - {{\boldsymbol {\bar{\lambda }} }_i}} \right\Vert ^2,\\ \hbox{s.t.} \quad & {\boldsymbol {\lambda } _i} \in {\mathcal{Q} _i}, \; \forall i \in \mathcal{M}. \tag{26}\end{align*}
View SourceRight-click on figure for MathML and additional features.That is to say, when given the external requests, we must find a strategy vector {{\boldsymbol {\lambda }^\ast }} \in {\mathcal{Q}}, such that \begin{equation*} \boldsymbol {\lambda } _i^\ast \in \mathop {\arg \min }\limits _{{\boldsymbol {\lambda } _i} \in {\mathcal{Q}_i}} \left\lbrace {{R_i}\left({{\boldsymbol {\lambda } _i},\boldsymbol {\lambda } _{\Sigma }^\ast }, \gamma \right) + \frac{\tau }{2}{{\left\Vert {{\boldsymbol {\lambda } _i} - {{\boldsymbol {\bar{\lambda }} }_i}} \right\Vert }^2}} \right\rbrace, \tag{27}\end{equation*}
View Sourcefor each player i (i \in \mathcal{M}), where \tau (\tau > 0) is a regularization parameter and can guarantee the convergence of the IPA algorithm if its value is large enough. The idea is formalized in Algorithm 1.

Algorithm 1. Iterative Proximal Algorithm (IPA)
Input: \epsilon, \boldsymbol {\mu }, \boldsymbol {\lambda }, \mathcal{M}.

Output: \boldsymbol {p}_i.

Initialization: Randomly choose a feasible strategy vector {{\boldsymbol {\lambda }^{(0)}}} ({\boldsymbol {\lambda }^{(0)}} \in {\mathcal{Q}}). Set \boldsymbol {\bar{\lambda }} \leftarrow \boldsymbol {0}, and k \leftarrow 0.

while (\left\Vert {{\boldsymbol {\lambda }^{(k)}} - {\boldsymbol {\lambda }^{(k - 1)}}} \right\Vert > \epsilon) do

for (each player i \in \mathcal{M}) do

Receive \boldsymbol {\lambda }_\Sigma ^{(k)} and \gamma ^{(k)} from the information player, and compute \boldsymbol {\lambda }_i^{(k+1)} as follows: \begin{align*} & \boldsymbol {\lambda } _i^{(k + 1)} \in\\ & \quad \mathop {\arg \min }\limits _{{\boldsymbol {\lambda } _i} \in {\mathcal{Q}_i}} \left\lbrace {{R_i}\left({{\boldsymbol {\lambda } _i},\boldsymbol {\lambda }_\Sigma ^{(k)},{\gamma ^{(k)}}} \right) + \frac{\tau }{2}{{\left\Vert {{\boldsymbol {\lambda }_i} - {{\boldsymbol {\bar{\lambda }} }_i}} \right\Vert }^2}} \right\rbrace . \end{align*}
View SourceRight-click on figure for MathML and additional features.

Send the updated strategy to the communication player.

end for

if (Nash equilibrium is reached) then

All of the m players updates their centroids, i.e., {\boldsymbol {\bar{\lambda }} } \leftarrow {{\boldsymbol {\lambda }^{(k + 1)}}}.

end if

Set k \leftarrow k+1.

end while

return \boldsymbol {\lambda }^{(k)}.

Algorithm 
At the beginning, each cloud user i (i \in \mathcal{M}) sends its server parameters (\alpha _i, \bar{\mu }_i) and the external request arrival rate (\phi _i) to the virtual communication player. Then the communication player computes the regulation parameter (\tau) as in Theorem 3.6 according to the aggregated information. After this, the communication player puts the computed regulation parameter into the public information exchange module. Then, at each iteration k, the communication player broadcasts the current aggregated request profile (\boldsymbol {\lambda } _\Sigma ^{(k)}), and the current communication traffic (\gamma ^{(k)}). Within iteration k, each player receives the aggregated profile (\boldsymbol {\lambda } _\Sigma ^{(k)}, \gamma ^{(k)}) and computes its strategy by solving its own optimization problem in (26), and then sends the newly updated strategy to the communication player. Lastly, as indicated in Algorithm 1 (Steps 7-9), the communication player checks whether the Nash equilibrium has been achieved and if so, it broadcasts a signal to inform all players to update their centroid (\boldsymbol {{\boldsymbol {\bar{\lambda }}} _i}). This process continues until the strategies of all players (i.e., the request migration strategies of all servers) are kept fixed. In this paper, we assume that the strategies of all cloud users are unchanged if {\left\Vert {{\boldsymbol {\lambda } ^{(k)}} - {\boldsymbol {\lambda } ^{(k - 1)}}} \right\Vert } \leq \epsilon, where {\boldsymbol {\lambda } ^{(k)}} = ({\boldsymbol {\lambda } _i^{(k)}})_{i = 1}^m with \boldsymbol {\lambda } _i^{(k)} = ({{{({\lambda _{ij}})}^{(k)}}})_{j = 1}^m, and \epsilon is a relatively small constant.

3.4 Convergence Analysis of \mathcal{IA} Algorithm
In this section, we analyze the convergence of our proposed IPA algorithm. We prove that when the regulation parameter \tau is large enough, the IPA algorithm converges to a Nash equilibrium. Before addressing the convergence problem, we show a property about matrix, which is presented in Theorem 3.5.

Theorem 3.7.
Let \mathbf{A} = \left[ a_{ij} \right] be a real matrix with m order, then we have \begin{equation*} {\left\Vert \mathbf{A} \right\Vert _2} \leq m{\left\Vert \mathbf{A} \right\Vert _\infty }, \tag{28}\end{equation*}
View Sourcewhere {\left\Vert \mathbf{A} \right\Vert _2} and {\left\Vert \mathbf{A} \right\Vert _\infty } denote the 2-norm and infinite norm of matrix \mathbf{A}, respectively.

Proof.
Since \mathbf{A} is a real matrix, it is easy to obtain that \forall \boldsymbol {x} \begin{equation*} {\boldsymbol {x}^T}\left({\mathbf{A}{\mathbf{A}^T}} \right)\boldsymbol {x} = {\left({{\mathbf{A}^T}\boldsymbol {x}} \right)^T}\left({{\mathbf{A}^T}\boldsymbol {x}} \right) \geq 0. \end{equation*}
View SourceRight-click on figure for MathML and additional features.That is to say, the matrix \mathbf{A}^T\mathbf{A} is positive semidefinite and we can conclude that {\kappa _{\min }}\left({{\mathbf{A}^T}\mathbf{A}} \right) \geq 0 with {\kappa _{\min }}\left({\mathbf{A}^T}{\mathbf{A}} \right) denoting the minimal eigenvalue of matrix \mathbf{A}^T\mathbf{A}. Let {\kappa _{i }}\left({\mathbf{A}^T}{\mathbf{A}} \right) be the ith eigenvalue of matrix \mathbf{A}^T\mathbf{A}, then we have {\kappa _{i }}\left({\mathbf{A}^T}{\mathbf{A}} \right) \geq {\kappa _{\min }}\left({\mathbf{A}^T}{\mathbf{A}} \right) \geq 0. On the other hand, since \begin{equation*} \sum \nolimits _{i = 1}^m {{\kappa _i}\left({\mathbf{A}^T}{\mathbf{A}} \right)} = {{\mathbf{tr}}}\left({{\mathbf{A}^T}\mathbf{A}} \right), \end{equation*}
View Sourcewhere {{\mathbf{tr}}}\left({{\mathbf{A}^T}\mathbf{A}} \right) denotes the summation of all diagonal elements of matrix {{\mathbf{A}^T}\mathbf{A}}, i.e., {{\mathbf{tr}}}\left({{\mathbf{A}^T}\mathbf{A}} \right) = \sqrt{\sum \nolimits _{i = 1}^m {\sum \nolimits _{j = 1}^m {a_{ij}^2} } }, then we have \begin{align*} {\left\Vert \mathbf{A} \right\Vert _2} & = \sqrt{{\kappa _{\max }}\left({{\mathbf{A}^T}\mathbf{A}} \right)} \leq \sqrt{\mathbf{tr}\left({{\mathbf{A}^T}\mathbf{A}} \right)}\\ & \leq \sqrt{m \cdot {{\max }_{i \in \mathcal{M}}}\sum \nolimits _{j = 1}^m {{{\left\Vert {{a_{ij}}} \right\Vert }^2}} }\\ & \leq m \cdot {\max _{i \in \mathcal{M}}}\sum \nolimits _{j = 1}^m {\left\Vert {{a_{ij}}} \right\Vert } = m{\left\Vert \mathbf{A} \right\Vert _\infty }. \end{align*}
View SourceRight-click on figure for MathML and additional features.

Therefore, we obtain {\left\Vert \mathbf{A} \right\Vert _2} \leq m{\left\Vert \mathbf{A} \right\Vert _\infty }. This completes the proof and the result follows.

Theorem 3.8.
There exists a positive constant \tau such that \tau > \tau _0, then any sequence \lbrace {{\boldsymbol {\lambda } ^{(k)}}} \rbrace _{k = 0}^\infty generated by the \mathcal{IA} algorithm converges to a Nash equilibrium, where \begin{equation*} {\tau _0} = \left(m - 1 \right){m^2} \chi _{\max }, \tag{29}\end{equation*}
View SourceRight-click on figure for MathML and additional features.with \begin{align*} \chi _{\max } & = \frac{{\left({1 + {\alpha _{\max }}} \right)\left({\sigma {{\bar{\mu }}_{\min }} + 2\left({1 + {\alpha _{\max }}} \right){\phi _{\max }}} \right)}}{{{{\left({\sigma {{\bar{\mu }}_{\min }}} \right)}^3}}}\\ & \quad + \frac{{{{\bar{t}}^2}\left({1 - \bar{t}\gamma } \right) + 2{\phi _{\max }}{{\bar{t}}^3}}}{{{{\left({1 - \bar{t}\gamma } \right)}^3}}}, \tag{30}\end{align*}
View SourceRight-click on figure for MathML and additional features.where \sigma = \frac{\delta }{{1 + \left({1 - \delta } \right){\alpha _k}}}, \alpha _{\max } = \max _{k \in \mathcal{M}}\left(\alpha _k \right), \bar{\mu }_{\min } = \min _{k \in \mathcal{M}}\left(\mu _k \right), \phi _{\max } = \max _{i \in \mathcal{M}}\left(\phi _i \right), and \begin{equation*} \bar{t} = \frac{m}{{\left({\left({m - 2} \right){\phi _{\max }} + m\gamma } \right)}}. \tag{31}\end{equation*}
View Source

Proof.
To improve the overall readability of this manuscript, the complete proof of this theorem is given in the supplementary material, available online.

SECTION 4Performance Evaluation
In this section, we provide some numerical results to validate our theoretical analyses and illustrate the performance of the IPA algorithm. The performance metrics used in our simulation are the multiplied time value (T_R), namely \begin{equation*} {T_R} = \prod \limits _{i = 1}^m {{R_i}}, \tag{32}\end{equation*}
View Sourceand specific average response time (R_i), and fairness index (f\left(\mathbf{R}\right)) [36], where \begin{equation*} f\left(\mathbf{R} \right) = {{{{\left({\sum \limits _{i = 1}^m {{R_i}} } \right)}^2}} \mathord {\left/ {\vphantom{{{{\left({\sum \limits _{i = 1}^m {{R_i}} } \right)}^2}} {\left({m\sum \limits _{i = 1}^m {R_i^2} } \right)}}} \right.} {\left({m\sum \limits _{i = 1}^m {R_i^2} } \right)}}, \tag{33}\end{equation*}
View SourceRight-click on figure for MathML and additional features.is used to quantify the fairness of load balancing schemes. If all servers have the same expected response time, then f = 1 and the system is fair. Notice that, different from the central view, our method is developed in a distributed and non-cooperative environment.

In the following simulation results, we consider a scenario that the maximum total external request arrival rate (\Phi) can be 500 and the maximum mean request communication time can be 0.06. As shown in Table 3, the total external request arrival rate (\Phi) is varied from 50 to 500 with increment 25. The mean request communication time (t) is varied from 0.001 to 0.01 with increment 0.001, and from 0.01 to 0.06 with increment 0.01. The maximum processing rate of a server (\bar{\mu }_i) and its corresponding deteriorating rate (\alpha _i) are randomly chosen from 20 to 120 and 0 to 0.5, respectively. The number of servers (m) in the cloud provider is set as a constant 50. In our configuration, \delta is set as 0.2, that is to say, the aggregated requests at a server cannot exceed 80 percent expected processing capability of the server, and the accuracy control parameter (\epsilon) is set as 0.01. Of course, other parameter values can also be configured.

Fig. 4 shows an instance for the average response times of different servers versus the number of iterations of the proposed IPA algorithm. Specifically, Fig. 4 illustrates the average response time trends of 6 randomly selected servers (servers 7, 11, 17, 24, 35, and 50) during the iteration process (the iteration process of the while loop) of our proposed IPA algorithm. In this scenario, the total number of servers is 50. From Fig. 4, we can observe that the average response times of some servers (servers 11, 17, 24, 35, and 50) tend to decrease with the increase of the iteration number while some servers (server 7) tend to increase. However, all the average response times reach a relatively stable state, which verifies the convergency result shown in Theorem 3.8. That is, the average response times of all servers are kept unchanged after several iterations, i.e., reach a Nash equilibrium solution after several iterations. In addition, it can also be seen that the developed algorithm converges to a Nash equilibrium very quickly. Specifically, the average response times of all servers have already achieved a relatively stable state after around 8 iterations, which shows the high efficiency of our developed algorithm.


Fig. 4.
Convergency process of specific response time.

Show All

In Fig. 5, we compare the multiplied time values (calculated according to Eq. (32)) with the situations before and after IPA algorithm, i.e., compare the results without request migration and those with request migration configured by our IPA algorithm. Specifically, Fig. 5 shows the multiplied time values with the increase of total external request arrival rate. We conduct 300 times with initial strategies randomly chosen from the feasible strategy set, and present the mean value in Fig. 5. The initial multiplied time value ({IT}_R) corresponds to the result of a feasible strategy profile randomly generated in the initialization stage, i.e., the profile without request migration, while the result (T_R) corresponds to the value obtained by adopting our request migration scheme. Obviously, our IPA algorithm can significantly optimize the multiplied value generated by initial strategy, which shows that our proposed algorithm is effective for load balance under distributed environment. We can also observe that the trend of multiplied values tend to increase with increase of total external request arrival rate. The reason behind lies in that with the increase of total external requests, the expected response times of some servers significantly increase. To demonstrate this phenomenon, we further investigate the specific response times of different servers. The results are presented in Fig. 6.


Fig. 5.
Impacts of \Phi on multiplied time value.

Show All


Fig. 6.
Impacts of \Phi on specific response time.

Show All

In Fig. 6, we plot the average response time shapes of some servers for the developed IPA algorithm with the increase of total external request arrival rate. Specifically, in Fig. 6, we randomly select 3 servers (servers 8, 26, and 45) and show the expected response time trends. It can be seen that the average response times of some servers tend to increase with the increase of total external request arrival rate (servers 26 and 45), while some of them tend to decrease (server 8). The reason behind lies in that some slow servers tend to migrate their arrived requests to other servers to decrease their own expected response times. Otherwise, their expected response times will significantly increase even with a small load increase. On the other hand, some fast servers tend to process the arrived requests by themselves. Hence, the expected response times of some servers tend to increase while some servers tend to decrease. Fig. 7 presents the fairness results. The initial fairness index (If) corresponds to the initial strategy, i.e., the strategy without request migration, and the other corresponds to the strategy obtained by our IPA algorithm. We can observe that at first, both results are small and the result obtained by our algorithm is even worse. With the increase of total request arrival rate, both results tend to increase. However, the result obtained by IPA algorithm is more better. The reason behind lies in that when the total request is small, there are no aggregated requests on many servers, i.e., many servers run with very little requests compared to their whole processing capacities. However, with the increase of total request arrival rate, our method can find a better balancing strategy and reaches around 0.6-0.7 fairness index in our non-cooperative environment.


Fig. 7.
Impacts of \Phi on fairness index.

Show All

Figs. 8 and 9 present the impacts of mean request communication time on multiplied time value and the corresponding specific response times of some servers. Specifically, Fig. 8 illustrates the multiplied time value with the increment of mean communication time. We can observe that the multiplied time value increases with increase of mean request communication time (from 0.001 to 0.03). However, it keeps unchanged if the mean communication time of a request is large enough (from 0.04 to 0.06). Fig. 9 shows the corresponding specific average response times. We randomly select 3 servers (servers 10, 19, and 48). It can be seen that the average response times of servers tend to increase with the increase of mean request communication time (from 0.001 to 0.03) at first. Then, they are kept unchanged when the mean communication time is large enough (from 0.04 to 0.06). The reason behind lies in that at the beginning, even though the mean request communication time increases, some servers still prefer to migrate some of their requests to other servers to reduce their own expected response times. However, when the mean request communication time (i.e., the cost to migrate a request) is large enough, they will prefer to complete all the aggregated requests on their own. This also partly verifies the multiplied time shape shown in Fig. 8.


Fig. 8.
Impacts of t on multiplied time value.

Show All


Fig. 9.
Impacts of t on specific response time.

Show All

SECTION 5Conclusions
An increasing number of applications migrated to cloud centers, load balancing has become one of the most important factors for service quality. However, most of the existing scheduling algorithms in clouds ignore the server availability, which can lead to load imbalance and a great waste of computing resources. To remedy this problem to certain extent, we propose a non-cooperative game based load balancing scheme, which involves load-dependent server availability.

In this paper, we focus on request migration strategies of multiple servers for load balance in cloud. We consider the problem from a game theoretic perspective and formulate it into a non-cooperative game among the multiple servers, in which each server is informed with incomplete information of other servers. For each server, we define its average response time as a disutility function and try to minimize its value. We also take into account server availability, which impacts the processing rate of a server and thus its disutility. We solve the problem by employing variational inequality theory and prove that there exists a Nash equilibrium solution set for the formulated game. Then, we propose an iterative proximal algorithm to compute a Nash equilibrium solution. The convergence of the IPA algorithm is also analyzed and we find that it converges to a Nash equilibrium if several conditions are satisfied. Finally, we conduct some numerical calculations to verify our theoretical analysis. The experimental results show that our proposed IPA algorithm converges to a Nash equilibrium very quickly and significantly decreases the disutilities of all servers by configuring a proper request migration strategy.

As part of future directions, we will extend IPA to request migration across clouds, in which the communication cost can be large. Another direction is to study the integration of our IPA with some pre-scheduling algorithm.