Leveraging power consumption models in software systems can achieve easy deployment of low-cost, high-availability power monitoring in cloud datacenters that are usually large-scale, heterogeneous and frequently scaling up. However, traditional regression-based power consumption models generally have two drawbacks. First, their mathematical forms are usually fixed and determined a priori. This may cause unacceptable increase of error or over-fitting as the power signatures of cloud servers are usually uncertain. Second, the characteristic of workload dispatched to cloud servers is constantly changing while regression-based models can hardly generalize to a wide range of servers and workload types. As a novel solution, we in this paper propose a server power consumption model based on Elman Neural Network (PCM-ENN), aiming to allow accurate and flexible power estimation. PCM-ENN is an end-to-end black box model capable of learning the temporal relation between samples in a time series of power consumption. We trained and evaluated PCM-ENN on two power sequence datasets collected from heterogeneous hardware and operating systems running quasi-production benchmarks like CloudSuite. Experimental result shows that PCM-ENN generated accurate estimates on server power consumption with only small errors, outperforming widely-used linear regression model and NARX model in terms of accuracy.
SECTION 1Introduction
While cloud computing is still gaining increasing popularity around the world, excessive electricity consumption by cloud datacenters has become a prominent issue and drawn a lot of concern. Statistics shows that the annual electricity consumed by datacenters in the USA already reached 91 billion kilowatt-hours, while the figure is projected to soar to as high as 140 billion kWh in 2020 [1]. Over-consumption of energy certainly makes negative impacts on the development of cloud computing, bringing about problems such as increasing operation cost and adverse effects on environment.

Implementation of fine-grained power monitoring systems is the very foundation for realizing energy-aware power provisioning and management. Emerson's report in North America reveals that 51 percent of respondents cited adequate monitoring/ datacenter management capabilities among their three biggest concerns [2]. Traditionally, server power is measured using external metering devices or dedicated data acquisition interfaces. For instance, IBM PowerExecutive [30] is a plug-in tool for gaining as well as capping actual power consumption of servers under the specified architecture – System X. Hardware (e.g., sensors) power measuring can be the best option for homogeneous datacenters but is hardly a solution for heterogeneous ones such as legacy systems and cloud datacenters [28], [29]. The main reasons are but not limited to expensiveness, poor scalability [3] and coarse granularity. By contrast, power monitoring systems built on software are able to support fine-grained, low-cost, easy-to-extend monitoring in a cloud system that can be highly heterogeneous and constantly scaling [29]. The core of software power monitoring is the pre-built power consumption model, which is defined as one or multiple functions that map system performance related metrics to system power or energy consumption [4]. Power consumption model takes as input one or several metrics (features) at different sampling granularities (e.g., OS level and processor level), outputs estimated values of power (for an instant) or energy consumption (for a period). Power model is not only used for monitoring purposes, but also provides important guidance for energy-aware resource provisioning [5], [39], [41], capping [38] and scheduling [6], [7], [40]. For example, Shen et al. [38] proposed “power container”, which is a novel operating system facility that accounts for and controls the power and energy usage of every single task on multi-core systems. One of the key techniques in their work is an online, adaptive power model for capturing the power consumption of concurrent tasks. Niu et al. [8] implemented an energy-aware scheduling framework named GreenMR. The authors introduce the execution time models and power consumption models for Map phase and Reduce phase, separately. The models are used to profile the total run time and energy consumption jobs in a given resource configuration.

Previous studies mainly used regression-based methods to build power consumption models. The most widely adopted approach is linear regression because of its good interpretability and simplicity in training [9]. For example, Hsu and Poole [10] investigated a number of regression-based power consumption models which are all functions of CPU utilization. Lin et al. [11] surveyed mainstream component-level power models and evaluated their accuracy in experiment using regression analysis. Whereas regression models are commonly adopted, they have outstanding deficiencies. First, using fixed forms limits their ability to generalize to a diversity of server power curves. Second, they can hardly support incremental training whilst cloud infrastructures are upgrading fast. Third, temporal relation between time-series records (samples of power consumption in a time series) is neglected in regression models.

More and more studies on time-series processing begin to adopt Artificial Neural Network (ANN), but most of them focus on predicting power or workload in the future. For example, we have seen promising results in predicting workload using ANN or its improved forms [12], [13], [14]. ANN is complex but allows flexible training and more possibilities in model optimization, providing an entirely different way to build and train power consumption models that are suitable for cloud servers. In this paper, we propose to leverage artificial neural network and find the proper form of it to build the power consumption model for cloud servers. Fig. 1 demonstrates a software power monitoring framework applied to a cloud system where power models are applied to heterogeneous cloud servers. The models are trained on historical datasets collected from corresponding types of cloud servers.


Fig. 1.
The proposed framework of power monitoring using power consumption models in cloud datacenters.

Show All

Training data for each model is server-specific, whereas different servers with identical hardware can share a same power consumption model, which largely reduces the number of models needed. In particular, we take advantage of neural network to improve power models’ accuracy, enable incremental training, and enhance their ability to generalize what it learned. Moreover, we in this paper explore the temporal correlation between consecutive power records using a simple recurrent structure. We summarize the main contributions of our work as follows:

Based on the fundamental requirements of a power monitoring system, we first introduce a number of ANN architectures that can be applied to power estimation after training on time-series data set. We further summarize their advantages and limitations.

We propose a server power consumption model based on Elman Neural Network (PCM-ENN), which is able to learn the temporal impact from previous power consumption and make real-time estimation.

We trained PCM-ENN on mixed datasets containing multiple types (CPU-intensive, memory-intensive and I/O-intensive) of workload, and evaluated it on test datasets obtained by running a production benchmark suite. Experimental result on two completely heterogeneous servers shows that PCM-ENN is more accurate than linear regression model, NARX model and the monitoring software Joulemeter.

The rest of this paper is organized as follows. Section 2 introduces related work on prediction models and power models based on ANN. Section 3 summarizes a number of ANN structures that can be applied to processing power sequence. We present the proposed server power model based on ENN in Section 4 and show evaluation results in Section 5. Finally we conclude the paper in Section 6.

SECTION 2Related Work
Lin et al. [3] in their paper categorize power measuring methods into four classes: direct metering by hardware devices, power estimation using power consumption models, power measuring in virtualized environment, and simulation-based power estimation. They also figure out that traditional power metering with external devices or dedicated acquisition systems (e.g., IBM Active Energy Manager [15]) is not feasible in large-scale and heterogeneous datacenters mainly due to the problem of hardware compatibility.

Software monitoring systems built on power consumption model has the advantages of low deployment cost, high scalability and fine granularity [28], and they are also applicable to estimating the power of virtual machines [42] and containers. For instance, Joulemeter [16], a power monitoring tool developed by Microsoft, works on the basis of several component power models. The widely-used simulation framework CloudSim [17] uses pre-defined models to emulate cloud servers’ power consumption. Software-based accounting can also be applied to Non-IT units at the granularity of virtual machine [43]. Dayarathna et al. [18] in their paper discuss power models at different levels of granularity from single components to a whole datacenter entity, and figure out that a well-designed model should be six features including accuracy, speed, generality, portability, inexpensiveness, and simplicity. Based on component-level power models, Lin et al. [19] developed a distributed power consumption monitoring tool named EnergyMeter. Their work adopts a white box approach of power modeling and is based on a multi-component system model. They proposed to use three separated, independent component power models to estimate CPU, memory and disk's power, and combine them with the system idle power to obtain the estimate of the whole computer's power. Similar to Joulemeter, the solution is light-weight (because it only needs to track utilizations) and provides fine-grained power monitoring. However, a disadvantage of it is that multiple power models corresponding to multiple components have to be maintained. One or even all of the models may need to be retrained in case system hardware is upgraded. Tang et al. [29] proposed a software-based hierarchical power estimation approach for legacy datacenters. Similar to our rationale, they build power mapping functions (PMFs) of server states along with a selective incremental training process to achieve non-intrusive, zero-cost, accurate power monitoring. The work of Lin et al. [11] summarizes a great number of power models in different forms. They also experimentally evaluated the models and the results show a fact that the most suitable model differs from server to server. In other words, it is unpractical to find a fixed form of power model that fits all types of servers.

Regression models may perform poorly in heterogeneous environments. Dayarathna et al. [18] believed the main causes are the cross dependence between selected features, features’ being outdated after hardware upgrade, some features’ strong dependency on OS, and the complexity of contemporary system architecture. As an alternative, artificial neural network is attracting more attention. Similar to power monitoring, workload prediction is a significant technique for datacenter management. Many studies have already adopted different ANN structures, like BPNN [20], LSTM-ANN [21] and Fuzzy ANN [22], to build prediction models and demonstrated promising results. Kumar and Singh [12] built a simple feed-forward neural network and trained it with differential evolution algorithm. Prevost et al. [23] used a neural network and an Auto Regression Prediction Weiner Filter to predict cloud datacenters’ workload. Results proved that both of the models are accurate. The number of historical data inputs is a critical hyper-parameter, Roy et al [24] carried out experiment and figured out that with only three most recent data records the future workload can be accurately forecasted. Kumar et al. [21] took advantage of LSTM-ANN to predict the number of requests received by web servers. They compared their model with BPNN and showed a significant improvement in accuracy. Chen et al. [22] combined ensemble model and fuzzy neural network to make workload prediction. The fuzzy neural network takes as input the outputs of several base predictors and consists of six layers.

Power estimation and load prediction are different but quite similar in essence. First, both of them are traditionally done by mathematical models and regression analysis, and can both resort to new modeling methods like neural network. Besides, monitoring power consumption and workload will both generate time-series data, which also indicates that we should consider the relation between temporally neighboring data records. Ruiz et al. [25] proposed to use artificial neural network for energy consumption forecasting. They trained three typical neural network models-NAR (Non-linear Auto-Regressive Neural Network), NARX (NAR with exogenous inputs) and Elman Neural Network on a historical data set of buildings’ energy use. As a result, their study reveals neural networks’ potential in performing accurate power forecasting for buildings. However, how to utilize them to build power estimator for cloud servers need to be further explored.

Accuracy can no longer be guaranteed using traditional power models since the heterogeneity of both servers and workload becomes increasingly common in cloud datacenters. Thus it is of great necessity to explore how to build power models that are easy-to-generalize.

SECTION 3Modeling Time Series of Power with ANN
Traditional power consumption models assume that power consumptions at different moments are independent. But as a matter of fact, system power actually changes in a continuous manner (similar to the change of workload), and there is also experimental evidence supporting the implicit relation between power consumption at consecutive moments [25]. Basically, power consumption models can be categorized into two types: (1) predicting power by examining historical data, and (2) estimating current system power through collecting relevant performance metrics such as utilization. The first one can be achieved in a way nearly the same with workload forecasting [20]. We focus on the second type as our goal is to establish real-time power monitoring on cloud servers without any extra metering devices. Li et al. [26] built a software/program power consumption model using BPNN. The model takes as input the target program's time complexity, space complexity and data size, and was experimentally proved accurate. However, BPNN model does not take into account time sequence patterns. Adopting a different approach, we attempted to take advantage of recurrent neural network to build a system-level end-to-end power consumption model. We aim to realize precise, real-time power estimation exploiting commonly-used features that are easy to collect in OS. Considering that power modeling is not of high complexity (as a regression task essentially), we believe a simple recurrent neural network structure with one hidden layer is enough for power estimation.

In this section we introduce a number of ANN structures applicable to power estimation followed by a brief comparison of their strengths and limitations.

3.1 BPNN Models
Back Propagation Neural Network (BPNN) is a commonly used ANN structure that applies error back propagation to model training. Basically, there are two BPNN structures corresponding to power prediction and power estimation, respectively.

The first structure is used to predict power consumption by taking historical power data as input. We in this paper call it Sliding Window BPNN power model. Sliding Window BPNN power model makes prediction entirely based on historical data. This probably leads to poor accuracy because the change of power consumption shows large uncertainty and weak temporal correlation. Moreover, we have to feed historical power records into the model, which means that the Sliding Window BPNN model cannot work without ground truth (i.e., measured data) in the current window. Thus, the model is not fit for power estimation. The second BPNN structure has a different design of input layer, which represents a vector of system performance features such as CPU utilization and disk throughput rate. BPNN model with only features input has a drawback in common with regression model - it cannot learn the temporal relation between consecutive time-series records. But its advantage over regression model is that we can easily enhance its complexity by extending the hidden layer by adding neurons or increasing the number of layers.

3.2 NAR(X) Network Model
Non-linear Auto-Regressive Model (NAR) and Non-linear Auto-Regressive Model with Exogenous Inputs (NARX) are two forms of recurrent neural network commonly used in establishing prediction model on time-series data set.

NAR receives power values at n consecutive moments denoted as p(t−n),p(t−n+1),…,p(t−1). Its output layer typically contains only one neuron corresponding to the power consumption at time t. The limitation of NAR is similar to that of the Sliding Window BPNN model. The reason is that neither of them takes system performance features into account. But NAR takes advantage of the feedback from its output (current prediction) to input (feature input of next moment) to enables the model to work continuously and automatically without feeding of historical data.

NARX, as shown in Fig. 2, extends NAR network by introducing additional input neuron(s) to receive exogenous input(s). For power consumption model, we typically choose system utilization features as exogenous inputs. In Fig. 2, ud stands for the dth dimension of the input feature vector. NARX's advantage over NAR is that it explicitly associates current system power to both performance features and historical power. However, NARX increases the risk of over-fitting as the size of model input is enlarged.

Fig. 2. - 
The network structure of NARX power model
Fig. 2.
The network structure of NARX power model

Show All

3.3 ENN Model
Elman Neural Network (ENN) [31], proposed by Jeffrey Elman, is also referred to as Simple Recurrent Neural Network. ENN was first applied to automatic speech processing and soon proved effective in a wide range of time-series processing tasks. Different from Jordan Neural Network (e.g., NAR and NARX), the ultimate output of ENN is not directly fed back to the input layer. Instead, ENN relies on a layer named “states” to learn the temporal pattern within the time-series input (e.g., a power sequence measured at fixed intervals). The key difference between states (or a state layer) and an ordinary hidden layer is that there are local feedback connections within the state layer. In other words, a state neuron takes its output at the last moment as a part of input, which consequently makes a single state layer equivalent to a combination of multiple hidden layers in the process of forward propagation.

Elman neural network is essentially a basic form of recurrent neural network with a single hidden layer. ENN is widely adopted in time-series processing because its complexity is adequate for many applications like discrete signal analysis, dynamic systems [34] and predictions [35], [36]. Fig. 3 shows the network structure of a typical ENN power model, where sq(t) denotes the output of a neuron at time t in the state layer. The state layer of ENN contains local feedback (current states take as input the output of previous states) and thus plays the role of memory. This structure enables the hidden layer to retain the impact of previous data input on current feed-forward process and the memory in turn affects the next forward propagation after being updated. Therefore, ENN is an ideal model for processing time series of power consumption.


Fig. 3.
The network structure of ENN power model.

Show All

Elman Neural Network is usually trained using Back Propagation Through Time (BPTT) algorithm which shares similar backward propagation process with BP except that error is propagated back through time in the state layer. A specific hyper-parameter, steps_back, is needed to limit the back-propagation distance during ENN's training, and its optimal value basically depends on the temporal pattern of the target sequence.

According to BPTT training process, error in state layer propagates through time because the output of a state unit at time t depends on its output at time t−1:
st=f(Wxt+Ust−1+b),(1)
View Sourcewhere f is the activation function, st and xt denote the vectors of state layer output and features input, respectively. W and U are the matrices that consist of vectors of weights corresponding to performance features and local feedback of states, respectively. b is the bias vector. Let yt and Et denote ENN model's output and the loss computed at time t, respectively. Thus, the gradient of loss function with respect to W and U, according to the chain rule, can be respectively formulated as bellows:
∂Et∂W=∑tk=0∂sk∂W(∏tj=k+1∂sj∂sj−1)∂yt∂st∂Et∂yt(2)
View Source
∂Et∂U=∑tk=0∂sk∂U(∏tj=k+1∂sj∂sj−1)∂yt∂st∂Et∂yt,(3)
View Sourcewhere ∂sj/∂sj−1 is the derivative of the activation function. Examining (1) (2) and (3), it can observe that the term ∏tj=k+1∂sj/∂sj−1 exponentially increases (i.e., exploding gradient) or approaches zero (i.e., vanishing gradient) if we adopt commonly-used activation functions such as sigmoid or tanh. This phenomenon leads to the major limitation of ENN model but can be optimized by leveraging different activation functions, imposing limits on gradients, applying truncated BPTT algorithm [32], and using evolutionary methods [33] to accelerate training.

Table 1 summarizes the advantages and limitations of the ANN structures that are applicable to modeling time series of power.

TABLE 1 The Advantages and Limitations of Using BPNN, NAR, NARX or ENN to Model Power Consumption

From Table 1 we can see that ENN power model has clear advantages over other neural network structures. ENN model works independently on historical data and is able to learn the association between power consumption data regarding time dimension. Therefore, we propose to use ENN to build cloud server power model, namely PCM-ENN. To reduce the complexity in training, we leveraged BPTT algorithm with a short time step.

SECTION 4PCM-ENN
We introduce the proposed power consumption model based on Elman neural network (PCM-ENN) in this section. First, the network structure is introduced including the design of input layer, output layer, state layer, and the selection of activation function. We then discuss the methods we applied to model training optimization.

4.1 Model Design
The proposed PCM-ENN is an end-to-end black box power consumption model. Black box model stands for modeling method that treats the target system as a whole despite of its internal functioning. Multivariate regression model, for instance, is a typical black box model as the coefficients are usually not interpretable, whereas power models at component level [11] are white box models since system power is clearly decomposed as the summation of individual components’ power.

We selected CPU utilization, memory usage, disk throughput and disk IO request rate as our model's input, considering that they are the most commonly-used, easy-to-sample features for cloud server power models. The size of state layer is a tunable hyper-parameter in our model and will be decided through experiments. We will discuss it in the experimental evaluation section. We choose tanh (i.e., f(x)=(ex−e−x)/(ex+e−x)) and purelin (i.e., f(x)=x) as the activation functions of state layer and output layer, respectively.

We set our model's input layer size to 4(d=4), state layer size q (q should be determined through experiment) and only one neuron in the output layer. The output of PCM-ENN is an estimate of power consumption. We adopt different activation functions, weight initializers and bias initializers for the state layer and output layer. Note that we use tanh as the activation function of each state neuron because truncated BPTT can well eliminate the problem of vanishing or exploding gradients.

4.2 Model Training Optimization
Elman neural network, as a kind of recurrent neural network, is usually trained using Back Propagation Through Time (BPTT) algorithm. However, gradients diminish rapidly during back-propagation with long input sequence. Thus, we used Truncated BPTT algorithm to accelerate the training process of PCM-ENN. Truncated BPTT imposes a limit on the steps that training error propagates back through time in the state layer. Besides, we made use of regularization and early-stopping to eliminate over-fitting. Regularization is applied by adding an extra term to the calculation of loss for restricting the weight values. Early-stopping is a technique that terminates the training process according to some rule for the conservation of best model parameters before over-fitting occurs. The stopping rule we adopted is that validation error remains non-decreasing for a number of epochs. We did not adopt “dropout” since PCM-ENN is not of high complexity in structure.

SECTION 5Experimental Evaluation
In this section we briefly introduce experimental setup including the power consumption data set and parameter settings. Then we demonstrate the evaluation results of PCM-ENN against some baselines including NARX power model, the multivariate linear regression model, and the power monitoring software Joulemeter released by Microsoft.

5.1 Experimental Setup
We implemented, trained and evaluated PCM-ENN and NARX network using Python language based on the machine learning framework TensorFlow. The libraries we used mainly include Tensorflow1 1.6.0, Numpy 1.14.2, Scipy 1.0.1, and Scikit-learn 0.19.1. With Scikit-learn library, we utilized the class LinearRegression in the module linear_model to implement the multivariate linear regression model. We launched performance counters to collect CPU utilization, memory usage, disk throughput rate, and disk I/O operation rate while system power was obtained via an external metering device (model: Wattsup?Pro) with logging function.

To cover the diversity of server hardware and operating systems, we investigate the accuracy of power models on two data sets, which were sampled on servers with completely different hardware and operation systems running different suites of benchmarks.

On a Tower Server with Windows. The first data set used in our experiment was sampled on a Dell PowerEdge T110 server with Windows Server 2008 R2 sp1 as operating system. We use PCMark2 7(subversion: v1.4.0) to generate different types of workload (e.g., computation-intensive and storage-intensive). PCMark contains multiple benchmark suites. To enable the model to generalize to a wide range of workload, different benchmark suites were exploited including Computation Suite (CPU-intensive), System Storage Suite (Memory and I/O-intensive), and Productivity Suite (mixed workload, for validation and testing).

On a Blade Server with Linux. The second data set used was sampled on a Blade server (model: Dell R730) with Centos 7.6 (kernel version: 3.10.0) as operating system. We use a combination of Linux benchmarks to generate diverse workload. Specifically, they are CloudSuite 3.0 [37], Sysbench3 and IOzone4. Sysbench and IOzone are common benchmarks for testing Linux systems performance. CloudSuite, developed by a community, is a benchmark suite for cloud services consisting of eight popular applications in datacenters. They are based on real-world workload and represent practical setups in production environments.

Table 2 describes the two data sets we used in the experiments. Each data set is divided into training set and test set from which a part of data is used for validation. We normalized all the features as well as power in pre-processing since ENN is sensitive to the range of input and output values. We applied a simple min-max transformation where all the fields are mapped to [0, 1]. The transformation is formulated as (4):
z~d=zd − min(zd)max(zd )−min(zd),d=1,2,3,4,5,(4)
View SourceRight-click on figure for MathML and additional features.where z~d is the dth field (totally five fields including four features and power consumption) after standardization and zd is the original value. Standardization of model's input and output makes the model incompletely end-to-end. Therefore, we adopt a pre-processing module in the overall workflow to standardize input in advance and a post-processing module to inversely convert the model's output to the range of power consumption.

TABLE 2 Descriptions of the Power Data Sets Used in Our Experiments
Table 2- 
Descriptions of the Power Data Sets Used in Our Experiments
As mentioned in Section 4.2 we applied regularization and early-stopping to reduce the risk of over-fitting. After rounds of tests we finally selected L2 regularization and set lambda (impact of regularization term) to 0.0003. Observing that the model usually converged within tens of epochs, we used a small value of patience in order to optimize the training process.

5.2 Hyper-Parameter Optimization
We mainly discuss two hyper-parameters, namely state_size and steps_back, which make significant impact on the performance of PCM-ENN. We in the experiment set state_size to 6, 9, 12 and 15, in turn, while steps_back were set to 1, 2 and 3, in turn. The result on data set 1 is shown in Fig. 4. Similar results were observed on data set 2.

Fig. 4. - 
PCM-ENN's mean relative error with different state_size and steps_back settings.
Fig. 4.
PCM-ENN's mean relative error with different state_size and steps_back settings.

Show All

It is notable from Fig. 4 that the best setting of steps_back is 1. The reason is that the temporal correlation becomes much weaker when the time interval between two records increases. We also investigated the number of training epochs (iterations through all batches) before the model's convergence with different state_size and steps_back. The result is shown in Table 3, with the first number indicating the number of epochs needed and the second mean relative error (MRE) of the trained model. It can be noted that the model converged quickly when we set a short back-propagation time step (steps_back=1or2). The reason is that the truncated BPTT algorithm effectively accelerated the training process by limiting the back-propagation of errors along the dimension of time. We also find that the number of neurons in the state layer (state_size) does not make significant impact on the model's accuracy. It implies that the complexity of ENN with dozens of state neurons is sufficient for modeling server power consumption on our data set. According to the result, we finally set steps_back to 1 and the number of neurons in state layer to 12.

TABLE 3 The Number of Training Epochs and Model's MRE with Different Settings of State_Size and Steps_Back

5.3 Experimental Results
This section reports our experimental evaluation of the proposed power consumption model based on ENN. For comparison, we trained an NARX network on the same dataset and tuned its hyper-parameters until attaining its best accuracy. We also fitted multivariate linear regression models using Scikit-learn5, with the same set of features on the two data sets mentioned in Section 5.1, as shown in (5) and (6), respectively:
p~LR,1=26.57+25.94ucpu+0.97umem+0.03mdisk−0.0002rdisk(5)
View Source
p~LR,2=41.72+27.62ucpu+13.14umem−0.023mdisk−0.0054rdisk,(6)
View Sourcewhere ucpu,umem,mdisk and rdisk are CPU utilization, memory usage, disk throughput rate and IO request rate, respectively. We choose linear regression and NARX network as baselines because they are the most representative, commonly used models for regression problems that are time-independent or time-relevant, respectively. In addition, we launched a Windows power monitoring software, named Joulemeter [16], to estimate server power on a regular basis, and we set its interval to 1 second.

The functioning of Joulemeter relies on several built-in component power models of three major components (CPU, memory and hard disk). Its Developers from Microsoft adopt a linear model for each of them.

The estimated server power consumption by PCM-ENN, NARX model, linear regression model and Joulemeter (exclusive on Windows) on the two test data sets are drawn in Figs. 5 and 6, respectively. Actual power (ground truth) measured by the external meter is shown as the black solid line.


Fig. 5.
Comparing measured power data with estimated values by (a) PCM-ENN, (b) NARX network model, (c) linear regression model, and (d) Joulemeter over the running of windows benchmark (PCMark 7) on Dell PowerEdge T110 tower

Show All


Fig. 6.
Comparing measured power data with estimated values by (a) PCM-ENN, (b) NARX network model, and (c) linear regression model over the running of Linux benchmarks (CloudSuite + Sysbench + IOzone) on Dell PowerEdge R730 Blade

Show All

PCM-ENN precisely estimated the server's power consumption throughout the test period though some of the power peaks/troughs were under/over-estimated (e.g., the trough starting at the 227th second in data set 1 and the peak around the 850th second in data set 2). We think the reasons behind are two-fold. On one hand, the memorized “states” of the hidden layer “smooth” the estimate sequence but, from a holistic prospective, improve overall accuracy. On the other, extreme values are rare and may not appear in the training set to learn. For instance, server power reached 154.3 Watts at the 882nd second on R730 but the maximum value in the training set is merely 138.0, which probably leads to misestimate in extremely power-intensive situations. The estimates by Joulemeter and regression model deviated significantly from the real values in many periods (e.g., period from 130 to 140 on data set 1 and that from 530 to 760 on data set 2) and tended to overestimate the peaks. NARX network yielded better results than regression model, but it under-estimated the server's power consumption at the ending period of both tests.

To further clarify their accuracy, we computed every power model's mean absolute error (MAE), root mean square error (RMSE), maximum relative error (max_RE), and mean relative error (MRE). The statistical results on both data sets are summarized in Table 4.

TABLE 4 Statistical Comparison of Power Models’ Accuracy on Data Set 1 (Windows Benchmarks, Dell PowerEdge T110) and Data Set 2 (Linux Benchmarks, Dell PowerEdge R730)

We can conclude from Table 4 that the proposed power model PCM-ENN is of remarkable accuracy in the tests on the two heterogeneous machines, with relative error smaller than 4 and 2 percent, respectively. The result also shows its strong ability to generalize learning from the fact that PCM-ENN's maximum errors are apparently smaller than NARX, regression model, and Joulemeter even when the test sets contain more extreme values than the training sets.

We drew CDF (Cumulative Distribution Function) curves to better demonstrate how the four power estimators performed on the two test platforms. The curves are obtained by calculating relative error on each power record. The results are shown in Fig. 7. It can be observed from the error distribution (Fig. 7) that the deviations of PCM-ENN's output from real power are basically within a small margin, with 50 percent/80 percent of the estimate values above 95 percent accurate, while over 90 percent/97 percent of them above 90 percent accurate on data set 1 and 2, respectively. For regression model and the monitoring software Joulemeter, it is notable that more than 10 percent of their estimated values are below 90 percent accurate on the tower server. An important reason is that they are too sensitive to the changes of input features and, consequently, tend to make significantly jittering estimates on servers’ power, especially in case power peaks and troughs appear. Besides, we observe that only a tiny fraction of estimates by PCM-ENN is of relative error over 12 percent, whereas the regression model and Joulemeter are more likely to make deviated estimates. NARX network performed slightly better than regression model, with relative error averaging at 4.3 and 3.1 percent on the two servers respectively.


Fig. 7.
Cumulative Distribution Function of estimation error produced by PCM-ENN, NARX model, regression model and Joulemeter (exclusive on Windows) throughout the test on (a) Dell PowerEdge T110 Windows server and (b) Dell PowerEdge R730 Linux Server

Show All

Fast training is also a key feature especially in heterogeneous environments. We summarize the training cost of PCM-ENN for both T110 and R730 in Table 5. Besides, we also evaluate the cost of re-training when transplanting the model for T110 to fit the power behavior of R730. In this case, the original model saved for T110 can be reckoned as a pre-trained one. From the result we can see that the training finishes in a few seconds (on a personal notebook PC) as only less than 10 epochs are needed for convergence. Table 5 also shows a slightly reduction of time cost (roughly 6.7 percent) when pre-training is applied.

TABLE 5 Training Overheads of PCM-ENN for Servers T110 and R730

Overall, the experimental evaluation demonstrates that our proposed model based on Elman neural network is of high accuracy for server power estimation. It also reflects the model's ability to generalize as it can well perform on comprehensive workload on different hardware and platforms whilst supporting fast training and pre-training.

SECTION 6Conclusions
In this paper we first summarize several forms of neural networks that can be applied to cloud server power modeling on time-series datasets. Through analyzing their advantages and limitations, we figure out that ENN is the most suitable among the candidate models for estimating server power consumption as a time series in heterogeneous environment like clouds. Then with the aim of realizing real-time power consumption estimation we propose a novel cloud server power model, namely PCM-ENN. PCM-ENN is an end-to-end black box model that takes easy-to-collect, platform-independent performance features as input, and outputs an estimated value of server power. We trained the model on two datasets collected from a tower server and a blade server by running multiple types of workload after empirically determining the model's optimal hyper-parameters. The evaluation results of PCM-ENN with other baseline models show its high accuracy, fast training as well as strong ability to generalize what it learned from a limited amount of training data to a more complex test scenario with mixed workload.

We plan to focus our future work on increasing the model's feature dimension by considering more performance and state features. With a larger number of available features, feature selection and dimensionality reduction probably need to be done. Alternatively, principal component methods can be adopted to build separate feature sets for different types of workload, which enables the power estimator to be workload-aware for accuracy improvement. We are also trying to further improve our power model's accuracy and efficacy through exploring more complex forms of networks like streaming models.