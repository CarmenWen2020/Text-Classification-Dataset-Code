We consider the computation offloading problem in an edge computing system in which an operator jointly manages wireless and computing resources across devices that make their offloading decisions autonomously with the objective to minimize their own completion times. We develop a game theoretical model of the interaction between the devices and an operator that can implement one of two resource allocation policies, a cost minimizing or a time fair resource allocation policy. We express the optimal cost minimizing resource allocation policy in closed form and prove the existence of Stackelberg equilibria for both resource allocation policies. We propose two efficient decentralized algorithms that devices can use for computing equilibria of offloading decisions under the cost minimizing and the time fair resource allocation policies. We establish bounds on the price of anarchy of the games played by the devices and by doing so we show that the proposed algorithms have bounded approximation ratios. Our simulation results show that the cost minimizing resource allocation policy can achieve significantly lower completion times than the time fair allocation policy. At the same time, the convergence time of the proposed algorithms is approximately linear in the number of devices, and thus they could be effectively implemented for edge computing resource management.
Published in: IEEE Transactions on Cloud Computing ( Volume: 9, Issue: 4, Oct.-Dec. 1 2021)
Page(s): 1507 - 1520
Date of Publication: 20 June 2019 
ISSN Information:
INSPEC Accession Number: 21339648
DOI: 10.1109/TCC.2019.2923768
Publisher: IEEE
Funding Agency:
SECTION 1Introduction
The evolution of wireless access and the Internet of Things are driving the development of a variety of mobile applications such as face and object recognition, mobile augmented reality, and cognitive assistance [1], [2], [3]. These emerging human-in-the-loop applications have delay and computational requirements that often surpass the capabilities of handheld devices [4].

A promising approach to support these emerging applications is mobile edge computing (MEC) [5]. The key idea of MEC is to move cloud resources towards the network edge so as to overcome the issue of high end-to-end transmission delays, which are inherent to computation offloading to remote centralized clouds such as Microsoft Azure or Amazon EC2 [6]. Owing to the proximity of computing resources to the end users, MEC has the potential to significantly reduce response times for individual devices by allowing them to offload the computationally intensive tasks through a wireless network to nearby edge clouds. However, computation offloading to edge clouds imposes a huge load on limited wireless and computing resources, and thus the response times might be adversely affected by the contention for MEC resources.

In order to keep response times as low as possible, it is thus essential to jointly manage the wireless and the computing resources. Nonetheless, joint resource management in a MEC system is inherently challenging for various reasons. First, it requires one to take into consideration the heterogeneity of the devices and their workloads. For example, the devices can differ in terms of their computing capabilities, the amount of data they need to offload and the delay and the computational requirements of the tasks they generate. Second, devices in MEC systems are likely to be autonomous entities, and thus they may be interested in maximizing their own performance [7], [8]. Finally, MEC systems may consist of multiple heterogeneous communication and computing resources, e.g., wireless access points with different bandwidths and edge clouds with different computing capabilities. Therefore, the joint management of wireless and computing resources in MEC systems should be performed in accordance with the individual interest of the heterogeneous devices, the characteristics of their tasks and the heterogeneity of the infrastructure.

In this paper we consider devices that aim at minimizing the completion times of their own tasks, and we address the corresponding computation offloading problem by considering the interaction between an operator that jointly manages the wireless and computing resources, and devices that decide autonomously whether or not to offload the computations and in the case of offloading which of multiple heterogeneous wireless and computing resources to use. We model the problem as a multiple-leader common-follower Stackelberg game, in which devices are leaders and the operator is the follower. We consider two resource allocation policies for the operator, called the cost minimizing and the time fair resource allocation policy. We show that the resulting games played by the devices can be transformed into a weighted congestion game and into a player-specific congestion game under the cost minimizing and the time fair policy, respectively. We provide a closed form solution for the optimal cost minimizing resource allocation policy and we prove that Stackelberg equilibria exist for both policies. Based on our constructive equilibrium existence proofs, we propose two efficient decentralized algorithms that devices can use for computing offloading decisions under the cost minimizing and the time fair policy of the operator, respectively. We provide upper bounds on the price of anarchy of the games played by the devices, and thus we show that our proposed algorithms serve as approximation algorithms for the completion time minimization problems defined for the cost minimizing and the time fair resource allocation policies. Our analytical results show that the cost minimizing policy can guarantee better performance in terms of the worst case system cost and that the time fair policy can guarantee better performance in terms of the worst case computational complexity. Finally, we use simulations to show that the completion times achieved under the cost minimizing policy are significantly lower than the completion times achieved under the time fair policy and that the complexity of computing an equilibrium is on average almost linear in the number of devices for both policies.

The rest of the paper is organized as follows. We present the system model and the problem formulation in Section 2. We present the cost minimizing resource allocation policy and prove the existence of Stackelberg equilibria in Section 3. We present the time fair resource allocation policy and prove the existence of Stackelberg equilibria in Section 4. We provide a bound on the price of anarchy of the games in Section 5 and present numerical results in Section 6. We discuss related work in Section 7 and conclude the paper in Section 8.

SECTION 2System Model
We consider an edge computing system that consists of a set N={1,2,…,N} of wireless devices (WDs), a set A={1,2,…,A} of access points (APs), a set C={1,2,…,C} of edge clouds (ECs), and an operator that manages the allocation of the wireless and computing resources. We denote by Ai⊆A the set of APs through which WD i∈N can communicate with the ECs. For ease of reference, the key notations used in the paper are summarized in Table 1.

TABLE 1 Summary of Key Notations

Each WD i∈N generates computationally intensive tasks, which can be characterized by two parameters, the size Di of the input data and the expected number Li of CPU cycles required to perform the computation (e.g., in bits). As shown by recent works, the number X of CPU cycles required per data bit can be approximated by a Gamma distribution [9], [10]. Hence, based on the empirical mean E[X], the relationship between Li and Di can be expressed as Li=DiE[X]. To make the analysis tractable, we make the common assumption that the set of WDs is known (e.g., through signaling) [11], [12].

Each WD i∈N can decide whether to perform the computation locally or to offload the computation to one of the ECs c∈C through one of the APs a∈Ai. Thus, the set of feasible decisions for WD i is Di={i}∪{(a,c)|a∈Ai,c∈C}, where i corresponds to local computing and (a,c) to offloading through AP a to EC c. We refer to decision di∈Di of WD i as its strategy, and we refer to the collection d=(di)i∈N as a strategy profile, i.e., d∈×i∈NDi=D. For a strategy profile d∈D, we define the set Oa(d)≜{i|di=(a,⋅)} of WDs that offload their tasks through AP a and we denote by na(d)≜|Oa(d)| the number of WDs that offload their tasks through AP a. Similarly, we define the set Oc(d)≜{i|di=(⋅,c)} of WDs that offload their tasks to EC c and we denote by nc(d)≜|Oc(d)| the number of WDs that offload their tasks to EC c. Finally, we define the set O(a,c)(d)≜Oa(d)∩Oc(d) of WDs that offload their tasks through AP a to EC c and the set O(d)≜∪c∈COc(d) of all WDs that offload their tasks.

Fig. 1 shows an example of a MEC system that consists of N=5 WDs, C=2 ECs and A=3 APs. WD 1 performs the computation locally, WDs 2 and 3 offload their tasks to EC c1 through AP a, WDs 4 and 5 offload their tasks to EC c2 through APs b and c, respectively. In what follows we discuss our models of computing and wireless resource management.


Fig. 1.
Example of an edge computing system with N=5 WDs, C=2 ECs and A=3 APs. Transmission rates and cloud computing power may be actively managed by the operator.

Show All

2.1 Computing Resource Management
A WD that chooses local computing performs its task using its local computing resources. We denote by F^l_i the computational capability of WD i\in {\mathcal {N}} (e.g., CPU cycles/second). A WD that chooses offloading has to transmit the data through an AP a, after which the task is performed in an EC c. We denote by F^c the computing capability of EC c. We consider that the computing capability allocated to WDs i\in O_c(\mathbf{d}) is determined by the operator’s computing resource allocation policy \mathcal{P}_c: \mathfrak {D}\rightarrow \mathbb {R}_{\geq 0}^{|{\mathcal {C}}|x|{\mathcal {N}}|}. The policy sets for every strategy profile \mathbf{d}\in \mathfrak {D} the computing power provisioning coefficients (p_{i,c})_{i\in {\mathcal {N}},c\in {\mathcal {C}}}, akin to the weight of a job in generalized processor sharing (GPS). Using the shorthand notation \mathbf{p}_c= (p_{i,c})_{i\in {\mathcal {N}}}, we can express the computing capability allocated to WD i by EC c as \begin{equation*} F^c_i(\mathbf{d},\mathbf{p}_c) = F^c\frac{p_{i,c}}{\sum _{j\in O_c(\mathbf{d})}{p_{j,c}}}. \tag{1} \end{equation*}
View SourceRight-click on figure for MathML and additional features.Observe that for a policy that sets p_{i,c} = 1, \forall i\in O_{c}(\mathbf{d}),3\forall \mathbf{d}\in \mathfrak {D}, the computing power is shared equally. While GPS is an ideal scheduler, several process schedulers exist to approximate it in practice, e.g., DWRR [13].

2.2 Wireless Resource Management
The wireless medium of AP a is shared by the WDs that choose to offload through AP a. We denote by R_{i,a} the achievable PHY rate of WD i through AP a, which is determined by the physical characteristics of the wireless medium, distance, etc. The actual rate at which WD i can offload its data through AP a is determined by the operator’s rate allocation policy \mathcal{P}_r: \mathfrak {D}\rightarrow \mathbb {R}_{\geq 0}^{|{\mathcal {A}}|x|{\mathcal {N}}|}. The policy sets for every strategy profile the uplink access provisioning coefficients (u_{i,a})_{i\in {\mathcal {N}},a\in {\mathcal {A}}}, akin to the weight of a flow in GPS. Using the shorthand notation \mathbf{u}_a = (u_{i,a})_{i\in {\mathcal {N}}}, we can express the uplink rate assigned to WD i at AP a as \begin{equation*} \omega _{i,a}(\mathbf{d},\mathbf{u}_a) = R_{i,a}\frac{u_{i,a}}{\sum _{j\in O_a(\mathbf{d})}{u_{j,a}}}. \tag{2} \end{equation*}
View SourceObserve that for a policy that sets u_{i,a}(\mathbf{d}) = 1,\forall i \in O_{a}(\mathbf{d}) we obtain the model that describes the time-fair throughput sharing mechanisms in TDMA and OFDMA based MAC protocols [14].

2.3 Cost Model
We define the cost of a WD as the completion time of its task. In what follows we introduce our cost model in the case of computation offloading and in the case of local computing.

Computation Offloading. In the case of computation offloading the completion time of WD i’s task consists of two parts. The first part is the time needed to transmit D_i amount of data, and the second part is the time needed to perform L_i CPU cycles at the cloud server. Thus, if in strategy profile \mathbf{d} WD i offloads to EC c\in {\mathcal {C}} through AP a\in {\mathcal {A}}_i then its cost can be expressed as \begin{equation*} C^c_{i,a}(\mathbf{d},\mathbf{u}_a,\mathbf{p}_c) = D_i/\omega _{i,a}(\mathbf{d},\mathbf{u}_a) + L_i/F^c_i(\mathbf{d},\mathbf{p}_c). \tag{3} \end{equation*}
View SourceIn (3) we made the common assumption that the time needed to transmit the results from the cloud to the device can be neglected [11], [15], [16], [17], as for typical applications (e.g., face and object recognition), the size of the result of the computation is much smaller than D_i.

Local Computing. In the case of local computing the completion time of WD i’s task is determined by the number L_i of CPU cycles pertaining to the task and by the computing capability F^l_i. Thus, the local computing cost can be expressed as \begin{equation*} C^l_i= L_i/F^l_i. \tag{4} \end{equation*}
View Source

Total Cost. To define the total cost, we first define the shorthand notation \mathbf{u}\triangleq (\mathbf{u}_a)_{a\in {\mathcal {A}}} and \mathbf{p}\triangleq (\mathbf{p}_c)_{c\in {\mathcal {C}}}, and express the cost of WD i \begin{equation*} C_i(\mathbf{d},\mathbf{u},\mathbf{p}) = \sum \limits _{(a,c) \in {\mathcal {A}}_i\times {\mathcal {C}}} I_{d_i,(a,c)} C^c_{i,a}(\mathbf{d},\mathbf{u}_a,\mathbf{p}_c) + I_{d_i,i}C^l_i, \tag{5} \end{equation*}
View Sourcewhere I_{d_i,r} = 1 if d_i= r and I_{d_i,r} = 0 otherwise. Finally, we define the system cost C(\mathbf{d},\mathbf{u},\mathbf{p}) as \begin{equation*} C(\mathbf{d},\mathbf{u},\mathbf{p}) =\sum \limits _{i\in {\mathcal {N}}} \sum \limits _{(a,c) \in {\mathcal {A}}_i\times {\mathcal {C}}} I_{d_i,(a,c)} C^c_{i,a}(\mathbf{d},\mathbf{u}_a,\mathbf{p}_c) + \sum \limits _{i\in {\mathcal {N}}} I_{d_i,i}C^l_i. \tag{6} \end{equation*}
View Source

2.4 Operator Policies and Problem Formulation
We consider that in the edge computing system each WD is allowed to make an offloading decision so as to minimize its own cost. On the one hand, this assumption is motivated by the potential autonomy of WDs in edge computing systems [7], [8]. On the other hand, the obtained decentralized algorithms can serve as a good approximation for the optimal solution. Nonetheless, the decisions of the WDs interact with the computing resource and rate allocation policies of the operator, and hence we model the problem as a multiple-leader common-follower Stackelberg game, in which WDs are leaders and the operator is the follower. We consider two variants of the game, which differ in the set of operator policies. In the first game the set of feasible decisions for the operator is \mathfrak {A}_c = \lbrace (\mathbf{u}, \mathbf{p})| \mathbf{u}\in \mathbb {R}_{\geq 0}^{|{\mathcal {A}}|x|{\mathcal {N}}|}, \mathbf{p}\in \mathbb {R}_{\geq 0}^{|{\mathcal {C}}|x|{\mathcal {N}}|}\rbrace; we refer to this as the cost minimizing (CM) operator. In the second game the set of feasible decisions for the operator is \mathfrak {A}_t = \lbrace (\mathbf{u}, \mathbf{p})| u_{i,a} = 1, p_{i,c} = 1, \forall i\in {\mathcal {N}}, a\in {\mathcal {A}}, c\in {\mathcal {C}}\rbrace; we refer to this as the time fair (TF) operator.

Given a strategy profile \mathbf{d} chosen by the WDs, the objective of the operator is to minimize the system cost by jointly optimizing the allocation of wireless and computing resources. It does so by computing a best response (\mathbf{u}^{\ast},\mathbf{p}^{\ast}) \in \mathfrak {A}_{o}, o\in \lbrace c,t\rbrace to \mathbf{d} through solving \begin{align*} &\mathop{\min \limits} _{(\mathbf{u},\mathbf{p}) \in \mathfrak {A}_{o}} C(\mathbf{d},\mathbf{u},\mathbf{p}). \tag{7} \end{align*}
View SourceWe denote by (\mathcal{P}^{c,*}_r, \mathcal{P}^{c,*}_c) the optimal policy of the CM operator, i.e., the collection of best responses of the CM operator for every \mathbf{d}\in \mathfrak {D}, and we denote by (\mathcal{P}^{t,*}_r, \mathcal{P}^{t,*}_c) the optimal policy of the TF operator, i.e., the collection of best responses of the TF operator for every \mathbf{d}\in \mathfrak {D}.

The objective of every WD is to minimize its own completion time (5), given the announced allocation policy (\mathcal{P}_{r}^{\ast},\mathcal{P}_{c}^{\ast}) of the operator, through solving \begin{equation*} \mathop{\min \limits} _{d_i\in \mathfrak {D}_i}C_{i}(d_i,d_{-i},\mathcal{P}_{r}^{\ast}(d_i,d_{-i}),\mathcal{P}_{c}^{\ast}(d_i,d_{-i})), \tag{8} \end{equation*}
View Sourcewhere we use d_{-i} to denote the strategies of all WDs except WD i. We refer to the game played between the WDs and the CM operator as the cost minimizing computation offloading game (CM-COG) and to the game played between the WDs and the TF operator as the time fair computation offloading game (TF-COG).

In this paper we address three fundamental questions for these games. First, we address whether there is a combination of computation offloading strategy profile and allocation policy from which neither the WDs nor the operator have an incentive to deviate, i.e., a subgame perfect equilibrium of the Stackelberg game.

Definition 1 (SPE).
Let (\mathcal{P}_{r}^{\ast},\mathcal{P}_{c}^{\ast}) be a solution of (7), and d_i^{\ast} be a solution of (8). Then the point (\mathbf{d}^{\ast},\mathcal{P}_{r}^{\ast},\mathcal{P}_{c}^{\ast}) is a subgame perfect equilibrium (SPE) of the game \Gamma \in \lbrace \mathrm{CM}{-}COG,TF{-\mathrm {COG}}\rbrace if for any feasible (\mathbf{d},\mathcal{P}_r,\mathcal{P}_c) point the following holds \begin{equation*} C(\mathbf{d}^{\ast},\mathcal{P}_{r}^{\ast},\mathcal{P}_{c}^{\ast}) \leq C(\mathbf{d}^{\ast},\mathcal{P}_r,\mathcal{P}_c), \end{equation*}
View SourceRight-click on figure for MathML and additional features.\begin{equation*} C_i(d_i^{\ast},d_{-i}^{\ast},\mathcal{P}_{r}^{\ast},\mathcal{P}_{c}^{\ast}) \leq C_i(d_i,d_{-i}^{\ast},\mathcal{P}_{r}^{\ast},\mathcal{P}_{c}^{\ast}), \forall d_i\in \mathfrak {D}_i, \forall i\in {\mathcal {N}}. \end{equation*}
View SourceRight-click on figure for MathML and additional features.

If the game \Gamma \in \lbrace \mathrm {CM{-}COG,TF{-}COG}\rbrace admits an SPE, the second question is whether an SPE can be computed efficiently. Third, we address whether the system cost in an SPE is efficient compared to a centrally optimized system. Before we answer these questions we recall the following definition from game theory.

Definition 2 (Pure NE and Best reply (BR)).
A pure strategy Nash equilibrium (NE) is a strategy profile \mathbf{d}^{\ast} in which all players play their best replies to each others’ strategies, that is, \begin{equation*} C_{i}(d^{\ast}_i,d^{\ast}_{-i})\leq C_{i}(d_i,d^{\ast}_{-i}), \forall d_{i} \in \mathfrak {D}_i, \forall i\in {\mathcal {N}}. \end{equation*}
View SourceGiven a strategy profile d=(d_i,d_{-i}), a better reply of WD i is a strategy d^\prime _i such that C_{i}(d^\prime _i,d_{-i}) < C_{i}(d_i,d_{-i}), and a best reply of WD i is a better reply d^{\ast}_i such that C_{i}(d^{\ast}_i,d_{-i}) \leq C_{i}(d_i,d_{-i}), \forall d_i\in \mathfrak {D}_i.

SECTION 3Equilibria Under the Cost Minimizing Operator
We start the analysis by considering problem (7) solved by the CM operator, i.e., \begin{align*} &\mathop{\min \limits} _{(\mathbf{u},\mathbf{p}) \in \mathfrak {A}_c} C(\mathbf{d},\mathbf{u},\mathbf{p}), \tag{9} \end{align*}
View Sourcefollowed by problem (8) solved by the WDs.

3.1 Optimal Resource Allocation Policy of the CM Operator
Recall that an optimal resource allocation policy is essentially a collection of best responses (\mathbf{u}^{\ast},\mathbf{p}^{\ast}) \in \mathfrak {A}_c of the CM operator to the strategy profiles \mathbf{d}\in \mathfrak {D} played by the WDs. In what follows we show that a best response of the CM operator to a strategy profile \mathbf{d} is unique up to a scale factor and can be expressed in closed form.

Theorem 1.
Let \mathbf{d} be a strategy profile played by the WDs. The optimal allocation policy (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) of the CM operator assigns to \mathbf{d} the uplink access provisioning and computing power provisioning coefficients \begin{align*} u_{i,a}^{\ast} = \frac{\sqrt{D_i/R_{i,a}}}{\sum _{j\in O_{a}(\mathbf{d})}\sqrt{D_j/R_{j,a}}}, \forall a\in {\mathcal {A}}, \forall i\in O_a(\mathbf{d}), \tag{10} \end{align*}
View Sourceand \begin{equation*} p_{i,c}^{\ast} = \frac{\sqrt{L_i/F^c}}{\sum _{j\in O_c(\mathbf{d})}\sqrt{L_j/F^c}}, \forall c\in {\mathcal {C}}, \forall i\in O_c(\mathbf{d}). \tag{11} \end{equation*}
View Source

Proof.
The proof is given in Appendix A, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org.ezproxy.auckland.ac.nz/10.1109/TCC.2019.2923768.

It is important to note that following the optimal resource allocation policy, the CM operator allocates resources to the WDs depending on the characteristics of their tasks (i.e., D_i and L_i). Furthermore, the resource allocation policy of the operator can be made known a priori to the WDs, which allows us to analyze the computation offloading problem of the WDs.

3.2 Computing Equilibrium Offloading Decisions
Observe that for an arbitrary resource allocation policy (\mathcal{P}_r,\mathcal{P}_c) the interaction between the WDs can be modeled by a player-specific weighted congestion game \Gamma (\mathcal{P}_r,\mathcal{P}_c) = {<} {\mathcal {N}},(\mathfrak {D}_i)_{i\in {\mathcal {N}}},({C}_i)_{i\in {\mathcal {N}}} \!{>}\!, as (5) is both a function of the WDs’ parameters and of the resource provisioning coefficients. Unfortunately, for this class of games general equilibrium existence results are not available. In what follows we show that under the optimal resource allocation policy of the CM operator the game can be transformed into a weighted congestion game.

Theorem 2.
Consider that the CM operator uses the optimal policy (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c), i.e., \mathbf{u}^{\ast} and \mathbf{p}^{\ast} are the collections of the optimal provisioning coefficients given by (10) and (11), respectively. Then, the strategic interaction of the WDs can be modeled as a congestion game with resource-dependent weights w_{i,r}, \forall (i,r) \in {\mathcal {N}}\times \lbrace {\mathcal {A}}_i\cup {\mathcal {C}}\rbrace, in which the cost of WD i is given by \begin{equation*} \bar{C}_i(\mathbf{d}) = \sum \limits _{(a,c) \in {\mathcal {A}}_i\times {\mathcal {C}}} I_{d_i,(a,c)} (w_{i,a}w_a(\mathbf{d}) + w_{i,c}w_c(\mathbf{d})) + I_{d_i,i}C^l_i, \tag{12} \end{equation*}
View Sourcewhere w_r(\mathbf{d}) = \sum \nolimits _{j\in O_r(\mathbf{d})}w_{j,r}.

Proof.
Let us first substitute (10) and (11) into (3) in order to obtain the offloading cost of WD i through AP a to EC c under the optimal resource allocation policy (\mathcal{P}^{c,*}_r, \mathcal{P}^{c,*}_c), \begin{align*} \bar{C^c}_{i,a}(\mathbf{d}) = \sqrt{\frac{D_i}{R_{i,a}}} \sum \limits _{j\in O_a(\mathbf{d})} \sqrt{\frac{D_j}{R_{j,a}}} + \sqrt{\frac{L_i}{F^c}} \sum \limits _{j\in O_c(\mathbf{d})} \sqrt{\frac{L_j}{F^c}}. \tag{13} \end{align*}
View SourceSecond, let us define the weight w_{i,a} \triangleq \sqrt{{D_i}/{R_{i,a}}} for each tuple (i,a) \in {\mathcal {N}}\times {\mathcal {A}}_i and the weight w_{i,c} \triangleq \sqrt{{L_i}/{F^c}} for each tuple (i,c) \in {\mathcal {N}}\times {\mathcal {C}}. Observe that the offloading cost (13) in strategy profile \mathbf{d} depends on the total weight w_a(\mathbf{d}) = \sum _{j\in O_a(\mathbf{d})}w_{j,a} associated to AP a and on the total weight w_c(\mathbf{d}) = \sum _{j\in O_c(\mathbf{d})}w_{j,c} associated to EC c. Thus, the interaction between the WDs can be modeled as a weighted congestion game with resource-dependent weights. This proves the theorem.

We refer to the resulting strategic game as \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) = {<} {\mathcal {N}},(\mathfrak {D}_i)_{i\in {\mathcal {N}}},(\bar{C}_i)_{i\in {\mathcal {N}}} \!{>}\!, in which the players are WDs with the objective to minimize their costs given by (12). Observe that the game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) is the CM-COG expressed in strategic form and thus if \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) has a NE then the CM-COG has an SPE. Hence, in what follows we focus on the existence and computability of pure NE for \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c).

Before we formulate our next result let us recall the definition of an exact potential function from [18].

Definition 3.
A function \Phi : \times _i(\mathfrak {D}_i) \rightarrow \mathbb {R} is an exact potential for a finite strategic game \Gamma = {<} {\mathcal {N}},(\mathfrak {D}_i)_{i},(\bar{C}_i)_{i} \!{>} if for an arbitrary strategy profile (d_i,d_{-i}) and for any better reply d_i^\prime the following holds \begin{equation*} \bar{C}i(d_i^\prime,d_{-i}) - \bar{C}_i(d_i,d_{-i}) = \Phi (d_i^\prime,d_{-i}) - \Phi (d_i,d_{-i}). \tag{14} \end{equation*}
View Source

Given an arbitrary ordering of WDs, let us introduce the following shorthand notation, \begin{equation*} w_{a}^{\leq i}(\mathbf{d}) = \sum _{\lbrace j\in O_a(\mathbf{d})| j\leq i\rbrace } w_{j,a}, \qquad w_{a}^{ > i}(\mathbf{d}) = \sum _{\lbrace j\in O_a(\mathbf{d})| j > i\rbrace } w_{j,a}, \end{equation*}
View Sourceand \begin{equation*} w_{c}^{\leq i}(\mathbf{d}) = \sum _{\lbrace j\in O_c(\mathbf{d})| j\leq i\rbrace } w_{j,c}, \qquad w_{c}^{ > i}(\mathbf{d}) = \sum _{\lbrace j\in O_c(\mathbf{d})| j > i\rbrace } w_{j,c}. \end{equation*}
View SourceRight-click on figure for MathML and additional features.

Theorem 3.
The game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) has the exact potential function \begin{equation*} \Phi (\mathbf{d}) = \sum \limits _{i\in {\mathcal {N}}} \left (\sum \limits _{a\in {\mathcal {A}}}\Phi _{i,a}(\mathbf{d}) + \sum \limits _{c\in {\mathcal {C}}}\Phi _{i,c}(\mathbf{d}) + \Phi _{i,i}(\mathbf{d}) \right), \tag{15} \end{equation*}
View SourceRight-click on figure for MathML and additional features.where \Phi _{i,a}(\mathbf{d}) = I_{d_i,(a,\cdot)}w_{i,a}w_{a}^{\leq i}(\mathbf{d}), \Phi _{i,c}(\mathbf{d}) = I_{d_i,(\cdot,c)}w_{i,c}w_{c}^{\leq i}(\mathbf{d}), and \Phi _{i,i}(\mathbf{d}) = I_{d_i,i}C^l_i.

Proof.
Let us define function \Phi _i(\mathbf{d}) = \sum _{a\in {\mathcal {A}}}\Phi _{i,a}(\mathbf{d}) + \sum _{c\in {\mathcal {C}}}\Phi _{i,c}(\mathbf{d}) + \Phi _{i,i}(\mathbf{d}), and rewrite \Phi (\mathbf{d}) = \sum _{i\in {\mathcal {N}}}\Phi _i(\mathbf{d}). To prove that \Phi (\mathbf{d}) is an exact potential function, let us consider strategy profiles \mathbf{d} and \mathbf{d}^\prime such that \mathbf{d} = (d_k,d_{-k}) and \mathbf{d}^\prime = (d_{k}^{\prime },d_{-k}), and consider the following two cases.

Case 1: Changing offloading strategy: We start with considering the case when WD k offloads its task in both strategy profiles \mathbf{d} and \mathbf{d}^{\prime }. Let us denote by d_k= (a,c) and d_{k}^{\prime } = (a^\prime,c^\prime) the offloading decisions of WD k in \mathbf{d} and \mathbf{d}^{\prime }, respectively. If a\ne a^\prime and c\ne c^\prime then the difference between the cost of WD k in \mathbf{d} and that in \mathbf{d}^\prime is given by \begin{align*} \bar{C}_k(\mathbf{d}) - \bar{C}_k(\mathbf{d}^\prime) &= w_{k,a}w_a(\mathbf{d}) + w_{k,c}w_c(\mathbf{d})\\ &\quad - w_{k,a^\prime }w_{a^\prime }(\mathbf{d}) - w_{k,c^\prime }w_{c^\prime }(\mathbf{d}). \end{align*}
View SourceTo compute the change of the potential, observe that \Phi _{i,i}(\mathbf{d}) = \Phi _{i,i}(\mathbf{d}^\prime) for all WDs i\in {\mathcal {N}}, since the set of WDs that perform the computation locally is the same in \mathbf{d} and \mathbf{d}^\prime. We also have that \Phi _{i,r}(\mathbf{d}) = \Phi _{i,r}(\mathbf{d}^\prime) for every resource r\in {\mathcal {A}}\cup {\mathcal {C}}\setminus \lbrace a,a^\prime,c,c^\prime \rbrace since O_r(\mathbf{d}) = O_r(\mathbf{d}^\prime). Furthermore, we observe that \Phi _i(\mathbf{d}) = \Phi _i(\mathbf{d}^\prime) for all WDs i < k. For WDs i > k that offload their tasks through APs a and a^\prime we have that \Phi _{i,a}(\mathbf{d}) - \Phi _{i,a}(\mathbf{d}^\prime) = w_{i,a}w_{k,a} and \Phi _{i,a^\prime }(\mathbf{d}) - \Phi _{i,a^\prime }(\mathbf{d}^\prime) = -w_{i,a^\prime }w_{k,a^\prime }, respectively. Similarly, for WDs i > k that offload their tasks to ECs c and c^\prime we have that \Phi _{i,c}(\mathbf{d}) - \Phi _{i,c}(\mathbf{d}^\prime) = w_{i,c}w_{k,c} and \Phi _{i,c^\prime }(\mathbf{d})\; - \Phi _{i,c^\prime }(\mathbf{d}^\prime) = -w_{i,c^\prime }w_{k,c^\prime }, respectively. For WD k we have the following \begin{align*} \Phi _k(\mathbf{d}) - \Phi _k(\mathbf{d}^\prime) &= w_{k,a}w_{a}^{\leq k}(\mathbf{d}) + w_{k,c}w_{c}^{\leq k}(\mathbf{d})\\ & \quad - w_{k,a^\prime }w_{a^\prime }^{\leq k}(\mathbf{d}) - w_{k,c^\prime }w_{c^\prime }^{\leq k}(\mathbf{d}). \end{align*}
View SourceWe hence obtain the equality \begin{align*} & \Phi (\mathbf{d}) - \Phi (\mathbf{d}^\prime) = w_{k,a}w_{a}^{ > k}(\mathbf{d}) + w_{k,c}w_{c}^{ > k}(\mathbf{d}) - w_{k,a^\prime }w_{a^\prime }^{ > k}(\mathbf{d}) \\ &\quad - w_{k,c^\prime }w_{c^\prime }^{ > k}(\mathbf{d}) + w_{k,a}w_{a}^{\leq k}(\mathbf{d}) + w_{k,c}w_{c}^{\leq k}(\mathbf{d})- w_{k,a^\prime }w_{a^\prime }^{\leq k}(\mathbf{d})\\ &\quad - w_{k,c^\prime }w_{c^\prime }^{\leq k}(\mathbf{d}) = w_{k,a}w_a(\mathbf{d}) + w_{k,c}w_c(\mathbf{d}) - w_{k,a^\prime }w_{a^\prime }(\mathbf{d})\\ &\quad - w_{k,c^\prime }w_{c^\prime }(\mathbf{d}) = \bar{C}_k(\mathbf{d}) - \bar{C}_k(\mathbf{d}^\prime). \end{align*}
View SourceSimilarly, we can show that \Phi (\mathbf{d}) - \Phi (\mathbf{d}^\prime) = \bar{C}_k(\mathbf{d})\; - \bar{C}_k(\mathbf{d}^\prime) if WD k changes only the AP, i.e., if d_k= (a,c) and d_{k}^{\prime } = (a^\prime,c), a\ne a^\prime or if WD k changes only the EC, i.e., if d_k= (a,c) and d_{k}^{\prime } = (a,c^\prime), c\ne c^\prime.

Case 2: Changing between offloading and local computing: We continue with considering the case when WD k offloads its task in one of the strategy profiles \mathbf{d} and \mathbf{d}^\prime and it performs the computation locally in the other strategy profile. Let us first consider that WD k offloads its task in strategy profile \mathbf{d}, and denote by d_k= (a,c) its offloading decision, and that WD k performs the computation locally in strategy profile \mathbf{d}^\prime, i.e., d_{k}^{\prime } = 0. Then the difference between the cost of WD k in \mathbf{d} and that in \mathbf{d}^\prime is given by \begin{equation*} \bar{C}_k(\mathbf{d}) - \bar{C}_k(\mathbf{d}^\prime) = w_{k,a}w_a(\mathbf{d}) + w_{k,c}w_c(\mathbf{d}) - C^l_k. \end{equation*}
View Source

For the potential, we know that \Phi _{i,i}(\mathbf{d}) = \Phi _{i,i}(\mathbf{d}^\prime) for all WDs i\in {\mathcal {N}}\setminus \lbrace k\rbrace and we also have that \Phi _{i,r}(\mathbf{d}) = \Phi _{i,r}(\mathbf{d}^\prime) for every resource r\in {\mathcal {A}}\cup {\mathcal {C}}\setminus \lbrace a,c\rbrace. Furthermore, we observe that \Phi _i(\mathbf{d}) = \Phi _i(\mathbf{d}^\prime) for all i < k. For WDs i > k that offload their tasks through AP a we have that \Phi _{i,a}(\mathbf{d}) - \Phi _{i,a}(\mathbf{d}^\prime) = w_{i,a}w_{k,a}. Similarily, for WDs i > k that offload their tasks to EC c we have that \Phi _{i,c}(\mathbf{d}) - \Phi _{i,c}(\mathbf{d}^\prime) = w_{i,c}w_{k,c}. Finally, for WD k we have \begin{equation*} \Phi _k(\mathbf{d}) - \Phi _k(\mathbf{d}^\prime) = w_{k,a}w_{a}^{\leq k}(\mathbf{d}) + w_{k,c}w_{c}^{\leq k}(\mathbf{d}) - C^l_k. \end{equation*}
View SourceWe hence obtain the equality \begin{align*} & \Phi (\mathbf{d}) - \Phi (\mathbf{d}^\prime) = w_{k,a}w_{a}^{ > k}(\mathbf{d}) + w_{k,c}w_{c}^{ > k}(\mathbf{d}) + w_{k,a}w_{a}^{\leq k}(\mathbf{d}) \\ &\qquad + w_{k,c}w_{c}^{\leq k}(\mathbf{d}) - C^l_k= w_{k,a}w_a(\mathbf{d}) + w_{k,c}w_c(\mathbf{d}) - C^l_k \\ & \quad = \bar{C}_k(\mathbf{d}) - \bar{C}_k(\mathbf{d}^\prime). \end{align*}
View SourceSimilarily, we can show that \Phi (\mathbf{d}) - \Phi (\mathbf{d}^\prime) = \bar{C}_k(\mathbf{d}) - \bar{C}_k(\mathbf{d}^\prime) if WD k changes its strategy from local computing in \mathbf{d} to offloading to EC c through AP a in \mathbf{d}^\prime, i.e., if d_k= 0 and d_{k}^{\prime } = (a,c), which proves the theorem.

The existence of an exact potential function implies that \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) has a pure NE [18]. We can thus formulate the following result.

Corollary 1.
The game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) has a pure strategy NE \mathbf{d}^{\ast}. Hence, an SPE (\mathbf{d}^{\ast},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) for the CM-COG exists.

There are a variety of algorithms that are known to converge to an equilibrium for exact potential games, such as fictitious play [18], joint strategy fictitious play [19], and the best and better reply dynamics [18]. Nonetheless, they have exponential worst case complexity in general [20], [21]. Thus, the second fundamental question we address in this paper is whether a NE of \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) (and thus an SPE of the CM-COG) can be computed efficiently.

In what follows we propose the ImproveLocalComputing (ILC) algorithm to address this important question. The ILC algorithm starts from a strategy profile in which all WDs perform computation locally. Let us first denote by {\mathcal {N}}^\prime the set of WDs that have never changed their strategy from local computing to computation offloading (note that at the beginning {\mathcal {N}}^\prime = {\mathcal {N}}). The ILC algorithm consists of two phases that are executed alternatingly. In the first phase, among all WDs i\in {\mathcal {N}}^\prime that can decrease their cost by starting to offload, a WD with the maximum task complexity L_i is allowed to perform a best reply. In the second phase, which we refer to as the update phase, WDs i\in {\mathcal {N}}\setminus {\mathcal {N}}^\prime are allowed to update their best replies according to the AU algorithm shown in Fig. 2.


Fig. 2.
Pseudo code of the AsynchronousUpdates (AU) algorithm.

Show All

In what follows we show that by letting WDs to start to offload in non-increasing order of their task complexities, the ILC algorithm reduces the number of iterations compared to the best reply dynamic that lets WDs to start using cloud resources in an arbitrary order.

Proposition 1.
Let us consider a strategy profile \mathbf{d} in which all WDs j\in {\mathcal {N}}\setminus {\mathcal {N}}^\prime perform best replies and let us assume that there is a WD i\in {\mathcal {N}}^\prime that can decrease its cost by starting to offload to one of the ECs. Then upon WD i performs its best reply, WDs j\in O(\mathbf{d}) will not have an incentive to change between ECs.

Proof.
Let us assume that a best reply of WD i\in {\mathcal {N}}^\prime is offloading to an EC c, i.e., for any EC c^\prime \in {\mathcal {C}}\setminus \lbrace c\rbrace the following holds \begin{align*} (w_c(\mathbf{d}) + w_{i,c})w_{i,c} < (w_{c^\prime }(\mathbf{d}) + w_{i,c^\prime })w_{i,c^\prime }. \tag{16} \end{align*}
View SourceLet us next assume that upon WD i performs its best reply, a WD j\in O_c(\mathbf{d}) can decrease its offloading cost by changing its strategy from (\cdot,c) to (\cdot,c^\prime), i.e., that the following holds \begin{align*} (w_c(\mathbf{d}) + w_{i,c})w_{j,c} > (w_{c^\prime }(\mathbf{d}) + w_{j,c^\prime })w_{j,c^\prime }. \tag{17} \end{align*}
View SourceIn order to have (16) and (17) satisfied \sqrt{L_i} > \sqrt{L_j} must hold, which contradicts the fact that the ILC algorithm allows WDs i\in {\mathcal {N}}^\prime to start to offload in non-increasing order of their task complexities L_i. This proves the result.

Note that WDs can change between ECs only if the congestion in an EC decreases, i.e., if one of the WDs changes its strategy from offloading to local computing. This is, however, rarely the case, and as we show later, the number of iterations needed to compute an equilibrium allocation of offloading decisions using the ILC algorithm is on average almost linear in the number of WDs.

SECTION 4Equilibria Under the Time Fair Operator
We have so far shown that the the game played by the WDs under the resource allocation policy (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) of the CM operator can be transformed into a weighted congestion game, and we have proven that the CM-COG has an SPE. In what follows we show that under the resource allocation policy (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) of the TF operator the game played by the WDs can be transformed into a player-specific congestion game.

4Proposition 2.
Consider that the TF operator uses the time fair resource allocation policy (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c). Then, the strategic interaction of the WDs can be modeled as a player-specific congestion game, in which the cost of WD i is given by \begin{align*} \widetilde{C}_i(\mathbf{d}) = \sum _{(a,c) \in {\mathcal {A}}\times {\mathcal {C}}} I_{d_i,(a,c)}\left (\frac{D_i}{R_{i,a}}n_a(\mathbf{d}) + \frac{L_i}{F^c}n_c(\mathbf{d})\right) + I_{d_i,i}C^l_i. \tag{18} \end{align*}
View Source

4Proof.
Given the equal sharing of resources, it follows from (1) and (2) that the offloading cost (3) of WD i through AP a to EC c can be expressed as \begin{align*} \widetilde{C}_{i,a}(\mathbf{d}) = \frac{D_i}{R_{i,a}}n_a(\mathbf{d}) + \frac{L_i}{F^c}n_c(\mathbf{d}). \tag{19} \end{align*}
View SourceObserve that the offloading cost (19) depends on the total number n_a(\mathbf{d}) of WDs sharing the AP a, the total number n_c(\mathbf{d}) of WDs sharing the EC c, and on the characteristics of WD i’s task. Thus, the interaction between the WDs can be modeled as a player-specific congestion game. This proves the result.

4.1 Computing Equilibrium Offloading Decisions
We refer to the resulting strategic game as \Gamma (\mathcal{P}^{t,*}_{r},\mathcal{P}^{t,*}_{c}) = {<} {\mathcal {N}},(\mathfrak {D}_i)_{i\in {\mathcal {N}}},(\widetilde{C}_i)_{i\in {\mathcal {N}}} \!{>}, in which the players are WDs with the objective to minimize their cost given by (18). Observe that the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) is the TF-COG expressed in strategic form and thus if \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) has a NE then the TF-COG has an SPE. Hence, in what follows we focus on the existence and computability of pure NE for \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c).

In what follows we prove our result concerning the existence of a pure strategy NE under the TF operator. Our proof is based on the JoinAndPlayAsynchronousUpdates (JPAU) algorithm, which we propose for computing a NE of the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c). The pseudo code of the JPAU algorithm is shown in Fig. 3. The algorithm adds WDs one at a time, and lets them play their best replies given the other WDs’ strategies, and thus the following result is based on an induction in the number N of WDs.


Fig. 3.
Pseudo code of the JPAU algorithm.

Show All

Theorem 4.
The game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) has a pure strategy NE.

Proof.
The proof is given in Appendix B, available in the online supplemental material.

Even though the proof of Theorem 4 is fairly involved, the JPAU algorithm itself is computationally efficient, as we show next.

Proposition 3.
When a new WD enters the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) in a NE \mathbf{d}^{\ast}(n- 1), a new NE can be computed in O((A- 2)|{\mathcal {N}}_{n- 1}|^2 - (A- 3)|{\mathcal {N}}_{n- 1}|) time.

Proof.
The proof is given in Appendix C, available in the online supplemental material.

By adding WDs one at a time, it follows that the JPAU algorithm computes a NE of the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) in polynomial time.

Corollary 2.
The JPAU algorithm terminates in a NE of the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) in O((A- 2)N^3 - (A- 3)N^2) time.

Finally, since \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) is the TF-COG expressed in strategic form, we can formulate the following result.

Corollary 3.
The game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) has a pure strategy NE \mathbf{d}^{\ast}. Hence, an SPE (\mathbf{d}^{\ast},\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) for the TF-COG exists.

4.2 Implementation Considerations
In what follows we discuss how the SPE can be implemented in practice. Given the information about the resource allocation policy adopted by the operator, WDs perform best replies one at a time according to the ILC and JPAU algorithms in the case of the CM-COG and TF-COG, respectively. Upon its turn, a WD computes the set of its best replies based on the information about the congestion on resources, as provided by the operator. If it can improve its current offloading decision then it reports one of its best replies to the operator, otherwise it reports its current offloading decision. The operator then sends the updated information about the congestion on the resources to the next WD that is supposed to update its offloading decision. Upon convergence, given the equilibrium offloading decisions of WDs, the operator allocates wireless and computing resources according to the adopted resource allocation policy. By Corollaries 1 and 3 the resulting state is an SPE of the CM-COG and the TF-COG, respectively. Fig. 4 illustrates the information exchange between the operator and the WDs for the edge computing system shown in Fig. 1.


Fig. 4.
Example of the information exchange between the operator and WD_{1} and WD_{5}.

Show All

Observe that the WDs need to report only their offloading decisions in the case of the time fair operator and apart from the offloading decisions they need to reveal the characteristics of their tasks (i.e., the size D_i of the input data and the expected complexity L_i) in the case of the cost minimizing operator. Therefore, the implementation of the SPE of the TF-COG requires less information about the WDs’ tasks than the implementation of the SPE of the CM-COG, and thus the time fair resource allocation policy may be a better choice in systems in which privacy and confidentiality are of major concern.

SECTION 5Price of Anarchy
We have so far analyzed the interaction between the WDs under the cost minimizing and the time fair resource allocation policies of the operator and we proposed the ILC and the JPAU algorithms for computing an equilibrium of offloading decisions of the WDs under these two policies, respectively. Furthermore, we showed that the computational complexity of the ILC algorithm (which is exponential in the worst case) can be reduced by letting WDs start to offload in non-increasing order of their task complexities, and we proved that the worst case complexity of the JPAU algorithm is polynomial in N. In this section we quantify the worst case ratio between the system performance in an SPE and the optimal performance using the price of anarchy (PoA). We do so by providing an upper bound on the PoA of the CM-COG (denoted by PoA_\mathrm {CM-COG}) and the TF-COG (denoted by PoA_\mathrm {TF-COG}), respectively. Let us recall that the games \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) and \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) are strategic representations of the CM-COG and the TF-COG games, respectively. Therefore, we have PoA_\mathrm{CM-COG} = PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*}) and PoA_\mathrm{TF-COG} = PoA(\mathcal{P}_{r}^{t,*},\mathcal{P}_{c}^{t,*}).

We start with the definition of the PoA(\mathcal{P}_r,\mathcal{P}_c) of the strategic game played by the WDs for a policy (\mathcal{P}_r,\mathcal{P}_c) of the operator for which an equilibrium allocation \mathbf{d}^{\ast} of offloading decisions exists \begin{equation*} PoA(\mathcal{P}_r,\mathcal{P}_c) =\frac{\max \nolimits _{\mathbf{d}^{\ast}\in \mathfrak {D}^{\ast}}\sum \nolimits _{i\in {\mathcal {N}}}C_i(\mathbf{d}^{\ast},\mathcal{P}_r,\mathcal{P}_c)}{\min \nolimits _{\mathbf{d}\in \mathfrak {D}}\sum \nolimits _{i\in {\mathcal {N}}}C_i(\mathbf{d}, \mathcal{P}_r,\mathcal{P}_c)}, \tag{20} \end{equation*}
View SourceRight-click on figure for MathML and additional features.where \mathfrak {D}^{\ast} is the set of equilibria of offloading decisions under (\mathcal{P}_r,\mathcal{P}_c).

5.1 Price of Anarchy of the CM-COG
In order to provide an upper bound on PoA_\mathrm{CM-COG}, we provide an upper bound on PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*}) of the strategic game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c).

Theorem 5.
PoA_\mathrm{CM-COG} = PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*})\leq \frac{3 +\sqrt{5}}{2}.

Proof.
Our proof is inspired by Theorem 3.1 in [22], which provides a PoA bound for normalized weighted congestion games. Our proof extends the PoA bound to the game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c), which is not a normalized weighted congestion game.

We start with defining the set {\mathcal {R}} = {\mathcal {N}}\cup {\mathcal {A}}\cup {\mathcal {C}} of all resources available in the system. Furthermore, we denote by {\mathcal {R}}_{d_i} the set of resources that WD i uses in strategy profile \mathbf{d}, and we use \mathbf{d}^{\ast} and \hat{\mathbf{d}} to denote a NE and an optimal strategy profile of \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c), respectively. Let us define the local computing weight w_{i,i} \triangleq \sqrt{L_i/F^l_i} for each WD i\in {\mathcal {N}}, and the set of WDs using local computing link i O_i(\mathbf{d}) = \lbrace i| d_i= i\rbrace. Observe that either O_i(\mathbf{d}) = \emptyset or O_i(\mathbf{d}) = \lbrace i\rbrace holds since the local computing resources are not shared among WDs. We can thus express the total weight w_i(\mathbf{d}) = \sum \nolimits _{i\in O_{i}(\mathbf{d})}w_{i,i} associated with local computing link i, which is either w_i(\mathbf{d}) =0 or w_i(\mathbf{d}) = w_{i,i}.

Using the above notation we can express the system cost C(\mathbf{d},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) for \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) in a strategy profile \mathbf{d} as \begin{align*} C(\mathbf{d},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) = \sum \limits _{r\in {\mathcal {R}}} \sum \limits _{i\in O_r(\mathbf{d})} w_r(\mathbf{d})w_{i,r} = \sum \limits _{r\in {\mathcal {R}}} w_r^2(\mathbf{d}). \tag{21} \end{align*}
View SourceFurthermore, from the definition of a NE we obtain \begin{align*} & \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}}}w_r(\mathbf{d}^{\ast})w_{i,r} \leq \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}} \cap {\mathcal {R}}_{\hat{d}_i}} w_r(\mathbf{d}^{\ast})w_{i,r} \\ &\quad + \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}} \setminus {\mathcal {R}}_{\hat{d}_i}} \big (w_{r}(\mathbf{d}^{\ast}) + w_{i,r}\big)w_{i,r} \leq \sum \limits _{r\in {\mathcal {R}}_{\hat{d}_i}} \big (w_r(\mathbf{d}^{\ast}) +w_{i,r}\big) w_{i,r}. \tag{22} \end{align*}
View SourceFirst, by summing inequality (22) over all WDs i we obtain \begin{align*} \sum \limits _{i\in {\mathcal {N}}} \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}}} w_r(\mathbf{d}^{\ast})w_{i,r} \leq \sum \limits _{i\in {\mathcal {N}}} \sum \limits _{r\in {\mathcal {R}}_{\hat{d}_i}} \big (w_r(\mathbf{d}^{\ast}) + w_{i,r}\big) w_{i,r}. \tag{23} \end{align*}
View SourceSecond, by reordering the summations, (23) can be rewritten as \begin{align*} \sum \limits _{r\in {\mathcal {R}}} \sum \limits _{i\in O_r(\mathbf{d}^{\ast})} w_r(\mathbf{d}^{\ast})w_{i,r} \leq \sum \limits _{r\in {\mathcal {R}}} \sum \limits _{i\in O_r(\hat{\mathbf{d}})} \big (w_r(\mathbf{d}^{\ast})w_{i,r} + w_{i,r}^2 \big). \tag{24} \end{align*}
View SourceNext, from the definition of the total weight w_r(\mathbf{d}) = \sum \nolimits _{i\in O_r(\mathbf{d})} w_{i,r} associated with resource r and from \sum \nolimits _{i\in O_r(\mathbf{d})}w_{i,r}^2 \leq w_{r}^{2}(\mathbf{d}) we obtain \begin{align*} \sum \limits _{r\in {\mathcal {R}}} w_r^2(\mathbf{d}^{\ast}) \leq \sum \limits _{r\in {\mathcal {R}}} w_r(\mathbf{d}^{\ast})w_r(\hat{\mathbf{d}}) + \sum \limits _{r\in {\mathcal {R}}} w_r^2(\hat{\mathbf{d}}). \tag{25} \end{align*}
View SourceWe can now use the Cauchy-Schwartz inequality (\sum \nolimits _{r\in {\mathcal {R}}}a_rb_r\leq \sqrt{\sum \nolimits _{r\in {\mathcal {R}}}a_r^2 \sum \nolimits _{r\in {\mathcal {R}}} b_r^2}) to obtain \begin{align*} \sum \limits _{r\in {\mathcal {R}}} w_r^2(\mathbf{d}^{\ast}) \leq \sqrt{\sum \limits _{r\in {\mathcal {R}}}w_r^2(\mathbf{d}^{\ast}) \sum \limits _{r\in {\mathcal {R}}} w_r^2(\hat{\mathbf{d}})} + \sum \limits _{r\in {\mathcal {R}}} w_r^2(\hat{\mathbf{d}}). \tag{26} \end{align*}
View SourceIf we divide the right and the left side of inequality (26) by \sum \nolimits _{r\in {\mathcal {R}}} w_r^2(\hat{\mathbf{d}}) > 0 we can rewrite it using (21) as \begin{align*} \frac{C(\mathbf{d}^{\ast},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c)}{C(\hat{\mathbf{d}},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c)} \leq \sqrt{\frac{C(\mathbf{d}^{\ast},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c)}{C(\hat{\mathbf{d}},\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c)}} + 1. \tag{27} \end{align*}
View SourceSince (27) holds for any NE of the game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c), it holds for the worst case NE too, and thus we have \begin{align*} PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*}) \leq \sqrt{PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*})} + 1. \tag{28} \end{align*}
View SourceBy solving (28) we obtain that \begin{align*} PoA_\mathrm{CM-COG} =PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*}) \leq \frac{3 + \sqrt{5}}{2},\tag{29} \end{align*}
View Sourcewhich proves the theorem.

5.2 Price of Anarchy of the TF-COG
Next, using a similar approach to the one presented in the proof of Theorem 5, in what follows we provide an upper bound on PoA_\mathrm {TF-COG} by providing an upper bound on the PoA(\mathcal{P}_{r}^{t,*},\mathcal{P}_{c}^{t,*}) of the strategic game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c).

Theorem 6.
PoA_\mathrm {TF-COG} = PoA(\mathcal{P}_{r}^{t,*},\mathcal{P}_{c}^{t,*})\leq N+ 1.

Proof.
We start with the definition of the weights in \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) for all resources {\mathcal {R}} = {\mathcal {N}}\cup {\mathcal {A}}\cup {\mathcal {C}} available in the system \begin{equation*} \widetilde{w}_{i,i} \triangleq \ \frac{L_i}{F^l_i}, \widetilde{w}_{i,c} \triangleq \ \frac{L_i}{F^c}, \widetilde{w}_{i,a} \triangleq \ \frac{D_i}{R_{i,a}}. \end{equation*}
View SourceUsing the above notation we can express the system cost \widetilde{C}(\mathbf{d},\mathcal{P}_{r}^{eq},\mathcal{P}_{c}^{eq}) for \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) in a strategy profile \mathbf{d} as \begin{align*} \widetilde{C}(\mathbf{d},\mathcal{P}_{r}^{eq},\mathcal{P}_{c}^{eq}) = \sum \limits _{r\in {\mathcal {R}}} \sum \limits _{i\in O_r(\mathbf{d})} n_r(\mathbf{d})\widetilde{w}_{i,r} = \sum \limits _{r\in {\mathcal {R}}} n_r(\mathbf{d}) \widetilde{w}_r(\mathbf{d}), \tag{30} \end{align*}
View Sourcewhere \widetilde{w}_r(\mathbf{d}) \triangleq \sum \nolimits _{i\in O_r(\mathbf{d})}\widetilde{w}_{i,r}.

Furthermore, let us use \mathbf{d}^{\ast} and \hat{\mathbf{d}} to denote a NE and an optimal solution of \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c), respectively.

Now, from the definition of a NE we obtain \begin{align*} &\sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}}}n_r(\mathbf{d}^{\ast})\widetilde{w}_{i,r} \leq \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}} \cap {\mathcal {R}}_{\hat{d}_i}} n_r(\mathbf{d}^{\ast})\widetilde{w}_{i,r} \\ &\quad + \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}} \setminus {\mathcal {R}}_{\hat{d}_i}} \big (n_{r}(\mathbf{d}^{\ast}) + 1\big)\widetilde{w}_{i,r} \leq \sum \limits _{r\in {\mathcal {R}}_{\hat{d}_i}} \big (n_r(\mathbf{d}^{\ast}) +1\big) \widetilde{w}_{i,r}.\tag{31} \end{align*}
View SourceFirst, by summing inequality (31) over all WDs i we obtain \begin{align*} \sum \limits _{i\in {\mathcal {N}}} \sum \limits _{r\in {\mathcal {R}}_{d_i^{\ast}}} n_r(\mathbf{d}^{\ast})\widetilde{w}_{i,r} \leq \sum \limits _{i\in {\mathcal {N}}} \sum \limits _{r\in {\mathcal {R}}_{\hat{d}_i}} \big (n_r(\mathbf{d}^{\ast}) +1\big) \widetilde{w}_{i,r}. \tag{32} \end{align*}
View SourceSecond, by reordering the summations (32) can be rewritten as \begin{align*} \sum \limits _{r\in {\mathcal {R}}} \sum \limits _{i\in O_r(\mathbf{d}^{\ast})} n_r(\mathbf{d}^{\ast})\widetilde{w}_{i,r} \leq \sum \limits _{r\in {\mathcal {R}}} \sum \limits _{i\in O_r(\hat{\mathbf{d}})} \big (n_r(\mathbf{d}^{\ast})\widetilde{w}_{i,r} +\widetilde{w}_{i,r} \big). \tag{33} \end{align*}
View SourceRight-click on figure for MathML and additional features.Using the definition of the total weight \widetilde{w}_r(\mathbf{d}) \triangleq \sum \nolimits _{i\in O_r(\mathbf{d})}\widetilde{w}_{i,r} associated with resource r we can rewrite (33) as \begin{align*} \sum \limits _{r\in {\mathcal {R}}} n_r(\mathbf{d}^{\ast})\widetilde{w}_{r}(\mathbf{d}^{\ast}) \leq \sum \limits _{r\in {\mathcal {R}}}n_r(\mathbf{d}^{\ast})\widetilde{w}_{r}(\hat{\mathbf{d}}) + \sum \limits _{r\in {\mathcal {R}}}\widetilde{w}_{r}(\hat{\mathbf{d}}) . \tag{34} \end{align*}
View SourceRight-click on figure for MathML and additional features.Next, observe that n_r(\mathbf{d}) \leq N must hold for any feasible strategy profile \mathbf{d} and for every resource r\in {\mathcal {R}}, and that |O_r(\mathbf{d})| \geq 1 implies n_r(\mathbf{d}) \geq 1. Therefore, we have that \sum \nolimits _{r\in {\mathcal {R}}}n_r(\mathbf{d}^{\ast})\widetilde{w}_{r}(\hat{\mathbf{d}}) \leq N\sum \nolimits _{r\in {\mathcal {R}}}n_r(\hat{\mathbf{d}})\widetilde{w}_{r}(\hat{\mathbf{d}}) and \sum \nolimits _{r\in {\mathcal {R}}}\widetilde{w}_{r}(\hat{\mathbf{d}}) \leq \sum \nolimits _{r\in {\mathcal {R}}}n_r(\hat{\mathbf{d}})\widetilde{w}_{r}(\hat{\mathbf{d}}). By using these observations in (34) we obtain the following inequality \begin{align*} \sum \limits _{r\in {\mathcal {R}}} n_r(\mathbf{d}^{\ast})\widetilde{w}_{r}(\mathbf{d}^{\ast}) \leq (N+ 1) \sum \limits _{r\in {\mathcal {R}}}n_r(\hat{\mathbf{d}})\widetilde{w}_{r}(\hat{\mathbf{d}}). \tag{35} \end{align*}
View SourceFinally, since \sum _{r\in {\mathcal {R}}} n_r(\hat{\mathbf{d}})\widetilde{w}_r(\hat{\mathbf{d}}) > 0 must hold, we can divide the right and the left side of inequality (35) by \sum _{r\in {\mathcal {R}}}n_r(\hat{\mathbf{d}})\widetilde{w}_{r}(\hat{\mathbf{d}}) to obtain \begin{align*} \frac{\sum \limits _{r\in {\mathcal {R}}}n_r(\mathbf{d}^{\ast})\widetilde{w}_r(\mathbf{d}^{\ast})}{\sum \limits _{r\in {\mathcal {R}}}n_r(\hat{\mathbf{d}})\widetilde{w}_r(\hat{\mathbf{d}})} \leq N+ 1. \tag{36} \end{align*}
View SourceSince (36) holds for any NE of the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c), it also holds for the worst case NE, and thus using (30) we obtain \begin{align*} PoA_\mathrm{TF-COG} = PoA(\mathcal{P}_{r}^{t,*},\mathcal{P}_{c}^{t,*}) \leq N+ 1, \tag{37} \end{align*}
View Sourcewhich proves the theorem.

Observe that the PoA(\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*}) and PoA(\mathcal{P}_{r}^{t,*},\mathcal{P}_{c}^{t,*}) are in fact bounds on the approximation ratio of the ILC and JPAU algorithms used for computing a NE of the games \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) and \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c), respectively. Therefore, the ILC algorithm outperforms the JPAU algorithm in terms of the worst case system performance and the JPAU algorithm outperforms the ILC algorithm in terms of the worst case complexity. Consequently, the cost minimizing resource allocation policy might be a better choice than the time fair resource allocation policy in systems in which a guarantee on the worst case system performance is more important than a guarantee on the worst case computational efficiency, and vice versa.

SECTION 6Numerical Results
In the following we show results from extensive simulations to evaluate the system performance from the perspective of the operator of the WDs.

For the simulations we placed ECs and WDs uniformly at random over a square area of 1 \mathrm {km} \times 1 \mathrm {km}, and we placed 5 APs at random on a regular grid with 25 points defined over the area. This uniform deployment corresponds to a dense urban area. We consider that the channel gain of WD i in the case of offloading through the same AP a depends on its distance d_{i,a} from the AP and on the path loss exponent \alpha. We use \alpha =4 according to the path loss model in urban and suburban areas [23]. For simplicity we assign a bandwidth of B_{i,a}=5\;MHz to each communication link (i,a) \in {\mathcal {N}}\times {\mathcal {A}}_i. The transmit power P^t_{i,a} at which WD i offloads the data through AP a is drawn from a continuous uniform distribution on [0.05, 0.18]W according to [24]. Given the noise power P_{n} we calculate the transmission rate R_{i,a} achievable to WD i for offloading to AP a as R_{i,a} = B_{i,a} \mathrm{log}(1 + d_{i,a}^{-\alpha }\frac{P^t_{i,a}}{P_{n}}). The input data size D_i is drawn from a uniform distribution on [0.2, 4]Mb, and the number X of CPU cycles required per data bit is a Gamma distributed random variable with the shape k = 0.5 and scale \theta = 1.6. Given D_i and X, we calculate the complexity of a task as L_i= D_iX.

We consider two operator policies in the evaluation. We refer to (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) as the CM policy. Under the CM policy the WDs use the ILC algorithm for computing a NE of the game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c), as shown in Section 3. As a baseline for comparison, we consider the TF policy (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c), under which the WDs use the JPAU algorithm for computing a NE of the game \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c), as shown in Section 4.

As a baseline for the ILC and JPAU algorithms proposed for computing an equilibrium of offloading decisions, we use the FastestLinkNearestCloud (FLNC) algorithm. According to the FLNC algorithm WDs offload the computation through the AP with the highest achievable transmission rate and to the EC closest to the chosen AP. Observe that FLNC can be used with both operator policies. The results shown are the averages of 1000 simulations, together with 95 percent confidence intervals.

6.1 User-Oriented Performance
We start with considering the system performance from the point of view of the WDs. We define the performance gain PG_\mathrm{TF-FLNC}(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) (w.r.t. the TF-FLNC) for a strategy profile \mathbf{d}^A computed by algorithm A \in \lbrace \mathrm {ILC,JPAU,FLNC}\rbrace under a resource allocation policy (\mathcal{P}_r,\mathcal{P}_c) \in \lbrace (\mathcal{P}_{r}^{c,*},\mathcal{P}_{c}^{c,*}), (\mathcal{P}_{r}^{t,*},\mathcal{P}_{c}^{t,*})\rbrace as \begin{equation*} PG_\mathrm{TF-FLNC}(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) = \frac{C(\mathbf{d}^{FLNC}, \mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c)}{C(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c)}. \end{equation*}
View Source

Fig. 5 shows the performance gain as a function of the number N of WDs for two MEC systems, one with C = 1 (F^{c_1} = 192 GHz) and one with C = 3 (F^{c_i} = 64 GHz), i.e., ECs are homogeneous. The figure shows that the performance gain is largest when the operator uses the CM policy and WDs offload according to an equilibrium computed by the ILC algorithm. Interestingly, even CM-FLNC outperforms TF-JPAU for C = 1 ECs and N > 10 WDs. These results indicate that the operator’s resource allocation policy has a large impact on the user-perceived performance. Overall, we can observe that the performance gain increases with a decreasing marginal gain in N, which suggests that the achievable performance gain is limited by the congestion on the APs and ECs.


Fig. 5.
Performance gain versus the number of WDs N for A= 5 APs. Homogeneous ECs, F^{c,tot} = 192\;\mathrm{GHz}.

Show All

Fig. 6 shows the corresponding performance gain for heterogeneous ECs for two MEC systems, one with C = 3 ECs and one with C= 6 ECs. The total cloud computing capability F^{c,tot} = 192\;\mathrm{GHz} of the system is distributed among the ECs such that F^{c_1} = 32 GHz and F^{c_i} = F^{c_{i- 1}} + 32 GHz, i > 1, for C= 3 ECs, and F^{c_1} = 12 GHz and F^{c_i} = F^{c_{i- 1}} + 8 GHz, i > 1, for C = 6 ECs. As in Fig. 5, the results in Fig. 6 show a decreasing marginal gain in N and confirm that the largest performance gain is achieved by the CM-ILC. Nonetheless, a comparison of Figs. 5 and 6 reveals that the performance gain is affected by the number of ECs in the system and the way the total cloud computing capability is shared among the ECs. On the one hand, the performance gain increases with C. On the other hand, the performance gain for C= 3 ECs is greater in the case of heterogeneous ECs than that in the case of homogeneous ECs. Thus, CM-ILC is most beneficial when edge cloud resources are heterogeneous. The improved performance is partly due to that the WDs in the baseline strategy profile (computed by the FLNC) offload their tasks through the fastest link to the EC that is closest to the chosen AP, and since WDs, APs and ECs are randomly placed over the area, the number of WDs per EC is not proportional to its computing capability, as we will see later.

Fig. 6. - 
Performance gain versus the number of WDs $N$N for $A= 5$A=5 APs. Heterogeneous ECs, $F^{c,tot} = 192\;\mathrm{GHz}$Fc,tot=192 GHz .
Fig. 6.
Performance gain versus the number of WDs N for A= 5 APs. Heterogeneous ECs, F^{c,tot} = 192\;\mathrm{GHz}.

Show All

6.2 Infrastructure-Oriented Performance
In order to evaluate the system performance from operator’s perspective, we investigate how the choice of the resource allocation policy and the algorithm for computing the offloading decisions of WDs affects the number n_c(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) of WDs per EC and the cost C^c(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) = \sum _{i\in O_c(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c)}C_i(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) per EC. For consistency, we show results for a system with heterogeneous cloud resources, i.e., F^{c,tot} = 192 GHz divided among three ECs such that F^{c_1} = 32 GHz and F^{c_i} = F^{c_{i - 1}} + 32 GHz, for i > 1.

Figs. 7 and 8 show n_c(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) and C^c(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) for each of the ECs as a function of the number N of WDs, respectively. The results are shown for the ILC, JPAU and FLNC algorithms under both the CM and TF resource allocation policies. By looking at n_c(\mathbf{d}^A, \mathcal{P}_r,\mathcal{P}_c) for all ECs for a fixed N, we observe from Fig. 7 that the ratio of the WDs that offload their tasks decreases as N increases. This happens because the number of WDs that cannot benefit from offloading due to high congestion on the shared resources increases with N. Fig. 7 also shows that the difference in the congestion experienced by the ECs is smallest when the offloading decisions of the WDs are computed by the FLNC algorithm. This is due to that in the strategy profile computed by the FLNC algorithm WDs offload their tasks to the EC that is closest to the fastest AP, and since the WDs, APs, and ECs are placed uniformly at random over the region, all ECs experience the same congestion on average. Consequently, the corresponding cost per EC, shown in Fig. 8, is inverse proportional to the computing capability of the EC.


Fig. 7.
Congestion per EC versus the number of WDs N for A= 5 APs, C= 3 ECs. Heterogeneous ECs, F^{c,tot} = 192\;\mathrm{GHz}.

Show All


Fig. 8.
Cost per EC versus the number of WDs N for A= 5 APs, C= 3 ECs. Heterogeneous ECs, F^{c,tot} = 192\;\mathrm{GHz}.

Show All

On the contrary, in the case of equilibria computed by ILC and by JPAU (i.e., equilibria under the CM and TF policies, respectively) the congestion and the cost per EC are proportional to the computing capability of the EC as shown in Figs. 7 and 8, respectively. We also observe that the total number of WDs that offload their tasks and the total offloading cost are higher in an equilibrium computed by the JPAU algorithm than in an equilibrium computed by the ILC algorithm. This is due to that the cloud computing resources are shared among WDs independently of their tasks’ complexities in the case of the TF policy, and consequently the WDs overuse the ECs.

6.3 Computational Complexity
We characterize the computational complexity of an algorithm as the number of iterations needed to compute a computation offloading strategy profile. Since \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) is a potential game, we use the AU algorithm (cf. Fig. 2) as a baseline for comparison, as it is guaranteed to converge from an arbitrary initial strategy profile [18]. For the AU algorithm we consider three initial strategy profiles: a randomly chosen initial strategy profile (RandomAU), an initial strategy profile in which all WDs offload their tasks such that the number of WDs offloading the computation to an EC is proportional to its computing capability (ECProportionalAU), and an empty strategy profile where the WDs enter the game in non-increasing order of their task complexities (JoinNon-IncrAU). Furthermore, we consider the complexity of computing an equilibrium of \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) using the JPAU algorithm.

Fig. 9 shows the number of iterations needed to compute an equilibrium of \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) and an equilibrium of \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c), as a function of N for the same set of parameters as in Fig. 5. We observe that the number of iterations scales approximately linearly with N in all cases and that computing an equilibrium of \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c) using the ILC algorithm is more efficient than computing an equilibrium of \Gamma (\mathcal{P}^{t,*}_r,\mathcal{P}^{t,*}_c) using the JPAU algorithm; the difference is up to 50 percent.


Fig. 9.
Number of iterations versus the number of WDs N for A= 5. Homogeneous ECs, F^{c,tot} = 192\;\mathrm{GHz}.

Show All

We also observe that the choice of the initial strategy profile affects the complexity of computing an equilibrium of the game \Gamma (\mathcal{P}^{c,*}_r,\mathcal{P}^{c,*}_c), and we make three observations. First, the number of iterations required by ILC and by JoinNon-IncrAU is insensitive to the number of ECs, while the number of iterations required by RandomAU and by ECProportionalAU increases with the number of ECs. This is due to that in the case of ILC and of JoinNon-IncrAU the WDs start using ECs in non-increasing order of their task complexities, and thus it follows from Proposition 1 that when a new WD starts offloading, WDs will not have an incentive to change between ECs. This is not true in the case of RandomAU and of ECProportionalAU, since they start from a strategy profile where WDs did not start to offload in the order of the complexities of their tasks, and consequently the WDs can decrease their offloading cost not only by changing between the APs, but also by changing between the ECs. Second, the ECProportionalAU has the highest computational complexity. This is due to that ECProportionalAU starts from an initial strategy profile that has the highest congestion on the resources and thus when a WD updates its strategy the number of WDs affected by the update step is higher than in the case of the other initial strategy profiles. Finally, the smallest computational complexity can be achieved by the proposed ILC algorithm. On the one hand, this is because the WDs do not have to choose their initial strategy as in the case of the JoinNon-IncrAU. On the other hand, the WDs cannot decrease their offloading cost by changing between the ECs as in the case of the RandomAU and ECProportionalAU.

To summarize, the proposed CM-ILC algorithm can provide a significant reduction in terms of completion times and has low computational complexity, and could be a good candidate for coordinating the offloading decisions of WDs for edge computing.

SECTION 7Related Work
There is a large body of recent works on computation offloading for mobile cloud computing [11], [15], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36]. Many of these works assume that the offloading decisions of devices are determined by a centralized entity with the objective to meet the energy and latency constraints of the devices [11], [25], [26], [27], [28], [29], [30]. Zhao et al. [25] considered that devices offload the computation either to a computationally limited local cloud or to a computationally rich remote cloud, and proposed a policy that schedules resources in the clouds so as to meet the delay requirements of the applications. Sardellitti et al. [11], You et al. [26], Al-Shuwaili et al. [27] formulated the computation offloading problem as an optimization problem that minimizes the energy consumption of the mobile devices under latency constraints. You et al. [26] considered that devices may offload their tasks to an edge cloud through a base station, and proposed a policy for managing computing and communication resources assuming that the base station has perfect knowledge about the system. Sardellitti et al. [11], Al-Shuwaili et al. [27] considered a network composed of multiple cells, each equipped with an edge cloud. Sardellitti et al. [11] proposed an iterative algorithm for jointly optimizing the allocation of computing and uplink bandwidth resources, and [27] proposed an iterative algorithm for jointly optimizing the allocation of computing and both uplink and downlink bandwidth resources. Gao et al. [28] considered the problem of joint optimization of network selection and service placement under random mobility of users and proposed an iterative algorithm that minimizes the average system delay. Shutong et al. [29] proposed an online algorithm for distributing the workload across multiple edge clouds, which are managed by an operator that apart from the workload distribution decides about the activation status of the edge clouds, and acts as the auctioneer that solicits bids from multiple service providers. Liu et al. [30] considered a mobile cloud computing system in which a centralized entity located in the cloud implements an online algorithm for scheduling the transmissions between the mobile devices and the cloud so as to minimize the energy consumption of mobile devices. Unlike these works, we propose a novel approach to address the computation offloading problem by considering the interaction between an operator that manages the allocation of wireless and computing resources and devices that make their offloading decisions in a decentralized manner.

Closer related to ours are recent works that propose decentralized algorithms based on a game theoretic treatment of the computation offloading problem [15], [31], [32], [33], [34], [35], [36]. Authors in [31] considered the interaction between devices that always offload their tasks and an operator that optimizes the allocation of wireless and computing resources. Compared to [32], we consider both the cost minimizing and the time fair resource allocation policies and besides the analysis of a game in the case of the cost minimizing operator, we also prove the existence of Stackelberg equilibria in the case of the time fair operator, we establish an upper bound on the price of anarchy of the resulting Stackelberg game and we propose a polynomial complexity algorithm for computing an equilibrium of the game. Meskar et al. [33] considered that devices may offload the computation to the cloud through a single wireless link if doing so minimizes their own energy consumption, and proved the existence of equilibria when devices with the same delay budget compete only for wireless resources. Chen et al. [15], Zheng et al. [34], Jošilo and Dán [35] considered that devices may offload their tasks to the cloud through one of multiple wireless links so as to minimize the linear combination of the delay and the energy consumption. Chen et al. [15] considered the congestion only on the wireless links and proved the existence of equilibria under the assumption that a device experiences the same channel gain for all wireless links. Zheng et al. [34] extended the equilibrium existence results of [15] to a dynamic environment, where devices may be active or inactive. Jošilo and Dán [35] considered that devices may offload their tasks to the cloud through one of multiple heterogeneous wireless links, modeled the congestion on both cloud and wireless links and provided a polynomial time algorithm for computing equilibria. Jošilo and Dán [36] considered a fog computing system where multiple devices may offload their computational tasks to each other or to an edge cloud and provided an efficient algorithm for computing a mixed strategy equilibrium in a decentralized way. Our work differs significantly from these works, as we model the congestion on multiple heterogeneous wireless links and edge clouds, which are managed by an operator that can implement one of two resource allocation policies and given the resource allocation policy of the operator we consider that devices can autonomously decide whether or not to offload the computations, and if so, to which of multiple edge clouds and through which of multiple wireless links. To the best of our knowledge, ours is the first work on computation offloading for mobile cloud computing that closes the gap between the works that propose centralized solutions and the works that propose decentralized solutions.

Closest to our work in the literature on game theory is [37], which considers the effectiveness of Stackelberg strategies for atomic congestion games. Authors in [37] consider that the leader controls a subset of non-selfish players, focus on affine latency functions and on congestion games on parallel links. On the contrary, in our model the leader manages the sharing of resources, and we consider a player-specific weighted network congestion game for which the existence of equilibria is not known in general [38]. Thus, our work provides a novel game theoretic perspective on congestion games.

SECTION 8Conclusion
We have provided a game theoretical analysis of selfish computation offloading in a mobile edge computing system where wireless and computing resources are jointly managed by an operator, and devices make offloading decisions autonomously so as to minimize the completion times of their tasks. We consider the cost minimizing and the time fair allocation policies of the operator and we use a Stackelberg game to model the interaction between the operator and devices. We expressed the cost minimizing resource allocation policy in closed form and proved the existence of Stackelberg equilibria for both policies. Using game theoretical tools, we developed efficient decentralized approximation algorithms for computing offloading decisions of devices under both policies of the operator. Our numerical results show that the proposed algorithms are computationally efficient and that the system performance can be significantly improved through optimally allocating wireless and computing resources in a system, while allowing the devices to make their offloading decisions autonomously.