The cloud computing paradigm provides numerous tempting advantages, enabling users to store and share their data conveniently. However, users are naturally resistant to directly outsourcing their data to the cloud since the data often contain sensitive information. Although several fine-grained access control schemes for cloud-data sharing have been proposed, most of them focus on the access control of the encrypted data (e.g., restricting the decryption capabilities of the receivers). Distinct from the existing work, this article aims to address this challenging problem by developing a more practical bidirectional fine-grained access control scheme that can restrict the capabilities of both senders and receivers. To this end, we systematically investigate the access control for cloud data sharing. Inspired by the access control encryption (ACE), we propose a novel data sharing framework that combines the cloud side and the edge side. The edge server is located in the middle of all the communications, checking and preventing illegal communications according to the predefined access policy. Next, we develop an efficient access control algorithm by exploiting the attribute-based encryption and proxy re-encryption for the proposed framework. The experimental results show that our scheme exhibits superior performance in the encryption and decryption compared to the prior work.

SECTION 1Introduction
The cloud computing paradigm provides numerous tempting advantages, such as powerful computation capacity, flexible resource sharing and low cost. It enables users to obtain desired services in an unprecedented and convenient manner, regardless of time and location. Cloud storage service, such as iCloud, Dropbox and Google Drive, is one of the most fundamental services provided by cloud computing [1]. By migrating the local data into the cloud, users can enjoy convenient data management and sharing at a low cost. With the development of the information industry, the cloud storage will become more popular in the future.

Traditionally, a fine-grained cloud-data sharing system usually considers the receivers’ access control instead of the senders’. Only the receiver who has the decryption right can recover the message. It seems sufficient for a cloud data sharing system. However, for the people who want to control the information flow in the system, this is not enough. Consider an application where a company stores its top-secret documents in the cloud and encrypts them using an access policy that determines which employees are allowed to decrypt the documents. Caused by mistakes or malice, a legitimate employee may share the plaintext directly with other employees who do not have the decryption rights. In addition, a doctor may share a file to a businessman and a man may share a video of campus violence to a student through the public cloud storage. If the cloud server is allowed to check the contents of the sharing file, it will violate the user's data privacy. Moreover, the senders can avoid checking the contents by processing the sharing file, e.g., changing the file type. As a result, how to construct a cloud-data sharing system that can restrict the capabilities of both senders and receivers while preserving the users’ privacy is an important and challenging problem.

The general solution to protecting the data privacy is to employ a searchable encryption scheme (SE) to encrypt the data files and potential keywords before uploading them to the cloud. The encrypted data can be subsequently retrieved with a corresponding keyword and decrypted by those who have the decryption keys. However, how can the encrypted data be shared efficiently. To enable a search on the data file, it requires the sender to share his secret key with the receivers or stay online to generate the search trapdoor [2], [3]. To address this problem, Sun et al. [4] proposed an attribute-based keyword search scheme, which provides fine-grained search authorization. Then the file can be searched by those whose attributes satisfy the access policy.

If all the users are honest, using the above method is enough to address the aforementioned issue. But in reality, we must consider the more complicated situation where a sender may be dishonest. To cope with this issue, Damgård et al. [5] initialized a study on a novel primitive called access control encryption, which introduces a sanitizer to route messages from senders to receivers. It gives different privileges to different users, indicating which files they can read and which files they can share. To prevent a malicious sender from sending a message in plaintext or in a screenshot, the sanitizer must secure the message before broadcasting it to the receivers. If the cloud server is used to perform as the sanitizer, it will put a heavy burden on the cloud since the sanitizer must process each message. Especially with the rapid development of Internet-of-Things (IoT) technology, data sharing on the cloud has incorporated many new features, such as real-time and data transmission intensiveness [6]. For instance, in an electronic health system, the data owner may upload health data to the cloud server in real time, and the uploaded data need to be sanitized and stored by the cloud server. If all the processing is handed over to the cloud server, it will cause huge computational pressure on the server. Furthermore, as the cloud server is usually far away from the data owner, there will be a large delay caused by data transmission. To mitigate the computing burden and reduce the transmission latency, we should simplify the sanitizer's operations and possibly outsource it to a third party, which is only semi-trusted.

Inspired by the access control encryption, we propose in this paper a novel bidirectional access control scheme by exploiting attribute-based encryption and proxy re-encryption. The concept of bidirectional was introduced in proxy re-encryption [7], and we use it to describe the access control that restricts the capabilities of both senders and receivers. Specifically, we introduce the edge server to perform as a sanitizer, which can reduce the burden of cloud server. When the edge server receives a data file from a sender, it will check the validity of the information flow by the predefined access policy. We differentiate access policy and access structure in our scheme. In the access control encryption, the access policy is denoted by a predicate P:[n]×[n]→{0,1}. A sender Si is allowed to send files to a receiver Rj only when P(i,j)=1. In our scheme, the access policy is defined by the central authority and is formed as P:S×S→{0,1}, where S stands for the attributes of the users (senders and receivers). In addition, the access structure is used for the attribute-based encryption. When a sender wants to send a file to a receiver, the attributes of the sender and the receiver must satisfy the access policy, e.g., the sender and the receiver must have the same attributes (the real access policy can be more complicated). If the information flow is valid, the edge server will perform a signature authentication to verify the identity of the sender and then re-encrypt the data file. The sanitized data file will be sent to the receivers, and be decrypted by those whose attributes satisfy the access structure in the ciphertext.

1.1 Motivation and Contribution
While numerous fine-grained access control schemes have been proposed for data sharing in the cloud [8], [9], most of them have concentrated on allowing fine-grained access to the encrypted data (e.g., restricting the decryption abilities of the receivers). However, when the sender is dishonest, the data may be shared with the receivers who should not get the ciphertext.

In this work, we are motivated to address the above mentioned problem and proposed a secure cloud data sharing scheme that can achieve more practical bidirectional access control. To achieve this goal, we construct an attribute-based access control encryption (AACE) that fulfills the aforementioned bidirectional fine-grained access control. Specifically, cryptographic alone is insufficient for the access control encryption [10], and requires a sanitizer to process all the communication between the senders and receivers. So we construct a secure fine-grained data sharing scheme by combining the cloud server and the edge server. The edge server is located in the middle of all communications, checking and preventing illegal communication. To the best of our knowledge, no systematic investigation of data sharing for cloud-edge computing has been conducted. To fill this gap, this paper makes the following major contributions:

We develop a novel fine-grained data sharing framework that combines the cloud side and the edge side. In our scheme, we employ the edge server to perform as a sanitizer that re-encrypts and routes the messages between the senders and the receivers according to the predefined information flow access policy.

We present a formal definition of the attribute-based access control encryption (AACE) method and its corresponding security model. We exploit the attribute based keyword search to realize a fine-grained data access control at the receiver side.

In addition, we use proxy re-encryption and signature authentication to realize the information flow control of the sender side. This process is performed before the file reaches the receivers. Even if the sender sends a file in plaintext, the receivers will receive a re-encrypted ciphertext.

Then we provide a concrete attribute based access control encryption (AACE) and a data sharing construction based on the proposed AACE. Compared with many existing cloud data sharing constructions, which assume the sender is fully honest, we use a more practical threat model where the sender can also be malicious, thus requiring a higher security guarantee.

1.2 Related Work
Sahai and Waters [11] invented the notion of attribute-based encryption (ABE). Unlike the traditional public-key encryption, ABE provides a more fine-grained access control of the encrypted data. Goyal et al. [12] introduced the definitions of key-policy ABE (KP-ABE) and ciphertext-policy ABE (CP-ABE). ABE has been shown to have applications in many areas, e.g., electronic health-record (EHR) systems [13] and searchable encryption [14], [15]. However, in public cloud storage, CP-ABE is more practical [16]. Although a variety of protocols [17], [18] have been designed for cloud access control using CP-ABE, many other challenges still exist.

Xue et al. [20] proposed an access control scheme for encrypted cloud storage by combining the owner-side and cloud side. They exploited a hybrid attribute-based encryption and a digital signature to ensure the access control on the data user and the integrity of the message, respectively. However, they did not consider the condition that the sender may be malicious. To enhance the access control functionality, Damgård et al. [5] conducted a study on access control encryption (ACE). They used a novel control on the information flow, both in terms of what the users could read, as well as what they could send. Additional ACE applications have been proposed [21], [22]. Kim and Wu [10] reduced the construction of an ACE scheme to a proxy re-encryption scheme and presented a generic ACE construction for general policies. Motivated by ACE, Han et al. [19] proposed an information-flow control scheme based on ABE, which can prevent corrupt senders from sending messages to unauthorized receivers. However, it is inefficient and cannot be applied directly to cloud-data sharing. In Table 1, we provide the comparison between our scheme and the related access control encryption in terms of assumption, predicate, ciphertext size and the sanitizer's key size.

TABLE 1 The Comparison Between Our Scheme and the Related Access Control Encryption

Blaze et al. [23] first introduced the proxy re-encryption. It allows a proxy to process the message without leaking the information of the encrypted message. Liang et al. [24] introduced a CP-ABE scheme that supports policy updating through the proxy re-encryption technique. After that, numerous CP-ABE with policy updating using the technique of proxy re-encryption have been proposed [25], [26]. Proxy re-encryption is also widely used in user revocation schemes [27], [28]. However, the proxy re-encryption in our scheme is different from the existing schemes because the senders do not need to generate a transformation key and the proxy just performs a re-randomization on the ciphertext. We exploit the proxy re-encryption to prevent a malicious sender from directly sending a plaintext or screenshot to the receivers.

Recently, edge computing has become a new computing paradigm [29]. It decentralizes the computing power and storage resources of the cloud to edge nodes closer to users to provide low latency and high quality services [30], [31]. In addition, it offers context awareness, mobility and scalability which makes it widely used in the IoT environment [32], [33]. Wang et al. [34] presented a novel cloud-edge computing framework, where the cloud server mainly processes large-scale data, while the edge side is used to provide real time service. Combining the cloud side and edge side can bring numerous benefits [35]. For example, applying them to a traditional data sharing system can alleviate the burden on the cloud, and users can enjoy a series of high-quality services at a low latency [36], [37]. Furthermore, it can reduce the network bandwidth usage by mitigating the data transmission from users to the cloud [38].

1.3 Outline
The rest of this paper is organized as follows. In Section 2, we introduce the preliminaries and cryptographic primitives involved in our scheme. Then we provide formal definitions of the system and security models in Section 3. Next, we present a concrete construction in Section 4. We then present the security proof and experimental results in Sections 5 and 6, respectively. Finally, we conclude this work in Section 7.

SECTION 2Preliminaries
In this section we will describe the preliminaries that are associated with our scheme. All the notations used in this paper are summarized in Table 2.

TABLE 2 Notations

2.1 Access Structure and Monotone Span Program
Definition 1 (Access Structure [12]).
Let P1,…,Pn be a set of attributes. A collection A⊆2P1,…,Pn is monotone if ∀B,C: if B∈A and B⊆C, then C⊆A. A monotone access structure is a monotone collection A of non-empty subsets of P1,…,Pn, i.e. A⊆2P1,…,Pn∖{∅}.

If U stands for the universe of attributes, a Monotone Span Program (MSP) over Zp is given by a labeled matrix M of n1×n2 and a mapping: ρ:{1,…,n1}→U, which maps the ith row of M to an attribute in U. Let S be a subset of U and I={i|i∈{1,…,n1},ρ(i)∈S} stands for the rows of M(every row is labeled by one literal). The MSP(M,ρ) accepts S if there exists coefficients {γi}i∈I such that:
∑i∈IγiMi=(1,0,0,…,0).(1)
View Source

2.2 Bilinear Map and Dual Paring Vector Spaces
Let G1 and G2 denote two cyclic multiplicative groups of prime order p, g1 is the generators of G1 and g2 is the generator of G2. The bilinear pairing is a map e:G1×G2→GT with the following properties:

Bilinear: for all g1∈G1, g2∈G2 and a,b∈Zp, we have e(ga1,gb2)=e(g1,g2)ab

Non-degenerate: e(g1,g2)≠1.

Computability: it is efficient to compute e(g1,g2) for all g1∈G1 and g2∈G2. A pairing is asymmetric if G1≠G2 and no efficient computable homomorphism exists between them.

Dual Paring Vector Spaces(p,GT,V,V∗,C,Cs∗) [39] is a tuple of a prime p, a cyclic group GT of order p, two n-dimensional vectors V,V∗ and their canonical bases: C:=(c1,…,cn) of V and C∗:=(c∗1,…,c∗n) of V∗ generated by Dual(Znp) that satisfy the “dual orthonormal”, meaning that:
ci⋅c∗j={0 (mod p),δ (mod p),i≠ji=j,(2)
View Sourcewhere δ is a random element of Zp. Then for g1∈G1 and g2∈G2, we have that
e(gci1,gc∗j2)=1,
View Sourcewhenever i≠j, and 1 stands for the identity element in GT.

2.3 Decision Linear Assumption
Let pG=(p,G1,G2,GT,g1,g2,e)←Gen(1λ), where Gen(1λ) is an asymmetric group generator, g1 is the generator of G1 and g2 is the generator of G2. Let D:=(gx11,gx21,gx12,gx22,gx1r11,gx2r21,gx1r12,gx2r22), T0:=(gr1+r21,gr1+r22),T1:=(gr1,gr2) where x1,x2,r1,r2,r⟵RZp, the advantage for all PPT adversaries A in solving the decision linear problem is defined as
AdvADLIN(λ):=∣∣Pr[A(1λ,pG,D,T0)=1]−Pr[A(1λ,pG,D,T1)=1]∣∣≤negl(λ).
View SourceRight-click on figure for MathML and additional features.

The probability is taken over the randomness used by A. Note that it is hard for all probabilistic polynomial time adversaries A to distinguish T0 from T1 for pG←Gen,x1,x2,r1,r2,r←Zp.

SECTION 3System Model and Security Model
In this section, we describe the cloud-edge data sharing framework proposed in our scheme. Furthermore, the security definitions are provided.

3.1 System Model
As shown in Fig. 1, the access control system consists of five entities: cloud server, edge server, central authority, data owners and data users.

Central Authority (CA) is a fully trusted party that initializes the system and generates the secret keys for users (senders and receivers). In addition, it will publish an information flow policy π:S×S→{0,1} to define the relationship between the attributes of senders and receivers.

Fig. 1. - 
System model.
Fig. 1.
System model.

Show All

Cloud Server (CS) is a semi-trusted party that provides data storage service for users. When the receiver requests a data file, cloud server will check whether the receiver can decrypt the data file before downloading.

Edge Server (ES) is a semi-trusted party that processes the requests from the senders. To prevent malicious senders from transmitting files to receivers, the edge server will check the access policy to ensure that the sender can share files with the receivers and re-randomize the ciphertext. The edge server can cache the data file for user downloading when it has sufficient storage.

Sender is the publisher of files. All the communications must be routed by the edge server. Therefore, as shown in the system model, the data file cannot be uploaded to the cloud server directly.

Receiver obtains data files from the edge server and the cloud server. When the sender and the receiver are located in the same area, the receiver can obtain the shared file from the edge server directly. Otherwise, the data file can be transferred to the edge server close to the receiver and then forward to the receiver.

Remark 1.
It is worth nothing that in practical applications, there will be multiple edge servers, and there will be senders and receivers in the area of each edge server. When the sender and the receiver are in the same edge area, the time to upload and download files is reduced. Otherwise, the receiver can get the shared files from the cloud server through the closer edge server. When the edge server has enough memory, it can cache the data files. Because a group of users have the same decryption rights in attribute based encryption, other users with the same decryption rights can directly get the cached shared files from the edge server when they download the files, thus reducing the download delay.

To achieve the fine-grained access control (provided in Table 3), we consider three types of control among the entities in our system:

TABLE 3 Fine-Grained Access Control in Our Scheme

Control I: Sender uses the attribute-based encryption to encrypt the data file, which ensures the fine-grained access control on receivers.

Control II: The edge server ensures the validity of the information flow through the predefined access policy. If sender's and receiver's attributes satisfy the policy, the communication will go on.

Control III: The cloud server verifies whether the receiver can decrypt the data file before downloading, which prevents a malicious receiver from downloading the data files.

Next, we give the formal definition of attribute-based access control encryption (AACE).

Setup(1λ)→(msk,mpk): On inputting a security parameter λ, the algorithm returns the master public key mpk and the master secret key msk.

Keygen(msk,AU,idi)→ski: On inputting the master secret key msk and a set of attributes AU along with an identity idi, the algorithm returns a secret key sk.

Encrypt(mpk,(M,ρ),ski,msg)→ct: On inputting the master public key mpk, access structure (M,ρ), a message msg∈M and the sender's secret key ski, the algorithm returns a ciphertext ct.

Sanitize(ct,mpk)→ct′: On inputting a ciphertext ct and the master public key mpk, the algorithm returns the sanitized ciphertext ct′ or a invalid symbol ⊥.

Decrypt(ct′,skj)→msg′: On inputting a sanitized ciphertext ct′ and the receiver's secret key skj, the algorithm outputs a message msg′ or an invalid symbol ⊥.

Definition 2 (Correctness).
An attribute based access control scheme ΠAACE is correct if for all messages msg∈M, and all attributes AS,AR∈U where π(AS,AR)=1. Let (mpk,msk)←setup(1λ),sk←keygen,ct←encrypt(ski,msg), we have that
Pr[decrypt(skj,sanitize(mpk,ct))=msg]=1−negl(λ).
View SourceRight-click on figure for MathML and additional features.

3.2 Security Model
The security notions (no-read up and no-write down) were invented for the information flow control [10]. Recently, it was improved to suit for an ACE scheme: the no-read rule and the no-write rule [5]. In our scheme, the no-read rule guarantees that only the privileged receivers should be able to decrypt the data file. The no-write rule guarantees that a sender can only share files with the receivers when their attributes satisfy the access policy. Specifically, no sender with attributes AS should be able to construct a valid ciphertext which can be accessed by a receiver with attributes AR whenever π(AS,AR)=0. Here we give the formal definitions.

Definition 3 (no-read rule).
Let ΠAACE be an attribute based access control encryption scheme. Given a security parameter λ and a bit b∈0,1, we define the no-read rule experiment ExptreadΠAACE,A(λ,b) between a challenger C and an adversary \mathcal {A}.

{{\sf setup}}: The challenger \mathcal {C} runs \sf setup(1^\lambda) to obtain mpk, msk, and gives mpk to \mathcal {A}.

{{\sf key query}}: On inputting a set of attributes A_U, the challenger \mathcal {C} returns a secret key \sf sk=KeyGen(msk,S) and gives it to \mathcal {A}.

{{\sf challenge}}: On inputting a pair of messages (msg_0, msg_1) and an access structure \mathbb {A}, the challenger \mathcal {C} returns a ciphertext \sf ct=Encrypt(mpk,\mathbb {A},msg_b) and gives it to \mathcal {A}.

\mathcal {A} outputs a bit b^{\prime } as the output of the game. An attribute based access control encryption scheme is called no-read rule security if the advantage for all PPT adversaries \mathcal {A} is, \begin{align*} Adv_{\Pi }^{\mathcal {A}}(\lambda):&=\left| Pr[Expt_{\Pi,\mathcal {A}}^{read}(\lambda,0)=1]-\right.\\ &\left. Pr[Expt_{\Pi,\mathcal {A}}^{read}(\lambda,1)=1]\right| =negl(\lambda). \end{align*}
View Source

The no-read rule actually guarantees control I. An attribute based access control encryption scheme that satisfies the no-read rule security means that a non-privileged receiver cannot be able to decrypt the data file. And sender anonymity is also required in the no-read rule. In our scheme, we employ an anonymous identity to protect the senders’ identity privacy.

Definition 4 (no-write rule).
Let \Pi _{{\sf AACE}} be an attribute based access control encryption scheme. Given a security parameter \lambda and a bit b\in {0,1}, we define the no-write rule experiment \sf Expt_{\Pi _{AACE},\mathcal {A}}^{write}(\lambda,b) between a challenger \mathcal {C} and an adversary \mathcal {A}.

{{\sf setup}}: The challenger \mathcal {C} runs \sf Setup(1^\lambda) to obtain mpk, msk, and gives mpk to \mathcal {A}.

{{\sf key\ query}}: On inputting a set of attributes A_U, the challenger \mathcal {C} returns a secret key \sf sk=KeyGen(msk,S) and gives it to \mathcal {A}.

{{\sf challenge}}: On inputting a ciphertext ct and an access structure \mathbb {A}, the challenger sets \sf ct_0=ct. Then it uniformly selects a message \sf msg^{\prime }\leftarrow M and returns a sanitized ciphertext \sf ct_1=Sanitize(Encrypt(mpk,\mathbb {A},msg^{\prime }),\mathbb {A}) and gives it to \mathcal {A}.

\mathcal {A} outputs a bit b^{\prime } as the output of the game. An attribute based access control encryption scheme is called no-write rule security if the advantage for all PPT adversaries \mathcal {A} is, \begin{align*} Adv_{\Pi }^{\mathcal {A}}(\lambda):&=\left| Pr[Expt_{\Pi,\mathcal {A}}^{write}(\lambda,0)=1]-\right.\\ &\left. Pr[Expt_{\Pi,\mathcal {A}}^{write}(\lambda,1)=1]\right| =negl(\lambda). \end{align*}
View SourceRight-click on figure for MathML and additional features.

The no-write rule actually guarantees control II, and ensures that even a legal sender should not be able to share files with the specified receiver if they do not satisfy the access policy.

SECTION 4Our Construction
In this section, we will describe the cloud-edge data sharing system design. First, we will give a detailed description of the AACE algorithm. Then we will describe the specific operations of the system.

4.1 The Proposed AACE Algorithm
First, function \mathbf Setup() is run by the central authority (CA) to generate the master public and secret key pair. The process of this function is given in Function 1.

Function 1. Setup
INPUT: The secret parameter 1^\lambda.

OUTPUT: The master public key mpk and master secret key msk.

1) CA runs an asymmetric group generator Gen(1^\lambda) to obtain (p, G_1, G_2, G_T, e, g_1, g_2), where g_1 and g_2 are the generators of G_1 and G_2, respectively.

2) Let S be a set of attributes. CA publishes a policy \pi : S \times S to define which senders can communicate with the specified receivers. It then picks a_1, a_2, b_1, b_2 \leftarrow Z_p^*, d_1, d_2, d_3 \leftarrow Z_p.

3) Finally it returns (g_1,g_2,h_1=g_2^{a_1},h_2=g_2^{a_2},T_1=e(g_1,g_2)^{d_1a_1+d_3},T_2=e(g_1,g_2)^{d_2a_2+d_3}) as the master public key mpk, and outputs (a_1,a_2,b_1,b_2,g_1^{d_1},g_1^{d_2},g_1^{d_3}) as the master secret key msk.

Second, function \mathbf KeyGen() is run by the central authority (CA) to generate the public and secret key pair for the user. The process is given in Function 2.

Function 2. KeyGen
INPUT: The master secret key msk, user identity id_i and his attribute sets A_U.

OUTPUT: User's secret key and public key.

1) Select r_1,r_2 \leftarrow Z_p and compute: \begin{equation*} sk_0 = (sk_{0,1},sk_{0,2},sk_{0,3})=(g_2^{b_1r_1},g_2^{b_2r_2},g_2^{r_1+r_2}) \end{equation*}
View Source

2) For attributes y\in A_U and t=1,2, CA selects \sigma _y\leftarrow Z_p and computes: \begin{equation*} sk_{y,t}=H_1(y1t)^\frac{b_1r_1}{a_t}\cdot H_1(y2t)^\frac{b_2r_2}{a_t}\cdot H_1(y3t)^\frac{r_1+r_2}{a_t}\cdot g_1^\frac{\sigma _y}{a_t} \end{equation*}
View Source

and sets sk_y=(sk_{y,1},sk_{y,2},sk_{y,3}), where sk_{y,3}=g_1^{-\sigma _y}.

3) Select \sigma ^{\prime } and compute: \begin{equation*} sk_t^{\prime }=g_1^{d_t}\cdot H_2(11t)^\frac{b_1r_1}{a_t}\cdot H_2(12t)^\frac{b_2r_2}{a_t}\cdot H_2(13t)^\frac{r_1+r_2}{a_t}\cdot g_1^\frac{\sigma ^{\prime }}{a_t} \end{equation*}
View Source

and set sk^{\prime }=(sk_1^{\prime },sk_2^{\prime },sk_3^{\prime }), where sk_3^{\prime }=g_1^{d_3} \cdot g_1^{-\sigma ^{\prime }}.

4) Run Dual(Z_p^4) algorithm to obtain two orthonormal bases \boldsymbol{C} and \boldsymbol{C}^*. And then choose \alpha \in Z_p^* to compute pk=(T_3=e(g_1,g_2)^{\alpha \boldsymbol{c_1c_1}^*},h_3=g_1^{\boldsymbol c_1},h_4=g_1^{\boldsymbol c_2},h_5=g_1^{H_3(id_i)}) as the public key and sk_\theta =(\alpha,g_2^{\boldsymbol{c}_{1}^{*}} ,g_2^{\boldsymbol{c}_{2}^*}) as the signature key.

5) Output the secret key (sk_0,{sk_y}_{\lbrace y\in A_U\rbrace },sk^{\prime },sk_\theta) and the public key pk.




Third, function \mathbf Encrypt() is run by the sender to encrypt the message. The process of this function is given in Function 3.

Function 3. Encrypt
INPUT: The master public key mpk, access structure (\mathcal {M},\rho) and a message msg.

OUTPUT: The ciphertext CT.

1) The sender selects s_1,s_2\leftarrow Z_p and computes: \begin{equation*} ct_0=(ct_{0,1},ct_{0,2},ct_{0,3})=(g_2^{a_1s_1},g_2^{a_2s_2},g_2^{s_1+s_2}) \end{equation*}
View Source

2) Suppose \mathcal {M} is a n_1\times n_2 rows matrix. Then for i\in \lbrace 1,\ldots,n_1\rbrace and l\in \lbrace 1,2,3\rbrace it computes: \begin{equation*} \begin{split} ct_{i,l}=H_1(\rho (i)l1)^{s_1} \cdot H_1(\rho (i)l2)^{s_2}\\ \cdot \prod _{j=1}^{n_2}[H_2(jl1)^{s_1}\cdot H_2(jl2)^{s_2}]^{\mathcal {M}_{i,j}} \end{split} \end{equation*}
View Source

and sets ct_i=(ct_{i,1},ct_{i,2},ct_{i,3}).

3) Compute ct^{\prime }=T_1^{s_1}T_2^{s_2}\cdot msg and set ct=(ct_0,ct_1,\ldots,ct_{n_1},ct^{\prime }) as the ciphertext.

4) To prove the sender's identity, it selects r\in Z_p^* and a set of attributes A_R satisfying the access structure (\mathcal {M}, \rho) then computes: \begin{equation*} \beta =H_3(h_5||T||CT||A_S||A_R),\theta =g_2^{(\alpha +r\beta)\boldsymbol{c_1}^*-r\boldsymbol{c_2}^*} \end{equation*}
View Source

where A_S is a subset of the sender's attributes that satisfy the access policy \pi (A_S,A_R)=1 and T is the current time.

5) Then the sender sends (ct,pk,T,A_S,A_R,\theta,(\mathcal {M},\rho)) as the ciphertext CT to the edge server.




Fourth, function \mathbf Sanitize() is run by the edge server to sanitize the ciphertext. The process of this function is given in Function 4.

Function 4. Sanitize
INPUT: The ciphertext CT.

OUTPUT: The sanitized ciphertext CT^{\prime }.

1) Edge server first checks the freshness of the message, and rejects the message if it is not fresh.

2) Edge server then checks whether the sender can share data files with the receiver through the access policy \pi (A_S,A_R)\stackrel{?}{=}1. If the sender's attributes and receiver's attributes satisfy the policy, edge server will verify the validity of the received message.

3) Edge server checks whether the equation: e(g_1^{\boldsymbol{c_1}+\beta \boldsymbol{c_2}},\theta)=T_3 holds to verify the validity of the received message. If it does not hold, the sanitizer rejects the message; Otherwise, the edge server accepts the message.

4) If the above process succeeds, the edge server selects s_1^{\prime },s_2^{\prime }\leftarrow Z_p and rerandomizes the ciphertext: \begin{equation*} \begin{split} ct_0^{\prime } =(ct_{0,1} \cdot h_1^{s_1^{\prime }},ct_{0,2} \cdot h_2^{s_2^{\prime }},ct_{0,3} \cdot g_2^{s_1^{\prime }+s_2^{\prime }})\\ = (g_2^{a_1(s_1+s_1^{\prime })},g_2^{a_2(s_2+s_2^{\prime })},g_2^{s_1+s_2+s_1^{\prime }+s_2^{\prime }})\end{split} \end{equation*}
View Source

5) For i\in \lbrace 1,\ldots,n_1\rbrace and l\in \lbrace 1,2,3\rbrace it computes: \begin{align*} ct_{i,l}^{\prime }&=ct_{i,l} \cdot H_1(\rho (i)l1)^{s_1^{\prime }} \cdot H_1(\rho (i)l2)^{s_2^{\prime }}\\ &\cdot \prod _{j=1}^{n_2}[H_2(jl1)^{s_1^{\prime }} \cdot H_2(jl2)^{s_2^{\prime }}]^{\mathcal {M}_{i,j}} \end{align*}
View SourceRight-click on figure for MathML and additional features.

ct^{\prime \prime }=ct^{\prime }\cdot T_1^{s_1^{\prime }} \cdot T_2^{s_2^{\prime }} and set ct_i^{\prime }=(ct_{i,1}^{\prime },ct_{i,2}^{\prime },ct_{i,3}^{\prime }).

6) Finally it outputs the sanitized ciphertext CT^{\prime }=(ct_0^{\prime },ct_1^{\prime },\ldots,ct_{n_1}^{\prime },ct^{\prime \prime }).

Algorithm 
Algorithm 
Finally, function \mathbf Decrypt() is run by the data receiver to recover the message. The process of this function is shown in Function 5.

Function 5. Decrypt
INPUT: The master public key mpk, the sanitized ciphertext CT^{\prime } and the secret key sk.

OUTPUT: The recorded message msg.

1) The receiver parses the ciphertext CT^{\prime } as CT=(ct_0,ct_1,\ldots,ct_{n_1},ct^{\prime }) and the secret key sk=(sk_0,{sk_y}_{y\in S},sk^{\prime },sk_{\sigma }).

2) If the attributes in the secret key sk satisfy the access structure (\mathcal {M},\rho) in ciphertext CT, then according to Eq. (1) we can always find a set of constants {\gamma _i}_{\lbrace i=1,\ldots,n_1\rbrace } that satisfy the equation, then compute: \begin{align*} C&=ct^{\prime }\cdot e\bigg(\prod _{i=1}^{n_1}ct_{i,1}^{\gamma _i},sk_{0,1}\bigg) \cdot e\bigg(\prod _{i=1}^{n_1}ct_{i,2}^{\gamma _i},sk_{0,2}\bigg) \\ & \cdot e\bigg(\prod _{i=1}^{n_1}ct_{i,3}^{\gamma _i},sk_{0,3}\bigg)\\ D &= e\bigg(sk_1^{\prime } \cdot \prod _{i=1}^{n_1}sk_{\rho (i),1}^{\gamma _i},ct_{0,1}\bigg) \cdot e\bigg(sk_2^{\prime } \cdot \prod _{i=1}^{n_1}sk_{\rho (i),2}^{\gamma _i},ct_{0,2}\bigg)\\ &\cdot e\bigg(sk_3^{\prime } \cdot \prod _{i=1}^{n_1}sk_{\rho (i),3}^{\gamma _i},ct_{0,3}\bigg) \end{align*}
View Source

3) Then it recovers and outputs the message as msg=\frac{C}{D}.


4.2 System Operations
The AACE scheme is designed for cloud-edge data sharing. The whole process of AACE includes system initialization, user registration, file sharing, file sanitize, and file access operations. The main operations are shown in Fig. 2.

{{\sf System initialization}}: In this phase, CA runs the \sf setup algorithm to obtain a master public key mpk and master secret key msk.


Fig. 2.
System operations.

Show All

{{\sf User registration}}: When a user enters the data sharing system for the first time, CA will run \sf keygen\rightarrow (pk,sk) to generate a pair of keys, and return them to the user (senders and receivers).

{{\sf File sharing}}: The sender employs a searchable encryption scheme to encrypt data file and then uses the proposed AACE algorithm to encrypt the encryption key k and the associated file tag t. Let ct_m=SE(k,m) denote the encryption of the sharing data and ct_k=AACE.Encrypt(pp,(k,t)) to be the encryption of the keys and the file tag. After that, the sender computes a token tkn=PRF(k,t) where PRF is a pseudo-random function keyed by k. The token will be used for the downloading authentication, since only the receivers whose attributes satisfy the access policy can decrypt the ciphertext ct_k. Then the token along with (ct_m,ct_k) will be sent to the edge server.

{{\sf File sanitizing}}: When the edge server receives tkn and (ct_m,ct_k) from the sender, it first runs the \sf sanitize algorithm to process the ct_k. If the sender can share the data with the specified receivers, the edge server will send (tkn, ct_m) to the cloud server and broadcast the sanitized ciphertext ct_k^{\prime } to all receivers.

{{\sf File access}}: The receiver uses his secret key to decrypt the ct_k^{\prime }, when the attributes in his keys satisfy the access structure, then he can retrieve the message (k,t). Then he computes tkn=PRF(k,t) and sends this to the cloud server. If the token is valid, the cloud server will retrieve the data file and send it to the edge server closer to the receiver.

SECTION 5Security Analysis of Our Scheme
In this section, we first analyze the correctness of our construction and then provide a formal security proof of our scheme. Specifically, we deduce the correctness and security to the underlying primitive. From the proof we can conclude that our scheme satisfies the no-read rule security and the no-write rule security.

5.1 Correctness Analysis
For a valid signature \theta =g_2^{(\alpha +r\beta)\boldsymbol{c_1}^*-r\boldsymbol{c_2}^*}, it holds \begin{align*} &e(g_1^{\boldsymbol{c}_1+\beta \boldsymbol{c}_2},\theta) = e(g_{1}^{\boldsymbol{c_{1}}+\beta \boldsymbol{c_{2}}} ,g_2^{(\alpha +r\beta)\boldsymbol{c_{1}}^*-r\boldsymbol{c_2}^*})\\ &=e(g_1,g_2)^{(\alpha +r\beta)\boldsymbol{c_{1}}\boldsymbol{c_{1}}^*-r\beta \boldsymbol{c_{2}}\boldsymbol{c_{2}}^* =e(g_1,g_2)^{\alpha \boldsymbol{c_{1}}\boldsymbol{c_{1}}^*=T_3}} \end{align*}
View SourceFor a sanitized ciphertext CT^{\prime }, \begin{align*} D &= e\bigg(sk_1^{\prime } \cdot \prod _{i=1}^{n_1}sk_{\rho (i),1}^{\gamma _i},ct_{0,1}\bigg) \cdot e\bigg(sk_2^{\prime } \cdot \prod _{i=1}^{n_1}sk_{\rho (i),2}^{\gamma _i},ct_{0,2}\bigg)\\ &\cdot e\bigg(sk_3^{\prime } \cdot \prod _{i=1}^{n_1}sk_{\rho (i),3}^{\gamma _i},ct_{0,3}\bigg)\\ &=e(sk_1^{\prime },ct_{0,1})\cdot e(sk_2^{\prime },ct_{0,2})\cdot e(sk_3^{\prime },ct_{0,3})\cdot e\bigg(\prod _{i=1}^{n_1}sk_{\rho (i),1}^{\gamma _i},ct_{0,1}\bigg)\\ &\cdot e\bigg(\prod _{i=1}^{n_1}sk_{\rho (i),2}^{\gamma _i},ct_{0,2}\bigg)\cdot e\bigg(\prod _{i=1}^{n_1}sk_{\rho (i),3}^{\gamma _i},ct_{0,3}\bigg) \end{align*}
View SourceThen we take the first component g_1^{d_t} of sk_i^{\prime } and compute, \begin{align*} &e(g_1^{d_1},ct_{0,1})\cdot e(g_1^{d_2},ct_{0,2})\cdot e(g_1^{d_3},ct_{0,3})\\ &=e(g_1,g_2)^{d_1a_1(s_1+s_1^{\prime })}\cdot e(g_1,g_2)^{d_2a_2(s_2+s_2^{\prime })}\\ &\cdot e(g_1,g_2)^{d_3(s_1+s_1^{\prime }+s_2+s_2^{\prime })}=T_1^{s_1+s_1^{\prime }}\cdot T_2^{s_2+s_2^{\prime }} \end{align*}
View Sourcewhich can be divided by the ct^{\prime } in the sanitized ciphertext, and for the rest components in C and D, \begin{align*} \prod _{i=1}^{n_1}ct_{i,l}^{\gamma _i}&=\prod _{i=1}^{n_1}\cdot H_1(\rho (i)l1)^{(s_1+s_1^{\prime })\gamma _i} \cdot H_1(\rho (i)l2)^{(s_2+s_2^{\prime })\gamma _i}\\ &\cdot \prod _{j=1}^{n_2}[H_2(jl1)^{(s_1+s_1^{\prime })} \cdot H_2(jl2)^{(s_2+s_2^{\prime })}]^{\gamma _i\mathcal {M}_{i,j}}\\ &=\prod _{j=1}^{n_2}[H_2(jl1)^{(s_1+s_1^{\prime })} \cdot H_2(jl2)^{(s_2+s_2^{\prime })}]^{\sum _{i=1}^{n_1}\gamma _i\mathcal {M}_{i,j}}\\ &\cdot \prod _{i=1}^{n_1}\cdot H_1(\rho (i)l1)^{\gamma _i(s_1+s_1^{\prime })} \cdot H_1(\rho (i)l2)^{\gamma _i(s_2+s_2^{\prime })}\\ &=H_2(1l1)^{(s_1+s_1^{\prime })} \cdot H_2(1l2)^{(s_2+s_2^{\prime })}\\ &\cdot \prod _{i=1}^{n_1}\cdot H_1(\rho (i)l1)^{\gamma _i(s_1+s_1^{\prime })} \cdot H_1(\rho (i)l2)^{\gamma _i(s_2+s_2^{\prime })}\\ \end{align*}
View SourceThen it is easy to see that the rest components in C and D are equal.

5.2 Security Analysis
First, we will use some compact representations to simplify the proof. Following [40], in our scheme, [x]_1 stands for g_1^x, [y]_2 stands for g_2^y and [z]_T stands for e(g_1,g_2)^z. For a column vector \boldsymbol{v}:=(v_1,\ldots,v_n)^T, [\boldsymbol{v}]_1 is a n-dimensional tuple (g_1^{v_1},\ldots,g_1^{v_n})^T. It is similar for a matrix \mathcal {M}. And for two matrices \boldsymbol{A,B}, [\boldsymbol{A}^T\boldsymbol{B}]_T denotes e([\boldsymbol{A}]_1,[\boldsymbol{B}]_2). The outputs of \sf Samp(\lambda) is \begin{equation*} {\mathrm {Z}}: = \left[ {\begin{array}{c}{u_1}\\ 0\\ 1 \end{array}\begin{array}{c}0\\ {{u_2}}\\ 1 \end{array}} \right],{z^ \bot }: = \left[ {\begin{array}{c}u_1^{ - 1}\\ {u_2^{ - 1}}\\ { - 1} \end{array}} \right], \end{equation*}
View Sourcewhere u_1,u_2{\stackrel{R}{\longleftarrow }}Z_p^*. If we set \begin{equation*} \boldsymbol{A} = \left[ \begin{array}{c}{a}{a_1}\\ 0\\ 1 \end{array}\begin{array}{c}0\\ {{a_2}}\\ 1 \end{array} \right],\;\boldsymbol{r} = \left[ {\begin{array}{c}{r_1}\\ {{r_2}} \end{array}} \right],\;\boldsymbol{r}^{\prime} = \left[ {\begin{array}{c}{r_1}\\ {{r_2}}\\ r \end{array}} \right] \end{equation*}
View SourceRight-click on figure for MathML and additional features.then we can rewrite the \sf DLIN assumption as \begin{equation*} ([\boldsymbol{A}]_1,[\boldsymbol{A}]_2,[\boldsymbol{Ar}]_1,[\boldsymbol{Ar}]_2)\approx ([\boldsymbol{A}]_1,[\boldsymbol{A}]_2,[\boldsymbol{r^{\prime }}]_1,[\boldsymbol{r^{\prime }}]_2) \end{equation*}
View SourceRight-click on figure for MathML and additional features.where the symbol \approx means the former is indistinguishable from the latter.

Theorem 1.
Our attribute based access control encryption scheme satisfies the no-read rule if no adversary can efficient break the experiment \sf Expt_{\Pi _{AACE},\mathcal {A}}^{read}(\lambda,b) with a nonnegligible probability.

Proof.
We use a series of hybrid experiments to prove the security. The zeroth hybrid experiment, \sf Hyb_0, is of course the AACE security experiment \sf Expt_{\Pi _{AACE},\mathcal {A}}^{read}(\lambda,b). At first \mathcal {C} runs the \sf setup algorithm to initialize the system and obtain mpk and msk. It then generates the public-secret key pair \sf (pk, sk)\leftarrow keygen and gives \sf mpk, pk to \mathcal {A}. Upon receiving a query from \mathcal {A}, \mathcal {C} runs the \sf keygen algorithm as in the real scheme to interact with \mathcal {A}. When \mathcal {A} makes a challenge query with a pair of messages \sf msg_0,msg_1\in M, the challenger \mathcal {C} answers the queries by computing the \sf encrypt(sk,msg_b) algorithm.

We first revise the experiment. This modified form will be the first hybrid experiment, \sf Hyb_1. The modified experiment \sf Expt_{\Pi _{AACE},\mathcal {A}}^{read}(\lambda,b) is defined as follows

{{\sf setup}}: Run the group generator to obtain the public parameters as before. Then use the \sf Samp(p) algorithm to obtain (\boldsymbol{A},\boldsymbol{a}^\bot),(\boldsymbol{B},\boldsymbol{b}^\bot). Select d_1,d_2,d_3\stackrel{R}{\longleftarrow }Z_p and set \boldsymbol{d}=(d_1,d_2,d_3)^T be a column vector. Finally, it outputs mpk:=([\boldsymbol{A}]_2,[\boldsymbol{d}^T\boldsymbol{A}]_T) and msk:=(pp,\boldsymbol{A},\boldsymbol{B},[\boldsymbol{d}]_1).

{{\sf key\ query}}: The challenger \mathcal {C} maintains two lists L_1 and L_2 to simulate the random oracle. The entries of L_1 is formed by (x,\boldsymbol{W}_x) or (j,\boldsymbol{U}_j) where x\in \lbrace 0,1\rbrace ^* and j\leftarrow Z_p^*, and \boldsymbol{W}_x,\boldsymbol{U}_j are 3\times 3 matrices over Z_p. And the entries of L_2 is formed by (q,r) where q denotes the query that \mathcal {A} will make, and r is an element in G. When A makes a query of xlt, for l\in \lbrace 1,2,3\rbrace and t\in \lbrace 1,2\rbrace, \mathcal {C} first checks whether the query (xlt,r) has been queried in L_2. If the query exists, \mathcal {C} returns r, otherwise \mathcal {C} checks whether (x,\boldsymbol{W}_x) in L_1. If yes, \mathcal {C} will compute r:=[(\boldsymbol{W}^T_x\boldsymbol{A})_{l,t}]_1, then returns r and appends (xlt,r) to L_2. Otherwise, it picks a random 3\times 3 matrices \boldsymbol{W}_x and appends (x,\boldsymbol{W}_x) to L_1, then \mathcal {C} computes r as the former case and appends (xlt,r) to L_2. Finally, r is given to \mathcal {A}. When the query is 0xlt, \mathcal {C} checks whether the query (0jlt,r) can be found in L_2. If the query exists, \mathcal {C} returns r, otherwise \mathcal {C} checks whether (j,\boldsymbol{U}_j) in L_1. If yes, \mathcal {C} will compute r:=[(\boldsymbol{U}^T_j\boldsymbol{A})_{l,t}]_1, then append (0jlt,r) to L_2 and return r. Otherwise, it picks a random 3\times 3 matrices \boldsymbol{U}_j and appends (j,\boldsymbol{U}_j) to L_1, then \mathcal {C} computes r as the former case and appends (0jlt,r) to L_2. Finally, r is given to \mathcal {A}. When the query is anything else, C checks whether (q,r) has been queried in L_2. If yes, then \mathcal {C} returns r. Else, \mathcal {C} selects r^{\prime }\in G and appends (q,r^{\prime }) to L_2. Finally, r^{\prime } is given to \mathcal {A}.

Upon receiving a key query Q from \mathcal {A}, \mathcal {C} first checks whether the query has been made. For every y\in Q, if (y,\boldsymbol{W}_y) or \boldsymbol{U}_1 cannot be found in list L_1, then \mathcal {C} generates them in the above way. Otherwise \mathcal {C} computes sk_0=[\boldsymbol{Br}]_2,sk_y=[\boldsymbol{W}_y\boldsymbol{Br}+\sigma _y\boldsymbol{a}^\bot ], and sk^{\prime }=[\boldsymbol{d}+\boldsymbol{U}_1\boldsymbol{Br}+\sigma ^{\prime }\boldsymbol{a}^\bot ]_1, where r_1,r_2,\sigma ^{\prime },\sigma _y are randomly picked from Z_p, and \boldsymbol{r} denotes a 2-dimensional vector (r_1,r_2)^T. Finally, (sk_0,\lbrace sk_y\rbrace _{y\in S},sk^{\prime }) is given to \mathcal {A}.

{{\sf encryption\ query}}: When \mathcal {C} receives a message \sf msg and an access policy (\mathcal {M},\rho) from \mathcal {A}, \mathcal {C} first checks whether the query has been made. If [(\boldsymbol{W}_{\rho (i)}^T\boldsymbol{A})_{l,t}]_1 or [(\boldsymbol{U}_j^T\boldsymbol{A})_{l,t}]_1 cannot be found in list L_2, then \mathcal {C} generates them in the above way. Otherwise \mathcal {C} computes ct_0=[\boldsymbol{As}]_2,ct_i=[\boldsymbol{W}_{\rho (i)}^T\boldsymbol{As}+\sum _{j=1}^{n_2}(\mathcal {M})_{i,j}\boldsymbol{U}_j^T\boldsymbol{As}]_1, and ct^{\prime }=[\boldsymbol{d}^T\boldsymbol{As}]_T\cdot msg, where s_1 and s_2 are randomly picked from Z_p, and \boldsymbol{s} denotes a 2-dimensional vector (s_1,s_2)^T. Finally, (ct_0,\lbrace ct_i\rbrace _{i=1,\ldots,n_1},ct^{\prime }) is given to \mathcal {A}.

{{\sf sanitize\ query}}: When \mathcal {C} receives a query of (ct,A_S,A_R,\theta,(\mathcal {M},\rho)), if A_S and A_R satisfies \pi (A_S,A_R)=1 and the signature is valid, then he checks whether the query has been made. If [(\boldsymbol{W}_{\rho (i)}^T\boldsymbol{A})_{l,t}]_1 or [(\boldsymbol{U}_j^T\boldsymbol{A})_{l,t}]_1 cannot be found in list L_2, then \mathcal {C} generates them as the Encryption query does. Otherwise \mathcal {C} computes ct_0^{\prime }=ct_0[\boldsymbol{As^{\prime }}]_2,ct_i^{\prime }=ct_i[\boldsymbol{W}_{\rho (i)}^T\boldsymbol{As^{\prime }}+\sum _{j=1}^{n_2}(\mathcal {M})_{i,j}\boldsymbol{U}_j^T\boldsymbol{As^{\prime }}]_1, and ct^{\prime \prime }=ct^{\prime }[\boldsymbol{d}^T\boldsymbol{As^{\prime }}]_T, where s_1 and s_2 are randomly picked from Z_p, and \boldsymbol{s^{\prime }} denotes a 2-dimensional vector (s_1^{\prime },s_2^{\prime })^T. Finally, (ct_0^{\prime },\lbrace ct_i^{\prime }\rbrace _{i=1,\ldots,n_1},ct^{\prime \prime }) is given to \mathcal {A}.

{{\sf challenge}}: \mathcal {A} requests a pair of messages \sf (msg_0,msg_1), the challenger selects a random bit b and runs the encrypt and sanitize algorithm to obtain a sanitized ciphertext ct^{\prime }. Finally, \mathcal {A} outputs a bit b^{\prime }.

Lemma 1.
If \Pi _{{\sf ABE}} is a fully secure attribute scheme, then the above construction is a secure attribute based access control encryption scheme.

Proof.
Suppose there exists an efficient adversary \mathcal {A} that can break the no-read rule experiment. Then we can construct an adversary \mathcal {A}^{\prime }. \mathcal {A}^{\prime } is given the input 1^\lambda and access to all the query oracle. When \mathcal {A} makes an encryption query on a message \sf msg\in M, \mathcal {A}^{\prime } runs a encryption query and returns a ciphertext. When \mathcal {A} queries its sanitize oracle on a ciphertext \sf ct, \mathcal {A}^{\prime } runs a sanitize query and returns the sanitized ciphertext. When \mathcal {A} makes a challenge query and outputs a bit b^{\prime }. \mathcal {A}^{\prime } outputs 1 if \mathcal {A} succeeds, and 0 otherwise. We assume all the query oracle is random oracle, the view of \mathcal {A} when run as a subroutine of \mathcal {A}^{\prime } is distributed identically to the view of \mathcal {A} in \Pi _{{\sf AACE,\mathcal {A}}}^{read}. Thus \begin{equation*} Pr|\Pi _{{\sf AACE,\mathcal {A^{\prime }}}}^{read}=1|-Pr|\Pi _{\mathcal {A}}^{read}=1|=negl(\lambda). \end{equation*}
View SourceSince the security of our attribute based access control encryption can be reduced to the DLIN assumption, and the detailed proof can be found in [41]. That means Pr|\Pi _{\mathcal {A}}^{read}=1|=negl(\lambda) and thus Pr|\Pi _{AACE,\mathcal {A^{\prime }}}^{read}=1|=negl(\lambda). We can conclude that our attribute based access control encryption satisfies the no-read rule.

Theorem 2.
Our attributes access control encryption satisfies the no-write rule if no adversary can efficiently break the experiment \sf Expt_{\Pi _{AACE},\mathcal {A}}^{write}(\lambda,b) with a nonnegligible probability.

Lemma 2.
If no efficient adversary can forge a valid signature with a nonnegligible probability, then our Construction satisfies the no-write rule.

At the beginning, we will describe the experiment in the same way to simplify the proof.

{{\sf key\ query}}: When receiving an identity id_i, \mathcal {C} runs \sf Dual(\cdot) to obtain two orthonormal bases \boldsymbol{C},\boldsymbol{C}^*, and computes pk=([\alpha \boldsymbol{d}_1\boldsymbol{d}_1^*]_T,[\boldsymbol{d}_1]_1,[\boldsymbol{d}_2]_1),sk=(\alpha,[\boldsymbol{d}_1^*]_2,[\boldsymbol{d}_2^*]_2). Then it returns (pk,sk), and pk is given to \mathcal {A}.

{{\sf signature\ query}}: When \mathcal {A} makes a signature query, \mathcal {C} picks r\stackrel{R}{\Longleftarrow }Z_p and computes \theta =[(\alpha +r\cdot H(msg))\boldsymbol{d}_1^*-r\boldsymbol{d}_2^*]_2 as the signature.

{{\sf verify}}: On inputting a key pair (pk,sk), a message msg\in M, and a signature \theta, it outputs 1 if and only if e([\boldsymbol{d}_1+H(msg)\boldsymbol{d}_2]_1,\theta)=[\alpha \boldsymbol{d}_1\boldsymbol{d}_1^*]_T.

{{\sf challenge}}: \mathcal {A} is given pk and the access to the signature query oracle. We use Q to denote the query set that \mathcal {A} makes. Note that \mathcal {A} can make as many queries as it wants. Finally, \mathcal {A} outputs (msg,\theta). \mathcal {A} succeeds if and only if \sf verify(msg,\theta)=1 and msg\notin Q. In this case, the experimental output is defined to be 1.

Proof.
It is clear that for any malicious encryptor, if he cannot forge a valid signature, the edge server would terminate the communication and drop the message. The messages will not be delivered to the receivers. So the no-write rule is reduced to the security of the signature. Next, we will provide the proof.

Lemma 3.
If \Pi is a secure signature scheme and H is a secure hash function, then the above construction is a secure signature scheme.

Proof.
Let \Pi ^{\prime } denote the above construction, and \mathcal {A}^{\prime } be an efficient adversary. Q denotes a set of queries \mathcal {A} has made, whose entries are formed by (msg,\theta), and let (msg^{\prime },\theta ^{\prime }) denote the final output of \mathcal {A}^{\prime }. We assume that msg^{\prime }\notin Q. We define col to be the event that H(msg)=H(msg^{\prime }). Then we have \begin{equation*} \begin{split} &Pr|\Pi _{\mathcal {A}^{\prime }}^{^{\prime }(forge)}=1| \\ &=Pr|\Pi _{\mathcal {A}^{\prime }}^{^{\prime }(forge)}=1\wedge col|+ Pr|\Pi _{\mathcal {A}^{\prime }}^{^{\prime }(forge)}=1\wedge \overline{col}| \\ &\leq Pr|col|+Pr|\Pi _{\mathcal {A}^{\prime }}^{^{\prime }(forge)}=1\wedge \overline{col}|. \end{split} \tag{3} \end{equation*}
View Source

Subsequently, we show that both terms in the above equation are negligible to complete the proof. Intuitively, Pr|col| is negligible by the collision resistant of H, and the second term is negligible. First, we construct the following algorithm to find a collision in H.

Run key query to get pk and give it to \mathcal {A}^{\prime }.

\mathcal {A}^{\prime } makes a signature query of \sf msg_i, the algorithm computes \theta =[(\alpha +r\cdot H(msg_i))\boldsymbol{d}_1^*-r\boldsymbol{d}_2^*]_2 and adds (msg_i,\theta) to the query list Q. Finally \theta is given to \mathcal {A}^{\prime }.

When \mathcal {A}^{\prime } outputs (msg^{\prime },\theta ^{\prime }), if there exists a message msg_i\in Q that H(msg^{\prime })=H(msg_i), then the algorithm outputs (msg^{\prime },msg_i).

Let us analyze the above algorithm. When running the above algorithm to get a signature, the view of \mathcal {A}^{\prime } is distributed identically to the view of \mathcal {A}^{\prime } in the experiment \Pi _{\mathcal {A}^{\prime }}^{^{\prime }(\sf forge)}. Particularly, the signature given to \mathcal {A}^{\prime } in the above algorithm has the same distribution as the signature that \mathcal {A}^{\prime } obtained in the experiment \Pi _{\mathcal {A}^{\prime }}^{^{\prime }(\sf forge)}. Thus, when the collision occurs, we have \begin{equation*} Pr|Hash-col_{H}=1|=Pr|col|. \end{equation*}
View SourceRight-click on figure for MathML and additional features.

Since H is a secure hash function, we can conclude that Pr|col| is negligible. We then show that the second term is negligible. Let \mathcal {A} be an adversary that attacks \Pi _{sig} in \Pi _{\mathcal {A}^{\prime }}^{^{\prime }(\sf forge)}, the adversary \mathcal {A} is given access to the signature query as the above algorithm. When \mathcal {A}^{\prime } makes a query of \sf msg_i, \mathcal {A} computes \widehat{msg_i}=H(msg_i) and requests a signature \theta on \widehat{msg_i}. Finally, \theta is given to \mathcal {A}^{\prime }. When \mathcal {A}^{\prime } outputs (msg^{\prime },\theta ^{\prime }), \mathcal {A} outputs (H(\widehat{msg^{\prime }}),\widehat{\theta ^{\prime }}).

Consider the above experiment \Pi _{\mathcal {A}}^{(\sf forge)}, the view of \mathcal {A}^{\prime } when run as a subroutine by \mathcal {A} is distributed identically to the view in the experiment \Pi _{\mathcal {A}^{\prime }}^{^{\prime }(\sf forge)}. Whenever both \Pi _{\mathcal {A}^{\prime }}^{^{\prime }(\sf forge)}=1 and the collision col does not occur, \mathcal {A} outputs a valid forgery. That means, \begin{equation*} Pr|\Pi _{\mathcal {A}}^{(\sf forge)}=1|=Pr|\Pi _{\mathcal {A}^{\prime }}^{^{\prime }(\sf forge)}\wedge \overline{col}|. \end{equation*}
View SourceRight-click on figure for MathML and additional features.Since \Pi is a secure signature scheme, the detail proof can be found in [42]. we can conclude that the former probability is negligible. This concludes the proof of the lemma.

SECTION 6performance Evaluation
In this section, the computation and communication overhead of the proposed scheme are evaluated and compared with other schemes [19], [26]. In Table 4, we provide a comparison of computation overhead to analyze the performance of these schemes in the key generation, encryption, sanitization and decryption. Moreover, a comparison of communication overhead is provided in Table 6 with regard to the size of the user key, the size of the ciphertext and the size of the sanitized ciphertext. They are the theoretical analysis of the proposed scheme and the comparative schemes, and they indicate the reasons for the difference between these schemes.

TABLE 4 Comparisons of Computation Overhead
Table 4- 
Comparisons of Computation Overhead
TABLE 5 Benchmark Time of Different Operations (ms)
Table 5- 
Benchmark Time of Different Operations (ms)
TABLE 6 Comparisons of Communication Overhead

In order to verify the comparison in Tables 4 and 6, we implement these schemes using the charm 0.50 framework in Python 3.6 on a laptop with Intel(R) Core(TM) i5-4210M CPU and 8 GB memory running Ubuntu 18.04. Particularly, since the symmetric bilinear pairings have serious security issues [43], we use the MNT224 curve for pairings. We use the access policy like ‘\sf A_1~and~A_2~and\cdots and~A_n’ which ensures that all the n attributes are involved in the decryption procedure. In our experiments, the running time is computed by calculating the average of running each procedure 10 times with the same input. The experimental results can be found in Figs. 3 and 4. In Table 5 we list the benchmark time (in millisecond) of different operations on MNT224 curve.

Fig. 3. - 
Computation overhead under the same settings.
Fig. 3.
Computation overhead under the same settings.

Show All

Fig. 4. - 
Communication overhead under the same settings.
Fig. 4.
Communication overhead under the same settings.

Show All

First, we analyze the computation overhead of these schemes. As shown in Table 5, the exponentiation and pairing operations are the most time-consuming. And the exponentiation operation on G_2 requires much longer time than the exponentiation operation on G_1 and G_T.

It can be seen from Table 4 that the scheme proposed by Han et al. [19] requires the least exponential operation on G_2. The proposed scheme requires more exponentiation operations on G_1. And HAPRE [26] requires the most exponentiation operations on G_2. Therefore, the experimental results depicted in Fig. 3a show that the scheme of Han et al. [19] performs best in key generation. The proposed scheme does not perform very well, but it is fully secure under standard assumption which achieves better security. In addition, it is admissible for a central authority with relatively large computation power.

From Table 4 we can find that the proposed scheme requires the least exponentiation operations on G_2. However, HAPRE [26] requires the most exponentiation operations on G_2. Therefore, from the experimental results depicted in Fig. 3b we can see that the proposed scheme performs best in encryption. Since the sanitization of the proposed scheme and Han's scheme [19] are similar to the encryption, we will not analyze it separately. As HAPRE [26] is actually an outsourcing decryption scheme, the sanitization requires a large number of pairing operations to partially decrypt the ciphertext. The experimental results can be found in Fig. 3c. We can see that the proposed scheme still has superior performance.

It can be seen from Table 4 that the decryption time is mainly related to the number of pairing operations. HAPRE [26] outsources a large number of pairing operations to the sanitization step, so it needs the least decryption time. The required pairing operation of decryption of Han et al. [19] is linear with the number of attributes used in the decryption, so it takes the most time. The pairing operation required in decryption of the proposed scheme is independent of the number of attributes, so it also has the better performance. The experimental results can be found in Fig. 3d. We can see that the decryption of the proposed scheme only takes about 0.02s. It is almost as good as HAPRE [26] which uses outsourcing decryption. Besides, the computation overhead of the proposed scheme in setup takes about 0.02s and it takes only about 0.04s for the edge server to determine whether a sender can share files with the receiver, which are both very small constants.

Second, we analyze the communication overhead of these schemes. Before the analysis, we need to recall that the element on G_2 is 3 times the size of the element on G_1 in the MNT224 curve. From Table 6, we can see that the user key of Han et al. [19] has the fewest elements on G_2. The proposed scheme has the fewest elements on G_2 in the ciphertext. Furthermore, the sanitized ciphertext of HAPRE [26] is partially decrypted, so the sanitized ciphertext in their scheme is the smallest and does not change with the increase of the number of attributes. The experimental results can be found in Fig. 4. Note that the results are both evaluated by encrypting a random element in G_T. Because the sharing data usually is very large, the typical method is to use a KEM method wherein ABE is used to encrypt a random element in G_T and use the random element to generate a key K. Then the shared data is encrypted using the key K through an efficient symmetric encryption scheme. Thus the communication cost is reduced to the cost of transmitting an encryption of key K. Although the users’ key size in our scheme is the largest in these schemes, in fact, even when the number of attributes is 50, the key size is only about 14 KB.

In order to evaluate the overhead in the actual transmission process, we used three cloud servers to simulate the local user, edge server and cloud server, respectively. The local user and the edge server are located in the same city, the cloud server is located in the other city. The bandwidth is set to be 50Mbps and the size of the test file is from 128 KB to 4096 KB. The results are generated by caculating the average of 100 statistics obtained every 5 minutes. It can be seen from Fig. 5a that the upload time that the file is sanitized by the edge server and then uploaded to the cloud server is basically the same as the time that the file is directly uploaded from the local to the cloud server for sanitization. In Fig. 5b, Case 1 represents that the data sender and the data receiver are in the same area, and the data user can download the file directly from the edge server; In Case 2, the data sender and the data receiver are not in the same area. In this case, the data file can be obtained from the cloud server through the edge server close to the receiver; In Case 3, when the edge server is not used, users need to download files directly from the cloud server. The results show that using the edge server to forward the file will significantly reduce the time of downloading a data file in Case 1. And in Case 2, the transmission time is basically the same as the time of Case 3. Although the download process in Case 2 may increase the communication overhead, it is worth noting that in the attribute-based encryption, a group of users usually have the same decryption rights. Therefore, when the cloud server files are sent to the edge server, other users with the same attributes can get the data directly from the edge serve, thus reducing the transmission cost of data download. The above analysis of experimental results shows that we can use edge servers to process messages and forward them, leading to the lower communication delay. Therefore, our construction is efficient and practical.


Fig. 5.
Transmission overhead.

Show All

SECTION 7Conclusion
In this paper, we proposed a novel practical attribute-based access control encryption scheme for cloud-edge data sharing, which not only enforces the access control of the encrypted data, but also restricts the information flow of the shared data. The scheme satisfied the no-read and no-write rules, which means it is secure against malicious senders and non-privileged receivers. Then, we presented the operations of the cloud-edge data sharing system. Finally, we implemented the proposed construction to investigate its performance. The experimental results showed that the proposed scheme is efficient and practical.