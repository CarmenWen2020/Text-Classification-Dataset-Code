Mobile Edge Computing (MEC) has become an attractive solution to enhance the computing and storage capacity of mobile devices by leveraging available resources on edge nodes. In MEC, the arrivals of tasks are highly dynamic and are hard to predict precisely. It is of great importance yet very challenging to assign the tasks to edge nodes with guaranteed system performance. In this article, we aim to optimize the revenue earned by each edge node by optimally offloading tasks to the edge nodes. We formulate the revenue-driven online task offloading (ROTO) problem, which is proved to be NP-hard. We first relax ROTO to a linear fractional programming problem, for which we propose the Level Balanced Allocation (LBA) algorithm. We then show the performance guarantee of LBA through rigorous theoretical analysis, and present the LB-Rounding algorithm for ROTO using the primal-dual technique. The algorithm achieves an approximation ratio of 2(1+ξ)ln(d+1) with a considerable probability, where d is the maximum number of process slots of an edge node and ξ is a small constant. The performance of the proposed algorithm is validated through both trace-driven simulations and testbed experiments. Results show that our proposed scheme is more efficient compared to baseline algorithms.

SECTION 1Introduction
Nowadays, pervasive mobile computing and the Internet of Things are driving the development of many new compute-intensive and latency-sensitive applications, such as mobile gaming and virtual/augmented reality (VR/AR), and massive data will be generated at the edge of networks. However, many devices, such as smartphones and wearable devices, have a limited processing capacity and may not be able to process their data. Due to network bandwidth, storage and data privacy concerns, it is also impractical, and often unnecessary, to send all of the data to a remote cloud. Fortunately, Mobile-Edge Computing (MEC) has been gaining strong momentum as an emerging paradigm that provides cloud computing-like capabilities including computing and storage resources, at the edge of wireless access networks. Although MEC is less powerful than a remote cloud [1], [2], the transmission latency between a user and a mobile edge cloud is much lower than that of the remote cloud as it is located at the network edge.

In a real-world task-offloading scenario, the arrivals of users are dynamic and the tasks must be processed quickly. This motivates us to consider the online scenario where users arrive dynamically, and resources are allocated based on only the past offloading decisions and current states of the edge nodes. Therefore, making correct decisions when the task arrivals are uncertain is challenging. Meanwhile, with the increasing complexity of applications and wireless networks, the scale of the dynamic offloading problem is an enormous obstacle [3].

To tackle this issue, Li et al. [4] proposed an online computation rate maximization algorithm using the Lyapunov method for a multi-user MEC system by jointly managing the radio and computational resources and allocating time for energy transfer and data transmission; Chen et al. [5] formulated a multi-user multi-task computation offloading problem for green MEC and used the Lyapunov optimization approach to determine the energy harvesting policy. Although the Lyapunov optimization is often used to deal with online problems, it takes time to converge, and cannot fully adapt to bursts of task requests in a short time. Some other studies chose to use deep learning or deep Q-network (DQN) methods [6], [7], [8], [9], [10], [11], [12], which require training in advance and have no explicit theoretical performance guarantees.

Meanwhile, these studies mainly focused on the energy-efficient and resource-efficient computational service offloading scheme in MEC. Only a few works have considered the revenue maximization problem in task offloading [13], [14], [15], [16], and these works have considered either the edge offline scenario or cloud-edge competition scenario.

Service providers such as Amazon and Alibaba have deployed many edge nodes and built their own edge node server platforms, which can provide the computing power of content delivery network (CDN) edge nodes (ENS [17] and Lambda@edge[18]). Enterprises or individuals can rent their edge nodes by paying on demand or on time. In this work, we study the revenue-driven online task offloading (ROTO) problem in MEC. Specifically, we focus on offloading multiple computation intensive tasks to a set of edge nodes, and the objective is to maximize the revenue of edge nodes from the perspective of service providers. Fig. 1 illustrates a typical offloading scenario in which a set of edge nodes constitute a mobile edge cloud. Generally, edge node services are constructed based on the operator’s network and the task offloading is done by the Base Stations (BS) of the operators. We assume that the service provider can obtain the information of the BS and control some functions of the BS through software define network (SDN). Users can offload their tasks to the edge nodes to extend their own computing ability via paying for task execution. Moreover, a user can offload its task only to edge nodes if the user and edge nodes are within the communication range of the same BS. A user first sends its task to the nearby BS, then the BS decides how to offload the task to the edge nodes within its communication range according to the revenue, computing demand of the task, and states of the edge nodes.


Fig. 1.
System illustration. Multiple edge nodes constitute a mobile edge cloud. We aim to optimize the revenue earned by the edge nodes.

Show All

We first formulate the ROTO problem into an integer linear programming problem, then we prove that ROTO is NP-complete by reducing the multi-dimensional knapsack problem to it. To solve it, we first relax it to a linear fractional programming problem, i.e., ROTO-LP. We then present two important notions, level and move-up energy, that enable us to design an efficient algorithm, named level balanced allocation (LBA). By intelligently constructing a potential function and using the primal-dual schema, we prove that LBA can achieve an approximation ratio of 2(1+ξ)ln(d+1), in which d is the maximum number of the process slots of an edge node. Based on the intuitions obtained from designing LBA for ROTO-LP, we finally propose the level balanced rounding (LBR) algorithm for ROTO by combining LBA and the rounding technique. Using the Chernoff bound and probability analysis, we prove LBR can achieve the same approximation ratio as LBA with a high probability, i.e., at least 1−e−σn, where n is the number of users. We implemented LBR on our testbed consisting of 8 Raspberry Pis and 4 mobile phones. Trace-driven simulations and testbed experiments reveal the effectiveness of LBR.

Our main contributions are summarized as follows:

We develop a multi-user computation offloading framework for a mobile edge computing system to maximize the total revenue. We provide a formal formulation of the revenue-driven online task offloading (ROTO) problem, which proved to be NP-complete.

We design the Level Balanced Allocation (LBA) algorithm to solve ROTO-LP, which achieves an approximation ratio of 2(1+ξ)ln(d+1).

Based on LBA, we propose the Level Balanced Rounding (LBR) algorithm and obtain the solution of ROTO. We prove that LBR achieves an approximation ratio of 2(1+ξ)ln(d+1) with a probability of at least 1−e−σn.

We conduct trace-driven simulations and testbed experiments to evaluate the performance of the proposed algorithm. The results are shown from different perspectives to provide conclusions.

The rest of the paper is organized as follows. Prior works are reviewed in Section 2. The system model is discussed and the offloading problem is formulated in Section 3. The proof of the ROTO NP-hardness is also explained in Section 3. The online algorithm to provide maximum revenue is proposed and analyzed in Section 4. Simulation results and testbed experiments are investigated in Sections 5 and 6, respectively. In Section 7, we conclude the paper.

SECTION 2Related Work
In this section, we give a brief overview about some related works in regards to task offloading in mobile edge computing.

First of all, task offloading is divided into two categories according to whether there are dependencies between tasks. The problem of offloading dependent tasks in MEC is complicated thus most of works will make many assumptions. Kao et al. [19] concerned a dependent task assignment problem over multiple devices. However, they did not impose restrictions on the capacity of the devices, which makes their algorithm more inclined to offload the tasks on a few devices with more capable devices. GenDoc [20] jointly considered the problem of dependent task offloading and service caching placement with the objective of application completion time minimization. However, GenDoc does not consider the computing capacities when offloading tasks to edge nodes. In fact, mobile edge nodes are resource-sensitive and GenDoc may cause irrational use of limited computing resources. In the field of offloading independent tasks, Jošilon et al. [21] used game theory to coordinate offloading various task requests from multi-user to the mobile edge cloud. Zhu et al. [22] investigated the task offloading problem in wireless powered mobile edge computing. Zhao et al. and Ma et al. [23], [24] considered the factor of service caching when offloading tasks. Chen et al. [25] leveraged the idea of software defined network, and investigated the task offloading problem in ultra-dense networks. Tao et al. and Jošilo et al. [26], [27] focused on task offloading of autonomous devices. In this paper, we focus on offloading the independent tasks in MEC.

The above works considered offline scenarios only, that is, the arrival of all tasks is known in advance. However, to further enhance the agility of the mobile edge cloud, an online algorithm is more preferred. When considering online offloading scenarios, most studies chose to use deep learning [6], [7] or reinforcement learning methods [9], [10], [11] for different objectives such as maximizing the weighted sum computation rate [9], minimizing the energy consumption [6] and minimizing the running cost [7], [10], [11]. However, these works require training in advance and have no explicit theoretical performance guarantee. In addition to machine learning-related methods, Lyapunov optimization approach is often applied to analyze the online offloading. Chen et al. [5] discussed multi-user multi-task offloading scheduling schemes in a renewable mobile edge cloud system, and used Lyaponov optimization approach to determine the energy harvesting policy. Ning et al. [28] comprehensively consider both of MEC and could computing and design an iterative heuristic algorithm to minimize the offloading delay. Guo et al. [29] investigated the problem of collaborative mobile-edge computation offloading in 5G HetNets and proposed a game-theoretical computation offloading scheme. However, these studies mainly focused on the energy-efficient and resource-efficient computation offloading scheme in MEC. Different from theirs, we consider how to maximize the benefits of edge nodes from the perspective of service providers. In additional, Lyapunov method takes time to converge, and cannot fully adapt to bursts of task requests in a short time. We use the primal-dual theory instead of deep learning or Lyapunov’s theorem to solve the problem. What’s more, in solving this problem, we propose our algorithm with theoretical guarantees.

SECTION 3Model and Problem Formulation
In this section, we first elaborate the computation task model and edge node execution model. Then we formulate task computation offloading as an optimization problem to maximize offloading revenue. The goal of the optimization is to determine the optimal edge nodes to offload tasks for users based on the arrival of users and their resource requirements. For ease of presentation, we only consider the CPU resource. Other type of resources such as memory usage or disk I/O cycles can be similarly addressed [19], [30]. After that, we provide the proof of the ROTO NP-hardness.

3.1 Computation Task Model
Consider a time horizon T, which for simplicity is taken to be discrete but can be extended to be continuous. We assume that there are n independent users that need to offload their tasks to edge nodes, where the set of users is denoted as U={u1,u2,…,un}. The task of user ui is characterized by a set of parameters, {Si,βi,Tarri,Tddli,αi1,…,αij,…,αim}, in which Si denotes the input data size (in byte); βi denotes the number of CPU cycles required to process one byte of data [31]; Tarri and Tddli represent the arrival time and deadline of the task, respectively; αij represents the ratio between the revenue that edge node ej can get and the computing demand of ui [5], [32]. Note that, if ej and ui are not within the communication range of the same BS, we set αij as zero.

Considering the rapid development of 5G networks and short distance between users and edge nodes, we assume that the time of data transmission between a user and an edge node is small enough to be ignored [33]. Thus, the required computing demand (CPU cycles per second) of ui is equal to (βi⋅Si)/(Tddli−Tarri), which is denoted as bi. Based on this, we define the revenue that edge node ej can get if the task of ui is offloaded to ej as αijbi.

According to our survey, the price paid by the user is based on the computation resource used, service type and service time slot [34], [35], [36]. We focus on compute intensive tasks, which means the service types of all tasks are the same. And the price for running the same task on different edge nodes will not vary greatly. Thus we can assume that maxej∈C(i)αij≤(1+ξ)minej∈C(i)αij, where ξ is a small constant and C(i) is the set of edge nodes that can provide servers to ui.

In this paper, we focus on the scenarios in which the mobile device has very limited computational resources, and hence all the tasks should be offloaded to edge nodes for execution. The task of each user is atomic and cannot be further divided, and one task is assumed to be offloaded to only one edge node.

3.2 Edge Node Execution Model
We assume that there are m independent edge nodes that can provide computing service for users, where the set of edge nodes is denoted as E={e1,e2,…,em}. Edge node ej has Vj process slots, which means ej can process at most Vj tasks at the same time, and these process slots share the entire computing capacity. Denote yij as a binary indictor: yij=1 if the task of ui is offloaded to edge node ej and yij=0 otherwise. Hence
∀ ej∈E:∑i=1nyij≤Vj,(1)
View Source
∀ ui∈U,ej∈E:yij∈{0,1}.(2)
View Source

A user can connect to an edge node if the user and edge node are within the communication range of the same BS. Denote C(i) as the set of edge nodes that are within the communication range of the same BS as ui. To meet the task offloading feasibility constraints, it requires
∀ ui∈U:∑ej∈C(i)yij≤1,(3)
View Source
∀ ui∈U,ej∉C(i):yij=0.(4)
View Source

Denoting the computing capacity of edge node ej as Bj (CPU cycles per second). An edge node cannot provide computing resources that exceed its capacity. Hence
∀ ej∈E:∑i=1nbiyij≤Bj.(5)
View Source

In this paper we assume that the computing demand bi is not less than minej∈C(i)Bj/Vj. This assumption is reasonable, because there is no need for users to offload their task to edge nodes for processing if the computing demand is small.

3.3 Problem Formulation
In this work, we intend to maximize the overall revenue of edge nodes. The main problem studied is defined as follows:

Problem 1.
Given a time horizon T, a set of users U with parameters {Si,βi,Tarri,Tddli,αi1,…,αij,…,αim} corresponding to the task of ui, a set of edge nodes E with parameters {Bj,Vj} corresponding to ej, and n sets C(1),…,C(n) denoting the edge nodes that are connected to ui, the revenue-driven online task offloading problem is to find an allocation of tasks to edge nodes that maximizes the overall revenue.
max∑i=1n∑ej∈C(i)αijbiyij,(6)
View Source
s.t.(1)−(5),(7)
View Sourcewhere bi=(βiSi)/(Tddli−Tarri).

Theorem 1.
The ROTO is NP-complete.

Proof.
We prove this by reducing the multi-dimensional knapsack problem to ROTO, which is NP-complete. The multi-dimensional knapsack problem is defined as follows: the weight of knapsack item i is given by a D-dimensional vector wi¯¯¯¯¯={w1i,…,wiD} and the knapsack has a D-dimensional capacity vector {W1,…,WD}. Knapsack item i has its value vi. The target is to maximize the sum of values of items in the knapsack so that the sum of the weight in each dimension j does not exceed Wj.

We construct the tasks and edge nodes as follows:

We set the number of edge node to be 1, the process slot to be V and the process capacity to be B.

For each item i in knapsack, we construct a task ui in ROTO,

For the weight of item i, we construct a vector {1,bi} in ROTO,

For the value of item i, we construct the reward αibi of ui in ROTO.

For the capacity of knapsack, we construct a vector {V,B} in ROTO.

The construction can be finished in polynomial time; thus, we reduce solving the NP-complete multi-dimensional knapsack problem to solving a special case of ROTO, implying that ROTO is NP-complete.

With this transformation, we can prove the theorem easily: assume, without loss of generality, there is a solution to the multi-dimensional knapsack problem, then this solution is also the answer to the special case of ROTO.

SECTION 4Algorithmic Design
In this section, we first relax ROTO to a linear fractional programming problem (Section 4.1), for which we propose the LBA algorithm based on the level and move-up energy notions (Section 4.2). We then show the performance guarantee of LBA through rigorous theoretical analysis (Section 4.3), after which we present the LBR algorithm for ROTO and prove it has the same approximation ratio as LBA with a high probability (Section 4.4).

4.1 Relaxing ROTO to ROTO-LP
We relax constraint (2) and get the following linear formulation of ROTO, which we call ROTO-LP:
max∑i=1n∑ej∈C(i)αijbiyij(8)
View Source
s.t.∀ ui∈U:       ∑ej∈C(i)yij≤1,(9)
View Source
∀ ui∈U,ej∉C(i):yij=0,(10)
View Source
∀ ej∈E:                ∑i=1nbiyij≤Bj,(11)
View Source
∀ ej∈E:              ∑i=1n⌈yij⌉≤Vj,(12)
View Source
∀ ui∈U,ej∈E:yij∈[0,1].(13)
View SourceNote that it is necessary to round yij in constraint (12), which makes the result meet the constraint that edge node ej can process at most Vj tasks at the same time.

For an online setting, at each time t∈T, only a task of user ui∈U that arrives before t is known. This implies both the objective function (8) and the left hand side sum in Eqs. (9), (11) and (12) are unknown ahead, and they are gradually revealed to the algorithm over the operation period. The online algorithm does not know the length of T and has to take into account possible future arrivals and reserve the resources properly.

4.2 The Online Algorithm for ROTO-LP
In this subsection, we propose LBA to solve ROTO-LP, in which each task can be divided into arbitrary size.

4.2.1 Preliminaries
Let d be the maximum number of process slots of all edges, i.e., d=maxjVj. Denote the amount of computing resources ej has allocated to users by Ωj. The notion of the level is defined as follows.

Definition 1.
(Level) Each edge node ej is associated with a level Lj, which is an integer between (d−Vj) and d. The level of an edge node changes only when the amount of computing resources it has allocated to users changes. Formally, we have
Lj≜d−Vj+⌊VjΩjBj⌋.(14)
View SourceRight-click on figure for MathML and additional features.

From the above definition, we know if Ωj=0, then Lj=d−Vj; if Ωj=Bj, then Lj=d. We design this notion, level, for capturing how ‘full’ an edge node is. The proposed LBA algorithm prefers allocating the computing resources of edge nodes with a small level to a newly coming task. By doing so, LBA strives to keep all edge nodes at the same level to avoid overloading edge nodes, which probably increases the probability of offloading a newly coming task to an edge node with sufficient resources. Because, otherwise, a newly coming task may find all of the edge nodes it can connect to are at the biggest level, i.e., overloaded.

Algorithm 1. LB-Allocation (LBA) alg. for ROTO-LP
Initialization: Ωj←0, ∀ej;

Lj←d−Vj+⌊VjΩjBj⌋, ∀ej;

μj←BjVj⋅(Lj+1)−Ωj, ∀ej.

if a new task from user ui arrives then

Invoke LB shown in Algorithm 2.

if the task of ui finishes then

for each edge node ej in Qi do

yij←0, Ωj←Ωj−ωij, Lj←d−Vj+⌊VjΩjBj⌋;

μj←BjVj(Lj+1)−Ωj.

Note that, the level of each edge node is an integer, and it cannot precisely represent how full an edge node is. We introduce another important notion below.

Definition 2.
(Move-up Energy) The move-up energy μj of edge node ej is the amount of computing resources ej has to allocate to some tasks such that the level of the edge node is increased by exactly one. Formally,
μj≜BjVj(Lj+1)−Ωj.(15)
View Source

Take e9 in Fig. 2 for example, suppose B9=8, V9=4, and d=4. Initially, L9=0 and μ9=2, since it requires to allocate 2 units of resources to increase its level to 1. When the task of u2 arrives at time Tarr2 and LBA allocates 2.2 units of resources to it, L9 changes into 4−0+⌊4×2.28⌋=1, and μ9 changes into 84(1+1)−2.2=1.8.


Fig. 2.
An example of running LBA algorithm.

Show All

4.2.2 The Level Balanced Allocation Algorithm
The principle of LBA is as follows: when a new task arrives, LBA gradually allocates the computing resources of the edge nodes with the smallest move-up energy among the edge nodes with the smallest level to the task. Formally, we define the preference below.

Definition 3.
(Preference) LBA prefers allocating the computing resources of ei than ej if and only if
Li<Lj(16)
View Sourceor
Li=Lj and μi<μj.(17)
View SourceIf one of the two conditions holds, we denote the preference as
ei≻ej.(18)
View SourceRight-click on figure for MathML and additional features.

Algorithm 2. Level Balanced (LB) Procedure
b′i←bi, Qi←∅, ωij←0, yij←0, ∀ej∈E;

if each edge node ej in C(i) with Lj=d then

break;

else

while b′i≠0 do

L← set of edge nodes with the smallest level;

h←argminej∈L(μj).

if b′i≥μh then

Lh←Lh+1, b′i←b′i−μh;

ωih←ωih+μh, Ωh←Ωh+μh;

μh←BhVh(Lh+1)−Ωh;

if Lh≠d, then Qi←Qi⋃{eh}.

else if b′i<μh and Qi≠∅ then

for each edge node ej in Qi do

ωij←ωij+b′i∣Qi∣, Ωj←Ωj+b′i∣Qi∣;

μj←BjVj(Lj+1)−Ωj, b′i←0.

else

break.

for each edge node ej in C(i) do

yij←ωijbi.

Algorithm 1 shows the details of LBA. Lines 1−3 show the initialization of Ωj, Lj, and μj of each edge node. Remember that, LBA handles the online ROTO-LP problem. Lines 4−5 invoke the level balanced procedure (shown in Algorithm 2) to allocate resources when a new task arrives. Lines 6−9 update yij, Ωj, Lj, and μj of each edge node when the task of ui finishes.

Before we highlight the level balanced (LB) procedure, we introduce a few notations. We use ωij to denote the amount of resources allocated by ej to the task of ui; we use Qi to maintain the set of edge nodes that have allocated resources to ui; we use b′i to represent the amount of computing demand from ui that has not been allocated. Lines 2−3 in LB check whether all edge nodes that can be reached from ui have exhausted their computing capacities. Lines 5−20 are the main loop that handles the resource allocation.

In each iteration, LB first chooses one of the edge nodes with the highest preferences, i.e., LB chooses eh such that no other edge node ej in C(i) is more preferred by LB. If b′i≥μh, then LB allocates μh amount of resources on eh to the task of ui and updates Ωh, Lh, μh, ωih, and b′i. Note that, by allocating μh amount of resources on eh to the task of ui, the level of eh increases by exactly 1. If b′i<μh, the remaining computing demand of ui cannot increase the level of any edge node by 1, LB equally splits the remaining demand into |Qi| pieces and allocates a single piece to each edge node in Qi.

The complexity of Algorithm 1 is O(nm2). Every time when a new task arrives, Algorithm 2 is invoked. LB gradually allocates the computing resources to the task. The allocation lasts at most O(m) rounds and each round LB checks m edge nodes. So the complexity of LB is O(m2) and the complexity of Algorithm 1 is O(nm2).

4.2.3 Example
Here we use a simple example to intuitively explain our algorithm. In Fig. 1, users u1, u2 and u3 decide to offload their tasks to edge nodes e7, e8 and e9. Assuming that e7, e8 and e9 can process at most 2, 3 and 4 tasks at the same time, respectively. The computing capacity of e7, e8 and e9 are 2, 6 and 8 units, respectively. The levels of e7, e8 and e9 are initialized to 2, 1 and 0, respectively. \mu _7 is initialized as 1 unit, and \mu _8 and \mu _9 are both initialized as 2 units. The running process of this example is shown in Fig. 2.

Without loss of generality, we assume that u_2 submits its task first, and its computing demand is 2.2 units. Since e_9 has the smallest level and \mu _9 is smaller than b_{2}^{^{\prime }} (b_{2}^{^{\prime }} is initialized as 2.2 units), LBA first allocates 2 units of computing resources on e_9 to u_2 and updates the states of e_9, which makes \mu _9=2, \Omega _9=2, \omega _{1,9}=2, L_9=1. Then LBA adds e_9 to Q_2. After that, b_{2}^{^{\prime }} is updated to 2.2-2=0.2. Since b_{2}^{^{\prime }} is smaller than any move-up energy of edge nodes with the smallest level, LBA allocates b_{2}^{^{\prime }} units of computing resources on edge nodes in Q_2, i.e., e_9. The states of e_9 are updated according to LBA, which makes \mu _9=1.8, \Omega _9=2.2 and \omega _{1,9}=2.2. Then, u_1 submits its task with a demand of 3.8 units. Since e_8 and e_9 have the smallest level and \mu _9 is smaller than \mu _8 (1.8<2), LBA first allocates 1.8 units of computing resources on e_9 to u_1 and updates the states of e_9. In the end, 1.8 and 2 units of computing resources on e_9 and e_8 are allocated to u_1, respectively. Finally, u_3 submits its task with a demand of 5.6 units. According to LBA, e_7 allocates 1.2 units of computing resources to u_3; e_8 and e_9 each allocate 2.2 units of computing resources to u_3.

4.3 Competitive Analysis of LBA
In this section, we first formulate the dual problem of ROTO-LP and then intelligently construct the potential function, which plays an important role in the analysis. We then present two lemmas and the weak duality theorem before proving the approximation ratio of LBA.

4.3.1 Dual Problem of ROTO-LP
Here we use an indicator variable k_{ij} to help analyze the algorithm, where k_{ij} denotes whether the task of u_i is offloaded to edge node e_j. Hence \begin{align*} &\forall e_j\in \mathbb {E}: & \quad\quad\quad\quad\quad \sum \limits _{i=1}^{n}k_{ij}\leq V_j, \tag{19} \end{align*}
View Source\begin{align*} &\forall u_i\in \mathbb {U},e_j\in \mathbb {E}: & \quad\quad y_{ij}= k_{ij}y_{ij}, \tag{20} \end{align*}
View Source\begin{align*} &\forall u_i\in \mathbb {U},e_j\in \mathbb {E}: & \quad\quad k_{ij}\in \lbrace 0,1\rbrace . \tag{21} \end{align*}
View Source

Put z_{i} to be the dual variable for user u_i, and introduce a variable x_{j} for edge node e_j, then the dual problem of ROTO-LP is to minimize \sum _{j=1}^{m}B_{j}x_{j}+\sum _{i=1}^{n}z_{i} subject to \begin{align*} &\forall u_i\in \mathbb {U},e_j\in \mathbb {E}: & \qquad z_{i}+b_ik_{ij}x_j\geq \alpha _{ij}b_ik_{ij}, \tag{22} \end{align*}
View Source\begin{align*} &\forall e_j\in \mathbb {E}: & \qquad \sum \limits _{i=1}^{n}k_{ij}\leq V_j, \tag{23} \end{align*}
View Sourceand constraints x_j\geq 0, z_i\geq 0, k_{ij}\in \lbrace 0,1\rbrace, \forall e_j\in \mathbb {E}, u_i\in \mathbb {U}.

Before entering the approximation analysis, we first elaborate the potential function, f(i,j), which relates the values of the prime variables to that of the dual objective function.

4.3.2 Potential Function
Consider the time point when u_i just arrives, in which the ith dual constraint is given and assume that it is not satisfied. Our goal is to constrain the derivative of the dual cost (D) as a function of the primal profit (P). That is, show that \frac{\partial D}{\partial y_{ij}}=B_j\frac{\partial x_{j}}{\partial y_{ij}}\leq \lambda \frac{\partial P}{\partial y_{ij}}, where \lambda is going to be the competitive factor. Supposing that the derivative of the dual cost satisfies \begin{align*} B_j\frac{\partial x_j}{\partial y_{ij}}=A\left(b_ix_j+\frac{\alpha _{ij}b_i}{d}\right), \tag{24} \end{align*}
View Sourcewhere A is a constant. Then, since x_j\leq \frac{\alpha _{ij}b_i}{b_i}=\alpha _{ij} (due to Inequality (22)), \frac{\alpha _{ij}b_i}{d}\leq \alpha _{ij}b_i for d\geq 1, and \frac{\partial P}{\partial y_{ij}}=\alpha _{ij}b_i, we get that A\left(b_ix_j+\frac{\alpha _{ij}b_i}{d}\right)\leq 2A\frac{\partial P}{\partial y_{ij}}. Thus, \lambda =2A. By solving Eq. (24), we get \frac{\partial x_j}{\partial y_{ij}}=\frac{A}{B_j}\left(b_ix_j+\frac{\alpha _{ij}b_i}{d}\right). Through integration, the following equation can be obtained: x_j=G\cdot exp\left(\frac{A}{B_j}\sum \nolimits _{w=1}^{i}b_wk_{wj}y_{wj}\right)-\frac{\alpha _{ij}}{d}, where exp(x)=e^x and G can take any value. Next, we have the following two boundary conditions on this equation:

Initially, x_j=0, and this happens when \frac{\sum _{w=1}^{i}b_wk_{wj}y_{wj}}{B_j}=0;

If \frac{\sum _{w=1}^{i}b_wk_{wj}y_{wj}}{B_j}=1, (i.e., the primal constraint is tight) then x_j=\alpha _{ij}. (Then, the dual constraint is also satisfied.)

The first boundary gives G=\alpha _{ij}/d. The second boundary gives A=\ln (d+1). Thus we get the potential function: \begin{equation*} f(i,j)=\frac{\alpha _{ij}}{d}\left[exp\left(\frac{\ln (d+1)}{B_j}\sum \limits _{w=1}^{i}b_wk_{wj}y_{wj}\right)-1\right]. \end{equation*}
View SourceIf \sum _{w=1}^{i}b_wk_{wj}y_{wj}=B_j, then f(i,j)=\alpha _{ij}. We denote \alpha _i=\max _{e_j\in C(i)}\alpha _{ij}. And for edge node e_j, x_j=f(i,j).

4.3.3 Bounded Iteration
Let P(i) and D(i) be the values of the objective function of the primal and dual solutions, respectively, derived from the algorithm when u_i submits its task. Upon the arrival of a new task, we update both primal and dual programs. The primal program is updated by adding a new constraint corresponding to the user and a new term b_{i}k_{ij}y_{ij} to each constraint of an edge node. The dual program is updated by adding a new variable z_{i} for the new user and a constraint of the form b_{i}k_{ij}x_{j}+z_{i}\geq b_{i}k_{ij} for each edge node.

The dual solution is an assignment of values to the variables x_j and z_i. Initially, the values of primal and dual solutions are zero. Let \Delta P(i) and \Delta D(i) be the changes of P(i) and D(i), respectively, after user u_i submits its task.

Lemma 1.
In each iteration (arrival of u_i): \Delta D(i)\leq 2(1+\xi)\ln (d+1)\Delta P(i).

Proof.
First, we consider the situation where the task of u_{i} is not fully allocated to edge nodes. This means that all edge nodes in C(i) where k_{ij}=1 have exhausted all their computing capacities after allocating computing resources to u_i. In this case, the corresponding variable x_j with k_{ij}=1 are all \alpha _{ij} at the end of the iteration. As a result, all the new dual constraints are satisfied, and we can set z_i=0. For x_j with k_{ij}=0, setting z_{i}=0 also satisfies the constraints, because b_i \cdot 0 \cdot x_j+0=0=b_i \cdot 0. We only need to show that the change in the dual cost in this iteration is bounded. When we increase the variable y_{ij}, the derivative of the primal profit of the algorithm is \frac{\partial (\alpha _{ij}b_iy_{ij})}{\partial y_j}=\alpha _{ij}b_i. The derivative of the dual cost B_j\frac{\partial f(x)}{\partial y_{ij}} is: \begin{align*} &B_j\frac{\alpha _{ij} b_i\ln (d+1)}{dB_j}\left[exp\left(\frac{\ln (d+1)}{B_j}\sum \limits _{w=1}^{i}b_wy_{wj}\right)\right]\\ =&\ b_i\ln (d+1)\left(\frac{\alpha _{ij}}{d}\left[exp\left(\frac{\ln (d+1)}{B_j}\sum \limits _{w=1}^{i}b_wy_{wj}\right)-1\right]+\frac{\alpha _{ij}}{d}\right)\\ =&\ b_{i}\ln (d+1)\left(x_j+\frac{\alpha _{ij}}{d}\right)\\ \leq &\ b_{i}\ln (d+1)\cdot 2\alpha _{ij} <2(1+\xi)\ln (d+1)\alpha _{ij}b_i. \end{align*}
View SourceThe first inequality holds since x_j=\alpha _{ij} and \alpha _{ij}/d\leq \alpha _{ij}.

Thus, we get \Delta D(i)\leq 2(1+\xi)\ln (d+1)\Delta P(i) after u_i submits its task under the condition where the task of user u_{i} is not fully allocated by LBA.

Then we consider the situation where the task of user u_{i} is fully offloaded to the edge nodes in C(i). Note that the task may be offloaded to several edge nodes. We analyze this situation as follows. For edge node e_j with k_{ij}=0, the derivative of the dual cost is 0, and the constraint is satisfied for all z_i\geq 0. For edge nodes with k_{ij}=1, the derivative of the dual cost is b_i\ln (d+1)(f(j,\alpha _{ij})+\alpha _{ij}/d). We set z_i=b_i\ln (d+1)(\alpha _i-\alpha _i/d) to satisfy all the new dual constraints for edge node with k_{ij}=1. We can prove these constraints are satisfied as follows: \begin{align*} &z_i+b_ix_j \tag{25} \end{align*}
View Source\begin{align*} =&b_i\ln (d+1)\left(\alpha _i-\frac{\alpha _i}{d}\right)+\frac{b_i\alpha _i}{d}\left[exp\left(\frac{\ln (d+1)}{B_j}\sum \limits _{w=1}^{w}b_wy_{wj}\right)-1\right] \tag{26} \end{align*}
View Source\begin{align*} =&\frac{b_i\alpha _i}{d}\left[(d-1)\ln (d+1)+exp\left(\frac{\ln (d+1)}{B_j}\sum \limits _{w=1}^{i}b_wy_{wj}\right)-1\right] \tag{27} \end{align*}
View Source\begin{align*} \geq &\frac{b_i\alpha _i}{d}\left[(d-1)\ln (d+1)+exp\left(\frac{\ln (d+1)}{d}\right)-1\right] \tag{28} \end{align*}
View Source\begin{align*} \geq &\frac{b_i\alpha _i}{d}\cdot d \geq \alpha _{ij}b_i. \tag{29} \end{align*}
View SourceInequality (28) holds since \sum _{w=1}^{i}b_wy_{wj}/B_j\geq 1/d for each node with k_{ij}=1. The first inequality of (29) holds since (d-1)\ln (d+1)+exp\left(\frac{\ln (d+1)}{d}\right)-1\geq d, for d\geq 3. Thus, all the new dual constraints are satisfied.

Therefore, when u_i arrives, the dual cost of each edge node, e_j (z_i+B_j\Delta (x_j)), is updated as \begin{align*} &b_i\ln (d+1)\left(\alpha _i-\frac{\alpha _i}{d}\right)+b_i\ln (d+1)\left(x_j+\frac{\alpha _{ij}}{d}\right) \\ =&\ b_i\ln (d+1)\left(\alpha _i-\frac{\alpha _i}{d}+x_j+\frac{\alpha _{ij}}{d}\right) \\ \leq &\ b_i\ln (d+1)\left(\alpha _i-\frac{\alpha _i}{d}+x_j+\frac{\alpha _i}{d}\right) \\ = &\ b_i\ln (d+1)(\alpha _i+x_j) \\ \leq &\ b_i\ln (d+1)\cdot 2\alpha _i \leq 2(1+\xi)\ln (d+1)\alpha _{ij}b_i. \end{align*}
View SourceThus the lemma follows.

4.3.4 Feasibility
Here, we show the feasibility of LBA.

Lemma 2.
The algorithm LBA produces a feasible solution for both the primal and dual ROTO-LP problem.

Proof.
For the ROTO-LP problem, LBA never increases \sum _{w=1}^{i}b_wy_{wj} to be greater than B_j. Whenever \sum _{w=1}^{i}b_wy_{wj} increases in some iteration and reaches B_j, LBA stops allocating computing resources from e_j to users, because the computing capacity of e_j is exhausted. Therefore, the value of \sum _{w=1}^{i}b_wy_{wj} is not going to change anymore unless some tasks processed on e_j are completed, which reduces \sum _{w=1}^{i}b_wy_{wj}. Also, LBA never increases \sum _{j\in C(i)}y_{ij} beyond 1. Whenever \sum _{j\in C(i)}y_{ij} in some iteration equals to 1, LBA stops allocating computing resources for u_i, because u_i’s computing demand is satisfied.

For the dual problem of ROTO-LP, before any task on e_j is finished, the resources allocated on e_j will not decrease after the arrivals of subsequent users, which makes x_j monotonically increasing and the constraint (22) always holds. Once a task on e_j is finished, the value of x_j is either equal to 0 (no task is processed on e_j anymore) or greater than 1/d (at least one task is processed on e_j). We set z_i=b_iln(d+1)(\alpha _i-\alpha _i/d). If x_j=0, then the constraint (22) is satisfied for any z_i\geq 0. If x_j\ne 0, from Eqs. (25), (26), (27), (28), and (29), the constraint (22) still holds.

4.3.5 Weak Duality
We prove weak duality of ROTO-LP here.

Theorem 2.
Let y=(y_{11},\ldots,y_{ij},\ldots,y_{nm}) and x=(x_1,x_2,\ldots,x_m) be feasible solutions to the primal and dual ROTO-LP, respectively. Then: \begin{equation*} \sum \limits _{j=1}^{m}B_{j}x_{j}+\sum \limits _{i=1}^{n}z_{i} \geq \sum \limits _{i=1}^{n}\alpha _{ij}b_iy_{ij}. \end{equation*}
View Source

Theorem 2 states that the value of any feasible dual solution is at least the value of any feasible primal solution. Thus, the solution of the dual program can be used as a upper bound for any feasible primal solution. The proof of this theorem is as follows:

Proof.
\begin{align*} & \sum \limits _{j=1}^{m}B_jx_j+\sum \limits _{i=1}^{n}z_i \tag{30} \end{align*}
View Source\begin{align*} \geq & \sum \limits _{j=1}^{m}\left(\sum \limits _{i=1}^{n}b_ik_{ij}y_{ij}\right)x_j+\sum \limits _{i=1}^{n}z_i \tag{31} \end{align*}
View Source\begin{align*} \geq & \sum \limits _{j=1}^{m}\left(\sum \limits _{i=1}^{n}b_ik_{ij}y_{ij}\right)x_j+\sum \limits _{i=1}^{n}\left(z_i\sum \limits _{j=1}^{m}y_{ij}\right) \tag{32} \end{align*}
View SourceRight-click on figure for MathML and additional features.\begin{align*} = & \sum \limits _{i=1}^{n}\left(\sum \limits _{j=1}^{m}b_ik_{ij}x_{j}\right)y_{ij}+\sum \limits _{i=1}^{n}\sum \limits _{j=1}^{m}z_iy_{ij} \tag{33} \end{align*}
View SourceRight-click on figure for MathML and additional features.\begin{align*} = & \sum \limits _{i=1}^{n}\left(\sum \limits _{j=1}^{m}(b_ik_{ij}x_{j}+z_i)\right)y_{ij} \tag{34} \end{align*}
View SourceRight-click on figure for MathML and additional features.\begin{align*} \geq & \sum \limits _{i=1}^{n}\alpha _{ij}b_ik_{ij}y_{ij} \tag{35} \end{align*}
View SourceRight-click on figure for MathML and additional features.\begin{align*} = & \sum \limits _{i=1}^{n}\alpha _{ij}b_iy_{ij}, \tag{36} \end{align*}
View Sourcewhere inequalities (31) and (32) hold since \sum _{i=1}^{n}b_ik_{ij}y_{ij}\leq B_j and \sum _{j=1}^{m}y_{ij}\leq 1. Eq. (33) holds by changing the order of summation. Eq. (34) holds by merging the summation. Inequality (35) holds since x=(x_1,x_2,\ldots,x_m) is feasible, which means inequality (22) is satisfied. Eq. (36) holds since k_{ij}y_{ij}= y_{ij}.

Theorem 3.
Algorithm LBA is 2(1+\xi)\ln (d+1)-competitive.

Proof.
Theorem 3 can be easily proved based on Lemmas 1 and 2 and the weak duality.

4.4 The Online Algorithm for ROTO
In this subsection, we propose the solution to solve the ROTO problem, and show that the proposed algorithm achieves an approximation of 2(1+\xi)\ln (d+1) with a probability of at least 1-e^{-\sigma n}, where n is the number of users and \sigma is a constant.

4.4.1 The Level Balanced Rounding Algorithm
The pseudo code of the algorithm is shown in Algorithm 3. Upon the arrival of a user u_i, LBR invokes LB procedure and gets the fractional solution y_{ij} for offloading decisions (Line 5). The key idea of LBR is using the rounding technique to turn the fractional solution into an integer solution. The rounding steps are as follows: Since \sum _{e_j\in \mathbb {E}}y_{ij}\leq 1, we can map each \sum _{w=1}^{j}y_{iw} (j from 1 to m) to a point with value \sum _{w=1}^{j}y_{iw} on the interval [0,1], and the segment between point \sum _{w=1}^{j-1}y_{iw} and \sum _{w=1}^{j}y_{iw} represents the probability of offloading the task to edge node e_j. Note that \sum _{w=1}^{m}y_{iw} may be smaller than 1, then the segment between point \sum _{w=1}^{m}y_{iw} and point 1 represents the probability of rejecting the task of u_i.

Algorithm 3. LB-Rounding (LBR) alg. for ROTO
Initialization: \Omega _j \leftarrow 0, \forall e_j;

\qquad \qquad \qquad L_j \leftarrow d-V_j+\lfloor \frac{V_j\Omega _j}{B_j}\rfloor, \forall e_j;

\qquad \qquad \qquad \mu _j \leftarrow \frac{B_j}{V_j}\cdot (L_{j}+1)-\Omega _j, \forall e_j.

if a new task of user u_i arrives then

Invoke LB shown in Algorithm 2 for the solution y_{ij}.

Choose r uniformly in the interval [0,1].

if r>\sum _{w=1}^{m}y_{iw} then

Reject the task of u_i, \ddot{y_{ij}}\leftarrow 0, \forall e_j\in C(i).

for j=1 to m do

if \sum _{w=1}^{j-1}y_{iw}<r\leq \sum _{w=1}^{j}y_{iw} then

Allocate u_i to e_j;

\ddot{y_{ij}}\leftarrow 1, \Omega _j\leftarrow \Omega _j-\omega _{ij}+b_{i}, \omega _{ij}\leftarrow b_{i};

L_j\leftarrow d-V_j+\lfloor \frac{V_j\Omega _j}{B_j}\rfloor, \mu _j\leftarrow \frac{B_j}{V_j} (L_{j}+1)-\Omega _j;

\ddot{y_{iw}}\leftarrow 0, \forall w\ne j, break.

for each edge node e_j in C(i) do

if \ddot{y_{ij}}=0 then

\Omega _j\leftarrow \Omega _j-\omega _{ij}, \omega _{ij}\leftarrow 0, L_j\leftarrow d-V_j+\lfloor \frac{V_j\Omega _j}{B_j}\rfloor;

\mu _j\leftarrow \frac{B_j}{V_j} (L_{j}+1)-\Omega _j, Q_i\leftarrow Q_i\setminus \lbrace e_j\rbrace.

if the task of u_i finishes then

for each edge node e_j in Q_i do

\ddot{y_{ij}}\leftarrow 0, \Omega _j\leftarrow \Omega _j-\omega _{ij}, L_j\leftarrow d-V_j+\lfloor \frac{V_j\Omega _j}{B_j}\rfloor;

\mu _j\leftarrow \frac{B_j}{V_j} (L_{j}+1)-\Omega _j.

We choose r uniformly in the interval [0,1] (Line 6). Then we decide whether to reject the task or to offload the task to a specific edge node according to r (Lines 7-18). We use \ddot{y_{ij}} to represent the solution produced by LBR. Note that \ddot{y_{ij}} is a binary variable after rounding, in general \ddot{y_{ij}}\ne y_{ij}. Lines 12-13 update \Omega _j, L_j, and \mu _j of the edge node e_j with \ddot{y_{ij}}=1. Lines 15-18 update the states of each edge node e_j with \ddot{y_{ij}}=0 in C(i). Lines 19-22 update the states of each edge node when a task finishes.

The complexity of Algorithm 3 is \mathcal {O}(nm^3). Compared to Algorithm 1, Algorithm 3 has one more step. Every time when LBA gets the fractional solution, LAR uses the rounding technique to turn the fractional solution into an integer solution. And the complexity of rounding is \mathcal {O}(m). As a result, the complexity of Algorithm 3 is \mathcal {O}(nm^3).

4.4.2 Analysis
Denote the objective value achieved by the LBA algorithm as Y. Denote the optimal objective value of ROTO and ROTO-LP as OPT and OPT-LP, respectively. Note that we have proved in the previous section that Y\geq \frac{\text{OPT-LP}}{2(1+\xi)\ln (d+1)}. Since ROTO-LP is a convex relaxation of ROTO, we have OPT-LP\geq OPT. Thus, we get 2(1+\xi)\ln (d+1)Y\geq \text{OPT}.

Denote the objective value derived from LBR as \ddot{Y}. We define a random variable \ddot{Y_{i}} such that \ddot{Y_{i}}=\sum _{e_j\in C(i)}\alpha _{ij}b_i\ddot{y_{ij}}. Then, we have \ddot{Y}=\sum _{i=1}^{n}\ddot{Y_{i}}, and E[\ddot{Y}]=\sum \nolimits _{i=1}^{n}E[\ddot{Y_i}]=\sum \nolimits _{i=1}^{n}\sum \nolimits _{e_j\in C(i)}\alpha _{ij}b_i\ddot{y_{ij}}=Y.

Theorem 4.
For any \delta \in (0,1), \begin{equation*} Pr\left(\ddot{Y}<(1-\delta)\frac{\text{OPT}}{2(1+\xi)\ln (d+1)}\right)\leq e^{-\sigma n}. \end{equation*}
View Source

Proof.
We use the Chernoff Bound [37] to facilitate the proof.

Obviously, the random variables \lbrace \ddot{Y_i}\rbrace are independent by construction. By applying the Chernoff Bound, we have \begin{align*} & Pr\left(\ddot{Y}\leq (1-\delta)\frac{\text{OPT}}{2(1+\xi)\ln (d+1)}\right) \\ = &\ Pr\left(\sum \limits _{i=1}^{n}\ddot{Y_{i}}\leq (1-\delta)\frac{\text{OPT}}{2(1+\xi)\ln (d+1)}\right) \\ \leq &\ Pr\left(\sum \limits _{i=1}^{n}\ddot{Y_{i}}\leq (1-\delta)\frac{\text{OPT-LP}}{2(1+\xi)\ln (d+1)}\right) \\ \leq &\ Pr\left(\sum \limits _{i=1}^{n}\ddot{Y_{i}}\leq (1-\delta)Y\right) \\ = &\ Pr(\ddot{Y}\leq (1-\delta)Y) \\ \leq &\ exp(-\delta ^2Y/2). \end{align*}
View Source

Without loss of generality, we assume that OPT=\mathcal {O}(n). Since Y\geq \frac{\text{OPT-LP}}{2(1+\xi)\ln (d+1)}\geq \frac{\text{OPT}}{2(1+\xi)\ln (d+1)}, we can find some constant C>0 such that Y\geq Cn for sufficiently large n. Therefore, \begin{equation*} exp\left(-\frac{\delta ^2Y}{2}\right)\leq exp\left(-\frac{\delta ^2Cn}{2}\right). \end{equation*}
View SourceLet \sigma =\delta ^2C/2, then we have \begin{align*} Pr\left(\ddot{Y}<(1-\delta)\frac{\text{OPT}}{2(1+\xi)\ln (d+1)}\right)\leq e^{-\sigma n}. \end{align*}
View SourceThe theorem holds immediately.

4.5 Discussions
In this subsection, we discuss a few limitations of our work and some possible future directions.

Divisible Tasks. We assume in this work that the tasks of users are atomic. However, in many situations, a task can be divided into several independent or dependent subtasks. For dependent subtasks, we consider the subtasks that can be processed in parallel as independent tasks according to their DAG graphs. We consider independent subtasks as a new task and set the revenue of them according to their weights in the entire task.

Non-negligible Devices’ Capacities. Our work focus on the scenarios that the mobile device has very limited computing resource, and hence all the tasks should be offloaded to the edge nodes for execution [38]. Under the condition where the mobile device has more powerful computing capacity and the task is divisible, we can consider the user as a special edge node, which only connects to the user itself, and set the revenue as the energy consumption if the task is processed locally. LBA can be slightly adjusted to suit this condition.

Dynamic Revenue. Our work assumes that the revenue of the task is fixed. However, users may be willing to pay more for their tasks due to the urgency. The revenue ratio \alpha _{ij} can be dynamically modified according to current time and deadline, which means scheduling some urgent tasks can bring in more revenue. Meanwhile, because of the existence of competition, users need to consider how to modify their prices so that their tasks can be completed at the edge node with minimal cost. We plan to use game-theoretic framework to study this problem.

Uncertain Task Requirements. We mainly talk about the scenario where the computing requirement of each task is available. However, in realistic scenarios, the size of the task can be measured but its processing time is generally uncertain until it is completed. Task assignment under the uncertainty of the processing time is well studied in theoretical computer science [39], [40]. However, most works focus on the design of efficient task scheduling and do not concern the allocation of computing resources. We would like to study the computation offloading problem under uncertain processing time in the future.

Nonnegligible Transmission Time. In this paper, we assume that with the rapid development of 5G network, the time of transmission is small enough to be ignored [33]. Meanwhile, we assume that users arrive one by one and the task of the user can only be offloaded to the edge nodes that are within the communication range of the same BS as the user. As a result, the scale of the ROTO problem will not be particularly large. However, for large-scale MEC scenes, the performance of the algorithm may not be as good as theoretically. Collecting and scheduling a large amount of edge nodes in a short period of time is a big challenge. We plan to use a distributed competition method to analysis the problem when considering the transmission delay. Specifically, we plan to design a self-organizing distributed framework, that is, whenever a user arrives, the scheduling calculations of task offloading is only performed in the BS to which the user can connect.

SECTION 5Trace-Driven Simulation
In this section, we demonstrate the performance of LBR. We compare LBR with three baseline algorithms. Both of them assume that the information of all users is known in advance. The first one is the Random Allocation (RA) algorithm, when the user arrives, RA randomly offloads the task to an edge node connected to the user. The second one is the Greedy Allocation (GA) algorithm, which always offloads tasks to the edge node with the maximum revenue. The third one is the optimal (OPT) solution, which is obtained from the existing mathematical tools (IBM CPLEX [41]). After presenting the setup and parameters, the results are shown from different perspectives to provide insightful conclusions.

5.1 Simulation Settings
We envision a mobile edge computing system deployed inside a megacity in Asia.

Edge Node Trace. For the locations of envisioned edge nodes, we use the locations of the Starbucks due to the fact that Starbucks shops in a city can usually achieve a decent coverage for users. In addition, the distribution of Starbucks actually follows the population density, making them perfect locations for edge cloud deployment in the future. We collect the locations of 105 Starbucks in the megacity, which is shown in Fig. 3. Each Starbucks is envisioned as an edge node. Then the default number of edge nodes is 105. The computing capacity of an edge node is in a range of 3-4 GHz and the process slots of each edge node is in a range of 4-12.


Fig. 3.
Loc. of starbucks.

Show All

Task Trace. The task statistics are in accordance with [31]. For tasks, the expected input data size per task is 8 MB, and the expected number of CPU cycles required to process one byte of data is 1000, which makes the computing demand of users be in a range of 0.27-0.4 gigacycles. The price statistics are in accordance with [35], [36]. The value of the price of unit computing demand \alpha _{ij} is set between 0.5 and 0.6.

User Trace. The number of customers visiting a Starbucks shop in a day in the megacity is about 500, which implies about 50 customers in an hour. We set the total running time as \mid \mathbb {T}\mid =100. We set the default number of users to 5000. Locations of users are randomly distributed in the megacity. In the 5G scenario, we consider a user can connect to an edge node if the distance between them is within the communication range, and the default communication range is 3km. For users, we use the data traces of Google clusters [42]. Note that, these traces only contain the information of processing time, dependency relationship and required processing resources for each task. We adjust users' arrival time based on Poisson distribution to accommodate stochastic arrival and the length between deadlines and arrival time are uniformly distributed in [20, 30].

5.2 Simulation Results
In Fig. 5a, we evaluate the influence of the number of users which varies from 2000 to 6000. We observe the trend that as the number of users grows, the overall revenue grows accordingly. This is reasonable because more users will be served to maximize the revenue as long as the edge nodes have sufficient computing capacity. We also observe that, the overall revenue does not exceed a certain threshold. This is because the computing capacity of edge nodes is limited. Once edge nodes exhaust their capacities, the future users will not be served, thus the revenue will no longer increase. Our online algorithm always outperforms the RA and GA and is close to the optimal algorithm.

Fig. 4. - 
Our testbed.
Fig. 4.
Our testbed.

Show All

Fig. 5. - 
Simulation results for our algorithm and the baseline algorithms with different configurations.
Fig. 5.
Simulation results for our algorithm and the baseline algorithms with different configurations.

Show All

Fig. 5b shows the impact of the number of edge nodes on overall revenue. We randomly choose 60-100 edge nodes among 105 edge nodes. We observe that the overall revenue increases as the number of edge nodes increases. This is because, with the increase of the number of edge nodes, the computing capacity has increased accordingly. And more computing capacity will also bring more revenue. Still, our algorithm performs better than RA and GA and is close to the optimal algorithm.

In Fig. 5c, we inspect the impact of the network topology. We vary the communication range from 1km to 5km, which makes the average number of edge nodes that connect to a user vary between 1 and 20. We observe that, the overall revenue grows as the number of connections increases. This is as expected, because when there are few connections, it is very likely that all the edge nodes that connected to the user have exhausted their computing capacities, while other edge nodes still have sufficient capacities. With more connections, this happens less likely. And the overall revenue in our algorithm is significantly higher than that in RA and GA and is close to the optimal algorithm.

Fig. 5d shows the results with different number of process slots. We vary the number of process slots of each edge node from 4 to 12. We can see from Fig. 5d, as the number of process slots grows, the overall revenue grows. This is because, with more process slots more users can be served by each edge node, thus the overall revenue increases. And our algorithm outperforms the classic RA and GA algorithms and is close to the optimal algorithm.

The reasons why LBR outperforms GA and RA will be discussed in Section 6.2.

SECTION 6Testbed Experiment
In this section, we implement the revenue-driven online task offloading system and conduct experiments based on the implementation to validate the performance of LBR.

6.1 Testbed Setting
Deployment Platforms. The testbed environment is shown in Fig. 4; we use 5 Raspberry Pi 4 Model B (ARM Cortex-A72 CPU, 4 Cores @ 1.5GHz)) and 3 Raspberry Pi 3 Model B (ARM Cortex-A53 CPU, 4 Cores @ 1.2GHz) as edge nodes. We use 2 Samsung S4 and 2 Samsung note3 phones as users, and each user is connected to 3-5 Raspberry Pis. The program is written in python3.7 environment, and has roughly implemented with about 2.3k lines of codes.

User Trace. We adjust users' arrival time based on Poisson distribution. The time between the arrival time and the deadline of a task are uniformly distributed in [10,15].

Task Trace. Consider the realistic task trace from Google cluster as computation-intensive tasks, which contains the information of processing time, dependency relationship and required processing resources for each task [42]. The expected number of CPU cycles required to process one byte of data is in accordance with [31]. We set up two different tasks in our experiments, namely \mathrm{pdf2text} and \mathrm{html2text} programs. The expected number of CPU cycles required to process one byte of data of \mathrm{pdf2text} and \mathrm{html2text} is 1000 and 6000, respectively. The value of the price of unit computing demand \alpha _{ij} is set between 0.5 and 0.6. We set the size of each \mathrm{pdf2text} task between 1.05MB and 4.45MB, and the size of each \mathrm{html2text} task is set between 5.9MB and 9MB. We set the total running time as \mid \mathbb {T}\mid =100.

6.2 Performance Comparison
Fig. 6a shows the change in overall revenue over time. Note that an edge node can only gain the revenue after the task is successfully executed. In the first 10 seconds, the total revenue remains at 0 because no tasks have been completed yet. We observe that the performance of all algorithms is very similar in the beginning. This is because the computing resources of edge nodes were sufficient in the beginning and all tasks can be offloaded to edge nodes. We also observe that GA and RA perform better than LBR in the beginning, this is because LBR always selects the edge node with the smallest level, which may not bring the biggest revenue. However, LBR outperforms baselines over time, and the overall revenue in LBR is 50 percent higher than that in the baselines in the end.

Fig. 6. - 
Testbed results for our algorithm and the baseline algorithms with different configurations.
Fig. 6.
Testbed results for our algorithm and the baseline algorithms with different configurations.

Show All

The experimental results on the testbed are consistent with our simulation results. Figs. 6b and 6c show the overall revenue versus the number of users and the number of edge nodes, respectively. The overall revenue increases with the growth of the number of users and the number of edge nodes, and LBR achieves significant revenue increment compared to other algorithms. Fig. 6d evaluates the impact of the number of connections between users and edge nodes on the overall revenue. By increasing the number of connections, the overall revenue will also increase.

The reason why LBR outperforms GA and RA in Figs. 5a, 5b, 6b and 6c is as follows: In the beginning, GA prefers to offload tasks on the edge nodes with the maximum revenue, which causes imbalance in the remaining resources of edge nodes. Thus, some edge nodes may exhaust their resources quickly while others still have sufficient resources. As a result, the newly arrived task is very likely to be rejected because all of the edge nodes it can connect to are overloaded. This situation may also occur when applying RA.

The reason why LBR outperforms GA and RA in Figs. 5c, 5d, and 5d is as follows. The number of connections and process slots will not affect the offloading decisions of GA and RA. More connections and process slots will only slow down the speed at which some edge nodes exhaust their resources, and cannot change the result that some edge nodes exhaust their resources while others have sufficient resources.

SECTION 7Conclusion
In this paper, we formulate the task computation offloading as an optimization problem to maximize offloading revenue while providing performance guarantees. The proposed algorithm achieves the approximation of 2(1+\xi)\ln (d+1) with a probability of at least 1-e^{-\sigma n}. Trace-driven simulations and testbed experiments have shown that our proposed scheme outperforms the classic RA and GA algorithms and is close to the optimal algorithm.