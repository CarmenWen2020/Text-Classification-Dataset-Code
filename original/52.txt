Abstract
With increasing vehicle automation, drivers are likely to engage in non-driving related tasks. However, before fully autonomous vehicles can be achieved, drivers remain the fallback when automation limits are reached and/or in unexpected situations. Transition from automated to manual control could be particularly difficult for drivers who are “out-of-the-loop”. To support safe and smooth control transition, we adopted the blended sonification approach in manipulating background music to convey information about the reliability level of the automation. A driving simulator study consisting of 36 participants was conducted to investigate the effectiveness of sonification feedback—three levels of system reliability was mapped to background music pitch levels—on takeover events. Participants were assigned to one of three groups that received continuous sonification feedback, intermittent sonification feedback, or no feedback about automation reliability. The proposed blended music sonification was found effective in increasing monitoring behavior and decreasing visual response times to takeover requests during automated driving. Steering control in a takeover scenario that required substantial amount of maneuvering also benefitted from having sonification feedback. There was some evidence that sonification feedback provided continuously was more effective than when it was provided intermittently, possibly related to observed differences in the associated glance patterns. In conclusion, blended sonification may be an effective approach in helping drivers stay on the loop during automated driving, although the study was limited to the choice of music examined. Our future work will investigate how best to combine automation reliability information and traffic situational information to better support situation awareness and facilitate task-switching in automated driving.

Previous
Next 
Keywords
Human-automation interaction

Blended sonification

Automation reliability

Driver feedback

Autonomous vehicles

Conditionally automated driving

1. Introduction
While autonomous vehicles (AV) technologies have progressed rapidly in recent years, full autonomy has not yet been achieved. To establish the role of human drivers in vehicles of increasing automation, the Society of Automotive Engineers (SAE) defines 6 levels of driving automation, from “Level 0 – no automation” to “Level 5 – full automation” (SAE, 2018). The current AV technologies stand somewhere in the middle of this spectrum—at level 3, conditional automation, human drivers may be relieved of physically controlling the vehicle and instead perform supervisory control tasks monitoring how well the automation is driving the vehicle. Human drivers are still expected to take over and drive manually in situations that the automation cannot handle, such as when the automation system meets its boundaries (e.g., AV enters un-mapped area, inclement weather conditions), or when encountering novel, unexpected situations (e.g., jaywalking pedestrians, sensor failures/data recording problems). In such situations, the automated driving system may decide to disengage itself and issue a takeover request (TOR) to drivers. Adverse events, including crashes, could happen if human drivers are unable to resume control in a timely and safe manner. To better assist these takeover events, human factors studies have largely focused on designing TORs and understanding factors that may influence driver responses to such requests. For example, studies have examined the impact of TOR timing (Gold et al., 2013), TOR modality (Petermeijer et al., 2017a, 2017b), traffic density (Dogan et al., 2017; Radlmayr et al., 2014), and driver's cognitive load (Naujoks et al., 2018) on driver takeover performance.

Driver takeover is particularly challenging in conditionally automated driving because drivers are often not paying attention to the roadway preceding a TOR alert. Studies have shown that people are likely to engage in non-driving related tasks (NDRT) when the automation is performing the dynamic driving tasks (Carsten et al., 2012; De Winter et al., 2014; Llaneras et al., 2013). Immersion in NDRTs can pose potential safety risks if drivers are not fallback-ready when they are called upon to take over in critical situations due to being “out-of-the-loop” (OOTL)” (Merat et al., 2019). The potential for OOTL has long been recognized as an automation design challenge, given that it could lead to insufficient trace of automation states such that operators may fail to detect, diagnose and take over manual operations as needed (Endsley and Kiris, 1995).

Feedback design in automation has been considered as a potential solution to the OOTL problem by supporting the understanding of automation states (Norman, 1990). Research on driver feedback for highly automated driving has largely targeted the recognition of potential hazards and other useful information about the traffic environment (e.g., Cohen-Lazry et al., 2017; Hock et al., 2016; Lindemann et al., 2018). However, these studies have not always found feedback about the driving environment effective in supporting takeover events. For example, in Dogan et al. (2014)’s driving simulator study, information about traffic density and speed threshold aimed to support the anticipation of takeover requests did not improve response times to takeover requests. The authors speculated that the participants’ assumption that the system would not fail likely contributed to their low level of monitoring during automated driving, thus undermining the effectiveness of the feedback. It is therefore important for feedback design to specifically help drivers achieve an appropriate amount of monitoring of the automation and/or the driving environment. In particular, Moray (2003) argued that when interacting with an automated system, monitoring should be proportional to reliability, such that an operator may adapt a sampling strategy sufficient for identifying states that require their attention/action.

A few studies have investigated the use of continuous feedback to keep drivers informed about the automation state. Beller et al. (2013) developed a schematic face symbol for an adaptive cruise control (ACC) system to convey uncertainty information dynamically. The face symbol shows up during an unclear driving situation, such as when the system meets its boundaries. The results showed that with the uncertain face symbol, drivers directed more attention to the driving related scene and reacted faster during a safety-critical situation in a driving simulator study. Helldin et al. (2013) designed a different graphical display using seven horizontal bars to convey system ability information. The system ability fluctuates due to inclement weather and the number of bars indicates the system ability level. This study also found that drivers were able to react faster to takeover events with the system ability display. A more recent study by Kunze et al. (2019) designed an anthropomorphic interface to continuously present system uncertainty. System uncertainty was mapped to a heartbeat animation, where the higher the system uncertainty was, the faster the heartbeat. This mapping was intended to mimic faster heartbeat in a stressful, uncertain situation. Drivers receiving this uncertainty feedback showed significantly higher monitoring behaviors to the road scene; however, there was no significant benefits to their takeover response times.

Cohen-Lazry et al. (2017) was one of the limited studies that conveyed continuous driver feedback about automation using the auditory modality. More specifically, the continuous feedback came in the form of verbal messages relayed by the experimenter about potential hazard events. Drivers were found to monitor the road more with the feedback; however, there was also no significant benefits to reaction times associated with this feedback. Seppelt and Lee (2019) combined both visual and non-speech auditory feedback to help drivers monitor the states of an ACC system. Compared to discrete warnings, Seppelt and Lee found that drivers receiving continuous feedback appeared to develop a more explicit understanding of the automation system, and that the combined use of visual-auditory modality supported drivers was more effective than a single-modality display.

These studies have all shown improvement of driver attention allocation to the driving scene under continuous feedback; however, evidence of takeover behavior/quality was somewhat mixed. The current study aims to extend existing efforts on designing continuous feedback that will support drivers in conditionally automated driving to mitigate the risks associated with drivers being OOTL. Appropriately designed feedback on system states provided throughout a trip may help drivers employ visual sampling strategies that are more adaptive to both the driving environment and the level of automation reliability. Specifically, we are interested in further investigating the auditory modality for continuous feedback, given that drivers’ visual channels are likely to be occupied elsewhere during NDRTs. In addition, haptic modality is probably more suitable for temporary warnings (Petermeijer et al., 2016) and that long durations of vibration often annoy users (Kaaresoja and Linjama, 2005).

1.1. Sonification for process monitoring
Using non-speech audio signals to transfer information to the users—sonification (Kramer et al., 1999)—has been investigated in various domains and is particularly effective for process monitoring. Process monitoring can be categorized into three types: direct, peripheral, and serendipitous-peripheral monitoring (Vickers, 2011). For direct monitoring, proper auditory design can be useful if the interface is cluttered (visually or aurally) with many variables that require careful monitoring (e.g., Deschamps et al., 2016, on oxygen saturation level monitoring for preterm neonates). In applications of serendipity-peripheral monitoring, sonifications are designed to provide supplemental information that would be useful but not required to the user. In the “Music Monitor” system developed by Tran and Mynatt (2000), gradual transition of instrument voices and tempo in background music subtly provided information about the party lively status of two rooms simultaneously. Finally, for peripheral monitoring, sonification may support operators in diverting their attention to a second task that also has information to be monitored. Arrabito et al. (2019) developed sonification to convey information on engine revolutions per minute (RPM) as part of a multimodal display for monitoring an unmanned aerial vehicle. Results showed that with the support of sonification, participants were faster and more accurate at detecting critical events in engine RPM compared to visual-only command interface.

In the aforementioned study by Seppelt and Lee (2019), sonification alerted drivers to changes in the state of the ACC. Parameters including time-to-collision, time headway, range rate, and on/off status were conveyed via the use of a major 5th chord tone and a secondary intermittent tone, and the manipulation of their presence, loudness change, and pitch change. The auditory signals faded out if ACC had maintained 1.5 s of time headway at a range of 40 m for 4 s to signal that the system had entered a steady state (cruise control). With the intention to support driver situation awareness about the driving environment during automated driving, Gang et al. (2018) designed spatialized earcons (synthetic short melodies or pure-tone “beeps”) to represent different traffic events including traffic density, encountering of obstacles, fast approaching and tailgating vehicles, and approaching emergency vehicles. Their study found that generally, the synthesized earcons improved participants' awareness of simulated events (while attending to a reading task), but the earcons did not support drivers better than the existing environmental auditory cues (e.g., engine noise of other vehicles in conveying a nearby vehicle). In the context of manual driving, Graham (1999) compared the use of two auditory icons—car horn and tire skidding sounds—to pure-tone and speech warnings for collision warning, and found that the auditory icons entailed faster responses but incurred more false-positive reactions.

1.2. Blended sonification
Sonification designs usually involve the creation of non-speech sounds (e.g., earcon—abstract, synthetic or pure-tone “beeps”, and auditory icon—snippets of sounds that represent objects/actions that exist in natural and everyday life) displayed as discrete signals or embedded within existing soundscapes. More recently, Tunnerman et al. (2013) introduced the concept of Blended Sonification, a sonification idea hinged on auditory augmentation that augments existing sounds to transmit additional information to the listeners, such as the “Music Monitor” of party lively status in Tran and Mynatt (2000). Blended sonification advocates for the integration of sounds from a user's daily life into the feedback design; the major components to be integrated include: (1) the physical environment (PE); (2) the digital environment (DE); (3) the user (U) and (4) the resulting auditory display. The first three components may leverage existing auditory signals and data, to be integrated (filtered and/or added) and transported as information flow to the auditory display.

Music appears to be an ideal platform for blended sonification. In therapeutic settings, Bergstrom et al. (2014) successfully manipulated the volume and tempo of the music to help participants reflect on and better modulate their own arousal level. Walus et al. (2016) added music sonification to help communicate alcohol consumption risk in a PowerPoint presentation to the participants (information about higher risks were associated with more distortion of accompanying music). In automobile driving, a few studies have also explored the manipulation of music parameters to influence drivers’ perception of performance (Burnett et al., 2017; Cassidy and Macdonald, 2010) and time (Cassidy and Macdonald, 2010). These manipulations were intentionally subtle rather than providing salient feedback to communicate with drivers. For example, Nykanen et al. (2016) manipulated the background audio (podcast and music) to provide feedback on speed control for energy-efficient driving. Deviation from the desired speed was communicated through reduced treble or bass effect of the music/podcast. Participants were generally able to understand the music alteration cues easily, but the advantage of sonification on maintaining the desired speed was only apparent in the lower speed condition.

The choice of sonification design schemes to support monitoring largely depends on the task and its environment. Blended sonification design has not been well explored in the context of automated driving, but has the potential for communicating useful information, such as automation reliability level, in an easily understood and acceptable manner. In automated driving, it is straightforward to think of the vehicle itself as the PE, the automated driving agent as the DE, and the drivers as the users. The relationships between these four major components are illustrated in Fig. 1. As music listening has long been a popular activity common in driving (Stutts et al., 2003) and will likely remain so in highly automated rides (Pfleging et al., 2016), it may be a useful medium to communicate system states to the users. Music itself then becomes the auditory signal in the environment as shown in Fig. 1.

Fig 1
Download : Download high-res image (139KB)
Download : Download full-size image
Fig. 1. Blended sonification illustration, adapted from Tunnerman et al. (2013) for an automated driving context. Letter A in the white circles represent auditory signals (A in the gray circle represents added auditory signal); D represents data input; and F in the gray circle represents filtered output. Filtered data is communicated to driver via auditory display as illustrated by the dashed arrow. The links that connect between the letters represent the information flow from the environment and the automated driving agent to the auditory display.

1.3. Objectives and hypothesis
Leveraging Tunnerman et al.’s blended sonification concepts, our study aimed to investigate the use and manipulation of background music as auditory feedback for conveying automation reliability level (data of the automated driving agent in Fig. 1) in facilitating transitions from automated to manual driving when drivers are engaged in a non-driving related task (NDRT). In a driving simulator study, the use of continuous sonification feedback (continuously altered background music) was compared to having no feedback (with unaltered background music) and to having sonification feedback provided only on an intermittent basis (short snippets of altered background music) on their impact on driver attention allocation and takeover responses in conditionally automated driving. We elected to include this intermittent feedback condition as an example of intermittent auditory feedback that has been applied successfully in other system monitoring applications, such as blood pressure monitoring (Watson, 2006; Watson and Gill, 2004). The addition of this intermittent feedback condition allowed us to investigate to what extent continuous feedback may benefit drivers compared to providing information only intermittently, which is similar to having a driver glance at a visual display from time to time. The following hypotheses were investigated:

H1. Participants receiving sonification feedback on automation reliability level will show increased monitoring of the road than those in the control group (no feedback), similar to the increased monitoring behaviors in drivers who received continuous feedback in Kunze et al. (2019). As changes in automation reliability level would likely be unpredictable and vary over time, we also hypothesized that feedback with continuous mapping of reliability level will result in more monitoring behavior than that with intermittent mapping.

H2. Participants receiving sonification feedback on automation reliability level will demonstrate shorter (improved) response times to takeover requests, compared to those in the control group. Previous studies have found inconsistent results in the effectiveness of feedback in improving takeover response times; non-significant results were often ascribed to difficulty in interpreting feedback or lack of feedback specifically for monitoring automation status. We hypothesized that our blended sonification scheme on automation reliability would be easier for drivers to perceive and understand the level of reliability, thus supporting a more adaptive monitoring strategy that may lead to improved takeover outcome. Further, as Seppelt and Lee (2019) have found, continuous feedback was able to improve driver response times more so than discrete warnings, we thus hypothesize that participants receiving continuous feedback will also respond to TORs faster than those receiving intermittent feedback, as more monitoring may also increase the chance of perceiving hazard or system limits earlier to be ready for a takeover scenario.

H3. Sonification feedback on automation reliability level will improve driver manual control during a takeover event; drivers receiving continuous feedback will benefit from faster response and therefore have better takeover quality, compared to those who receive intermittent feedback.

H4. There will be no observable differences in perceived workload among the experimental groups, since all participants will receive the same driving scenarios. As the NDRT employed (reading) in this study is primarily a visual task, it is less likely to interfere with the sonification feedback through background music (auditory resource), in accordance with the multiple resource theory (Wickens, 2002).

2. Method
A driving simulator study was conducted to evaluate the effectiveness of automation reliability sonification as continuous feedback in conditionally automated driving (SAE level 3, SAE, 2018). By definition, automation at this level is responsible for driving under restricted conditions, but human drivers are expected to take over the driving task when necessary or upon request, a situation that is commonly referred to as the takeover request (TOR). The University at Buffalo Institutional Review Board approved this experimental protocol.

2.1. Participants
Thirty-six participants (18 females) between the ages of 18 and 39 (M = 25.5, SD = 4.3) were recruited from the University at Buffalo campus. All had a valid US driver's license for more than two years (M = 4.7, SD = 3.5), self-reported normal hearing and normal or corrected-to-normal vision. An additional criterion required that the participant had not participated in any driving simulator studies for the past 6 months. 31 out of 36 participants reported they listen to music while driving. Participants were compensated with a $15 Amazon gift card for their participation which lasted about one and a half hours. Table 1 summarizes the demographics of participants under each experimental group.


Table 1. Participant demographics for different experimental feedback groups.

Experimental Group	Number of Participants	Age (Years)	Driving Experience (Years)
Continuous Group	12	M = 26.33, SD = 4.66	M = 6.16, SD = 5.15
Intermittent Group	12	M = 23.8, SD = 3.16	M = 4.67, SD =2.64
Non-feedback Group	12	M = 26.33, SD = 4.70	M = 3.33, SD =1.37
Overall	36	M = 25.5, SD = 4.3	M = 4.7, SD = 3.5
2.2. Apparatus
The study was conducted using NADS miniSim (Fig. 2 left panel), a fixed-base quarter cab size driving simulator with three 48″ display monitors providing a 138°field of view. The simulator collects data at a rate of 60 Hz. The gaze was recorded at a rate of 50 Hz using the second generation Tobii Pro Glasses, a wearable eye tracking system (Fig. 2 right panel). Engine and road noise were played back via the simulator speakers. The sonification feedback was played back using a Dell PC (Precision Tower 5810) connected to the Logitech z623 2.1 speaker system. The left and right speakers were placed on each side of and slightly behind the driver seat. A Microsoft Surface Go tablet with 10″ touchscreen was provided to participants for the non-driving related task. Participants could hold the tablet in any position they prefer when interacting with it.

Fig 2
Download : Download high-res image (262KB)
Download : Download full-size image
Fig. 2. Driving simulator setup and the wearable eye tracker used.

2.3. Feedback design
Our proposed sonification feedback was designed to reflect changes in system reliability resulting from the interaction between automated driving agent and the driving environment. The prerequisite of an autonomous vehicle is the ability to sense the environment and then act upon the information it senses. However, the environment may be beyond the design of the capability of automated driving agent to understand the environment (e.g. encountering construction site, identifying other car's intention and so on) or induce errors in sensors (e.g. debris, fog, snow, or rain). Exceptional environmental conditions or inferior data fed to the driving algorithms which navigate the car potentially lower the system reliability. The continuous sonification was intended to display system reliability in a continuous manner, such that this feedback generally stays in the peripheral and only brought to the foreground when music parameter is manipulated in periods of lower reliability. After reviewing the design guideline proposed by Faltaous et al. (2018), which found that drivers perceive visual reliability discretely rather than continuously, to reduce the amount of information drivers need to memorize and to increase the distinguishability between high and low reliability, we further divided and tested three discrete reliability levels:

Fully Reliable: The reliability of the system in performing the dynamic driving tasks safely is trustworthy. Drivers are assumed to be able to perform NDRTs without worrying the road situation.

Moderately Reliable: The reliability of the system in performing the dynamic driving tasks safely is moderate. Drivers are assumed to be able to perform NDRTs but at times need to allocate their attention to the road situation.

Unreliable: The reliability of the system in performing the dynamic driving tasks to be safe is low. Drivers may continue to perform NDRTs but will need to allocate more attention to the road situation in order to prepare for takeover.

Overall enjoyment of music listening is important; however, it is also imperative that the change of music parameters (reliability information) is perceived. To draw drivers’ attention, we mainly manipulated the music pitch. To design continuous feedback that represents the fully reliable level, the music is played at the original pitch level. When the reliability is at the moderate reliability level, the music pitch will be shifted 2 semitones downward (divide the original frequency by the factor of 1.12). The adjustment for the lowest reliability level is to shift 4 semitones downward (divide the original frequency by the factor of 1.26). In addition, to avoid listeners mistaking the shifted pitch level for original pitch level after a period of time, band pass filter was added to the pitch shifted music to create a muffled effect. Final adjustment was made on volume to ensure music at all three levels were similar in loudness (within the range of 60 to 70 dB at the driver seat position). Table 2 summarizes the sonification design.


Table 2. Summary of music sonification design.

Music Parameters/Effects	Reliability Level
Fully Reliable	Moderately Reliable	Unreliable
Frequency	Original Pitch	2 Semitones downward	4 semitones downward
Band pass filter	–	Low pass filter: 3000 Hz with 12 dB roll rate
High pass filter: 306 Hz with 12 dB roll rate	Low pass filter: 700 Hz with 12 dB roll rate
Amplify	–	Approximately 8 dB	–
Bass and Treble	–	–	Enhancing bass by 10 dB and output volume by 4 dB
The music track manipulated in this study was a free ambient electronic track “Carefree” available for free online (Macleod, 2014). We intentionally chose a track without vocal content to avoid imposing additional cognitive load associated with language processing on the participant. The music was also fairly even in tempo (96 bpm) and without noticeable changes in volume or sound effects to minimize any potential influences on a participant's mood or behavior.

2.4. Experimental design
Participants, stratified by gender, were randomly assigned to one of three feedback conditions: continuous feedback, intermittent feedback, and no feedback. Background music was on for all participants. Participants in the continuous feedback group experienced distortions in music (sonification scheme as previously described) corresponding to changes in automation reliability level on a continuous basis (see Fig. 3a). Intermittent feedback, on the other hand, communicates drops in reliability level through music distortion only periodically (every 12 s), and only when system reliability drops to the unreliable level. In other words, participants receiving intermittent feedback would only perceive a snippet (1.5 s) of music distortion if the corresponding reliability level is low during an intermittent feedback period (see Fig. 3b). We initially included the moderately reliable level for intermittent feedback, but pilot testing found it difficult for participants to differentiate the two kinds of distortions when they were not presented side by side (as in the continuous feedback condition). Extending the individual intermittent feedback duration to support perception of changes in reliability level would render it too closely resembling the continuous feedback condition. Fig. 3a) and b) show examples of how music distortion maps to the reliability level in the present study for the continuous and intermittent feedback groups, respectively. Provided with the assigned feedback, each participant experienced the same set of four takeover events in two experimental drives, detailed in the following sections.

Fig 3
Download : Download high-res image (317KB)
Download : Download full-size image
Fig. 3. Illustration of music pitch level (red line) mapping to the system reliability (blue line) for continuous and intermittent feedback. In a) continuous feedback, music pitch level maps continuously to the system reliability; in b) intermittent feedback, music pitch level will decrease 4 semitones with short snippet (1.5 s) every 12 s when reliability state is unreliable. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

2.5. Driving scenario
Two driving scenarios were created for this experiment. Each drive consisted of two takeover events and three other non-takeover driving events (see Table 3). These 10 events are a mix of infrastructure changes (e.g. construction site, highway exit, traffic light), sensor degradation due to environmental conditions (e.g. fog), traffic (e.g. identifying cut-in vehicles, slowdown vehicle, stranded cars) and algorithm issue (e.g. event without visible natural cues). Participants followed real-time instructions to drive through a pre-determined course in a simulated conditionally automated vehicle. The first drive started in manual driving mode in a 2-lane road urban area and soon after participants were instructed to enter a 4-lane interstate highway. Roughly 40 s before entering the highway, participants were verbally prompted to turn on the background music by pressing a button on the back of the steering wheel. The vehicle automatically engaged in automated driving mode with a short auditory notification roughly 30 s after entering the highway. In automated driving mode, the speed was set to 65 mph. The drive ended after five events, when the vehicle entered a 2-lane rural highway. In the second drive, participants also started with manual driving on a 2-lane rural highway, and they were asked to turn on the background music after 80 s. Participants then drove manually for another 40 s before engaging in automated driving. This drive ended after five events, when the vehicle reentered an urban area. It took approximately 16 min to complete each drive.


Table 3. Experimental events designed in two drives.

Event	Drive1	Required Takeover	Drive2	Required Takeover
1	Construction site	No	Fog area	No
2	Cut-in vehicle	Yes	Fog area with slow car	Yes
3	Stranded vehicles	No	Construction site	Yes
4	Event without specific reason	Yes	Stranded vehicles	No
5	Exit highway and traffic light	No	Traffic light	No
Reliability level (fully, moderately and unreliable) of automation during the drive was predetermined in this study, such that all four takeover events occurred during unreliable automation states. During a takeover event, a takeover request (TOR) was issued with an auditory warning “Please take over!” and participants had 5 s to resume manual control before the self-driving function disengaged on its own. While participants would need to maintain longitudinal and lateral control after taking over, only one event—the second takeover event in the second drive with a construction site in the ego-lane—required immediate, larger maneuvers (slowing down and steering around the construction site) to avoid a potential crash. After the takeover event, the vehicle reengaged in automated driving mode and the reliability level was reset to fully reliable. All participants experienced the drives and the events in the same order, regardless of which feedback group he/she was assigned to. Fig. 4 shows the timeline of the two drives and the corresponding reliability level changes.

Fig 4
Download : Download high-res image (709KB)
Download : Download full-size image
Fig. 4. Driving scenario timelines for Drive 1 and Drive 2, respectively. Changes in system reliability level over the course of an experimental drive is shown on top of a timeline of driving events. The beginning of a driving event is marked by a cross, with red crosses being the ones for which a takeover request was issued. Blue textured areas represent manual driving segments. Event time points slightly differed across participants, depending on their initial manual driving time. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)

2.6. Non-driving related task
While the autonomous vehicle was under self-driving mode, participants were asked to perform a non-driving related task (NDRT): reading articles from the tablet provided. Participants could hold the tablet in any position they preferred. This NDRT was intended to be both visually and cognitively demanding, and allowed participants to naturally switch their gaze off the road and let their hands off the steering wheel. The articles were randomly selected from the Medium website (www.medium.com), and each article took about 5 min to read. Articles were mainly related to science and technology given most of the participants were students from the school of engineering and applied sciences. To encourage participants to engage in the NDRT, participants were told that they would need to finish 5 out of 10 articles to complete the study.

2.7. Procedures
Upon arrival, research objectives and experiment processes were introduced to the participants. Followed by the introduction, participants reported their vision and hearing and tried out the eye tracker. Participants then signed the consent form after they agreed to participate. Participants then filled out questionnaires about their demographics, experience with ADAS, and their past music learning experience.

Participants were assigned to different groups of feedback conditions before their arrival. For participants in the sonification feedback groups (both continuous and intermittent), the experiment started with learning the meaning of the sonification and then a 12-mintue simulator training, while the baseline group started directly with the simulator training session. In the simulator training, the first 6 min was manual driving to familiarize with basic maneuvers of the simulator, and the last 6 min was familiarizing taking over the driving control authority from self-driving mode and reengaging self-driving function from manual driving mode. They were told that to disengage automated driving, they could either: press the disengagement button, press the brake pedal or press the gas pedal. A driving mode indication bar was presented on the bottom-left corner of the center screen, and participants were instructed about the meaning of the color of the mode bar. Participants were then instructed not to put their feet on the pedals when the automated driving was on. While not explicitly asked to, participants generally had at least one hand off (more often both hands off) the steering wheel to manually hold the tablet to perform the reading task. During the training, participants were instructed to observe speed limit signs closely, to drive their car in the right lane, and not to overtake lead vehicles unless additional instructions are given.

The purpose of providing reliability information was explained: “The reliability information is to let you know how confident the self-driving car is in itself to handle the current traffic situation and maneuver the car. Therefore, it serves as a hint to tell you that you might need to be aware of the environment, and you need to be ready if there is take over request given to you. If there is no takeover request eventually, the car will still perform the driving tasks.” Participants were also instructed that if they ever feel need to take over when the reliability level drops, they are free to do so.

In addition, all participants were told that they were responsible for driving safely throughout the experiment. Each participant experienced 2 driving sessions containing 4 takeover events providing either continuous music feedback, intermittent feedback, or no feedback depending on the condition they were assigned to. Participants were also provided with an optional 3 to 5 min break between the two drives. The entire drive lasted about 32 min. Following the driving session, participants answered the post-driving questionnaire as well as the NASA-TLX questionnaire of workload.

2.8. Dependent measures
Dependent measures were used to assess the effectiveness of sonification feedback with respect to the following: (i) pre-takeover monitoring—allocation of visual attention to the road in preparation for a potential takeover; (ii) response times to a takeover request (TOR); and (iii) quality of the transfer of control, i.e., the manual control performance immediately following the takeover request until stability is reached. Fig. 5 illustrates how the measures, detailed below, are chronologically related to the takeover event in the present study.

Fig 5
Download : Download high-res image (198KB)
Download : Download full-size image
Fig. 5. Chronological order of measures used in the present study (in italics). ATTR: road attention ratio; VRT: Visual response time; MRT: Manual response time; PSD: Power spectral density; SRR: Steering wheel reversal rate. Lengths of intervals are not drawn in proportion to elapsed time.

Pre-takeover monitoring. Based on glance durations, i.e., the time of gaze directed towards a given area of interest (in this case the forward roadway) to the moment it moves away from it, two metrics were computed for each of the four monitoring periods prior to a takeover request (see Fig. 5): the road attention ratio (hereafter “ATTR”, which is the percentage of time spent looking at the forward roadway), and the total number of glances at the forward roadway greater than 2 s (hereafter “Long Glances”). The choice of 2 s as a threshold followed the work of Samuel and Fisher (2015), which showed that when drivers were distracted, forward roadway glances that were less than 2 s were insufficient to obtain critical information for identifying latent hazards.

Response times to TOR. Two types of response times were assessed: (i) visual response time (VRT), defined as the time between a TOR was issued and the participant's first glance back at the road, and (ii) manual response time (MRT), the time between a TOR was issued and the participant's first manual input (button press or depressing the brake/gas pedal) to regain manual control. A negative response time was possible (and included in subsequent analyses) if a visual/manual response was initiated before the TOR was issued.

Takeover quality. This analysis focused on the takeover event in which participants had to maneuver around a construction site, as this event required a significant amount of maneuvering to avoid a crash. Steering performance, namely the average power spectral density (PSD) of steering angles and steering reversal rates (SRR), were analyzed for this event. The PSD indicates the expenditure of energy in steering behavior, which also implied how much control effort is exerted (Macdonald and Hoffmann, 1980). The SRR was calculated with a moving window of 0.8 s length (Östlund et al., 2004) using 10° as the reversal thresholds, following the threshold used for major steering corrections in previous studies (Choudhary and Velaga, 2017; Kountouriotis et al., 2016).

Finally, a post-driving questionnaire was administered to assess participants’ experiences of the sonification feedback for the two feedback groups. The questionnaire consisted of 5-point Likert scales on the ease of perception of music distortion, level of annoyance with the music distortion, how much the participant liked the music feedback system, and the acceptance level of the music feedback system. Participants were also administered the NASA-TLX (Hart and Staveland, 1988) questionnaire to measure their workload during the experimental drive for all three groups.

3. Results
Participants in two sonification feedback groups responded to questions about how easy it was to perceive changes in music after the driving sessions. Only one participant in the continuous feedback group expressed difficulty in perceiving music changes when performing the reading task. Video recordings confirmed that all participants in the two feedback groups demonstrated—by their gazes and head movements—to various extents responses to the music distortions. The following sections report our analysis on monitoring behaviors, visual/manual responses to takeover requests, takeover quality during physical transfer of control, and subjective responses related to the feedback system.

All analyses adopted a significance level of 0.05 and were conducted using R (R Core Team, 2018). Linear mixed effects models were built for the dependent measures using R package “lme4” (Bates et al., 2015). Linear mixed effects models can handle imbalanced dataset due to missing data and are not subjected to the “sphericity” assumption of the mixed ANOVA. In case of assumption violations, data transformation was applied to the dependent measures as appropriate. If data transformation did not address the assumption violations, robust mixed ANOVA (Field and Wilcox, 2017) and non-parametric methods were used. Post-hoc comparisons with Tukey's test were performed using R package “emmeans” (Lenth, 2019).

3.1. Pre-takeover monitoring behaviors
On average, the road attention ratio (ATTR) for the continuous group, intermittent group and no feedback group were 7.52% (SD = 10.71%), 2.78% (SD = 2.78%), and 0.60% (SD = 0.87%) of time spent looking at the forward roadway during the monitoring (automated driving) period, respectively. Fig. 6 shows the boxplot of average of ATTR for different groups of participants. The effect of feedback types on ATTR was analyzed using linear mixed effects model with participant as random effect and feedback type (3 levels) and takeover event (4 levels) as fixed effects. Box-Cox transformation was performed on the raw data since the homogeneity of variance and normality assumptions were violated. After controlling for takeover event in the model, results indicated that feedback type had a significant effect on ATTR (Χ2(2) = 21.098, p < .001, partial η2 = 0.34). As hypothesized, post-hoc comparisons showed that participants receiving feedback (continuous or intermittent) allocated more attention back to the road compared to those who did not. Compared to the no feedback group, ATTR was significantly higher in continuous feedback group (t(33) = 5.06, p < .001) and in intermittent feedback group (t(32.9) = 3.242, p = .008). However, no significant difference was found between the continuous and the intermittent group.

Fig 6
Download : Download high-res image (215KB)
Download : Download full-size image
Fig. 6. Boxplot of average road attention ratio (ATTR) for three groups of participants. Each dot on the plot represents a single data point of ATTR. There are 4 (events per participant) × 12 (participants) = 48 data points collected in each feedback group, for a total of 144 data points across all groups.

The effect of feedback type on long glances was analyzed using a Generalized linear mixed effects model with Poisson distribution, given that the dependent measure—the number of long glances—is a count variable. Participants’ long glances during a trial were first calculated as rates and then scaled up to counts in a one-minute duration. Similar to ATTR analysis, participant was treated as a random effect, feedback type and takeover event as fixed effects. After controlling takeover event, the result indicated that feedback type had a significant effect on participants’ long glances (Χ2(2) = 12.364, p = .002, partial η2 = 0.16). Post-hoc comparisons with Tukey's test revealed that the frequency of long glances in the continuous group was significantly higher than the no feedback group (p < .001), the expected counts of long glances in no feedback group is only roughly 14% of the continuous group. The intermittent group was found to have higher frequency of long glances compared to the no feedback group, however, only marginal significant difference was found (p = .055). Finally, the difference between the continuous and intermittent group was not significant. Fig. 7 shows the frequency of long glances across different groups of participants.

Fig 7
Download : Download high-res image (285KB)
Download : Download full-size image
Fig. 7. Frequency of number of long glances for three groups of participants.

3.2. Response times to TOR
3.2.1. Visual response time
Fig. 8 shows the distribution of visual response times (VRT) across the three feedback conditions. Since distortions signaling unreliable automation level were displayed before a TOR was issued for both feedback groups, some participants began to monitor the road when they perceived the music change, which led to a negative value for VRT. Among all 144 (36 × 4) responses, 23, 10, and 0 visual responses were made prior to the TOR issues for continuous, intermittent and no feedback group, respectively.

Fig 8
Download : Download high-res image (286KB)
Download : Download full-size image
Fig. 8. Distribution of the visual response time for three groups of participants.

The assumptions of normality and homogeneity were both violated in the initial analysis. As Box-Cox transformation did not alleviate the assumption violations, a robust mixed ANOVA was used. For the visual response time, a significant effect of feedback type was found (F(2, 18.1997) = 11.704, p <0.001, partial η2 = 0.56). However, neither the effect of takeover event (F(3, 14.018) = 0.4, p = .755, partial η2 = 0.08) nor the interaction was found significant (F(6, 15.078) = 0.214, p = .967, partial η2 = 0.08). Post-hoc comparisons on feedback type indicated that the VRT of the continuous group was significantly faster than the intermittent group (MEANconvsint = −3 s, CI = −6.23 to 0.23 s, p = .025), and significantly faster than the no feedback group (MEANconvsnof = −3.65 s, 95% CI = −6.86 to −0.43 s, p = .016). Finally, VRT of intermittent feedback group was significantly faster than the no feedback group (MEANintvsnof = −0.646 s, 95% CI = −1.16 to −0.13 s, p = .010).

3.2.2. Manual response time
Manual response time (MRT), the difference between the time of participants’ first reaction (either pedals reaction, or button press) and the TOR issue time, was calculated for all takeover events. Fig. 9 shows participants’ MRTs by event and feedback type. The effect of feedback type on MRT was analyzed using a linear mixed effects model, where participant was treated as random effect, and feedback type and takeover event were treated as fixed effects. After controlling for the takeover event, feedback type was found to significantly impact participants’ MRTs (Χ2(2) = 11.785, p = .003, partial η2 = 0.19). Post-hoc comparison with Tukey's test indicated that MRTs in the continuous group were significantly faster by 1.36 s (± 0.38) than in the no feedback group (t(33) = 3.531, p = .004). However, there was no significant difference between the continuous group and the intermittent group, or between the intermittent group and the no feedback group. Finally, the robust correlation coefficient between the visual response time and manual response time showed that there was a moderate positive correlation (ρ = 0.453, p <0.0001).

Fig 9
Download : Download high-res image (332KB)
Download : Download full-size image
Fig. 9. Boxplot of the manual response times of all takeover events for three groups of participants. Black solid dots and the corresponding values indicate the average response time of a takeover event of a group. Colored dots are individual participants’ manual reaction times in each takeover event in different feedback groups. There is a total of 144 manual reaction time data points.

3.3. Takeover quality
Takeover quality was assessed for only the second takeover event in Drive 2, as this was the only event requiring substantial maneuvers by the participant to avoid a crash during the takeover. In this event, participants were required to steer away to avoid crashing into a construction site. Participants who failed in their attempts to manually take over and either veered off-road or crashed into the construction site were removed from the steering behavior analyses (four participants in the continuous feedback group, one in the intermittent group, and two in the control group). In total, the steering behavior analyses included data from 29 out of 36 participants. All failed attempts involved participants reacting with the brake pedal, but they failed to brake hard enough to disengage in time. As this was the final takeover event of the drive, these failed events did not impact other analyses in the study.

Fig. 10 presents the time series data of the steering wheel angle. The widest range of steering angle was found in the no feedback group when participants steered away from the construction site, while participants in the intermittent group exhibited a slightly narrower steering angle range, and the continuous group showing the narrowest range. The steering behavior for a 15 second period following the TOR was analyzed using the computed PSD and 10-degree SRR variables. Poorer quality of takeover performance is implied with larger values of PSD (more effortful control) and larger 10-degree SRR (more large-angle corrections).

Fig 10
Download : Download high-res image (329KB)
Download : Download full-size image
Fig. 10. Time series data of steering wheel angle after TOR was issued for three groups of participants.

Fig. 11 illustrates the average of the spectral power after logarithm transform for all three groups. A significant main effect of the feedback type was found (F(2, 26) = 5.37, p = .01 partial η2 = 0.29). Post-hoc comparisons with Tukey's HSD method showed significant differences between the continuous and the no feedback group (p = .008), with no feedback group showing significantly higher power spectral density in log scale. However, there were no significant differences between the intermittent and no feedback groups, and between the intermittent and continuous groups. The difference of power spectral density between continuous group and no feedback indicates that participants in the no feedback group showed a greater expenditure of energy in steering behavior, which also implied more control effort was exerted. There were also no differences among the three groups of participants in their normal steering control (comparing their power spectral density of steering angles for a 30 second straight road section of manual driving, X2(2) = 4.3662, p = .11).

Fig 11
Download : Download high-res image (219KB)
Download : Download full-size image
Fig. 11. Boxplot of average spectral power density of steering wheel angle time series data in log scale for three groups of participants.

Fig. 12 shows the mean 10-degree SRR of each feedback groups. The Shapiro-Wilk test of normality was violated (W = 0.873, p = .002), therefore the Kruskal-Wallis test was used. The result showed that there was a significant effect of feedback on the 10-degree SRR (X2(2) = 10.709, p = .005, partial η2 = 0.29). Post-hoc comparison was carried out using Dunn's pairwise tests (p-value adjusted with Bonferroni correction). 10-degree SRR of continuous group was significantly lower than the no feedback group (p = .003), however, difference between intermittent and no feedback group, as well as intermittent and continuous group were not statistically significant.

Fig 12
Download : Download high-res image (208KB)
Download : Download full-size image
Fig. 12. Average 10-degree steering wheel reversal rate [1/min] for all three groups.

3.4. Subjective measure
The mean and the standard deviation of the weighted scores of NASA-TLX by each group of the participants are presented in Table 4. No statistical difference was found in each individual factor nor in overall weighted score across groups.


Table 4. NASA-TLX score ratings for three groups of participants.

Factors	Mean Score (SD) by Feedback Conditions	Statistics
Continuous	Intermittent	No Feedback
Mental	13.3 (8.8)	11.6 (10.3)	16.4 (9.1)	X2(2) = 2.06, p = .356
Physical	1.4 (2.1)	3.1 (4.1)	1.8 (1.9)	F(2,33) = 0.828, p = .446
Temporal	8.7 (6.8)	10.5 (9.1)	11.5 (9)	F(2,33) = 0.326, p = .724
Performance	14.3 (11.1)	16.8 (11.2)	10.2 (9.8)	F(2,33) = 1.138, p = .333
Effort	7.6 (6.8)	11.1 (9.1)	13.3 (8.7)	F(2,33) = 1.436, p = .252
Frustration	4.58 (5.5)	3.5 (6.1)	3.8 (5.8)	F(2,33) = 0.109, p = .897
Overall	49.9 (19.1)	56.6 (20.6)	57 (17.7)	F(2,33) = 0.517, p = .601
Overall, the majority of the participants did not find the sonification annoying (see Table 5 for the summary of scores). However, both groups of continuous and intermittent sonification had 25% (n = 12 for each group) of the participants rate the music distortion as annoying or very annoying. One of the participants in the continuous group who rated the sonification as being annoying mentioned that he barely listened to music while driving, therefore it was not a good experience when he also had to perform the reading task. Concerning whether the participant liked the idea of using music as a medium for providing reliability information, the majority of participants had positive attitude towards the methodology. However, both groups still had around 17% of the participants who disliked the methods. One of the participants in the intermittent group mentioned that he usually reads in silence and did not like the idea of playing music in the background when reading, although he did not rate the sonification as being annoying. For the acceptance level of having a similar feedback system in a self-driving car in the future, 66.7% and 75% of participants rated a high acceptance level in the continuous group and intermittent group, respectively. Two of the participants who rated low acceptance noted that they seldom listened to music while driving, and one rated low acceptance in the continuous group mentioned it was hard to read and focus on the music at the same time. No participants rated moderately low or low acceptance in the intermittent group.


Table 5. Subjective ratings of the annoyance and like-dislike of the sonification feedback.

Questions	Possible Ratings	Continuous	Intermittent
Mean	SD	Mean	SD
Annoyance	1. Very annoying
5. Not annoying at all	3.75	1.54	3.75	1.22
How much of annoyance was the sonification when you perceived the change in the experiment?
Like-Dislike	1. Extremely dislike
5. Extremely like	3.83	1.53	3.83	1.11
How much do you like the method for providing the reliability information?
Acceptance	1. Low acceptance
5. High acceptance	3.75	1.29	3.92	0.67
In the future, if there is a similar feedback system in a self-driving car, what is your acceptance level?
4. Discussion
This study examined the possibility of using background music to provide reliability information to address driver out-of-the-loop issues during automated driving. We investigated sonification feedback delivered continuously or intermittently in a driving simulator study. Using multiple measures of visual attention, driving performance, and subjective responses, we expected that the sonification feedback on automation reliability level would benefit participants in takeover events, and have found mostly supporting evidence for the expected benefits as discussed below.

4.1. Pre-takeover monitoring behaviors
In support of our first hypothesis that sonification feedback would impact driver attention allocation to result in more monitoring behaviors, participants in both sonification feedback groups showed larger proportion of visual attention to the road during automated driving (non-takeover sections) compared to the control group provided with unaltered music playing in the background. This result is consistent with Cohen-Lazry et al. (2017), who provided verbal feedback, and Kunze et al. (2019), who provided visual feedback, that drivers received continuous feedback made more forward roadway glances compared to drivers who did not receive feedback. While the attention ratio in the continuous feedback group was not significantly higher than the intermittent feedback group, participants receiving continuous feedback alone demonstrated more frequent longer (greater than 2 s) glances. It appears that when participants received continuous feedback via music sonification, they were more disposed to switch their attention back to the road for a longer period of time, whereas when intermittent feedback were provided, participants were responding to music distortions momentarily, i.e., by raising their head briefly and quickly returning to look down at the tablet. This switching of gaze between road scene and tablet is similar to what Janssen et al. (2019) referred to as interleaving in their takeover framework, which models the driving task as an interruption to the NDRT. From this perspective, our sonification feedback—both continuous and intermittent—may serve as a forewarned (potential) interruption from which the interleaving of attention (back and forth between the NDRT and driving task) begins. However, differences in eye glance patterns during interleaving between the two feedback groups may affect the subsequent takeover performance.

We also note that the sonification scheme in the intermittent feedback group only portrayed two levels of reliability (fully reliable and unreliable); however, providing an intermediate level was unlikely to increase the perception of urgency to result in longer glances. It remains an interesting research question to further investigate the visual sampling strategies associated with continuous and intermittent feedback. Furthermore, as we found different interleaving glance behaviors among the two feedback groups, future studies on takeover control should continue to investigate how interleaving glance behaviors—either a result of feedback or other factors (e.g., individual differences, engagement level in NDRT)—are associated with takeover quality and safety outcomes.

4.2. Driver response times to TOR
We sought evidence for the effectiveness of sonification in preparing drivers for takeover events via analyses of both visual and manual response times to takeover requests. Not surprisingly, participants receiving sonification feedback, especially in the case of continuous feedback, exhibited improved visual response times to a TOR. In a number of cases, participants were already looking at the road when the TOR was issued. As TORs occurred during unreliable-automation periods, those responding to sonification was able to divert their attention back to the driving task in a timely manner to monitor for potential TOR events. On the other hand, without any feedback, participants engaged in the NDRT were simply responding to the TOR when it was issued. However, we note that in a few cases, despite the sonification feedback provided, some participants were also responding to the TORs passively, potentially due to an inappropriate trust in automation or a lack of understanding in either the feedback system or the automation's capability. The indifference to feedback may also be the artifact of being in a simulator experiment. One participant from the intermittent feedback group mentioned that he barely thought manual intervention would be needed in this study.

The effectiveness of sonification feedback was also evident in the manual response times to TOR. Participants in the continuous feedback group were the fastest among the three groups in their manual response to TOR. As mentioned earlier, many participants receiving continuous feedback already had their gazes on the road when a TOR was issued; their manual response times were thus likely to be minimal without the need for additional head movements and/or gaze redirections to obtain the necessary information for taking over. Interestingly, while many participants in the continuous group had switched their gazes back to the road before a TOR, only two showed an attempt to intervene automated driving before a TOR was issued. It seems that most participants, while monitoring the road due to their awareness of reduced automation reliability, were still waiting for further takeover instruction to be given. This observation is similar to the finding of Tijerina et al. (2016), in which drivers delayed intervening response and instead explored the system's lane-keeping behaviors when the system confidence level was reduced without imminent hazard. This may explain why the first glance time and manual intervention time was only moderately correlated in our study. It may also be the case that even though audio information was provided, participants still seek visual cues for their decision to takeover, as suggested by the conjecture of Nykanen et al. (2016). One thing to note here is that in a similar study, Cohen-Lazry et al. (2017) did not find improved manual response time for drivers supported with continuous driving-related feedback that had significant higher number of forward roadway glances. A primary difference between their study and the present one is the information content the feedback was designed to communicate—while we provide information on automation reliability, theirs were on specific driving event/situation. Furthermore, given that they were providing verbal feedback only during a driving event/situation, what they referred to as “continuous” feedback were really “continual” (on-going but not without interruptions), and in a sense similar to the intermittent feedback in the present study. Cohen-Lazry et al. also did not report the duration of the roadway glances, which may provide further insights on whether these glances were long enough for participants to gain critical information and thus impact their monitoring decisions and subsequent manual responses.

4.3. Takeover quality
We expected that the effect of faster manual response would carry over to participants’ takeover control quality as participants should have more time to make the necessary maneuvers to avoid a crash. To this end, we analyzed a takeover event that required steering maneuvers to avoid crashing into the construction site. This event was the first and only takeover event in our two experimental drives that participants needed to steer away from a hazard after disengaging the automation. The results showed that for participants who successfully completed the transition from automated mode to manual mode, the continuous feedback group had smaller steering control variability and exerted less effort to switch lane compared to the control group. On the other hand, participants in the control group on average had to perform more major correction of heading error. This is likely due to a sudden need for lane-switching to steer away from the hazard and their reactions were more automatic than prepared.

Similar to those receiving continuous feedback, the group receiving intermittent feedback demonstrated more monitoring and shorter—sometimes even negative—visual response times compared to the control group. However, the sonification feedback did not significantly improve the manual response time or steering control in this group. As alluded to earlier, we observed that participants in the intermittent feedback group tended to respond briefly and only to the snippets of music distortion. Samuel and Fisher (2015) observed that less than 2 s of forward roadway glance are not sufficient for drivers to detect critical information when they are distracted. It may be that the brief glances at the road corresponding to intermittent feedback were also insufficient in preparing the participant for an impending takeover. Furthermore, these participants rarely continued to monitor the road when music distortions ended, even though they were informed prior to the experiment that the intermittent feedback were samples of reliability level, rather than a continuous representation of the actual reliability level.

One caveat in our analysis of manual responses is that only the steering responses of those who successfully took over control were included, which resulted in the report of only 29 out of 36 participants’ steering responses in this analysis. However, in the continuous feedback group, those who did not succeed in takeover started braking in time, but failed to brake hard enough to disengage from automation in time. These participants eventually disengaged from automation, but was by then too late to make a smooth transition and thus steered off the road, which terminated the simulation. Researchers have emphasized that the effectiveness of actions is critical to a successful takeover (McDonald et al., 2019). In our case, the handful of participants who were not able to take effective initial actions despite the sonification feedback suggests that our training/familiarization with the simulator setup might have been insufficient for some, but it may also indicate that participants who were monitoring the situation could become overly confident in their ability to respond well to a TOR. Driver takeover is a complex process beyond eye-motor coordination, especially when immediate subsequent steering maneuver is required. Future research on automated driving should carefully consider the effects of system familiarization (e.g., Hergeth et al., 2017) and training (e.g., Ebnali et al., 2019; Payre et al., 2016).

4.4. Study limitations and future work
In addition to the limitations described above, we also note that participants in this study were allowed to hold the tablet for reading in any positions they preferred. As a result, a variety of reading postures were observed; some preferred to lean the tablet on the steering wheel, and some rested the tablet in their lap. The range of postures might have confounded with participants’ motor movements for gaze redirection and their manual response times to takeover, as Yang et al. (2018) found that body posture has an impact on the hands-on steering wheel time and takeover quality. Future experiments may consider how best to control for drivers’ motoric state as they engage in NDRTs. Also, we did not attempt to control participants’ level of engagement in their reading task. It is possible that when the cognitive resources of a participant are heavily occupied, participants may have less capacity to perceive or process the audio signals. Variations of NDRT type and the level of engagement in one may be a topic of interest to the research community in driver-automation interaction. Future studies may also be interested in exploring feedback design options that consider driver physical, physiological, and cognitive state.

As an exploratory study, we intentionally selected music that has simple structure and without vocal contents to minimize cognitive processing of the music that could potentially interfere with the reading task or the verbal takeover request. In reality, drivers may engage in a wide range of NDRT and may listen to different types of music. Future studies manipulating a variety of music and other audio sources (e.g., podcast, radio etc.) could investigate more possibilities of blended sonification design to support automated driving.

Finally, the long-term effect of blended music sonification has yet to be explored. Over time drivers may become more apt at relating changes in music to the information mapped, or conversely drivers may become desensitized to such changes. Sonification schemes may also be based on individual preferences in music in addition to their real-time driver state. For example, using more familiar music may be more effective in a sonification design similar to ours; Jacobsen et al. (2005) found in their study that detection of changes in sounds were enhanced when sounds were familiar.

Overall, while our study results lend support to the effectiveness of sonification feedback on supporting takeover events in conditionally automated driving, successful implementations of sonification feedback must consider carefully how humans perceive, process, and respond to audio information in various situations related to automated driving.

5. Conclusion
This paper presents a driving simulator study that investigated the use of music manipulation as a medium to provide system reliability information continuously in conditionally automated driving, compared to having similar but intermittent feedback or no feedback at all. Results lend support to the effectiveness of the proposed blended music sonification in increasing monitoring behavior during automated driving and in supporting the takeover process. Furthermore, there was some evidence that music feedback provided continuously was more effective than when provided intermittently, possibly an extension of the induced glance patterns. Moreover, using music as a feedback medium in this study was well received by participants and did not induce higher workload in participants, compared to those who received no feedback. As alluded to in our discussions above, our music sonification scheme appears to support more of a general awareness of when to look at the road rather than assisting drivers in specific situations. Notwithstanding this and other study limitations noted earlier, our study found blended sonification to be a potentially effective way for improving automation transparency and to keep drivers on the loop in automated driving. In the future, we aim to investigate how best to combine automation reliability information and traffic situational information to better enhance driver situation awareness and facilitate task-switching in automated driving.

