Federated learning has attracted much research attention due to its privacy protection in distributed machine learning. However, existing work of federated learning mainly focuses on Convolutional Neural Network (CNN), which cannot efficiently handle graph data that are popular in many applications. Graph Convolutional Network (GCN) has been proposed as one of the most promising techniques for graph learning, but its federated setting has been seldom explored. In this article, we propose FedGraph for federated graph learning among multiple computing clients, each of which holds a subgraph. FedGraph provides strong graph learning capability across clients by addressing two unique challenges. First, traditional GCN training needs feature data sharing among clients, leading to risk of privacy leakage. FedGraph solves this issue using a novel cross-client convolution operation. The second challenge is high GCN training overhead incurred by large graph size. We propose an intelligent graph sampling algorithm based on deep reinforcement learning, which can automatically converge to the optimal sampling policies that balance training speed and accuracy. We implement FedGraph based on PyTorch and deploy it on a testbed for performance evaluation. The experimental results of four popular datasets demonstrate that FedGraph significantly outperforms existing work by enabling faster convergence to higher accuracy.

Federated learning has shown great promise in enabling collaborative machine learning among distributed devices while preserving their data privacy [1]. There is a growing amount of research efforts on federated learning [2], [3], but they study Convolutional Neural Network (CNN) models that show superior learning accuracy on image and voice data. However, many applications generate graph data (e.g., social graphs and protein structures) consisting of nodes and edges, and much evidence has shown that CNN cannot efficiently handle graph learning [4], [5]. Graph Convolutional Network (GCN) [6] has been proposed to deal with graph learning by a novel graph convolution operation. Different from CNN’s convolution operation that filters a small set of neighboring pixels, a graph convolution operation filters the features of neighboring nodes. Unfortunately, existing work of federated learning mainly focuses on CNN, leaving GCN under explored.

Recently, there are several preliminary research efforts about graph learning on decentralized datasets. Zhou et al. [7] have studied a vertical federated learning scenario on graphs, where clients maintain the same nodes but with different features and edge types. Similarly, Mei et al. [8] assume that graph structural, features and labels belong to different sources. These works are different from the general setting studied in our paper. Some recent works explore the intersection of graph and federated learning by discussing the effect of Non-I.I.D data distribution in federated graph learning [9], [10]. However, these works do not consider the inter-graph connections, which is a pervasive phenomenon in the real world [11].

In this paper, we study federated learning on GCN based on graph data distributed among multiple computing clients that do not allow direct data sharing due to privacy protection. Each client has a subgraph with edge connections to the subgraphs held by others. Every graph node is associated with some features that contain private information. For example, medical records in hospitals can be organized as graphs, where each graph node represents a record and its features include personal information (e.g., ages, genders, and occupations) as well as health conditions (e.g., diseases) [11]. It has been widely recognized that these feature data is privacy-sensitive and they cannot be exposed. Given some nodes with labels, the goal of graph learning is to predict the labels of other nodes.

Federated learning on GCN is not a simple extension of its counterpart on CNN because of two unique challenges. First, GCN training involves node feature sharing among clients, leading to the risk of privacy leakage. To exploit graph structure information, the graph convolution operation is designed to aggregate feature data of neighboring nodes. Such an operation would fail if some neighboring nodes are maintained by other clients, who refuse to expose their features. A straightforward solution for privacy protection is to eliminate feature sharing, but it would seriously decrease training accuracy, which has been confirmed by our experimental results. The second challenge is the high training overhead incurred by large graph size [12], [13]. For example, a social network maintained by Facebook contains over 3 billion users, and the corresponding graph data size may be several hundreds of gigabytes [14]. Since a GCN model stacks several layers of the same structure with the original graph, the model size becomes extremely large, even exceeding the physical memory constraint.

In this paper, we propose FedGraph, a federated graph learning system that integrates the ideas of federated learning and GCN to open new opportunities for privacy-preserving distributed graph learning. FedGraph is especially good at learning on distributed graphs with complicated connections, and can converge to a high training accuracy by addressing the above challenges. For the first challenge about the dilemma of feature sharing and privacy protection, a common solution is to use cryptography-based techniques, e.g., homomorphic encryption [15], [16], to enable computation over encrypted data. Despite strong security guarantee, these techniques have high computational overhead, making them inappropriate choices for FedGraph that pursuits high training speed. There also exist hardware-based solutions, e.g., SGX [17], [18], for privacy protection, but security hardware has limited capacity and it cannot handle large graph data [18]. FedGraph solves the dilemma by designing a cross-client graph convolution operation, without heavy cryptographic operations or dedicated hardware. Instead of directly sharing node features, FedGraph embeds them into low-dimensional representations before sharing, so that original features cannot be recovered.

To reduce GCN training overhead, graph sampling has been widely adopted to randomly select a mini-batch of nodes for training [12], [19], [20], [21]. GraphSAGE [12] is a graph sampling method based on node neighboring relationship. It randomly selects a fixed number of neighbors when applying the graph convolution operation for each node. FastGCN [20] has been proposed to improve sampling efficiency by independently selecting nodes for each graph convolution layer. However, existing work cannot satisfy the requirements of FedGraph design due to three weaknesses. First, these sampling methods depend on some hand-crafted parameters that rely heavily upon the knowledge of domain experts. For example, the performance of GraphSAGE is determined by the parameter specifying the number of sampled neighbors, and manual parameter tuning is time-consuming. Second, existing methods ignore the tradeoff between training speed and training accuracy. Sampling fewer nodes accelerates training but decreases accuracy. Third, clients participating in federated graph learning are heterogeneous in graph size and computational capability. Applying the same sampling policy for all clients is far from the optimal solution.

These weaknesses make the sampling algorithm design challenging in FedGraph. Instead of struggling to improve existing heuristic designs, we resort to Deep Reinforcement Learning (DRL) techniques and design an intelligent sampling algorithm that can automatically adjust sampling policies by jointly considering computation overhead, training accuracy and client heterogeneity. By carefully examining various DRL algorithms, we choose the Deep Deterministic Policy Gradient (DDPG) and cast it to federated graph learning. The main contributions of this paper are as follows.

We propose FedGraph as a novel federated graph learning system. We formally present the procedures of local training by clients and global parameter update by the server. A lightweight cross-client convolution operation is proposed to enable feature sharing among clients while avoiding privacy leakage.

A DRL-based sampling algorithm is designed for FedGraph, so that it can automatically find the best sampling policy that makes a good tradeoff between training speed and accuracy.

We implement a prototype of FedGraph and evaluate it on a testbed. Four popular graph datasets are used in performance evaluation. The experimental results show that FedGraph enables at least 2 times faster convergence to about 10% higher accuracy than existing work.

The rest of this paper is organized as follows. We review some necessary background of GCN and federated learning in Section 2. The FedGraph design is presented in Section 3, followed by the intelligent sampling policy design in Section 4. Section 5 gives experimental results. Related work is presented in Section 6. Finally, Section 7 concludes this paper.

SECTION 2Background and Motivation
In this section, we present some necessary backgrounds of federated learning and GCN. In addition, we analyze existing graph sampling approaches as well as their weaknesses, which motivate FedGraph design in this paper.

2.1 Federated Learning
The goal of federated learning is to train a shared model among distributed devices while avoiding the exposure of their training data. A typical federated setting consists of a number of devices, each of which holds a dataset that cannot be exposed to others. In addition, there is a parameter server responsible for synchronizing training results among devices. Federated learning contains multiple training rounds. In each training round, devices first download the latest global model from the parameter server and independently conduct training using their local data. Then, they send updated models or model differences back to the parameter server. After collecting training results from all devices, the parameter server integrates them to create a new global model. During the whole training process, devices share only models and it is almost impossible to infer the training data from these models. Due to the protection for training data, federated learning becomes one of the hottest topics in recent years and many important research efforts have been made to address various challenges [2], [22], [23], [24]. However, they all focus on CNN models, and GCN-oriented federated learning is seldom studied.

2.2 Graph Convolutional Network
CNN has achieved great success in learning on euclidean data, e.g., images and videos. However, a large amount of data in practice are expressed as graphs consisting of nodes and edges, which are also called non-euclidean data. Graph Convolutional Network (GCN) [6] has been proposed as one of the most promising techniques for graph learning. By stacking multiple graph convolutional layers, GCN is able to exploit information of graph structure and node/edge features for node/edge classification problems in various applications. Specifically, we consider an undirected graph defined as G=(V,E), where sets V and E include nodes and edges, respectively. The corresponding graph adjacency matrix is denoted by A. Each node v∈V is associated with a feature vector x(v). A GCN contains L convolutional layers, each of which has the same structure as the original graph G. In the lth layer, each node v is represented by a vector h(l)(v), which is called node embedding. The first layer is the input graph and we have h(1)(v)=x(v). As shown in Fig. 1, the graph convolution operation aggregates embeddings of neighboring nodes, transfers the results into low-dimensional representations, and finally feeds them to an activation function σ(⋅), e.g., ReLU, to generate node embeddings of the next layer. Formally, the propagation rule of GCN can be defined as follows:
Z(l+1)=QH(l)W(l);H(l+1)=σ(Z(l+1)),(1)
View Sourcewhere H(l) includes all node embeddings in the lth layer, and Q=D~−12A~D~−12. For the matrix D~, we have D~ii=∑jA~ij and A~=A+I, where I is an identity matrix. The feature weights included in W(l) are trainable parameters. Given some nodes with labels, we can train the feature weight matrix W(l) using gradient descent algorithms. The trained parameters can be used to classify the nodes without labels.


Fig. 1.
Illustration of graph convolution operation.

Show All

2.3 Graph Sampling
In many applications, graphs are very large and the corresponding GCN training has high computational overhead. Graph sampling has been proposed to reduce the sizes of graphs used for GCN training, and its existing work can be classified into two categories. One is node-wise neighbor-sampling that iteratively samples a fixed number of neighbors for each node. As shown in Fig. 2a, given some nodes in the (l+1)th layer, we randomly select a subset of their neighbors as the lth layer. Such a sampling guarantees that aggregation of node embeddings always happens among neighboring nodes. A representative work of node-wise neighbor-sampling is GraphSAGE [12]. However, the number of sampled nodes may exponentially increase as more layers are constructed. In addition, Huang et al. [25] have pointed out that it incurs redundancy of embedding calculation at some nodes, e.g., the red nodes in Fig. 2a, which are the shared neighbors of other nodes. Several recent approaches, e.g., VR-GCN [19] and Cluster-GCN [26], have been proposed to improve the performance of node-wise neighbor-sampling, but they cannot fundamentally address this weakness.


Fig. 2.
An illustration of different sampling approaches. The sampled nodes are marked in color (dark, red, and blue). The dashed arrows denote edge connections in the original graph. The solid arrows denote the edges preserved by sampled nodes.

Show All

The other kind of approaches is called layer-wise importance-sampling. Its basic idea is to independently sample a fixed number of nodes for each GCN layer based on a sampling probability, which is calculated based on node degrees. FastGCN [20] is a typical approach of layer-wise importance-sampling. However, since nodes of different layers are sampled independently, some sampled nodes may have no connections with the ones in the previous layer, like the blue-marked node shown in Fig. 2b. The embeddings of some unlinked nodes may be lost during graph convolution operations, which would deteriorate the training performance.

The strengths and weaknesses of both sampling approaches motivate us to design a new sampling policy that can well control the computation overhead while keeping neighboring relations during sampling.

SECTION 3FedGraph Design
We consider a typical setting of federated graph learning, which consists of a set C of computing clients that conduct local training tasks, and a server responsible for global parameter update, as shown in Fig. 3. Computing clients and the server may locate at different locations and they are connected by wide-area networks. Each client i∈C maintains a graph Gi(Vi,Ei), where each node v∈Vi is associated with a feature vector x(v) that cannot be exposed to other clients. A subset Vlabeli⊆Vi of nodes have labels denoted by {y(v)|v∈Vlabeli}, which can be used as training data. The edge set Ei contains the internal edges among nodes in Vi, as well as the external ones connecting to nodes held by other clients. Each client is aware of the existence of neighboring nodes maintained by others but cannot directly access their feature vectors.


Fig. 3.
The FedGraph architecture. Each client i maintains a local graph Gi. During the training, nodes in the mini-batch (nodes in red) aggregate neighbors’ embeddings to generate the next layer’s embeddings, denoted by red arrows. When training completes, each client i uploads its local model weights Wi to the parameter server. Finally, the parameter server aggregates all local model weights to the updated global model W¯ and sends it back to all clients.

Show All

We assume that computing clients and the parameter server are honest-but-curious, i.e., they honestly follow the federated learning procedures but want to learn feature information held by others. This is a typical threat model that has been widely used by current federated learning research [15], [27], [28]. Some other more serious threat models are discussed as follows. Some malicious clients can tamper with the training by modifying model parameters sent to the parameter server. To deal with this threat, we can use Trusted Execution Environment (TEE) for local training. TEE is commonly available on modern CPUs. It enables an isolated execution environment guaranteed by hardware, and adversaries cannot access data and codes in TEE. Besides, malicious parameter servers can modify global model parameters to compromise federated learning. We can use secure multi-party computation (MPC) or homomorphic encryption (HE) to protect the model aggregation. Besides, TEE can be also used to protect global model aggregation at the parameter server.

Our system design is shown in Fig. 4. We customize the parameter server and clients by adding new modules to implement intelligent sampling. The parameter server contains three main modules. The DDPG-based sampling algorithm generates sampling policies for all clients. A model aggregator collects local feature weights trained by clients and aggregates them to generate new global feature weights for next-round training. In addition, a communication module is designed for message exchanges between the parameter server and clients. This communication module is realized by gRPC APIs, which are based on TCP communication protocol. Each client has a module of GCN construction, responsible for creating a GCN model according to sampling policy. A GCN training module is designed to run the training algorithm.

Fig. 4. - 
System design.
Fig. 4.
System design.

Show All

In FedGraph, in order to predict y(v) of unlabeled nodes, clients collaboratively train global feature weights W¯¯¯¯¯. There are multiple training rounds. In each round, clients download the latest feature weights from the server and construct local GCNs to train these weights. Due to the existence of external edge connections, local GCN training involves embedding sharing among clients. After that, they send updated feature weights to the server, which then creates new global feature weights that will be used for the next-round training. Although FedGraph shares a similar process with traditional federated learning, it has unique procedures of local training and global parameter update, which are presented as follows.

3.1 Local GCN Training by Clients
The local GCN training procedure of each client i∈C is described in the Algorithm 1. At the beginning of each round, client i downloads the latest feature weights W¯¯¯¯¯ as well as a graph sampling policy Pi from the server. The local feature weights are initialized as Wi=W¯¯¯¯¯. Then, this client launches multiple training iterations to update feature weights based on local graph data. Specifically, each training iteration consists of the following two main steps.

Algorithm 1. Local Training Procedure of Client i∈C
for each training round t do

Download the latest feature weights W¯¯¯¯¯ and a sampling policy Pi from the parameter server;

Initialize the local feature weights as Wi=W¯¯¯¯¯;

for each iteration do

Construct a GCN Gi={V(1)i,V(2)i,…,V(L)i}=ModelConstruct(Gi,Pi)

for each layer l=1,2,…,L−1 do

for each node v∈V(l)i do

if l=1 then

z(l+1)i(v)=∑u∈ViQ˜(l)i(v,u)h(l)i(u)W(l)i;(2)
View Source

else if l>1 then

z(l+1)i(v)=∑u∈ViQ˜(l)i(v,u)h(l)i(u)W(l)i+∑j∈Cj≠i∑u∈VjQ˜(l)i(v,u)h(l)j(u)W(l)j;(3)
View Source

end if

Generate the embeddings of the (l+1)−th layer:
h(l+1)i(v)=σ(z(l+1)i(v));(4)
View Source

end for

end for

Calculate the loss according to the function:
L=1|V(L)i|∑v∈V(L)iloss(y(v),zLi(v))(5)
View Source

Update the local feature weight:
Wi←Wi−ϵ∇L(6)
View Source

end for

Submit updated feature weights Wi to the server;

end for






3.1.1 GCN Construction
We construct a GCN Gi of L layers, using the function ModelConstruct() that samples a subset of nodes according to the policy Pi. The basic idea is to start by randomly selecting a set of nodes with labels, which is also referred to as a mini-batch. For each node in the mini-batch, we then iteratively aggregate the embeddings of a sampled subset of neighbors at most L−1 hops away.

The pseudo codes of ModelConstrut() are shown in Algorithm 2. Specifically, a sampling policy can be expressed by Pi={κi,p(1)i,p(2)i,…,p(L−1)i}, where κi denotes the mini-batch size, and {p(1)i,p(2)i,…,p(L−1)i} are neighbor sampling probabilities of L−1 layers, respectively. As shown in line 1, we sample κi labeled nodes as the mini-batch and they compose the final Lth layer. Then, we iteratively construct other GCN layers in a backward direction. For each node v in the (l+1)th layer, we randomly select a subset N(l)i(v) of its neighbors into the lth layer with a probability p(l)i. In addition, we create a matrix Q˜(l)i to replace Q in (7), where Vi(v) denotes the set of neighbors of node v in the original graph Gi. The matrix Q˜(l)i describes the updated adjacent relation after sampling, and it will be used for feature aggregation later. All sampled nodes in the lth layer are maintained in set V(l)i, as shown in the final line.

Algorithm 2. The Pseudocodes of ModelConstruct()
Randomly select κi labeled nodes as a mini-batch and include them into the Lth layer, i.e., V(L)i;

for each layer l=L−1,…,2,1 do

for each node v∈V(l+1)i do

Sample a subset N(l)i(v) of neighbors according to a selection probability p(l)i;

Update the adjacent matrix Q˜(l)i as follows.
Q˜(l)i(v,u)=⎧⎩⎨|Vi(v)||N(l)i(v)|Qi(v,u),0,if u∈N(l)i(v);otherwise;(7)
View Source

end for

V(l)i=∪v∈V(l+1)iN(l)i(v);

end for

Algorithm 
The GCN construction combines the strength of node-wise sampling and layer-wise sampling. These sampling probabilities are independent, which offers opportunities for fine-grained sampling over layers, like layer-wise sampling. By carefully setting these probabilities, we can avoid the high computational cost incurred by the recursive explosive expansion of the neighborhood. Meanwhile, since the sampling process is based on neighborhood relation, which is similar to node-wise sampling, we can avoid sampling nodes without connections.

3.1.2 GCN Training
After constructing a GCN model, we continue to train this GCN based on gradient descent. The cross-client graph convolution operation is described in lines 7-13 of Algorithm 1. Specifically, clients aggregate embeddings of only internal neighbors when they process the first GCN layer, as shown in Eq. (2). From the second layer, we enable clients to aggregate both internal neighbors and external ones, which is shown in Eq. (3). Such a design can prevent the leakage of local origin features while enabling information sharing. We will give the security analysis in Section 3.3.

After aggregation, a nonlinear transformation is applied to generate the node embedding h(l+1)i(v) of the next layer, as shown in Eq. (4). With the objective of minimizing a loss function defined in Eq. (5), we compute the gradients and update feature weights in Eq. (6), where ϵ is the learning rate. Finally, client i submits the updated feature weights (or their differences from downloaded ones) to the parameter server.

3.2 Global Parameter Update by the Server
The procedure of global weight update by the parameter server is shown in Algorithm 3. The server starts by initializing random feature weights W¯¯¯¯¯ and sampling policies {P1,P2,…P|C|}, and then sends them to clients, respectively. In each of the following training rounds, it collects updated local feature weights from all clients, followed by two main tasks. First, it creates global feature weights by aggregating local weights as shown in Eq. (8), where κi denotes the mini-batch size, i.e., the number of labeled nodes, at client i in the current training round. The second task is to update sampling policies for clients using function GenSampling(), whose details will be given in the next section. The design of GenSampling() is one of the most important contributions of this paper, and it relies on the deep reinforcement learning technique to balance computational overhead and model accuracy. Finally, the server sends new global feature weights and sampling policies to clients to start the next round of training.

Algorithm 3. Global Weight Update of Parameter Server
Initialize random feature weights W¯¯¯¯¯ and sampling policies {P1,P2,…P|C|}, and send them to clients, respectively;

for each training round t do

Collect feature weights {W¯¯¯¯¯,W1,W2,..,W|C|}, from all clients;

Create global feature weights:
W¯¯¯¯¯=∑i∈Cκi∑i∈CκiWi;(8)
View Source

Update the sampling policy {P1,P2,…,P|C|}=GenSampling(W¯¯¯¯¯,W1,W2…,W|C|);

Send global feature weights W¯¯¯¯¯ and sampling policy Pi to every client i∈C;

end for


3.3 Security Analysis
To show how our proposed Algorithm 1 protects feature data, we consider two clients i and j, who need to share node embeddings during training, without loss of generality. Suppose client i aggregates embeddings from client j and wants to infer the original node features h(1)j. Note that h(1)j is a matrix containing features of all nodes held by client j, i.e., h(1)j(v)=xj(v),v∈Vj.

We let Vij denote the client i’s neighboring nodes at client j. According to Algorithm 1, client i can get information of {h(2)j(Vij)W(2)j,h(3)j(Vij)W(3)j,…,h(L)j(Vij)W(L)j}. Then, client i can guess node embeddings {h(2)j,…,h(L)j} by approximating remote W(l)j using local W(l)i, which is possible when they just synchronize global feature weights from the server.

However, it would be difficult for client i to further infer h(1)j(Vij) because h(2)j=σ(Q~(1)jh(1)jW(1)j) and client i has no information about Q~(1)j, i.e., the adjacent matrix in client j after sampling. Furthermore, the guess of {h(2)j,…,h(L)j} can hardly achieve high accuracy due to the dimension reduction of embeddings in higher layers. Given that original features of neighboring nodes can be protected, it would be impossible to get the features of internal nodes at client j. Therefore, we can conclude that FedGraph can protect the node features while enabling information sharing during federated graph learning.

SECTION 4Intelligent Graph Sampling Based on DRL
Sampling policies {P1,P2,…P|C|} determine how many nodes are involved in GCN training, and they affect both computational overhead and training accuracy. By sampling fewer nodes, we can accelerate the training process with reduced computational overhead, while lowering training accuracy. On the other hand, with more sampled nodes, we can better approximate the original GCN to achieve higher training accuracy, but incurs a high computational cost. Therefore, it is significant to design sampling policies to make a tradeoff, however, which has been ignored by existing work. Meanwhile, sampling policy design is difficult due to a large optimization space, and manual tuning hardly works in practice. We desire automatic algorithms, with minimum human involvement, to generate good sampling policies.

By carefully examining sampling policies, we find that their influence on the learning performance, in terms of training speed and accuracy, cannot be described using precise closed-form expressions. Instead of struggling with heuristic algorithm design, we resort to Deep Reinforcement Learning (DRL) that can automatically approximate a good solution. The idea of DRL can be implemented in various ways, generating a thriving family of algorithms for different application scenarios with different performance. By carefully comparing candidate DRL algorithms, we choose to use Deep Deterministic Policy Gradient (DDPG) algorithm [29], which can efficiently handle the high-dimensional and continuous action space of our problem. DDPG combines Deep Q-Networks and actor-critic approach and thus enjoys their benefits.

4.1 DDPG-Based Problem Formulation
To apply DDPG, we first formulate our problem as a Markov decision process as follows.

State Space. We define the system state of the training round t as the observed feature weights at the beginning of this round, which can be represented by s[t]={W¯¯¯¯¯[t],W1[t],W2[t],…,W|C|[t]}. Note that W¯¯¯¯¯[t] is the global feature weights and Wi[t] denotes the local feature weights of client i∈C. The whole action space is denoted by S. Since the state space is huge, we leverage the principal component analysis (PCA) [30] to project the high-dimensional space onto a lower-dimensional space while keeping the distribution information as complete as possible.

Action Space. At the beginning of round t, the parameter server needs to decide graph sampling policies for all clients. The action a[t] of each round t is therefore defined as the corresponding sampling policies, i.e., a[t]={P1[t],P2[t],…,P|C|[t]}. The action space is denoted by A.

Reward. Since both learning speed and accuracy are considered as performance metrics, the reward should be defined to reflect them. We use the completion time of each training round t, which is denoted by δ[t], to evaluate the training speed. The server can easily obtain δ[t] by measuring the time consumption of collecting local training results from all clients. The training accuracy λ[t] is calculated based on a testing set at the parameter server. We consider a typical federated setting, where the parameter server is usually the task publisher that holds a testing set. Each client has its own training set and validation set, which cannot be exposed due to privacy concerns. With the information of δ[t] and λ[t], we define the reward of each round t as follows,
r[t]=Ω(λ[t]−Λ)−α(δ[t]−β),(9)
View SourceRight-click on figure for MathML and additional features.where Λ is the target accuracy. The constants Ω, α and β can be adjusted to express different preferences on learning speed and accuracy. The reward contains two parts. The first part evaluates accuracy improvement. We notice that λ[t] shows nonlinear improvements as the learning proceeds. It can be quickly improved in the first few training rounds, but the improvement becomes smaller later. In order to make the reward unbiased, we use an exponential function here. The second part evaluates the completion time of each training round in the negative form, to encourage fast training. In practice, the completion time of a client is affected by many factors, i.e., computational hardware or network latency. We alleviate the impact of these factors by adding a constant β in (9), so that we can better evaluate the influence of different sampling policies. In our experiments, we control the time penalty, i.e., α(δ[t]−β), close to 1, as referred to [24], which can be easily achieved by profiling.

Learning Policy and Objective. We define the DRL learning policy in our problem as πθ:S→A, which is parameterized by θ. More precisely, given a state s[t], the algorithm outputs a deterministic action at. The objective of our DRL-based sampling algorithm is to maximize the expected cumulative discounted reward from the starting state, which is defined as
J(θ)=E[R[t]|S[t]=s[t]],
View SourceRight-click on figure for MathML and additional features.where R[t]=∑∞k=0γkr[t+k] is the cumulative discounted reward function.

The action-value function qπ(s[t],a[t]) is defined to describe the expected cumulative discounted reward after executing action a[t] in state s[t] based on policy πθ, i.e., qπ(s[t],a[t])=E[R[t]|S[t]=s[t],A[t]=πθ(s[t])]. Typically, we use neural networks to approximate the policy function πθ and action-value function qπ.

4.2 Sampling Based on DDPG
The DDPG-based sampling algorithm design is illustrated in Fig. 5. We design an actor network μ(s|θμ) to predict deterministic actions, and a critic network q(s,a|θq) to estimate the action-value function qπ(s,a). Meanwhile, we maintain copies of the actor network and critic network, denoted by μ~(s|θ~μ) and q~(s,a|θ~q), which are also referred to as target networks. They can be used to update the original actor and critic networks.


Fig. 5.
Illustration of DDPG-based sampling.

Show All

Similar to Deep Q-Networks, we maintain a replay buffer of finite size to store historical transitions defined as (s[t],a[t],r[t],s[t+1]). We update the actor and critic networks by sampling a mini-batch of transitions from the reply buffer. When the buffer is full, the oldest samples are discarded. We then formally introduce the DRL-based sampling algorithm, i.e., implementation details of function GenSampling(), and explain how it learns the optimal sampling scheme.

Algorithm 4. Sampling Algorithm Based on DRL
Randomly initialize the actor μ(s|θμ) and critic q(s,a|θq) with parameters θμ and θq;

Initialize the target networks μ~(s|θ~μ) and q~(s,a|θ~q) with parameters θ~μ←θμ and θ~q←θq;

Initialize the initial state s[0]={W¯¯¯¯¯[0],W1[0],…,W|C|[0]};

Reduce the dimension of initial state: s′[0]=PCA(s[0]);

Initialize the exploration noise Δ and replay buffer;

Generate sampling policies represented by a[0]=μ(s′[0]|θμ)+Δ0 and send them to clients;

for episode = 1,2,…,Z do

for t = 1,2,…,T do

Observer the state s[t] and reward r[t−1];

s′[t]=PCA(s[t]);

Store the transition (s′[t−1],a[t−1],r[t−1],s′[t]) into the replay buffer;

Randomly select a mini-batch of K transitions from the replay buffer;

Update the critic and actor networks by (11) and (12);

Update the target networks by soft update method:
θ~μ=ϕθμ+(1−ϕ)θ~μ,(13)
View Source
θ~q=ϕθq+(1−ϕ)θ~q;(14)
View Source

Generate sampling policies a[t]=μ(s′[t]|θμ)+Δt;

end for

end for



The pseudo codes of the DDPG-based algorithm are shown in Algorithm 4. We initialize four networks as well as the system state in lines 1−5. At the beginning of training round t, the server observes the current state information s[t] in the form of feature weights of all clients, and the reward r[t−1] defined in (9), as shown in line 9. Then, we reduce the dimension of s[t] to get s′[t] using the PCA method [30], and then store the transition (s′[t−1],a[t−1],r[t−1],s′[t]) into the replay buffer. After that, we randomly select a mini-batch of K transitions to update the critic network by minimizing the loss function
L=1K∑k=1K(qtarget−q(s′[tk−1],a[tk−1]|θq))2,(10)
View Sourcewhere qtarget=r[tk−1]+γq~(s′[tk],μ~(s′[tk]|θ~μ)|θ~q) is the target action value. The parameters of the critic network are updated by
θq[t]=θq[t−1]−ηq∇L,(11)
View Sourcewhere ηq is the learning rate. Then we update the actor network as follows:
θμ[t]=θμ[t−1]−ημ[1K∑i∇aq(s[i],a)∇θμμ(s[i])|a=μ(s[i])],(12)
View Sourcewhere ημ is the learning rate of the actor network. The parameters of two target networks are updated in line 14, where ϕ≪1. Finally, we obtain the action a[t] representing sampling policies based on updated networks.

SECTION 5Performance Evaluation
5.1 Experimental Settings
We implement FedGraph using PyTorch and Deep Graph Library (DGL) [31], a Python package dedicated to deep learning on graphs. We deploy FedGraph on 20 computing clients with Intel i7-10700 CPU, 32 GB memory, and Geforce RTX 2080 GPU. We consider 4 popular graph datasets: Cora, Citeseer, PubMed, and Reddit, which have been widely used for GCN studies [12], [19], [20], [21], [25], [26]. Some statistic information of these datasets is summarized in Table 1. Since some graphs, e.g., Cora and Citeseer, are with limited sizes, we synthesize large graphs based on these datasets using the following method. Given a dataset in Table 1, each client i randomly selects a proportion ξi of nodes as its local graph data, and {ξ1,ξ2,…,ξ|C|} belongs to a normal distribution with a mean of 0.8. It is possible that generated local graphs overlap on some nodes, especially for small graph datasets, like Cora and Citeseer. For large graphs, we carefully control the local graph generation to avoid overlapping. Even some nodes overlap in the synthesized datasets, we treat them as different nodes and there is no influence to training performance. A similar graph synthesis method has been adopted by [32]. For the local dataset, we randomly choose a set of nodes to generate a training set, a validation set, and a test set. The edge connections across clients are maintained according to the original graph. For local graph learning, each client constructs a 3-layer GCN, including an input layer and two convolutional layers. We set 16 hidden units, 50% dropout rate, 0.01 learning rate for Cora, Citeseer, and PubMed. For Reddit, there are 128 hidden units, the dropout rate is 20%, and the learning rate is 0.0001. We set the batch size as 256 for Cora, Citeseer, and Reddit, 1,024 for PubMed [20]. We use ADAM optimizer for local GCN training. For the reward function (9), we set the base of exponential function, i.e., Ω, as 128 in our experiments. Since FedGraph relies on the exponential property of reward function, the base has little influence on FedGraph. Moreover, the difference of training accuracy λ[t] and target accuracy Λ affects the reward in each round t. For each dataset, we choose the best accuracy reported by existing work. Even we have no knowledge of the best accuracy, we can make an estimation according to experiences. Since FedGraph only relies on the exponential property of reward function, such estimation has little influence to FedGraph. Both constants α and β aim to balance accuracy improvement and time cost. In our experiments, we control the time penalty α(δ[t]−β) close to 1, similar to the settings in [24]. For comparison, we extend the following three graph sampling schemes for federated graph learning.

Full-batch: We do not conduct graph sampling and use the original graph to construct GCN.

TABLE 1 Graph Data Statistics

GraphSAGE: A typical node-wise neighbor-sampling method that iteratively samples a fixed number of neighbors. The neighbor-sampling sizes of two convolutional layers are set as 25 and 10, respectively, which are the same with the settings in [12], [20], [26].

FastGCN: A typical layer-wise importance-sampling method that independently samples a fixed number of nodes, which is also called layer size, for each layer. The layer size of Cora and Citeseer is set to 256, and that of Reddit and PubMed is 8,192, which are the settings advocated by [21].

In the DRL-based sampling algorithm of FedGraph, both actor-networks and critic-networks have 2 hidden layers of 512 and 256 units. We compress feature weights into 20 dimensions by using the tool sklearn.decomposition.PCA [33].

5.2 Experimental Results
Convergence of DRL-Based Sampling. We let FedGraph train 300 episodes and show cumulative returns under four datasets in Fig. 6. We set the target accuracy as 90.16% for Cora, 78.7% for PubMed, 87.9% for Citeseer, and 96.27% for Reddit. We observe that cumulative discounted returns of four datasets can converge to stable values in less than 100 episodes, Especially, the biggest dataset, Reddit, almost converges after 50 episodes, as shown in Fig. 6d. These facts demonstrate good convergence of our proposed DRL-based sampling scheme.

Results of Training Accuracy. The accuracy convergence of different sampling schemes is shown in Fig. 7, where we can see that FedGraph can converge at a faster speed and achieve higher accuracy. For a fair comparison, we use physical time, instead of the number of training rounds, as the metric to evaluate training speeds of different schemes. That is because clients have graphs of different sizes, and they consume different time costs in each training round. Specifically, FedGraph achieves 75% accuracy at about 5 seconds on Cora, but the other three algorithms take more than 10 seconds to achieve similar accuracy. In PubMed, FedGraph takes about 15 seconds to achieve 73% accuracy, but GraphSAGE and full-batch scheme need more than 2 times as long to converge. In the largest datasets Reddit, FedGraph’s advantages are more obvious, as shown in Fig. 7d. We summarize the reasons as follows. GraphSAGE has a serious problem of computation redundancy, which consumes more time for training. FastGCN can not get sufficient embedding information from other clients because some sampled nodes have no edge connections. Full-batch scheme needs to calculate the embeddings of all nodes, which incurs high computational cost especially on larger graphs PubMed and Reddit. FedGraph has well addressed the weaknesses of the above methods and thus achieves higher performance. Note that the total number of training rounds is fixed to 300 and FastGCN completes training earlier because it samples fewer nodes for training. Moreover, to evaluate the scalability of FedGraph, we enlarge the experimental scale to 50 clients and show corresponding results in Fig. 8. We can find that FedGraph still outperforms other sampling schemes.

Influence of Graph Heterogeneity. We study the influence of graph heterogeneity by changing the variance of ξi. We consider three heterogeneity levels, and the corresponding variances are 0.1 (low), 0.5 (middle) and 1 (high), respectively. For a better understanding, we calculate the ratio between the smallest graph size and the largest size, and the results are about 0.2, 0.4 and 0.6, respectively. We measure the training time to converge to a target accuracy that can be achieved by most of sampling schemes. In PubMed, we set target accuracy to 72%, but FastGCN can converge to 68.6% only. As shown in Fig. 9, the training time of all sampling schemes increases as graphs become more heterogeneous under all datasets. However, FedGraph has better control on the time growth because its DRL-based sampling jointly considers the training speed and accuracy.

Effect of Cross-Client Embedding Sharing. FedGraph uses the cross-client graph convolution operation to enable embedding sharing between clients while hiding local features during local GCN training. For comparison, we consider two alternative methods, one (referred to as FedGraph_allShare) is to share embeddings from the first layer to maximize the information sharing, and the other (referred to as FedGraph_nonShare) is to discard cross-client sharing to simplify the design. We show the accuracy convergence of these three designs in Fig. 10. The total number of training rounds is set to 300. We can find that the curve of FedGraph is close to that of FedGraph_allShare, which demonstrates that FedGraph has little information loss even though it eliminates the embedding sharing in the first layer. It is because that the high-layer embedding contains information about the original features. Hence, FedGraph can efficiently learn from cross-clients embedding sharing without the original feature exchanging. Simultaneously, FedGraph significantly outperforms FedGraph_nonShare under all datasets. In Cora and Citeseer, cross-client convolution operations can increase training accuracy by about 10%. In PubMed, two designs have similar final accuracy, but FedGraph enables quick convergence. Reddit is more sensitive to cross-client embedding sharing than other datasets, and FedGraph_nonShare converges to an accuracy of about 70%, while FedGraph can converge to about 90%. That is because Reddit has rich edge connections as shown in Table 1, and ignoring cross-client edges would seriously break the whole graph structure. Note that FedGraph_nonShare completes 300-round training earlier because it eliminates embedding sharing.

The Impact of GCN Depth. We study the impact of GCN depth by changing the number of graph convolutional layers. The results are shown in Fig. 11. We can see that for all datasets, there is obvious growth of time complexity as we increase the number of layers from 2 to 4. Meanwhile, the accuracy has little changes. In particular, the accuracy of Citeseer decreases as the growth of GCN layers because of the over-smoothing issue [6], [34], [35].

Fig. 6. - 
Cumulative discounted returns of FedGraph.
Fig. 6.
Cumulative discounted returns of FedGraph.

Show All


Fig. 7.
Accuracy convergence of different sampling schemes with 20 clients. Note that, FastGCN completes the training with less time as it samples fewer nodes for training. However, it has poor performances in all datasets.

Show All

Fig. 8. - 
Accuracy convergence of different sampling schemes with 50 clients.
Fig. 8.
Accuracy convergence of different sampling schemes with 50 clients.

Show All

Fig. 9. - 
The convergence time under different levels of graph heterogeneity.
Fig. 9.
The convergence time under different levels of graph heterogeneity.

Show All

Fig. 10. - 
Convergence of FedGraph and FedGraph_nonShare. FedGraph_nonShare completes the training with less time as it ignores lots of connections in the local training. However, it has a poor convergence.
Fig. 10.
Convergence of FedGraph and FedGraph_nonShare. FedGraph_nonShare completes the training with less time as it ignores lots of connections in the local training. However, it has a poor convergence.

Show All

Fig. 11. - 
Training accuracy and time under different GCN depths.
Fig. 11.
Training accuracy and time under different GCN depths.

Show All

The Impact of Non-IID Data. The effectiveness of FedGraph on handling non-IID data is demonstrated in Fig. 12. We generate the non-iid data distribution by selecting a subset of node types for each local graph. The experimental results show that FedGraph still outperforms other schemes.


Fig. 12.
Accuracy convergence of different sampling schemes on non-iid data.

Show All

SECTION 6Related Work
6.1 Federated Learning
Federated learning has attracted great research attention due to its great promise in enabling privacy-preserving distributed machine learning [3], [22]. Zhao et al. [2] have demonstrated the impact of non-IID data in federated learning with mathematical and proposed an approach that sends a set of uniform distribution data to each client to reduce the effect of non-IID data.

Recently, several works study GNNs under different federated settings from the one in this paper. Suzumura et al., [36] develop a federated learning platform to detect financial crime activities across multiple financial institutions. They extract global graph information to euclidean data by graph analytic methods instead of graph neural networks. Besides, they assume the global graph belongs to all clients. In contrast, we study GCNs on non-euclidean data, and each client owns a local graph.

Jiang et al., [37] propose a novel distributed surveillance system based on GNN and federated learning. There are two critical differences between this work and our paper. First, they consider a cross-device federated setting, involving a large number of cameras with limited computation and communication capability. In contrast, we study a cross-silo federated setting, which typically involves a small number of clients. Second, they aim to protect the trained model. However, we explore inter-client connections and protect node features.

Mei et al., [8] study federated privacy-preserving graph neural networks with a vertical federated setting, i.e., assume that graph structural, features, and labels belong to different sources. However, we consider a horizontal federated setting, i.e., each local client maintains a complete graph dataset with its own graph structure, node features, and labels.

6.2 Graph Convolutional Networks
Due to its excellent performance, GCN has been widely used in many graph learning applications, like node classification [6], [38], link prediction [39], and recommendation systems [40]. Recently, several studies have applied GCN in natural language processing tasks, like machine translation [41] and relation classification [42]. In order to accelerate GCN training, NeuGraph [43] has been proposed as a new framework that supports efficient and scalable parallel neural network computation on graphs. NeuGraph can support not only single GPU training, but also parallel processing on multiple GPUs. Scardapane et al. [13] have proposed distributed GCN training based on message passing exchanges. However, this work ignores privacy protection, which is necessary for federated learning scenarios.

Graph sampling can effectively reduce GCN training overhead. Hamilton et al. [12] have proposed GraphSAGE that constructs a simplified GCN by sampling a subset of neighboring nodes. However, GraphSAGE incurs redundant computation at some nodes as common neighbors [25]. Although several works has been proposed to alleviate the redundant computation by reducing the size of sampled nodes, like VR-GCN [19] and Cluster-GCN [26], they still can not well address this problem when training a very large and deep GCN. To deal with this problem, layer-wise sampling methods, like FastGCN [20] and LADIES [21], have been proposed to sample the nodes for each layer independently, instead of sampling neighbors for each node. This kind of sampling method can efficiently reduce the computation cost, but some sampled nodes may have no connection due to independent sampling, which would degrade training accuracy. In addition, all above sampling methods depend on hand-crafted parameters that need manual tuning. The weaknesses of existing work motivate the FedGraph design with intelligent sampling in this paper.

SECTION 7Conclusion
In this paper, we propose FedGraph as a novel federated graph system to enable privacy-preserving distributed GCN learning. Different from traditional federated learning, FedGraph is more challenging because GCN training process involves embedding sharing among clients. To address this challenge, FedGraph uses a novel cross-client graph convolution operation to compress the embeddings before sharing, so that private information can be well hidden. In addition, to reduce GCN training overhead, FedGraph adopts a DRL-based sampling scheme that can well balance the training speed and accuracy. Experimental results on a 20-client testbed show that FedGraph significantly outperforms existing schemes.