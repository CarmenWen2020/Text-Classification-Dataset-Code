Edge Computing provides mobile and Internet-of-Things (IoT) app vendors with a new distributed computing paradigm which allows an app vendor to deploy its app at hired edge servers distributed near app users at the edge of the cloud. This way, app users can be allocated to hired edge servers nearby to minimize network latency and energy consumption. A cost-effective edge user allocation (EUA) requires maximum app users to be served with minimum overall system cost. Finding a centralized optimal solution to this EUA problem is NP-hard. Thus, we propose EUAGame, a game-theoretic approach that formulates the EUA problem as a potential game. We analyze the game and show that it admits a Nash equilibrium. Then, we design a novel decentralized algorithm for finding a Nash equilibrium in the game as a solution to the EUA problem. The performance of this algorithm is theoretically analyzed and experimentally evaluated. The results show that the EUA problem can be solved effectively and efficiently.

SECTION 1Introduction
Over the past decade, mobile and Internet-of-Things (IoT) devices, including mobile phones, wearable devices, tablets, etc., have become increasingly popular. According to Ericsson's report [1], it is predicted that there will be about 20 billion mobile and IoT devices by 2023. The rapid growth and advances of mobile and IoT devices have fueled the variety and sophistication of mobile and IoT apps (together referred to as apps hereafter). Many apps are resource-hungry, computation-intensive and high energy consumption. It has become increasingly difficult and impractical for mobile and IoT devices to run such apps due to their limited computing capacity and battery power. To tackle this problem, mobile and IoT devices can offload computation tasks to the cloud to utilize its configurable and powerful computing capacity [2], [3], [4], [5].

In recent years, apps have emerged that require low latency, e.g., face recognition [6], natural language processing [7], interactive gaming [5], etc. The cloud often cannot fulfill the stringent requirements of such latency-sensitive apps due to the often unpredictable network latency and expensive bandwidth [8]. It is an evident weakness of the cloud computing paradigm because humans are acutely sensitive to delay which is very difficult to reduce at the wide area network scale [9]. Edge computing, as a key technology that facilitates the 5G mobile network, allows computation tasks to be offloaded from mobile and IoT devices to edge servers endowed with cloud-like computing capacities. These edge servers, each powered by one or many physical machines, are deployed at base stations that are geographically close to app users. App users can offload computation tasks to nearby edge servers instead of the cloud. The edge computing paradigm paves the way for apps that require low latency [10]. Extensive research has been conducted in the past few years on computation offloading in the edge computing environment [9], [10], [11], [12], [13], [14], [15], [16], [17], [18].

While existing research focuses on the latency reduction and/or energy saving from the edge infrastructure providers’ or mobile and IoT devices’ perspectives, this paper studies a critical problem from mobile and IoT app vendors’ perspective. The edge computing paradigm allows mobile and IoT app vendors (referred to as app vendors) to hire computing capacities, e.g., CPU, memory, bandwidth, on edge servers from the edge infrastructure provider, e.g., AT&T, Telstra, etc. Their services can then be deployed on those edge servers to serve nearby app users with low latency. Usually, an edge server covers a specific geographical area so that the app users within its coverage can connect to it via wireless access [19]. Thus, edge servers are deployed in a distributed fashion - usually near cellular base stations [19], [20] - so that they can cover different geographical areas. The coverage areas of adjacent edge servers usually intersect to avoid blank areas that are not covered by any edge servers. An app user located in the intersection area can connect to one of the nearby edge servers (proximity constraint) that has sufficient computing capacity (capacity constraint) such as CPU, memory and bandwidth. Given a number of app users in a particular area, there are many ways to allocate them to the edge servers that cover that area. An inappropriate allocation might result in a large number of app users that are not allocated to any of the edge servers. Thus, from the app vendor's perspective, a straightforward and important objective is to maximize the number of its users allocated to edge servers. Following the pay-as-you-go pricing model, the app vendor pays for the computing capacities of the edge servers hired from the edge infrastructure provider. Thus, the app vendor's other important objective is to minimize the overall system cost for serving the app users. This problem is referred to as the Edge User Allocation (EUA) problem.

The cloud computing paradigm enables multi-tenancy, the ability to serve multiple tenants simultaneously based on a single application instance [21]. It allows computing resources to be shared by multiple tenants more efficiently than single-tenancy, i.e., running one application instance for each tenant [22], [23]. For example, a multi-tenant web application achieves higher throughput than a single-tenant under the same workload [24] because the consolidation of user workloads enables high server utilization in general [25]. Edge computing inherits multi-tenancy from the cloud computing paradigm and thus allows an app vendor to achieve a cost-effective solution to its EUA problem in the edge computing environment. The key is to fully leverage multi-tenancy, i.e., to allocate a maximum number of its app users to a minimum number of edge servers.

In this paper, we introduce EUAGame, a game-theoretic approach for finding a solution to the EUA problem. Game theory has been widely used in the field of distributed computing [5], [9], [26]. It is a powerful tool for the design of decentralized mechanisms [27]. In the edge computing environment, an app vendor often needs to accommodate a very large number of app users in a particular area. Thus, finding a centralized optimal solution will suffer from high complexity, due to the aforementioned proximity and capacity constraints of the EUA problem. EUAGame eases the burden of centralized optimization by making allocation decisions for app users individually while achieving a collectively satisfactory allocation solution. In addition, EUAGame allows app users to specify their individual (and often differentiated) interests in different computing capacity dimensions. EUAGame models an app vendor's EUA problem as an EUA game. In this game, each app user is simulated as a player in the game that finds a nearby edge server to offload its computation tasks. EUAGame then employs a decentralized algorithm to make allocation decisions for the app users that achieve the Nash equilibrium of the game. The main contributions of this paper are as follows:

We first model the EUA problem as a constraint optimization problem and prove that it is NP-hard to find the centralized optimal solution.

To solve the EUA problem in a distributed manner, we formulate it as a game which takes into account app users’ benefits, the multi-tenancy benefit and the overall system cost. The aim of the game is to maximize the number of allocated app users and minimize the overall system cost while fulfilling all proximity constraints and capacity constraints.

We analyze the EUA game and prove that it is a potential game which admits a Nash equilibrium.

We propose a decentralized algorithm for finding the Nash equilibrium in the EUA game.

We analyze the performance of the algorithm theoretically and experimentally.

The remainder of the paper is organized as follows. Section 2 motivates this research with an example. Section 3 presents the system model. Section 4 formulates the EUA game. Section 5 presents the decentralized algorithm for finding the Nash equilibrium in the EUA game. Section 6 evaluates the proposed algorithm theoretically and experimentally. Section 7 reviews related work. Finally, Section 8 concludes this paper and points out future work.

SECTION 2Motivating Example
A representative example latency-sensitive application in the edge computing environment is mobile gaming [28]. Most mobile games are resource-hungry. By offloading computation to remote cloud servers, cloud gaming platforms, e.g., Sony PlayStation Now1 and Nvidia Shield,2 offers an energy-efficient gaming solution to thin-client devices like mobile phones and tablets [29]. However, the often unpredictable network latency between the remote cloud servers and players’ devices limit the popularity of cloud gaming. Edge computing tackles this limitation by allowing computation to be offloaded from players’ devices to nearby edge servers.

Fig. 1 shows an example, where four edge servers, i.e., s1,…,s4, are available for a game app vendor to choose from to allocate its 10 app users, i.e., u1,…,u10. Each edge server covers a particular geographical area. App users that are outside the coverage area of an edge server cannot be allocated to that edge server due to the proximity constraint. For example, u3 can be allocated to s2, but not to s1, s3 or s4. Furthermore, the game app vendor must consider the capacity constraints, e.g., CPU, memory, bandwidth, etc. Compared with cloud servers powered by mega-scale data centers, edge servers are limited in their computing capacities, which are usually shared by multiple app vendors. Thus, an edge server must have adequate computing capacities available to accommodate the app users allocated to that edge server. In Fig. 1, the available computing capacities of an edge server and app users’ capacity needs, both unitized for simplicity, are represented by vectors ⟨CPU, memory, storage, bandwidth⟩. Under the capacity constraints, u7,u8,u9 and u10 cannot be all allocated to s4 because their aggregate capacity needs, i.e., ⟨4, 4, 4, 4⟩, exceed the available computing capacities of s4, i.e., ⟨2, 3, 4, 3⟩. For example, if u1,u2 and u6 are allocated to s1, u4 cannot be allocated to s1 because s1 does not have adequate CPUs to accommodate all the four app users. In fact, u4 cannot be allocated to any other edge servers either because it is not covered by any other edge servers. In this case, u4 will have to perform the computation tasks locally or offload it to the remote cloud server. Considering both the proximity and capacity constraints, a possible allocation solution is to allocate u1,u2 and u4 to s1, u3,u6,u8 and u10 to s2, u5 and u7 to s3, and u9 to s4. This way, no constraints are violated. However, although all the app users are allocated, it might not be the optimal allocation solution because the system cost might not be the lowest. For example, u9 can be allocated to s3 rather than s4 so that the app vendor does not need to hire s4. This can lower the overall system cost. In fact, there are many solutions that fulfill all the proximity and capacity constraints. Finding the optimal one that allocates the most app users to the least edge servers is not trivial. Multi- tenancy further complicates this allocation problem because it impacts the server utilization and consequently the overall system cost under the pay-as-you-go pricing model.


Fig. 1.
An example EUA scenario.

Show All

In real-world applications in the edge computing environment, the scales of most EUA problems can be much larger than the example discussed. Thus, finding an optimal solution to a large-scale EUA problem is very challenging. App vendors are in urgent needs of an approach that can help them allocate their app users effectively and efficiently.

SECTION 3System Model
For an app vendor, EUA aims to allocate its n app users U={u1,…,un}, to m edge servers S={s1,…,sm} in a particular area. The capacity need of an app user ui,i=1,…,n,, is denoted by ωi=(ωki), where k∈D={cpu, memory, storage, bandwidth, ...}. The available capacity of an edge server sj, j=1,…,m is denoted by cj=(ckj), where k∈D. Similar to many studies of edge computing [5], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], we investigate the EUA problem in quasi-static scenarios where the app users remain unchanged during the allocation, e.g., their capacity needs and locations. More dynamic scenarios will be investigated in our future work. In this section, we introduce the user benefit model, the multi-tenancy model, the system cost model and the optimization model. The notations adopted in the paper are summarized in Table 1.

TABLE 1 Key Notations
Table 1- 
Key Notations
3.1 Multi-Tenancy Benefit Model
Compared with single-tenancy, multi-tenancy enables higher utilization of the computing resources on cloud servers [25] as well as edge servers. According to the experimental results presented in [30], the CPU utilization of a server sj can be approximated with
fcpu(sj)=−logx(y),(1)
View Sourcewhere x (0.9<x<1.0) is determined by the computation task size, y (y>1) is the number of app users allocated to the server.

In general, the CPU utilization of a server increases with the increase in y because multi-tenancy enables a higher degree of resource sharing on the server. As y continues to increase, which incurs a higher overhead for resource sharing, e.g., handling scheduling conflicts, the increase in CPU utilization slows down and converges. At some point, the multi-tenant server is outperformed in overall CPU utilization by multiple single-tenant servers combined. This is also confirmed by [25]. The storage utilization of a multi-tenant server follows a similar pattern—improved by sharing and impacted by oversharing [25]. In this study, we assume that the sharing of other computing capacities of a multi-tenant server, e.g., memory and bandwidth, follows similar patterns as CPU and storage. Thus, the multi-tenancy benefits of an edge server sj are calculated with
fk(sj)=−logxk(y),(2)
View Sourcewhere k∈D and xk is determined by the computation task size. The computation task size impacts the sharing of different computing capacities in different ways. Thus, a xk is specific to a computing capacity. An EUA problem is solved from the app vendor's perspective for a particular app. App users are allocated to edge servers to offload their computation tasks of the same size. Thus, xk is app-specific and does not vary during the allocation process.

3.2 User Benefit Model
An app user ui can be allocated to an edge server sj only if it is covered by sj
ui∈cov(sj),∀ui∈U,∀sj∈S.(3)
View Source

Such an edger server sj is referred to as ui's neighbor edge server. The set of ui's neighbor edge servers is indicated by N(ui).

Definition 1 (Allocation Decision).
Given a user ui and S={s1,…,sm}, an allocation decision indicates to which edge server ui(1<i<n) is allocated to. It is denoted by ai(0<ai<m), where ai=0 indicates that ui is not allocated to any edge server.

Definition 2 (Allocation Strategy Profile).
Given U={u1,…,un} and S={s1,…,sm}, an allocation strategy profile is a set of all app users’ allocation decisions indicated by a=(a1,…,an).

From an app user's perspective, its direct interests, savings in computing capacities and energy consumption on their mobile or IoT devices, reduction in network latency, etc., will be ensured by the edge infrastructure provider as long as it is allocated to an edge server. However, from the app vendor's perspective, the allocation decision made for an app user, i.e., which edge server it is allocated to, impacts the corresponding multi-tenancy benefit produced. Based on the multi-tenancy benefit model, given an allocation strategy profile a=(a1,a2,…,an), the overall benefit of an individual allocation decision ai is calculated by aggregating its savings in those dimensions
Ba(ai)={∑k∈Dλki⋅fk(sai)⋅ωki,0,ai≠0ai=0,(4)
View Sourcewhere λki is the weight assigned by the app vendor that indicates the priority for the kth computing capacity for ui since app users might have different needs for those computing capacity dimensions. For example, an app user with a low-memory mobile or IoT device requires a higher weight on memory over other computing capacities. For some apps, it is possible that app users have different capacity needs. For example, a game app user that demands higher resolution and frame rate in the game requires more CPUs, memory and bandwidth. However, it is not the case for most apps, e.g., face recognition and natural language processing. The users of such an app usually have the same capacity needs. Thus, for those apps, there is ωki=ωkj,∀ui,uj∈U.

3.3 System Cost Model
In the edge computing environment, app vendors hire computing capacities on edge servers from the edge infrastructure provider to serve their app users. App vendors need to pay for the hired computing capacities based on the pay-as-you-go model. This incurs cost. Hiring more computing capacities, e.g., CPU, memory, storage and bandwidth, incurs higher cost.

Given an allocation decision ai for user ui(1<i<n), an allocation strategy profile a=(a1,a2,…,an), based on the multi-tenancy benefit model, the cost incurred by ai is defined as
Za(ai)={∑k∈Dλki⋅(1−fk(sai))⋅ωki,∑k∈Dλki⋅ωki,ai≠0ai=0.(5)
View SourceRight-click on figure for MathML and additional features.

When ai≠0, i.e., ui is allocated to an edge server. The cost incurred by ai is the computing capacities originally needed minus the the multi-tenancy benefits produced by ai. One of the app vendor's optimization objectives is to maximize the number of app users allocated to hired edge servers. Any app users that are not allocated to any edge servers, i.e., ai=0, will have to perform the computation tasks locally. This incurs a loss of benefit from the app vendor's perspective and thus is included as part of the system cost. Without this part of the system cost, minimizing the overall system cost will be equivalent to minimizing only the cost for hiring the computing capacities. The app vendor will be driven to allocate none of its app users to any of the edge servers. Minimizing this part of the system cost serves the app vendor's other objective to maximize the number of allocated app users, which will increase the cost for hiring computing capacities because more computing capacities are required to serve more app users. Therefore, given an allocation strategy profile, the app vendor's objective to minimize the overall system cost is represented as follows:
Za=min∑ui∈UZa(ai).(6)
View Source

3.4 Optimization Model
The EUA problem can be modeled as a constrained optimization problem (COP) that consists of a finite set of variable X={x1,…,xn}, with a domain Di (i=1,…,n) listing the possible values for each variable xi in X, and a set of constraints C over X. A solution to a COP is an assignment of a value to each variable xi in X from Di such that all constraints in C are fulfilled. Given a set of users U={u1,…,un} and a set of edge servers S={s1,…,sm}, the COP model for an EUA problem is formally expressed as follows:
 maxI{ai>0}(7)
View Source
min∑ui∈UZa(ai),(8)
View Sourcesubject to
ai∈{0}∪{j|ui∈cov(sj)},∀ui∈U(9)
View Source
∑ui∈U:ai=j(1−fk(sj))⋅ωki≤ckj,∀k∈D.(10)
View Source

Objective (7) maximizes the number of allocated app users. There is I{ai>0}=1 if ai>0 or 0 otherwise. It calculates the number of edge servers hired. Objective (8) minimizes the overall system cost. Constraint family (9) is the coverage constraints that ensure every user ui∈U can be allocated to an edge server sj∈S only when it is covered by sj. Constraint family (10) is the capacity constraints where ckj is the kth available computing capacity of edge server sj. It ensures that the computing capacity needs of the users allocated to an edge server must not exceed that edge server's available computing capacities.

The solution to this COP is an allocation strategy a=(a1,a2,…,an) that achieves objectives (7) and (8), and in the meantime fulfills constraints (9) and (10). How to achieve both optimization objectives is specific to app vendors. An app vendor with a low budget might prioritize objective (8). For such an app vendor, the Lexicographic Goal Programming (LGP) technique can be employed to prioritize objective (8) over objective (7).

The EUA problem is in fact the generalization of the classic bin packing problem. In a classic bin packing problem, we are given an infinite supply of bins S={s1,…,sm} with a capacity C∈N, a set of n items U={u1,…,un} sized wi (0<wi≤C). The objective is to pack all the items in U into the fewest bins possible such that the total item size in each bin must not exceed the bin capacity: ∑ui∈U(sj)ωi≤C,∀sj∈S, where U(sj) is the set of items in sj∈S. In the EUA problem, each edge server is a bin with a certain capacity. This is because edge servers might have different hardware specifications and host different apps for different numbers of app users. Each app user with computing capacity needs is regarded as an item with a size. Edge servers’ available computing capacities and app users’ computing capacity needs are usually multi-dimensional, e.g., CPU, memory, storage and bandwidth, which can be represented as a d-dimensional vector. Thus, the EUA problem can be modeled as a variable size vector bin packing problem. It is an NP-hard problem because the classical bin packing problem, which is NP-hard [31], is a special case of the variable size vector bin pack problem with d=1 and the same size for all the bins. In the edge computing environment, the number of app users that an app vendor needs to accommodate can be very large, especially in areas with high user density, e.g., CBD areas, university campuses, etc. Thus, app vendors need a tractable approach for finding the solutions to their EUA problems.

SECTION 4Edge User Allocation Game
This section presents EUAGame, our game-theoretic approach for solving the EUA problem. The reasons for the adoption of a game-theoretic approach are threefold. First, app users may have differentiated needs and pursue different interests. Game theory has been successfully employed in many fields as a powerful tool for analyzing the interactions among multiple players who act in their own interests. In the edge computing environment, it can be employed to devise incentive compatible EUA mechanisms for finding collectively satisfactory EUA solutions such that no app users have the incentive to deviate unilaterally. Second, by leveraging the intelligence of each individual app user, EUAGame attempts to solve the EUA problem in a distributed manner. It can ease the heavy burden of finding the centralized optimal solution. It will also scale with the size of the EUA problem, e.g., the number app users to allocate and the number of available edge servers. Finally, compared with a centralized approach, a decentralized game-theoretic approach can find EUA solutions quickly. This fulfills app users as well as app vendors’ needs for low latency in the edge computing environment.

4.1 Game Formulation
The EUA game is built to find a decision profile for the app vendor that allocates app users to edge servers in a cost-effective manner. The decision profile contains one decision for each app user. Those decisions are made for the app users, following the rules of the game, to achieve the app vendors objectives. Similar to [5], [9], in the game, the app users are simulated as players that make the decisions on which edge servers they are allocated to, i.e., ai=j (j∈{0}∪{j|ui∈cov(sj)})) for each ui∈U. Let us use a−i=(a1,…,ai−1,ai+1,…,an) to represent all app users’ allocation decisions except user ui. Given other app users’ decisions a−i, app user ui would like to make a proper decision ai to maximize its benefit in terms of savings on computing capacities
maxai∈{0}∪{j|sj∈N(ui)}Ba(ai),(11)
View Sourcewhere N(ui) is the set of ui's neighbor edge servers, i.e., edge servers that cover ui.

Base on (11), the EUA problem can be formulated as a game χ=(U,{Ai}ui∈U,{Bi}ui∈U), where U is the set of app users, Ai is ui's finite set of user allocation decisions and Bi is the benefit function that calculates the benefit of ui's allocation decision ai∈Ai. In this game, there might be conflicts among app users. For example, the allocation of some app users to a particular edge server might prevent some other app users from being allocated to the same edge server or any edge server. In Fig. 1, if u2 and u6 are allocated to s1, i.e., a2=a6=2, either u1 or u4 cannot be allocated to any edge server. If u2 or u6 is willing to select s2, i.e., a2=2 or a6=2, both u1 and u4 can be allocated to s1. However, a2=2 or a6=2 might result in conflicts with other app users. To study how the conflicts among the app users can be mitigated, we investigate whether the game admits at least one Nash equilibrium [32]:

Definition 3 (Nash Equilibrium).
An allocation decision profile a∗=(a∗1,a∗2,…,a∗n) is a Nash equilibrium if no app user can further increase its benefit by unilaterally changing its allocation decision, i.e.,
Ba∗−i(a∗i)≥Ba∗−i(ai),∀ai∈Ai,ui∈U.(12)
View Source

Whether the EUA game admits at least one Nash equilibrium is of significant importance of this research. The Nash equilibrium has the property that each app user's allocation decision is its best response to the choices of the n−1 other app users.

Lemma 1.
In the Nash equilibrium a∗ of the EUA game, the allocation decision a∗i of each user ui (ui∈U) must be the best choice in Ai in response to a−i.

The proof of Lemma 1 can be found in Appendix A. Lemma 1 ensures that, if a Nash equilibrium can be found, EUAGame can use it as a self-enforcing EUA solution. A self-enforcing solution, once agreed upon by the app users, does not need centralized means of enforcement, because it is in each app user's self-interest to follow the agreement if the others do [33]. This alleviates the need for a centralized approach for finding a solution to the EUA problem. It also allows app users to quickly find EUA solutions to large-scale EUA problems.

4.2 Game Property
In this section, we investigate the existence of a Nash equilibrium in the EUA game. The key is to prove that the EUA game is a potential game [34], which is defined as follows:

Definition 4 (Potential Game).
A game is a potential game if, for a potential function ϕ(a), there is
Ba−i(ai)<Ba−i(a′i)⇒ϕa−i(ai)<ϕa−i(a′i),(13)
View Sourcefor any ui∈U, ai,a′i∈Ai and a−i∈∏l≠iAl.

Based on Definition 3, the Nash equilibrium in an EUA game can be interpreted in a different way [35]. A decision profile a∗ is a Nash equilibrium if, for all app users ui∈U, there is Ba∗−i(a∗i)=maxai∈AiBa∗−i(ai). Thus, in a potential game, there is always at least one Nash equilibrium which can be found by locating the local optima of the potential function, as proven by Marden et al. [36]. This property has also be leveraged by Chen et al. in [5], [9].

To prove that the EUA game is a potential game, we first introduce and prove a property of the EUA game.

Lemma 2 (Individual Capacity Constraint).
Given an allocation decision profile a=(a1,…,an), app user ui's required computing capacity ωi=(ωki),k∈D, and the available computing capacity of edge server sj, cj={ckj},k∈D, ui can be allocated to sj if, for all other app users who have been allocated on the same edge server sj, there is
ζki(a)≜∑ul∈U∖{i}:al=jωkl≤Tki,(14)
View Sourcewhere
Tki=ckj+∑ul∈U:al=jfk(sj)⋅ωkl−ωki.(15)
View Source

The proof of Lemma 2 can be found in Appendix B. Armed with Lemma 2 that constrains the kth (k∈D) computing capacity, for all k∈D, we define
Ti=∑k∈Dλki⋅⎛⎝ckj+∑ul∈U:al=sjfk(sj)⋅ωkl−ωki⎞⎠.(16)
View Source

According to Eq. (15), more app users allocated to an edge server sj will produce more multi-tenancy benefits, which indicates higher utilization of the computing capacities hired on sj. Based on Lemma 2, we define a function
ϕa−i(ai)=−∑i=1n∑k=1dλki⋅fk(sai)ωki⋅Ti⋅I{ai=0}+12∑ui∈U∑uj≠ui∑k∈Dλkifk(sai)ωkiλkjfk(saj)ωkjI{ai=aj}I{ai>0},(17)
View Source

where I{condition} is an indicator function that returns 1 if condition is true, and 0 otherwise.

Now, we prove that the EUA game formulated in Section 4 is a potential game with function ϕa−i(ai) defined in (17).

Theorem 1 (EUA Potential Game).
The EUA game is a potential game with the potential function ϕa−i(ai).

The proof of Theorem 1 can be found in Appendix C.

SECTION 5Decentralized Allocation Mechanism
A potential game admits at least one Nash equilibrium [36]. An important property of potential games is the Finite Improvement Property, which indicates that a Nash equilibrium of a potential game can be reached via a process that goes through a finite number of iterations [34]. The finite improvement property ensures that this process will eventually end and find a Nash equilibrium. This motivates the design and development of our decentralized allocation mechanism for finding the Nash equilibrium in the formulated EUA game, which will be presented and analyzed in this section.

5.1 Mechanism Design
Given U={u1,.,un} and S={s1,…,sm}, EUAGame employs an iterative process for app users to reach the Nash equilibrium. The pseudo code is presented in Algorithm 1. This process starts with an initial allocation strategy profile (Lines 1-3). Then, based on Eq. (5), the system cost for each edge server sj∈S incurred by decision profile a in the current iteration t (t=1,2…), denoted by a(t), is calculated with Eq. (18) (Line 5)
ρa(t)(sj)≜∑k=1d∑ui∈U:ai=jλki(1−fk(sj))ωki.(18)
View Source

Next, leveraging the Finite Improvement Property, we let an app user ui that can improve its benefit update its current allocation decision ai to a better one a′i in each iteration t. Specifically, each user ui∈U first calculates the updated system cost for each sj∈N(ui) incurred by a′(t) updated from a(t) with the change from ai to a′i (Lines 7-9). There are three cases, as indicated
ρa′(t)(sj)=⎧⎩⎨⎪⎪⎪⎪⎪⎪⎪⎪ρa(t)(sj)−∑k∈Dλki(1−fk(sj))ωki,ρa(t)(sj)+∑k∈Dλki(1−fk(sj))ωki,ρa(t)(sj),for sj=saifor sj=sa′iotherwise.(19)
View Source

Next, ui finds its optimal allocation decision a′i that incurs the lowest total system cost across N(ui). If a′i≠ai, it sends a′i to the other app users requesting to contend for the decision update opportunity (Line 10). If there are multiple such allocation decisions, it randomly selects one to be sent. In each iteration of the allocation process, only one app user wins the contest for the decision update opportunity and can update its allocation decision. The winner in each iteration can be selected in a centralized or decentralized manner. The former requires centralized control [9] and the latter requires messaging synchronizing [5]. Either way, the calculation in each iteration of the allocation process (Lines 5-17) is performed by individual app users in parallel. The app users who did not win the opportunity for decision update do not update their allocation decisions in the current iteration. This process iterates until no app users would like to update their allocation decisions. Their individual allocation decisions constitute the final decision profile as the solution to the EUA problem.

Algorithm 1. Decentralized EUA Allocation
Initialization:

each ui chooses the edge server decision ai=0

End of initialization

repeat

compute the system cost on sj∈S incurred by a(t): ρa(t)(sj)

for each ui∈U do

for each server sj∈N(ui) do

calculate the system cost ρa′(t)(sj) under a′(t) updated from a(t) with a′i=j

end for

find the decision a′i that incurs the lowest total system cost across N(ui)

if a′i≠ai then

send a′i to contend for decision update opportunity

if wins the opportunity then

update its allocation decision with a′i

end if

end if

end for

until no more decision updates needed

5.2 Convergence Analysis
The Finite Improvement Property of the potential game ensures that the allocation process will complete and reach a Nash equilibrium after a finite number of iterations. Let R be the total number of iterations, Qi≜∑k∈Dλkaifk(ai)ωki, Qmin≜min(Qi), Qmax≜max(Qi), Tmin≜min(Ti) and Tmax≜max(Ti) (i=1,…,n), Theorem 2 holds for the quantification of R.

Theorem 2 (Upper Bound for Convergence Time).
When Ti and Qi are non-negative integers for any ui∈U, the maximum convergence time of EUAGame, measured by the maximum number of decision iterations, is nQmaxTmax/Qmin−n2Qmin/2, i.e., R≤nQmaxTmax/Qmin−n2Qmin/2.

The proof of Theorem 2 can be found in Appendix D. Theorem 2 shows that EUAGame converges within a quadratic time. Here, we consider the case where Qi and Ti are non-negative integers for ease of exposition. For a more general case where Qi and Ti can be real numbers, the experimental results demonstrated in Section 6.2 show that EUAGame converges rapidly with a convergence time that scales with the number of app users (n) and the number of edge servers (m).

SECTION 6Performance Evaluation
This section theoretically and experimentally evaluates the performance of EUAGame in achieving app vendors’ two optimization objectives as discussed in Section 3.4: 1) maximize the number of allocated app users; and 2) minimize the overall system cost.

6.1 Theoretical Analysis
As discussed in Section 5.1, the app users make their allocation decisions in parallel in every iteration of the allocation process. The winner of the contest for the decision update opportunity in each iteration may be determined in a non-deterministic manner, e.g., via random selection. Therefore, there might be multiple Nash equilibria in an EUA game. Thus, the performance of EUAGame is largely dependent of the Price of Anarchy (PoA) of the decentralized EUA allocation mechanism, which measures the ratio between utility of the worst Nash equilibrium and the centralized optimal solution [37]. In the EUA game, the utility of a Nash equilibrium is measured by the number of allocated app users and the overall system cost.

6.1.1 PoA in Number of Allocated App Users
Let us use χ to denote the set of decision profiles that reach different Nash equilibrium in the EUA game and a∗=(a∗1,a∗2,…,a∗n) to denote the centralized optimal decision profile. Given a decision profile a∈χ, let poauser(a) be the PoA measured by the ratio between the numbers of app users allocated with a and a∗, poauser(a) can be calculated as follows:
poauser(a)=mina∈χ∑sj∈Snumsj(a)∑sj∈Snumsj(a∗)=mina∈χ∑ui∈UI{ai>0}∑ui∈UI{a∗i>0},(20)
View Sourcewhere numsj(a) and numsj(a∗) are the numbers of app users allocated with a and a∗ respectively.

Theorem 3 (PoA in the Number of Allocated App Users).
Given any decision profile a∈χ that achieves a Nash equilibrium in the EUA game and the centralized optimal decision profile a∗, the PoA of EUAGame poauser(a), measured by the ratio between the numbers of app users allocated with a and a∗, fulfills
1≥poauser(a)≥(⌊Tmin/Qmax⌋)/(⌊Tmax/Qmin⌋+1)(21)
View Source

The proof of Theorem 3 can be found in Appendix E.

6.1.2 PoA in Overall System Cost
The other optimization objective of an EUA game is to minimize the overall system cost. Thus, we also need to analyze the PoA of EUAGame in the overall system cost. Let us again use χ to denote the set of decision profiles that reach different Nash equilibria in the EUA game and a∗=(a∗1,a∗2,…,a∗n) to denote the centralized optimal decision profile. Given a decision profile a∈χ, let poacost(a) be the PoA measured by the ratio between the overall system costs incurred by a and a∗, poacost(a) is calculated as follows:
poacost(a)=(mina∈χ∑ui∈UZi(a))/∑ui∈UZi(a∗).(22)
View Source

As discussed in Section 3.3, there are two components in the overall system cost Za, incurred by hiring computing capacities on edge servers and failures to allocate app users to any edge servers. Let us use Zedgei(a) Zlocali(a) to represent the former and the latter components of the overall system cost respectively. Given Qi, Qmax and Qmin defined in Section 5.2, let us define
Zedgei(a)≜∑k∈Dλki⋅ωki−Qi(23)
View Source
Zedgei,min(a)≜∑k∈Dλki⋅ωki−Qmax(24)
View Source
Zedgei,max(a)≜∑k∈Dλki⋅ωki−Qmin,(25)
View Sourcewhere Qmin≤Qi≤Qmax, and Zlocali(a)≜∑k∈Dλki⋅ωki.

Based on the above definitions, we have Theorem 4.

Theorem 4 (PoA in Overall System Cost).
Given a decision profile a∈χ that achieves a Nash equilibrium in the EUA game and the centralized optimal decision profile a∗, the PoA of EUAGame poacost(a), measured by the ratio between the overall system costs achieved with a and a∗, fulfills

1≤poacost(a)≤∑ui∈U(Zlocali(a)⋅I{ai=0}+Zedgei,max(a)⋅I{ai>0})∑ui∈U(Zlocali(a∗)⋅I{ai=0}+Zedgei,min(a∗)⋅I{ai>0}).(26)
View Source
The proof of Theorem 4 can be found in Appendix F.

6.2 Experimental Evaluation
We have conducted a set of small-scale experiments and a set of large-scale experiments. In the first set of experiments (set #1), we compare the effectiveness of EUAGame, measured by the percentage of allocated app users (I{ai>0}/n) and the overall system cost Za, i.e., app vendors’ two optimization objectives (7) and (8), against the Optimal optimization approach and two baseline approaches, which are originated from [38], i.e., Random and Greedy. Given a set of app users and a set of edge servers, Optimal solves the EUA problem based on the COP model presented in Section 3.4, Random allocates each app user to one of its neighbor edge servers that has adequate available computing capacities and Greedy allocates an app user to its neighbor edge server with the most available computing capacities. In the second set of experiments (set #2), we compare EUAGame against only Random and Greedy because the scales of the EUA problems have become too large for Optimal to find a solution within a reasonable amount of time. To evaluate the efficiency of EUAGame, we also present and discuss the convergence time measured by the average number of iterations taken for EUAGame to reach a Nash equilibrium, which is an important metric for evaluating the efficiency of game-theoretical approaches [5], [9], [26]. All the experiments are conducted on a Windows machine equipped with Intel Core i5 processor (4 CPUs, 2.4 GHz) and 8 GB RAM.

Experiment Data. The experiments are conducted on the locations of real-world base stations and end-users within Metropolitan Melbourne in Australia, which has a total area of over 9,000 km2. Australian Communications and Media Authority (ACMA) publishes the radio-comms license dataset that contains the geographical location of all cellular base stations in Australia, which we use as the locations of edge servers because edge servers are usually deployed at base stations [19]. The Asia Pacific Network Information Centre (APNIC) provides all IP address blocks allocated to Australia. We use the IP lookup service at http://ip-api.com/ to convert the obtained IP addresses into geographical locations to simulate app users’ locations. Since IP addresses in the last octet are likely to have identical geographical addresses returned by the IP lookup service, app users are uniformly distributed around each of the obtained geographical locations. Then, the coverage of each edge server is randomly set based on the density of app users within its coverage areas. In high-density areas, such as the central business distinct, the coverage radius of an edge server is set between 450 and 750 meters. In medium-density areas, the coverage radius is randomly set between 2,000 and 3,000 meters. Finally, as for the low-density area, the radius is from 7,000 to 8,000 meters. The raw experiment data are publicly available3 for the reproduction and validation of our experimental results.

Experiment Settings. To comprehensively evaluate EUAGame, we have simulated various EUA scenarios by changing three experiment parameters: 1) the number of app users; 2) the number of edge servers; and 3) the available computing capacities on edge servers. The available computing capacities on each edge server are randomly generated following normal distributions. The details are shown in Table 2, where the last column indicates the average computing capacity in each capacity dimension on each edge server. Each experiment is repeated for 100 times and the results are averaged.

TABLE 2 Experiment Settings
Table 2- 
Experiment Settings
Experiment Set #1. Through comparison with Optimal, Random and Greedy, Figs. 2, 3, and 4 demonstrate the effectiveness of EUAGame in experiment set #1 and the impacts of the three parameters, i.e., the number of app users (n), the number of edge servers (m) and the available computing capacities of the edge servers (c). Overall, Optimal allocates the most app users with the lowest overall system cost. Second to Optimal, EUAGame outperforms Random and Greedy significantly. Compared to Optimal, the performance loss of EUAGame in both the percentage of allocated app users and the overall system cost is less than 15 percent in all cases. On average across all cases in this experiment set, EUAGame only allocates 3.38 percent fewer app users with 4.76 percent more overall system cost than Optimal. This demonstrates the high performance of EUAGame in maximizing the percentage of allocated users and minimizing the overall system cost. Fig. 2a shows that when n exceeds a certain number, 16 for Random, 20 for Greedy and EUAGame, 24 for Optimal, the percentage of allocated app users starts to decrease. This is due to the more fierce competition among app users caused by the increase in n. As n becomes overly large, the edge servers will not be able to accommodate all the app users. In the meantime, the increase in n results in higher overall system cost, as demonstrated by Fig. 2b. This is because more computing capacities are needed and more app users are not allocated. Fig. 3a shows that, when m increases, more edge servers with more available computing capacities are able to accommodate more app users. This increases in the cost for hiring the computing capacities. However, it decreases the cost caused by failures to allocate apps users more significantly. Thus, the overall system cost decreases overall as m increases, as illustrated in Fig. 3b. In experiment set 1.3, we increased the available computing capacities on edge servers. This impacted the effectiveness of the comparing approaches in a way similar to the increase in m. As a result, Fig. 4 shows increasing trends for the percentage of allocated users and decreasing trends for overall system cost very similar to Fig. 3.


Fig. 2.
Effectiveness versus number of app users (Set #1.1).

Show All


Fig. 3.
Effectiveness versus number of edge servers (Set #1.2).

Show All


Fig. 4.
Effectiveness versus server computing capacities (Set #1.3).

Show All

Experiment Set #2. Figs. 5, 6, and 7 show the results in experiment set #2, i.e., large-scale experiments where Optimal cannot find solutions in a tractable manner. In general, EUAGame outperforms Greedy and Random in both allocated app users and overall system cost in all cases, significantly in some and marginally in the others. In this experiment set, the average advantages of EUAGame over Greedy and Random are 4.73 and 6.98 percent in terms of allocated app users, and 14.3 and 12.64 percent in terms of overall system cost. Most phenomena presented in Figs. 5, 6, and 7 are similar to Figs. 2, 3, and 4. Some interesting ones can be seen in Figs. 6b and 7b. In Fig. 6b, as m increases, the overall system costs achieved by Greedy and Random first decrease and then increase. The increase is caused by the increase in the number of allocated app users which is illustrated in Fig. 6. As m increases, Greedy and Random allocate the app users to more edge servers. This lowers the multi-tenancy benefit. In experiment set #2.2, when m exceeds 128, the decrease in multi-tenancy benefit starts to impact the overall system cost more significantly than the increase in the number of allocated app users. As a result, the overall system cost starts to increase. EUAGame, taking into account the multi-tenancy benefit, is capable of accommodating the same number of or more app users with a much lower overall system cost, 13.71 and 11.92 percent less than Greedy and Optimal respectively. Fig. 7b shows that c impacts the overall system costs in a similar way but much less significantly. Considering the multi-tenancy benefit, EUAGame again outperforms Greedy and Random significantly, by 14.86 and 13.35 percent respectively. Fig. 8 shows the convergence time of EUAGame measured by the average number of iterations taken by EUAGame to reach a Nash equilibrium in each subset of experiments in experiment set #2. The results in experiment set #1 exhibit trends similar to Fig. 8 and thus are not presented due to space limit. Fig. 8a shows that the convergence time of EUAGame increases linearly with the number of app users. Please note that base-10 scales are used for the X axis of Fig. 8a, same as Figs. 8b and 8c. Fig. 8b shows that the convergence time of EUAGame increases mildly with m. As m increases, each app user has more edge servers to select from, which increases the possibility of its decision updates. Fig. 8b also shows that the impact of m on the convergence time of EUAGame is less significant than that of n. Fig. 8c shows that as c increases, the convergence time of EUAGame first increases and then decreases slightly when c exceeds 60. At the beginning of the increase in c, more edge servers offer app vendors more possibilities for decision updates. The convergence time increases accordingly. As c continues to increase, EUAGame is capable to accommodate all the app users, as demonstrated in Fig. 7. It becomes less necessary for app users to update their decisions. Thus, the convergence time decreases. The results demonstrated in Fig. 8 show that EUAGame scales well with all three parameters, which indicates its high efficiency. This is critical to large-scale real-world applications in the edge computing environment because finding the centralized optimal solutions to the EUA problems in such scenarios is NP-hard as discussed and proved in Section 3.4.


Fig. 5.
Effectiveness versus number of app users (Set #2.1).

Show All


Fig. 6.
Effectiveness versus number of edge servers (#2.2).

Show All


Fig. 7.
Effectiveness versus available server capacities (#2.3).

Show All


Fig. 8.
Efficiency of EUAGame.

Show All

SECTION 7Related Work
One of the critical limitations of mobile and IoT devices is their limited computing capacities and energy capacities. This is also one of the key drivers that promote the advances in distributed computing paradigm in recent years, including cloud computing and edge computing. Both cloud computing and edge computing allow computation tasks to be offloaded from mobile and IoT devices to external servers deployed in the cloud or at the edge of the cloud. This way, the limitation of mobile and IoT devices’ computing capacities can be tackled. The research problem of how to effectively and efficiently offload computation tasks is referred to as computation offloading. It is one of the most active research problems in the fields of cloud computing and edge computing.

7.1 Computation Offloading in Cloud Computing
Computation offloading in cloud computing has been extensively investigated in the last decade from a variety of perspectives, e.g., load balancing [39], virtual machine placement [40], task dependencies [41], etc. Most research work in this field is focused on the performance of cloud computing systems. To name a few representative pieces of work, Yu et al. [3] study the topology configuration and rate allocation problem in cloud radio access networks. A theoretical approach is employed to tackle the delayed channel state information problem of rate allocation problem with the objective to optimize the end-to-end performance of cloud computing systems. Also aiming to improve the end-to-end performance of cloud computing systems, Yin et al. [4] take into account the cloud pricing information and the spectrum efficiency in wireless networks in their study of power allocation and interference management. Multiple problems encountered in the cloud computing environment, including cloud service price determination, resource allocation, and interference management are modeled as a Stackelberg game. Chen et al. [5] propose a game-theoretical approach for solving the computation offloading problem. This approach allows app users to make their own decisions on computation offloading while considering the network latency and the energy consumption on their devices. This way, the computation offloading problem can be solved in a distributed manner.

7.2 Computation Offloading in Edge Computing
Cloud computing is capable of alleviating the computation burden on mobile and IoT devices. However, the often unpredictable network latency between mobile and IoT devices and remote servers in the cloud has become a major obstacle to latency-sensitive mobile applications [8]. In 2010, Cisco [42] proposed a new computing paradigm, often referred to as edge computing or fog computing. As a natural extension of cloud computing, the edge computing paradigm pushes the cloud resources closer to app users by distributing edge servers across locations geographically close to app users, e.g., base stations. A lot of researchers have shifted their attention from cloud computing to edge computing in the last few years.

You et al. [14] propose a suite of optimal and near-optimal approaches for solving the network resource allocation problem in the edge computing environment based on two wireless access protocols, i.e., TDMA and OFDMA. To minimize mobile and IoT devices’ energy consumption and network latency in the multi-channel cloud computing environment, Chen et al. [9] propose a game-theoretic approach—similar to their approach in [5] - that allocates the wireless channels of an edge server across multiple mobile and IoT devices. Neto et al. [18] attempts to improve the energy efficiency for mobile and IoT devices during computation loading through profiling and predicting users‘ task execution times and energy consumption.

Instead of mobile and IoT devices’ energy efficiency, some researchers investigate the energy efficiency of the edge servers from the edge infrastructure provider's perspective. Wang et al. [15] study the computation offloading problem to minimize an individual edge server's energy consumption subject to users’ constraints for computation latency. Chen et al. [10] also devote their efforts to ensuring the energy efficiency for edge servers by proposing an online peer computation offloading framework where edge servers can offload computation tasks to each other. Cost is also an active research topic. Yao et al. [43] adopt the integer linear programming technique to help edge infrastructure providers deploy edge servers in a cost-effective manner. Yin et al. [20] tackle a similar edge server deployment problem, also with the objective to optimize the performance of the edge computing systems and server deployment costs. Wang et al. [12] model the computation offloading problem as a convex problem and then decompose it so that it can be solved in a distributed manner.

Some researchers appeal to physical equipment to improve the performance of the edge computing system. Guo et al. [11] propose a new network architecture named hybrid fiberwireless (FiWi) network that connects edge servers and cloud servers with fibers. To tackle mobile and IoT devices’ energy constraint, Bi et al. [13] leverage the new wireless power transfer technology during computation offloading. Chen et al. [16] assume that users’ devices in the edge computing environment can harvest energy from various resources, such as solar radiation, wind and in-door light. Then, the conventional computation offloading problem is transformed into a green computation offloading problem.

Edge computing inherits the pay-as-you-go pricing model from cloud computing, which allows mobile and IoT app vendors to hire computing capacities on edge servers from edge infrastructure providers to host their apps and to server their app users. Thus, the cost incurred for app vendors is critical to the success of edge computing because, after all, app vendors are the main customers in the edge computing environment. Unfortunately, all the above existing work tackles the computation offloading problem from either the devices’ or the edge infrastructure providers’ perspectives, none from the app vendors’ perspective as to how to cost-effectively serve their users in the edge computing environment. This paper makes the first attempt to model and solve this important and challenging new problem in the edge computing environment from app vendors’ perspective. This new problem is referred to as Edge User Allocation (EUA), which aims to maximize the number of app user served with minimum overall system cost for an app vendor.

SECTION 8Conclusion
In this paper, we proposed EUAGame, a novel game-theoretical approach for solving the Edge User Allocation (EUA) problem from app vendors’ perspective in the edge computing environment. We show that the EUA problem is NP-hard and model it as a potential game in which app users make their own allocation decisions. This way, the EUA problem can be solved in a distributed manner. We prove that the EUA game admits at least one Nash equilibrium and propose a decentralized allocation mechanism to achieve it. Its performance is evaluated both theoretically and experimentally.

This research has established the basic foundation for the EUA problem and opened up many research directions. In our future work, we will first investigate the impacts of app users’ mobility and trajectories on EUAGame. Then, we will consider app users’ dynamic participation in the EUA game, including the arrivals of new app users and the departures of existing app users. We will also improve EUAGame to accommodate app users’ diverse capacities needs and investigate the impact on user experience.