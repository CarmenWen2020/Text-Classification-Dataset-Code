Mobile cloud computing is envisioned as a promising approach to augment computation capabilities of mobile devices for emerging resource-hungry mobile applications. In this paper, we propose a game theoretic approach for achieving efficient computation offloading for mobile cloud computing. We formulate the decentralized computation offloading decision making problem among mobile device users as a decentralized computation offloading game. We analyze the structural property of the game and show that the game always admits a Nash equilibrium. We then design a decentralized computation offloading mechanism that can achieve a Nash equilibrium of the game and quantify its efficiency ratio over the centralized optimal solution. Numerical results demonstrate that the proposed mechanism can achieve efficient computation offloading performance and scale well as the system size increases.

SECTION 1Introduction
As smart-phones are gaining enormous popularity, more and more new mobile applications such as face recognition, natural language processing, interactive gaming, and augmented reality are emerging and attract great attention [1][2]. This kind of mobile applications are typically resource-hungry, demanding intensive computation and high energy consumption. Due to the physical size constraint, however, mobile devices are in general resource-constrained, having limited computation resources and limited battery life. The tension between resource-hungry applications and resource-constrained mobile devices hence poses a significant challenge for the future mobile platform development [3].

Mobile cloud computing is envisioned as a promising approach to address such a challenge. As illustrated in Fig. 1, mobile cloud computing can augment the capabilities of mobile devices for resource-hungry applications, by offloading the computation via wireless access to the resource-rich cloud infrastructure such as Amazon Elastic Compute Cloud (EC2) and Windows Azure Services Platform. In the cloud, each mobile device is associated with a cloud clone, which runs on a virtual machine (VM) that can execute mobile applications on behalf of the mobile device [5][6].


Fig. 1.
An illustration of mobile cloud computing.

Show All

Although the cloud based approach can significantly augment computation capability of mobile device users, the task of developing a comprehensive and reliable mobile cloud computing system remains challenging. A key challenge is how to achieve an efficient computation offloading coordination among mobile device users. One critical factor of affecting the performance of mobile cloud computing is the wireless access efficiency [7]. If too many mobile device users choose to offload the computation to the cloud via wireless access simultaneously, they may generate severe interference to each other, which would reduce the data rates for computation data transmission. This hence can lead to low energy efficiency for computation offloading and long data transmission time. In this case, it would not be beneficial for the mobile device users to offload computation to the cloud.

In this paper, we adopt a game theoretic approach to address such a challenge. Game theory is a useful framework for designing decentralized mechanisms, such that the mobile device users in the system can self-organize into the mutually satisfactory computation offloading decisions. The self-organizing feature can add autonomics into mobile cloud computing system and help to ease the heavy burden of complex centralized management (e.g., information collection from massive mobile device users and computation offloading scheduling) by the cloud. Moreover, as different mobile devices are usually owned by different individuals and they may pursue different interests, game theory is a powerful tool to analyze the interactions among multiple mobile device users who act in their own interests and devise incentive compatible computation offloading mechanisms such that no mobile user has the incentive to deviate unilaterally.

Specifically, we model the decentralized computation offloading decision making problem among mobile device users for mobile cloud computing as a decentralized computation offloading game. We then propose a decentralized computation offloading mechanism that can achieve the Nash equilibrium of the game. The main results and contributions of this paper are as follows:

Decentralized computation offloading game formulation: We formulate the decentralized computation offloading decision making problem among multiple mobile device users as a decentralized computation offloading game, by taking into account both communication and computation aspects of mobile cloud computing.

Analysis of game structure: We analyze the decentralized computation offloading game in both homogenous and heterogeneous wireless access cases. For the homogenous case, we show that the game admits the beneficial cloud computing group structure, which guarantees the existence of Nash equilibrium. For the more general heterogeneous case, we show that the game is a potential game, and hence admits the finite improvement property and possesses a Nash equilibrium.

Decentralized mechanism for achieving nash equilibrium: We devise a decentralized computation offloading mechanism such that mobile device users make decisions locally, which can significantly reduce the controlling and signaling overhead of the cloud. We show that the mechanism can achieve a Nash equilibrium of the decentralized computation offloading game. We further quantify the price of anarchy (PoA), i.e., the efficiency ratio of the mechanism over the centralized optimal solution. Numerical results demonstrate that the proposed mechanism can achieve efficient computation offloading performance and scale well as the system size increases.

The rest of the paper is organized as follows. We first discuss related work in Section 2, and introduce the system model in Section 3. We then propose the decentralized computation offloading game and develop the decentralized computation offloading mechanism in Sections 4 and 5, respectively. We present the numerical results in Section 6 and finally conclude in Section 7.

SECTION 2Related Work
Most previous work has investigated the efficient computation offloading mechanism design from the perspective of a single mobile device user [6][7] [8][9] [10][11][12] [13][14] [15]. Rudenko et al. in [12] demonstrated by experiments that significant energy can be saved by computation offloading. Huertacanepa and Lee in [13] developed an adaptive offloading algorithm based on both the execution history of applications and the current system conditions. Xian et al. in [14] introduced an efficient timeout scheme for computation offloading to increase the energy efficiency on mobile devices. Rahimi et al. in [16] proposed a two-tier cloud architecture to improve both performance and scalability of mobile cloud computing. Huang et al. in [11] proposed a Lyapunov optimization based dynamic offloading algorithm to improve the mobile cloud computing performance while meeting the application execution time. Barbera et al. in [7] showed by realistic measurements that the wireless access plays a key role in affecting the performance of mobile cloud computing. Wolski et al. in [15] proposed a prediction based decision making framework for determining when an offloaded computation will outperform local execution on the mobile device. Wen et al. in [6] presented an efficient offloading policy by jointly configuring the clock frequency in the mobile device and scheduling the data transmission to minimize the energy consumption.

To the best of our knowledge, only a few works have addressed the computation offloading problem under the setting of multiple mobile device users [17][18] [19]. Yang et al. in [17] studied the scenario that multiple users share the wireless network bandwidth, and solved the problem of maximizing the mobile cloud computing performance by a centralized heuristic genetic algorithm. Rahimi et al. in [18] took into consideration user mobility information and proposed a centralized greedy scheme to solve the computation offloading problem with multiple mobile users. Barbarossa et al. in [19] proposed a centralized scheduling algorithm to jointly optimize the communication and computation resource allocations among multiple users with the latency requirements. The centralized computation offloading schemes above requires that all the mobile device users submit their own information (e.g., wireless channel gain and the size of computation tasks) to a centralized entity (e.g., the cloud), which will determine the offloading schedule accordingly. Along a different line, in this paper we adopt the game theoretic approach and devise a decentralized mechanism wherein each mobile device user makes the computation offloading decision locally. This can help to reduce the controlling and signaling overhead of the cloud.

SECTION 3System Model
In this section, we introduce the system model of mobile cloud computing. We consider a set of N={1,2,…,N} collocated mobile device users and each of which has a computationally intensive and delay sensitive task to be completed. There exists a wireless access base-station s , through which the mobile device users can offload the computation to the cloud (e.g., Amazon EC2 or Microsoft Azure). Similar to many previous studies in mobile cloud computing [6] [17][19] and mobile networking [20][21] [22], to enable tractable analysis and get useful insights, we consider a quasi-static scenario where the set of mobile device users N remains unchanged during a computation offloading period (e.g., within several seconds), while may change across different periods. The general case that mobile users may depart and leave dynamically within a computation offloading period will be considered in a future work. Since both the communication and computation aspects play a key role in mobile cloud computing, we next introduce the communication and computation models in details.

3.1 Communication Model
We first introduce the communication model for wireless access. The wireless access base-station s can be either a WiFi access point, or a Femtocell network access point [23], or a macrocell base-station in cellular networks that manages the uplink/downlink communications of mobile device users. We denote an∈{0,1} as the computation offloading decision of mobile device user n. Specifically, we have an=1 if user n chooses to offload the computation to the cloud via wireless access. We have an=0 if user n decides to compute its task locally on the mobile device. Given the decision profile aa=(a1,a2,…,aN) of all the mobile device users, we can compute the uplink data rate for computation offloading of mobile device user n as [24]
Rn(aa)=Wlog2(1+PnHn,sωn+∑m∈N∖{n}:am=1PmHm,s).(1)
View SourceHere W is the channel bandwidth and Pn is user n ’s transmission power which is determined by the wireless access base-station according to some power control algorithms such as [25][26]. Further, Hn,s denotes the channel gain between the mobile device user n and the base-station, and ωn=ω0n+ω1n denotes the background interference power including the noise power ω0n and the interference power ω1n from other mobile device users who carry out wireless transmission but do not involve in the mobile cloud computing.

From the communication model in (1), we see that if too many mobile device users choose to offload the computation via wireless access simultaneously, they may incur severe interference, leading to low data rates. As we discuss latter, this would negatively affect the performance of mobile cloud computing.

3.2 Computation Model
We then introduce the computation model. We consider that each mobile device user n has a computation task In≜(Bn,Dn) that can be computed either locally on the mobile device or remotely on the cloud via computation offloading. Here Bn denotes the size of computation input data (e.g., the program codes and input parameters) involving in the computation task In and Dn denotes the total number of CPU cycles required to accomplish the computation task In. A mobile device user n can apply the methods in [3][5] [17] to obtain the information of Bn and Dn. We next discuss the computation overhead in terms of both energy consumption and processing time for both local and cloud computing approaches.

3.2.1 Local Computing
For the local computing approach, a mobile device user n executes its computation task In locally on the mobile device. Let Fln be the computation capability (i.e., CPU cycles per second) of mobile device user n. Here we allow that different mobile devices may have different computation capability. The computation execution time of the task In by local computing is then given as
Tln=DnFln.(2)
View SourceFor the computational energy, we have that
Eln=νnDn,(3)
View Sourcewhere νn is the coefficient denoting the consumed energy per CPU cycle. According to the realistic measurements in [6][27], we can set νn=10−11(Fln)2.

According to (2) and (3) , we can then compute the overhead of the local computing approach in terms of computational time and energy as
Zln=γTnTln+γEnEln,(4)
View Sourcewhere 0≤γTn,γEn≤1 denote the weights of computational time and energy for mobile device user n’s decision making, respectively. To provide rich modeling flexibility and meet user-specific demands, we allow that different users can choose different weighting parameters in the decision making. For example, when a user is at a low battery state, the user would like to put more weight on energy consumption (i.e., a larger γEn ) in the decision making, in order to save more energy. When a user is running some application that is sensitive to the delay (e.g., video streaming), then the user can put more weight on the processing time (i.e., a larger γTn), in order to reduce the delay. Note that the weights could be dynamic if a user runs different applications or has different policies/demands at different computation offloading periods. For ease of exposition, in this paper we assume that the weights of a user are fixed within one computation offloading period, while can be changed in different periods.

3.2.2 Cloud Computing
For the cloud computing approach, a mobile device user n will offload its computation task In to the cloud and the cloud will execute the computation task on behalf of the mobile device user.

For the computation offloading, a mobile device user n would incur the extra overhead in terms of time and energy for transmitting the computation input data to the cloud via wireless access. According to the communication model in Section 3.1, we can compute the transmission time and energy of mobile device user n for offloading the input data of size Bn as, respectively,
Tcn,off(aa)=BnRn(aa),(5)
View Sourceand
Ecn(aa)=PnBnRn(aa).(6)
View Source

After the offloading, the cloud will execute the computation task In. Let Fcn be the computation capability (i.e., CPU cycles per second) assigned to user n by the cloud. The execution time of the task In of mobile device user n on the cloud can be then given as
Tcn,exe=DnFcn.(7)
View SourceRight-click on figure for MathML and additional features.

According to (5), (6) , and (7), we can compute the overhead of the cloud computing approach in terms of processing time and energy as
Zcn(aa)=γTn(Tcn,off(aa)+Tcn,exe)+γEnEcn(aa).(8)
View SourceRight-click on figure for MathML and additional features.

Similar to many studies such as [10][11] [12][13] [14], we neglect the time overhead for the cloud to send the computation outcome back to the mobile device user, due to the fact that for many applications (e.g., face recognition), the size of the computation outcome in general is much smaller than the size of computation input data including the mobile system settings, program codes and input parameters.

According to the communication and computation models above, we see that the computation offloading decisions aa among the mobile device users are coupled. If too many mobile device users simultaneously choose to offload the computation task to the cloud via wireless access, they may incur severe interference and this would lead to a low data rate. When the data rate Rn(aa) of a mobile device user n is low, it would consume high energy in the wireless access for offloading the computation input data to cloud and incur long transmission time as well. In this case, it would be more beneficial for the user to compute the task locally on the mobile device to avoid the long processing time and high energy consumption by the cloud computing approach. In the following sections, we will adopt a game theoretic approach to address the issue of how to achieve efficient computation offloading decision makings among the mobile device users.

SECTION 4Decentralized Computation Offloading Game
In this section, we develop a game theoretic approach for achieving efficient computation offloading decision makings among the mobile device users. The primary rationale of adopting the game theoretic approach is that the mobile devices are owned by different individuals and they may pursue different interests. Game theory is a powerful framework to analyze the interactions among multiple mobile device users who act in their own interests and devise incentive compatible computation offloading mechanisms such that no user has the incentive to deviate unilaterally. Moreover, by leveraging the intelligence of each individual mobile device user, game theory is a useful tool for devising decentralized mechanisms with low complexity, such that the users can self-organize into a mutually satisfactory solution. This can help to ease the heavy burden of complex centralized management by the cloud and reduce the controlling and signaling overhead between the cloud and mobile device users.

4.1 Game Formulation
We consider the decentralized computation offloading decision making problem among the mobile device users within a computation offloading period. Let a−n=(a1,…, an−1,an+1,…,aN) be computation offloading decisions by all other users except user n. Given other users’ decisions a−n, user n would like to select a proper decision an∈{0,1} (i.e., local computing or cloud computing) to minimize its computation overhead in terms of energy consumption and processing time, i.e.,
minan∈{0,1}Vn(an,a−n),∀n∈N.
View SourceAccording to (4) and (8), we can obtain the overhead function of mobile device user n as
Vn(an,a−n)={Zln,Zcn(a),if an=0,if an=1.(9)
View Source

We then formulate the problem above as a strategic game Γ=(N,{An}n∈N,{Vn}n∈N), where the set of mobile device users N is the set of players, An≜{0,1} is the set of strategies for user n, and the overhead function Vn(an,a−n) of each user n is the cost function to be minimized by player n. In the sequel, we call the game Γ as the decentralized computation offloading game. We now introduce the concept of Nash equilibrium [28].

Definition 1. A strategy profile aa∗=(a∗1,…,a∗N) is a Nash equilibrium of the decentralized computation offloading game if at the equilibrium aa∗, no player can further reduce its overhead by unilaterally changing its strategy, i.e.,
Vn(a∗n,a∗−n)≤Vn(an,a∗−n),∀an∈An,n∈N.(10)
View Source

The Nash equilibrium has the nice self-stability property such that the users at the equilibrium can achieve a mutually satisfactory solution and no user has the incentive to deviate. This property is very important to the decentralized computation offloading problem, since the mobile devices are owned by different individuals and they may act in their own interests.

4.2 Game Property
We then study the existence of Nash equilibrium of the decentralized computation offloading game. To proceed, we first introduce an important concept of best response [28].

Definition 2. Given the strategies a−n of the other players, player n’s strategy a∗n∈An is a best response if
Vn(a∗n,a−n)≤Vn(an,a−n),∀an∈An.(11)
View Source

According to (10) and (11), we see that at the Nash equilibrium all the users play the best response strategies towards each other. Based on the concept of best response, we have the following observation for the decentralized computation offloading game.

Lemma 1. Given the strategies a−n of other mobile device users in the decentralized computation offloading game, the best response of a user n is given as the following threshold strategy:
a∗n={1,0,if∑m∈N∖{n}:am=1PmHm,s≤Ln,otherwise,
View Sourcewhere the threshold
Ln=PnHn,s2(γTn+γEnPn)BnW(γTnTln+γEnEln−γTnTcn,exe)−1−ωn.
View Source

The proof is given in Section 8.1 of the separate supplementary file, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org.ezproxy.auckland.ac.nz/10.1109/TPDS.2014.2316834. According to Lemma 1, we see that when the received interference ∑m∈N∖{n}:am=1PmHm,s is lower enough, it is beneficial for user n to offload the computation to the cloud. Otherwise, the user n should compute the task on the mobile device locally. Since the wireless access plays a critical role in mobile cloud computing, we next discuss the existence of Nash equilibrium of the decentralized computation offloading game in both homogeneous and heterogeneous wireless access cases.

4.2.1 Homogeneous Wireless Access Case
We first consider the case that users’ wireless access is homogenous, i.e., PmHm,s=PnHn,s=K, for any n,m∈N. This can correspond to the scenario that all the mobile device users experience the similar channel condition and are assigned with the same transmission power by the base-station. However, different users may have different thresholds Ln, i.e., they are heterogeneous in terms of computation capabilities and tasks.

For the homogenous wireless access case, without loss of generality, we can order the set N of mobile device users so that L1K≥L2K≥⋯≥LNK. Based on this, we have the following useful observation.

Lemma 2. For the decentralized computation offloading game with homogenous wireless access, if there exists a non-empty beneficial cloud computing group of mobile device users S⊆N such that
|S|≤LiK+1,∀i∈S,(12)
View Sourceand further if S⊂N,
|S|>LjK,∀j∈N∖S,(13)
View SourceRight-click on figure for MathML and additional features.then the strategy profile wherein users i∈S play the strategy ai=1 and the other users j∈N∖S play the strategy aj=0 is a Nash equilibrium.

The proof is given in Section 8.2 of the separate supplementary file, available online. For example, for a set of four users with (L1K,L2K,L3K,L4K)=(5,4,3,2), the beneficial cloud computing group is S={1,2,3}. In general, when L1K≥0, we can construct the beneficial cloud computing group by using Algorithm 1. Thus, we have the following result.

Theorem 1. The decentralized computation offloading game with homogenous wireless access always has a Nash equilibrium. More specifically, when L1K<0, all users n∈N playing the strategy an=0 is a Nash equilibrium. When L1K≥0, we can construct a beneficial cloud computing group S≠∅ by Algorithm 1 such that the strategy profile wherein users i∈S play the strategy ai=1 and the other users j∈N∖S play the strategy aj=0 is a Nash equilibrium.

The proof is given in Section 8.3 of the separate supplementary file, available online. Since the computational complexity of ordering operation (e.g., quicksort algorithm) is typically O(NlogN) and the construction procedure in Algorithm 1 involves at most N operations (with each operation of the complexity of O(1)), the beneficial cloud computing group construction algorithm has a low computational complexity of O(NlogN) . This implies that we can compute the Nash equilibrium of the decentralized computation offloading game in the homogenous wireless access case in a fast manner.

 - 
Show All

4.2.2 General Wireless Access Case
We next consider the general case including the case that users’ wireless access can be heterogeneous, i.e., PmHm,s≠PnHn,s. Since mobile device users may have different transmission power Pn, channel gain Hn,s and thresholds Ln, the analysis based on the beneficial cloud computing group in the homogenous case cannot apply here. We hence resort to a power tool of potential game [29].

Definition 3. A game is called a potential game if it admits a potential function Φ(aa) such that for every n∈N, a−n∈∏i≠nAi, and a′n,an∈An, if
Vn(a′n,a−n)<Vn(an,a−n),(14)
View SourceRight-click on figure for MathML and additional features.we have
Φ(a′n,a−n)<Φ(an,a−n).(15)
View Source

Definition 4. The event where a player n changes to an action a′n from the action an is a better response update if and only if its cost function is decreased, i.e.,
Vn(a′n,a−n)<Vn(an,a−n).(16)
View Source

An appealing property of the potential game is that it admits the finite improvement property, such that any asynchronous better response update process (i.e., no more than one player updates the strategy at any given time) must be finite and leads to a Nash equilibrium [29]. Here the potential function to a game has the same spirit as the Lyapunov function to a dynamical system. If a dynamic system is shown to have a Lyapunov function, then the system has a stable point. Similarly, if a game admits a potential function, the game must have a Nash equilibrium.

We now prove the existence of Nash equilibrium of the general decentralized computation offloading game by showing that the game is a potential game. Specifically, we define the potential function as
Φ(aa)=12∑n=1N∑m≠nPnHn,sPmHm,sI{an=1}I{am=1}+∑n=1NPnHn,sLnI{an=0},(17)
View Sourcewhere I{A} is the indicator function such as I{A}=1 if the event A is true and I{A}=0 otherwise.

Theorem 2. The general decentralized computation offloading game is a potential game with the potential function as given in (17), and hence always has a Nash equilibrium and the finite improvement property.

The proof is given in Section 8.4 of the separate supplementary file, available online. Theorem 2 implies that any asynchronous better response update process is guaranteed to reach a Nash equilibrium within a finite number of iterations. This motivates the algorithm design in following Section 5.

SECTION 5Decentralized Computation Offloading Mechanism
In this section we propose a decentralized computation offloading mechanism in Algorithm 2 for achieving the Nash equilibrium of the decentralized computation offloading game.

 - 
Show All

5.1 Mechanism Design
The motivation of using the decentralized computation offloading mechanism is to coordinate mobile device users to achieve a mutually satisfactory decision making, prior to the computation task execution. The key idea of the mechanism design is to utilize the finite improvement property of the decentralized computation offloading game and let one mobile device user improve its computation offloading decision at a time. Specifically, by using the clock signal from the wireless access base-station for synchronization, we consider a slotted time structure for the computation offloading decision update. Each decision slot t consists the following two parts:

Interference measurement: Each mobile device user n locally measures the received interference μn(t)=∑m∈N∖{n}:am(t)=1PmHm,s generated by other users who currently choose the decisions of offloading the computation tasks to the cloud via wireless access. To facilitate the interference measurement, for example, the users m who choose decisions am(t)=1 at the current slot will transmit some pilot signals to the base-station. And each mobile device user can then enquire its received interference μn(t) from the base-station.

Decision update contention: We exploit the finite improvement property of the game by having one mobile device user carry out a decision update at each decision slot. We let users who can improve their computation performance compete for the decision update opportunity in a decentralized manner. More specifically, according to Lemma 1, each mobile device user n first computes its set of best response update based on the measured interference μn(t) as
Δn(t)≜{a∗n:Vn(a∗n,a−n(t))<Vn(an(t),a−n(t))}=⎧⎩⎨⎪⎪1,0,∅,if an(t)=0 and μn(t)≤Ln,if an(t)=1 and μn(t)>Ln,otherwise.
View SourceThe best response here is similar to the steepest descent direction selection to reduce user’s overhead. Then, if Δn(t)≠∅ (i.e., user n can improve), user n will contend for the decision update opportunity. Otherwise, user n will not contend and adhere to the current decision at next decision slot, i.e., an(t+1)=an(t). For the decision update contention, for example, we can adopt the random backoff-based mechanism by setting the time length of decision update contention as τ∗. Each contending user n first generates a backoff time value τn according to the uniform distribution over [0,τ∗] and countdown until the backoff timer expires. When the timer expires, if the user has not received any request-to-update (RTU) message from other mobile device users yet, the user will update its decision for the next slot as an(t+1)∈Δn(t) and then broadcast a RTU message to all users to indicate that it wins the decision update contention. For other users, on hearing the RTU message, they will not update their decisions and will choose the same decisions at next slot, i.e., an(t+1)=an(t).

According to the finite improvement property in Theorem 2, the mechanism will converge to a Nash equilibrium of the decentralized computation offloading game within finite number of decision slots. In practice, we can implement that the computation offloading decision update process terminates when no RTU messages are broadcasted for multiple consecutive decision slots (i.e., no decision update can be further carried out by any users). Then each mobile device user n executes the computation task according to the decision an obtained at the last decision slot by the mechanism. Due to the property of Nash equilibrium, no user has the incentive to deviate from the achieved decisions. This is very important to the decentralized computation offloading problem, since the mobile devices are owned by different individuals and they may act in their own interests. By following the decentralized computation offloading mechanism, the users adopt the best response to improve their decision makings and eventually self-organize into a mutually satisfactory solution (i.e., Nash equilibrium).

We then analyze the computational complexity of the algorithm. In each iteration, N mobile users will execute the operations in Lines 5-15. Since the operations in Lines 5-15 only involve some basic arithmetical calculations, the computational complexity in each iteration is O(N). Suppose that it takes C iterations for the algorithm to converge. Then the total computational complexity of the algorithm is O(CN). Numerical results in Section 6 show that the number of iterations C for convergence increases linearly with the number of users N. This demonstrates that the decentralized computation offloading mechanism can converge in a fast manner in practice.

5.2 Performance Analysis
We then discuss the efficiency of Nash equilibrium by the decentralized computation offloading mechanism. Note that the decentralized computation offloading game may have multiple Nash equilibria, and the proposed decentralized computation offloading mechanism will randomly select one Nash equilibrium (since a random user is chosen for decision update). Following the definition of PoA in game theory [30], we will quantify the efficiency ratio of the worst-case Nash equilibrium over the centralized optimal solution. Let Υ be the set of Nash equilibria of the decentralized computation offloading game. Then the PoA is defined as
PoA=maxaa∈Υ∑n∈NVn(aa)minaa∈∏Nn=1An∑n∈NVn(aa),
View Sourcewhich is lower bounded by 1. A larger PoA implies that the set of Nash equilibrium is less efficient (in the worst-case sense) using the centralized optimum as a benchmark. Let Zcn¯¯¯¯¯¯=(γTn+γEnPn)BnWlog2(1+PnHn,sωn)+γTnTcn,exe. We can show the following result.

Theorem 3. The PoA of the decentralized computation offloading game is at most
∑Nn=1Zln∑Nn=1min{Zln,Zcn¯¯¯¯¯¯}.
View Source

The proof is given in Section 8.5 of the separate supplementary file, available online. Intuitively, Theorem 3 indicates that when users have lower cost of local computing(i.e., Zln is smaller), the Nash equilibrium is closer to the centralized optimum and hence the PoA is lower. Moreover, when the communication efficiency is higher (i.e., PnHn,s is larger and hence Zcn¯¯¯¯¯¯ is larger), the performance of Nash equilibrium can be improved. Numerical results in Section 6 demonstrate that the Nash equilibrium by the decentralized computation offloading mechanism is efficient, with at most 10percent performance loss, compared with the centralized optimal solution.

SECTION 6Numerical Results
In this section, we evaluate the proposed decentralized computation offloading mechanism by numerical studies. We first consider the mobile cloud computing scenario that N=20 mobile device users are randomly scattered over a 50m×50m region and the wireless access base-station is located in the center of the region. For the wireless access, we set the channel bandwidth W=5 MHz, the transmission power Pn=100 mWatts, and the background noise ωn=−100 dBm. According to the physical interference model [24], we set the channel gain Hn,s=d−αn,s, where dn,s is the distance between mobile device user n and the cloudlet and α=4 is the path loss factor. We set the decision weights γTn=γEn=0.5. For the computation task, we use the face recognition application in [1], where the data size for the computation offloading Bn=420 KB and the total number of CPU cycles Dn=1,000 Megacycles. The CPU computational capability Fln of a mobile device user n is randomly assigned from the set {0.5,0.8,1.0} GHz and the computational capability on the cloud Fcn=100 GHz [1].

We first show the dynamics of mobile device users’ computation cost Vn(aa) by the proposed decentralized computation offloading mechanism in Fig. 2. We see that the mechanism can keep mobile users’ cost decreasing and converge to an equilibrium. To verify that the convergent equilibrium is a Nash equilibrium, we further show the dynamics of the potential function value Φ(aa) of the decentralized computation offloading game in Fig. 3. It demonstrates that the proposed decentralized computation offloading mechanism can lead the potential function of the game to the minimum point, which is a Nash equilibrium according to the property of potential game.


Fig. 2.
Dynamics of user cost by the decentralized computation offloading mechanism.

Show All


Fig. 3.
Dynamics of potential function by the decentralized computation offloading mechanism.

Show All

To investigate the impact of computation size on decentralized computation offloading, we then implement the simulations with different number of CPU processing cycles Dn required for completing the computing task. Upon comparison, we also implement the local mobile computing solution such that all the mobile device users compute their tasks locally on the mobile devices. The results are shown in Fig. 4. We see that the system-wide computing cost ∑n∈NVn(aa) by decentralized computation offloading and local mobile computing solutions increases as the number of CPU processing cycles Dn increases. However, the system-wide computing cost ∑n∈NVn(aa) by decentralized computation offloading increases much slower than that of local mobile computing. This is because that as the number of CPU processing cycles Dn increases, more mobile device users choose to utilize the cloud computing via computation offloading to mitigate the heavy cost of local computing.


Fig. 4.
System-wide computing cost with different number of CPU processing cycles.

Show All

To evaluate the impact of communication data size on the decentralized computation offloading, we next implement the simulations with different data size for computation offloading Bn in Fig. 5. We observe that the system-wide computing cost ∑n∈NVn(aa) by decentralized computation offloading as the data size for computation offloading Bn increases, due to the fact that a larger data size requires higher overhead for computation offloading via wireless communication. Moreover, we see that the system-wide computing cost ∑n∈NVn(aa) by decentralized computation offloading increases slowly when the data size for computation offloading Bn is large. This is because that the data size for computation offloading Bn is large, more mobile device users choose to compute the tasks locally on the mobile devices, in order to avoid the heavy cost of computation offloading via wireless access.

Fig. 5. - System-wide computing cost with different data size for the computation offloading.
Fig. 5.
System-wide computing cost with different data size for the computation offloading.

Show All

To benchmark the performance of the decentralized computation offloading mechanism, we further implement the system-wide computing cost minimization solution by centralized optimization, i.e., maxaa∑n∈NVn(aa). Notice that the centralized optimization solution requires the complete information of all mobile device users, such as the details of computing tasks, the transmission power, the channel gain, and the CPU frequency of all mobile devices. While the decentralized computation offloading mechanism only requires each mobile device user to measure its received interference and make the decision locally. We run experiments with the number of N=10,15,…,50 mobile device users being randomly scattered over the square area, respectively. We repeat each experiment 100 times and show the average system-wide computing cost in Fig. 6. We see that the system-wide computing cost by all the computation offloading solutions increases as the number of mobile device users N increases. The proposed incentive compatible computation offloading solution can reduce up-to 33 and 38 percent computing cost over the solutions of all the users choosing the local computing and choosing the cloud computing, respectively. Compared with the centralized optimization solution, the performance loss of the decentralized computation offloading mechanism is less than 10 percent in all cases. This demonstrates the efficiency of the proposed decentralized computation offloading mechanism. We next evaluate the convergence time of the decentralized computation offloading mechanism. Fig. 7 shows that the average convergence time increases linearly with the number of mobile device users N. This shows that the decentralized computation offloading mechanism scales well with the size of mobile device users. This is critical since computing the centralized optimal computation offloading solution involves solving the integer programming problem (i.e., the decision variables an∈{0,1}) and the computational complexity grows exponentially as the number of mobile device users N increases.


Fig. 6.
Average system-wide computing cost.

Show All


Fig. 7.
Number of iterations by decentralized computation offloading mechanism.

Show All

To evaluate the controlling and signaling overhead reduction by the decentralized computation offloading mechanism, we further show the number of controlling and signaling messages exchanged among the mobile users and between the users and the cloud in Fig. 8. It demonstrates that the decentralized computation offloading mechanism can reduce the number of controlling and signaling messages by at least 89 percent over the centralized optimal computation offloading scheme in all cases. This is because that for the decentralized computation offloading mechanism, a mobile user would exchange messages (for interference measurement and decision update announcement) only when it updates its computation decision. While for the centralized optimal computation offloading scheme, each mobile user needs to report all its local parameters to the cloud, including the transmission power, the channel gain, the background interference power, the local computation capability, and many other parameters. Moreover, in some application scenarios, due to privacy concerns some mobile users may be sensitive to the revealing of their local parameters and hence do not have the incentive to participate in the centralized optimal computation offloading scheme. While the decentralized computation offloading mechanism does not have this issue since each mobile user can make the computation offloading decision locally without exposing its local parameters.


Fig. 8.
Number of controlling and signaling messages by the centralized optimal and decentralized computation offloading mechanisms.

Show All

SECTION 7Conclusion
In this paper, we consider the computation offloading decision making problem among mobile device users for mobile cloud computing and propose as a decentralized computation offloading game formulation. We show that the game always admits a Nash equilibrium for both cases of homogenous and heterogenous wireless access. We also design a decentralized computation offloading mechanism that can achieve a Nash equilibrium of the game and further quantify its PoA. Numerical results demonstrate that the proposed mechanism is efficient and scales well as the system size increases.

For the future work, we are going to consider the more general case that mobile users may depart and leave dynamically within a computation offloading period. In this case, the user mobility patterns might play an important role in the problem formulation.