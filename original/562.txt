Abstract
Finding influential members in social networks received a lot of interest in recent literature. Several algorithms have been proposed that provide techniques for extracting a set of the most influential people in a certain social network. However, most of these algorithms find influential nodes based solely on the topological structure of the network. In this paper, a new algorithm, namely NodeRank, is proposed that ranks every user in a given social network based on the topological structure as well as the interests of the users (nodes). Higher ranks are given to people with great influence on other members of the network. Furthermore, the paper investigates a MapReduce version of the algorithm that enables the algorithm to run on multiple machines simultaneously. Experiments showed that the MapReduce model is not suitable for the NodeRank algorithm since MapReduce is only applicable for batch processes and the NodeRank is highly iterative. For that reason, a parallel version of the algorithm is proposed that utilizes Hadoop Spark, a framework for parallel processes that supports batch operations as well as iterative and recursive algorithms. Several experiments have been carried out to test the accuracy as well as the scalability of the algorithm.

Introduction
Nowadays, social network sites are playing a great role in our daily lives. Be it an individual or a company, one cannot deny the importance of these sites as they help people to communicate easily regardless of their geographical locations. For companies and businesses, social networks are considered one of the top if not the best medium to market their goods and products, conduct customer analysis, identify the state of the market, etc.

Due to this huge importance, social networks gained a lot of interest in the literature. Several papers proposed many techniques that help analyze social networks. Social network sites have billions of users that together form a massive amount of data, which makes extracting useful information out of it very difficult. The purpose of these techniques is to provide a reliable way to analyze this huge data (Said et al. [1]).

One of the beneficial information one can get from such networks is identifying the most influential members. In other words, amongst all the users in a social network, which ones have a great effect on other people in the network to the point that they make them take actions toward a certain situation.

Knowing influential members in a network has very important applications in real life (Zhao et al. [2]). For example, assume that a company has a new product and plans to start a marketing campaign on a certain social network site. The company wants to choose a certain group of people that have the potential to spread their product to other members in the network. The selection of this set of people is very critical as choosing the wrong group might render the whole marketing campaign to fail. Therefore, the company should choose a highly influential set of people to ensure that their product will continue to spread among other users.

Finding influential users with different ranks (i.e. influential power on others) can work better for a company to have more flexibility in selecting influential people for its marketing campaign. That is, if an algorithm finds only the top k influential people and most of them refuse to cooperate, or asking for a very high unaffordable price, the company’s marketing campaign might be stopped altogether. Therefore, the proposed algorithm allows for more opportunities to find other influential users since it sorts the nodes of the social network according to their influence. This way the company may select, for example, users with mid-level influential rank to lead the marketing campaign, if that is more appropriate for their requirements.

Many algorithms have been devised to identify influential people in social networks (Al-Garadi et al. [3]). The majority of these algorithms relied on the topological structure of the network, i.e. friendships and relations between users; in order to find such information. While depending solely on the topological structure of the network may give somewhat good results, one cannot ignore the interests of the users when looking for influential users. That is, the fact that two people are friends with each other does not mean that they can influence one another since their interests may be different. An interest of a user (node) is the set of its attributes and skills, such as basketball, politics, traveling, hiking, reading, and movies. Such interest of a user is extracted form a user’s profile in a social network. Some work has been done in the area of finding influencers while taking their interests into consideration. The issue with these studies is that when they account for the interests, they look for an exact match between the interests or their frequencies rather than their actual semantic meaning. That is two words can have the same semantic meaning even if they are spelled differently. Moreover, existing research works have not utilized the social communities to identify influential people or maximize influence in the network (Khomami et al. [4])

The contribution of this work is to propose an algorithm, namely NodeRank; that, given any social network; ranks all the users inside it based on their influence on other users. The algorithm ranks these users based on the topological structure of the network as well as the semantic meaning of their interests.

Since social networks are considerably huge in terms of numbers of users and their relationships, algorithms should be able to process these social networks in a reasonable amount of time. So, this work also proposes a parallel version of the ranking algorithm, namely NodeRankParallel, using Hadoop Spark (Zaharia et al. [5]); a processing engine that helps highly computational algorithms run on multiple machines for faster execution.

The rest of the paper is organized as follows. Sect. 2 surveys the works on the area of finding influential users. Section 3 presents some definitions that are helpful in formulating the algorithm. In Sect. 4, the NodeRank algorithm is introduced. The parallel version of the algorithm is presented in Sect. 5. Experimental results are shown in Sect. 6. Lastly, we conclude the paper in Sect. 7.

Literature review
Aldrich [6] argues that influence no longer resides exclusively in institutions, or large corporations, but it is also located in the networks that structure communities. Therefore, social networks improve disaster recovery for communities. The work in Al Aghbari et al. [7] proposed a method that discovers online communities based on nodes topology and their interests. Huang and Liu [8] argue that online social capital had a positive impact on job performance and job satisfaction. The study supports the idea that the use of social networks can bring a positive impact on important organizational processes and employee outcomes.

When Richardson and Domingos [9] first published their work on mining knowledge-sharing sites for viral marketing, they raised much interest in information diffusion on social networks—namely, the maximization of information diffusion. Using data on a social network, with estimates for the extent to which individuals can influence one another, they introduced the problem of how to initially target a few influential members of the network—with conventional viral marketing methods, such as giving out free samples of the product—in order to trigger a cascade of influence by which friends will recommend the product to other friends, and many individuals will ultimately try it. Kempe et al. [10] provided potential solutions to this problem that were tested on the two most popular information diffusion models: the Linear Threshold model and the Independent Cascade model. The two models assume that the graph of the underlying network is static, and do not work with dynamic networks. Both models are described by Shakarian et al. [11].

The work done by Kempe et al. [10] was also amongst the first to handle the problem of information diffusion maximization on social networks, and the application of their algorithm on the Linear Threshold Model instigated the work done by Narayanam and Narahari [12], whose goal was to approximate the minimum initial target set for the Linear Threshold model using the game-theoretic Shapley value. Papapetrou et al. [13] employ the same concept in their methods to solve the problem of attributing influence to a set of individuals who participate in a set of tasks. On the other hand, Chen et al. [14] improved previously proposed algorithms to achieve better running time and proposed a degree discount heuristic. Another method by Ben et al. [15] involved an acceptable worst-case solution of the maximization problem: The case where the given social network is a tree and thus has a polynomial-time solution. Both of the works of Chen [16] and Singer [17] consider another form of the maximization problem—the -coverage problem. That is to find a subset S of influential nodes having minimal size such that this subset would influence at least  of the network.

While the Information Diffusion Maximization problem is alternatively known as the Influence Maximization problem, the solution to that problem is to find the alleged target set of most influential nodes, different definitions of influence have recently emerged in the literature changing the traditional outlook on detection of influential nodes in a social network.

Khorasgani et al. [18] proposed a top leader detection method based on the structure of communities. Their work considers a community as a set of followers congregating around a potential leader, and thus their proposed algorithm involves community detection through identification of leaders. (Husseini et al. 19) proposed an ant-based label propagation algorithm to detect communities on social networks. To detect communities on social networks without specifying number of communities, (Li et al. [20]) used block diagonal dominance technique, which starts by reordering the nodes of the graph.

Another definition of influence was proposed by Goyal et al. [21], which is used to discover leaders in online social network communities. Their definition of influence is based on observations of the propagation of actions amongst users in a time window. Similarly, the work by Agarwal et al. [22] identifies influential bloggers in a community by utilizing metadata such as: in links, out links, blog post length, and comments.

Their work differs from that of Ilyas and Radha [23] who have proposed the ranking of influential nodes using principal component centrality. They have also previously introduced a KLT-inspired node centrality heuristic for identifying influential neighborhoods in graphs (Ilyas and Radha [24]). These methods instead of merely identify influential nodes, they rank users in the social network according to some given measures. Users that are ranked highest are considered the most influential. In a similar method, Zareie et al. [25] proposed two algorithms that ranks the influence of network users based on their neighbors diversity measures. They describe a user influence based on the user’s number of neighbors (friends) and the structure of the neighbors in the network.

The proposed ranking algorithms by Cha et al. [26] do not depend on centrality. In their work, they measured user influence on Twitter. They concede that a node with a higher degree does not necessitate the identification of an influential node—calling it the “Million follower fallacy” and discuss the downside of ranking users according to their number of friends.

Some methods used in defining influence do so by using other social concepts. Romero et al. [27], devised a general model for influence using the concept of passivity in a social network. They developed an efficient algorithm to quantify the influence of all the users in the network. They proposed that the influence of a user thus depends on not only the size of the influenced audience but also on their passivity and argue that it should be taken into consideration when ranking users. Another method that uses the same approach is by Aral [28], where the authors ranked the influence and susceptibility of individuals on the social network, challenging the notion that influence is based on the characteristics of influential nodes exclusively.

Fang et al. [29] model the interests of users using a hypergraph, which is built based on the users’ interactions with the posted images by other users. That is two users are connected with a hyperedge if one user comments or favorites the images posted by the other user. The hypergraph is used to rank nodes in order to find the influential user in a certain topic. Amato et al. [30] used a very similar method too. However, hypergraphs suffer from high computational complexity that is proportional to the number of vertices and the difficulty of assigning weights for the different modalities. These challenges prevent the hypergraph method from achieving high accuracies. Additionally, relying on the interactions with images to build interests may not result in accurate interests. For example, a user may negatively comment on an image; however, a hypergraph would consider this interaction as an interest in the topic.

Definitions and assumptions
A social network can be represented by a graph G that consists of a set of nodes, N, and a set of edges, E. Each node in the graph represents a user in a real-world social network, whereas each edge between two nodes represents a friendship/relationship between the corresponding users. Generally, in social network, each node can be assigned to a list of tags that constitutes the set of interests for the users in the social network.

Definition 1
In social networks, an influential node is a node that is able to induce its neighborhood nodes (users) to make critical decisions.

For example, if node A can persuade node B to buy a certain product or to make critical decisions, then it is said that node A has an influence on node B.

Axiom 1
For a node to have a positive influence on another node, they should: 1) be directly connected, since people trust their friends more than non-friends and 2) share common interests between them.

Definition 2
Two nodes share common interests if they share similar node characteristics derived from demographical, social and cultural attributes of users.

Let nodes n and m be friends in a social network, the influencing power of node n over m or the probability for node n to influence node m (
) depends on the number of common interests between the two nodes. Moreover, the influence of one node, say n, on the other, say m, depends on the common interests between the other node m and its friends. In other words, the influence of node n on its friend m increases as the common interests between node m and its friends decreases. The intuition behind this comes from the fact that since node m does not have any other friends with common interests but node n, node n becomes the only influencer on node m which in turn increases the influence value.

Definition 3
A node is said to be an influential node if it has more directional effect on the nodes in the network as compared to the rest of the nodes.

Axiom 2
For a number of nodes in a network, an influential node satisfies the following: (1) has a relatively large number of friends compared to the other nodes, (2) have a relatively high influence on its friends and 3) have a relatively higher propagation of influence.

Note that, the directional effect is considered as effects within existing common interests, and not effects that modify the set of interests.

Said differently, given two nodes n and q that are not necessarily friends but connected via multiple links, the propagated influence from node n to node q can be considered as the probability of node n influencing node q (
).

Having a large number of friends gives higher probability that the node is very influential in the network. Recall that for a node to have an influence on another one they should first have a relationship between them, so it is only logical that having many friends makes the node more influential as it now has the chance to influence more nodes. Note that a node is considered an influential node if its number of friends is relatively large as compared to other nodes

Definition 4
Propagation of Influence is broadcasting the influence of a node beyond its friends to other nodes in the network. That is, the directional effect of node v to other nodes  in a network, such that, there exists a path from v to all . A higher influence of a node on its friends yields a higher propagation of influence from the node.

A node that has many friends is not necessarily an influential node. For it to be influential it should have a high influence value on its friends. That is, the node in question should share many common interests with its friends. Also, the node should have the ability to propagate its influence to the friends of the friends. In other words, the node should influence a large number of nodes in the networks and not just its immediate friends.

Definition 5
The problem of finding influential nodes is defined as the problem of searching the social networks for the nodes that hold a substantial influence on the rest of the nodes in the whole network.

Note that the proposed NodeRank algorithm ranks nodes based on (1) the similarity of interests of a node to other nodes, and (2) the topology structure (connection of a node to other nodes). The interests of nodes can be extracted from any social network (Facebook, Twitter, etc.). However, the network structure may differ from one social network to another. For example, the ‘friend’ feature in Facebook is considered a bidirectional link between any two nodes involved in a friendship; however, the ‘like’ feature is unidirectional. On the other hand, Twitter’s ‘follow’ feature is unidirectional. In our experiments, we assumed bidirectional links (Facebook ‘friend’ feature). However, the proposed NodeRank algorithm can easily be adapted to incorporate unidirectional links.

NodeRank algorithm
The paper proposes an algorithm, namely NodeRank, to solve the problem of finding influential nodes described in the previous section. This is achieved by assigning a rank to each node in the network, which describes the influence of that particular node on the other nodes.

The basic idea
NodeRank takes the social network graph as an input and determines the most influential nodes. For each node, NodeRank assigns a rank to it that indicates how much it is influencing the other nodes. The rank given to each node is dependent on three main factors: (1) the degree of the node (the degree of a node is equal to the number of friends it has), (2) the value of node’s influence on its friends and (3) the value of the friends’ influences on their friends.

For example, the graphs in Fig. 1, node a in Fig. 1a has seven friends (nodes b through i), whereas in Fig. 1b, node a has only three friends (nodes b through d). Node a in Fig. 1a has access to more nodes than that in Fig. 1b and therefore it has a higher chance of influencing more nodes. In other words, node a in Fig. 1a would have a higher rank because it has a higher degree.

Another determining factor for the rank of the node is how well it influences its friends. The graphs in Fig. 2 show node a in two different positions, but in both of them the node has a degree equals to two. Node a in Fig. 2a shares common interests with its friends. On the contrary, node a in Fig. 2b has no common interests with its friends, which reduces its influence compared to the previous scenario and hence leads to a lower rank. Furthermore, the friends of node a in Fig. 2a also share common interests with their friends which helps propagating the influence of node a. For example, in Fig. 2a, node c, which is a direct friend of node a, has two interests {food and tech.} and both of its fiends, which are node g and node h, have interests that are common with the {tech} interest of node c. Similarly, node b in 2.a, which is a direct friend of node a, has two interests {cars and photography} and its friend (node d) has a similar interest, which is {photography}. Due to this similarity between the interests of the friends and friends of friends, the propagation of influence of node a to the network would have higher probability. That is not the case in Fig. 2b in which the friends of a do not share common interests with their friends. Because of the above two reasons node a in Fig. 2a would have a higher rank than that in Fig. 2b.

Fig. 1
figure 1
The node rank for node a in a is higher than a in b since its degree is higher

Full size image

Fig. 2
figure 2
The node rank for node a in a is higher than a in b since it has friends that are more influential

Full size image

Detailed description
Before formulating the ranking equation, a formula is needed to calculate the similarity of interests between two nodes. In other words, given two nodes with their interests, the formula should answer the following question: how similar these two nodes are in terms of their interests? In this work, the WordNet ontology (Miller [31]) is used to obtain the ancestors of a certain word as well as the information content of that word. To measure the similarity between two interests, we use the Lin’s similarity formula (Lin [32]) shown in Eq. (1),


 
 

(1)

where 
 is the similarity between interest 1 and interest 2 bound between zero and one, 
 is a set of all common ancestors between the two interests and 
 is the information content in the word. Equation (1) gives a score that indicates whether the two interests are close or not. When the score is one, the two interests are very close to each other. For example, to find the similarity between Wagon and Car concepts, WordNet is used. WordNet taxonomy is represented as a graph, where each node represents a unique concept (or synset) in the taxonomy. Therefore, Lin similarity is a measure of how close two concepts (say, Wagon and Car) are in the graph. This is calculated by the finding the shortest path between these two concepts and their common ancestor, which would be Wheeled Vehicle.

In a social network, a single node can have a set of interests, I. Equation (1) gives a score between two individual nodes interests. To obtain the score between two sets of interests, we use Eq. (2).


 
  
 
 

(2)

Where 
 is the similarity between the two sets of interests, 
 and 
. 
 and 
 are the number of interests in set 
 and set 
, respectively.

For a given node v and the set of its friends F, the summation of all similarities between node v and node  is given by:

In NodeRank, the influence of one node on another node is considered as a probability. That is the influence of v on  is considered as the probability of node v influencing node f. Moreover, since it is probability, the summation of influences by friend nodes on the node should equal to 1. To obtain this probability, the following equation is used:


 
 

(4)

Where w is a weighting factor that keeps the probability between zero and one and can be calculated using Eq. (5).


 
 
 
 

(5)

Given two nodes v and r that are not direct friends, to calculate the propagated influence from v to r, the shortest path should be found between these two nodes. The weights of each edge are the probabilities calculated using Eq. (4). For any two nodes, the probability of the first node to influence the second one is not the same as the probability of the second node influencing the first. Because of this, the graph becomes directed since each edge has two weights one for each direction.

Once the path is calculated, obtaining the propagated influence is achieved by using Eq. (6).


 
 

(6)

Where L is the list of nodes that construct the shortest path from v to r.

Finally, to get the rank of node v, the propagated influence from node v to all nodes in the network is calculated and then averaged. In other words:

Where NR(v) is the node rank of node v. From Eq. (7), the rank of the node represents the average probability of that node affecting any other node in the network. Note that the concept of friendship and whether it is a direct friend or friend of a friend, can be considered a realization of credibility to some extent. That is direct relationships (friends) are more credible and thus result in more influence than indirect relationships (friends of friends).

The set of nodes that have the highest ranks is considered as the set of influential nodes in that network. Algorithm 1 lists the steps followed by NodeRank.

figure a
As shown in algorithm 1, NodeRank takes a graph representation of the social network as an input. In lines 2 to 11, the two nodes that belong to each edge in the input graph are read, the influence is calculated for each node on its corresponding node using Eq. (4), and the influence is represented by a directed edge from the influencing node to the corresponding node with weight equals the influence. Finally, the edge is removed from the original input graph. In line 12, the influence of each node on the rest of the nodes is calculated using Eq. (6). In lines 13 and 14, the rank of each node is calculated using Eq. (7).

NodeRankParallel algorithm
As stated earlier, the number of nodes in social networks these days is so large that it can easily reach to millions and in some cases billions. Analyzing such huge number of nodes cannot be carried out on a single machine. The other option is to divide the job between multiple machines so that the results are produced quicker. For this reason, the NodeRankParallel is proposed, a parallel version of the NodeRank algorithm that can utilize a cluster of machines to produce results faster.

In this work, the NodeRankParallel has two approaches, a NodeRankParallel that utilizes MapReduce programming model, and another version of the algorithm that uses Hadoop Spark.

MapReduce (Dean and Ghemawat [33]) is a programming paradigm developed by Google in 2004, which enables applications utilizing this pattern to run on multiple machines. A MapReduce-based algorithm consists of two main steps, namely map and reduce. In the map step, data are filtered and sorted, whereas aggregate operations such as finding minimum value or counting are done in the reduce step. A MapReduce system, such as Hadoop, is a group of computers connected in a master-slave setup. Master machines manage the distribution of data across slaves, the resource allocation for processes, and the parallel execution of the application. Slave machines hold data, typically in Terabytes, and execute the actual application on the data it has. MapReduce system also supports data redundancy and fault tolerance. It is worth noting that MapReduce system is only beneficial when dealing with huge volumes of data. So, if an application with relatively small data size were to run on a MapReduce system, it would take more time to finish than running it on a typical computer. This is due to the fact that MapReduce systems have communication overhead as well as disk read and write overhead. In other words, MapReduce systems are very suitable for situations where the processing time is much larger than the communication and disk read/write time.

MapReduce algorithms, as the name suggests, are divided into two subroutines: map and reduce. The role of the map function is to map different keys into values. These key-value pairs are then grouped by their keys and sent to the reduce function. The reduce function takes the list of values associated with the key and perform some processing to get a result for that particular key. While this model has proven to be very effective for batch processing, it has a clear disadvantage when it comes to iterative algorithms. MapReduce relies on storing intermediate results in the hard drive. The output of the map and reduce functions are written to the hard drive and are not maintained in the system memory. Implementing an iterative algorithm on MapReduce would most probably require calling the map and reduce functions several times leading to excessive IO operations and hence lower execution speeds.

Spark (Zaharia et al. [5]), on the other hand, is a framework that helps algorithms run on a cluster of machines 100 times faster than MapReduce for in-memory processes and 10 times faster for hard drive processes, regardless whether the algorithm requires iterative or batch processing. Spark is able to achieve this huge improvement through what is called Resilient Distributed Data-Structure (RDD). RDDs are immutable collections of objects that are partitioned and distributed across the cluster. These RDDs can be created either from files in the hard drive or from other RDDs. RDDs are fault tolerant, meaning they can generate themselves in the case of data loss or corruption.

As stated earlier, two versions of the NodeRanksParallel algorithm are proposed using MapReduce and Spark

Fig. 3
figure 3
The block diagram for the NodeRankParallel algorithm using MapReduce

Full size image

NodeRankParallel with MapReduce
The NodeRankParallel consists of four stages: Similarities Calculation, Friend-to-Friend Influences Calculation, All-Pairs Influences Calculation and Node Ranks Calculation, as shown in Fig. 3. Each one of these stages is a MapReduce job, meaning that each one has its own map and reduce phases.

(1)
Similarity calculation stage

The input to the NodeRankParallel is the graph G that consists of the sets of nodes, edges, and interests. The similarities calculation stage labels every edge in the network by the similarity of its endpoint nodes. Figure 4 shows the block diagram for the similarities calculation stage. Each mapper of this stage receives a line as input that holds the node ID as well as its interests and the IDs of its friends. The mapper then outputs the node ID as well as its interests. It also generates entries for every friend the node has. Each entry contains the friend ID as the key and the node ID with its interests as the value. As for the reducer in this stage, it takes sets of entries for every node. One of these entries holds the interests of the node itself and the rest have the interests of its friends. The reducer uses this data to calculate the similarities between the node and its friends. When the similarities are obtained, the reducer generates a pair with the node ID as the key and a list of node-similarity tuples as the value.

Fig. 4
figure 4
Stage 1 of the NodeRankParallel MapReduce version. This stage outputs each node with the similarities between the node and its friends

Full size image

(2)
Friend-to-friend influence calculation stage

The second stage, Fig. 5, is responsible for calculating the influence of each node on every friend it has; in other words, it calculates all possible values of 
 in Table 1. The mapper in this stage receives the output of the reducer from the previous stage. Recall that each key-value tuple has the node ID as the key and the list of friends as well as their similarities as the value. This is all the data the mapper needs to calculate the influence of every friend on the node. After the influence calculation, the mapper emits an entry for each friend the node has. Each entry has the friend ID as the key and the influence of the friend over the node with the node ID as the value. The reducer in this stage prepares the output of the mapper for the next stage. It takes each entry and replicates it N times where N is the number of nodes in the network. For every time it replicates, the entry gets appended with the ID of a different node.

Fig. 5
figure 5
Stage 2 of the NodeRankParallel MapReduce version. Each entry of the output in this stage consists of a node and its influence on one of its friend

Full size image

Table 1 Table of symbols
Full size table

(3)
All-pairs influence calculation stage

In the all-pairs influence calculation stage, Fig. 6, the influence of each node on every node is calculated. To achieve this, all-pairs shortest paths should be calculated taking the influences as the weight of the link. The cost of the path in this scenario is determined by taking the links forming the path and multiplying their weights. The best path is the one with the highest multiplication result. In this work, the Dijkstra algorithm is used to calculate the distances. Because of that, this stage is iterative, since Dijkstra visits a subset of nodes in each iteration. This iterative step is shown in Fig. 3 as a feedback loop on this stage (stage 3). The loop is terminated once all nodes have been visited. The mapper of this stage receives the node ID as well as its friends and its influence on them. It also receives another node ID. This other node represents the source of the path to be found and the first node ID is the destination. The mapper then calculates the cost of the path so far using the node friends as the next hop and emits the results. The reducer, on the other hand, picks up the best one out of them.

Fig. 6
figure 6
Stage 3 of the NodeRankParallel MapReduce version. The output lists each node and its influence on every node in the graph

Full size image

(4)
Node ranks calculation

The final stage computes the rank of all the nodes in the graph. Figure 7 shows the block diagram for this stage. For each node, its influences on the rest of the nodes, obtained from the previous stage, are averaged and assigned as the rank for that node. The mapper takes as an input a list, each entry in the list consists of a node-pair and a number. The first node in the pair is the influencer node ID and the second node is the influenced node ID, whereas the number represents the value of the influence. The job of the mapper is to output a new key-value pair in which the key is the influencer node ID and the value is the influence. The reducer receives a list of influences for each particular node. The reducer averages influence values to get the rank of the node. Once the rank is computed, the reducer outputs the node ID along with its rank.

Fig. 7
figure 7
Stage 4 of the NodeRankParallel MapReduce version. The output of this stage is a list of all nodes and their ranks

Full size image

NodeRankParallel with spark
The NodeRankParallel takes as input two lists: a list of all the nodes in the graph and another list for all the edges. Each entry in the list consists of the node ID and a set of its interests. The list of edges consists of entries each representing the end points nodes IDs. Algorithm 2 summarizes the NodeRankParallel using Spark.

In line 2, an RDD is created by reading the file containing the nodes list. Each line in the file is read and mapped to a pair of node ID and an array of its interests.

Line 3 reads the edges list from the edges file and generates an RDD. This RDD consists of tuples of two numbers that represent the node IDs forming the edge.

Line 4 joins the nodes and edges RDD by the node IDs to get the interests of each endpoint in the edges RDD. This step is very important to calculate the influence of a certain relation between the nodes.

Line 5 finds the influence of each node on the other. Each entry in the edgesWithInterests consists of the two nodes forming the edge as well as their interests. Equations (4) and (5) are used to get the influence of each node on its friends.

Line 6 creates a graph using nodesRDD and edgesWithInfluence taking the influence calculated from the previous step as the weights of the edges.

In line 7, the influence of each node over the rest of the nodes in the graph is calculated. Recall that calculating the influence of a source node on any destination node requires finding a path between the two nodes. In case multiple paths are found, the weight of each path is computed and the one with the maximum weight is taken. The weight of the path can be obtained by multiplying the weights of its edges. Basically, this is a shortest-path problem with two differences: 1) the weight of the path is obtained by multiplying the weights of its edges and 2) the path with the maximum weight is taken. In this work, the Distributed-Block Floyd Warshall algorithm proposed by Zheng ([34]) is used to obtain the all-pairs-shortest-paths. This algorithm is designed for Spark, given a graph  with n vertices, it calculates  matrix of distances S, where 
 is the weight of the shortest path from i to j. The result of this step is an adjacency matrix with the desired influences.

In line 8, the rank of the node is calculated by averaging each row of the adjacency matrix as in Eq. (7).

figure b
Fig. 8
figure 8
The effect of increasing the size of the graph on the ranks of the nodes

Full size image

Typically, working with social network graphs is memory-bound as the available memory impacts the performance. At the same time, computing influential nodes in a social network graph requires a lot computation and thus it is CPU-time as well. Therefore, the proposed NodeRank algorithms employ Big Data platforms (i.e. MapReduce and Spark) to overcome these issues.

Analysis and experiments
Several experiments have been carried out to test the accuracy of the NodeRank and the scalability of the NodeRankParallel. This section starts by showing the results for the accuracy tests and later shows the results for the scalability experiments.

Testing environment
The tests in this work are carried out using a four-node cluster. Each workstation has 22GB of system memory. Three of these machines are powered by an Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz, whereas the last workstation is powered by an Intel(R) Xeon(R) CPU E5-2603 v3 @ 1.60GHz. Apache Hadoop version 2.7 is used while testing the MapReduce version of the NodeRankParallel. Each mapper and reducer is given a 1GB of memory and a single core. For the Spark version of the algorithm, Apache Spark 2.1 is used. A single Spark worker is created on each workstation.

NodeRank accuracy analysis
The first experiment tests how can the rank of a node be affected by the degrees of its friends. For this test, the similarity of interests between all connected nodes is set to be equal to simplify the analysis. This experimental analysis was performed by both MapReduce and Spark implementations and both yielded similar results. Figure 8 shows the results of the first experiment.

From Fig. 8a, node 1 has the highest rank since it is affecting more friends than any other node in the graph (from axiom 2). The second reason behind its high rank is that it is influencing nodes that have one or no friends at all, so it has a great effect on them (Definition 3). Nodes 2, 3 and 4 have the second highest ranks. These nodes have a higher rank than the others (except for node 1) because, in addition to influencing node 1, they affect other nodes that have no friends at all. This makes them the only effectors to theses nodes which make them, in turn, have a higher rank. The rest of the nodes, 5 through 9; have the lowest ranks since they do not have many friends to influence.

In the second experiment, more friends were added to the friends of node 1; the results of this experiment are shown in Fig. 8b. In this graph, node 6 has two friends, node 5 has three friends and one more friend was added to node 2. After computing the ranks of the nodes as shown in Fig. 8b, it is clear that this change lowered the rank of node 1. The introduction of new friends to the friends of node 1 weakens the influence of node 1. For instance, in Fig. 8a, node 1 is the only effector on node 5 and in Fig. 8b, node 5 is influenced by four friends, not just one. Node 1 still managed to be the highest influencer in the graph since it is influencing more nodes than the others. The rank for node 5 in Fig. 8b is far much higher than when it was in the graph in Fig. 8a. This is due to the fact that it is now affecting 4 friends rather than just one as it was in Fig. 8a.

The number of nodes is increased to 20 in the third experiment and the results are shown in Fig. 8c. Node 5 now has a total of six friends, each of nodes 2 and 6 has three friends and node 4 has two friends. For this scenario, node 1 is no longer the highest influencer in the graph and node 5 becomes the one with the highest rank. This happened due to several reasons, the first being that node 5 is now influencing more friends than node 1 and more importantly five of its friends are solely influenced by it. The second reason is that node 5 as well as nodes 6, 2 and 4, which are all friends of node 1, are influenced by new more nodes in addition to node 1. This makes it much harder for node 1 to influence these nodes, which yields a lower rank.

Another experiment has been carried out to test the effect of incorporating the interests in finding influential nodes. For this test, a network has been given to the NodeRank algorithm as an input twice; once without the nodes interests and another time with their interests. Figure 9 shows the result for this experiment. Figure 9a shows the ranks for the nodes without taking their interests into consideration, whereas Fig. 9b shows their ranks while including the interests in the influence calculation. The numbers labeling the edges in Fig. 9b indicate the similarity of interests between its endpoint nodes. The ranks for the nodes differ drastically in the two scenarios, for the first one node 5 has the highest rank of 0.6250 and for the second one node 4 has the highest rank of 0.7039.

In Fig. 9a, the interests were not considered, so the influence calculations were based only on the connections between the nodes. Since node 5 has the highest degree in the networks, in other words, it knows more people than any other node; it is given the highest degree. Node 4 came on second in the rank because it has the highest number of nodes after node 5. The rest of the nodes have low rankings since each one is connected to a single node, and thus their influence is small.

In contrast to Fig. 9a, in Fig. 9b node 4 has the highest rank amongst all nodes in the network. In this scenario, nodes 1, 2 and 3 share many common interests with node 4, indicated by the high numbers on the edges. On the other hand, nodes 6, 7, 8 and 9 have only a few interests in common with node 5. So, although node 5 has a higher number of friends than 4, it did not earn the highest rank in the network since its connections are weak due to having few common interests with its friends. So not only node 4 jumps from 0.5 to 0.7039, but also the rank for node 5 gets lowered from 0.625 to 0.5513, which makes a large difference in the rank between the two nodes. Note that the rest of the nodes get affected by including the influence as well. All of node 4 friends are ranked higher than the previous case since now they know a more influential node and they too share many common interests with node 4. The friends of node 5 are getting lower ranks in this scenario because of the low number of common interests between them and node 5.

Fig. 9
figure 9
The effect of incorporating the interests in finding influential nodes

Full size image

During earlier experiments, only synthetic datasets were used. So, for the last experiment, the NodeRank algorithm is tested using a real Facebook dataset that consists of approximately 4000 nodes (data.world/facebook_dataset). In this dataset, nodes represent users and edges represent friendship relationships between users. The Facebook dataset was analyzed and we computed for each node its degree, the rank of each friend node, the number of friends of each friend, etc., as shown in Table 2. The Facebook dataset was used for this test to see how the algorithm behaves and ranks the nodes in case the dataset contains actual people and relationships. In other words, the dataset has a real-life topological structure. The dataset does not have interests associated with each node, so used Wordnet to generate interests and then distributed these interests to each node. The results of this experiment are shown in Table 2.

Table 2 NodeRank results for top 10 nodes after running on a Facebook dataset of 4000 nodes
Full size table

Before going into the discussion of the results in Table 2, we show the relation between each column in the table and the rank of the node. The Degree column represents the number of friends a node has. Clearly, the higher the degree, the bigger the rank is going to be. The second column is the Friends Ranks, which lists the summation of ranks for the friends of the node. The value of the Friends Ranks column is proportional to the rank of the node. The explanation behind this is that when a certain node is influencing a friend with a higher rank, the chances of its influence to propagate through that friend is higher. The Friends Degree column holds the summation of the degrees for the friends. When the value of this column increases the rank of the node decreases due to the fact that more nodes are participating in the influence process, which yields a lower rank for all of its friends. The last column is the Sum of Friends of the Friends Ranks. This column sums up the ranks for all friends of the friends. It is also inversely proportional to the rank of the node because having a friend with a large degree but whose friends have low ranks gives the chance to the node in question to have more influence on it.

The results in Table 2 show that node 107 has the highest rank followed by node 3437 with a very slight difference between the two. The explanation for node 107 being the highest ranked node is straight forward, node 107 has more friends than the rest of the nodes. Moreover, the ranks of its friends are significantly higher than the rest of the nodes which makes the node have a good propagation of influence.

The next node is 3437, which has 547 friends compared to the fourth node 1684, that has 792 friends. The difference between the two degrees is not large when compared to the difference between the summation of their friends degrees. The friends degrees of node 3437 is 10333 which is much smaller than the friends degrees of node 1684 (30054).

To have a more consistent comparison, nodes with similar degrees were chosen, namely, nodes: 122, 3233 and 567, each having 63 friends. Node 122 has the lowest friends degrees as well as friends of the friends ranks. Node 567 has the highest friends ranks. Node 122 managed to get the highest rank amongst the three although it has a lower friends ranks than node 567. The friends of node 122 have almost 40% fewer friends the those of node 567. Furthermore, friends of the friends ranks for node 122 is almost 50% less than those of node 567. Because of these two reasons, node 122 was given the highest rank.

Again, the same situation happens with nodes 3233 and 567, where node 567 has better friends ranks than node 3233 but worse in terms of friends of the friends degrees and ranks.

NodeRankParallel scalability results
As for the NodeRankParallel, several experiments have been conducted to test its scalability. Two datasets are used in these experiments: a Facebook dataset that contains 4039 nodes and 88233 edges and a synthetic dataset that contains 10000 nodes and 266212 edges.

For the Facebook dataset, NodeRankParallel is executed 25 times using 50/25 mappers/reducers to 2/1 mappers/reducer. The results of this experiment are shown in Figs. 10 and 11.

Fig. 10
figure 10
Total execution time for NodeRankParallel using Facebook dataset (MapReduce version). Note that the number of reducers is half of that of mappers at each run

Full size image

Fig. 11
figure 11
The execution time for each stage in the NodeRankParallel using Facebook dataset (MapReduce version)

Full size image

Figure 10 shows the total execution time for the four stages at different runs. The x-axis represents the number of mappers at each run whereas the y-axis shows the time in seconds. In each run, the number of reducers is set to half the number of mappers. This is because the number of entries to each stage is huge, which requires many mappers but the results from the mapper are grouped to a far lower number which requires fewer reducers. NodeRankParallel achieves good results since execution time decreases exponentially with a linear increase of mappers and reducers. Figure 11a, b, c and d show the execution time for each stage individually. As shown from the figures, stage 3 takes the longest time to finish followed by stage 4. This is logical since stage 3 computes the all-pairs shortest paths.

Stages 1 and 2 do not scale very well like the other two, this is due to the fact that these stages are not computationally expensive when the number of nodes is relatively small. This is evident by their execution times that are negligible compared to the other stages. The behaviors of stage 1 and 2 in Fig. 11a and b, respectively, are dominated by the overhead of the mappers and reducers rather than the computation.

To ensure that the first two stages are scalable, we used another synthetic dataset with 10000 nodes. The same tests are conducted as with the Facebook dataset. The results of this experiment are shown in Figs. 12 and 13.

Fig. 12
figure 12
Total execution time for NodeRankParallel using the 10K synthetic dataset (MapReduce version)

Full size image

Fig. 13
figure 13
The execution time for each stage in the NodeRankParallel using the 10K synthetic dataset (MapReduce Version)

Full size image

As in the previous experiment, the overall time of execution decreases exponentially as it goes from 106658 seconds for 2 mappers/1 reducer to 8527 for 50 mappers/25 reducers. The last two stages are shown in Fig. 13c and d scale very well.

For the first two stages, the situation is different. It is clear that the execution times for these stages scale far better than in the previous test (Fig. 13a and b). This is because the dataset size has increased by almost double the number of nodes and triple the number of edges. Because of that, the processing load has increased and thus, the computation work dominates the overhead of the mappers and reducers. As a result, we notice a smooth scalability for stage 1 and 2 in this experiment.

For the Spark version of the parallel algorithm, the same cluster is utilized. This allowed for a 15-executor setup, each executor has 4 cores and 4 GB of memory. The number of nodes used in this test is 50000. The results of this test are shown in Fig. 14. The execution time decreases exponentially as the number of workers increases. The execution time is almost 24 hours when a single executor is used and a mere five hours only when using the full 15 executors.

Fig. 14
figure 14
Total execution time for NodeRankParallel using the 50K synthetic dataset (Spark version)

Full size image

For the last experiment, the same 50000-nodes graph is processed by the MapReduce version, the results of which are shown in Fig 15. The Spark version achieves less execution time than the MapReduce version due to less IO operations. Using Spark, the NodeRankParallel finished executing in just about five hours using the full power of the cluster whereas using MapReduce it took about 87 hours to finish the same job.

Fig. 15
figure 15
Total execution time for NodeRankParallel using the 50K synthetic dataset (Spark vs MapReduce versions)

Full size image

Conclusion
In this paper, the NodeRank algorithm is proposed, which ranks nodes in a given social network based on their influence on other nodes. The NodeRank algorithm gives a higher rank for nodes that have many friends. Also, the rank of the node increases as the propagation of its influence increases. This is achievable when a certain node is friends with other influential nodes. When ranking, the NodeRank takes into consideration the topological structure of the network as well as the semantic meaning of the nodes interests. Since social networks typically have a large number of nodes and edges, the paper proposed the NodeRankParallel, which is a Spark version of the original NodeRank algorithm. This enables the proposed algorithm to run on multiple machines simultaneously and give results much quicker. Several experiments have been conducted using both synthetic datasets as well as a subset of a Facebook dataset which showed good results in ranking the nodes in these networks. The NodeRankParallel is also tested in terms of its scalability. Our results show that the execution time for NodeRankParallel decreases exponentially with a linear increase in the number of mappers.