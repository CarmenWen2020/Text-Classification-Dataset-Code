Abstract
Fuzzy C-mean (FCM) is an algorithm for data segmentation and classification, robust and very popular within the scientific community. It is used in several fields such as computer vision, medical imaging and remote control. The purpose of this paper is to propose a parallel implementation of the iterative type-2 fuzzy C-mean (IT2FCM) algorithm on a massively parallel SIMD architecture to segment different MRI images. IT2FCM is an FCM standard variant; its objective is identical to that of FCM, except that the first has a higher accuracy level than the second. However, it is expensive in terms of time processing. Therefore, it is practically important to reduce its execution time while preserving the quality of the segmentation. This implementation is then compared with the sequential versions in the C language and Python using the Numpy and Numba libraries, and then, we compared it to another parallel method from the literature. The execution time obtained is faster than the sequential versions by about 15 × and 4 × for the second parallel version. The results achieved are very satisfactory compared to those taken from the literature.

Introduction
Medical image processing for the disease diagnosis has become very popular among doctors. Its practicality and effectiveness for the various existing modalities such as magnetic resonance imaging (MRI), computed tomography (CT) and digital mammography prove its importance.

Medical imaging produces a mass of images for human organs including MRI. From the latter, a safe scan provides a soft tissue scanned images for a proper medical diagnosis [1].

The segmentation technique is a part of the image treatment process; its objective differs between abnormality detection, quantitative analysis and post-surgical evaluation. Several segmentation algorithms have been suggested [2] in the literature in order to reach a better segmentation quality capable of detecting inconsistencies with high exactness. Among the classification techniques, we mention the K-mean (KM) and fuzzy C-mean (FCM) algorithms. The KM method is an accurate rigid clustering one in the classification and the segmentation results that depend on the initial centroids [3], while fuzzy is an unsupervised gentle learning technique that allows us to order a data point into several classes with different membership degrees. The aim is to find region centers that minimize the objective function [4, 5]. In each iteration, the algorithm updates the centroids and membership matrices. According to the basic FCM algorithm, several improvements have been introduced and have produced numerous development versions [6,7,8,9].

Type-2 fuzzy C-mean allows us to model various uncertainties, which cannot be handled appropriately by type-1 fuzzy sets [10,11,12,13]. Of course, the use of type-2 fuzzy generally increases the calculation complexity compared to type-1 fuzzy C-mean because of the additional dimension of having to calculate secondary grades for each primary member. Furthermore, the images resolution used increased, which lead to a rise in response and execution time for the used technique, especially for the sequential systems’ mono-processors. Hence, the current trend tends to parallelism and parallel architectures as an alternative for designing algorithms; it requires a huge amount of processing such as distributed systems or computing grids. Graphic processing units (GPUs) belong to the SIMD (single instruction multiple data) massively parallel architectures composed of hundreds of cores capable of executing simultaneously several tasks. Compute Unified Device Architecture (CUDA) is a GPU computing platform and a minimal extension of the C programming model introduced by NVIDIA in late 2006 [14, 15]. In this paper, we propose a parallel implementation of the IT2FCM (iterative type-2 FCM) algorithm [16] to solve the execution time delay problem. This implementation named hybrid, as we share the tasks between the CPU and the GPU; then, we compare our version to a parallel one taken from literature and to different sequential versions implemented with C and Python (Numpy, Numba) languages. Python, as a matter of fact, is one of the most widely used languages in scientific fields such as physics, bioinformatics and machine learning. Its handicap is that it is too slow. This slowness is due to its nature (interpreted language), especially with the matrix calculations’ presence in addition to simple and nested loops. To overcome this, Python offers several libraries capable of making it as fast and efficient as possible, such as Numpy. The latter is a mathematical library designed to manipulate matrices or multidimensional arrays as well as mathematical functions operating on these arrays. Python also offers Numba (https://numba.pydata.org/), which is just-in-time compiler for Python that works best on code that uses Numpy arrays and functions, and loops. This compiler significantly increases the execution time of the standard Python.

The rest of the paper is organized as follows: Section 2 discuses some related works. Section 3 details the IT2FCM sequential implementation. Section 4 details the parallel implementations of the IT2FCM algorithm. Section 5 presents the experimental results. Finally, we conclude the paper contribution.

Related work
The graphic processors’ use in the medical field and precisely for segmentation techniques has known several implementation proposals [17] capable of reducing the algorithms’ execution time requiring intensive computation. For FCM and its variants, several researchers have proposed fairly significant accelerations. Their implementations are influenced not only by the method used but also by the card performance [18]. In [19], the authors accelerated the FCM algorithm performance on the GPU using the CUDA environment. They compared their parallel implementation to sequential implementations written in C +  + and MATLAB. To do this, they used a GTX(Giga Texel Shader eXtreme) 560 graphics card of Fermi architecture to achieve an acceleration of 10 × over the sequential C +  + implementation and between 50 × to 100 × over the Matlab implementations. With h the same objective, a hybrid parallel implementation has been proposed in [20, 21] to reduce the execution time of FCM and some of its variants. The authors of these papers managed to attain a processing time improvement of about 5 × and 10 ×  , respectively, compared to the sequential implementation with C# under the GT 740 m card. Another variant of FCM has been parallelized in [18]; this algorithm does the segmentation while eliminating intensity inhomogeneity BCFCM (bias correction FCM). The maximum acceleration resulting from their implementation is 52 × on a GTX 580 GPU, 21 × on GTX 760 and 12 × on GT 740 m. The same authors have proposed a massively parallel version of the SFCM (spatial FCM) classification algorithm [22], which relies on the noise artifact. Including the neighboring spatial function in the process of updating the membership matrix has minimized the influence of noise on segmentation.

The remaining comparisons are summarized in Table 1.

Table 1 Comparative study of the different performances of parallel implementations of the FCM algorithm
Full size table

Interval fuzzy type-2
Interval type-2 fuzzy presents an improved version of the standard FCM [16] that extends a pattern set to fuzzy type-2 sets by intervals using two fuzzifiers m1 and m2 that create an uncertainty footprint (FOU) for the fuzzifier m; its objective is to observe the effect of uncertainty management of the two fuzzifiers. It is frequently used in pattern recognition to partition an image containing {x1, …, xN} pixels into C cluster {v1, …,vc}. It is based on minimization of the following objective function:


 
 

(1)

xk: the kth pixel,

vi: The cluster center i.

uik: The membership degree to which pixel xk belongs to cluster vi.

N: The total number of pixels in the image.

|| xk-vi ||: Any norm expressing the similarity between pixel xk and cluster center vi.

m: A weighted exponent parameter (m > 1) on each fuzzy membership value determines the amount of fuzziness of the resulting classification according to the following formula:


 

(2)

The first main step of this iterative algorithm consists in updating the membership function to determine in which cluster the pixel belongs according to Eqs. (3 and 4):


 
 
 
 
 
 
 
 
 
 
 

(3)


 
 
 
 
 
 
 
 
 
 
 
 

(4)

The second main step is to update the centroids based on the new membership matrix according to Eqs. (5 and 6).


 

(5)

where 
 
 
  Else 
 
 and m = 2


 

(6)

where 
 
 , Else 
 
 
 and m = 2.

P: is the index of the cluster center in the sorted list.

 and 
 represent an interval cluster centers where 
 is the left value (minimum) and 
 the right value (maximum).

 represents the middle of the interval [
].

 and 
 are calculated using (5) and (6), respectively.

Algorithm 1 represents the sequential implementation’s different steps.

figure a
Moreover, this algorithm is implemented under two environments: a C and Python.

Parallel interval type-2 IT2FCM implementations
Parallel interval type-2 PIT2FCM_1
In this section, we will detail our proposed hybrid parallel implementation of the IT2FCM algorithm called PIT2FCM_1. The idea starts with an image transfer to the GPU in a single vector; then, the initial centroids are assigned to constant memory since they will be used in read-only mode on the GPU. Note that the image pixels’ vector is sorted in an ascending manner using the quick sort algorithm on CPU before the phase of transferring the image data to the graphics processor.

In the iterative part of the algorithm, we start by calculating and updating:

(1)
The new membership matrices 
 
 
 
 based on Eqs. (3 and 4), respectively. These two functions are perfectly adequate to the GPU architecture since each thread is in charge of calculating the membership matrix for each pixel with respect to each centroid independently. This allows it to perform well on the GPU.

(2)
The update of new centroids is the algorithm’s critical part; its drawback is a summation’s operation that requires all threads to write on the same memory location which causes serial execution. This latter gives a better execution time results on the CPU compared to the GPU; the second weak point is the smallness of the centroids’ number, which does not allow the GPU to exploit its multithreading to accelerate this expression. On the other hand, if each thread k that represents a pixel makes sure to compute the expression 
 and 
 where i represents the cluster, we would have a parallel execution. The results would be stored in a vector of size N*C, which will eliminate the mentioned second weak point; we are then left with only one constraint that will be executed on the GPU. The summation has less influence on the efficiency of the method. For the pixel location’s search operation at the image vector level, we used the fast binary search algorithm where each thread calls this function in a parallel and independent way from the device. Then, we proceeded with the summation’s calculation on GPU. The result obtained is transferred to the CPU to finish the centroid calculation, which requires a very limited number of division operations related to the clusters number.

(3)
To calculate the objective function, so with the same reasoning of the centroid update we can execute the formula for updating the cost function in parallel. Then, the result is transferred to the CPU and compared with the old objective function.

figure b
Parallel interval type-2 PIT2FCM_2
In the second implementation, we tried to reproduce the authors’ same implementation method in [21] while taking into consideration their optimizations, except for the equation 
 
 in (Eqs. 3 and 4) where, according to the author, it is calculated only once to be used in the term 
 
 
 (Eqs. 3 and 4), which is not theoretically valid since 
 
 
 is the elements’ summation where each component is to be raised to the power 2/m-1 for each element of k. For the convergence condition, we used the objective function (Eq. 1) where 
 
 
 
 
 moreover we worked with the parameters m, m1, m2 as a variable and not a constant.

figure c
Results and discussion
Experiment setup
The parallel algorithms were implemented using the Microsoft Visual Studio 2019 program and the CUDA 9.2 library (https://developer.nvidia.com/cuda-92-download-archive). The sequential IT2FCM algorithm is programmed in C and compiled with the same Microsoft program used for the parallel versions. The python version is programmed and compiled within PyCharm 2020.1.2 using Numba 0.50.1. Speed-up results were carried out on: Intel(R) Core (TM) i5-3230 M 2 Cores 2.6 GHz CPU and Nvidia GeForce GT 740 m with 384 shader cores, 2048 MB amount memory, core speed (810–980) Mhz.

MRI images database
To validate the parallel implementations’ efficiency with the sequential ones, we have extensively experimented the two parallel versions of the clustering algorithm on different MRI images with different densities. We used for this experiment; nine selected medical images from a wide database. All these images are segmented into five clusters (Fig. 1).

Fig. 1
figure 1
Different medical images used for experiments

Full size image

Some GPU implementation specifications
In order to have an optimized implementation, GPU programming has many challenges to achieve high-performance improvements over the sequential one [36].

Depending on the compute capability and the number of threads per block, the GPU can reach its height performances. This compute capability identifies the features supported by the GPU hardware and is used by applications at runtime to determine which hardware features and/or instructions are available on the present GPU.

The first challenge is the usage management of the different types of memory on GPU. Indeed, transferring data from the CPU side to the GPU side and from GPU side to CPU side causes important delays. To deal with this problem, data transactions between CPU and GPU must be tracked and any useless transaction should be eliminated.

The second main challenge is the optimal GPU utilization. The best number of threads that run in single block of memory is 256 threads per block as shown in Table 2. We used this value for our parallel implementations.

Table 2 GPU utilization percentages for different numbers of threads per block configurations
Full size table

Notation
We use expression (8) to calculate the speedup achieved by our parallel implementation’s versions over the sequential ones.


 

(8)

Implementation Performances of IT2FCM-based implementations on MRI images
For the performance experiment, we used different MRI images of different body organs such as brain, mammography, prostate and cardiac.

The parameter values of the IT2FCM algorithm model used are: m1 = 1.1, m2 = 5.0

Execution Time results
In this paragraph, we will present the runtime comparisons results for different images of different sizes. First, we established the execution times’ histograms according to the algorithm implemented by changing the type and size of the image (Figs. 2, 3, 4 and 5).

Fig. 2
figure 2
Execution time comparison between different implementations for Brain-1

Full size image

Fig. 3
figure 3
Execution time comparison between different implementations for breast-1

Full size image

Fig. 4
figure 4
Execution time comparison between different implementations for prostate

Full size image

Fig. 5
figure 5
Execution time comparison between different implementations for cardiac

Full size image

Figures 2, 3, 4 and 5 show the parallel and sequential executions for different implementations of Brain-1, Breast-1, Prostate and Cardiac images. These algorithms are implemented, respectively, in sequential C language, sequential Python language and CUDA parallel language in two versions, PIT2FCM_1 and PIT2FCM_2.

Indeed, the execution time achieved for Brain-1 with our parallel implementation method is of the order of 5.36 s compared to 82.15 s and 67.43 s for sequential implementations under C and Python, respectively. These results remain valid for Breast-1, prostate and Cardiac images with, as the execution times achieved result for Breast-1 under our PIT2FCM_1 implementation, 5.2 s compared to 76.31 s and 64.36 s for sequential versions under the C and Python environment, respectively.

In fact, Python (Numba, Numpy) performance can be nearly as fast as C/C +  + . In some cases, Numba could perform better than C/C +  + depending on the optimization flag (-O1,-O2,–O3) used for the C/C +  + compiler (https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html). As long as our case is concerned, visual studio compiler uses –O2 optimization for C version, while Numba uses –O3 which is more optimized than –O2 which leads to a Numba superiority against the C version.

However, both parallel implementations’ versions are much better than sequential ones.

Figure 6 summarizes the results of the histograms above.

Fig. 6
figure 6
Execution time comparison between different implementations and different images

Full size image

Table 3 summarizes the different values of run times for different images used in our experiment (Fig. 7).

Table 3 Execution time for different images’ segmentation
Full size table

Fig. 7
figure 7
Speedups of the parallel versions versus the sequential ones for Brain-1

Full size image

Minimum runtimes are achieved with our PIT2FCM_1 implementation compared to the sequential C version. Indeed, the latter are remarkably validated and manifested for Brain-1, Brain-2, Breast-1, Brain-3 and Breast-2 images (Fig. 8).

Fig. 8
figure 8
Speedups of the parallel versions versus the sequential ones for Breast-1

Full size image

Speedups results
Compared to sequential versions, PIT2FCM_1 implementation tested on several images of different sizes and types is much more performant than its corresponding PIT2FCM_2.

Indeed, the maximum speedup value reached for the Prostate image is of the order of 15.44 × for the parallel implementation PIT2FCM_1 compared to the sequential implementation in C , and it is of the order of 13.11 × for the sequential version of Python. While for the parallel version PIT2FCM_2, the maximum speedup values achieved are of the order of 3.44x, 2.79 × compared to C and Python implementations , respectively.

However, the maximum value reached for PIT2FCM_2, for all the test images used, is of the order of 3.44 × manifested for the prostate and always in relation to the sequential C version.

We note that:

C: represents the sequential C implementation.

Py: represents the sequential Python implementation.

V1: represents the first parallel version PIT2FCM_1.

V2: represents the second parallel version PIT2FCM_2.

Table 4 summarizes the different values of speedups for different images used in our experiment.

Table 4 Speedups for different images’ segmentation
Full size table

On the other hand, we note that our parallel implementation method gave very good speedup results for the same test images with respect to PIT2FCM_2 compared to the sequential python implementation. The results of the speedups obtained are: 12.58x, 12.73x, 12.96 × and 12.55 × for Brain-1, Brain-2, Brain-5 and Prostate images , respectively.

In conclusion, our PIT2FCM_1 implementation method is the most efficient compared to the other implemented versions.

Example of image segmentation comparison between FCM and PIT2FCM and IT2FCM
Figure 9 shows a set of various medical images judiciously chosen from a large database with different sizes and types to experimentally test the performance of the parallel implementation of the two algorithms PIT2FCM and IT2FCM in order to segment them.

Fig. 9
figure 9
Experiment results of segmentations comparison between FCM IT2FCM and PIT2FCM

Full size image

It is noticeable that images segmented with IT2FCM are better than those segmented with ordinary FCM. These images used for our experiment are segmented into 5 clusters.

To better validate the performance of our PIT2FCM_1 parallel implementation, we applied it to brain, breast, chest and prostate images (Fig. 10). Indeed, the 5 clustered regions representing the tissue materials for each image are well and truly discerned.

Fig. 10
figure 10
Experiment results of segmented Images with PIT2FCM

Full size image

Conclusion
In this paper, we improved the execution time of IT2FCM-based image segmentation algorithm by using GPU card while preserving the original algorithm segmentation quality. We studied different hybrid CPU-GPU implementations with CUDA and sequential implementations using C language and Python language on different images of different body organs. The results show that our proposed PIT2FCM_1 improves the execution time much better than that of the PIT2FCM_2. In general, by considering both accuracy and execution time results, the hybrid implementation of the PIT2FCM_1 seems to be the best option to use form all implementations options that we have studied in this paper.