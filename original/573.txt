Abstract
Due to the severity and great harm of coal and gas outbursts accidents, outbursts prediction becomes very necessary; the paper presents a hybrid prediction model of feature extraction and pattern classification for coal and gas outbursts. First, discrete wavelet transform (DWT) is utilized as a preprocessing technique to decompose subseries and extract the features with different frequencies and the optimal feature components are retained; second, in order to eliminate the redundancy between the features and uncorrelation between features and outbursts, we use the fast independent component analysis (FICA) to obtain each independent component, obtaining the global information in the feature; then, the obtained features are input into linear discriminant analysis (LDA), under the guidance of class labels, then the local information in features is obtained; finally, the projected features are input into the deep extreme learning machine (DELM) classifier based on the optimal parameters by quantum particle swarm optimization (QPSO) for training and classification. The experimental results on the dataset of coal and gas outbursts show that compared with other models in the current prediction of coal and gas outbursts, this method has significant effect on various indicators.

Introduction
Coal and gas outbursts are dynamic process with complex mechanism and many influencing factors; these mechanism and evolution law are not clear up to now and outbursts disaster cannot be effectively prevented and controlled, which seriously threaten the safety of coal mine production in the world [1]. Therefore, fast and accurate dynamic prediction of coal and gas outbursts has important practical significance for economic development and coal mine safety production in the world. The feature indexes selection of coal and gas outbursts influencing factors play an important part in the outbursts prediction. However, the acquired coal and gas outbursts feature indexes and sample data have noisy components due to the pollution of measurement accuracy, calculation accuracy, recording and storage process. There exit redundancy and irrelevance between features and outbursts. If the original features and sample data are directly used for classification, the accuracy of classifiers cannot be guaranteed and the efficiency is very poor, so for the classification of coal and gas outbursts, feature denoising and feature extraction are very necessary. The accuracy and reliability of coal and gas outbursts depend on the selected feature indexes and the selection of prediction indexes depends on the preprocessing of coal and gas outbursts influencing factors.

Coal and gas outbursts are random, complexity, nonlinear and non-stationary, in order to reduce the complexity of coal and gas outbursts prediction, eliminate the influence of noise caused by uncertainty and local random factors on prediction results, recover the whole statistical law of original sample data as possible regular distribution and maintain the authenticity and integrity of the sample data based on the interference, it is very necessary to perform feature denoising. However, the traditional feature denoising methods such as the Fourier transform, Kalman filter and Particle filter have some defects, although these methods can achieve better denoising effect, it can cause the information loss of the sample data, which can make it difficult to furtherly perform the effective feature extraction and obtain much higher classification performance, these methods also cannot reflect the important characteristics of nonlinear and non-stationary time–frequency local characteristics [2]. Wavelet analysis [3] can be used to process the signal, judge the main frequency band range of the signal, obtain the energy distribution and characteristics in different frequency bands and normalize the relative energy of each frequency band. Wavelet transform signal is decomposed into two kinds: high frequency component and low frequency component. The low frequency contains the main signal performance and the high frequency contains more noise signal, wavelet denoising is realized by smoothing the high frequency and reconstructing it. The main advantage of DWT is that it can provide more local information by decomposing the signal, so as to solve the above problems effectively [4]. The collected sample data may be polluted by random and noise factors, which have poor effect on sample data quality and can bring difficulties for the following data analysis, so this paper uses DWT method to solve the feature denoising and other related problems. The high-frequency part of the feature is reconstructed smoothly to realize the denoising. Wavelet theory has the advantages of decorrelation, multi-resolution and base selection flexibility [5]. It can effectively distinguish the noise components in the sample data and feature indexes, remove the noise and obtain the non-stationary characteristics, in this paper DWT is applied in the feature preprocessing.

After the acquired coal and gas outbursts sample data are denoised, there exit redundancy and uncorrelation in the coal and gas outbursts influencing factors, effective feature extraction is very necessary for the prediction of coal and gas outbursts. At present, there are many feature extraction methods of coal and gas outbursts influencing factors, which are divided into linear and nonlinear feature extraction. The linear extraction methods include the following: PCA [6, 7], ICA [8], LDA [9], FA [10]; the nonlinear feature extraction methods include the following: LLE [11], KPCA [12,13,14]and ISOMAP [15], then Table 1 presents many feature extraction methods and gives their advantages and disadvantages, and we can compare and summary these methods. At the same time, because coal and gas outbursts influencing factors have the characteristics of random and diversity, the relationships between influencing factors, outbursts and influencing factors are also very complex, the single feature extraction method cannot fully mine the internal laws of the outbursts influencing factors. The correlation information between them cannot be extracted and the information components contained in the influencing factors cannot be integrated, which makes that the prediction effect of the classifier is not high. The literature shows that the sample data of coal and gas outbursts contain quite complex information, including global and local structure information, Gaussian and non-Gaussian components, significant nonlinear and linear characteristics. In order to analyze the features of sample data better, we need to use the mixed feature fusion method to extract features in multiple feature spaces, single subspace feature extraction algorithm has its limitations and it cannot be superior to other subspaces in any case. Therefore, this paper focuses on the problems which exist in the single feature extraction of coal and gas outbursts and makes full use of the combination of local linear feature LDA and global nonlinear feature extraction FICA methods to make up for the shortcomings of single feature extraction method.

Table 1 Comparisons of different feature extraction methods
Full size table

Classifier model selection for outbursts prediction is another issue addressed in this study, the common classifiers are BP neural network [6], support vector machine (SVM) [8], random forestry (RF) [10] and other intelligent classifier technologies [16]. These methods play an important role in improving the prediction of coal and gas outbursts. Among them, PNN and RF all assume the feature indexes of coal and gas outbursts prediction are independent of each other and there are some disadvantages such as complex calculation, long learning time and large sample space. ELM is a single hidden layer feedforward neural network, which is characterized by the connection weight matrix between input layer and hidden layer, and the offset of hidden layer nodes only need one-time random initialization, instead of updating by traditional back propagation algorithm. The only thing to be calculated is the weight matrix between hidden layer and output layer, which can be calculated by finding the square of generalized inverse matrix. Compared with other models, ELM has some obvious advantages. From the perspective of classification performance, ELM will achieve classification performance similar to or even better than SVM and gain many successful experiences in small sample data and high-dimensional nonlinear pattern recognition problems. ELM can approach any nonlinear objective function with arbitrary precision by giving an activation function satisfying certain conditions, which has strong nonlinear approximation ability and can be used to describe coal and gas outbursts prominent nonlinear evolution of space–time. However, due to the randomness, the parameters of ELM are not optimal and there are problems in stability and reliability, so parameter optimization is needed. Many kinds of literatures have proposed some optimization methods such as genetic algorithm (GA) [17], ant colony (AC) [18], cuckoo search optimization (CSO) [19] and particle swarm algorithm (PSO)[20]. To some extent, these intelligent optimization algorithms can solve the problems that the optimal solution of parameters cannot obtain by experience setting, however these optimization algorithms are generally based on the mode of evolutionary algorithm. The disadvantages of the evolutionary algorithm are that the optimization algorithm is easy to trap at local minima, the parameters searched are not optimal and the efficiency is not high, so the algorithm needs iteration continuously. QPSO is a global searching algorithm, which theoretically guarantees to find the best solution in the searching space. Compared with PSO, the iterative equation of QPSO [21] does not need the particle velocity vector and it needs less parameters to be adjusted, which can be realized more easily, related experimental results also show that QPSO has better performance than standard PSO algorithm.

In order to improve the prediction accuracy and efficiency of coal and gas outbursts, we propose an optimization classifier model QPSO-DELM coupled DWT feature denoising and FICA–LDA feature extraction. The main contributions of this paper are as follows: The first stage is feature decomposition and reconstruction, we use DWT to smooth the coal and gas outbursts noise feature information and extract the main components in the original features, providing the high-quality sample data for the following feature extraction and classification. The second stage is dual space feature extraction, FICA is used to extract high-order information, the accounting information maps the high-dimensional features in the input space to the new low-dimensional feature space and separates the independent features, then LDA is used to extract second-order statistical information, we can find the dimensions with identification ability through dimensionality reduction, so that the original sample data can be reflected in these dimensions and the different classes can be distinguished as much as possible to get the optimal identification characteristics. The third stage is machine learning algorithm and parameter optimization, we can use the DELM with high learning ability and generalization ability to predict outbursts and use the QPSO algorithm with good comprehensive performance to optimize the related parameters of the DELM. Finally, we conduct a comprehensive evaluation using the actual dataset of coal and gas outbursts, this includes a comparison with state-of-the-art feature extraction and classifier methods in coal and gas outbursts prediction.

The remaining part of the article is organized as follows. Section 2 offers the materials and methodologies used in the experiments and introduces our proposed approach. The dataset preparation and configuration environment of the proposed schemes are presented, then the experimental results are analyzed in Sect. 3. Conclusions based on this research and future research targets are highlighted in Sect. 4.

Theory and method
Coal and gas outbursts are complex nonlinear and random, so we propose a mixed feature extraction and classifier model based on DWT + FICA–LDA + QPSO-DELM. Firstly, we use DWT to decompose different features in coal and gas features and reconstruct them by selecting threshold and threshold functions to form a new feature set of indicators; second, FICA algorithm is used to extract non-Gaussian features, forming independent features to produce a new feature set of space, then LDA is used to extract Gaussian features and local information, FICA–LDA feature extraction method can obtain the discrimination features; finally, the obtained features are input to the DELM based on QPSO for classification, as shown in Fig. 1.

Fig. 1
figure 1
Flowchart of proposed comprehensive prediction model

Full size image

Feature preprocessing
DWT
Wavelet transform [22] is a signal analysis tool for time–frequency analysis, which has unique advantages in time–frequency localization. It can extract information hidden in the original features and sample data, analyze local features and non-stationary in the sample data. Discrete wavelet can be defined  in the following Eq. (1) and (2):

, 
,


 
 

(1)


 
 

(2)

where φ is the parent wavelet, t is the discrete data feature, T is the length of data, integer variables m and n are the scale and conversion factor of discrete wavelet, data analysis is data decomposition and reconstruction,  denotes detail component,  denotes the approximate component. The series of approximations represents the low-frequency components, which contains the trend information of the original signal. The detail series represents the high-frequency components, including the characteristic signals of the influencing factors related to the original signal. In this study, a fast discrete wavelet analysis algorithm called Mallat is used, which is based on four filters: low and high pass decomposition filter, low and high pass reconstruction filter. The signal can be decomposed into an approximate value (an) and several detail values (dn) through the multi-level decomposition process based on Mallat. In the decomposition step, the signal is divided into two high-frequency and low-frequency components, while the low-frequency is divided into two parts: high frequency and low frequency. High frequency is called signal detail, low frequency is the approximate value of signal and the final result is the combination of high-frequency and low-frequency components. The original signal can be reconstructed by the following wavelet transform:


 

(3)



(4)

In wavelet decomposition, a selection of proper wavelet function and the number of decomposition layers are very necessary, many types of wavelet functions such as Daubechies, Symlet, Gaussian, Mexican hat, Morlet and Shannon wavelets can be used in wavelet decomposition. It is found that Daubechies wavelet function has the advantages of effective local ability in the field of time–frequency[39]. Therefore, Daubechies wavelet function is used as the wavelet base in this paper to balance the wavelength and smoothness. The number of decomposition layers is 3 according to the related literatures and experience value, which can more effectively separate various feature components.

Selection of threshold and threshold function
The selection rule of threshold and the design of threshold function [23] are the key factors that affect the denoising effect, the threshold function can be divided into two kinds: soft threshold and hard threshold. The hard threshold function has a break point, which simply keeps or removes the signal. While the soft threshold is used to distinguish the threshold value, it also uses the threshold value to attenuate the signal. In this paper, the soft threshold function is used, that is, when the absolute value of the wavelet coefficient is greater than or equal to the given threshold value, the value is the original value minus the threshold value, when it is less than the given threshold value, the value is zero. After the threshold function is selected, the threshold needs to be selected. The quality of threshold selection directly determines the performance of noise reduction model and it is very important to select the threshold and carry out threshold quantification to noise reduction. The types of threshold mainly include: fixed threshold, unbiased likelihood estimation threshold, heuristic threshold, minimax threshold, etc. In this paper, the fixed threshold is adopted according to related references [40]. In a word, the combination of fixed threshold and soft threshold function is used in the selection of wavelet analysis threshold and threshold function.

Wavelet denoising algorithm
DWT [24] is used to decompose the original data, it can compare the signals of different frequency ranges and divide the signals with different characteristics into subspaces of different resolution scales, then reconstruct the signals with wavelet coefficients. The reconstructed data not only can remove the unstable factors, but also can maintain good details. The noise of measured data has high-frequency signal and the essence of wavelet denoising extracts high-frequency part from the signal. The details of wavelet transform process include wavelet decomposition, threshold and threshold function processing and wavelet reconstruction:

1.
Wavelet decomposition. Select the appropriate wavelet function and the number of multi-scale decomposition layers, then analyze the wavelet transform of the original signal, on this basis, get the lowest approximation coefficient (low frequency) and the discrete detail coefficient (high frequency) of each layer.

2.
Threshold and threshold function processing. After wavelet processing, the threshold method is used to deal with the high-frequency coefficients of the discrete detail coefficients of each layer, so as to eliminate the noise.

3.
Wavelet reconstruction. After threshold processing, the low-frequency wavelet coefficients of wavelet decomposition and the high-frequency wavelet coefficients are used to reconstruct and the smoothed signals are obtained.

FICA–LDA feature extraction
ICA
ICA [25, 26] model assumes that the observed mixed signal variable y = (y1, y2,…)  is composed of n independent unknown source signals s = (s1, s2,… sn) and it is a linear mixture, so there is a relationship between the mixed signal y and the source signal s, which can be expressed  in the following Eq. (5) using vectors and w is the unknown mixed coefficient matrix.

where n is the unknown unpredictable noise, which accords with the Gaussian distribution. ICA recovers the source signal and mixture matrix through y. The main idea removes the correlation between the data variables from the non-Gaussian signal of the original data, so that the components of each variable are statistically independent of each other. ICA has a better separation effect on the cross signal and it can more deeply mine the effective information which is covered due to the cross signal. Superior performance in signal separation, redundancy elimination and noise reduction can be obtained to realize decomposition and fusion of deformation information. In this paper, formula (5) is analyzed by using FICA algorithm which is more efficient than traditional ICA.

FICA
Because the FICA [27] algorithm takes the maximum negative entropy as a search direction, we first discuss the decision criterion of negative entropy, the definition of negative entropy is as follows:

where H(Y) is a Gaussian random variable with the same variance and it is the differential entropy of the random variable.

According to information theory, among the random variables with the same variance, the random variables with Gaussian distribution have the maximum differential entropy. When there is a Gaussian distribution, the stronger the non-Gaussian property is, the smaller the differential entropy is, so it can be used as a non-Gaussian measure of random variables. Since it is impractical to calculate the probability density distribution function needed to know for differential entropy according to Eq. (7), the following approximate formula is adopted:



(8)

where G(⋅) is some non-quadratic function and V is a Gaussian variable of standard normal distribution. In this way, the problem of finding the maximum value of J(W) is transformed into the problem of solving the maximum value of 
,



(9)

That is, when solving the value of mixed matrix w, each independent component has the strongest non-Gaussian property and the best separation effect. The iteration formula (9) is used for calculation.



(10)

where g (.) is the derivative of function G(). At the same time, w (k+ 1) was normalized by Eq. (10). Therefore, the specific iterative steps are as follows:

1.
Select the initial value w;

2.
Calculate w (k + 1) according to Eq. (9);

3.
Normalize w (k + 1) according to Eq. (10);

4.
If the value of adjacent w is less than the given value, the iteration stops; otherwise, it turns to setp2.

LDA
LDA [28,29,30] is a supervised linear dimensionality reduction method based on Fisher's discriminant criteria, the key goal is to find a projection matrix G to maximize the Fisher criterion after sample projection is made. The optimal projection direction can be found by eigenvalue decomposition of the scattering matrix. The specific steps are as follows:

Step1: Let x be a matrix of k class data 
, each 
 includes 
 samples, then calculate the mean vector of all kinds of samples 
 and the mean vector of all samples 
, which are expressed as follows:

Step2: Calculate the inter-class scatter matrix 
 and intra-class scatter matrix of the sample 
, respectively, the formulas are expressed as follows:


 

(13)


 

(14)

Step3:Find the projection matrix G and define fisher criterion function, in order to obtain the maximum value of G, it can be solved in the following ways:



(16)

where 
 is the eigenvector corresponding to the eigenvalue  of matrix 
.

Step4: The Lagrange multiplier method is used to solve all samples with the most optimal projection direction, then it can achieve the purpose of dimension reduction:

FICA–LDA feature extraction
The FICA can extract the high-order statistics information of non-Gaussian from original features, and it can provide much more information than the second-order statistics method. From the non-Gaussian features, we can find nonlinear expression which makes the components become statistically independent or as independent as possible. FICA can effectively extract non-Gaussian components of sample data and reduce the complexity of prediction model, but FICA is an unsupervised learning method and it is unable to extract all kinds of correlation information between class labels and various features, so it reduces its accuracy and sensitivity in feature extraction. LDA can find an optimal projection matrix, so that it can get a new feature space after the matrix mapping. In the new feature space, each category is easier to be recognized and the dimension can also be reduced. LDA only depends on the second-order statistics information and the main variables obtained are uncorrelated and the sample data is Gaussian distribution. For random variables or processes that do not obey Gaussian distribution, the second-order statistics cannot fully represent their statistical characteristics.

In view of this situation, we propose a dual space feature extraction fusion algorithm based on the combination of FICA and LDA, the basic idea is that we use the FICA of high-order statistical information to extract the useful information of coal and gas outbursts and separate the relevant and unrelated features in the new feature space, then use LDA supervised learning to extract the second-order statistics information. In this way, we can make full use of the complementarity of the two feature spaces, the difficult recognition patterns in one feature subspace are easy to be recognized in the other feature subspace, FICA can extract complete useful information and separate useful features and noise features, LDA can reduce the dimension of features, improving the classification accuracy. In the two feature spaces, we combine the advantages of FICA and LDA method to mine all kinds of hidden information in the features of coal and gas outbursts sample data and influencing factors to the greatest extent, which can contribute to improve the prediction accuracy of classifier. The core of the algorithm is to combine the advantages of FICA and LDA dual space feature extraction algorithm, in view of the complexity and diversity of coal and gas outbursts, considering the characteristics of existing coal and gas outbursts sample data and influencing factors, we design a dual space feature extraction algorithm combining FICA and LDA and the implementation steps of the fusion method are as follows (Fig. 2):

Fig. 2
figure 2
Flowchart of proposed DWT + FICA–LDA model

Full size image

DELM
ELM
ELM [31,32,33] is a single hidden layer feedforward neural network, and it is mainly composed of three layers: input layer, single hidden layer and output layer. With the advantages of parameter selection, fast learning speed and good generalization performance, the ELM is fast, simple, easy to realize and has strong generalization. For small sample data, logical regression and neural network are obviously affected, while ELM function can maintain good performance, which makes it have obvious advantages under the condition that sample data are difficult to obtain. Suppose that there are N discrete training sample data 
, where 
. Single-layer feedforward neural network model can be expressed as follows:


 

(18)

where L is the number of neurons in the hidden layer, g (x) is the activation function, 
 is the weight value of the ith neuron in the input layer and the hidden layer, 
 is the bias value of the ith neuron in the hidden layer, 
 is the weight value of the first neuron of the output layer and  the hidden layer, 
 is the actual output value, the hidden layer output T can be expressed as:

The output matrix H of the hidden layer can be expressed as follows:


 

(20)

The output weight matrix of the hidden layer can be expressed as: 
, the output matrix of the fitting is as follows: 
 its biggest feature is that the connection weight matrix between the input layer and the hidden layer, and the offset of the nodes in the hidden layer only need to be initialized randomly once, without updating through the traditional back propagation algorithm. The only calculated one is the weight matrix between the hidden layer and the output layer, which can be obtained by the method of finding the generalized inverse matrix. Algorithm flow is as follows:



(21)



(22)

Step 1: Given the training dataset, randomly determine the hidden layer node parameters and input weights and thresholds.

Step 2: Select the activation function to calculate the output matrix H of the hidden layer.

Step 3: H is the generalized inverse matrix of the hidden layer output matrix, the least square method is used to calculate the output layer weight .

DELM
Although ELM has more advantages, it also has some problems. ELM is not suitable for constructing deeper network structure, it reduces the amount of computation and machine overhead. The weight β from the hidden layer node to the output layer node of ELM is solved by the generalized inverse matrix of the hidden layer output and the robustness of the model is not strong. ELM only considers the empirical risk, and neglects  the structural risk, so the data may be over-fitting, this problem can be solved by using the DELM [34,35,36]. DELM is a multiple-layer neural network, its learning procedure is highly efficient in learning time and has good generalization ability. Compared with ELM, DELM adds the restriction of regular term to prevent over-fitting. In this method, the regularized terms are constructed in the linear equations to solve the problem of insufficient computational stability and over-fitting, and the structural risk and empirical risk of ELM are balanced. DELM can obtain the output weight  by evaluating the loss function with the weighted least squares.


 
 
 

(23)

C is used to balance the empirical risk and structural risk of the learning machine. For the solution of the above-mentioned conditional extremum problem, the partial derivative is used after the Lagrange equation is converted to the unconditional extremum.

Therefore, for the DELM, the output weight  can be expressed as follows:


 
 
 

(25)

And the objective function y is as follows:


 

(26)

QPSO
PSO
Particle swarm optimization (PSO) [20] is a global optimization algorithm based on iteration, it  is easy to implement and has no many parameters to adjust. In particle swarm optimization, a group of particles is composed of m particles in d-dimensional space. The position of the ith particle is 
 and the velocity is 
. Each iteration of particles in particle swarm optimization algorithm updates its own velocity and position through individual extremum pbest and global extremum gbest. The updating formula of velocity and position is as follows.



(27)

where , m is the particle size; 
 is the d dimension of the individual extreme value pbest of the ith particle in the j iteration, 
 is the d dimension of the global extreme value gbest of all particles in the j iteration, w is the inertia weight factor, c1 and c2 are the particle acceleration learning factors, r1 and r2 are the random numbers between 0 and 1. Inertia weight W is used to balance the global and local exploration ability of particle swarm, which is very important for particle swarm. A large inertia weight is conducive to the exploration ability, but it has weak particle generalization ability. On the contrary, a small inertia weight is conducive to the fast generalization ability and leads to local optimization. In the current work, we propose a nonlinear decreasing inertia weight method to adjust the W value, taking further performance improvement as the equation:


 

(29)

where 
 and 
 are the maximum and minimum values of w, respectively, t is the current number of iterations and tmax is the maximum number of iterations.

QPSO
The main defects of PSO are that the global generalization ability cannot be guaranteed and there are too many parameters to be set, which is not conducive to find the optimal parameters of the model to be optimized. The change of particle position is lack of randomness and easy to fall into the trap of local optimum. In order to solve this problem, Sunetal proposed the quantum particle swarm optimization algorithm (QPSO) [37], it is inspired by the particle swarm optimization algorithm trace analysis and quantum mechanics. The algorithm cancels the particle's moving direction attribute and the updating of particle's position has nothing to do with the particle's previous motion. In this way, the random particles of particle's position are added and the particles are moved according to the following iterative formula,


 

(30)

where pbestij are the best positions of all pbests in particle swarm and mbestj represents the average best position of the particle history of pbest, and m represents the size of the particle swarm.



(31)

where pij (t) represents the update of the ith particle position, ∅ij is the random value generated by the unified probability distribution in the range of [0,1], 
 are the best global positions of all gbests in particle swarm, the iterative process of position of the ith particle is as follows.



(32)

Here, α is the contraction expansion factor, it is the only parameter controlling the particle generalization speed in the quantum particle swarm algorithm and it is very sensitive to the population number and the maximum number of iterations, we set the value range of α as (0.5,1), u is the random value generated by the unified probability distribution in the range of [0,1], xij represents the position of the ith particle, the combination of particle swarm optimization and equation (31) is quantum particle swarm optimization.

QPSO-DELM
Coal and gas outbursts are small sample data, the common logic regression and neural network are obviously affected and the DELM function maintains good performance, which makes it have obvious advantages under the condition that the sample data are  difficult to obtain. Because DELM randomly generates input weights and hidden layer thresholds, the generalization ability of the model is poor and the prediction accuracy is not ideal. In this paper, QPSO is used to optimize the input weights and hidden layer thresholds of the DELM, which greatly improves the prediction accuracy and efficiency of the DELM model. The flowchart is  as follows in Fig. 3:

Fig. 3
figure 3
Flowchart of proposed QPSO-DELM classifier model

Full size image

Experiment
Dataset description and preprocessing
The influencing factors of coal and gas outbursts include geological stress, gas and physical properties of coal seam. The experimental data come from the historical data of mine in Henan Province. With reference to previous literature [38], the coal and gas outbursts influencing feature  indexes include the following: gas pressure (1), initial velocity of gas output (2), initial velocity of gas emission (3), coal seam firmness coefficient (4), structural coal thickness (5), fault structure complexity (6). These indexes are operability, extensive and applicable in engineering practice. Gas outbursts are bipartition problem, namely 1 for the outburst type and 0 for the non-outburst type, as listed in column7. Table 2 gives a part of coal and gas outbursts sample data.

Table 2 Raw data for coal and gas outbursts
Full size table

In order to make the experimental results more objective, the method of tenfold cross-validation is used to verify the classification effect, that is, the dataset is randomly divided into ten parts, one of which is taken as the testing set in turn, the other nine parts are taken as the training set and then the corresponding classification method is run to classify and learn the data in the training set and the testing set is used to test, and the corresponding 10 times testing results are obtained. In this paper, according to the data distribution characteristics of coal and gas outbursts, due to the use of different units in the acquisition, there are great differences in the order of magnitude, which affects the convergence speed and accuracy of the algorithm. Before training the model, this paper uses the normalization method to process these data into new data within the range of [0,1] and removes the dimension to make the indexes more comparable.

Experimental environment and parameter setting
The validity of the algorithm is further verified by comparing experiments on real datasets. All experiments are completed on a CPU with the main frequency of 2.8 GhZ and a PC with 4 GB memory. The operating system is windows7 and the algorithm is implemented in Python 3.7 environment. In order to eliminate the random factors, we perform ten times with different random seeds on each experiment. The average performance of these ten repetitions is regarded as the final result. The classifiers  such as (SVM, KNN, RF, DT) might be sensitive to the values of its main controlling parameter, we use grid search optimization to tune all kinds of parameters. The wavelet basis function is DB4, the number of decomposition layers is 3, the parameters of the DELM and SVM are selected by QPSO and 10 cross-validation. According to the above evaluation parameters, the overall accuracy, precision, sensitivity, specificity are obtained according to reference. True TP indicates the number of samples correctly marked for application, true negative TN indicates the number of samples correctly marked for application, false negative FN indicates the number of samples incorrectly marked for application and false negative FP indicates the number of samples incorrectly marked for application.


 

(35)

Experimental results and analysis
Performance of DWT
As can be seen from Figs 4 and 5 and Table 3, the accuracy of the four algorithms are shown with the increasement of different independent components of FIC, the accuracy of DWT + FICA on different classifiers are higher than that of FICA. At the same time we also find out that the prediction accuracy of different feature extraction with different classifiers is the highest when the independent component is FIC3.

Fig. 4
figure 4
Comparison of FICA feature extraction

Full size image

Fig. 5
figure 5
Comparison of DWT + FICA

Full size image

Table 3 Accuracy comparison of different components of FIC using different classifiers
Full size table

The results show that when the number of independent components is too low, it is difficult to completely separate the independent information carried in the feature and the independent components decomposed cannot express the sample information. When the number of independent components gradually rises, the independent information in the influencing factors can be separated one by one to fully express the sample information it represents, which leads to the improvement of the final discrimination accuracy. When the number of independent components reaches a certain level, the prediction accuracy of the discriminant model is stable. The accuracy does not continue to increase with the increase in independent number. At the same time, a certain feature of the sample may be reflected in multiple features. In order to avoid the complexity brought by feature redundancy and interference to the stability of the model, it is necessary to eliminate the features describing the same sample property in different dimension spaces and compress the sample data while mining the sample difference features. The characteristics of DWT + FICA can solve this series of problems very well, which is very helpful to improve the signal-to-noise, enhance the statistical independence and non-Gaussian of the feature and separate the components as independent components with non-Gaussian as independence measure.

Performance comparison of different feature extraction methods
In order to verify the accuracy and validity of the FICA–LDA feature extraction proposed in this paper, all kinds of feature information such as linear feature, Gaussian feature, non-Gaussian feature, nonlinear feature and any two features are extracted to form new feature vector, respectively. SVM and ELM classifiers are used to classify and the classification results are compared with the methods proposed in this paper. Here we mainly compare the effects of several different feature combinations. From Tables 4 and 5, it can be seen that after FICA, KPCA, PCA, LLE and LDA are combined on the two classifiers, the accuracy of algorithms is improved. Among them, FICA–LDA feature extraction is the best way to extract features on ELM, with the accuracy 0.99, which is higher than that of KPCA–LDA, PCA–LDA and LLE–LDA. The indexes of SVM can be slightly lower than that of ELM, this is because after the original data is decomposed by FICA, the feature points of the original feature are compressed and the redundant information in the feature is also removed, the relatively independent information in the original feature is mined by using the characteristics of high-order moments of the dataset, so that the feature information covered by the original cross-feature can be effectively separated from each other, which can improve the modeling effect. The LDA removes the redundancy and obtains the characteristics of the optimal discrimination, so we can establish a discrimination model based on this kind of information through LDA on the basis of FICA, which has a better discrimination effect and improves the classification performance. KPCA, PCA and LLE are linear and nonlinear feature extraction methods, respectively, and their effects are close to FICA.

Table 4 Comparison of different feature extraction using SVM
Full size table

Table 5 Comparison of different feature extraction using ELM
Full size table

The coal and gas outbursts influencing factors have the characteristics of non-Gaussian distribution and high nonlinearity. The traditional feature extraction methods only consider the information maximization while neglects the cluster structure information of the sample data, which leads to the incomplete feature extraction. The features are linear and each feature has non-Gaussian characteristics, which are the complex of Gaussian signal and non-Gaussian signal. FICA–LDA feature extraction is very suitable for the prediction of outbursts in this paper, it can effectively select feature information and ensure the integrity of the information to achieve better classification results. From the different indicators of the two classifiers, we can see that the effect of various indicators obtained by FICA–LDA feature extraction is not only higher than that of the single feature method, but also is the highest in various feature combinations. It shows that the combination of FICA–LDA feature extraction can extract more features and improve the classification accuracy.

Comparison of different kernels function using ELM and DELM
From Tables 6 and 7, we can see that the accuracy and execution time of different kernel functions of ELM and DELM algorithms with different hidden layers are compared. Among the four kernel functions, the accuracy of Tan and Relu kernel functions with ELM and DELM are the best, which are 0.98 and 0.99, respectively, and the execution time is 0.006 and 0.0019 s, respectively. The overall performance is the best with DELM, for the model established by the algorithm, the training accuracy of Softwax and Sigmoid kernel functions are about 0.95 and 0.98 for outbursts datasets, which are lower than that of DELM model and the execution time is long. Sigmoid kernel function obtains the worst effect with ELM classifier, only the accuracy is 0.95 and the time is 0.006 s. The effect of kernel functions with DELM is better than that of ELM. From Figs. 6 and 7, we can also see that when the number of hidden layer nodes in ELM changes, the accuracy also changes. When the number of hidden layer nodes in ELM increases from 2 to 7, the accuracy increases slowly. When the number of hidden layer nodes is 3, the accuracy is the highest. When the number of hidden layer nodes is higher than 3, the accuracy begins significantly less.

Table 6 Comparison of different kernel functions using ELM
Full size table

Table 7 Comparison of different kernel functions using DELM
Full size table

Fig. 6
figure 6
Comparison of different kernel functions using ELM

Full size image

Fig. 7
figure 7
Comparison of different kernel functions using DELM

Full size image

Compared with the ELM learning models, DELM model realizes the function of adding regularization to prevent over-fitting and it can still maintain the characteristics of rapid learning. The training classification accuracy of DELM model is higher than that of ELM and the testing time is lower, which shows that optimization can make the model classification result more stable. Compared with all kinds of kernel functions, the model with Tan function as activation function has higher accuracy, shorter execution time and more stable performance. Therefore, we choose the DELM model as the classifier after considering the relationship between the execution time and the accuracy. The number of the best hidden layer nodes is set to 3 and the best kernel function is Tan kernel function. Under the premise of less training time, we can get higher training accuracy.

Performance comparison of different processes of ours using different classifiers
From Tables 8 and 9, we can see the experimental comparison of various indicators on two different classifiers at different stages of ours. Only the classification accuracy is compared here and other indicators are shown in the Table. For SVM classifier, the classification accuracy of DWT + FICA–LDA is 0.99, which is higher than that of DWT + FICA and DWT + LDA. DWT + FICA–LDA on DELM classifier can obtain the highest accuracy, this shows that the combination of DWT + FICA–LDA can produce good prediction accuracy. FICA only relies on high-order statistics information, which can effectively extract non-Gaussian components and global information of process data and reduce the complexity of detection model. But FICA is an unsupervised learning method, it can’t extract all kinds of correlation information between class label and feature, which reduces its accuracy and sensitivity in feature extraction. LDA can find an optimal projection matrix, so that the feature space can get a new feature space after this matrix mapping and each class in the new feature space is easier to be identified and the dimension can also be reduced. LDA only relies on the second-order statistics information and obtains the local information. The main variables obtained are uncorrelated and they cannot fully represent their statistical characteristics. In this way, FICA and LDA feature extraction methods are combined with each other, with the complementary advantages and the feature information of coal and gas outbursts extraction are complete. From Tables 7 and 8, we can also see that the QPSO and PSO algorithm are compared with the different classifiers of SVM and DELM. In terms of accuracy and other indicators, the QPSO algorithm can achieve 1 accuracy. Compared with PSO, the accuracy is improved and the running time is less, but the accuracy of SVM keeps the same. This shows that the combination of different classification algorithms and appropriate optimization algorithms is very important for the prediction effect.

Table 8 Performance comparison using SVM
Full size table

Table 9 Performance comparison using DELM
Full size table

Comparison with the existing methods in literatures
It can be seen from Table 10 that compared with the models in the literatures, the method proposed in this paper has excellence results, the accuracy is 1 based on the same dataset. Compared with KPCA + ELM, KPCA + PNN, this proposed method adopts DWT to perform the feature denoising and FICA–LDA is used in feature extraction, then the strong nonlinear fitting ability of DELM is used to achieve better prediction results, with the accuracy increased by 0.16, 0.11, respectively; compared with ISOMAP + WLSVM, PCA + SVM, FA + RF, the effect of proposed method in this paper is more effective, with the accuracy increased by 0.17, 0.15, respectively, it can achieve less consumption of calculation time and lower feature dimensionality on the premise of a high accuracy. Consequently, we can conclude that the proposed method has an advantages in combination of property in training time and testing accuracy than the other compared methods.

Table 10 Comparison with different algorithms in literatures
Full size table

At the same time, we also compare their performances in terms of running time for real data. It can be seen from Table 10 and Fig. 8 that the running time of ours is 1.40 s, which is lower than most methods. Moreover, it can predict outbursts according to the distribution characteristics of coal and gas outbursts sample data, which not only has better classification performance, but also has a low running time. The other methods are between 2.01 s and 2.55 s. Because these methods have the defect of high complexity, which make them more time-consuming. The advantages of our proposed methods are significant compared with most methods. Therefore, comprehensive analyses demonstrate that the proposed method is effective in feature extraction and classification performance for coal and gas outbursts prediction.

Fig. 8
figure 8
Computation time at different stages of proposed method

Full size image

To sum up, our proposed method has higher prediction accuracy and average computation cost over the compared prediction methods in prediction of coal and gas outbursts. However, the proposed model has some defects. The proposed model has only been validated on one available dataset, but the different datasets should be tested in order to achieve better generalization performance. The current work deals with solving a two-class problem, however solving a multi-class problem is highly in demand. Further, ours requires more time cost to obtain the high accuracy, so a model with less computation time can be investigated in future.

Statistical significance test
In order to evaluate the effectiveness of our proposed method, the statistical analysis of ours is compared with other feature extraction models mentioned in the literatures. In this paper, a statistical significance test called a binomial test is conducted between ours and other methods. A brief description of the binomial test is given below according to reference [20], we compare the accuracy of the proposed with the accuracy of others in literatures. The results are achieved and the confidence interval is set to 0.95. Table 10 shows the E-value of independent sample binomial test. If E-values is small,  ours is better than the other models  with high confidence, it means that there exits significant difference between the two methods. From the result, it shows ours is better than the other methods with high confidence for this problem. The values are less than 0.05, it proves that the performance of ours is better than others. According to the results of Table 11, there are not values more than 0.05, which shows the performance of ours has much different with other methods, ours can obtain the highest accuracy compared with other methods in literatures.

Table 11 Comparison of traditional methods and ours using binomial test
Full size table

Conclusion
Considering the noise components in coal and gas outbursts influencing factors, this paper introduces the DWT into the feature preprocessing of coal and gas outbursts influence factors and reasonably eliminates the random fluctuation and noise feature information, which contributes to improve the  prediction accuracy of coal and gas outbursts. Due to the complexity of coal and gas outbursts, the components obtained by DWT have redundant and uncorrelated information, which can't get better noise reduction effect, the coal and gas outbursts have nonlinear and non-Gaussian, on the basis of the above, this paper deeply analyzes the combination of FICA and LDA algorithms, which can capture the essential information contained in it as much as possible and uses the non-Gaussian to separate the components as independent components. In view of the incompleteness of information extracted by FICA, we input the features and class labels separated by FICA into the LDA supervision layer, projects the features and makes the features have class differentiation, carry out feature fusion and dimensionality reduction, extract Gaussian feature components and eliminate the redundancy and correlation between features, then the new features are formed; in view of the randomness of the parameter setting of DELM algorithm, the QPSO algorithm is applied in the optimization of DELM parameters and the coal and coal and gas outbursts prediction model based on QPSO-DELM is proposed, then the prediction accuracy of the model is significantly improved. Through example verification and comparative analysis, it is proved that the proposed model has strong generalization ability and high prediction accuracy, and it can be applied in the fields of coal and gas outbursts prediction. In the future, we will verify the proposed methods on different datasets of coal and gas outbursts, improve the generalization ability and adaptability of the model, and provide new ideas and effective technical means for coal and gas outbursts prediction.

