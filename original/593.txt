Abstract
In this paper, dispersed knowledge – accumulated in several decision tables is considered. Dispersion of knowledge is not a part of the work of the system. We assume that the knowledge is already in the dispersed form when it provides to the system. An advanced process of detecting the relations between the decision tables and constructing coalitions is used. The purpose of this paper is to use the measure to determine the strength of the coalition. With this method, a simple method of combining vectors of decisions generated based on local decision tables was applied. The purpose of using the Shapley-Shubik index was to reduce the computational complexity compared to the approach proposed in the earlier papers. In this paper, the results of experiments are presented, and the two approaches are compared. Based on these results, some conclusions have been drawn.

Keywords
Knowledge-based systems
Group decisions and negotiations
Global decision
Dispersed knowledge
Shapley-Shubik power index

1. Introduction
An approach in which joint decisions is made by separate entities – agents – has a wide range of uses. Agents make local decisions based on local knowledge that is available only to them. It can be assumed that this local knowledge is stored in the form of a set of local knowledge bases, or more specifically, a set of local decision tables. Of course, local knowledge can have various forms. By various forms, we understand the possibility of conducting an inference that is based on local decision tables in which sets of conditional attributes and sets of objects are quite diverse. An important assumption that must be satisfied is that all of the knowledge that is used needs to be related to the same domain.

More specifically, in this paper, a situation in which the following assumptions are adopted is considered. We have access to a set of decision tables. The knowledge in these tables was collected independently, but the same decision attributes are presented in all of the tables. There are no restrictions on the sets of conditional attributes or the sets of objects in the decision tables. Different tables may have common conditional attributes (or objects), but this is not necessary. This type of data are called dispersed data. Our goal is to use all of the decision tables and to make a decision for the values that are specified on the conditional attributes that occur in all of the tables.

In [39] and in other papers [10], [41], [47], the concept of distributed decision-making can be found. The main difference between distributed and dispersed concepts is that dispersed data is less constrained, and its structure is less specified. In dispersed data, both objects and attributes can be shared among local tables. In addition, we can not even check whether the common objects occur in separate tables because the objects' identifiers are not unique and uniform for all tables. In this way, we want to reflect the real situation in which knowledge is collected in dispersed form. We only know that a common decision attribute exists in all local decision tables. In distributed data, usually, we can identify objects between local tables. Also, typically, data is stored originally in a single table, and then the partition method (horizontal or vertical partitions) is applied for the data.

Voting is one of the most popular ways to aggregate the agents' decisions. Very often, the weights are assigned to agents. The standard weighted voting procedure considers counting the sum of the agents' weights that are in favour of some outcome. If this value is larger than or equal to a given quota, then the decision that is taken is equal to this outcome.

The agents' actual influence on the outcome of the weighted voting is not equal to the agents' weight. An extreme case can be a game in which the given quota is equal to the sum of all players' weights. Then, only a coalition consisting of all the agents may take a decision. Therefore, an agent with the smallest weight assigned has the same impact on a global decision as an agent with the highest weight value. Many methods for calculating the power of agents in the weighted voting game can be found in the literature [7], [11], [40], [24], [3], [28], [29]. The choice of the power index calculating method should always be considered in the context of a given problem. The power indexes are characterized by various properties, such as efficiency, symmetry, null player, strong monotonicity, transfer and mergeability. The power index that should be used in a given situation is often considered through the prism of these properties.

1.1. A brief review on the previous research
The concept of making decisions based on dispersed knowledge was considered in the papers [33], [34], [35], [36], [37]. The main novelty of this paper is to use the Shapley-Shubik power index in a dispersed decision-making system. This approach is completely different from the approaches that were used in previous papers. In this article, we combined issues from multiple classifier systems with issues that are related to game theory.

In the paper [35], a decision-making system with a dynamic structure that is created using a negotiations stage was proposed. In this system, a group of agents that are called clusters are formed. It was concluded that in the approach with negotiation, the clusters are more complex, and therefore that they better reconstruct and illustrate the agents' views on the classification. However, when the effectiveness of the system's inference was compared, it was found that a better method for generating clusters is not reflected in the final result. The cause of this was the method of conflict analysis that was used, which did not take into account the power of the agents. In order to overcome these drawbacks, two different approaches were considered. The first approach was proposed in the paper [37]. A modification of the method of conflict analysis, which consists of calculating the agents' weights expressed by the number of agents in the cluster or by statistical measures of the vectors generated by the agents, was described there. The second approach uses measurements from the game theory – Shapley-Shubik power index – to determine the agents' strength. In this paper, we present numerous experiments that were performed on dispersed data that had different degrees of complexity. We also compared the results obtained with the results from the papers [35], [37]. The results that were obtained indicate that the use of the agents' strength provides much better results compared to a situation in which the weights are not used.

As was mentioned earlier, part of the methodology that is used in this article is taken from the paper [35], in which a system with a negotiation stage was proposed. A description of the creation of the system's structure is as follows. A test object for which we want to determine a global decision based on all of the available knowledge is given. A vector that describes the classification of a test object that is made based on the local base is generated for each local knowledge base. Relations between the local decision tables are defined. We distinguish three types of relations – friendship, conflict and neutrality. The local decision tables are combined into coalitions that agreed on the classification of the test object. This is accomplished in a process that consists of two stages. In the first step, groups consisting of the local decision tables in a friendship relation are created. The second step involves re-analyzing the coalitions that were created in the previous step. This is a negotiation process in which decision tables in a neutrality relation are attached to the initial coalitions.

When the coalitions, so the structure of the system is created, decisions within coalitions are made. For this purpose, two methods are used. The first, simple method does not resolve inconsistencies in the knowledge. The purpose of the second method, much more complicated and computationally complex, is the elimination of inconsistencies in the knowledge. This method was proposed in the paper [33]. Both methods are described further in this paper. This paper's main goal is to use the Shapley-Shubik index in the dispersed decision support system and show that if we calculate the coalitions' strength properly, then the process of knowledge aggregation can be significantly simplified without loss of the quality of the decisions made.

1.2. The motivation and advantage of the new method
The importance of the novelty introduced in this paper can be illustrated in the following example taken from the medical domain. Suppose we have a set of hospitals with oncology departments. Each hospital has its local decision table with information about historical patients. Information about the performed tests as well as the diagnosis is stored in the table. Each hospital has different patients, but some patients may be common. Moreover, each hospital may use other evidence for diagnosis (could perform different tests), which does not have to be consistent with other units. We want to diagnose a new patient using the knowledge from all these hospitals. We are creating coalitions of hospitals that are consistent with the diagnosis. If, however, a coalition of hospitals with high confidence in their diagnosis will not have a greater impact on the final decision than the impact of only one hospital that is moderately confident about his diagnosis, then all the efforts to create coalitions will be wasted. The power index will be used to calculate the power of each hospital. A separate simple game will be defined for each decision's value. The power index value will be assigned proportionally to the hospitals' certainty in making the decision. Then, the coalition's strength will be determined based on the aggregated values of the coalition's members' power index.

There are three basic motivations for the present research. The first motivation is to take advantage of complex coalitions generated by the method with the negotiation stage. If the coalitions' strength and structure are not taken into account in the final decision-making process, the advanced analysis of relations between agents makes no sense. All the efforts to create complex structures is wasted in such a decision-making method. That is why it is necessary to define the strength of agents and, consequently, the strength of coalitions.

The second motivation is an application of the game theory issues to dispersed data. The Shapley-Shubik power index is used because it is best suited to analysing the distribution of profits resulting from building a coalition (in our case, the profit is the influence on the final decision). Shapley [40] wrote that an agent's strength should be a measure of the expected payoff. Moreover, this index is subject to very few paradoxes compared to other indexes and is the measure that is formally the clearest and has the least restrictive assumptions. Nevertheless, the game theory provides many tools to assess agents' strength efficiently and determines optimal decisions. It is planned to use other methods in future work.

The third motivation is to simplify the method of aggregating knowledge within the coalition. Since we emphasise using the advantages from complex coalitions, it may not be necessary to use a computationally complex method of aggregating knowledge within the coalition. Research shows that when using the power index and a simpler aggregating method, the obtained results are not worse, and in some cases even better, than for the advanced method of coalition's knowledge aggregation.

Numerous experiments that were carried out using the proposed approach are presented in the paper. The main contributions of this paper are listed below:

•
application of the Shapley-Shubik index to determine the agents' strength in a dispersed decision-making system

•
a new method for generating the local decisions within one cluster

•
a new method of determining a set of global decisions

•
the results that were obtained were compared with the results that were obtained in the papers [35], [37].

The first advantage of the proposed new method is taking full benefits from the complex coalitions' structure in the decision-making process. The second advantage is the simplification of the coalition's knowledge aggregation method without obtaining worse results.

2. Related work
The purpose of the power indexes is to measure the influence of agents on the outcome of a vote. L. Shapley and M. Shubik [40] and J. Banzhaf in [7] proposed the most popular power indexes. The essence of these indexes is to calculate the probability that the coalition will change to winning from losing when an agent joins the coalition. The difference between the Shapley-Shubik power index and the Baznhaf index is the way for counting the coalitions. The papers [46], [25], [22] present other methods for calculating the agents' power. There are indexes based on minimal winning coalitions, such as the Deegan-Packel index, the Holler index or the Johnston index [24]. In the literature, indexes with pre-coalitions that perform more sophisticated analysis can also be found [28], [29]. In such indexes, some meta-knowledge is necessary about agents who are unlikely to form coalitions. Power indexes found a large number of applications. In the paper [17], the Shapley value is used to obtain an inconsistency measure that indicates the contribution of each formula to the overall inconsistency in the base. In the paper [4], this index was used to analyse the relative importance of sensors output. Based on the Shapley value, a method of quantifying the individual participant's contribution to the Crowd IQ was considered in the paper [5]. The Shapley index was used to resolve airport problems in the paper [2]. In the paper [16], the Shapley inconsistency values were defined in order to analyse inconsistencies in a distributed information system. In this paper, the Shapley-Shubik index was used in the process of decision making based on dispersed knowledge. Other indexes will be used in future work.

Decision support systems are computer technology solutions that can support complex decision making and problem-solving. Various aspects of decision support issues are discussed in the papers [42], [43]. The multi-attribute decision-making (MADM) problem is one of the approaches in this domain. Each agent determines its preferences for given alternatives based on a specific set of attributes in this approach. As in this paper, the issues proposed by Pawlak (the rough set theory) are used in the MADM methods. In the paper [53], the advantages of the rough set, the fuzzy set and the intuitionistic fuzzy rough set were used, and a method for determining the ranking of alternatives that is more flexible and has broader applications than traditional methods was proposed. In the paper [52], an extension of the fuzzy rough set model to two pairs of fuzzy rough set models was defined. The authors showed that the proposed model makes consistent decisions with traditional models but has wider applications. In this paper, a different approach to combining agents' decisions is used. Agents are rather classifiers that are built based on dispersed data here, and the agents' decisions are the predictions in the form of vectors over the decision classes. So the fundamental difference lies in the form of analysed data based on which decisions are made.

In the literature, the problem of making decisions based on set of local tables can be found in many papers. For example, in the ensemble learning approach [15], [20] this issue is discussed. The aim of a multiple classifier system is to reduce misclassification by constructing an ensemble based on base classifiers. An up-to-date survey on multiple classifier system was presented in the paper [50]. The adaptive weighted voting procedure to combine the binary classifiers was proposed in the paper [18]. A probabilistic framework for classifier combination for the majority vote and the weighted majority vote was presented in the paper [21]. Federated machine learning [38] is a new trend in data mining that considers dispersed data usage. The main assumptions adopted are as follows: data exists in the form of isolated islands, and data owners do not expose its data to others. Therefore, the main focus is put on the strengthening of data privacy and security. Some approaches that are considered in this paper can be applied with such assumptions.

Another approach to the classification problem based on several decision tables can be found in [8], [9], [19]. State-of-the-art algorithms and applications in distributed data mining can be found in the paper [51]. In Distributed Data Mining (DDM) methods, only horizontal or vertical partitions of the data are considered.

The processes of formulating the coalition and negotiations are very important in this paper. In [30], [31], [32] one of the methods for coalition formation was proposed. A conflict model that is described assumes that the agents want to use a peaceful method to analyse the conflict. Definitions of the relations – conflict, friendship and neutrality are given in the articles. The concepts that were provided by Pawlak are used in this paper.

An important issue of social interaction is the theory of negotiations and the formation of coalitions. These concepts are studied in the social sciences as well as in computer science. The various negotiation models are briefly discussed in [23].

Besides classification methods dedicated to dispersed data, in the literature, other problems in the context of dispersed data are considered. For example, clustering method for dispersed data is described in the paper [48]. A distributed dimension reduction algorithm for data obtained from geographically dispersed machines is proposed in the paper [1]. A distributed text mining system is defined in the article [54]. There are many methods dedicated to dispersed data that are based on Internet and gird computing. A detailed literature review can be found in the paper [51].

3. Simple games and power indexes
In this section, the game theory's basic concepts, which are significant in this paper, will be given.

Most games can be represented as simple games in which the participants of the game can either be for or against a given conclusion. We will consider the weighted voting systems, i.e. each voter is assigned a non-negative real number. The necessary and sufficient condition for the adoption of a given decision is that the coalition of voters for it reaches the amount determined by the decision-making rule. In this type of games, we define a winning coalition – a subset of voters that may independently decide and a losing coalition – a subset that does not have this ability. The definition of a simple game, which was taken from the book [45], is as follows.

Definition 3.1

Let N be a set of players. We say that 
 is a set of winning coalitions, if

1.
Ø – an empty set is a losing coalition,

2.
 – a coalition of all players is a winning coalition,

3.
if  and , then  – if S is a winning coalition, then each coalition containing S is also a winning coalition.

The simple game is a pair .
In a simple game we define a decisive player.
Definition 3.2

Let  be a coalition and  be a player. If the coalition S is a losing coalition, but adding the player j to the coalition S will change its status to a winning coalition, then the player j is a decisive player for coalition S.

An important concept is also a minimal winning coalition.
Definition 3.3

Let  be a winning coalition. If for each player in S elimination of this player from the coalition turns it to losing coalition then the coalition S is a minimal winning coalition.

The relative strength of the players does not respect the proportion of weights. Even players with different weights can have the same importance in forming the winning coalitions. Power indexes are used to calculate the relative strength of individual participants in the group decision-making process in terms of their demand for winning coalitions.

Various power indexes can be found in the literature [24], [3], [28], [29]. Historically the first of the power indexes is the Shapley-Shubik index. In this index, we assume that all of the arrangements of players are equally likely. The Shapley-Shubik index value for the player is equal to the probability that the player will be decisive for the coalition. The value of the Shapley-Shubik index for the player j can be calculated from the following formula(1)
 
 

The Shapley-Shubik index can be interpreted in terms of coalition formation by taking into account the permutations of the voters. Calculation of the strength of a given voter independent from the orders of voters in winning coalitions leads to the Banzhaf index. The value of the Banzhaf index for the player j can be established based on the following formula(2)
 

The Johnston index is based on the idea that a player's strength should be influenced by whether in a winning coalition she/he is the only participant whose defection is critical (strength should be greater), or whether everyone has such a possibility (that player's strength should be smaller). Let , we denote by  the set of critical players in S(3) The value of the Johnston index for the player j can be calculated based on the following formula(4)
 
 
 

The Deegan-Packel index is based on the minimal winning coalitions. It is assumed that a player's value resulting from belonging to a certain minimal winning coalition should be the same as the other player from the same minimal winning coalition. The value of the Deegan-Packel index for the player j can be calculated based on the following formula(5)
 
 
 
 These values are normalized.

The mentioned above indexes can be characterized by certain properties - rational expectations, postulates, or criteria regarding the power index. Sometimes selecting one power index for the specific application among the many available can be justified by these desired properties. Some properties that are important in our discussion are listed below:

•
A null player property: if in a simple game a given player is not necessary for any coalition to be a winning coalition, then the power index for such a player should be equal to 0 [24], [3].

•
A symmetry property: the value of a player should depend on her/his and other players' weights, not their labels [24], [3].

•
A efficiency property: the sum of the values of power index for all players is equal to 1 [24], [3].

•
A strong monotonicity: if a player in a given system has a weight greater than the other player, her/his power should not be less than that of the other player [24], [3].

•
A transfer property: the change in power depends only on the change in the voting game. In other words, if we have two pairs of simple games with the same set of players and the transitions from one game to another in one pair entail adding the same set of winning coalitions, then the differences of the power index values within both pairs of games are equal [12].

•
A mergeability property: power in a merged game that is a component from two games is a weighted mean of power in these games, with the weights equal to the number of minimal winning coalitions in each component game.

Table 1 shows the fulfilment of individual properties by the discussed power indexes. In the table, + means that the power index fulfils the property, and − means that it does not fulfil the property.


Table 1. Power indexes and fulfilled properties.

Power index	Null player	Symmetry	Efficiency	Strong monotonicity	Transfer	Mergeability
Shapley-Shubik	+	+	+	+	+	−
Banzhaf	+	+	−	+	+	−
Johnston	+	+	+	−	−	−
Deegan-Packel	+	+	+	−	−	+
It seems that violating certain property should not be the reason to limits applications of a given power index, but the properties can be some indicators. Moreover, the power indexes have certain characteristic interpretations. For example, the Shapley-Shubik index is undoubtedly the best suited for analyzing the distribution of profits resulting from creating a coalition. However, suppose instead of the profits from creating a coalition, the coalition partners talk about the blackmail related to its betrayal (for systems with unstable forms of cooperation, with a higher level of competition, with a strong level of political conflict). In that case, a better measure will be the Banzhaf index. Among the presented power indexes, the Johnston index most fully reflects the position of the president in the US legislative process. When we know that creating only minimal coalitions is highly probable (they guarantee maximum profits), then the Deegan-Packel index will be appropriate.

In the application of the power index to dispersed knowledge, we want to correlate power with the distribution of profits (the profit will be an increased influence on the final decision). The essential properties for the considered application are strong monotonicity and transfer, as they relate the power in two different games with the same set of players, and we will consider many simple games - separate for each decision value and test object. Efficiency is also important for the application. That is why it was decided to use the Shapley-Shubik index. Nevertheless, we do not exclude applying the other power indexes mentioned above to dispersed knowledge in future work.

The indexes discussed above are a-priori indexes, i.e. their calculations assume that possible coalitions are equally likely, regardless of voters' behaviour, preferences, and mutual orientations. Other types of indexes with defined pre-coalitions can also be found in the literature [28], [29]. However, some preliminary knowledge is needed about the possible coalitions when we want to use them. In the applications presented in this paper, we automatically classify (make group decisions) based on a set of local tables. Voters are classifiers generated from local tables, and it is difficult to define such initial knowledge of a priori unions structure. So, at the moment, it seems to be impossible to consider such indexes for dispersed knowledge.

Determining the values of the power indexes are quite complex and time-consuming. However, in the literature, we can find an approach of multilinear extension of game [27] that significantly simplify the calculations.

4. A dispersed decision-making system – basic notations
Before we proceed to the formal description of the decision-making process, we will first discuss it based on an example from the medical domain that was mentioned in Section 1.2. Thus, there is a set of local tables collected in oncology departments of various hospitals. We want to make a diagnosis for a new patient. The considered system is dynamic, i.e. a new structure (coalitions) is created for each test object. We use an approach based on similarity because we want to match the historical cases to the new patient as much as possible. The steps of the decision-making process can be described as follows:

1.
For each test object (new patient), we select similar historical cases and determine the vector over the decision values. This vector can be interpreted as the frequency of different decisions taken for similar historical cases.

2.
We determine coalitions of local tables with similar vectors. Again, we use a similarity approach to strengthen the decisions that are often made in the historical cases based on several local tables.

3.
Vectors of local tables within a coalition are aggregated. We propose two different methods for this purpose:

(a)
The first, deeper and more complex method consists of aggregating local tables by combining objects with the same values on common attributes in local tables. The objects in the aggregated table no longer correspond to real historical patients but are only connections of unequivocal diagnostic test and consistent decision.

(b)
The second method is much less complex and consists of simple transformations of the vectors from one coalition.

4.
The final decisions based on the coalitions' vectors are taken using the power index. The index is used in order to strengthen the influence of the more significant coalitions on final decisions.

As we can see, there are many levels in the decision-making process. Of course, there may be additional ones. For example, when determining the final decisions, feedback to coalitions' partners and possibly changing decisions can be used. Similarly, the aggregation of local tables can be realised in several stages. However, due to the already complex decision-making process, no such additional levels were considered.
Usually, the users of the decision system expect justification for the made decisions. In the process described above, such a justification will not be very clear and transparent. It would rather be based on showing the historical cases similar to the newly diagnosed patient (based on which the vector over the decisions was created). Further detailed justification could only be addressed to the advanced users. Of course, this is a disadvantage of the proposed solution.

The knowledge that is supplied to a dispersed system is stored in a set of local knowledge bases. All available knowledge is used in order to make global decisions. For this purpose, we will apply the concepts of conflict analysis proposed in [30]. In this model, an agent is able to determine its local decisions. The definition of a resource agent is given below.

Definition 4.1

A resource agent ag in Ag has access to the resources that are represented by a decision table 
, where 
 is a set called the universe; 
 is a set of conditional attributes, and 
 is a set of attribute a values that contain the special signs * and ?. The equation ⁎ for some 
 means that for an object x, the value of attribute a has no influence on the value of the decision attribute, while the equation  means that the value of attribute a for object x is unknown; 
 is referred to as a decision attribute and 
 is called the value set of 
.

In the above definition, it is not assumed that the sets of conditional attributes are disjoint. In addition, it is not assumed that the sets of objects are equal or disjoint. However, we assume that the knowledge accumulated in all of the decision tables relates to the same domain. What is reflected by the fact that in all of the decision tables the same decision attributes occur.

In this paper the Shapley-Shubik index was applied in a dispersed system in order to assess the importance of each of the agents during the decision-making process. In the dispersed system, we connect agents that make similar decisions into groups. During the preliminary experiments, the efficiency of inference was studied in a system in which groups of resource agents were not defined. A simple approach consisting in generating the global decisions with regard to the power of individual resource agents does not give good results.

4.1. The process of creating groups of agents
In this section we will discuss very briefly the method for generating groups of resource agents. In [35] the method of creating clusters – groups of agents was proposed. This method includes the negotiation stage.

Some of the concepts that are used in the process of creating clusters are based on the concepts introduced in [30]. These are concepts such as – a friendship relation, a conflict relation and a neutrality relation as well as a method for determining the intensity of any conflicts between the agents.

In the method, groups of resource agents that agree on the classification of the test object are created. In order to better illustrate the stages of creating coalitions, a diagram is drawn and presented in Fig. 1. As was shown in the diagram, the process of creating clusters is realised in two stages. At first, the initial coalitions are created. After that, the negotiation stage is carried out. The test object classification is the basis for these two steps. For each agent 
, a vector of values 
 (with dimension equal to the number of decision classes) is generated. This vector represents the classification that is made by the agent. Based on the vector of values, a vector of ranks 
 is specified. The relations between the agents and the intensity of conflicts are determined based on the vectors 
. Three types of relations between agents are used in the proposed approach: a relation of friendship, a relation of conflict and a relation of neutrality. The function 
 is defined for test object x and each value of the decision attribute 
; 
(6)
  where 
 and 
 is the j-th coordinate of the vector of the rank 
. The distance between agents 
 is defined for test object x: 
(7)
 
 where 
.

Fig. 1
Download : Download high-res image (195KB)
Download : Download full-size image
Fig. 1. Stages of the process of creating clusters.

Definition 4.2

Let p be a real number that belongs to the interval . We say that agents 
 are in a friendship relation due to the object x, which is written 
, if and only if 
. Agents 
 are in a conflict relation due to the object x, which is written 
, if and only if 
. Agents 
 are in a neutrality relation due to the object x, which is written 
, if and only if 
.

The first step involves the creation of initial clusters – groups of agents that remain in a friendship relation. In the second step, the negotiation issues are applied and agents who are neutral are joined with an existing groups. In the second stage of clustering, the generalised distance function is used in order to determine the intensity of the conflicts between the two groups of agents. The function 
 is defined for test object x; 
(8)
 
 where 
 and 
 is the set of significant decision values for the pair of agents 
, 
. The set 
 contains the decisions for which agents 
 or 
 gave the highest rank. The generalized distance between agents 
 is defined for the test object x; 
(9)
 
  where . For two subsets of agents X and Y the value 
 is equal to the average difference of the ranks assigned to significant decisions for pairs of agents that belong to the set . By using this function, undecided agents are attached to the initial clusters. If the generalized distance does not exceed a certain threshold, then the agent without a coalition is included to the initial clusters. The threshold value is set by the system's user.
In order to demonstrate the method for generating the groups of resource agents, we investigated an example.

Example 4.1

Let it be given a dispersed system in which the set of agents is 
 and 
. For each resource agent, a decision table 
, , is defined. These tables have not been generated from a single table, we assume that they were accumulated separately in different centres. Therefore, as was mentioned earlier, the tables have different sets of objects and attributes. Test object x is described in Table 2.


Table 2. Conditional attribute values for test object x.

a1	a2	a3	a4	a5	a6	a7	a8	a9	a10	a11	a12	a13
x	4	3	2	4	3	2	4	4	3	3	2	2	4
The relations of friendship, conflict and neutrality between agents are defined first. The objects from decision tables are given in Table 3; the values of the similarity measure 
 (the Gower measure is used, see [37]) of the objects to the test object are also given in this table. Table 4 gives the vectors 
 and 
. For each pair of resource agents the value of the distance function is calculated. These values are given in Table 5.


Table 3. Decision tables of the resource agents.

a1	a2	a3	a4	a5	d	
4	4	4	4	3	v1	
 
3	4	2	4	4	v2	
 
4	2	4	4	3	v3	
 
3	3	3	3	3	v4	
 
3	3	2	4	3	v5	
 

a5	a6	a7	a8	d	
4	3	4	3	v1	
 
4	4	3	2	v2	0
2	3	4	4	v3	
 
3	3	2	4	v4	
 
3	4	2	4	v5	
 

a7	a8	a9	a11	a12	d	
3	3	3	3	4	v1	
 
3	4	3	3	4	v2	
 
4	4	4	3	3	v3	
 
3	2	3	4	4	v4	
 
4	4	4	4	4	v5	
 

a1	a2	a10	d	
4	4	4	v1	
 
3	3	4	v2	
 
4	3	4	v3	
 
3	2	4	v4	0
3	3	3	v5	
 

a3	a9	a11	a12	d	
4	2	3	4	v1	0
2	4	4	3	v2	
 
2	4	4	2	v3	
 
3	3	3	4	v4	
 
4	2	4	4	v5	0

a6	a12	a13	d	
3	3	4	v1	
 
2	2	4	v2	1
3	4	4	v3	
 
2	4	4	v4	
 
2	4	3	v5	
 

a4	a5	a10	a11	a12	d	
3	3	2	2	3	v1	
 
4	4	3	4	3	v2	
 
3	3	3	2	4	v3	
 
4	3	4	4	4	v4	
 
3	4	4	4	4	v5	0

Table 4. Vectors of values 
 and vectors of ranks ri.

Resource agent	Vector of values 
Vector of ranks 
ag1	[0.6, 0.4, 0.6, 0.4, 0.8]	[2,3,2,3,1]
ag2	[0.25, 0, 0.5, 0.5, 0.5]	[2,3,1,1,1]
ag3	[0.2, 0.4, 0.4, 0.2, 0.4]	[2,1,1,2,1]
ag4	[0.33, 0.33, 0.67, 0, 0.67]	[2,2,1,3,1]
ag5	[0, 0.25, 0.5, 0.25, 0]	[3,2,1,2,3]
ag6	[0.33, 1, 0.33, 0.67, 0.33]	[3,1,3,2,3]
ag7	[0.4, 0.4, 0.6, 0.4, 0]	[2,2,1,2,3]

Table 5. Distance function between agents ρx.

Resource agents	ag1	ag2	ag3	ag4	ag5	ag6	ag7
ag1	0	0.4	0.6	0.4	1	1	0.8
ag2		0	0.4	0.4	0.8	1	0.6
ag3			0	0.4	0.6	0.6	0.4
ag4				0	0.6	1	0.4
ag5					0	0.4	0.2
ag6						0	0.6
ag7							0
Then the clusters are created. In the first step, the initial clusters are defined. In the definition of friendship relation 4.2 we have parameter p. Let it will be equal to . The condition 
 is fulfilled for only one pair of agents 
. Thus, only one initial cluster 
 is generated. In the second stage for each agent that has not been included in any initial clusters, the value of function 
 (Formula (8)) and the value of generalized distance function (Formula (9)) are calculated for each initial cluster and for each agent without a coalition with which the agent is not in a conflict relation. When calculating the function values 
 the set 
 contains decisions to which agents 
 or 
 gave rank 1. The functions values are given in Table 6, Table 7. In the case when agents are in conflict, the corresponding cell in Table 7 contains the sign X.


Table 6. Function 
.

Resource agents	ag1	ag2	ag3	ag4	ag5	ag6	ag7
ag1	0	1	1	0.5	1.5	2	1.5
ag2		0	0.75	0.67	1	1.75	1.5
ag3			0	0.33	1	1.33	1
ag4				0	1	1.67	1
ag5					0	1.5	0
ag6						0	1.5
ag7							0

Table 7. Generalized distance function between agents.

ag1	ag2	ag3	ag4	{ag5,ag7}	ag6
ag1	0	1	1	0.5	X	X
ag2		0	0.75	0.67	X	X
ag3			0	0.33	0.67	1.33
ag4				0	0.67	X
{ag5,ag7}					0	1
ag6						0
Illustration of the conflict situation is given in Fig. 2. Agents and initial clusters are represented by circles. A pair of circles is linked, if a pair of agents is in neutrality relation. Cluster is represented as a clique. The clique is the subset of vertices such that every two vertices are linked. The function value 
 is calculated for each clique. If this value does not exceed the threshold, a cluster is created. The formula for calculating the threshold was given in [35] 
. Three clusters are generated 
, 
 and 
. The generalized distance is smaller than the threshold value 
 
, 
 
 and 
 
.

Fig. 2
Download : Download high-res image (31KB)
Download : Download full-size image
Fig. 2. Graphical representation of conflict situation.

In the paper [35] a computational complexity of this method has been discussed. The method has an exponential complexity due to the number of resource agents. The number of resource agents in the system is rather small; therefore, the algorithm execution time is short.
4.2. The structure of the system – synthesis agents
The proposed dispersed system has a hierarchical structure. A superordinate agent is defined for each cluster that contains more than one resource agents. This agent is called a synthesis agent, 
, where j – number of cluster. Definition of a dispersed system is as follows.

Definition 4.3

By a dispersed decision-making system with dynamically generated clusters, we mean
(10)
 where Ag is a finite set of resource agents; 
 is a set of decision tables of the resource agents; 
 is a finite set of synthesis agents defined for the clusters that are dynamically generated for test object x, 
 is an injective function that each synthesis agent assigns to the cluster that is generated due to classification of object x.

4.3. Local decisions within one cluster
In this section, two methods of generating the local decisions of synthesis agents are described. The first method is proposed in this paper, and the second method is taken from the previous paper of the author. In both methods, local decisions are determined as a certain vector of values. The first approach calculates the vector of the values for the synthesis agent by making simple arithmetic transformations of the vectors that have been assigned to the resource agents that belong to the subordinate cluster. The second approach is more complex and involves the elimination of inconsistencies in the knowledge that has been accumulated in the decision tables of the resource agents that belong to one cluster. This approach was proposed in [33]. The power index value for the synthesis agent will be determined using the local decisions. The global decisions will be taken with regard to the power indexes of the synthesis agents and the local decisions that are generated.

4.3.1. The aggregation of the vectors that determine the level of certainty with which resource agents make the decisions
For each resource agent we have a classification of a test object stored as the vector 
. Now we want to generate classification that is made by the cluster. For this purpose we make simple arithmetic operations on the vectors 
 that are assigned to the resource agents 
. At first the vectors(11)
 are transformed according to the formula 
 
.

In order to determine the level of certainty with which a decision is taken by the synthesis agent, the sum of the vectors that are assigned to the resource agents that belong to the cluster can be calculated. We have to remember that in the method of creating clusters, the groups of agents are not disjoint. Thus, one agent may be included in many clusters. If several clusters contain the same agent, the agent can not be fully involved in any of the clusters. In such situations, the partial participation of the agent in the cluster's creation is calculated. Thus, in the first stage in the process of determining local decisions, the degree of the membership of each agent in the clusters is calculated.

Let there be a given dispersed decision support system 
, 
 is a classified object}. For each resource agent  and test object x a coefficient of agent's membership in clusters is calculated(12)
 
 This value is inversely proportional to the number of clusters that contain the agent.

Then, according to the formula(13)
 
 the vector of values is determined for j–th cluster. The formula above is the weighted average of vectors 
 from one cluster. The weights are equal to the coefficient of agent's membership in clusters.

In order to demonstrate the method for generating the local decisions within one cluster, we investigated an example that is presented at the end of Section 4.3.

Note that the method mentioned above has a linear complexity of computing due to the number of resource agents, the number of synthesis agent and the number of decision values. In order to explain the complexity, let us analyse the method's steps. The transformation of the vectors that are assigned to the resource agents has a complexity of 
. Calculation of the coefficients of agent's membership in clusters has a complexity of 
. Calculation of the weighted average of the vectors has a complexity of 
. Furthermore, because the number of resource agents, the number of synthesis agent and the number of decision values in the system is rather small, the algorithm execution time is short.

4.3.2. Elimination of inconsistencies in the knowledge – the approximated method of the aggregation of decision tables
The approximated method of the aggregation of decision tables is a more complicated and computationally complex method. The essence of this method is to generate coherent knowledge on the basis of the decision tables of the resource agents from one cluster. Inconsistencies of knowledge may occur within clusters because there are no assumptions about the form of the sets of objects or the sets of attributes. A situation in which contradictory decisions are made based on two decision tables that have common conditional attributes and for the same values for common attributes is an inconsistency of knowledge.

Different definitions of inconsistencies in the knowledge can be found in the literature. For example, in the paper [16], an inconsistency between distributed sources is modelled with respect to some integrity constraints. The authors assumed that they had a priori set of integrity constraints based on the context, and they queried each source to get the answers. The inconsistencies are resolved by removing the facts from answers. In the paper [13], an inconsistency is considered to be a violation of the constraints that are expressed by conditional functional dependencies. Inconsistency in a decision table is a situation in which two objects are indiscernible in terms of the available knowledge, but they have different decision values. One of the methods that can be used to eliminate such an inconsistency is to use the generalised decision function [44]. As was mentioned earlier, a different approach to the inconsistencies in the knowledge was adopted in this paper.

In the approximated method of the aggregation of decision tables, a set of new decision tables is created, on the basis of the decision tables of resource agents. An aggregated decision table is created for each synthesis agent. This table is defined based on relevant objects from the decision tables of resource agents from one cluster. The relevant objects are the objects that have the greatest similarity to the test object. From each local decision tables, 
 relevant objects are selected. The parameter 
 is chosen experimentally. If the values of the decision attribute and common conditional attributes are equal, then the relevant objects from one cluster are concatenated. In this way, aggregated objects are created. In [33], a formal definition of the aggregated tables of synthesis agents can be found.

After defining the aggregated decision tables, a c–dimensional vector of values 
, 
 is generated for each cluster . The value 
 is equal to the maximum value of the similarity measure of objects from the decision class 
 of the aggregated decision table of synthesis agent 
 to the test object x.

Then the vectors of values assigned to the individual clusters are transformed according to the formula 
 
 for . In this way we obtain the final form of the vectors of values.

In the paper [49] a computational complexity of this method has been discussed. The method has an exponential complexity due to the number of relevant objects (the value of the parameter 
). The approximated method of the aggregation of decision tables takes most of the time while generating a global decision by the system.

In order to demonstrate the methods for generating the local decisions within one cluster we investigated an example.

Example 4.2

Consider the dispersed system that was used in Example 4.1. Thus, the set of synthesis agents consists of three agents 
 and we have the following clusters 
, 
 and 
. The objects of the decision tables of resource agents are given in Table 3. We consider the two methods for generating the local decisions within one cluster.

The aggregation of the vectors that determine the level of certainty with which resource agents make the decisions

This method consists of simple arithmetic operations that are performed on the vectors that are assigned to the resource agents. These vectors are shown in Table 8 (they were created by transforming the vectors that were presented in Table 4 in such a way that the sum of a vector's coordinates is equal to 1). The weighted sum of these vectors is calculated in this method. The weights are equal to the coefficient of agent's membership in the clusters that was defined in Formula (12). These coefficients are shown in Table 9. Then, according to Formula (13), the vector of values for each cluster is determined as follows:
 
 
 
 
 
 
 
 
 
 Elimination of inconsistencies in the knowledge – the approximated method of the aggregation of decision tables


Table 8. Transformed vectors that indicate the level of certainty.

Resource agent	Vector
ag1	[0.214, 0.143, 0.214, 0.143, 0.286]
ag2	[0.143, 0, 0.286, 0.286, 0.286]
ag3	[0.125, 0.25, 0.25, 0.125, 0.25]
ag4	[0.167, 0.167, 0.333, 0, 0.333]
ag5	[0, 0.25, 0.5, 0.25, 0]
ag6	[0.125, 0.375, 0.125, 0.25, 0.125]
ag7	[0.222, 0.222, 0.333, 0.222, 0]

Table 9. Values of the coefficient of agent's membership in clusters.

ag1	ag2	ag3	ag4	ag5	ag6	ag7
The number of clusters to which the agent belongs	1	1	3	2	2	1	2

The coefficient of agent's membership in clusters	1	1	
 
 
 
1	
 
In this method, an aggregated decision table is generated for each synthesis agent based on the relevant object (
) of the resource agents from one cluster (given in Table 3). The decision tables of the synthesis agents are given in Table 10; the values of the Gower similarity measure to the test object are also given in this table. As was mentioned, relevant objects that have the same values of the decision attribute and common conditional attributes are concatenated. For example, consider the aggregated table of synthesis agent 
. The agent is superordinate to the cluster 
. The first object from the set 
 is created by combining the first object from decision table 
, the first object from decision table 
 and the first object from decision table 
. Since there is no object in decision table 
 that would have the value of a decision attribute and the values of common conditional attributes 
, 
 and 
 equal the values of these attributes for the first object from 
 and the first object from 
, the value of the first aggregated object and attribute 
 is equal to ?. Other objects from the aggregated decision tables were constructed in a similar manner.


Table 10. Decision tables of the synthesis agents.

a1	a2	a3	a4	a5	a6	a7	a8	a9	a10	a11	a12	d	
4	4	4	4	3	?	3	3	3	4	3	4	v1	
 
4	4	?	?	4	3	4	3	?	4	?	?	v1	
 
3	4	2	4	4	4	3	2	?	?	?	?	v2	
 
3	4	2	4	4	?	3	4	3	?	3	4	v2	
 
3	3	?	?	?	?	3	4	3	4	3	4	v2	
 
3	3	?	?	4	4	3	2	?	4	?	?	v2	
 
4	2	4	4	3	?	4	4	4	?	3	3	v3	
 
4	3	?	?	2	3	4	4	4	4	3	3	v3	
 
3	3	3	3	3	3	2	4	?	?	?	?	v4	
 
3	3	3	3	3	?	3	2	3	?	4	4	v4	
 
3	2	?	?	3	3	2	4	?	3	?	?	v4	
 
3	2	?	?	?	?	3	2	3	3	4	4	v4	
 
3	3	2	4	3	4	2	4	?	3	?	?	v5	
 
3	3	2	4	3	?	4	4	4	3	4	4	v5	
 

a1	a2	a3	a4	a5	a7	a8	a9	a10	a11	a12	d	
4	4	?	?	?	3	3	3	4	3	4	v1	
 
4	4	4	?	?	?	?	2	4	3	4	v1	
 
?	?	?	3	3	?	?	?	2	2	3	v1	
 
3	3	?	?	?	3	4	3	4	3	4	v2	
 
3	3	2	?	?	?	?	4	4	4	3	v2	
 
?	?	2	4	4	?	?	4	3	4	3	v2	
 
4	3	?	?	?	4	4	4	4	3	3	v3	
 
4	3	2	?	?	?	?	4	4	4	2	v3	
 
?	?	?	3	3	?	?	?	3	2	4	v3	
 
3	2	3	?	?	?	?	3	4	3	4	v4	
 
3	2	?	4	3	3	2	3	4	4	4	v4	
 
3	3	?	?	?	4	4	4	3	4	4	v5	
 
3	3	4	?	?	?	?	2	3	?	?	v5	
 
?	?	?	3	4	4	4	4	4	4	4	v5	
 
?	?	4	3	4	?	?	2	4	4	4	v5	0

a3	a4	a5	a6	a7	a8	a9	a10	a11	a12	a13	d	
?	?	?	?	3	3	3	?	3	4	?	v1	
 
4	?	?	?	?	?	2	?	3	4	?	v1	0
?	3	3	3	?	?	?	2	2	3	4	v1	
 
?	?	?	?	3	4	3	?	3	4	?	v2	
 
2	4	4	?	?	?	4	3	4	3	?	v2	
 
?	?	?	2	?	?	?	?	?	2	4	v2	1
?	?	?	?	4	4	4	?	3	3	?	v3	
 
2	?	?	?	?	?	4	?	4	2	?	v3	
 
?	3	3	3	?	?	?	3	2	4	4	v3	
 
?	4	3	2	3	2	3	4	4	4	4	v4	
 
3	?	?	2	?	?	3	?	3	4	4	v4	
 
?	3	4	2	4	4	4	4	4	4	3	v5	
 
4	3	4	2	?	?	2	4	4	4	3	v5	
 
The vectors 
, 
, 
 were designated based on the similarity values that are given in Table 10. Table 11 shows these vectors. The result of the transformation of the vectors, the aim of which was to obtain a sum of the vectors coefficients that was equal to 1, are also given in this table. The vectors that are shown in Table 11 are the final result of this step of the decision-making process. In the next stage, the method of conflict analysis is implemented.


Table 11. Vectors that were assigned to a cluster that indicate the level of certainty.

Synthesis agent	Vector that indicates the level of certainty with which the decisions were taken	Transformed vector
as1	[0.36, 0.4, 0.5, 0.43, 0.67]	[0.15, 0.17, 0.21, 0.18, 0.28]
as2	[0.4, 0.43, 0.6, 0.3, 0.5]	[0.18, 0.19, 0.27, 0.13, 0.22]
as3	[0.43, 1, 0.57, 0.5, 0.3]	[0.15, 0.36, 0.20, 0.18, 0.11]
5. Conflict analysis
After generating the local decisions within each cluster the Shapley-Shubik index is used in order to determine the global decisions. At first the value of the Shapley-Shubik index is calculated for each cluster. Then, the vectors for the clusters are aggregated into one vector. In the final step, decision to which the highest value of the vector's coefficient was assigned is chosen and the ε–neighbourhood for the decision is calculated.

5.1. Application of the Shapley-Shubik index
The power index will be calculated for each synthesis agent. In order to do this, a simple game must be considered. In the previous stage, the local decisions of synthesis agents were generated in the form of vectors 
, 
, . For each decision value, a separate simple game is defined on the basis of these vectors. The simple game for the decision value 
 is defined as follows. Let's assume that the set of synthesis agents is the set of players, so . Each synthesis agent 
 has voting power equal to 
. Agents form coalitions, the coalition is a winning coalition if the sum of the voting power of its members is greater than threshold 
. Some preliminary experiments have been made in order to determine the optimal value of 
. It was found that the best results are achieved when(14)
 
 
 Thus, we say that a coalition of synthesis agents  is a winning coalition when 
.

The adopted threshold value can be interpreted as the average value of the agents' voting weights (the synthesis agents' coordinates for decision value 
). During the experiments aimed at determining the optimal threshold the following values were tested: 50%, 25% and 75% of the sum 
. However, they gave worse results in terms of the classification quality of a dispersed decision-making system. The good results achieved by the adopted threshold can be justified, that in this way the agents who have voting weights above the average will obtain a larger power index. It seems that the adopted threshold will not be appropriate in the case when voting weights of agents have very low variability (in an extreme case when all voting weights are equal to the average).

According to the above definition, the Shapley-Shubik index for the decision 
 and the agent 
 is defined as follows:(15)
 
 

For each synthesis agent 
 the value is calculated 
 that is equal to the sum of the Shapley-Shubik index for all decision values. This value is used to recalculate the vector of decisions of the synthesis agent. It is implemented as follows(16)
 After this conversion, the agents with greater power, will have a greater impact on final decision. The vector's values that are obtained in this way are used in the next step of determining a global decision, which is described in the section below.

The Shapley-Shubik power index (and the other power indexes) is computationally difficult to calculate, especially when we are dealing with a large number of agents. It requires a computation time which is exponential in the number of players. Alternatively, in some domains it is possible to compute power indexes through a subexponential algorithm, but that places restrictions about the domain [6], [14]. But in the approach that is being considered, the number of agents is rather small and it is possible to use the exact formula of the Shapley-Shubik index. Computational times are also not very large as can be seen in the experimental section.

In order to demonstrate application of the Shapley-Shubik index in a dispersed system we investigated an example.

Example 5.1

Consider a dispersed decision-making system that was used in Example 4.2. In order to create a separate simple game for each decision value we use the vectors of synthesis agents that were generated for both considered methods for generating the local decisions. For example, for the method of aggregation of the vectors and decision 
 agents 
, 
 and 
 have voting power equal respectively 0.48, 0.24 and 0.28. The threshold value for a winning coalition (Formula (14)) is equal to 
. The process of forming a coalition is as follows. Agents join the coalition sequentially. The coalition is a losing coalition at the beginning. But at some point, it turns into a winning coalition when an agent joins to the coalition. This means that this is a crucial agent for the coalition. Of course, when additional agents join the coalition, it will remain the winning coalition. All of the possible orderings are listed below. The decisive agent is underlined in each of the orderings. 
 
 
 
 
 
 
 
 
 
 
 
 
 The values of the power index for individual agents and decision 
 are equal to 
 
 
 
.

The simple games, that are considered for each of the decisions are presented in Table 12. Each row of the table represents a separate simple game. The values of the Shapley-Shubik index for the decisions and for both considered methods for generating the local decisions are given in Table 13.


Table 12. The voting power of synthesis agents and the thresholds ql(x) for a winning coalition.

vl ∈ Vd	Method of aggregation of the vectors	Approximated method of the aggregation of decision tables
Voting power	ql(x)	Voting power	ql(x)
as1	as2	as3	as1	as2	as3
v1	0.48	0.24	0.28	0.33	0.15	0.18	0.15	0.16
v2	0.31	0.40	0.69	0.47	0.17	0.19	0.36	0.24
v3	0.75	0.67	0.63	0.68	0.21	0.27	0.20	0.23
v4	0.47	0.28	0.53	0.43	0.18	0.13	0.18	0.16
v5	0.82	0.25	0.21	0.43	0.28	0.22	0.11	0.20

Table 13. Values of the Shapley-Shubik index.

vl ∈ Vd	Method of aggregation of the vectors	Approximated method of the aggregation of decision tables
as1	as2	as3	as1	as2	as3
v1	
 
 
 
 
 
 
v2	
 
 
 
 
 
 
v3	
 
 
 
 
 
 
v4	
 
 
 
 
v5	
 
 
 
 
 

∑	
 
 
 
 
 
φ3(x)=1
The values of the power index of the synthesis agents are then used to recalculate the vectors that are assigned to the synthesis agents. The vectors that are obtained after applying Formula (16) are given in Table 14.


Table 14. Vectors that take into account the level of certainty and the power of an agent.

Synthesis agent	Method of aggregation of the vectors	Approximated method of the aggregation of decision tables
as1	[1.2857, 0.8254, 2.0000, 1.2540, 2.1905]	[0.2312, 0.2544, 0.3179, 0.2725, 0.4239]
as2	[0.1574, 0.2685, 0.4444, 0.1852, 0.1667]	[0.4487, 0.4808, 0.6731, 0.3365, 0.5609]
as3	[0.4630, 1.1574, 1.0417, 0.8796, 0.3472]	[0.1531, 0.3571, 0.2041, 0.1786, 0.1071]
5.2. Method of determining a set of global decisions – ε–neighbourhood
The vectors that were assigned to synthesis agents are used in the last stage of taking global decisions by all of the agents. We assume that each synthesis agent votes for decision values with the voting power that is equal to the coordinate of the vector that corresponds to the particular decision. Therefore, the sum of the vectors that are assigned to clusters is calculated(17)
 
 In order to define a set of global decisions, the ε–neighbourhood of decision with the highest number of votes are defined. This is done as follows. At first, decisions with the highest number of votes are determined(18)
 
 
 Then, the ε–neighbourhood of decisions 
 is defined(19)
 
 
 And this is the set of global decisions for a test object x that are generated by a dispersed system.

Note that the method mentioned above has a linear complexity of computing due to the number of synthesis agents and the number of decision values. This complexity results from the complexity of calculating the sum of the vectors that are assigned to particular clusters.

Example 5.2

Consider a dispersed decision-making system that was used in Example 5.1. The ε-neighbourhood method is used in the last step of the process of generating global decisions. At first the sum of the vectors that were assigned to the clusters (Table 14) is calculated. For the method of aggregation of the vectors it is  and for the approximated method of the aggregation of decision tables it is . The decisions that are taken with the maximum level of certainty are selected. This is the third value of the decision 
 for both methods. A set of global decisions for a test object x is the ε-neighbourhood of those decisions. For example, if for the method of aggregation of the vector , then 
, and if for the approximated method of the aggregation of decision tables , then 
. As can be seen the value of ε has a different impact on the result and different sets of decisions are obtained for both methods.

Finally, let us note that the use of the Shapley-Shubik power index significantly changed the level of certainty that was associated with the decisions. Consider the vectors of rank that are assigned to the decisions based on the vectors that were calculated in Example 4.2 (before applying the power index) and for the two methods – for the method of aggregation of the vector  and for the approximated method of the aggregation of decision tables . After applying the Shapley-Shubik index, the vectors of rank are  for the method of aggregation of the vector and  for the approximated method of the aggregation of decision tables. As can be seen, the ordering of the decisions changed completely after using the power index.

6. Experimental study
The experiments were performed on data from the repository which was artificially dispersed. However, as much generality as possible was kept to produce the dispersed data. The sets of the attributes in the local tables were selected randomly from the original set of attributes, but in such a way that some of the attributes were common and the sets in various tables were different. No object identifiers were stored in tables so that it could not be possible to determine common objects. Unfortunately, the author does not have access to the real-life dispersed data. Access to data is difficult for various reasons: confidentiality, consent to data processing, the unwillingness of units to share data and other legal regulations. Difficult access to real data is a common and essential problem in scientific research, while obtaining access to dispersed data is even more difficult.

The experiments were conducted on three different data sets and five different versions of dispersion for each data set were analyzed. All of the methods and algorithms presented above were implemented in C# language. In order to make global decisions, dispersed data, stored in *.txt file is provided to the system. The file contains: the number of resource agents and the decision tables for all of the agents.

6.1. Methodology
This section will describe how the dispersed data were received and how they were analyzed. The data from the UCI repository, [http://www.ics.uci.edu/~mlearn/MLRepository.html] were used. Soybean data set – that is related to the external characteristics of soybeans in order to diagnose pathogens that affect any impairments. Vehicle Silhouettes data set – that is related to vehicle type recognition based on a set of features. Landsat Satellite data set – that is related to the identification of satellite images.

Two disjoint sets of data were received from each of the analyzed data sets – a training set and a test set. In the UCI repository the test sets for Soybean and Landsat Satellite are available. The Vehicle Silhouettes data set was divided randomly. The training set contains 70% of the objects, the test set contains 30% of the objects. The characteristics of the data sets are given in Table 15.


Table 15. Data set summary.

Data set	# The training set	# The test set	# Conditional attributes	# Decision classes
Soybean	307	376	35	19
Vehicle silhouettes	592	254	18	4
Landsat satellite	4435	1000	36	6
Then, for each data set, process of dispersion was carried out. For each data set, five different dispersed data were considered: 
 – system with 3 decision tables, 
 – system with 5 decision tables, 
 – system with 7 decision tables, 
 – system with 9 decision tables, 
 – system with 11 decision tables. The dispersion process was not optimized in any way. It was performed only once in the way described in [33].

The measures for determining the quality of the classification were:

•
estimator of classification error on a test set independent of the training set(20)
 
 
 where 
, when 
 and 
, when 
; the test set is stored in a decision table 
; 
 is a set of global decisions generated by the dispersed decision-making system with dynamically generated clusters 
 for the test object x.

•
estimator of classification ambiguity error on a test set independent of the training set(21)
 
 
 where 
, when 
 and 
, when 
.

•
the average size of the global decisions sets generated for a test set(22)
 
 

The following designations were adopted:

•
 – the approximated method of the aggregation of decision tables; 
 – the number of relevant objects that were chosen from each decision class of a resource agent's decision table

•
S – the aggregation of the vectors that determine the level of certainty with which resource agents make decisions. This method involves calculating the weighted average of the vectors that are assigned to the resource agents

•
 – the ε–neighbourhood method, where ε determines the radius of the neighbourhood

For each data set the experiments were carried out using:

•
the approximated method of the aggregation of decision tables in conjunction with the Shapley-Shubik index and the ε–neighbourhood method

•
the aggregation of the vectors of the values in conjunction with the Shapley-Shubik index and the ε–neighbourhood method

The following experiment plan was adopted:
1.
The optimal values of parameters 
 and 
 are determined. Parameter 
 is the number of relevant objects used in the cluster creation process. Parameter 
 occurs in the approximated method of aggregation of the decision tables. All values from the set 
 were analyzed for the Soybean and the Vehicle Silhouettes data sets. For the Landsat Satellite data set, values from the set  were used. The minimum value of 
 and 
 was chosen, for which the lowest value of the estimator of classification error on a test set was reached. The optimal value of parameter p is determined (see Definition 4.2). All values from the set  were analyzed. The minimum value of p was chosen, for which the lowest value of the estimator of classification error on a test set was reached.

2.
The optimal value of parameter ε is determined. Different values of parameter ε that were increased from 0 to the threshold point were analyzed. The value, for which the greatest improvement in the efficiency of inference was observed, was selected.

6.2. Experiments with the Soybean Data Set
Below the experiments that were conducted using the Soybean data set are described. This description is divided into two subsections. The first part shows the results that were obtained using the power index and the approximated method of the aggregation of decision tables or the aggregation of the vectors that were assigned to the resource agents. For comparison, the results that were obtained without using the Shapley-Shubik index in the dispersed decision-making system are presented in the second section.

6.2.1. The results obtained with using the Shapley-Shubik power index
Table 16 shows the results of experiments using a dispersed decision-making system using the approximated method of the aggregation of decision tables the power index and the ε-neighbourhood method. The following information is given in the tables: the name of the dispersed decision-making system (System), the optimal parameter values (Parameters), the algorithm's symbol (Algorithm), the three measures that were discussed earlier 
, the time t needed to analyze a test set (expressed in minutes).


Table 16. Using the Shapley-Shubik index and the approximated method of the aggregation of decision tables for the Soybean data set.

System	Parameters	Algorithm	e	eONE	
t
m1 = 4, p = 0.1	A(1)N(0.08)	0.016	0.340	1.620	0.04

m1 = 6, p = 0.05	A(1)N(0.077)	0.008	0.319	1.596	0.05
m1 = 6, p = 0.05	A(1)N(0.074)	0.011	0.303	1.553	0.05

m1 = 7, p = 0.05	A(1)N(0.095)	0.003	0.370	1.689	0.08
m1 = 7, p = 0.05	A(1)N(0.08)	0.016	0.324	1.540	0.08

m1 = 3, p = 0.05	A(2)N(0.086)	0.011	0.378	1.604	0.22
m1 = 3, p = 0.05	A(2)N(0.08)	0.016	0.362	1.545	0.22

m1 = 5, p = 0.05	A(1)N(0.095)	0.037	0.452	1.758	3.12
m1 = 5, p = 0.05	A(1)N(0.043)	0.074	0.301	1.362	3.12
Table 17 shows the results of experiments using a dispersed decision-making system using the aggregation of the vectors of values, the power index and the ε–neighbourhood method. The designations used in this Table are the same as in Table 16.


Table 17. Using the Shapley-Shubik index and the aggregation of the vectors of the values for the Soybean data set.

System	Parameters	Algorithm	e	eONE	
t
m1 = 2, p = 0.05	SN(0.08)	0.021	0.330	1.649	0.02

m1 = 1, p = 0.05	SN(0.085)	0.005	0.277	1.580	0.02
m1 = 1, p = 0.05	SN(0.064)	0.013	0.25	1.452	0.02

m1 = 1, p = 0.1	SN(0.133)	0.003	0.364	1.827	0.03
m1 = 1, p = 0.15	SN(0.106)	0.016	0.309	1.566	0.03

m1 = 1, p = 0.05	SN(0.136)	0.024	0.364	1.686	0.11
m1 = 1, p = 0.2	SN(0.136)	0.029	0.311	1.553	0.12

m1 = 1, p = 0.05	SN(0.19)	0.035	0.399	1.684	1.40
m1 = 1, p = 0.05	SN(0.103)	0.061	0.298	1.351	1.40
Analysing the results shown in Table 16, Table 17, we can say that comparable results were obtained when the approximated method of the aggregation of decision tables or the aggregation of the vectors of the values in conjunction with the Shapley-Shubik index are applied. In the case of systems with 3 (
) and 9 (
) resource agents the approximated method of the aggregation of decision tables provided better results. But in the case of the system with 11 (
) resource agents, the aggregation of the vectors of the values gives better results. Overall, based on the results that were obtained for the Soybean data set, no significant advantage can be found for any of the methods. As was mentioned earlier, the method of aggregating of vector values is much better in terms of computational complexity.

6.2.2. The results obtained without using the Shapley-Shubik power index
For comparison, the results of the experiments that are presented in the paper [35] are given in Table 18 and the results of the experiments that are presented in the paper [37] are given in Table 19. These results were obtained using a dispersed decision-making system, wherein the method of forming the system structure is the same as that presented in this paper. However, the Shapley-Shubik power index was not used in this approach. The approximated method of the aggregation of decision tables was used. Additionally, in the paper [37], different methods for determining the strength of clusters were used. The methods and their designations, which were considered in the paper [37], are listed and are given in Table 19:

•
the strength of a cluster calculated with respect to the number of component agents, designation F,

•
the strength of a cluster calculated with respect to the diversity of the decisions taken by resource agents, designation D,

•
the strength of a cluster calculated with respect to the number of component agents and the diversity of the decisions taken by the resource agents, designation FD,

•
the strength of a cluster calculated with respect to the diversity of the decisions taken by the synthesis agents, designation V.

The best results that were obtained for the methods for determining the strength of clusters are given in Table 19.

Table 18. The approach without using the Shapley-Shubik index, which were considered in the paper [35] (Soybean data set).

System	Parameters	Algorithm	e	eONE	
t
m1 = 5, p = 0.1	A(1)G(0.0088;2)	0.019	0.266	1.697	0.04

m1 = 4, p = 0.05	A(1)G(0.0144;2)	0.008	0.290	2.082	0.05
m1 = 4, p = 0.05	A(1)G(0.0122;2)	0.021	0.258	1.529	0.05

m1 = 2, p = 0.05	A(4)G(0.0156;2)	0.013	0.301	1.899	0.09
m1 = 2, p = 0.05	A(4)G(0.0117;2)	0.032	0.277	1.572	0.09

m1 = 4, p = 0.1	A(2)G(0.0174;2)	0.024	0.293	1.822	0.22
m1 = 1, p = 0.05	A(3)G(0.0103;2)	0.043	0.242	1.521	0.38

m1 = 2, p = 0.05	A(2)G(0.0225;2)	0.035	0.322	1.875	2.23
m1 = 2, p = 0.05	A(2)G(0.0123;2)	0.080	0.263	1.303	2.23

Table 19. The approach without using the Shapley-Shubik index, which were considered in the paper [37] (Soybean data set).

System	Parameters	Algorithm	e	eONE	
t
m1 = 2, p = 0.2	A(1)G(0.0026;2)FD	0.019	0.255	1.633	0.04

m1 = 1, p = 0.05	A(2)G(0.0019;2)D	0.008	0.274	1.739	0.08
m1 = 5, p = 0.05	A(1)G(0.0026;2)F	0.016	0.269	1.572	0.05
m1 = 6, p = 0.05	A(1)G(0.0026;2)D	0.011	0.303	2.077	0.08
m1 = 6, p = 0.05	A(1)G(0.00195;2)F	0.019	0.258	1.566	0.08

m1 = 8, p = 0.2	A(2)G(0.0026;2)F	0.008	0.263	1.660	0.24
m1 = 8, p = 0.2	A(2)G(0.0024;2)F	0.013	0.247	1.513	0.24

m1 = 3, p = 0.05	A(1)G(0.0026;2)D	0.024	0.335	1.726	2.35
m1 = 3, p = 0.2	A(1)G(0.0016;2)FD	0.043	0.258	1.324	3.05
The results presented in Table 16, Table 17, Table 18, Table 19 were compared. The best results in terms of the measures e and 
 are bold in the tables. Some general conclusions that can be drawn on the basis of the results that were obtained are as follows. In the case of the Soybean data set for a smaller number of resource agents, the approach using the Shapley-Shubik index and the approximated method of the aggregation of decision tables provides better results. In the case of a larger number of resource agents, the approach that does not use the Shapley-Shubik index, which was presented in the paper [37], produced better results.

6.3. Experiments with the Vehicle Silhouettes data set
As with the Soybean experiment, the description of experiments on the Vehicle Silhouettes data set was divided into two subsections. The designations used in all of the tables in this section are the same as in Table 16.

6.3.1. The results obtained with using the Shapley-Shubik power index
Table 20 shows the results of experiments using a dispersed decision-making system using the approximated method of the aggregation of decision tables, the power index and the ε-neighbourhood method.


Table 20. Using the Shapley-Shubik index and the approximated method of the aggregation of decision tables for the Vehicle Silhouettes data set.

System	Parameters	Algorithm	e	eONE	
t
m1 = 9, p = 0.05	A(2)N(0.0074)	0.102	0.539	1.583	0.08
m1 = 9, p = 0.05	A(2)N(0.0032)	0.181	0.402	1.252	0.08

m1 = 1, p = 0.05	A(8)N(0.0077)	0.150	0.598	1.563	0.15
m1 = 1, p = 0.05	A(8)N(0.0041)	0.248	0.492	1.283	0.15

m1 = 9, p = 0.05	A(8)N(0.0086)	0.122	0.531	1.555	0.48
m1 = 9, p = 0.05	A(8)N(0.0044)	0.205	0.413	1.268	0.48

m1 = 9, p = 0.05	A(1)N(0.0042)	0.138	0.520	1.500	0.23
m1 = 9, p = 0.05	A(1)N(0.0026)	0.228	0.445	1.299	0.23

m1 = 3, p = 0.05	A(5)N(0.0038)	0.134	0.528	1.508	3.10
m1 = 10, p = 0.05	A(1)N(0.0022)	0.193	0.406	1.260	2.22
Table 21 shows the results of experiments using a dispersed decision-making system using the aggregation of the vectors of the values, the power index and the ε–neighbourhood method.


Table 21. Using the Shapley-Shubik index and the aggregation of the vectors of the values for the Vehicle Silhouettes data set.

System	Parameters	Algorithm	e	eONE	
t
m1 = 5, p = 0.05	SN(0.0149)	0.087	0.512	1.567	0.04
m1 = 4, p = 0.05	SN(0.0077)	0.165	0.413	1.291	0.03

m1 = 6, p = 0.05	SN(0.0197)	0.130	0.512	1.555	0.05
m1 = 6, p = 0.05	SN(0.0092)	0.209	0.413	1.264	0.05

m1 = 3, p = 0.05	SN(0.02)	0.106	0.5	1.535	0.05
m1 = 4, p = 0.05	SN(0.0092)	0.181	0.378	1.264	0.06

m1 = 2, p = 0.05	SN(0.0095)	0.161	0.543	1.543	0.13
m1 = 4, p = 0.05	SN(0.005)	0.240	0.413	1.256	0.14

m1 = 3, p = 0.05	SN(0.011)	0.138	0.504	1.528	2.19
m1 = 1, p = 0.05	SN(0.0052)	0.205	0.413	1.283	2.19
Analysing the results shown in Table 20, Table 21, we can say that comparable results were obtained when the approximated method of the aggregation of decision tables or the aggregation of the vectors of the values in conjunction with the Shapley-Shubik index are applied. In the case of systems with 3 (
), 5 (
) and 7 (
) resource agents, the aggregation of the vectors of the values gave better results. However, in the case of systems with 9 (
) and 11 (
) resource agents, the approximated method of the aggregation of decision tables provides better results. Overall, based on the results that were obtained for the Vehicle Silhouettes data set, no significant advantage can be found for any of the methods. It can only be said that the method of vector aggregation gives better results when we have a smaller number of resource agents. The approximated method of the aggregation of decision tables generates better results when the set of resource agents is more numerous. Of course, as was mentioned earlier, the method of aggregating the vectors values is much better in terms of computational complexity.

6.3.2. The results obtained without using the Shapley-Shubik power index
Similar to the case of the Soybean data set, the results of the experiments that are presented in the papers [35], [37] are given in Table 22 and Table 23 for comparison. The designations used in this Table are the same as in Table 18 and Table 19.


Table 22. The approach without using the Shapley-Shubik index, which was considered in the paper [35] (Vehicle Silhouettes).

System	Parameters	Algorithm	e	eONE	
t
m1 = 9, p = 0.05	A(2)G(0.0038;2)	0.122	0.488	1.516	0.08
m1 = 9, p = 0.05	A(2)G(0.002;2)	0.185	0.409	1.272	0.08

m1 = 1, p = 0.05	A(10)G(0.0043;2)	0.177	0.559	1.531	0.20
m1 = 1, p = 0.05	A(10)G(0.0022;2)	0.260	0.453	1.228	0.20

m1 = 9, p = 0.05	A(8)G(0.0072;2)	0.126	0.508	1.531	0.48
m1 = 9, p = 0.05	A(8)G(0.0035;2)	0.205	0.413	1.280	0.48

m1 = 5, p = 0.05	A(1)G(0.0048;2)	0.142	0.512	1.500	0.20
m1 = 5, p = 0.05	A(1)G(0.0026;2)	0.240	0.433	1.252	0.20

m1 = 2, p = 0.05	A(3)G(0.0055;2)	0.146	0.520	1.496	2.22
m1 = 2, p = 0.05	A(3)G(0.0028;2)	0.189	0.390	1.244	2.22

Table 23. The approach without using the Shapley-Shubik index, which was considered in the paper [37] (Vehicle Silhouettes).

System	Parameters	Algorithm	e	eONE	
t
m1 = 2, p = 0.05	A(2)G(0.0026;2)V	0.098	0.496	1.559	0.06
m1 = 5, p = 0.05	A(10)G(0.0014;2)D	0.169	0.402	1.287	0.11

m1 = 8, p = 0.05	A(10)G(0.00195;2)D	0.146	0.532	1.551	0.32
m1 = 8, p = 0.05	A(10)G(0.001;2)D	0.213	0.417	1.240	0.32

m1 = 1, p = 0.05	A(5)G(0.0021;2)FD	0.094	0.469	1.516	0.15
m1 = 1, p = 0.05	A(5)G(0.00105;2)FD	0.169	0.358	1.244	0.15

m1 = 5, p = 0.05	A(4)G(0.0011;2)FD	0.142	0.520	1.535	0.32
m1 = 2, p = 0.05	A(4)G(0.0005;2)F	0.205	0.390	1.236	0.25

m1 = 2, p = 0.05	A(3)G(0.00095;2)FD	0.122	0.472	1.465	2.20
m1 = 2, p = 0.05	A(3)G(0.00055;2)FD	0.177	0.366	1.252	2.20
The results presented in Table 20, Table 21, Table 22, Table 23 were compared. The best results in terms of the measures e and 
 are bold in the tables. General conclusions that can be drawn based on the results that were obtained are as follows. In the case of the Vehicle set the approach using the Shapley-Shubik index and the aggregation of the vectors of the values gave better results for a smaller number of resource agents. In the case of a larger number of resource agents, the approach that did not use the Shapley-Shubik index, which was presented in the paper [37], gave better results.

6.4. Experiments with the Landsat Satellite Data Set
Similar to the two previous sections, the description of the experiments on the Landsat Satellite data set was divided into two subsections. The designations used in all of the tables in this section are the same as in Table 16.

6.4.1. The results obtained with using the Shapley-Shubik power index
Table 24 shows the results of experiments using a dispersed decision-making system using the approximated method of the aggregation of decision tables, the power index and the ε-neighbourhood method.


Table 24. Using the Shapley-Shubik index and the approximated method of the aggregation of decision tables for the Landsat Satellite data set.

System	Parameters	Algorithm	e	eONE	
t
m1 = 1, p = 0.05	A(5)N(0.0073)	0.019	0.415	1.768	6.35

m1 = 1, p = 0.05	A(2)N(0.0129)	0.009	0.486	1.699	7.22
m1 = 1, p = 0.05	A(3)N(0.0044)	0.036	0.221	1.217	7.22

m1 = 3, p = 0.05	A(1)N(0.0123)	0.008	0.487	1.707	8.50
m1 = 3, p = 0.05	A(1)N(0.0049)	0.036	0.249	1.263	8.50

m1 = 5, p = 0.05	A(3)N(0.0113)	0.013	0.476	1.661	13.07
m1 = 5, p = 0.05	A(3)N(0.0046)	0.036	0.259	1.27	13.07

m1 = 2, p = 0.05	A(1)N(0.0103)	0.009	0.459	1.623	16.47
m1 = 2, p = 0.05	A(3)N(0.0042)	0.037	0.241	1.249	19.45
Table 25 shows the results of experiments using a dispersed decision-making system using the aggregation of the vectors of the values, the power index and the ε–neighbourhood method.


Table 25. Using the Shapley-Shubik index and the aggregation of the vectors of the values for the Landsat Satellite data set.

System	Parameters	Algorithm	e	eONE	
t
m1 = 2, p = 0.05	SN(0.0188)	0.01	0.468	1.713	6.30

m1 = 2, p = 0.05	SN(0.0256)	0.009	0.46	1.681	7.22
m1 = 2, p = 0.05	SN(0.0096)	0.036	0.225	1.227	7.22

m1 = 2, p = 0.05	SN(0.0253)	0.007	0.47	1.699	7.51
m1 = 2, p = 0.05	SN(0.0099)	0.032	0.24	1.256	7.51

m1 = 4, p = 0.05	SN(0.0243)	0.008	0.443	1.648	11.55
m1 = 4, p = 0.05	SN(0.0099)	0.036	0.248	1.268	11.55

m1 = 4, p = 0.05	SN(0.0217)	0.009	0.459	1.65	12.57
m1 = 4, p = 0.05	SN(0.0082)	0.036	0.249	1.256	12.57
Analysing the results shown in Table 24, Table 25, we can say that the using vector aggregation in combination with the Shapley-Shubik power index gives better results than using the approximated method of the aggregation of decision tables in conjunction with the Shapley-Shubik power index. In addition, the method of vector aggregation has a much lower computational complexity than the approximated method of the aggregation of decision tables.

6.4.2. The results obtained without using the Shapley-Shubik power index
Similar to the case of the Soybean data set, the results of the experiments that are presented in the papers [35], [37] are given in Table 26 and Table 27 for comparison. The designations used in this Table are the same as in Table 18 and Table 19.


Table 26. The approach without using the Shapley-Shubik index, considered in the paper [35] (Landsat Satellite).

System	Parameters	Algorithm	e	eONE	
t
WSDAg1	m1 = 1, p = 0.05	A(4)G(0.0029;2)	0.022	0.390	1.786	6.26

WSDAg2	m1 = 1, p = 0.05	A(3)G(0.0046;2)	0.011	0.367	1.618	7.34
m1 = 1, p = 0.05	A(3)G(0.0024;2)	0.040	0.220	1.237	7.34

WSDAg3	m1 = 1, p = 0.05	A(1)G(0.0066;2)	0.014	0.379	1.717	7.55
m1 = 1, p = 0.05	A(1)G(0.0032;2)	0.038	0.221	1.252	7.55

WSDAg4	m1 = 5, p = 0.05	A(2)G(0.0064;2)	0.019	0.363	1.626	12.07
m1 = 5, p = 0.05	A(2)G(0.0036;2)	0.044	0.247	1.274	12.07

WSDAg5	m1 = 2, p = 0.05	A(1)G(0.0097;2)	0.013	0.371	1.663	15.30
m1 = 2, p = 0.05	A(1)G(0.0048;2)	0.042	0.221	1.246	15.30

Table 27. The approach without using the Shapley-Shubik index, considered in the paper [37] (Landsat Satellite).

System	Parameters	Algorithm	e	eONE	
t
m1 = 1, p = 0.05	A(3)G(0.00182;2)V	0.012	0.42	1.762	6.14

m1 = 2, p = 0.05	A(4)G(0.00164;2)F	0.009	0.394	1.711	8.11
m1 = 1, p = 0.05	A(3)G(0.0007;2)V	0.037	0.216	1.223	8.20

m1 = 1, p = 0.05	A(1)G(0.00156;2)F	0.009	0.378	1.709	7.40
m1 = 1, p = 0.05	A(1)G(0.00076;2)F	0.034	0.225	1.254	7.40

m1 = 5, p = 0.05	A(3)G(0.00144;2)V	0.014	0.379	1.669	12.53
m1 = 5, p = 0.05	A(3)G(0.00074;2)FD	0.039	0.242	1.266	12.53

m1 = 2, p = 0.05	A(1)G(0.0014;2)V	0.011	0.386	1.645	16.16
m1 = 2, p = 0.05	A(3)G(0.00062;2)F	0.037	0.213	1.242	18.07
The results presented in Table 24, Table 25, Table 26, Table 27 were compared. The best results in terms of the measures e and 
 are bold in the tables. General conclusions that can be drawn on the basis of the results that were obtained are as follows. The approach using the Shapley-Shubik index and the vector aggregation method generated the best results for the Landsat Satellite data set.

It should be noted that the approach proposed in this paper (using the Shapley-Shubik index and the aggregation of the vectors of the values) has the smallest computational complexity and provides the results in the shortest time.

7. Discussion
An important contribution of this study is to use the issues from game theory in the process of decision support that is based on dispersed knowledge. In a previous work of the author, a combination of the issues from these two fields of science was not used. The author wanted to develop the issues that are associated with dispersed decision-making systems and they wanted to take full advantage of the possibilities offered by the method of generating clusters that was proposed in the paper [35]. The author searched for a solution to the problem using two approaches. The first approach was to determine the strength of the clusters using some statistical measures [37]. The second approach was to use the Shapley-Shubik index. In this study, the results that were obtained from the two approaches were compared (from this paper and from the paper [37]). The main conclusion is that the use of any approach to determine the strength of a cluster gives better results than an approach that does not use any measure of strength (results from the paper [35]). It is difficult to say which approach for determining the strength of a cluster is better.

Another significant contribution of this paper is proposing a simple method for generating local decisions within one cluster that is used instead of the computationally complex method of eliminating inconsistencies in the knowledge. As was mentioned earlier, one of these methods has a linear complexity, and the other has an exponential complexity. The biggest difference in the execution time of the methods can be observed in the case of a large data set – the Landsat Satellite data set and the results presented in Table 24, Table 25. Of course, the more resource agents there are, the greater the difference in the run time. However, the difference in the execution time is not as great as it could be (only those cases in which the approximated method of the aggregation of decision tables was completed within a reasonable time were considered). The execution time of the approximated method will be much longer in the case in which using a larger value of the parameter 
 will be necessary in order to get good efficiency. Note that for the Landsat Satellite data set, the parameter values for 
 from 1 to 5 were tested because the execution time of the algorithm was too long for larger values. When the value of the parameter 
 was equal to six, the system does not generate a result within two days (after two days the author stopped experiments). For this data set, the approximated method of the aggregation of decision tables can not be fully applied; it can only be used for very small values of the parameter 
. Probably, therefore, for the Landsat Satellite data set, the worse results are obtained using the approximated method of the aggregation of decision tables than using the method of aggregation of the vectors. Considering that currently, in most real cases, we are dealing with huge data sets – the use of the method of aggregation of the vectors with the Shapley-Shubik index is of major importance. Taking into account all of the data sets that were analyzed, an important conclusion that was obtained in this study is that when using the Shapley-Shubik index, the method of vector aggregation usually achieves comparable or better results than the approximated method of the aggregation of decision tables (in only 8 cases out of 28, the approximated method of the aggregation of decision tables generated lower values of the estimator of classification error).

As was mentioned earlier, the method of calculating the Shapley-Shubik index has an exponential complexity due to the number of synthesis agents (proof of NP-completeness can be found in the paper [26]). Thus, a limitation of the application of this method may be the execution time. Usually, the number of synthesis agents in a system is rather small. However, if the number of agents in the data set is large, instead of calculating the exact value of the power index, we can use approximate approaches, which have been discussed in the articles [14], [27]. These approaches are linearly dependent on the number of players.

The main two conclusions drawn from the results are as follows. When the Shapley-Shubik index is used, then comparable results are generated by the vectors' aggregation method (linear complexity) and the approximated method of the aggregation of decision tables (exponential complexity). We get better results when the coalitions' influence on the final decision depends on the Shapley-Shubik index than when we do not use any coalitions' weights. Statistical analysis was performed to confirm these observations. The results were divided into four groups: Group 1 – the approach using the Shapley-Shubik index and the approximated method of the aggregation of decision tables; Group 2 – the approach using the Shapley-Shubik index and the aggregation of the vectors; Group 3 – the approach without using the Shapley-Shubik index, which was considered in the paper [35]; Group 4 – the approach without using the Shapley-Shubik index, considered in the paper [37]. A set of 28 observations with four dependent variables was obtained (all data from Tables 16 – 27 were used). The Friedman's test was performed at first. The test confirmed that the differences between the classification error in these four groups are significant, with a level of . Then, in order to determine the pairs of groups between which statistically significant differences occur, a nonparametric Wilcoxon each pair test and a parametric t-test for dependent groups were performed. Both tests showed that there is no significant difference between the pair Groups 1 and 2. This means that the hypothesis that the mean errors in both groups are the same cannot be rejected. So when we use the Shapley-Shubik index, there is no need to use the complex method of aggregation of decision tables. The much simpler method of vectors' aggregation produces comparable results. For the following pairs: Groups 1 and 3, Groups 1 and 4 and Groups 2 and 3, the importance of differences was confirmed at a significance level less than 0.05 (the exact p-values are given in Table 28). Thus, the hypothesis was confirmed that it is better to use the Shapley-Shubik index (results from Groups 1 and 2) than not to use any weights (results from Group 3). It is difficult to say which method of calculating coalitions' weights is better. It should be noted that both tests did not confirm statistical significance for the errors obtained in Group 2 and Group 4.


Table 28. p-Values for a nonparametric Wilcoxon each pair test and a parametric t-test.

Group 3	Group 4
Wilcoxon	t-test	Wilcoxon	t-test
Group 1	0.00003	0.00002	0.02	0.0066
Group 2	0.0008	0.0011	–	–
To summarise, using the method of vector aggregation in conjunction with the Shapley-Shubik index can be applied in practice for large data sets such as the Landsat Satellite data set. For such data sets, the use of the approximated method of the aggregation of decision tables with large values of parameter 
 is not possible due to the long execution time. Therefore, for the data sets for which the approximated method does not generate a result within a reasonable time, at larger values of the parameter 
, the proposed in the paper approach should be applied. In such cases, the method of aggregation of the vectors with the Shapley-Shubik index generates better results in a short time. In practice, this property of the proposed approach is very important because, in applications such as medicine, banking, credit risk, fraud detection and recommender systems, there are huge data sets that are often in a dispersed form. As was confirmed experimentally for such data sets, the best results are obtained by the method of vector aggregation in conjunction with the Shapley-Shubik index. Furthermore, these results are obtained in the shortest time. This is the greatest advantage of the proposal.

8. Conclusion
In this paper, using the Shapley-Shubik power index in a dispersed decision-making system is proposed. In cases in which global decisions are taken based local decisions, the voting method is used very often. When decisions are taken by a vote, the Shapley-Shubik power index is often used to evaluate the actual ability of agents to influence the outcome of the vote. Therefore, using the Shapley Shubik index in a dispersed decision system appears to be very natural and obvious approach.

There was a presumption that using the Shapley-Shubik index would not require the method of elimination of inconsistencies in knowledge that is computationally complex. Therefore, in the paper, the results that were obtained using the approximated method of the aggregation of decision tables were compared with those that were obtained using a much simpler method – the aggregation of the vectors that determine the level of certainty with which resource agents make decisions.

Based on these results, it can be concluded that using the Shapley-Shubik index in conjunction with the method of vector aggregation gives good results for systems with a smaller number of resource agents.

