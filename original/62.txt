Abstract
The present study investigates the potential of measuring a person's stress level by their computer mouse usage. This measurement approach is based on the assumption that cognitive and physiological changes due to stress do manifest in measurable psycho-motor changes when using the mouse. We conducted a within-participant laboratory experiment in which we captured the mouse usage of N = 53 participants during four tasks in a high-stress and a low-stress condition. Although self-report as well as physiological data indicated successfully manipulated differences in stress level between the conditions, we failed to find clear differences in mouse usage as a function of stress level. Theoretical as well as methodological challenges of the research area, which emerged from the results, are discussed.

Previous
Next 
Keywords
Computer mouse

Usage

Behavior

Unobtrusive

Stress

Measurement

Machine learning

1. Introduction
To unobtrusively measure human affective, mental and physical states has received growing interest in recent years due to advances in technology and computational power (Mohr et al., 2017; Picard, 2014). Several measurement approaches have emerged that utilize sensors that monitor target processes such as facial expression or heart rate (Calvo and D'Mello, 2010). One largely overlooked but ubiquitous and promising sensor is the computer mouse. The mouse allows continuous, unobtrusive data gathering without the need of extra equipment in settings where computers are frequently used (e.g., in the office).

The present study focuses on the potential of using the computer mouse for acute stress measurement. Stress is an omnipresent characteristic of contemporary life in western societies with an increasing prevalence (American Psychological Association, 2018). In the short-term, a stress reaction indicates that an individual is overwhelmed (Zapf and Semmer, 2004) and in the long-term, frequent exposure to stressful events or circumstances paired with insufficient coping or recovery can lead to chronic strain, which imposes considerable cost on individuals and society (Hassard et al., 2018; Scott et al., 2018). Consequently, being able to efficiently monitor stress is of importance in order to deliver just-in time counter measures against a situational overload and to prevent lasting health impairments (Alberdi et al., 2016).

First empirical studies demonstrated the potential usefulness of stress measurement through mouse movement (e.g. Hibbeln et al.; 2017; Yamauchi and Xiao, 2018). However, the empirical evidence is sparse, and studies are heterogeneous in their reasoning (if there is any), methodological approaches and results. The present paper tries to advance the field by providing a critical overview of the empirical state-of-the-art as well as the theoretical connection between stress and goal-directed mouse use and an examination of the proposed relationship in an explorative empirical study. Furthermore, we try to advance the field by making our study materials, data as well as analytical approaches openly available at http://doi.org.ezproxy.auckland.ac.nz/10.5281/zenodo.3941808.

2. Background
2.1. Stress and stress measurement
Stress is a broad concept that has multiple meanings depending on the perspective (Beehr, 2014; McEwen, 2000). In biological terms, stress describes an adaptive physiological process to situational demands (Heinrichs et al., 2013). In contrast to this neutral definition, in psychological terms, stress is often used to describe a response to a situation that is appraised as taxing or exceeding one's resources and endangering one's well-being (Lazarus and Folkman, 1984). In the latter perspective, stress describes a state of negative tension sometimes referred to as distress to distinguish it from a neutral or even positive (eustress) understanding of stress (Zapf and Semmer, 2004). In the present study, we adopted the negatively couched definition, because it is important to identify when an individual feels overwhelmed. Today's increasingly volatile, uncertain, complex and ambiguous society (Grönlund, 2007) confronts individuals with repeated stressors. An accumulation of stressful episodes can lead to chronic strain with possibly lasting health impairments if the individual is not able to cope with the stressors or if the individual is not able to adequately recover from them (McEwen and Seeman, 2003). Moreover, today's stressful episodes most likely are rooted in cognitive or emotional demands (Grönlund, 2007). In such situations, the physiological adaption process of stress seems largely inept or even maladaptive for the individual. For example, a stress reaction because of an upcoming deadline might cause increased physical agitation and reduced higher cognitive functioning (Arnsten, 2009), which results in less productivity and an increase in anxiety that the upcoming deadline cannot be met. Reliable and unobtrusive measurement of acute distress is an important first step in order to mitigate or prevent negative stress-related consequences.

There exists a variety of stress measurement approaches (for reviews see Alberdi et al., 2016; Can et al., 2019). Perhaps the most common and straightforward way to assess stress is by self-report. Asking a person directly about their perceived stress level is intuitive, easy, cheap, and it does justice to the subjective nature of stress since a situation may be judged differently depending on its importance to a person and his or her personal resources to cope with it (Lazarus and Folkman, 1984). For the purpose of non-obtrusive and/or long-term stress measurement, self-report, however, is inept, because it requires the target person's attention and collaboration. Another disadvantage of self-report is its subjectivity and thus falsification due to idiosyncrasies and bias (e.g., memory bias) (Paulhus and Vazire, 2007). Additionally, people might not be fully aware of how much they are stressed, or they might not be able to notice subtle changes (Alberdi et al., 2016).

A second approach to measuring stress makes use of physiological signals and is popular for attempts in automatic stress or emotional state detection (Calvo and D'Mello, 2010). In response to stress, the central nervous system undergoes a complex physiological process (for a comprehensive review see Pruessner et al., 2010). Various methods and parameters exist to quantify these physiological mechanisms and therefore the stress response (Alberdi et al., 2016; Can et al., 2019). Often-used procedures and physiological stress markers include the electrocardiogram to measure heart activity, electrodes to measure electrodermal activity and saliva tests or hair samples to determine the acute or cumulative cortisol level and therefore the hormonal stress response. The physiological approach, by contrast to the self-report approach, provides “objective” data about an individual's physiological arousal. While a high-resolution measurement of physiological signals often requires expensive and obtrusive equipment, wearable sensors such as smartwatches that can continuously measure one or more physiological signal are becoming cheaper, less obtrusive and more reliable (for a review on available technologies and current challenges of the field, see Can et al., 2019).

A third approach makes use of behavioral measures. Stress measurement via the computer mouse is an example of such a behavioral approach. Its rationale is that the stress response manifests in psycho-motor changes when using the mouse. Compared to the physiological approach, behavioral approaches have been used much less so far (Alberdi et al., 2016). Next to mouse usage, other behavioral approaches include the analysis of posture, facial expression, pupillary response, speech or touch interactions on smartphones (e.g. Ghosh et al., 2019; Matthews et al.s, 2020). Similar to physiological measures, behavioral measures use sensors such as a camera to catch subtle changes that can be quantified into stress markers. The preeminent advantage of using the mouse for stress measurement is that it is a ubiquitous sensor integrated in everyday life that allows continuous data collection without the need for extra equipment and without the need for the user to change his or her customary behavior, making it an objective, cheap, convenient and unobtrusive measurement instrument. The disadvantage of using the computer mouse for stress measurement is that the measurement is tied to computer usage, which limits its potential spread. There are two main areas of application: (1) in work-related contexts (Alberdi et al., 2016) and (2) in human-computer interaction (Hibbeln et al., 2017). The workplace is one of the most common and strong sources of stress (American Psychological Association, 2018) and at the same time it is a context that often requires computer use. In a German survey, almost 50% of the participants reported that they frequently use a desktop computer or laptop in their job (Bitkom, 2018), and a survey among office workers showed that they spend on average 6.5 hours on the computer during a typical workday (Entwisle, 2020). Although the computer mouse is not the only input device to navigate on the computer, the absolute usage figures highlight that a considerable number of individuals use the computer mouse for a considerable amount of time during their day in a context in which stress measurement is important. In the human-computer interaction context, stress measurement via the computer mouse can help to improve user experience (Hibbeln et al., 2017). For example, in an e-learning context, if the mouse usage patterns indicate that the user is stressed, the e-learning application could provide additional guidance or suggest a break.

2.2. The computer mouse as a measurement instrument
In a theoretical paper, Zimmermann et al. (2003) proposed the idea to infer the user's emotional state from his or her computer device usage and explained the advantages of this method compared to other emotional state recognition techniques. Their research was motivated by the idea to improve the user experience in human-computer interaction by letting the computer “know” about the user's emotional state and therefore be able to adapt accordingly (Zimmermann et al., 2003). Zimmermann (2008) followed this up with an empirical study, in which participants did an online shopping task after an emotion manipulation through movie clips. There was a significant correlation between mouse movement parameters such as the duration of the cursor movement and participants’ self-rated arousal. Since then, other studies have picked up the idea and tested it using different mouse usage tasks, mouse usage parameters as well as emotional states.

Most studies focused on the relationship between mouse usage with valence and arousal as the two fundamental dimensions of emotional states (Russell, 1980). A typical setup consists of an emotion manipulation followed by a mouse usage task. Grimes et al. (2013) used pictures for their emotion manipulation and captured mouse movements while the participants’ rated the valence and arousal of the pictures. They found that participants made more directional changes in their mouse movements and moved their mouse a greater distance after viewing arousing pictures. Participants also moved their mouse a greater distance after viewing negative pictures. However, the authors did not confirm their hypothesis regarding mouse speed and emotional states or negative valence and directional changes. Hibbeln et al. (2017) focused on the relationship between valence with mouse distance and speed in three studies: Study 1 used an unfair versus fair intelligence test to manipulate negative versus neutral valence and a mouse-dragging task. In Study 2, participants purchased an item in a fictional online shop with versus without errors and delays during the website use. In Study 3, which was correlational, participants used a car or laptop configurator on a website and rated their valence after each task. In all studies, mouse distance increased and mouse speed decreased in negative valence conditions. The authors showed in Study 2 and 3 that both mouse parameters predict the valence condition at 82% accuracy (Study 2) and the individual valence ratings with an out-of-sample R² of .17 (Study 3). Yamauchi and Xiao (2018) established a correlation among several emotional states and mouse movements (i.e., distance from an ideal line and directional changes) in four laboratory studies using different emotion induction techniques (i.e., music, film clips, pictures) and capturing mouse movements during choice tasks. Other studies reported significant relationships between computer mouse usage and emotional states (Grimes and Valacich, 2015; Macaulay, 2004; Salmeron-Majadas et al., 2014). Khan et al. (2013) collected mouse data as well as valence and arousal ratings from 26 participants in a field experiment during a period of several days. They found that usage data predicted emotional ratings on an individual level, but not on a group level.

Furthermore, researchers have linked mouse usage to more specific feeling states such as fatigue or stress. Pimenta et al. (2016) captured mouse and keyboard usage during classwork in a computer laboratory to predict user fatigue level at an accuracy of 81%. Ungruh (2015) predicted participants’ fatigue level from their mouse usage during a simulated night shift at 62% accuracy. Sun et al. (2014) let participants work on prototypical mouse tasks in a stress versus non-stress condition. The damping ratio and damping frequency calculated from mouse usage (both parameters are proxies for muscle stiffness) differed between the conditions. Moreover, the authors used their data to classify stress versus non-stress on unseen mouse data using machine learning at 70% accuracy. Finally, Kowatsch, Wahle and Filler conducted a laboratory study (2017a) and a field study (2017b) to examine the relationship between stress and mouse speed. In the laboratory study, participants were exposed to either a stressor or a control task before and after retracing the edge of a square with the computer mouse: Mouse speed differed between the two trials in the stress condition, but not in the control condition. In the field study, mouse speed as well as valence and arousal ratings were collected in frequent intervals from 62 employees during their working hours: Mouse speed predicted a combination of the arousal and valence rating coined as eustress (high arousal with positive valence) and distress (high arousal with negative valence).

Overall, the empirical evidence supports the idea that emotional states are reflected in an individual's mouse usage behavior. However, the tentative picture in the literature is blurry, and more research is needed to verify and carve out effects. Most studies provide no, little or fragmentary theoretical reasoning regarding a connection between emotional states and mouse usage, which has resulted in the observable heterogeneous use of concepts, approaches and results. Therein, most studies do not focus on stress per se. Furthermore, as Yamauchi and Xiao (2018) pointed out, many studies used a small sample and have considerable methodological flaws or limitations.

2.3. Tapping theory to link stress to mouse usage
Psycho-motor behavior, which among other things underlies mouse usage, has a long research tradition: Fitts (1954) studied the speed-accuracy trade-off in reaching a target depending on the distance to the target and the target`s width. Other authors built on Fitts` findings and constructed models that describe and predict human movement in goal-directed tasks (e.g., Meyer et al., 1988; van Gemmert and van Galen, 1997; Wolpert et al., 1995). Their common ground is the conceptualization of psycho-physical movement as inherently variable because of noise in its processes. In their theory on stress and human motor performance, van Gemmert and van Galen (1997) argue that stress both activates the motor system and enhances neuromotor noise, which affect motor behavior and ultimately task performance (van Galen and van Huygevoort, 2000). They provide support for their theory in studies in which participants carried out different goal-directed hand movements in a high versus low stress condition. Differences in movement and performance-related parameters (e.g., hand pressure, reaction times, error rates) as well as in neuro-motor activations of the involved muscles were observed (van Galen et al., 2002; van Galen and van Huygevoort, 2000; van Gemmert and van Galen, 1997).

Experimental research by other authors who studied the effects of stress on sensorimotor processes supports these results. Compared to control conditions, exposure to stressful or emotional stimuli led to increases in motor-evoked potentials and muscle activity (e.g., Coelho et al., 2010; Finsen et al., 2001; Laursen et al., 2002; Lundberg et al., 1994), facilitated force production (e.g., Coombes et al., 2008; Naugle et al., 2012) and caused changes in motor performance (e.g., Tanaka et al., 2012). Visser et al. (2004) found increased muscle activity and force extension on the computer mouse as well as changes in task performance and mouse usage behavior in a high versus low mentally demanding tasks. In a review of 31 studies, Staal (2004) concluded that stress impairs motor performance, with fine motor skills being at greater risk of impairment.

Another consequence of noise in the motor process is that this variability requires the brain to monitor action plans and adapt them if necessary, making goal-directed movement a continuous interaction between sensorimotor and cognitive processes (Harris and Wolpert, 1998; Song and Nakayama, 2009; Wolpert and Landy, 2012). An emerging stream of research utilizes this binding of cognition and motor processes to study cognitive processes such as decision making in real time using mouse movements (Freeman, 2011, 2018). Although the cognitive processes during movement are not fully understood, cognitive functions such as the working memory or attention have shown to be important elements in motor processes (Gallivan et al., 2016; Mattek et al., 2016). Stress is known to affect cognitive functioning (Elling et al., 2011). A neuroscientific view argues that the stress response is accompanied by increased brain activation in regions responsible for more adaptive and habitual responses alongside decreased activation in regions responsible for higher order cognition (Arnsten, 2009). In line with this hypothesis, the prefrontal cortex, a brain region associated with highest-order cognition, appears to be most sensitive to detrimental effects of stress (Arnsten, 2009). This detrimental effect of stress on higher-order cognition has been shown with regard to working memory (Oei et al., 2006; Qin et al., 2009; Schoofs et al., 2008), attentional control (Sänger et al., 2014), selective attention (Elling et al., 2011) and cognitive control (Plessow et al., 2012). On a similar note, Hibbeln et al. (2017) used Attentional Control Theory (ACT, Eysenck et al., 2007) to explain that negative emotions decrease mouse cursor speed and increase travelled mouse distance. According to ACT, anxiety, an emotional state typically associated with stress (Zapf and Semmer, 2004), causes attention to shift from a goal-oriented to a stimulus-oriented focus. In neuroscientific terms, anxiety suppresses attentional inhibition, which leads to increased information processing, which in turn consumes more working memory capacity, ultimately resulting in slower reaction time (slower mouse speed) and larger deviation from an ideal line between the start and end of a mouse trajectory (increase in distance) (Hibbeln et al., 2017).

Taken together, there is strong evidence that stress affects sensorimotor and cognitive processes involved in goal-directed movements. This supports a link between mouse movement and stress, and it underlines the potential to use the computer mouse as a convenient, continuous and unobtrusive stress measurement instrument. Based on our summary of the research, we tentatively suggest that stress causes a decline in speed and/or accuracy of goal-directed mouse movements. However, both stress as well as mouse movement represent complex processes, and theoretical reasoning as well as empirical evidence are in an early state. We therefore think that the research area is not up to testing specific hypothesis about the relationship between stress and specific mouse usage parameters in specific situations. The goal of the present paper, therefore, was to openly explore the relationship between stress and mouse usage during a variety of typical mouse usage actions. For the time being, such an explorative approach may contribute to advance the field and enable a tentative understanding of the underlying processes.

3. Method
3.1. Participants
Fifty-three participants between 19 and 34 years of age (M = 21.8, SD = 3.4, 40 women and 13 men) took part in the study. Most participants were students (92.5 %), who received course credit in exchange for their participation. The non-student participants did not receive any compensation for their participation. All participants were required to be fluent in German, had normal or corrected-to-normal vision and operated the mouse with their right hand.

3.2. Design
We conducted a within-participant laboratory experiment, in which participants worked on four different mouse usage tasks during a high-stress and low-stress condition. The success of the stress manipulation was assessed using self-report as well as physiological data. Furthermore, the experiment included a typing task, which is not the topic of the present paper. To minimize possible training and novelty effects, a practice phase preceded the actual conditions. The practice phase introduced all tasks in a demo version. The experiment was delivered through a home-programmed single page React web application that ran in the Firefox web browser.

3.3. Stress manipulation
As participants worked on several tasks during each condition, it was necessary to induce differing stress levels during all tasks between conditions and to keep the stress level constant during all tasks within a condition. To meet these requirements, in the high-stress condition we created a persistently and highly demanding situation that participants perceived as uncontrollable and that included social-evaluative threat, as both components have shown to elicit psychobiological stress response in the laboratory (Dickerson and Kemeny, 2004), whereas in the low-stress condition the situation was less demanding. The stress manipulation was similar to related studies (e.g. Arnrich et al., 2009; Sun et al., 2014). We tried to simulate the contrast between a prototypical neutral work situation, which requires basic engagement and mild cognitive effort versus a prototypical stressful work situation, which requires high cognitive effort and performance pressure.

In detail, before every mouse task, participants worked on five mental arithmetic tasks (MAT). MATs are a widespread mental stress induction method in experiments (Dickerson and Kemeny, 2004). Our implementation was loosely based on the Trier Mental Challenge Test (Pruessner et al., 1999). In each MAT, participants saw a mathematical expression (e.g., 5 + 2) in the middle of the screen and buttons with the numbers 0 to 9 arranged in a circle around it (Fig. 1). The participants’ task was to solve the mathematical expression by clicking the button with the corresponding number (here: 7). The correct answer was always a number between 0 and 9. A countdown bar visualized the time limit of 7 seconds per task. Halfway through the time limit, the bar`s color changed from black to red. A score indicated the total performance during all MATs presented in the same condition. A correct mouse click on a number added a point to the score. An incorrect mouse click or no answer during the time limit subtracted a point from the score. Thus, the score could be negative.

Fig 1
Download : Download high-res image (102KB)
Download : Download full-size image
Fig. 1. Screenshot of the mental arithmetic task.

The two stress conditions differed as follows. First, the difficulty of the MATs varied: While in the low-stress condition, the mathematical expressions were simple additions or subtractions involving two numbers in a number range from 0 to 10 (e.g., 4 + 2), in the high-stress condition, there were up to three numbers in each mathematical expression in a number range from 0 to 21 (e.g., 2 + 16 - 13). Second, to increase perceived time pressure, there was a ticking sound with the MATs in the high-stress condition. Third, to increase social-evaluative threat, there was a sound upon wrong answers in the MAT in the high-stress condition, which the experimenter, who was within earshot but out of a participant´s sight, could hear. Fourth, to further increase social-evaluative threat, before the start of the tasks in the high-stress condition, participants were told that their performance is being monitored and evaluated and that additional tests with the experimenter will follow if their performance turns out to be too weak. Before the start in the low-stress conditions, participants were told that their performance is not being monitored or evaluated in any way.

We strictly separated the stress manipulation from the mouse tasks because manipulating stress through changes in the mouse tasks, for example, by adding time pressure to tasks in the high-stress condition (Hernandez et al., 2014), confounds the effects of the emotional state and the stress manipulation on mouse usage.

3.4. Mouse tasks
We created four tasks to measure different aspects of mouse usage behavior (Fig. 2). Following Sun et al. (2014) the tasks represented the basic goal-directed mouse usage actions of clicking on a target, dragging and dropping a target as well as steering the mouse cursor. The source code of all tasks is available for further use. The tasks were identical in the high-stress and low-stress condition. The tasks started immediately after the end of the MATs. Detailed instructions together with a shortened version of each task were given in the practice phase beforehand. All tasks had a time limit. Participants were asked to work as fast and accurately as possible on all tasks.

Fig 2
Download : Download high-res image (318KB)
Download : Download full-size image
Fig. 2. Screenshots of the mouse tasks. From top left to bottom right: Point-and-click task, drag-and-drop task, drawing task, follow-box task.

One of the four mouse task was a point-and-click task: Participants needed to click on a circle that was presented at a predefined position on the screen inside a rectangular task box. After a successful click, the circle reappeared at another predefined position. The task consisted of 26 circle clicks and had a time limit of 30 seconds. The practice phase consisted of 10 circle clicks at different positions with a time limit of 25 seconds.

One of the four mouse tasks was a drag-and-drop task: Participants saw a colored circle in the middle of the task box and colored squares at every corner of the task box. Their task was to drag the circle inside the same-colored square and drop it there. If participants dragged the circle outside of the task box or dropped it outside of the correct square, its position was reset to the task box center. After a successful drag-and-drop, a new colored circle appeared in the task box`s center. The order of the circle`s colors was fixed. The task consisted of 15 drag-and-drops and had a time limit of 60 seconds. The practice phase consisted of 4 drag-and-drops (one for every color) with a time limit of 25 seconds

One of the four mouse tasks was a drawing task: Participants were presented a straight grey line inside the task box. Their task was to redraw the line from a marked starting position to a marked ending position. They were able to draw inside the task box by holding the left mouse button down while moving the mouse. After participants reached the end position of the line with their drawing, the line as well as participant`s drawing was erased and a new line appeared that started at the end position of the previous line. The length of the lines and their direction varied. The task consisted of 13 lines and had a time limit of 60 seconds. The practice phase consisted of 4 lines with a time limit of 25 seconds.

One of the four mouse tasks was the follow-box task: Participants saw a vertically centered grey square at the left border of the task box. The task started as soon as participants moved their mouse cursor inside the grey box. During the task, the box moved back and forth horizontally between the borders of the task box in a straight line with constant velocity. Participants’ task was to keep the mouse cursor inside the moving box. The box`s color indicated whether the mouse cursor was inside (blue) or outside (grey) of the box. The task had a time limit of 30 seconds. The task in the practice phase was identical with a shortened time limit of 20 seconds.

3.5. Measures
Computer mouse usage data was captured through a JavaScript application embedded in the web application. The JavaScript application collected the data in an event-based manner, that is, a data point was created every time a new mouse event (i.e., positional change or click) occurred. The sampling frequency during continuous movement was around 60 Hz, that is, a new data point was generated approximately every 15 ms. Each point consisted of the name of the mouse event, the cursor`s x/y position on the screen, a timestamp and task specific information (e.g., in the point-and-click task the number of circles clicked so far).

The effectiveness of the stress manipulation was assessed in a multi-method manner using self-report and physiological data. After each mouse task, participants were asked to rate their mood's valence (from 0 = positive to 4 = negative) and arousal (from 0 = calm to 4 = excited) on the Self-Assessment-Manikin (SAM, Bradley and Lang, 1994). At the end of each condition, participants rated their affective state in more detail on Version B of the German Multidimensional Mood Questionnaire (Mehrdimensionaler Befindlichkeitsbogen [MDBF]; Steyer et al., 1997). This questionnaire consists of twelve items about emotional states (e.g., “I`m feeling calm”), which are rated on a 5-point scale (from 0 = not at all to 4 = very much) and summarized into the three bipolar subscales good mood versus bad mood (Cronbach's α = .74 in the low stress and α = .91 in the high stress condition), alertness versus tiredness (Cronbach's α = .84 in the low stress and α = .86 in the high stress condition), and rest versus unrest (Cronbach's α = .59 in the low stress and α = .81 in the high stress condition). We additionally appended one item asking directly about the stress level (“I`m feeling stressed) and one item asking about nostalgia (“I`m feeling nostalgic) to the MDBF. The nostalgia item was used to test the specificity of the stress manipulation, as the stress manipulation should only affect stress-related affective states but not the feeling of nostalgia.

We measured heart rate as well as electrodermal activity as physiological stress markers (Alberdi et al., 2016). Both were continuously gathered during the experiment. Heart rate was captured wirelessly via the validated and reliable Polar H7 chest strap (Gillinov et al., 2017; Plews et al., 2017). The sensor collected the interbeat intervals between consecutive heartbeats at a sampling frequency of 1000 Hz (Giles et al., 2015). Electrodermal activity was measured using a standard protocol of attaching two surface electrodes to a participant`s left middle and index finger (van Dooren and Janssen, 2012). A measurement instrument attached to the electrodes collected the skin resistance with a corresponding timestamp at a rate of 60 Hz.

3.6. Procedure
The setup resembled a typical computer workspace with a commercially available computer mouse (Logitech B100, optical USB mouse with 800 dpi) and keyboard. As a cover story, participants were told to participate in a study about the evaluation of computerized tasks. Before the start, an experimenter collected participant`s informed consent and assisted in putting the heart rate sensor and skin electrodes on. To maximize physiological data quality, participants were asked to rest their left hand with the electrodes attached on a marked spot next to the keyboard and to move their hand as well as their body as little as possible during the experiment. After ensuring that the sensors adequately captured data, the experimenter took a seat behind the participant and turned towards the wall away from the participant`s back. The experimenter then stayed there silently for the duration of the session.

The study consisted of five parts: (1) Participants answered demographic questions. (2) Participants went through the practice phase. (3) Participants were randomly assigned to start with the high-stress or the low-stress condition. Both conditions commenced with an information page about whether task performance was being monitored and evaluated during the following tasks. In the high-stress condition, participants checked a box to agree to be monitored, evaluated and re-tested if their performance was low. There was no box to check in the low-stress condition. Next, participants worked on triads of MAT's followed by a mouse task followed by the SAM until they had completed all tasks. The sequence of the triads was randomized between participants but was the same within each participant. After completion of all tasks, participants filled out the MDBF and answered the stress item and the nostalgia item. Each of the two conditions ended with an information page about the end of the task block. Before the end page in the high-stress condition, participants were shown a loading bar and asked to wait “until their performance was evaluated”. After a few seconds, the loading bar disappeared, and a message informed the participants that their task performance was sufficient and no further testing was needed. (4) Participants completed the other condition. (5) Participants answered some self-rating questions, which were not part of the present research project. Finally, participants were debriefed about the stress manipulation. Before leaving, participants were asked to remain seated until they felt relaxed and ready to go.

3.7. Data preprocessing
The mouse, heart rate and electrodermal data required preprocessing consisting of several steps: Heart rate data were separated into data of the high-stress and low-stress condition. The condition data were screened by (1) visually inspecting the plotted data and (2) investigating the number of valid data points and possible artifacts: we considered interbeat intervals below 350 and above 1800 as artifacts in the experimental setting corresponding to a valid beats per minute range between 33 and 171. This procedure revealed five participants with a low number of valid data points or a high number of artifacts (more than 5% of all data points) in one or both conditions. We removed them from further analyses of the heart rate data (remaining n = 48). Next, the condition data were further separated into data of every task during the condition (e.g., point-and-click-task in high-stress condition). Next, those task data were again screened using the same techniques as just described. If this procedure revealed too few valid data points or too many artifacts in a task, we removed the task data of the given participant from further analyses. Finally, we used the Hrvanalysis Python package (version 1.0.3; Champseix, 2018) to linearly interpolate remaining artifacts and calculate the mean beats per minute (BPM) as the targeted stress marker (Alberdi et al., 2016) from the interbeat intervals time series.

Electrodermal data was separated into data of the high-stress and low-stress condition and then screened for anomality. The screening involved visually inspecting the plotted data and investigating the number of valid data points as well as possible artifacts. Unlike with the heart rate data, we did not define a range of valid data points with the electrodermal data, because the values can vary considerably across situations and individuals (Braithwaite et al., 2015). We rather inspected the data for abnormalities such as very small or extremely high variance. This procedure revealed one participant with a mean value of 0 and almost no variance indicating that the participants’ electrodes were not properly attached during the experiment. The participant's data were excluded from further analyses (n = 52). Next, the condition data were separated into data of every task during the condition and screened again. Subsequently, we smoothened the skin resistance time series data using a rolling mean with a subset size of 20 data points and calculated the average skin resistance as the targeted stress marker (Alberdi et al., 2016).

Mouse data had already been collected separately for each task. First, we removed non-task data (e.g., mouse movement to the starting point of the task). Second, we plotted the mouse movement and checked the plots for anomaly resulting from data recording errors or the participants not following instructions. This procedure revealed no conspicuous cases. However, some participants failed to complete one or more tasks in the time limit. We removed participants with incomplete task data from the corresponding mouse task datasets: Six participants were removed from the point-and-click task dataset (n = 46), three from the drag-and-drop task dataset (n = 50) and none from the follow-box task dataset (n = 53). Seventeen participants did not complete the drawing task in at least one condition. To prevent the exclusion of too many participants in the drawing task, we adapted the completion criterion by ignoring all data after 10 of the 13 drawing trials, thus lowering the number of participants to remove from the drawing-task dataset to ten (n = 43). Third, we removed all but one identical data points as they are recording errors, which applied to less than .01% of the data points. Forth, we linearly interpolated the mouse movement data into equally spaced-time steps of 15 milliseconds, a procedure typically done to mouse data (Yamauchi and Xiao, 2018). Last, we used the interpolated data to calculate mouse usage features that represent the behavior during the tasks. Following our understanding of an early and explorative state of research, we chose to calculate as many features as feasible instead of focusing on specific ones. Examples are the average mouse speed during the task and the total mouse distance travelled during the task. We also included some task specific features such as the amount of time the mouse cursor was inside the box in the follow-box task. A list of all features is in the appendix. For the sake of reproducibility, the source code of all data preprocessing is provided.

4. Results
4.1. Manipulation check
To check the success of the stress manipulation, we first tested whether there is an overall difference in participants’ stress level between conditions and second, whether participants’ stress level differed between conditions by task. To do so, we conducted paired-sample t-tests on the self-report and physiological stress measures. The analysis was carried out with the Pingouin package (version 0.3.5; Vallat, 2018) in Python. The package provides the p-value of a significance test as well as well as the approximated scaled Jeffrey-Zellner-Siow Bayes Factor (BF10; Rouder et al., 2009) of a Bayesian t-test, of which we report both.

In the high-stress condition, participants rated their affective state more negative (2.53 versus 3.07, t(52) = -8.80, p < .001, d = 0.75, BF10 > 100) and felt more unrest (1.98 versus 2.50, t(52) = -5.86, p < .001, d = 0.78, BF10 > 100) than in the low-stress condition. There was no difference on the alert versus tired scale, t(52) = 0.78, p = .938, d = 0.16, BF10 = 0.15. Participants reported a higher-stress level (1.81 versus 1.17, t(52) = 5.45, p < .001, d = 0.77, BF10 > 100), but comparable nostalgic feelings (0.38 versus 0.43, t(52) = -0.83, p = .411, d = 0.08, BF10 = 0.21). Physiologically, participants` average BPM was faster in the high-stress as compared to the low-stress condition (85.06 versus 80.80, t(47) = 4.71, p < .001, d = 0.31, BF10 > 100), and their average skin resistance was lower (313.26 versus 337.75, t(51) = -4.69, p < .001, d = 0.17, BF10 > 100). The results support the success of the stress manipulation. The non-significant result for nostalgia supports the specificity of the stress manipulation. As the tasks in both conditions required participants to stay focused and engaged, we had not expected a difference in the alert versus tired scale.

The per-task comparisons between the high versus low-stress condition showed the same pattern (supplementary material). In the high-stress condition, participants rated the valence of their mood as more negative and their arousal as higher, had a higher BPM as well as a lower skin resistance in the point-and-click task, the drag-and-drop task, the drawing task and the follow-box task, supporting the success of the stress manipulation on the task level (all p < .05, 0.15 <= d <= 1.07, all BF10 >= 5.82).

4.2. Mouse usage as a function of stress
If stress affects mouse usage behavior, mouse features might differ between the high-stress and the low-stress condition, as well. With the mouse features within each task, we applied the same statistical procedure as in the manipulation check. Since this involved conducting separate statistical tests with every mouse variable, to prevent an inflation of false positives, we applied Bonferroni correction to the alpha level (Nakagawa, 2004). However, as in line with our exploratory approach, we focused on unveiling variables or patterns of interest in the data that might provide clues for theoretical refinement or future empirical testing. Therefore, we report all tests without a corrected alpha level in parallel. A list of all tests in all tasks is in the appendix.

4.2.1. Point-and-click task
A total of 23 mouse features were compared resulting in a Bonferroni adjusted alpha level of .0022 per test (.05/23). There was no significant difference in any mouse usage feature using the adjusted alpha level. Ignoring the alpha adjustment, in the high-stress condition, participants’ moved a greater total distance (9583px compared to 9373px, t(46) = 2.15, p = .037, d = 0.30, BF10 = 1.29), had a higher standard deviation in their mouse speed (7.08 px/ms compared to 6.79px/ms, t(46) = 2.32, p = .025, d = 0.27, BF10 = 1.78) and a higher standard deviation in their movement angles (19.90° compared to 19.42°, t(46) = 2.23, p = .031, d = 0.37, BF10 = 1.49). The BF10 of all other mouse features in the point-and-click task was < 1, providing evidence against an effect of stress on the mouse usage features.

4.2.2. Drag-and-drop task
A total of 23 mouse features were compared resulting in a Bonferroni adjusted alpha level of .0022 per test (.05/23). There was no significant difference in any mouse usage feature for both the adjusted and the original alpha level. The BF10 of all mouse features in the drag-and-drop task was < 1, providing evidence against an effect of stress on the mouse usage features.

4.2.3. Drawing task
A total of 23 mouse features were compared resulting in a Bonferroni adjusted alpha level of .0022 per test (.05/23). There was no significant difference in any mouse feature for both the adjusted and the unadjusted alpha level. The BF10 of all mouse features in the drawing task was < 1, providing evidence against an effect of stress on the mouse usage features.

4.2.4. Follow-box task
A total of 20 mouse features were compared resulting in a Bonferroni adjusted alpha level of .0025 per test (.05/20). There was no significant difference in any mouse feature for both the adjusted and the original alpha level. The BF10 of all mouse features in the follow-box task was < 1, providing evidence against an effect of stress on the mouse usage features.

4.3. Using mouse features for stress prediction
We tested the accuracy of predicting the high-stress versus low-stress condition from the mouse data during each task. Machine learning algorithms were used to build (“train”) a model based on a randomly drawn part of the data and then tested the model's prediction accuracy on the remaining data. Instead of testing each mouse feature individually, the approach allowed us to test whether machine-learning models are able to identify systematic patterns in the data that hint at an effect of stress on mouse usage. Note that there is an infinite number of models that can be fit to the data. The approach therefore only lets us test if a specific model or specific set of models is able to find a relationship between stress and mouse usage and does not allow rejecting the existence of a relationship between mouse usage and stress as in statistical hypothesis testing.

The implementation of the analysis proceeded in steps. Most steps required a decision among several options (e.g., choosing a machine learning algorithm). As there exist infinite possibilities to fit a model to our data and there exists no model that works best for every problem (Wolpert and Macready, 1997), we tried out different options that had been used by others for a similar purpose (Hibbeln et al., 2017; Yamauchi and Xiao, 2018). The two Python packages Scikit-learn (version 0.20.1; Pedregosa et al., 2011) and MLxtend (version 0.16.0; Raschka, 2018) supported our analysis.

The first step was about choosing a suitable model performance evaluation approach. Relying on just one (random) split of the data into a training and a testing dataset may lead to bias, especially in small datasets (Kuhn and Kohnson, 2013). Therefore, we used 5-fold cross validation (Kuhn and Kohnson, 2013) and out-of-bag bootstrapping (Breiman, 1996). In 5-fold-cross validation, the dataset is split into five approximately equal parts. In five iterations, four parts are used for training the model while the remaining part is used for testing the model in such a manner that every part is used for testing once. Model evaluation then comprises an average prediction performance as well as the variance of prediction performance indicating the model`s stability. To assess the significance of our average model performance, we compared it to a distribution of 1,000 model performance tests on permutated class labels (Ojala and Garriga, 2010). If our model outperformed the models with permutated class labels at least 950 times (p < .05), we considered it to be better than random. In out-of-bag bootstrapping, a training dataset is created by resampling the dataset. All samples that were not drawn during resampling (out-of-bag samples) are used as the testing dataset. This procedure iterates to create a distribution of prediction performances, which allows the calculation of the average prediction performance, the variance of the prediction performance and a confidence interval of the prediction performance (Breiman, 1996). Here, the significance of the model is assessed using confidence intervals. Because of the within-study design, the dataset contained two rows of data for each participant (i.e., one from the high-stress condition and one from the low-stress condition). To consider this group structure, for both the 5-fold-cross validation as well as the out-of-bag bootstrapping, the dataset was split in a way that data from one participant was either only used for training or for testing.

The second step was about choosing a model performance evaluation criterion. We chose the fraction of correct predictions (i.e., accuracy), because it is easy to understand. The baseline accuracy for this study is 50% (i.e., randomly guessing one out of two conditions).

The third step was about choosing a classification algorithm. We used four algorithms: logistic regression, k-nearest neighbors, support-vector machines and random forest. All algorithms have been previously used for similar purposes (e.g., Vizer et al., 2009; Yamauchi and Xiao, 2018). We mostly used the algorithm`s default hyperparameter settings of the Scikit-learn package (version 0.20.1) and refrained from hyperparameter optimization following the rationale of conservative hypothesis testing by Yamauchi and Xiao (2018). For the logistic regression, it was the “liblinear” solver, L2 regularization and an inverse regularization strength of C = 1.0. For the k-nearest neighbors, we used three neighbors. For the support vector machine, the kernel was a radial basis kernel, the gamma parameter was 1/(the number of features * the variance of the flattened input feature matrix) and the inverse regularization strength C = 1.0. For the random forest, the number of tress was 100 and there was no set maximum depth. See the code for a complete overview.

The last two steps were about preprocessing the data. All preprocessing was done on the training dataset and then applied to the testing dataset. First, we standardized each mouse feature by subtracting the mean and dividing by the standard deviation. Second, we reduced the number of input features using feature selection. For every task, we had at least 20 mouse usage features and a maximum of 106 samples resulting in a high number of features compared to the number of samples. It therefore makes sense to reduce the number of input features to simplify the model, shorten training time and reduce overfitting (Guyon and Elisseeff, 2003). Moreover, reducing the number of input features can help identifying which features are especially important for stress measurement via the computer mouse. Different feature selection methods exist, from of which we used two: The first method is based on univariate statistical tests (sometimes called filter-technique, Guyon and Elisseeff, 2003). Here, we chose the five features with the highest t-values in a paired-sample t-test comparing the features in the high- and low-stress condition. The second method makes use of feature selection processes embedded in some machine learning algorithms (embedded-technique, Guyon and Elisseeff, 2003). Here, we used a random forest classifier on the training data and used its ranking of feature importance to select all features with an importance score greater than the mean. Next, we trained models using all selected features, resulting in 24 stress predictions per task. Note that testing the significance of multiple machine-learning models represents capitalization on chance similar to testing multiple mouse usage features. Bonferroni-corrected alpha levels of the permutation test are .0021 (.05/24) and Bonferroni-corrected confidence intervals of the out-of-bag bootstrapping are 99.79%. However, instead of solely looking at statistical significance after Bonferroni-correction, in the interest of unveiling patterns of interest we report the results with uncorrected alpha level in parallel.

Out of all 96 models, three models performed better than chance in the permutation test when ignoring Bonferroni correction of the significance level: in the point-and-click task, the k-nearest neighbors model with all mouse features (60.67% accuracy, p = .04) and with the filter feature selection (61.00% accuracy, p = .02) and in the drawing task, again the k-nearest neighbors model with all mouse features (59.58% accuracy, p = .05). No other predictions in any of our mouse tasks were significantly better than random guessing (Table 1). Fig. 3 exemplarily shows the results of the permutation test and out-of-bag bootstrap in the drawing task using the support-vector machine algorithm and the filter feature selection technique.


Table 1. Condition classification using engineered mouse usage features.

All features	Filter feature selection	Embedded feature selection
5-Fold-CV	Bootstrap	5-Fold-CV	Bootstrap	5-Fold-CV	Bootstrap
Acc	p	Acc	CI	Acc	p	Acc	CI	Acc	p	Acc	CI
Point-and-click task (23 features, 92 samples)
LR	49.00 (7.31)	.57	48.45 (7.21)	[34.40, 62.50]	54.22 (2.13)	.18	50.41 (6.91)	[37.50, 64.70]	50.00 (4.73)	.51	50.81 (6.70)	[37.50, 63.90]
KNN	60.67 (7.73)	.04*	54.70 (7.52)	[40.00, 68.20]	61.00 (10.96)	.02*	49.44 (8.23)	[34.20, 65.60]	54.56 (6.31)	.21	52.02 (7.79)	[36.10, 66.70]
SVM	51.22 (5.99)	.41	50.78 (7.07)	[36.70, 63.90]	54.22 (5.18)	.19	50.12 (6.71)	[36.10, 63.30]	52.11 (8.99)	.35	50.46 (6.34)	[38.20, 62.50]
RF	51.22 (3.98)	.45	48.53 (6.91)	[35.30, 61.80]	52.44 (8.70)	.32	50.73 (7.89)	[34.40, 65.40]	56.56 (8.18)	.13	50.31 (8.41)	[35.70, 64.70]
Drag-and-drop task (23 features, 100 samples)
LR	53.00 (9.27)	.32	50.47 (6.67)	[37.50, 63.60]	46.00 (7.35)	.84	48.55 (6.26)	[36.10, 60.50]	47.00 (5.10)	.75	50.18 (6.62)	[36.80, 62.50]
KNN	49.00 (5.83)	.59	50.40 (7.40)	[36.40, 65.40]	48.00 (6.00)	.63	50.42 (7.87)	[35.00, 66.70]	45.00 (13.78)	.84	48.48 (8.00)	[32.40, 63.90]
SVM	41.00 (9.70)	.95	47.10 (7.12)	[32.50, 60.50]	42.00 (10.77)	.93	48.29 (6.88)	[34.60, 61.80]	48.00 (11.22)	.66	46.62 (6.82)	[33.30, 60.00]
RF	46.00 (5.83)	.72	48.62 (7.15)	[34.20, 61.90]	50.00 (7.07)	.53	51.33 (7.49)	[36.80, 66.70]	48.00 (9.80)	.66	48.68 (7.25)	[34.20, 63.20]
Drawing task (23 features, 86 samples)
LR	39.31 (8.95)	.97	44.13 (6.83)	[30.00, 56.70]	49.03 (5.62)	.59	45.47 (6.13)	[33.30, 57.10]	34.86 (7.59)	1.00	43.21 (6.76)	[30.00, 56.20]
KNN	59.58 (8.81)	.05*	48.60 (7.60)	[34.40, 63.70]	54.44 (9.07)	.22	51.11 (8.39)	[33.30, 67.90]	51.53 (14.04)	.41	50.79 (7.94)	[35.50, 66.70]
SVM	55.00 (13.65)	.17	53.46 (6.01)	[41.70, 65.60]	50.14 (6.22)	.48	51.01 (6.79)	[37.50, 63.90]	51.53 (14.73)	.38	53.44 (6.46)	[40.00, 66.70]
RF	59.44 (9.88)	.07	53.15 (7.09)	[39.30, 66.70]	47.50 (7.67)	.70	51.61 (8.06)	[36.10, 66.70]	60.14 (11.02)	.05	53.15 (7.47)	[38.20, 67.90]
Follow-box task (20 features, 106 samples)
LR	40.55 (8.06)	.97	46.28 (6.67)	[33.30, 58.80]	51.00 (8.50)	.41	46.46 (5.60)	[35.30, 57.10]	47.27 (13.93)	.72	45.07 (6.15)	[32.50, 55.90]
KNN	50.00 (4.27)	.51	50.76 (6.91)	[36.80, 63.90]	52.73 (11.06)	.29	49.80 (7.55)	[35.30, 66.00]	55.73 (3.59)	.14	49.47 (7.08)	[36.10, 62.50]
SVM	49.09 (4.64)	.58	49.45 (5.97)	[38.10, 60.50]	50.27 (11.05)	.47	49.23 (6.22)	[37.50, 61.40]	50.09 (3.02)	.49	49.32 (6.14)	[37.50, 61.80]
RF	50.00 (7.61)	.50	48.69 (6.74)	[35.70, 61.10]	46.36 (8.25)	.77	47.55 (7.21)	[34.20, 62.50]	46.09 (12.42)	.76	48.10 (6.62)	[35.30, 60.50]
Note. The rows represent the results of an algorithm and the columns the results of the feature selection and validation procedure. In the accuracy (Acc) columns are the model's mean accuracies (standard deviations in parentheses) either based on 5-fold-cross validation or out-of-bag bootstrapping. The p-values represent the percentage of the cases in which the mean accuracy of 5-fold-cross validation outperformed the accuracies of the permutated class labels. The confidence intervals (CI) represent 95% of the bootstrapped accuracies. LR: logistic regression; KNN: k-nearest neighbors (with 3 neighbors); SVM: support vector machines; RF: random forest. *p < .05, ⁎⁎p < .002 (Bonferroni-corrected p-value).

Fig 3
Download : Download high-res image (451KB)
Download : Download full-size image
Fig. 3. Exemplary histograms of results from the permutation test (left) and bootstrapping (right) in the drawing task using the support vector machine algorithm and the filter feature selection. In the permutation test plot, the histogram represents the results from accuracy predictions of the randomly permutated class labels. The blue lines represent the confidence interval of the permutation scores, the green line the average permutation score, and the red line the average score of the 5-fold-cross validation with the actual class labels. In the bootstrap plot, the histogram represents the results of the bootstrapped accuracies. The blue lines represent the confidence intervals of the bootstrap results, the green line the accuracy of random guessing and the red line the mean accuracy of the bootstrap results. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)

4.4. Using mouse data for stress prediction without relying on engineered features
Although being based on theoretical reasoning and previous research, the selection of mouse features remained somewhat arbitrary, and information was lost during the transformation of the raw data into features. To remediate these problems, we additionally attempted to predict the stress condition using the raw mouse data without feature engineering. This was done in two ways. First, we created images of the mouse movement during each task from the raw data and used the resulting images for classification. The procedure was inspired by an online course about deep learning and its implementation using the Fastai package (version 1.0.59; Fastai, 2019) in Python (Howard, 2019). To visualize mouse data points, we created a scatterplot of the mouse click's and cursor position's x- and y-coordinates with the x- and y-axis of the plot corresponding to the screen size of 1920 × 1080 pixels. The size of each data point was set to be one pixel. The sequence of the mouse movement data points was visualized by assigning a color to each data point from purple to yellow, while mouse clicks were marked as black dots (Fig. 4 for an example). We used 5-fold-cross validation to evaluate the prediction performance. The classifier algorithm was a convolutional neural network (CNN) optimized for image classification (resnet34). Data preprocessing included resizing and cropping the image and normalizing the image data. The results revealed accuracies close to random guessing for each of the four mouse tasks (Table 2).

Fig 4
Download : Download high-res image (76KB)
Download : Download full-size image
Fig. 4. Mouse usage behavior of a participant during the drawing task. The rectangular frame represents the computer screen. The dots represent single mouse data points. Mouse movement data points are chronologically ordered from purple to yellow. Mouse clicks are black. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)


Table 2. Condition classification using images and time series.

Image classification	Time series classification
Point-and-click task	48.89 (2.22)	50.00 (0.00)
Drag-and-drop task	52.5 (4.33)	50.00 (0.00)
Drawing task	51.43 (7.00)	50.00 (0.00)
Follow-box task	50.00 (0.00)	50.20 (1.51)
Note. The columns represent the model's mean accuracies (standard deviations in parentheses) based on 5-fold-cross validation.

Second, since translating the raw data into images of the mouse's movement and clicks might be more preservative of spatial rather than temporal information, we focused on the temporal information by considering mouse movements and clicks as a time series of x- and y-coordinates. Our implementation was guided by blog posts about time series analysis and sequence classification (Brownlee, 2016a, 2016b, 2017) with slight modifications to fit the characteristics of our data. The classifier algorithm was a long short-term memory recurrent neural network (LSTM), which handles the sequence dependence of time series data (Brownlee, 2016b). Our model had one LSTM layer with 32 memory units and a LTSM dropout of 20%. Three data preparation steps preceded the classification: (1) Since LSTMs require uniform time steps between data points (Brownlee, 2017), we used interpolated mouse data. (2) The task data were split into smaller data chunks, because the number of data points of the entire task exceeded the recommendations on the number of data points that work best with LSTMs (Brownlee, 2017). Whenever possible, the task data were split in a way that they represented a single trial in a task (e.g., movement from one click to another click in the point-and-click task). We added some overlap to better represent the mouse usage behavior between the trials as it might carry information. (3) LSTMs require the data samples to be equal in length (Brownlee, 2017), which was not the case in the present study because the number of data points varied among trials and participants. To prevent information loss from removing data points, we equalized the data samples’ length by setting the length equal to the length of the longest trial and padded the length of all shorter trials with negative one values (i.e., the input vector of x-coordinates in a shorter trial was filled with -1, -1, -1, etc. to match the length of the longest input vector of x-coordinates). Again, the classification results revealed accuracies close to random guessing with each task (Table 2).

5. Discussion
The present study attempted to shed light on the potential of using a standard computer mouse for stress measurement. Using the mouse to reliably and validly measure feeling states such as stress would be a tremendously beneficial addition to existing stress measurement approaches. Theoretical reasoning about the effects of stress on cognitive and physiological processes in goal-directed motor behavior as well as first empirical studies into the relationship of computer mouse usage and emotional states suggest that stress alters mouse usage behavior during goal-directed tasks. At the same time, the research area is in an early stage without a deeper understanding of the underlying processes or precise correlations. To explore the relationship in more detail, we conducted a within-participant laboratory experiment in which participants worked on four mouse tasks in a high-stress versus low-stress condition. Self-reported as well as physiological data clearly evidenced the success of the stress manipulation: Participant's acute stress level proved to be higher in the high-stress than in the low-stress condition. Summarizing the results of all of the manifold data analytical approaches for the four different mouse tasks that tapped into different aspects of mouse usage behavior, we found no clear evidence for an effect of stress on mouse usage. There was a tendency that mouse usage behavior differed between the high-stress and low-stress condition in the point-and-click tasks with results slightly better than the significance threshold, which, however, vanished after Bonferroni-correction for multiple testing. Additional Bayesian analysis also provided little evidence in favor of an effect of stress on mouse usage and more evidence against such an effect. There was no other consistent or converging pattern between stress and mouse usage across the mouse tasks and data analytical approaches.

It is important to note that our data analysis was exploratory. The results do not allow ruling out that there exists a relationship between mouse usage and stress. However, in the present dataset with our manifold data analytical procedures, we were not able to find a consistent relationship. With different analytical approaches, other samples, designs and/or materials, a relationship might show up after all. Yet, the lack of clear evidence in the present study suggest that there is no straightforward generalizable relationship between mouse usage and stress. That is why the results lead us to act the devil's advocate in this budding research area. Comparing our initial evaluation of the research area with our evaluation of this research area after taking the results of the present study into account, we realize that we examined some aspects in the research area too superficially and might have never noticed them if the results of the present study had been different.

5.1. Critical evaluation of the research area
Even though the results of previous studies in sum hint at an influence of feeling states on mouse usage, we also pointed out a dearth of theoretical reasoning and empirical evidence in this area. As a matter of fact, the fragmentary state-of-the-art motivated us to conduct our own empirical study and use an exploratory data analysis approach about the effect of stress on mouse usage. Given the lack of evidence in favor of a consistent influence of feeling states on mouse usage in the present study, it seems even more necessary to illustrate ambiguities and shortcomings of previous research on the one hand and carve out differences of this study compared to other studies on the other hand.

Overlooking the available literature in hindsight, it stands out that much of the research seems to remain an initial attempt to study the effect of emotional states on mouse usage without a follow-up on the initial findings with confirmatory or detail-digging studies. There exist many empirical reports about pilot studies (e.g., Hernandez et al., 2014; Kowatsch et al., 2017a) as well as outlines of the general idea or possible implementations that do not provide empirical data (e.g., Kaklauskas et al., 2011; Zimmermann et al., 2003). Yet, to the best of our knowledge, at the writing of this report there exist only a few comprehensive studies about potential effects of emotional states on mouse usage (i.e., Hibbeln et al., 2017; Yamauchi and Xiao, 2018). We can only speculate on the reasons for this discrepancy. It is plausible that in some cases more research attempts got stuck in a dead end with no clear results or with limitations that lead to abandonment. As a result, there possibly is publication bias, in that studies that failed to bolster the initial promises are not part of the available literature. This comes in addition to the publication bias that harks back to journals’ publishing preferentially papers with statistically significant effects rather than those with null results. Likewise, Yamauchi and Xiao (2018) criticize that most of the empirical evidence in this research area is based on studies with small samples, with methodological flaws and/or with severe limitations.

Moreover, overlooking the results of previous research, we are not able to identify clear patterns in the relationship between emotional states and mouse usage. Within studies there were both significant and insignificant correlations between specific mouse usage features and specific emotional states. Between studies, the correlations tend to be heterogeneous. For example, Hibbeln et al. (2017) found an association between mouse speed and valence as well as mouse distance and valence in their three studies, but no association between mouse movement and arousal. Grimes et al. (2013) found an association between mouse distance and both valence and arousal, but mouse speed and valence were not correlated. Zimmermann (2008) found no correlations between mouse movement (here different mouse features are grouped together using principal component analysis) and both valence and arousal in one study and a correlation between mouse movement and arousal, but not valence in another study. In their field study, Kowatsch et al. (2017b) neither found correlations between mouse speed collected during employee's working hours and valence or arousal, but between mouse speed and a combined valence-arousal score. In the hitherto most comprehensive paper on the relationship between feeling states and mouse usage, Yamauchi and Xiao (2018) present four experiments, of which each relied on a relatively large sample, and all four experiments relied on the same mouse task, but used different emotion manipulation techniques as well as different questionnaires capturing different emotional states. Although Yamauchi and Xiao (2018) found links between mouse movements and self-reported emotional states in all of their experiments, the results do not seem to condense into a pattern: In the first experiment, mouse movement was correlated with anxiety in men and women. In the second experiment, mouse movement was correlated with all positive emotions of the PANAS-X (Watson and Clark, 1999) in men and women, but not with any negative emotion of the PANAS-X. In the third experiment, mouse movement was correlated with some positive emotions and one negative emotion of the PANAS-X in women. In men, there was a correlation between mouse movement and one positive emotion. In the fourth study, mouse movement was correlated with both valence and arousal in men and women. The authors themselves do not explain these inconsistencies (Yamauchi and Xiao, 2018).

One possible cause of the illustrated proliferation might be the exploratory and largely a-theoretic state of the research in this field. As in any other budding research field, pioneer researchers have many degrees of freedom in conducting a study and analyzing the data. In the cited examples, researchers chose different data preprocessing steps, extracted different mouse usage features, collected the data during different tasks and analyzed the data with different procedures. While methodological plurality is desirable in principle, in a novel research field it can lead to a plurality of results that are hard to integrate. Problematic, however, is that the many degrees of freedom increase the probability of finding and reporting false positive outcomes, which is even more pressing if exploratory data analytical principles are violated such as not validating the findings on an independent dataset (Kuhn and Kohnson, 2013).

5.2. Theoretical evaluation of the study results
Besides these methodological accounts for the heterogeneity of the findings, there are accounts on theoretical grounds. A first issue pertains to emotional states, which this research field attempts to link to changes in mouse usage behavior. Emotional states are a complex phenomenon, and emotion theorists do not agree on their ontological status and mutual relationship, resulting in different definitions and conceptualizations (Yamauchi and Xiao, 2018). The complexity surfaces in the diversity of discussed components and aspects in emotional states ranging from physiological processes to cultural influences (Oatley, Dacher & Jenkins, 2016). Hence, linking mouse usage behavior to specific emotional states is not straightforward and heavily depends on the conceptualization, manipulation as well as operationalization of the targeted state. In addition, this complexity makes it hard to adequately compare different studies or identify their potential ambiguities and problems. For example, Hibbeln et al. (2017) in their second study manipulated participants’ emotion by adding error messages and loading delays into a website on which participants had to navigate, while the website in the control condition worked without a hitch. The manipulation check revealed that participants in the experimental condition reported higher arousal and a more negative emotional state. The authors interpreted this state as frustration. In our study, we found the same arousal-valence pattern between the groups, but interpreted it as stress. To add to this, Kuppens et al. (2013) pointed out the importance of individual and situational differences in the relationship between valence and arousal and cast doubt on a static and lawful relationship between valence and arousal. In their review, the authors conclude that “for some […], feeling bad means feeling stress, anxiety, or other high-arousal negative states and feeling good means feeling excited and upbeat, whereas for others feeling good means feeling relaxed or content and feeling bad means feeling down or sad” (Kuppens et al., 2013, p. 934).

A similar complexity holds true for stress (Pruessner et al., 2010). When trying to understand what the construct of stress means in the context of emotional states, on the one hand, stress is viewed as an umbrella term for a reaction that involves characteristic emotional states such as fear or anger (Spector and Goh, 2001); on the other hand, stress is viewed as being connected or tantamount to a specific affective state (Russell, 2003). Ambiguity also shows in the present study. According to our definition, stress is a negative strain reaction to a situation that exceeds one's resources, which implies that there is an individual threshold beyond which a situation causes stress. However, all of our stress markers were continuous variables that ignored this purported threshold, although it can be argued that an increase in the perceived stress rating as well as an increase in negative valence indicates that the participants were indeed more stressed as compared to simply more aroused or challenged. Nevertheless, mouse usage might only be affected by acute stress beyond a certain intensity level. Taken together, there exist difficulties when zooming in on the micro-level of stress or emotional states and hypothesizing about their effects on mouse usage behavior. It is important that researchers transparently communicate their understanding of the target emotional state as well as their operationalization of the state. In the case of stress, it might be valuable to manipulate stress at different intensity levels. However, even then, there remains a gap between conceptualized and measured emotional state on the one side and the true target emotional state on the other side, which makes emotion and stress measurement and the comparison of different measurement techniques inherently noisy.

A second issue pertains to the fact that the mouse is an input device to execute tasks on the computer. Mouse usage, therefore, is inherently bound up with any task at hand. In consequence, changes in task execution will be mirrored in mouse usage. Thus, provided emotional states affect cognitive or physiological processes involved in task execution, emotional states will also affect mouse usage behavior. Such a behavioral change, however, only represents an indirect effect of emotional states on mouse usage mediated through task execution and is therefore bound with the task. For example, Hibbeln et al. (2017) let participants rearrange numbers in ascending order, buy a product on a webpage and use an online laptop or car configurator as tasks. Yamauchi and Xiao (2018) let participants work on a decision-making task in which they judged which of two figures was more similar to a base figure. In their argumentation, both Hibbeln et al. (2017) and Yamauchi and Xiao (2018) emphasize the importance of attention as the link between emotional states and mouse movement. Following this argumentation, the results in their studies could be due to an effect of emotional states on attention, which then determined task execution (e.g., choosing between two options or using a car configurator) and mouse movement accordingly. In terms of utilizing mouse usage for stress measurement, however, it is important to address the question, whether there is a task-independent, unique direct effect of emotional states on mouse usage that generalizes across situations and hence tasks. In our study, we did not find a converging effect of stress on mouse behavior across four typical mouse tasks, contradicting the existence of a direct effect of stress on mouse usage.

Regarding the effects of stress on cognitive processes involved in mouse usage, changes in mouse usage might only be visible if the cognitive demands of the task exceed a certain threshold. This could also explain the differing results between the present study and the studies done by Yamauchi and Xiao (2018) and Hibbeln et al. (2017), because their tasks, in contrast to the tasks used in the present study, might have required more cognitive resources. Similarly, the effects of stress on physiological processes involved in mouse usage might only be noticeable in tasks with more demands on fine motor skills, as stress seems to have greater detrimental effects on fine rather than gross motor skills (Staal, 2004). However, this might be less relevant for practical purposes, because the possible variance and absolute quantity of fine motor skill demands during regular computer does not exceed the demands required in this study in contrast to the variance and contrast in cognitive demands during regular computer use (with some exceptions such as gaming). Interestingly though, the point-and-click task was arguably the simplest out of the four mouse tasks in the present study, but was the only task where we found at least a tentative hint that it was affected by stress.

A third issue pertains to a possible compensation of effects of stress on mouse usage by the participants. In their theory on the effects of stress on motor performance, van Gemmert and van Galen (1997) argue that stress (defined as a demand for effort) increases noise in the neuromotor process, but also introduces limb stiffness as a biomechanical tool to compensate for the noise. In their view, motor task performance deteriorates only at high noise levels, where compensation through biomechanical adaption is no longer possible (van Galen and van Huygevoort, 2000). Similarly, spare capacity models argue that humans are temporarily able to compensate a decrease in performance during high workload or stress by resorting on spare resources and an increase in effort (Casali and Wierwille, 1983; Hockey, 1997; Pimenta et al., 2016). Although our study did not focus on task performance but on mouse usage in general, both were linked in the tasks (e.g., clicking on targets as fast and accurately as possible). The stress level differed between the two conditions, but the absolute stress level was moderate (a mean of 1.81 in perceived stress in the high-stress condition on a scale from 0 to 4). Moreover, the tasks were short with a maximum time limit of 60 seconds. Taken together, this set-up might have allowed participants to compensate possible effects of stress on their mouse usage. In Yamauchi and Xiao (2018), participant's mouse movement was captured during 96 task trials in each study. In line with the previous reasoning, a larger number of trials might be necessary to overcome potential compensatory efforts. Again, the point-and-click task - where we found at least a tentative hint that it was affected by stress - does not align with this argumentation, because the task was simple and short. An explanation could be that the point-and-click task was an intuitive task and therefore involved more automated mouse usage processes than the other tasks, which might be less controllable and therefore more sensible towards acute changes in the stress level.

Lastly, mouse usage might heavily differ between individuals. Individuals use different computer mice, are differently experienced computer users, and differ in their neuromotor coordination and emotional processing (Yamauchi and Xiao, 2018). Indeed, research in user identification showed that individuals have unique mouse usage patterns (e.g., Gamboa and Fred, 2004; Jorgensen and Tu, 2011). Likewise, Zimmermann (2008) reported higher between-person variance than within-person variance in his studies on the potential of using the mouse for emotion measurement. Our study showed a similar pattern. Moreover, the effects of acute stress on mouse usage might depend on the individual's constitution such as their chronic stress level as Frankenhaeuser (1986) suggests a qualitative difference between “effort without distress” or “effort with distress”. For example, at a low chronic stress level, the individual might compensate effects of acute stress on mouse usage. At medium chronic stress levels, the individual might not have the spare resources for compensation anymore causing acute stress to change mouse usage patterns, and at high chronic stress levels such as manifest burnout, the individual might show even other reactions in mouse usage behavior to acute stress.

To summarize, there are potentially severe theoretical, methodical and practical restrictions in using the mouse for stress measurement. Mouse usage behavior results from an interplay of complex individual cognitive, physiological as well as neuromotor processes and it highly depends on the given task. Its usefulness as a multi-purpose stress measurement might therefore fall behind physiological or other behavioral measures that monitor more universal, proximal and automated processes involved in a stress reaction such as hormonal changes or an increase in heart rate. Overall, there exists too little research on mouse usage behavior to measure stress and other emotional states in order to give statements about its usefulness. We tentatively suggest three ways to make use of mouse usage behavior in measuring stress and other emotional states. Future research should look into these and other ways more closely.

First, special mouse tasks for stress measurement might be developed. Such tasks could be useful to disambiguate the mouse usage behavior as a stress indicator. For example, Hibbeln et al. (2017) showed that negative affect in a puzzle-solving task reduced participant's mouse speed and increased the travelled mouse distance during the task, and the point-and-click task in the present study showed a slight sensibility towards changes in the stress level. If the effect holds true in further research, the puzzle-solving task or point-and-click task could be used as a behavioral indicator of participant's affective state. However, using special mouse tasks for stress measurement would give up many of the promises associated with the mouse as an unobtrusive and continuous measurement tool. Second, long-term mouse usage measurement might filter out a general effect of stress from the noisy data. Pimenta et al. (2016) used such an approach to classify fatigue by monitoring mouse and keyboard usage during computer classwork for three hours. They aggregated their data per hour and observed an increase in the mouse and keyboard features variance whenever users reported greater tiredness. An artificial neural network trained with the data was able to classify the tiredness level (collected on the seven-point USAFSAM mental fatigue scale; Ames and George, 1993) in 81% of the instances. Third, mouse usage might be more amenable to intraindividual stress measurement rather than interindividual stress measurement. Khan et al. (2013) collected mouse and keyboard usage data together with mood ratings from 26 participants during their home computer use for several days and found significant individual correlations but no general correlation. Future research should therefore try to carve out effects of stress on mouse usage on an individual level by letting participants work on different mouse tasks for multiple times during different stress levels. A longitudinal measurement approach is also able to capture the potential dynamics of an effect of acute stress on mouse usage. When repeatedly exposed to stressors, some individuals might show habituation in their physiological stress reaction (Roos et al., 2019), which is likely to affect their mouse movements.

5.3. Methodological considerations of the study at hand
Just as we critically evaluated other studies in the research area, we also need to discuss limitations and strengths of the study at hand. A first limitation is the relatively small and homogenous sample. Besides constraints on the generalization of the results to the general population, this also limits interpretability from a methodological point of view. Part of our data analytical approaches relied on machine learning. The recommended sample sizes for training a model is typically larger than the available sample, especially when using more complex models and a large number of input features (Beleites et al., 2013, Raudys and Jain, 1991). Similarly, the recommended sample sizes for testing the model tend to be greater as well (Beleites, Neugebauer, Bocklitz, Krafft, & Popp, 2012). On a related note, the variance of the models’ performances was fairly high in our study, indicating that the models where either not very stable or the test samples too small. Furthermore, the significance thresholds of the permutation test and the bootstrap intervals (typically greater than 60% accuracy) made it unlikely to detect small effects. Consequently, a similar study based on a larger sample should be pursued. In a larger sample, men and women should be analyzed separately, as research hinted at gender differences in mouse usage (Yamauchi et al., 2015; Yamauchi and Xiao, 2018). The sample should also vary in age, as aging is associated with changes in the neuromotor system (Seidler et al., 2010).

A second limitation concerns the preprocessing of the data and the data analytical approaches. The exploratory state of research in this area offers many researcher degrees of freedom, which makes it impossible to try out everything. We think that our procedure covered a wide range of approaches, but we are aware that there are more possibilities and that other studies used different approaches. We encourage everyone to use the available dataset from the study at hand for his or her own take on the data and share the results.

A third limitation challenges the ecological validity of the results. The data stem from an experimental study within an artificial setting (i.e., lab), contrived tasks and a deliberate emotional state manipulation. Moreover, participants had to use a provided mouse that was not their own. The effect of stress on mouse usage behavior might turn out to be different in a more natural environment with a naturally arrived stress state and personal hardware. However, this criticism pertains to most research in the laboratory, and we think that the current state of this research area profits from a laboratory study with a high degree of internal validity to better understand the effects of stress on mouse usage. Due to the standardized setting in the experiment at hand, potential deviations from mouse usage in a natural setting pertained to the low-stress and high-stress condition alike, thus unlikely leading to bias in the results. We additionally took measures to preserve as much ecological validity as possible by using simple, but prototypical mouse tasks together with a practice phase for accommodation to the tasks and the mouse, a commercially available ordinary mouse as well as a typical stress manipulation. The stress manipulation successfully increased stress level and cognitive load compared to the neutral and mildly demanding baseline activity in the low-stress condition. The medium-sized difference in stress as ascertained in the manipulation check might be representative of a daily hassle stress situation during a typical workday, where accumulation can lead to chronic strain with inadequate coping or recovery (Kanner et al., 1981). A potential compromise between internal and ecological validity for future research might be the use of an online-experiment in which participants use the mouse in their natural environment with their own hardware in a standardized way.

A fourth limitation regards the study design. Comparing the data of the high-stress and low-stress group treats stress level as dichotomous rather than as continuous. This criticism, however, pertains to any between-group comparison in which the independent variable is continuous rather than dichotomous. The alternative approach would be to correlate mouse usage behavior with an established stress measurement approach such as the heart rate. The disadvantages of the latter approach, however, are that all measurement approaches (e.g., heart rate) have their shortcomings (Alberdi et al., 2016) and that different measurement approaches might measure quantitatively and qualitatively varying parts of the variance in stress.

The study design at hand can be considered a strength. The stress level was experimentally manipulated, thus maximizing internal validity. The success of the stress manipulation was established using self-report, heart rate and electrodermal activity capturing both subjective and objective markers of the acute stress reaction. Moreover, by continuously capturing heart rate and electrodermal activity, we were able to ensure that the stress manipulation lasted throughout the mouse tasks and did not fade right after the manipulation.

We consider the multiplicity and transparency of methods and materials used in this study as another strongpoint. First, we studied the effects of stress on mouse usage in as many as four dedicated goal-directed mouse usage tasks. Second, we explored the data in depth and breadth using different analytical approaches, and despite our best effort to find meaningful patterns in the data, we were not able to do so. Among those analytical approaches, we introduced two novel ways to analyze mouse data without the need of arbitrary feature engineering: creating images of the mouse usage and considering mouse usage as a time-series of x- and y-coordinates. The implementation of both approaches in our study was tentative and can probably be improved with fine-tuning. Besides their use in the present research area, both procedures might be usefully applied with other data sources and more generally might inspire others to rethink how their data can be analyzed in novel ways. Lastly, we consider it a strongpoint of this work that in the interest of transparency and sharing we make all of our materials, data and analytical procedures openly available. We encourage researchers to critically evaluate and explore the materials on their own and use them to generate and test new ideas.

6. Conclusions
The present study lacks clear evidence about the feasibility of using the computer mouse for stress measurement. The results of our exploratory analysis are no proof that there exists no relationship between stress and mouse usage, but encouraged us to critically review the current state of the budding research field and highlight theoretical as well as methodological challenges of using the mouse for stress measurement. In our view, the computer mouse as a pervasive, inexpensive and unobtrusive sensor paired with the development of fast and easy-to-use techniques to analyze big amounts of complex data in a society with a looming stress problem make it a worthwhile contender for future research efforts. The work at hand tried to provide some guidance on which directions to consider and what pitfalls to avoid. The openly provided materials, data as well as analytical methods from this study are a tangible contribution to further study the intriguing possibility of capturing emotion through the mouse.