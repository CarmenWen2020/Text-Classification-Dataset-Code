Abstract
Self-stabilizing and silent distributed algorithms for token distribution in rooted tree networks are given. Initially, each process of a graph holds at most  tokens. Our goal is to distribute the tokens uniformly in the whole network so that every process holds exactly  tokens. In the initial configuration, the total number of tokens in the network may not be  where  is the number of processes in the network. The root process is given the ability to create a new token or remove a token from the network. We aim to minimize the convergence time, the number of token moves, and the space complexity. First, a self-stabilizing token distribution algorithm that converges within  asynchronous rounds and needs  redundant (or unnecessary) token moves is given, where  and  is the height of the tree network. Next, two novel mechanisms to reduce the number of redundant token moves are presented. One reduces the number of redundant token moves to  without any additional costs while the other reduces the number of redundant token moves to , but increases the convergence time to . All given algorithms have constant memory at each process and each link register.

MSC
68W1
5Distributed algorithms
Keywords
Token distribution
Self-stabilization
Constant space algorithm

1. Introduction
The token distribution problem was originally defined by Peleg and Upfal in their seminal paper [14]. Consider a network of  processes and  tokens. Initially, the tokens are arbitrarily distributed among processes but with up to a maximum of  tokens in any process. The problem is to distribute the tokens among the processes such that every process ends up with exactly one token. The above problem was redefined in another paper by the same authors [13] by considering  tokens instead of  tokens. The goal in this case is to reach a configuration at which each process has either  or  tokens. The token distribution problem is considered as the load balancing problem in distributed systems. A token can be considered to represent a unit of task (or load) of a process. The solution to the token distribution problem provides a solution of the load balancing problem, where the goal is to maintain the loads of process as evenly as possible.

The fault-tolerant (self-stabilizing) version of the problem of load balancing in distributed systems was first considered by Arora and Gouda [2]. A self-stabilizing algorithm has two properties, convergence and stability. The convergence property states that regardless of the initial distribution of loads among the processes, when the faults cease to occur (i.e.,if the environment no longer changes the load), the computation reaches a configuration where the loads of processes are balanced, within finitely many steps. Stability guarantees that the computation cannot shift any unit of load between two processes forever.

In [2] and many other papers on token distribution, a special property (referred to as constraint in [2]) is maintained. This property specifies that during any computation of the load balancing or token distribution algorithm, no new tokens are produced and no tokens are consumed by any process. However, that constraint cannot be maintained in our work due to the nature of the problem. The token distribution problem solved in this paper requires storing a fixed number () of tokens at each process. As we deal with self-stabilizing systems, the network (a tree rooted at a designated root process in this paper) can start in an arbitrary configuration where the total number of tokens in the network may not be exactly equal to . Instead, each process holds an arbitrary number, from zero to , of tokens in the initial configuration. Thus, our algorithm must make an exception to the constraint above; we assume that the root process can put (get) tokens to (from) an external store to decrease (increase) the total number of tokens in the network, but that the constraint holds for all other processes. We can think of the external store as the parent of the root process.

In this paper, we define three silent self-stabilizing token distribution algorithms for rooted tree networks. The performances of these algorithms are summarized in Table 1. We allow them to use only constant space. Specifically, the work space of all our algorithms, i.e., the amount of memory needed to store information other than tokens, is constant, both per process and per link register.

We first give a self-stabilizing token distribution algorithm  which has the convergence time of  (asynchronous) rounds. As we will show in Section 3, any self-stabilizing token distribution algorithm requires convergence time of  rounds (even if it uses arbitrarily large amount of memory space). Thus,  achieves the optimal convergence time despite that it uses only constant work space.

 may have redundant token moves. Informally, a token move is said to be redundant if it will later be reversed. Formally, If  are neighboring processes, and if, during the computation of the algorithm  tokens move from  to  and  tokens move from  to , where , then all of the moves from  to  are redundant, as well as  of the  moves from  to . In the worst case,  makes  redundant token moves, where  is the height of the tree network and .

Our second algorithm is , which combines the  with a 
 synchronizer, and our third algorithm is , which combines  with PIF (Propagation of Information with Feedback) waves.  has round complexity  and has  redundant moves, while  has round complexity  and  redundant moves. The third algorithm  is optimal in terms of the number of redundant token moves.

1.1. Related work
The token distribution problem was introduced by Peleg and Upfal in [14]. Another solution to the same problem was given by the same authors in [13]. In these papers, the problem is defined for general bounded degree graphs. Herley [7] gave another solution to the problem and claims that his solution is more efficient if the time needed for the local computation steps is not ignored. Another version of the problem, called the near-perfect token distribution problem, was introduced in [3]. In this problem, at the termination of the algorithm, no more than  tokens can be present at any process. There is a variation of the near-perfect token distribution problem, where the maximum difference of the number of tokens between any pair of processes at the termination of the algorithm is not constant, that is, the difference depends on some network parameter. Algorithms in [6], [9], [10] are in this category. Algorithms for general networks were given in [6], for complete binary trees in [9], and for meshes and torus networks in [10].

The token distribution problem for tree networks that we solve in this paper was given without a solution by Peleg in [12]. Another version of the token distribution problem on trees was given in [11], where , the total number of tokens, and , the number of processes, are computed by the algorithm. The tokens are then distributed perfectly among the processes in  time, where  is the diameter of the tree. Although the asynchronous message passing model is used, they use stronger communication primitives than the typical send/receive primitives. The result in [8] is for tree networks in another model called Dimension-exchange under the assumption that processes are given the knowledge of .

Arora and Gouda [2] gave self-stabilizing load balancing algorithms for ring and tree networks; starting from an arbitrary initial assignment of load (or tasks), their algorithms are guaranteed to converge to a configuration at which the loads of any two processes differ by at most one.


Table 1. Token distribution algorithms for rooted trees. ().

Convergence time	Redundant
token moves	Work space
(Process, Link)
 rounds		
 rounds		
 rounds		
Lower bounds	 rounds		–
2. Preliminaries
We consider a tree network  where  is a set of  processes and  is a set of  edges, each consisting of a pair  of processes. Let  be the root process of , and let  be the parent of any process . Let  be the set of neighbors of a process , and  the set of children of , i.e., all neighbors of  except its parent. For any , let 
 be the sub-tree of  consisting of  and its descendants, and let 
. Let 
 be the height of 
, the length of the longest simple path through  between  and a leaf of 
, and let 
, the height of .

For each edge , there are two link registers, 
, and 
. We call 
, an output register of  and an input register of . Variables of 
 can be read by both  and  but can be written only by .

2.1. Model of computation
We use the composite atomicity model of computation. A process  can read and write its local variables, can read and write the variables of its output registers, and can read the variables of its input registers.

The state of process or link register is defined by the values of its variables. The global state, or configuration of  is defined to be the states of all processes and link registers. We also define the neighborhood state of a process to consist of its state together with the states of all its output and input registers. We let  be the neighborhood state of  if the configuration is .

An algorithm  specifies a set of variables in processes, a set of variables in link registers, and an atomic action (or program code) that defines how a process  updates local variables and variables of the output registers and sends and/or receives tokens at each step according to its neighborhood state. We say a process is enabled if the execution of the atomic action would change the value of at least one variable or send/receive tokens; otherwise, the process is disabled.

At each step, the daemon, or scheduler, selects a non-empty set of enabled processes. Each selected process executes the atomic action at the step. If there are no enabled processes, the computation halts.

2.2. Problem specification
We now formally specify the version of the token distribution problem on a tree that we address in this paper. Given parameters , we must construct a self-stabilizing distributed algorithm  on  which has the properties that there can be no more than  tokens in the local memory of any process, there can be no more than one token in any link register, and no tokens can be lost or gained by the network except by , which can push (pull) a token to (from) a fictitious external store. As mentioned above, we can think of the external store as the parent of the root process and sometimes denote it by .

A configuration of  is legitimate if the local memory of each process contains exactly  tokens and there are no tokens in any link register. Let  be the set of the legitimate configurations of . We require that  be self-stabilizing, meaning that there exists a subset 
 such that 
 is closed and is a universal attractor, i.e., if 
 is a step of  and 
, then 
, and every computation of  eventually reaches 
 starting from any configuration. We say that  is silent if every computation of  is finite, i.e., eventually reaches a configuration at which no process is enabled.

2.2.1. Movement of tokens
If  are neighboring processes, it must be possible to move a token from  to , despite the fact that there is no variable which can be written by both processes. We use a simple 2-way switch for passing tokens. A process  can send a message 
 to , but only if there is no message in the register 
. There must be a predicate , computable by both processes, which is true if and only if  has sent a token to  which has not yet been read by . Thus,  must be able to change  from false to true, while  must be able to change  from true to false. To send a token,  writes a token into 
, then “flips”  to true. Seeing that  is true,  copies the token to its token store, then flips  to false.

The predicate  must have the following properties: (i) both  and  can calculate , (ii) if , then  may not put a token to 
, and when  does put a token to 
,  becomes true, (iii) if , then  may not get a token from 
, and when  does get a token from 
,  becomes false.

Tokens can also be moved by  to or from the external store.  can send a token to the external store if , while if , the root can get a token from the external store. However, we allow  to get (resp., send) a token from (resp., to) the external store only once at each step.

2.3. Complexities
We evaluate token distribution algorithms with three metrics — time complexity, space complexity, and the number of token moves.

We measure the time complexity in terms of (asynchronous) rounds. Let 
 be a computation of , and let  be the set of processes which are enabled at 
. We define the first round of computation  to be the smallest prefix, say 
, of  such that every member of  either executes or becomes disabled during the first  steps. Let 
 be the suffix of  starting from 
. The second round of  is defined to be the first round of 
, and so forth.

We measure the space complexity in terms of work space, that is, the amount of memory needed to store information other than tokens, per process and link register.

In our analysis, we focus on the number of redundant token moves. Intuitively, a move is redundant if it is unnecessary. Given  and configuration  of , let  be the number of tokens stored in the local memory of  at that configuration. and let  be the number of tokens in input registers of  at , and let . We define 
. That is  must send  tokens to  if ; otherwise  must receive  from  to achieve the goal of  tokens at each process, starting from the configuration . Thus, any computation of  starting from  must have at least 
 
 token moves. A computation which has 
 
 token moves we call an optimal computation. The redundancy of a computation starting at  is defined to be the number of token moves of that computation, minus the number of token moves of an optimal computation.

3. Lower bounds
In this section we let  be an arbitrary algorithm, in the composite atomicity model with link registers which solves the token distribution problem on all tree networks.

Theorem 1

For any , there exist a tree  and a computation of  on  that takes  rounds to reach a legitimate configuration.

Proof

We can assume  is odd. Let  have two children,  and 
 where 
. Consider a configuration of  on  where 
 holds 
 tokens in total and 
 holds zero tokens (Fig. 1). Process  must be selected by the scheduler  times to send 
 tokens to  and process 
 must be selected by the scheduler  times to receive 
 tokens from . Thus, there exists a computation of  starting from this configuration which takes  rounds to achieve the final token distribution.  □

Lemma 1

If a tree network  contains a process  which has exactly one child , there must be a configuration  of  such that (i)  and (ii)  is enabled to send a token to a neighbor.

Proof

Let 
 be a computation of such that 
. There must be a step 
 at which  changes from positive to non-positive. Pick  such that 
 and 
. At step 
,  sends a token to either 
 or 
. Since  has only two neighbors, 
.  □

Theorem 2

For any , there is a tree network  with  processes and a computation of  on  which contains  redundant token moves.


Download : Download high-res image (207KB)
Download : Download full-size image
Fig. 3. At step , , , and both registers are empty, as indicated by the fact that 
 and 
, which implies that  and  are both false. Since no token is sent from  to  during the next four steps,  will remain false. Although 
, that token does not exist. At step ,  writes the token 
 to 
 and reversing the value of 
, so that  changes from false to true. At step ,  reads the token and copies it into , reversing the value of 
 so that  changes back to false. The same procedure is then repeated, passing the token 
 from  to  in two steps.

Proof

We can assume that  is a multiple of 3. Let . Let  be the tree where  has  children, 
, where each 
 has one child, 
, and each 
 has one child, 
, which is a leaf (Fig. 2). We construct a computation 
 of  on . For each , let the neighborhood state 
 be a copy of 
 as given by Lemma 1. We specify that all 
 and no other processes be selected to execute at the first step of . By Lemma 1, at the first round, each 
 sends a token to 
 or each 
 sends a token to . For all , 
 holds. Furthermore, each 
 and 
 can have arbitrary state in 
 because each 
 is determined only by the state of 
 and the states of all its input and output registers. We now consider two cases.

Case 1.
Each 
 sends a token to 
 at the first step of . We let there be  tokens each in the local memories of 
 and 
 at 
. Then 
. It follows that, at some later step, 
 will send a token to 
. That move and the initial move of a token from 
 to 
 will be redundant.

Case 2.
Each 
 sends a token to , and does not send a token to 
, at the first step of . We let there be no tokens in the local memories of 
 and 
 at 
. Then 
. It follows that, at some later step,  will send a token to 
. That move and the initial move of a token from 
 to  will be redundant.

 will thus contain at least  redundant moves in both cases.  □

4. The basic algorithm
In this section, we define our simplest algorithm, , which is self-stabilizing and silent.

4.1. Overview of 
In a bottom-up computation, each process  estimates whether there are too many or too few tokens in its subtree, 
. If  estimates that , meaning that 
 has too many tokens,  sends a token to its parent. If  estimates that 
 has too few tokens for some , that is, that , then  sends a token down to . If  estimates that  has too (too few) tokens, it sends a token to (receives a token from) external storage. Eventually, each process will have exactly  tokens and  halts.

4.2. Variables and functions of basic
1.
Each process  has a structure , which holds between zero and  tokens, each of which is a bit string of length . We denote the number of tokens in  by .

2.
Each link register 
 has a variable 
, which holds a token.

3.
Each link register 
 has Boolean variables 
 and 
, which are used for communication between  and .

4.
If , the output register 
 has a variable 
, which is an estimate of the sign of . If  is a leaf, 
. The values of these estimation variables are computed bottom-up, and their intuitive meaning is as follows:  means that  needs to receive a token from its parent,  means that  needs to send a token to its parent, and  means that it needs to neither send nor receive a token. The values 
 and 
 are used instead of  and  in situations where sending a token to or receiving a token from  could be a redundant move. The value  simply means that  lacks the information to estimate .

5.
 

6.

7.

Functions of basic
1.
 inserts the token  into .

2.
 deletes a token from  and returns that token.

3.
 puts the token  to the external store.

4.
 gets a token from the external store and returns that token.

4.3. Passing tokens in 
In this subsection, we present the way to pass tokens between two processes in , which is similar to a self-stabilizing bit alternating algorithm [1].

Passing a token from a process  to a neighboring process  is done in two steps (Fig. 3). If  and there is a token named  in , then  is able to execute , deleting  from , writing to 
, and reversing the value of 
, causing  to become true. The second step is executed by . If , 
, and ,  is able to execute , copying the token  to  and reversing 
, causing  to become false.

Tokens can also be passed between  and the external store;  can move a token from its token store to the external store if , and can move a token from the external store to its token store if .

4.4. Algorithm 
In this section, we present our self-stabilizing token distribution algorithm, which we call . The work space complexity of  in each process (resp. on each register) is zero (resp. constant). Its convergence time is  rounds and it makes  redundant token moves where .

We use the standard notation , that is, , , and  if , , and , respectively.

During a computation of , each process  tries to estimate , that is, tries to find whether  is positive, negative, or just zero. Each process  reports that estimate to its parent  using a shared variable 
. When its estimate is negative,  sends a token to  if  holds a token and . When the estimate is positive,  sends a token to its parent  if  holds a token and .  always gets a new token from the external store to increase  when its estimate is negative, and puts a token to the external store to decrease  when the estimate is positive. If all processes  correctly estimate , each of them eventually holds  tokens. After that, no process sends a token.

Thus, estimating  is the key of algorithm . Each process  computes , its estimate of  as follows. 
 
 
  where the candidate values , 
, , 
, , and  of  represent that the estimate is positive, “never negative”, zero, “never positive”, negative, and “unsure”, respectively. A process sends a token to its parent only when its estimate is , and it sends a token to its child only when the child’s estimate is . Note that 
. For process , the domain of variable 
 is 
 if  is not a leaf, and is  if  is a leaf.

Algorithms 1 and 2 give the pseudo code of . When  executes, it first checks whether each input register 
 holds a token, and receives that token by invoking  unless  is full, using the token-passing mechanism (Lines 16, 1–4). Then,  sends a token to each child  such that  and 
 (i.e.,  is estimated to be negative) by invoking  unless  is empty (Lines 17, 5–9). Next,  and  perform different action. If , it sends a token to its parent if  and , i.e.,  is estimated to be positive, and reports the latest estimate of  to its parent by storing  into 
 (Lines 21–22). Note that  decreases when  sends a token to its parent, hence the values of  may differ in Lines 21 and 22. Process  invokes  which may increase or decrease the number of tokens in the tree (Lines 19, 10–15):  gets a token from the external store and stores it to its token store if , and it pops a token from its token store and puts the token to the external store if .

In the algorithm description, we have used several functions which take a process as an argument, such  and . The values of these functions also depend on the current configuration. In what follows, we denote such functions with an explicitly specified configuration when that configuration is not clearly understood from context, such as  and .

During a step, a process can use each link register at most once to send/receive a token, and can send to or receive from the external store at most one token. Subject to those constraints, a process will send and receive as many tokens as possible, as we state in Remark 1. We first define: 
 

Remark 1

If a process  is selected, then during that step: (a) the number of executions of  by  is , and (b) the number of executions of  by  is .

In what follows, we show the correctness and evaluate the number of redundant token moves and the convergence time of algorithm . First, we show that every computation of  is finite (Lemma 2). The correctness of  immediately follows. (Theorem 3).


Download : Download high-res image (168KB)
Download : Download full-size image

Download : Download high-res image (102KB)
Download : Download full-size image
Lemma 2

Every computation of  is finite.

Proof

Fix a computation 
 of . For any , we define a predicate 
, where 
 and 
 are also predicates: 
 holds if and only if  sends and receives tokens only finitely many times in , and 
 holds if and only if  or  changes the value of 
 only finitely many times in . In the remainder of this proof, we prove 
 for all . This proposition guarantees that every leaf  satisfies 
 because it has no children (BASE), and every process  with height  satisfies 
 if every process  with height smaller than  satisfies 
 (INDUCTION). Thus, this proposition implies 
 for all , which gives the lemma.

Let , and suppose 
 holds for all . Then,  sends or receives no token to or from its children, and 
 remains unchanged for all  after some point of the computation. Let 
 be the first step that  is selected after that point. (The unfair daemon may never select  after that point, but we need not consider this case because then 
 clearly holds.) Consider a computation after that step, say 
. Process  sends a token to  only if , and  sends a token to  only if . Hence,  sends and receives tokens at most 
 times in 
, which implies 
. Thus, there exists 
 such that  never sends or receives a token after 
. Since  never changes after 
,  also never changes after 
. This means that 
 never changes after 
, which implies 
. Thus 
 holds for any , which gives the lemma from the above discussion.  □

Theorem 3

Algorithm  is a silent self-stabilizing token distribution algorithm.

Proof

Let 
 be a computation of . Lemma 2 guarantees that  ends at its final configuration 
, that is, 
. No process is enabled in 
. Hence, every process holds  tokens in its token store and no token exists in registers in 
 because otherwise some process must be enabled.  □

We now give an asymptotically tight bound on the number of redundant token moves of . Recall that .

Lemma 3

The number of redundant token moves in any computation of  is .

Proof

For any process , let 
 and 
. During the computation 
 of , each  sends a token to  at most 
 times. This is because 
 is monotonically non-increasing, except for the case that the parent of a process 
 sends a token to  before the first time  is selected by the scheduler, and 
 decrements by one every time  sends a token to . Similarly,  sends a token to  at most 
 times in . Since 
 and 
, the number of redundant token moves in  is at most 
.  □

Lemma 4

The number of redundant token moves in some computation of  is .

Proof

Consider the network shown in Fig. 4 where  processes except for  are divided into four sets A, B, C, and D, each of which consists of  processes. Consider a configuration 
 where each process  in  holds no token (i.e., ), each process  in  holds  tokens (i.e., ), and 
 holds for all .

Consider a computation 
 such that the scheduler selects no process in  until a computation reaches a configuration, say 
, where no process  is enabled. Denote the prefix of  with length , i.e.,
, by 
. If , 
 holds for every process  in . Then, a process in  should not send a token to its child in 
 because this results in increasing  by one. However, in 
, the processes in  send tokens to their children 
 in total. If , 
 holds for every process  in . Then, a process in  should not send a token to its parent in 
 because this results in increasing  by one. However, in 
, the processes in  send tokens to their parents 
 in total. Therefore, we have 
. This means that the number of redundant token moves is  in computation .  □

Finally, we analyze the convergence time of . We first show that every computation of  satisfies predicate 
, which is defined as follows, within 
 rounds for any process : 


Download : Download high-res image (207KB)
Download : Download full-size image
Fig. 4. A tree to prove Lemma 4.

Lemma 5

Let  and let 
 be a step of  where 
 holds. Then, the following three statements hold: (1)
(2)
(3)

Proof

If 
, then 
 because 
 implies that  and 
 for all . If 
, then 
 because 
 implies that  and 
. Similarly, 
 holds if 
.  □

Lemma 6

Let . If 
 always holds for all , then once 
 holds, 
 always holds.

Proof

Let 
 be a step of  where 
 holds and 
 and 
 hold for all . It suffices to show 
 to prove the lemma. First, consider the case of 
. If 
 remains  in step 
, then 
 trivially holds. If 
 becomes  or 
 at the step, i.e., 
, then 
 holds and 
 for all  by the definition of . The latter statement, and Lemma 5, imply 
. Hence, 
 holds if 
. Similarly, 
 holds if 
. Next, suppose 
. In this case, 
 holds by Lemma 5. If 
, then 
 trivially holds by the definition of , and 
 and Lemma 5 imply that 
 for all , which implies 
. Hence, 
 holds if 
. Similarly, 
 holds if 
.  □

Lemma 7

Let . If 
 always holds for all , 
 always holds once  is selected twice by the scheduler or  becomes disabled.

Proof

Consider a computation 
 of  where 
 holds for all  and all . During the computation, 
 holds when  is disabled, by the definition of algorithm , and by the assumption that 
 holds for all . Hence, by Lemma 6, it suffices to show that 
 or 
 holds where 
 and 
 are the first and the second steps at which  is selected by the scheduler in . Process  cannot send a token to 
 in the both steps because  never holds in 
 if  sends a token to 
 in step 
. Assume that  does not send a token to 
 in step 
. Then, we have 
. Therefore, 
 holds thanks to the assumption that 
 holds for any . Similarly, 
 holds if  does not send a token to 
 in step 
.  □

Lemma 8

Let  and let 
 be a computation of . The predicate 
 holds for any 
, i.e., 
 always holds after 
 rounds have elapsed.

Proof

The lemma is proven by induction on 
. By Lemma 6, Lemma 7, every leaf process  always satisfies 
 after the first two rounds have elapsed, and every non-leaf process 
 always satisfies 
 after the first 
 rounds have elapsed if every child 
 always satisfies 
 after the first 
 rounds have elapsed.  □

Corollary 1

A computation of  reaches a configuration of 
 within  rounds and never deviates from 
 thereafter.

Furthermore, Lemma 9 trivially holds by the definition of . Note that Lemma 9 implies that no redundant token move can occur after a computation reaches a configuration in 
.

Lemma 9

For any process ,  is monotonically non-increasing during a computation of  starting from a configuration in 
.

In the rest of this section, we prove that every computation starting from a configuration in 
 finishes in  rounds. Given , we define 
  where 
 is the set of processes in 
 whose distance from  is no greater than  (e.g., 
 and 
). See Fig. 5. In the left tree of the figure,  because 
 holds at least  extra tokens (i.e., 
) for all , but 
 holds no extra token. In the right tree of the figure,  because 
 is short at least  tokens (i.e., 
) for , but 
 is short only one token. Let 
 be a computation starting from a configuration in 
 and  be a process such that 
 holds for some configuration 
. Then either 
 or 
 holds for 
. Intuitively, 
 has the following meaning: (i) when 
,  sends 
 tokens to  within 
 rounds in 
 if  always receives a token from 
 immediately after  sends a token to 
, and (ii) when 
,  receives 
 tokens from  within 
 rounds in 
 if  always sends a token to 
 immediately after 
 becomes true. Note that  holds when , by definition of . For any process , we define  as follows: 
 

Lemma 10

For any configuration , .

Proof

Let  be any process other than . Define 
. Then, 
. Therefore, 
.  □

Note that  is monotonically non-increasing during any computation starting from a configuration in 
 because both  and 
 are monotonically non-increasing once 
 holds in such a computation. Moreover,  decreases by at least one within a constant number of rounds, which we will prove as Lemma 16. We first prove Lemma 11, Lemma 12, Lemma 13, Lemma 14, Lemma 15 to prove Lemma 16.

Lemma 11

Let  and 
 a computation of  starting from a configuration in 
 where 
. In the first three rounds of ,  decreases by at least one if 
 or 
.

Proof

Let , 
, and 
. ( is the number of tokens that  sends to  or  sends to  in 
.) Assume that . It suffices to show 
 for any 
 because we then obtain 
, which results in 
. In the rest of this proof, let us write . Note that  because  or , and . By definition of 
, 
 holds. If 
, then, trivially, 
. Hence, we need consider only the case 
. In this case, letting 
 for simplicity, we have 
 because otherwise (i.e., if 
):

•
if  holds, then 
, which contradicts 
,

•
if  holds, then 
, which contradicts 
.

On the other hand, we have 
 since 
 and 
. Hence, if 
 (thus 
 for all 
), then some process 
 sends a token to its parent within the first two rounds of , and if 
 (thus 
 for all 
), then some process 
 sends a token to some of its children 
 with 
 within the first three rounds of . Thus, 
 if 
. The lemma holds because  and 
 imply 
.  □

Lemma 12

Let  and let 
 be a step of  where 
. If  and 
 hold, then we have 
.

Proof

Since 
, we have 
 for all . Moreover, 
 implies  for all . Therefore: 

Lemma 13

Let  and 
 be a computation of  starting from a configuration in 
. Assume that there are two processes 
 such that 
, 
, 
, 
, and 
. Then there exists a process  such that  decreases by at least one in the first three rounds of .

Proof

Since  starts from a configuration in 
, for any process ,  decreases by at least one if  sends a token to  or  sends a token to . Assume for contradiction that no process in  sends a token to  and  never sends a token to its children during the first three rounds of . The assumption 
 implies that 
 and 
 hold in the initial configuration 
. Thus, , 
, 
, and  hold at the end of the second round. Therefore, if  has at least one token in its token store or input registers at the end of the second round, then  must send a token to 
 or some other child of  in the third round. Otherwise,  must send a token to  in the third round. Thus, we reach a contradiction.  □

Lemma 14

Let  and 
 a computation of  starting from a configuration in 
. In the first round of ,  decreases by at least one if 
, 
, and 
.

Proof

Assume that 
, 
, and 
 hold. If 
, 
 because 
; however this contradicts 
. If 
, then 
 holds for all 
 because 
; however this contradicts 
 and 
. Hence, we need consider only the case that 
. Since 
 and 
, we have 
 and 
 for all 
. This implies that at least one process in 
 changes its  from 
 or  to  in the first round of . Therefore,  decreases in the first round of .  □

Lemma 15

Let  and 
 be a computation of  starting from a configuration in 
. In the first three rounds of ,  decreases by at least one if 
.

Proof

Let . Let 
 be the predicate that holds if and only if 
 or 
. We prove that 
 holds for all  by induction, which yields the lemma. Every leaf process  satisfies 
 because the domain of 
 excludes . For the inductive step, assume 
 for all  and assume 
 for contradiction. By Lemma 12, 
 always holds in the first three rounds, i.e.,
. Since  is monotonically non-increasing for all , it suffices to show that 
 decreases by at least one in the first three rounds for some child .

If some  satisfies 
,  decreases by at least one since 
 holds, contradiction. Therefore, 
 holds for all . If 
 for some ,  decreases by at least one in the first three rounds, by Lemma 11, Lemma 12, contradiction. Hence, 
 for all . Consider that there are two children 
 and 
 such that 
 and 
. Then,  decreases by at least one for some  in the first three rounds by Lemma 13. Thus  also decreases in the first three rounds by Lemma 11, contradiction. Furthermore, there is no process  such that 
 because otherwise  decreases in the first round of  by Lemma 14. Above, we have shown the followings:

(i)
, and

(ii)

The second statement implies that there exists no two processes 
 such that 
 and 
 since 
. Therefore, by the first statement, 
 holds for all  or 
 holds for all . However, this implies that 
 holds within the first three rounds by Lemma 5, contradiction.  □

Lemma 16

Let 
 be a computation of  starting from 
. Then,  decreases by at least one in the first three rounds of  if 
.

Proof

Assume that 
 and let . Assume for contradiction that  does not decrease in the first three rounds of , i.e.,
. Then, in the same way as the proof of Lemma 15, the following two statements hold:

•
 for all , and

•
 holds for all  or 
 holds for all .

Then,  decreases  by at least one for some  by pushing a token to or pulling a token from the external store in the first three rounds of , which gives 
, contradiction.  □

Lemma 17

Every computation  of  ends within  rounds.

Proof

Corollary 1, Lemma 10, Lemma 16 imply that  reaches a configuration where 
 and  for all  within  rounds. By pushing tokens to or pulling tokens from the external store,  also holds exactly  tokens after an additional  rounds, which results in a configuration where no process is enabled.  □

Theorem 4

Algorithm  is a silent and self-stabilizing token distribution algorithm, which uses no work space per process and only constant work space per register, converges in  rounds, and has  redundant token moves.

4.5. Algorithm 
In this subsection, we present algorithm , which reduces the number of redundant token moves of . The key idea is simple. Corollary 1 and Lemma 9 guarantee that every computation of  reaches a configuration in 
 within  rounds and no redundant token moves happen thereafter. However, some processes can send or receive many tokens in the first  rounds, which makes  redundant token moves in total in the worst case (Lemma 4). Algorithm  simulates a computation of  with a simplified version of a synchronizer given by [16], which loosely synchronizes a computation of  so that the following property holds.

For any integer , if a process executes the procedure of  at least  times, then every neighboring process of the process must execute the procedure of  at least  times.

This property and Lemma 7 guarantee that every process  can execute the procedure of  at most  times until a configuration in 
 is reached, after which no redundant token moves happen.

Download : Download high-res image (94KB)
Download : Download full-size image
The code of  is shown in Algorithm 3. Every process  has variable  and 
 for every . It always copies the latest value of  to 
 for all  (Line 20). It also has all variables of  to simulate a computation of . We say that a process  is ahead of  if , written . Process  increments its clock when it is ahead of no neighbors and it has a neighbor that is ahead of  or when  is enabled to execute the procedure of  (written ) and  holds for all neighbors  (Line 17). Process  executes the procedure of  every time  increments its clock (Line 18). It is easy to see that this simple algorithm satisfies the above property, hence we obtain the following theorem.


Download : Download high-res image (168KB)
Download : Download full-size image
Fig. 6. PIF waves of . A number in a circle represents the value of variable . Note that the 0-wave and the 1-wave run simultaneously.

Theorem 5

Algorithm  is a silent and self-stabilizing token distribution algorithm, which uses only constant work space per process and per register, converges in  rounds, and causes  redundant token moves.

4.6. Algorithm 
In this section, we present , which reduces the number of redundant token moves of  from  to , but increases the convergence time from  to . Algorithm  uses a Propagation of Information with Feedback (PIF) scheme [4] to reduce the number of redundant token moves. We use a simplified version of PIF. The pseudo code is shown in Algorithm 4. Each process  has a local variable , a shared variable 
 for all , and all variables of . A process  always copies the latest value of  to 
 for all  (Line 4). A computation of  repeats the cycle of three waves — the 0-wave, the 1-wave, and the 2-wave (Fig. 6). Once , the zero value is propagated from  to leaves (Line 1, the 0-value). In parallel, each process  changes  from  to  after verifying that all its children already have the zero value in variable  (Line 2, the 1-wave). When the 1-wave reaches a leaf, the wave bounces back to the root, changing the wave-value of processes from  to  (Line 3, the 2-wave). When the 2-wave reaches the root, it resets  to , thus the next cycle begins. A process  executes the procedure of  every time it receives the 2-wave, that is, every time it changes  from  to  (Line 3).

It is easy to see that every computation of  reaches a configuration from which the cycle of three waves is repeated forever. Furthermore, the above PIF mechanism guarantees that, for any path 
 such that 
 is a leaf, each process 
 receives the 2-wave at least once in the order of 
 before 
 receives the 2-wave twice. Therefore, it holds by Lemma 7 that a computation of  reaches a configuration in 
 before some process executes the procedure of  more than three times. Hence, the number of redundant token moves is  in total. However, the convergence time increases from  to  because it takes  rounds between every two consecutive computation of the procedure of  at each process in a computation of . , shown in Algorithm 4, is not silent. However, we can make  silent by slightly modifying it such that the root begins the 0-wave at Line 16 only when it detects that the simulated algorithm () has not terminated. This modification is easily implemented by using the enabled-signal-propagation technique presented in [5].

Theorem 6

 is a silent and self-stabilizing token distribution algorithm, which uses constant work space per process and per register, converges in  rounds, and uses  redundant token moves.



Download : Download high-res image (101KB)
Download : Download full-size image
5. Conclusion
We have given self-stabilizing and silent distributed algorithms for token distribution for rooted tree networks. The base algorithm  converges in  asynchronous rounds and causes  redundant token moves. Algorithms  and  use a synchronizer and a PIF scheme, respectively. Algorithm  reduces the number of redundant token moves to  without increasing convergence time while  reduces the number of redundant token moves to , but increases the convergence time to  rounds. All of the three algorithms uses constant memory space for each process and each link register.