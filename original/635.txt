Abstract
Cloud computing has been widely utilized to handle the huge volume of data from many cutting-edge research areas such as Big Data and Internet of Things (IoT). The fast growing of edge devices makes it difficult for cloud systems to process all data and jobs originating from edge devices, which leads to the development of edge computing by completing jobs on edges instead of clouds. Unfortunately, edge devices generally possess only limited computing power. Therefore, jobs demanding heavy computation under strict time constraints could have more difficulties to successfully complete their work on edges than on clouds in the Cloud-to-Edge continuum. If cloud systems could dynamically orchestrate cloud resources to expedite the execution of those jobs, not only their timely execution could be assured, also the loading of edge devices could be reduced. The Apache Hadoop is considered one of the most popular cloud systems in industry and academia. However, it does not support dynamic resource allocation. Previously we proposed and implemented a new model which can dynamically adjust the computing resources assigned to given jobs in the Hadoop cloud system to speed up their execution. Like other computer software, cloud systems completely rely on their underlying operating systems to access hardware components such as CPUs and hard drives. In this paper, we report our efforts to improve our model to collaborate with the Linux operating system to accelerate the execution of jobs with high priority to a greater extent. Compared with what our original model achieved, experiments show that our ameliorated model could further quicken the execution of prioritized jobs in Hadoop by up to around 21%. As a result, jobs from edges that require substantial computing resources promptly could have better chances to get accomplished on cloud systems.

Previous
Keywords
Cloud computing

Edge computing

Hadoop

HDFS

1. Introduction
Cloud computing has undoubtedly demonstrated its value in many advanced research areas such as Big Data and Internet of Things (IoT) in recent years. As more and more applications and services are moved to the cloud environment, ensuring their Quality of Service (QoS) on clouds has become a very challenging issue in particular when clouds often need to process a large amount of data from edge devices. In general, jobs with simple computation tend to be executed on edges while those requiring vast computing resources usually proceed their execution on clouds. However, for jobs with the requirement of immense computing power and time constraints such as those involved in autonomous driving, the location of their execution can be a difficult decision with respect to their QoS. The reason is twofold. The first one is that the computing power in most edge devices is not enough to complete those jobs within their time limits. The second is that, even though clouds have enough computing resources, those jobs are not easy to get their work done soon enough as cloud systems often simultaneously serve many jobs and cannot effectively allocate more computing resources to jobs with strict time constraints. The limitation of computing power on edge devices is unlikely to have noticeably improvement in the near future due to their nature. Accordingly, jobs with high demand of computation and strict time constraints could have better chances to complete their execution by their time limits on clouds if cloud systems can allocate more computing resources to them. Take the autonomous driving for example, it is extremely critical to recognize objects and their actions (such as a pedestrian crossing in front of the car) in frames taken by car cameras in a timely manner to make appropriate decisions. Some deep learning models like Convolutional Neural Network (CNN) have demonstrated their capabilities in object classification. Nevertheless, those models often demand a lot of computation, which is not quite feasible to be carried out by edge devices under the time constraint. As the realization of 5G network arrives, frames taken by car cameras could be speedily transmitted to clouds with abundant computing resources. If jobs processing those frames can be executed with high priority on clouds, the level of autonomous driving could be significantly improved. Like all other computer software, cloud systems totally depend on their host operating systems to utilize system resources such as CPU, memory, and hard drives. Consequently, cloud systems and operating systems should cooperate to distribute more system resources to jobs from edges that require heavy computation under strict time constraints so their QoS could be appropriately maintained during their executions. By doing so, edge devices could also reduce their computing load from those jobs and operate more efficiently.

The Apache Hadoop is one of the most commonly used cloud platforms in the community of cloud computing. Hadoop adopts the MapReduce programming framework, which divides individual jobs into multiple smaller units namely tasks. Tasks can be distributed to different computing nodes to run in parallel to hasten the course of job execution. Each computing node (called DataNode) in Hadoop can host multiple tasks if its computing resources permit. The computing resources in Hadoop are manipulated and allocated in a unit of “container”, which is a logical bundle containing CPU and/or memory. The number of containers a DataNode could provide is equal to the number of CPU cores that DataNode has. Each task of a job needs a container to carry out its execution. A container can serve only one task at a time. Once a job is submitted, the number of tasks therein and the number of containers it needs to complete its work can be immediately calculated in the system. The Yet Another Resource Negotiator (YARN) is responsible for resource management and allocation in Hadoop. When there is a free container available, YARN will assign it to a job picked by the job scheduler to execute the next unexecuted task of that job. To meet various requirements of jobs, Hadoop should be very flexible in the distribution of its computing resources. Unfortunately, Hadoop can only assign its computing resources to jobs in predefined ways, much less works with its host operating system to dynamically distribute system resources to jobs according to their computing demands.

Our recent work proposed a new model, Dynamic YARN (DYARN), to dynamically allocate more computing resources to jobs with high priority to make their execution faster in the Hadoop cloud environment [37]. By treating jobs needing lots of computing resources within a limited period of time in the Cloud-to-Edge continuum as the ones with high priority, our model could help them keep their QoS during their execution on clouds. Despite the fact that DYARN can assign more computing resources to those jobs, ultimately it is the operating system to decide the time computing resources are used for their execution. From the perspective of the operating system, when there are pending service requests prior to the arrival of jobs with high priority, usually computing resources will not be allotted to those prioritized jobs until pending requests are completed. In other words, the execution of prioritized jobs can be delayed under such circumstances. In this paper, we report our efforts of improving our DYARN model to cooperate with the Linux operating system to further accelerate the execution for prioritized jobs. As our improved model does not modify Hadoop job scheduler or Linux kernel, it will be very easy to apply our model to future versions of Hadoop and Linux. The experimental results show that the collaboration between DYARN and Linux could outperform DYARN alone by up to about 21% for jobs executed with high priority while regular jobs still can keep 50% of their allocated computing resources for their execution. Hence, without totally pausing the execution of regular jobs, our model could assist jobs demanding plenty of computing resources with time constraints to facilitate their QoS requirements. The remainder of this paper is organized as follows. Section 2 reviews works in QoS and performance issues in Hadoop system as well as operating systems. Section 3 explains the design and implementation of our model and how it cooperates with Linux. Section 4 presents experimental results. Section 5 concludes this paper, and the future work is discussed in Section 6.

2. Related work
The QoS concerns retaining degrees of service mainly about performance and reliability, which often puts challenges on cloud systems [4]. It is getting more difficult for clouds to deal with the issue of QoS as more edge devices rely on clouds to complete their tasks. Researchers had addressed QoS from different facets. Some schemes analyzed cloud workload to decide relative parameters in QoS models [9], [24], [28], [21]. The queuing theory was also used to explore how the hardware or software resource contention influences the overall performance in QoS [3], [35], [2], [11]. Besides, QoS is also a very important topic in hybrid clouds [30], [31], [20], [22] and Cloud-to-Thing continuum [19], [5].

Cloud systems could have various job schedulers to dispatch computing resources to jobs in different ways. Nevertheless, it is the underlying operating system to actually control their execution. To quickly start serving jobs with high priority, operating systems need to be able to provide them with prioritized services. The course of job execution requires services from CPU, memory, and hard drive. In particular, the scheduling of CPU and hard drive will largely decide the progress of job execution. Some studies worked on using prioritized disk service to expedite the execution of prioritized jobs in cloud systems [36], [6]. One potential disadvantage in this approach is that a customized version of Linux or disk driver is required, which is unfavorable to the system portability.

As a popular cloud platform, Hadoop has been advanced from different aspects. Some job scheduling algorithms intended to meet job deadlines under various circumstances [17], while some aimed at lowering mean completion time of jobs in dynamic heterogeneous Hadoop system [26]. The idea of bidding resources for job execution was also adopted in job scheduling [27]. Some researchers were concerned about cases where the consumption of network bandwidth and other resources is an issue [18], [25], [32]. Overall, job scheduling algorithms in cloud systems had been bettered from the angles of resource, priority, and deadlines. The main shortcoming of modifying job schedulers is that improvement done in one job scheduler needs extra efforts to be ported to other job schedulers.

To complete prioritized jobs as soon as possible, both cloud systems and operating systems have to simultaneously support their corresponding prioritized services to jobs with high priority. In the clouds of Hadoop running on Linux, the YARN needs to dispatch as many containers as possible to prioritized jobs, while the Linux should provide them with as much prioritized CPU and disk service as it can. This is why we want to incorporate the prioritized service from Linux into the model of dynamic resource allocation in Hadoop cloud system we previously developed [37]. To the best of our knowledge, our proposed model is the only one that Hadoop and Linux cooperate to provide dynamic resource orchestration in Hadoop while Hadoop job schedulers and Linux kernel remain unmodified.

The Hadoop Distributed File System (HDFS) is the default file system in Hadoop. It usually consists of one NameNode and multiple DataNodes. The NameNode manages the namespace and metadata of the entire file system, while DataNodes store files with multiple duplicates [10], [34], [33], [29]. The malfunction in the NameNode could cease the entire operation of HDFS [7], [12], [13]. Using a standby NameNode to replace the working NameNode is a common practice to keep the HDFS alive when the working NameNode fails to function appropriately [7], [14], [15], [23]. The reliability of files is surely a crucial issue to cloud systems. Hadoop secures its data reliability through snapshot and file duplication [1], [8]. The Apache Spark keeps intermediate results in node memory to reduce disk access to speed up job execution. Nevertheless, Spark does not provide prioritized service for jobs with high priority [16].

3. Dynamic resource orchestration
To achieve the collaboration between DYARN and Linux, we need to revise DYARN so it can communicate with Linux to complete the joint work of offering prioritized services on both sides. It was our goal to provide dynamic resource allocation to jobs with high priority without modifying job schedulers in Hadoop when DYARN was devised. Theoretically DYARN can work for new job schedulers developed in the future, which is good for system portability. Likewise, the easiness of system portability is what we want to maintain during the development of the collaboration between DYARN and Linux. We will first concisely describe how the original YARN functions and then briefly explain the design of DYARN, followed by detailing the realization of the collaboration between DYARN and Linux.

3.1. Resource allocation in YARN
Currently YARN supports three job schedulers including Capacity Scheduler (CS), Fair Scheduler (FS), and First In First Out (FIFO). Based on the system configuration, one of the job schedulers will be used when Hadoop is initialized. Both CS and FS can be configured to have multiple job queues, each of which can have its own share of system resources (CPU and/or memory). The main disparity between CS and FS is the number of jobs concurrently running in each job queue. For CS, each job queue can allow only one running job and the other jobs need to wait for their execution one after one. For FS, there can be multiple jobs concurrently executing in each job queue. The FIFO, as its name suggests, only keeps one job queue to host all jobs in the system, which is not a popular job scheduler due to its limitation. For CS and FS, the course of scheduling jobs to receive system resources (container) has two steps. The first step is to choose a job queue from all job queues, while the second step is to pick a job from the selected job queue. As stated, in the MapReduce programming framework, each job is decomposed into multiple smaller tasks. Each task needs a container for its execution. Once a job is selected by the scheduler, the next unexecuted task of that job will be assigned a free container to carry out the execution of that task.

YARN is mainly composed of three parts, which are Resource Manager (RM), Node Manager (NM), and Application Master (AM). The RM manages and distributes system resources in the entire Hadoop cluster. It executes on the NameNode. The NM monitors computing resources in units of containers on each computing node, which is usually a DataNode. There is only one instance of RM executing in the entire Hadoop, while each computing node has its own instance of NM. Each instance of NM periodically reports its free containers to RM. Therefore, RM has a global picture of system resources when it conducts the resource allocation. The relation between RM and multiple NMs is similar to the connection between the master and slaves in distributed computing. Every submitted job has a corresponding AM to govern its progress. Each AM regularly notifies RM of the number of containers it still needs to finish its job so RM knows how many more containers each job needs before its completion. Whenever a free container is available, RM will ask the job scheduler to select a job to utilize the free container. After that, RM will inform the AM of the selected job about the location of the free container and then the AM can start the process of running its next unexecuted task on that container. Fig. 1 illustrates the relation among RM, NM, and AM with respect to job execution.

Fig. 1
Download : Download high-res image (146KB)
Download : Download full-size image
Fig. 1. The relation among RM, NM, and AM regarding job execution in YARN.

3.2. Resource allocation in DYARN
In this section, we will briefly describe how DYARN achieves dynamic resource allocation to quicken the execution of jobs with high priority. In the original YARN, it is the job scheduler deciding which job can receive the next free container. Thus, it is unlikely to adjust the container allocation without making changes to the job scheduler. To make DYARN work for job schedulers developed in the future, we devised another approach to let prioritized jobs receive more containers by reducing the number of containers that regular jobs could get. When the job scheduler selects a job with regular priority, DYARN temporarily decreases the current number of containers that job yet needs to zero (or to a portion of the current number according to the user's choice). By doing so, RM will view the selected job as not requiring any more containers and therefore the free container will not be dispatched to it. The number of containers that the selected job needs will be resumed back to the original value once all prioritized jobs complete their execution. Since the free container is not used, RM will ask the job scheduler to pick the next job to receive the container. If the job scheduler selects a job with high priority, our scheme does not do anything so RM will assign the free container to the selected job as usual. As a result, jobs with regular priority will be temporarily suspended from receiving free containers, which means prioritized jobs could monopolize all free containers in the system to speed up their execution. No matter the priority of the job selected by the job scheduler is high or regular, DYARN does not make any changes to the job scheduler.

The usage of DYARN is very easy and transparent to users. During the submission of a job, users just need to add an extra “yield” flag to indicate the priority level of the job. For example, in the original YARN, if users would like to launch the well-known MapReduce benchmark “wordcount”, they would type “hadoop jar wordcount.jar wordcount wordcount-input wordcount-output”. In DYARN, users would type “hadoop jar wordcount.jar wordcount wordcount-input wordcount-output -D yield=1” to mean that this job is a regular job, which is willing to “yield” all containers it receives to prioritized jobs. Otherwise, users would use “-D yield=0” to indicate that this is a job with high priority, which will not relinquish any dispatched containers. For convenience, the value of “yield” will be set to one by default if users do not use the “yield” flag. In cases where users just want a job to yield x%, instead of 100%, of its containers, they can replace “-D yield=1” with “-D ratio=x%” during the job submission. For instance, when a job is submitted with a 70% yield ratio, that job can proceed its execution as usual until it has used 30% of containers it would originally have. When all prioritized jobs accomplish their execution, the container allocation to regular jobs instantly goes back to the original way.

3.3. Collaboration between DYARN and Linux
From the angle of Linux, each container executes as an individual process. As discussed, CPU and disk scheduling algorithms could greatly affect the progress of job execution. Previous study had shown the execution of given jobs could advance more quickly by using customized disk scheduling algorithms in Linux to promptly serve their disk requests. However, any changes made to Linux kernel will certainly lower the system portability, which is adverse to the future deployment of the system. In fact, Linux itself offers two shell commands, renice and ionice, to dynamically adjust the priority of using CPU and serving I/O among running processes in the system. For a running process, as long as its process id (PID) can be identified, the renice command can reset its priority of using CPU, while the ionice command can adjust its priority of doing I/O. Both commands can be directly invoked by Java programs. Since Hadoop was implemented in Java, renice and ionice can be adopted to adjust the priority of using CPU time and I/O for running processes in Linux.

The NM on each computing node (DataNode) manages its computing resources (containers) and their corresponding information such as PIDs of containers. This suggests that NM can apply renice and ionice commands to containers it administers to adjust their priority in using CPU and I/O resources when container processes execute in Linux. As stated, a MapReduce job is divided into multiple tasks, each of which uses a container for its execution. Consequently, for a job with high priority, all its containers should take precedence over other containers from regular jobs to use CPU and I/O resources, which could lead to quicker completion of that prioritized job. In DYARN, we managed to keep the priority level of each job in RM, which is reasonable since RM manages and allocates computing resources. Nevertheless, how to identify the priority level, regular or high, of a task is not as direct as it may appear. Even a job and all its tasks share the same priority level, there is no priority information stored in tasks. Theoretically, a task could be executed on any DataNode. Hence, when a task executes on a DataNode, the NM on that DataNode needs to find out the priority level of that task to decide if renice and ionice commands would be applied to the Linux process of the container for that task.

In DYARN, the priority level of each job is retained in RM. It seems that when NM handles a task, NM can query RM about the priority level of the job owning that task. The main drawback of this way is that doing so will put an extra load on RM, which is not good for system performance as RM is often busy at managing system resources. In the meanwhile, the communication protocol between NM and RM also requires modification, which is unfavorable in terms of preserving the original protocol structure. As a consequence, we adopted another approach without the inquiry between NM and RM. As explained, a job is divided into multiple smaller tasks. Take the WordCount benchmark for example. It counts the number of instances for individual words in a target file (or files). During its execution, each task is responsible for the counting of a particular portion (called split) of the target file. In other words, each target file is divided into multiple smaller portions (splits) and each of which is separately processed by a task executing on a container. Hadoop maintains the split information of a job at a particular directory (job-info directory) in HDFS in the form of “dfs://tmp/hadoop-yarn/staging/<user_name>/.staging/job_<appid>” so the associated tasks of the job can correctly locate their split information from that directory. During the submission of a prioritized job, our system creates an empty file, namely “is_high”, under its job-info directory to indicate its high priority. There will be no “is_high” files created when submitting regular jobs. When a task t is executed by a container on a DataNode, the NM on that DataNode can check the job-info directory of the job owning the task t to examine if there exists an “is_high” file created for the job. If so, the job owning the task t is a prioritized job and the task t should be executed with high priority. Then, both renice and ionice commands will be applied to the process of the container hosting the task t. Accordingly, the process for that prioritized task t can further quicken its execution by taking precedence over other regular processes to use CPU and I/O services in Linux. If there is no “is_high” file created for the job owning the task t, the job is a regular job. Under such circumstances, our model will not interfere with the execution of the task t. The entire job-info directory, including the “is_high” file our system creates, of a job will be automatically deleted by Hadoop after the job completes.

4. Performance evaluation
We conducted six experiments to evaluate whether the joint work between DYARN and Linux could outperform DYARN alone in expediting the execution of jobs with high priority. The experiments were repeated under the individual platforms of the original YARN, DYARN, and the collaboration between DYARN and Linux. For brevity, the test results of the three platforms will be referred to as “YARN”, “DYARN”, and “DYARN-Linux” respectively. The performance comparison between YARN and DYARN was detailed in our previous work. We will mainly report and discuss the performance difference between “DYARN” and “DYARN-Linux” in this section. The testing Hadoop cluster consists of one NameNode and three DataNodes connected in a LAN environment with a 1Gbs switch. All four computers have the same software and hardware configuration including Hadoop version 3.1.0, Ubuntu 16.04 LTS, an Intel i5-4590 3.3GHz CPU, 8 GB of memory, and a 1TB Seagate 7200rpm disk.

4.1. Experimental design
Among the six experiments, the results of “YARN” and “DYARN” in the first, the second, the fifth, and the sixth experiments are from the numbers reported in our previous “DYARN” work while all other results in the six experiments were newly collected under various levels of resource contention with different numbers of prioritized jobs in the system. The system was configured to use the FS scheduler and had three job queues equally sharing system resources. Practically, FS is a very common and popular scheduler since allocated system resources in any empty job queue can flexibly be utilized by other job queues holding jobs. By contrast, in CS, system resources allocated in a job queue cannot be used by other job queues even when that job queue has no jobs therein. Obviously, the inflexibility in CS could waste system resources under such circumstances. As described, DYARN allows users to decide percentage of system resources that regular jobs would “yield” during their job submission. The first two experiments target at a simple situation where there is one prioritized job in the system. The “yield” ratio of the first experiment is set to 100%, which means all regular jobs will temporarily not get free containers to continue their execution. This represents the case when users would like to accelerate the execution of the prioritized job as fast as possible. The second experiment sets the “yield” ratio to 50%, which explores the condition when the performance of regular jobs would be moderately affected during the execution of the prioritized job. The third and the four experiments are similar to the first two experiments except that there are two prioritized jobs in the system. The fifth and the sixth experiments resemble the third and the fourth experiments respectively aside from putting more regular jobs in the same job queue hosting prioritized jobs.

Except for DYARN-Linux, all test cases in each experiment were conducted three times to obtain the average values reported in this section. For DYARN-Linux, experiments were repeated ten times to report the average values from a larger scale. The Linux cache was cleared after each test to avoid the caching effect. In a real Hadoop environment, while MapReduce jobs are in execution, users often perform non-MapReduce work such as using the HDFS “get” command to view contents of files or the “put” command to copy local data to HDFS, which directly interacts with HDFS instead of getting system resources from YARN. Even YARN does not involve in the execution of this type of activities, their execution also consumes system resources. To simulate the workload of mixing MapReduce and non-MapReduce jobs in Hadoop, sixteen jobs were executed concurrently in each test. The amount of edge data submitted to clouds is large in general. We selected MapReduce benchmarks containing mixed CPU and I/O operations in various degrees to simulate various types of workloads. Among them, eight are well-known MapReduce benchmarks while the other eight are non-MapReduce jobs including four instances of “get” and four instances of “put” mentioned above. The MapReduce benchmarks comprised WordCount, Grep, WordMean, WordMedian, TeraSort, and RandomWriter. There were two instances of WordCount and Grep, while the other four had one instance each. Each of the sixteen jobs processed a different file with the size of 10 GB. The WordCount counts the number of instances of different words in files. The Grep looks for a given string in files. The WordMean calculates the average length of words in files while the WordMedian computes the median length of the words instead. The TeraSort does the sorting on files and the RandomWriter adds random data into files. One might be concerned about the nature of the testing benchmarks. As the types of workloads coming from edge devices are very diverse, it is not easy to establish representative workloads. However, regardless of types of edge workloads, jobs processing edge data on Hadoop are executed in the style of tasks, which is the same way how our testing benchmarks execute. Since our testing benchmarks consist of mixed CPU and I/O operations in various degrees, they could in a way simulate various workloads from edge devices.

4.2. The first experiment: one prioritized job in the 3-2-3 job allocation with a 100% yield ratio
The first experiment examines a simple situation where there is only one prioritized job in the system and the yield ratio is set to 100% for regular jobs. This is the case that the prioritized job could use all free containers during its execution. Fig. 2 illustrates the allocation of the eight MapReduce jobs in three job queues. The eight non-MapReduce jobs were not in any queue since they did not require services from YARN. The first queue hosted the first instance of WordCount (denoted as WordCount-1), RandomWriter, and WordMedian. The second queue had both instances of Grep (denoted as Grep-1 and Grep-2). The rest of the three MapReduce jobs were put in the third queue. For the original YARN, all eight MapReduce jobs were executed with equal priority as YARN does not offer prioritized execution. For DYARN and DYARN-Linux, WordCount-1 was the one executed with high priority while the other seven were run with regular priority. Table 1 lists the results of this experiment. The rows labelled with “job” show the names of the sixteen jobs in a group of four. The rows marked with “YARN” present the time (in seconds) needed to complete the jobs under original YARN. The “DYARN” rows list the time (in seconds) jobs took to accomplish their execution in DYARN. The “DYARN-Linux” rows manifest the time (in seconds) and their SD (standard deviation) the collaboration between DYARN and Linux could achieve. The improvement percentages of DYARN over YARN are displayed in “improvement-D” rows. The “improvement-DL” rows present the improvement of DYARN-Linux over YARN.

Fig. 2
Download : Download high-res image (93KB)
Download : Download full-size image
Fig. 2. The 3-2-3 job allocation of MapReduce jobs in three job queues.


Table 1. The first experiment: one prioritized job in the 3-2-3 job allocation with a 100% yield ratio.

job	WordCount-1	Grep-1	WordMean	WordMedian
YARN	2720.72	1599.30	1709.36	1828.11
DYARN	863.00	1457.96	1784.65	2298.25
DYARN-Linux	714.79(SD=17.76)	1472.83	1788.33	2321.23
improvement-D	68.28%	8.84%	-4.40%	-25.72%
improvement-DL	73.73%	7.91%	-4.62%	-26.97%
job	WordCount-2	Grep-2	TeraSort	RandomWriter
YARN	1836.57	1604.85	3141.83	1283.41
DYARN	1705.29	1411.39	3001.39	1562.25
DYARN-Linux	1713.95	1431.75	3020.64	1578.37
improvement-D	7.15%	12.05%	4.47%	-21.73%
improvement-DL	6.68%	10.79%	3.86%	-22.98%
job	Write-1	Write-2	Write-3	Write-4
YARN	5891.88	6566.33	5802.02	6745.02
DYARN	6000.90	6889.53	6098.10	6370.46
DYARN-Linux	6081.10	6936.05	6139.82	6474.45
improvement-D	-1.85%	-4.92%	-5.10%	5.55%
improvement-DL	-3.21%	-5.63%	-5.82%	4.01%
job	Read-1	Read-2	Read-3	Read-4
YARN	5696.83	4612.95	5842.80	5433.72
DYARN	5001.27	5070.87	5156.18	5693.25
DYARN-Linux	5084.22	5122.29	5208.13	5752.33
improvement-D	12.21%	-9.93%	11.75%	-4.78%
improvement-DL	10.75%	-11.04%	10.86%	-5.86%
For WordCount-1, DYARN reduced its execution time to 863.00 seconds from 2720.72 seconds done in YARN, creating an improvement percentage of 68.28% ((2720.72 - 863.00) / 2720.72 = 68.28%). With the cooperation between DYARN and Linux, the time was further reduced to 714.79 seconds (SD=17.76), offering 73.73% ((2720.72 - 714.79) / 2720.72 = 73.73%) improvement. In DYARN, since WordCount-1 was the only prioritized job, its container processes of tasks already arrived at Linux much sooner than other container processes of regular jobs did. This means conceptually there is almost no room for further improvement in DYARN-Linux. From the point of the operating system, even a prioritized process has to release the CPU when it issues I/O requests. However, in DYARN-Linux, a prioritized process can quickly get the CPU back as soon as possible, which is why DYARN-Linux could outperform DYARN in this experiment. Previously, we observed that some regular jobs, such as Grep-1 and WordCount-2, did better in DYARN than in YARN and we were not sure about the reason. We suspected that as the WordCount-1 finished less than one-third of its original time ((863.00 / 2720.72) = 31.72%) in DYARN, the resource contention among other jobs would immediately become less competitive, which may help some of them complete more quickly. The numbers for regular jobs show that their performances were slightly lower in DYARN-Linux than in DYARN, which matches what we expected. As DYARN-Linux helps the prioritized WordCount-1 get CPU back whenever possible, the execution of regular jobs would be affected to some degree in DYARN-Linux.

4.3. The second experiment: one prioritized job in the 3-2-3 job allocation with a 50% yield ratio
The second experiment resembles the first one except that the yield ratio lowers to 50% from 100%. This is a situation when users want regular jobs to be less impacted by retaining 50% of containers they would receive during the execution of prioritized jobs. The 100% yield ratio basically pauses the execution of jobs with regular priority until all prioritized jobs complete their execution, which could severely delay the progress of regular jobs on a busy cloud system. It will be more flexible if regular jobs can be allowed to proceed their execution to some degree when necessary. Table 2 presents the results. For the prioritized WordCount-1, compared with YARN, DYARN decreased its execution time to 1621.88 seconds, while DYARN-Linux further shortened the time to 1047.40 seconds. The improvement percentages of both are 40.39% and 61.50% respectively, which means DYARN-Linux did 21.11% (61.50% - 40.39% = 21.11%) better than DYARN. The 50% yield ratio indicates that regular jobs were able to continue their execution as usual until they had received 50% of containers they would originally have. As a result, many container processes from regular jobs could compete container processes from WordCount-1 for system resources. This explains why WordCount-1 in DYARN took 1621.88 seconds (Table 2) to complete its work in the second experiment while it only took 863.00 seconds (Table 1) in the first experiment. In DYARN-Linux, the execution time of WordCount-1 was 1047.40 seconds (Table 2) in the second experiment and was 714.79 seconds (Table 1) in the first experiment. In DYARN, compared with the 100% yield ratio, the 50% yield ratio caused the WordCount-1 to take extra 758.88 (1621.88 - 863.00 = 758.88) seconds to complete. Interestingly, In DYARN-Linux, WordCount-1 only took additional 332.61 (1047.40 - 714.79 = 332.61) seconds to accomplish. This suggests that allowing the concurrent execution of regular jobs could impact the progress of prioritized jobs less in the DYARN-Linux than in the DYARN.


Table 2. The second experiment: one prioritized job in the 3-2-3 job allocation with a 50% yield ratio.

job	WordCount-1	Grep-1	WordMean	WordMedian
YARN	2720.72	1599.30	1709.36	1828.11
DYARN	1621.88	1731.58	1837.57	2111.23
DYARN-Linux	1047.40(SD=29.28)	1743.13	1905.42	2208.19
improvement-D	40.39%	-8.27%	-7.50%	-15.49%
improvement-DL	61.50%	-8.99%	-11.47%	-20.79%
job	WordCount-2	Grep-2	TeraSort	RandomWriter
YARN	1836.57	1604.85	3141.83	1283.41
DYARN	2035.90	1715.06	3124.89	1526.53
DYARN-Linux	2156.37	1756.17	3247.45	1603.37
improvement-D	-10.85%	-6.87%	0.54%	-18.94%
improvement-DL	-17.41%	-9.43%	-3.36%	-24.93%
job	Write-1	Write-2	Write-3	Write-4
YARN	5891.88	6566.33	5802.02	6745.02
DYARN	6497.31	6075.01	6109.72	6473.58
DYARN-Linux	6660.86	6280.61	6272.52	6723.53
improvement-D	-10.28%	7.48%	-5.30%	4.02%
improvement-DL	-13.05%	4.35%	-8.11%	0.32%
job	Read-1	Read-2	Read-3	Read-4
YARN	5696.83	4612.95	5842.80	5433.72
DYARN	5452.39	4149.91	6012.66	5293.93
DYARN-Linux	5652.26	4268.05	6203.90	5449.14
improvement-D	4.29%	10.04%	-2.91%	2.57%
improvement-DL	0.78%	7.48%	-6.18%	-0.28%
4.4. The third experiment: two prioritized jobs in the 3-2-3 job allocation with a 100% yield ratio
The job allocation of the third and the fourth experiments was the same as that of the first two experiments (Fig. 2). The third experiment imitates the first experiment except that it had two prioritized jobs, WordCount-1 and Grep-1, creating a higher resource contention during the test. Table 3 presents the results of the third experiment. Compared with YARN, the improvement percentages of WordCount-1 in DYARN and DYARN-Linux are 63.61% and 69.57% respectively, while the percentages of Grep-1 are 63.26% and 69.16% correspondingly. Both prioritized benchmarks accomplished faster in the DYARN-Linux than in DYARN alone. Table 1 shows that DYARN-Linux outperformed DYARN by 5.45% (73.73% - 68.28% = 5.45%) when WordCount-1 was the only prioritized job in the system. Table 3 demonstrates that DYARN-Linux outran DYARN by 5.96% (69.57% - 63.61% = 5.96%) for WordCount-1 and by 5.9% (69.16% - 63.26% = 5.9%) for Grep-1 when both WordCount-1 and Grep-1 were executed with high priority. The comparable performance improvement, 5.45% and 5.96%, WordCount-1 received between the first and the third experiment suggests that DYARN-Linux does not lose its advantage over DYARN when there are more prioritized jobs in the system. It is worthwhile to examine the case of WordCount-1 in more details between the first and the third experiments. In the first experiment, WordCount-1 was the only prioritized job and it had an 73.73% (Table 1) improvement in DYARN-Linux. Even though the third experiment contains two prioritized jobs, the improvement percentage of WordCount-1 in DYARN-Linux was mildly decreased to 69.57% (Table 3) and Grep-1 had a 69.16% improvement. This shows that DYARN-Linux indeed could efficiently allocate system resources to jobs with high priority.


Table 3. The third experiment: two prioritized jobs in the 3-2-3 job allocation with a 100% yield ratio.

job	WordCount-1	Grep-1	WordMean	WordMedian
YARN	2720.72	1599.30	1709.36	1828.11
DYARN	990.14	587.55	1735.51	2181.24
DYARN-Linux	827.83(SD=16.00)	493.15(SD=13.84)	1790.13	2208.00
improvement-D	63.61%	63.26%	-1.53%	-19.32%
improvement-DL	69.57%	69.16%	-4.73%	-20.78%
job	WordCount-2	Grep-2	TeraSort	RandomWriter
YARN	1836.57	1604.85	3141.83	1283.41
DYARN	1797.99	1935.43	2963.44	1586.21
DYARN-Linux	1861.01	2001.45	3016.68	1584.60
improvement-D	2.10%	-20.60%	5.68%	-23.59%
improvement-DL	-1.33%	-24.71%	3.98%	-23.47%
job	Write-1	Write-2	Write-3	Write-4
YARN	5891.88	6566.33	5802.02	6745.02
DYARN	6639.84	6075.24	6470.48	6621.09
DYARN-Linux	6723.46	6241.44	6578.92	6720.54
improvement-D	-12.69%	7.48%	-11.52%	1.84%
improvement-DL	-14.11%	4.95%	-13.39%	0.36%
job	Read-1	Read-2	Read-3	Read-4
YARN	5696.83	4612.95	5842.80	5433.72
DYARN	5935.26	4110.97	5357.17	5471.58
DYARN-Linux	5994.49	4269.66	5453.68	5570.21
improvement-D	-4.19%	10.88%	8.31%	-0.70%
improvement-DL	-5.23%	7.44%	6.66%	-2.51%
4.5. The fourth experiment: two prioritized jobs in the 3-2-3 job allocation with a 50% yield ratio
The fourth experiment resembles the second experiment aside from the execution of two prioritized jobs, WordCount-1 and Grep-1. Table 4 presents the results of the fourth experiment. For WordCount-1, DYARN-Linux made a 61.50% (Table 2) improvement in the second experiment, and the percentage was decreased to 51.38% in the fourth experiment. However, Grep-1 had an 42.57% improvement in the fourth experiment. If we pair the results between the second and the fourth experiments, we can realize that when we put the second prioritized job in the system, the second prioritized job could also have a noticeable improvement percentage at the cost of limited reduction in the performance improvement from the first prioritized job, which is similar to what we observed in the pair of the first and the third experiments. As discussed, between the first and the second experiments, the execution of prioritized jobs was slowed down more in DYARN than in DYARN-Linux when the yield ratio was reduced to 50% from 100%. We also found the similar result between the third and the fourth experiments. This shows that, compared with DYARN, DYARN-Linux could help prioritized jobs experience less performance impact as the number of prioritized jobs increases, which is advantageous to prioritized jobs in a busy cloud system.


Table 4. The fourth experiment: two prioritized jobs in the 3-2-3 job allocation with a 50% yield ratio.

job	WordCount-1	Grep-1	WordMean	WordMedian
YARN	2720.72	1599.30	1709.36	1828.11
DYARN	1788.48	1171.28	1829.95	2046.39
DYARN-Linux	1322.93(SD=26.04)	918.40(SD=24.22)	1891.42	2201.14
improvement-D	34.26%	26.76%	-7.05%	-11.94%
improvement-DL	51.38%	42.57%	-10.65%	-20.41%
job	WordCount-2	Grep-2	TeraSort	RandomWriter
YARN	1836.57	1604.85	3141.83	1283.41
DYARN	2070.56	1833.28	2889.57	1327.18
DYARN-Linux	2138.20	1959.56	3054.00	1453.70
improvement-D	-12.74%	-14.23%	8.03%	-3.41%
improvement-DL	-16.42%	-22.10%	2.80%	-13.27%
job	Write-1	Write-2	Write-3	Write-4
YARN	5891.88	6566.33	5802.02	6745.02
DYARN	6134.44	6053.27	6213.73	6561.86
DYARN-Linux	6230.95	6148.45	6290.53	6692.90
improvement-D	-4.12%	7.81%	-7.10%	2.72%
improvement-DL	-5.75%	6.36%	-8.42%	0.77%
job	Read-1	Read-2	Read-3	Read-4
YARN	5696.83	4612.95	5842.80	5433.72
DYARN	5789.77	4204.27	5999.37	5227.16
DYARN-Linux	5883.17	4223.79	6120.61	5235.09
improvement-D	-1.63%	8.86%	-2.68%	3.80%
improvement-DL	-3.27%	8.44%	-4.75%	3.66%
4.6. The fifth experiment: two prioritized jobs in the 6-1-1 job allocation with a 100% yield ratio
The fifth and the sixth experiments explore the case when the resource contention is higher than that of the third and the fourth experiments. The job allocation in the first four experiments (Fig. 2) was rearranged as shown in Fig. 3. Both WordCount-1 and Grep-1 were executed with high priority while the other six jobs were run as regular jobs. We doubled the number jobs from three to six in the first job queue where both prioritized jobs executed. In the FS job scheduler, computing resources allocated in a job queue can be used by jobs in other job queues only when that job queue does not have any jobs therein. In the third experiment, WordCount-1 and Grep-1 were assured of using the computing resources allocated to the first job queue and the second job queue respectively during their execution. In the fifth experiment, WordCount-1 and Grep-1 simultaneously executed in the first job queue so both were only assured of the computing resources in the first job queue, which means the resource contention between both was higher in the fifth experiment than in the third experiment when they began to execute. Of course, WordCount-1 and Grep-1 could utilize resources allocated in the second and the third job queues when Grep-2 and WordCount-2 completed their execution. Table 5 lists the outcome of the fifth experiment. Both prioritized jobs finished faster in DYARN-Linux than in DYARN. For WordCount-1, compared with its number in YARN, the improvement percentages are 56.66% in DYARN and 63.98% in DYARN-Linux. Similarly, Grep-1 could run 53.10% faster in DYARN and 61.13% faster in DYARN-Linux. These numbers clearly verify that, even in a more competitive environment, DYARN-Linux still could hasten the execution of prioritized jobs to a larger degree than DYARN does.

Fig. 3
Download : Download high-res image (93KB)
Download : Download full-size image
Fig. 3. The 6-1-1 job allocation of MapReduce jobs in three job queues.


Table 5. The fifth experiment: two prioritized jobs in the 6-1-1 job allocation with a 100% yield ratio.

job	WordCount-1	Grep-1	WordMean	WordMedian
YARN	2340.84	1606.38	1720.52	1808.71
DYARN	1014.45	753.32	2156.10	2420.65
DYARN-Linux	843.22(SD=17.79)	624.32(SD=20.69)	2235.22	2447.96
improvement-D	56.66%	53.10%	-25.32%	-33.83%
improvement-DL	63.98%	61.13%	-29.92%	-35.34%
job	WordCount-2	Grep-2	TeraSort	RandomWriter
YARN	2118.76	1602.35	3117.11	1281.94
DYARN	2055.56	1603.52	4038.63	1610.09
DYARN-Linux	2124.66	1655.07	4143.33	1670.49
improvement-D	2.98%	-0.07%	-29.56%	-25.60%
improvement-DL	-0.28%	-3.29%	-32.92%	-30.31%
job	Write-1	Write-2	Write-3	Write-4
YARN	7553.57	6903.24	7598.16	7386.96
DYARN	7536.11	7374.49	7348.72	7499.80
DYARN-Linux	7612.37	7558.86	7485.84	7827.28
improvement-D	0.23%	-6.83%	3.28%	-1.53%
improvement-DL	-0.78%	-9.50%	1.48%	-5.96%
job	Read-1	Read-2	Read-3	Read-4
YARN	5411.63	5884.46	6196.49	5116.98
DYARN	4802.30	5421.20	5648.42	6004.88
DYARN-Linux	4968.49	5532.83	5846.27	6210.53
improvement-D	11.26%	7.87%	8.84%	-17.35%
improvement-DL	8.19%	5.98%	5.65%	-21.37%
4.7. The sixth experiment: two prioritized jobs in the 6-1-1 job allocation with a 50% yield ratio
The sixth experiment was conducted in the same ways as the fifth experiment except that the yield ratio was reduced to 50% from 100%, which simulates the situation where regular jobs can receive the first half of containers as they would have. The experimental results are displayed in Table 6. Both WordCount-1 and Grep-1 completed their jobs more quickly in DYARN-Linux than in DYARN. The improvement percentage of WordCount-1 was increased to 47.39% from 29.00% while the improvement percentage of Grep-1 was advanced to 37.04% from 23.31%. As what we would expect, the improvement difference of WordCount-1 is 18.39% (47.39% - 29.00% = 18.39%), which is higher than its 7.32% difference (63.98% - 56.66% = 7.32%, Table 5) in the fifth experiment. Likewise, for Grep-1, its improvement difference is 13.73% (37.04% - 23.31% = 13.73%), which is also higher than its 8.03% difference (61.13% - 53.10% = 8.03%, Table 5) in the fifth experiment. The improvement differences between the fifth and the sixth experiments manifest that DYANR-Linux could outperform DYARN to a larger degree for prioritized jobs when there are more container processes from regular jobs competing for system resources, which agrees with what we observed in the first four experiments. Overall, the results from all six experiments demonstrate that DYARN-Linux successfully orchestrates system resources to jobs with high priority to expedite their execution in the Hadoop cloud environment.


Table 6. The sixth experiment: two prioritized jobs in the 6-1-1 job allocation with a 50% yield ratio.

job	WordCount-1	Grep-1	WordMean	WordMedian
YARN	2340.84	1606.38	1720.52	1808.71
DYARN	1662.01	1231.96	1928.46	2083.20
DYARN-Linux	1231.61(SD=18.07)	1011.30(SD=10.80)	1985.73	2176.46
improvement-D	29.00%	23.31%	-12.09%	-15.18%
improvement-DL	47.39%	37.04%	-15.41%	-20.33%
job	WordCount-2	Grep-2	TeraSort	RandomWriter
YARN	2118.76	1602.35	3117.11	1281.94
DYARN	2238.51	1557.71	3706.96	1502.07
DYARN-Linux	2270.54	1610.11	3873.27	1601.49
improvement-D	-5.65%	2.79%	-18.92%	-17.17%
improvement-DL	-7.16%	-0.48%	-24.26%	-24.93%
job	Write-1	Write-2	Write-3	Write-4
YARN	7553.57	6903.24	7598.16	7386.96
DYARN	7517.94	7391.63	7354.78	7510.52
DYARN-Linux	7698.57	7528.77	7589.77	7730.24
improvement-D	0.47%	-7.07%	3.20%	-1.67%
improvement-DL	-1.92%	-9.06%	0.11%	-4.65%
job	Read-1	Read-2	Read-3	Read-4
YARN	5411.63	5884.46	6196.49	5116.98
DYARN	6241.21	5406.35	5613.42	4978.12
DYARN-Linux	6402.72	5581.71	5683.04	5115.59
improvement-D	-15.33%	8.12%	9.41%	2.71%
improvement-DL	-18.31%	5.14%	8.29%	0.03%
5. Conclusions
As more and more services initiated by edge devices, it is getting more challenging for clouds to efficiently process them in particular for those with strict time constraints. Ideally, jobs with strict time constraints tend to be executed on edges to get their work done by their deadlines, while jobs demanding a lot of computing power are handled on clouds with enough computing resources. Unfortunately, for those with the requirements of both, the location of their execution can be a difficult decision. On one hand, edge devices are unlikely to have enough computing power. On the other hand, it is not easy for clouds to support timely prioritized services as clouds often have to simultaneously face a large number of service requests. Previously, we proposed a dynamic service model in Hadoop cloud system to accelerate the execution of jobs with high priority. By treating jobs asking for a lot of computation with strict time constraints in the Cloud-to-Edge continuum as the ones with high priority, our dynamic service model could help them accomplish their work by their time limit. In this paper, we report our efforts to improve our model to work with the Linux operating system to facilitate the orchestration of computing resources by dynamically allocating more CPU and I/O resources to prioritized jobs in Hadoop cloud system to further speed up their execution. Our design and implementation was validated by experimental results under various situations. Compared with numbers from the original Hadoop, our improved model could surpass its predecessor by up to about 21% in shortening the execution time of jobs with high priority while regular jobs could yet use 50% of computing resources originally allocated to proceed their execution.

6. Future work
The containers yielded from regular jobs can be used by every prioritized job. Currently DYARN-Linux does not limit the number or percentage of jobs which can be executed with high priority. In the future, we could let the system administrator to set the limitation. Besides, our system does not discriminate between prioritized jobs, which means all jobs with high priority are treated equally in receiving containers. Practically, there may exist requirements to assign different levels of high priority to jobs. Thus, individual prioritized jobs can have different levels of high priority, which may correspond to what percentage of available containers each prioritized job could get. By doing so, we could establish the service level agreement (SLA) in the Cloud-to-Edge continuum in the future.