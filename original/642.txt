Abstract
Reliability is increasingly a major concern in network-on-a-chip (NoC) design, alongside increased performance demands from new applications and the need for continued miniaturization of silicon technology. In this article, we look at the task migration mechanism, used to recover from permanent processing element (PE) failures in NoCs, by remapping tasks performed on faulty cores to spare ones.

An innovative reliability-aware task mapping technique is presented, based on a hybridization between Multi-Objective Optimization (MOO) and Reinforcement Learning (RL). It takes place in two steps. In the first, a set of optimal remapping solutions for different failure scenarios is generated at design-time, using a Biogeography-Based Multi-Objective Optimization algorithm, while considering communication energy and migration costs. In the second step, an artificial neural network agent is trained to select the best remapping solution, from those generated at design-time, to recover from execution failures at run-time.

Experiments were carried out to evaluate our technique for different sizes of networks and on different benchmarks. The results obtained show that the technique based on the hybridization MOO_RL brings a great improvement in the reliability of the NoC and achieves a good compromise between reliability and performance. It also guarantees a reduction of the overhead caused by the storage space of the remapping solutions, compared to the existing solutions.

Previous
Next 
Keywords
Network-on chip

Reliability

Task migration

Spare placement

Multi-objective optimization

Reinforcement learning

1. Introduction
The performance of Multiprocessor Systems-on-chip (MPSoC) is increasingly determined by its interconnect architecture. The latter not only has a significant impact on the performance rendered, but also on the area, power consumption, latency, etc. The bus-based communication architecture that is traditionally used to ensure communication between the various cores of MPSoC, can no longer meet the increasing communication requirements required by these systems to properly run current and future applications. This limit is increased by the progress of VLSI technology which allows the integration of greater numbers of components such as memory units, PEs on a single chip. To overcome this limitation, networks on a chip (NoCs) [10], [15], [33], [63] have been proposed as a new paradigm of on-chip communication architecture. Based on a packet-switched mechanism, communication between PEs in a NoC-based MPSoC is done through three main components: routers, network interfaces (NIs), and interconnection links. Connectivity between NoC routers is defined by the type of topology applied.

NoCs are designed to solve communication architecture problems in MPSoCs and to address various challenges directly related to the requirements of current and future applications. To meet these requirements, constraints are placed on different phases of NoC design, which include mapping, routing, scheduling, etc. Consequently, several approaches and techniques have been proposed in the literature related to the work carried out on NoCs. The aim is to improve the main design goals of the NoC, such as latency, area, bandwidth, power consumption, communication efficiency, etc.

Reliability is a key factor in the design of NoCs [80]. These are subject to different types of faults, which are classified in [32]] into three types: intermittent, transient and permanent. The occurrence of any of these types of defects in a NoC can lead to disruption of normal functionality, and to adverse effects on the result of running applications. Designing a reliable NoC with performance in mind is therefore essential to ensure proper and correct operations in MPSoCs. Techniques for improving reliability in the literature include: routing, system design and mapping, all three sensitive to reliability [25], thus ensuring maximum reliability to deal with different types of faults at different levels of a NoC [59].

M. Radetzki et al. [86] proposed a classification of existing fault-tolerant techniques, exploiting various forms of redundancy, which are: time redundancy, informational redundancy and spatial redundancy. The classification is structured according to three communication layers of the NoC: the data link, the network, and the transport layers. The authors in [101] presented a review of design approaches to circumvent permanent faults in NoCs. They consider research on fault-tolerant topologies and fault-tolerant routing. In [8] some fault-tolerant approaches, dedicated to the system and the application level, are listed. In recent years, fault-tolerant mapping techniques for NoCs have received a lot of attention. A study of these techniques has recently been proposed in [59]. It has been observed that task migration is the most widely applied mechanism to recover from permanent failures of PEs at the MPSoC system level, by transferring tasks from faulty PEs to functional ones for a given application.

Decisions to remap or migrate tasks can be of three types: i) Static: all scenarios of failures and task migrations are predicted at design-time. They must be stored in a lookup table to handle failures that may occur during execution, causing area overhead. ii) Dynamic: the migration function is calculated and executed at runtime, without any prior calculation at design-time. Great attention must therefore be paid to the complexity of the migration mechanism applied, to avoid additional costs in terms of execution time. iii) Hybrid: migration in this category is done at runtime, based on certain predictions and calculations made at design-time. The techniques belonging to this category attempt to find a good compromise between storage overload and computational complexity.

This interesting feature of hybrid remapping (migration) motivated us to come up with a new fault-tolerant mapping based on hybrid task migration. The proposed reliability-aware task mapping technique is based on a hybridization between multi-objective optimization and reinforcement learning (RL). In [1], RL is described as an advanced prediction technique in multicore processor systems. In our technique, the RL algorithm is used to predict at design-time the different failure scenarios. It also allows teaching an artificial agent how to choose the best task migration solution among the set of optimal task migration solutions generated by a multi-objective algorithm, according to the scenario of failures injected randomly into the NoC environment. The knowledge gained by the agent from this learning step is used to find the best remap if failures occur at runtime. This allows the NoC to continue to function even with failures.

In this work, homogeneous platforms based on NoCs in 2D meshes with a single task per core are considered. Note that the scheduling step is outside the scope of this paper.

The main contributions of this paper can be summarized as follows:

•
A fault-tolerant mapping technique is proposed to overcome permanent failures that can occur during run time in NoC-based homogeneous PEs.

•
A multi-objective version of the Biogeography-Based Optimization Algorithm (MOBBO) is implemented to generate, at design-time, a set of optimal task migration solutions according to the predicted failure scenarios. The consumption of communication energy and the migration cost are the two objectives considered.

•
The RL algorithm is applied at design-time to train and to learn an artificial neural network agent how to select the adequate and the optimal migration solution for a given failure scenario, from those generated by MOBBO.

•
The storage space required to store task migration solutions and runtime migration overhead are reduced with RL_MOBBO hybridization.

The rest of this article is structured as follows:

section 2 briefly reviews some related work and presents the motivation for this work. The formulation of the problem, the objective functions and all the vector representations related to our work are presented in section 3. The description of our technique is detailed in section 4. Section 5 presents experiments and comparisons carried out to evaluate our technique. The results obtained are also discussed there. The article ends with a conclusion in section 6.

2. Related work and motivation
According to [75], [83], application mapping is classified as the fourth dimension in NoCs design research problems. It comes after the three key dimensions of the design which are: i) the communication infrastructure, ii) the communication paradigm and iii) the evaluation framework. This shows the important role of application mapping in determining the performance of NoCs. It motivated many researchers to include reliability mechanisms into mapping techniques to meet both the performance and the reliability required by modern NoC-based MPSoCs. Several reliability-aware mapping techniques are proposed in the literature to deal with different types of faults: transient, intermittent and permanent [59].

Uncertainties problem has been also considered in the application mapping process to improve the reliability of NoC-based MPSoC. Note that uncertainties can negatively affect traditional design approaches of NoC-based architectures, such as application mapping, as discussed in [50], [51]. They can be the cause of an overall degradation of the reliability of the system. Considering uncertainties is therefore of paramount importance in designing reliable NoC. Several techniques have been proposed to deal with this problem, as reported in [52], [62]. The uncertainty-aware mapping problem was recently addressed in [53]. The problem is formulated as a multi-objective optimization problem with the consideration of three objectives: reliability, performance and energy consumption. The proposed solution is based on the NSGA-II algorithm and Monte Carlo simulation techniques. The uncertainty-aware models that are developed in this work are integrated in computer-aided design tool for embedded systems under uncertainty for NoC-based architectures (DESUU-NOC). Note that the problem of uncertainty in NoC is not addressed by the solution presented in this article; however, we have included it for more exhaustiveness.

Because our work focuses on permanent failures, some solutions for recovering permanent failures based on application mapping in NoCs are briefly reviewed in this section. These solutions are grouped into three categories: static, dynamic and hybrid (quasi-static), depending on the analysis and the moment of the decision for the remapping of the tasks in the event of failure, as has already been mentioned in the section 1.

2.1. Static solutions
In [96], routing and mapping are considered concurrently to ensure the robustness of the NoC. Mapping coefficient and Robustness index are two parameters used respectively to optimize communication delay and maximize NoC robustness. A multi-objective genetic-based technique is adopted in this work, to tackle NoC reliability and minimize communication delay at design-time. An extension of this work is given in [84]. The authors propose to use a multi-objective evolutionary approach to increase the robustness of the NoC and minimize delays and power consumption. The mapping in [30] is formulated as a multi-objective problem to optimize power and latency when ensuring system functionality in the presence of permanently defective links. To determine the optimal Pareto mapping, an optimization heuristic is proposed. It is based on k-means clustering and the steepest climb algorithm. A static remapping is adopted in [4] to solve the problem of manufacturing defects in MPSoCs based on NoCs. A set of fault-tolerant mappings is generated at design-time, under different fault scenarios, taking into account both power consumption and execution time. A simulated annealing (SA) algorithm is used to select the optimal task mapping for a given defective tiles. The authors of [38] propose a task remapping at design-time to recover from permanent failures in heterogeneous MPSoCs based on NoCs. An initial task mapping is first carried out, taking into account the communication energy. A Fast heuristic is then applied to calculate different mapping solutions for different failure scenarios, optimizing both communication energy and migration overhead in addition to reliability. A static analysis technique is performed in [39], [43], to generate a mapping and scheduling of application tasks, determining the voltage and frequency of each core in the NoC. A fast gradient-based heuristic is used to optimize communication energy and reliability, based on a proposed temperature model.

2.2. Dynamic solutions
A self-recovery strategy based on remapping tasks at run-time is used to recover from multiple node and link failures in [17]. An evaluation of the communication and computation times of this technique is carried out in [18], [19]. NSGA-II was adopted in [46] to find, at run-time, the optimal Pareto mapping solutions with improved throughput and communication cost. Mean-Time-To-Failure (MTTF) is the metric used in this work to assess reliability when applying remapping in the occurrence of permanent failures. In [2], a dynamic remapping is proposed to deal with single and multiple permanent failures of PEs. This solution consists of two steps: the first determines a new mapping region composed of healthy PEs. In order to reduce communication and energy overload, the new determined region must be close to the initial mapping one. In the second step, a remapping of the application to the new region is performed dynamically in the event of failures, using the Kuhn-Munkres optimization algorithm. Reliability cost ratio based branch and bound (RCRBB) is a runtime reconfiguration technique proposed in [103]. It is used to find the best mapping that meets both reliability and performance with minimized runtime computational complexity. The branch and bound approach, with partial cost ratio is also introduced in [73]. A cost function which combines the energy and reliability of the reconfigurable architecture based on a NoC is integrated into the cost function of the mapping approach, with the aim of finding the best mapping pattern which also reduces the throughput and latency at runtime. The generation of a fault-tolerant task mapping is discussed in [22]. The proposed technique is based on a multi-region model, where the many-core model is divided into logical regions. For each one, an optimal mapping is selected at run-time to improve reliability and performance. The authors propose to use a multi-objective evolutionary approach based on NSGA-II to obtain a good compromise between reliability and performance, cost of migration, global communication traffic and power consumption.

2.3. Hybrid solutions
A linear integer programming (ILP) approach is applied in [35] to generate all possible task-to-core mappings for all permanent failure scenarios at design-time. These generated mapping solutions are stored in a memory location of the NoC. The correct solution is selected during execution, from this memory, when failures occur. In addition to minimizing the overhead in migration, the communication speed and energy are also considered in this technique. In [20], the PBIL algorithm is used both to optimize scheduling and to provide dynamic mapping. Run-time mapping is used to solve faulty situations. The major challenge is to avoid the delay caused by dynamic mapping. It is for this reason that preliminary analyses are carried out at design-time. These are used by the PBIL algorithm at run-time to choose the mapping scheme based on the failure scenario that has occurred. The reliability of NoC-based homogeneous MPSoCs is discussed by Das et al. [41]. They offer a combination of dynamic voltage and frequency scaling (DVFS) with mapping technique, to optimize both reliability and communication energy goals. A multi-objective genetic algorithm is used to select the mapping and frequency of each task. Fault tolerance is provided by task redundancy to deal with transient and permanent failures.

For the sake of completeness, Table 1 summarizes some relevant remapping techniques indicating the category of each.


Table 1. Fault-tolerant techniques based on remapping to recover from permanent failures.

Ref.	Year	Remapping type
[77]	2010	Static
[4]	2011	Static
[38]	2014	Static
[78]	2014	Static
[43]	2016	Static
Ref.	Year	Remapping type
[2]	2009	Dynamic
[57]	2009	Dynamic
[100]	2011	Dynamic
[29]	2011	Dynamic
[47]	2011	Dynamic
[17]	2011	Dynamic
[76]	2012	Dynamic
[56]	2012	Dynamic
[37]	2013	Dynamic
[70]	2013	Dynamic
[48]	2013	Dynamic
[46]	2014	Dynamic
[42]	2015	Dynamic
[8]	2016	Dynamic
Ref.	Year	Remapping type
[68]	2010	Hybrid
[34]	2012	Hybrid
[35]	2012	Hybrid
[21]	2013	Hybrid
[36]	2013	Hybrid
[39]	2014	Hybrid
[40]	2014	Hybrid
[82]	2018	Hybrid
Another point that is worth noting is that spare core placement techniques have been combined with mapping in many works to achieve flexible and reliable mapping techniques. The placement of spare cores has been discussed in [29]. Various spare placement scenarios are proposed and evaluated, namely: side, random, and uniform assignments. In addition to reliability, these scenarios are evaluated in terms of latency and communication power consumption. A dynamic spare placement adapted to each core graph of incoming application is introduced in [60], [61]. A Fault-Tolerant mapping based on spare cores placement is presented in [87], it takes into account the energy of communication. The authors in [9], [12] introduce a spare core placement algorithm, aiming to find adequate spare core positions which ensure fault tolerance with the minimum of communication energy. The flexible placements of spare cores are discussed in [11], [13]. The authors propose a solution based on ILP and a metaheuristic based on Particle Swarm Optimization (PSO) to ensure the reliability of NoCs taking into account communication cost, network latency and network power consumption.

From a review of the previously cited techniques, it is possible to conclude that the category of hybrid remapping deserves all the attention given to it, as it alleviates the disadvantages presented by static and dynamic remapping. It can also be noted that in most cases, the reliability-aware mapping problem is formulated as a multi-objective problem, taking into account reliability with different objectives. Table 2 presents the main multi-objective techniques adopted in the literature to optimize reliability and meet the constraints of mapping in NoCs.


Table 2. Heuristics and Multi-Objective algorithms for some reliable mappings.

Reference	Year	Optimization Algorithm	Objectives
[30]	2009	Heuristic based on k-means clustering and steepest-climb algorithm	Power and Latency
[84], [96]	2009-2012	Evolutionary-based approach	Communication delay and Power consumption.
[3]	2011	Multi-objective Branch-and-Bound	Power consumption
[47]	2011	Integer Linear Programming (ILP)	Execution time and Communication time
[35]	2012	Integer Linear Programming (ILP)	Migration Overhead and Communication time
[70]	2013	Mixed Integer Quadratic Programming	Migration overhead and Latency
[64], [65]	2012-2014	Scatter Search-Genetic Algorithm (SS-GA)	Communication power consumption, Communication time and Link load balance
[46]	2014	NSGA-II	Throughput and Communication time
[41]	2014	Multi-objective Genetic Algorithm	Communication power
[95]	2014	Genetic Algorithm	Power consumption and Thermal balance
[74]	2015	Dependencies-Neighborhood (LEC-DN) heuristic	Workload balance and Communication volume
[66], [67]	2014-2015	PSO-GA, PSO-SA and SS	Power Consumption, Execution time, Area and Load balance
[73]	2015	Branch and Bound	Power consumption, Throughput and Latency
[102]	2015	Branch and Bound	Communication energy and Latency
[22]	2016	NSGA-II	Migration overhead-Overall Communication time and Power Consumption
[24]	2016	A Constructive Heuristic	Communication time
[39]	2014	Gradient-Based Heuristic	Computation and Communication energy
[43]	2016	Gradient-Based Heuristic	Computation and Communication energy
[23]	2016	Hierarchical Heuristic	Workload balance
[104]	2017	Branch and Bound	Communication Energy, Latency and Throughput
[25]	2018	PSO, MILP	Average packet Delay
[14]	2019	PSO	Communication time
[11], [13]	2019-2021	PSO, ILP	Communication time, Latency, Throughput
The objective of our work is to propose a hybrid reliability-aware technique, based on analyses and predictions made at the design-time. As noted in [1], “In multicore processor systems, being able to accurately predict the future provides new optimization opportunities”. To take advantage of the prediction at design-time, we propose in our work to combine a multi-objective algorithm with reinforcement learning for more precision on the behavior of the NoC environment at the occurrence of a failure during the execution, assuming minimal degradation in NoC performance. More details on our technique are given in the following.

3. Remapping problem formulation in NoC
It seems necessary to us to start by giving some assumptions and definitions related to our work and to the problem treated. According to [69] [89], the mapping can be defined by its core and its topology / NoC graphs.

The core graph for a given application is a directed graph, G(C, E), where C is a set of cores and E the communication between the connected cores. For instance 
 represents the communication relationship between 
 and 
. Note that an application is a set of several concurrent tasks. Each task in the application is assigned to a core.

The NoC topology graph is a directed graph F(N, V). N denotes a set of nodes (tiles) in the NoC. 
 is the communication link between 
 and 
 represented by the number of hops between these two nodes.

Considering the two definitions above, mapping of the core graph G(C, E) onto the topology graph F(N, V) is defined by the function , such that, 
, ∃ 
 and 
 [89].

3.1. Problem formulation
Consider a topology based on a mesh, given an initial mapping represented by its two graphs G(C, E), F(N, V) and a set of failed PEs on which the application tasks are executed. The remapping allows this application to run on a new region of the NoC, containing healthy PEs, by applying a new mapping function M': T → R, where T denotes a set of tasks/cores and R a new region with healthy PEs (task migration example is illustrated in Fig. 1). The problem can therefore be formally defined as finding a set of optimal Pareto mappings with different spare core positions to deal with different failure scenarios predicted at design-time, with the aim of minimizing (
, 
): where 
 is the communication energy consumption, and 
 represents the migration cost. This metric was used in [22] as a fault tolerance metric.

Fig. 1
Download : Download high-res image (118KB)
Download : Download full-size image
Fig. 1. Migration of task 3 from a faulty core (F) to a spare one.

3.2. Objective functions
The two objective functions considered in our multi-objective optimization are discussed below.

•
Minimize the communication energy consumption (
): reducing energy consumption is of paramount importance in the mapping process. In our work, we use the energy model proposed in [108]. The average of the energy consumed 
 when sending a data bit from tile i to tile j is given by the following equation:(1)
 Where 
 is the number of hops between the two tiles i and j, 
 and 
 represent respectively the energy consumed by the router and the link. The total communication energy consumed by a given application mapped on  NoC is thus given by the following equation,(2)
 
 
 Where 
 is the communication weight between two tiles i and j.

•
Minimize the cost of migration (
): to minimize this metric, spare cores should be placed close to active processing ones, to which a given set of application tasks is pre-assigned. If a failure occurs in one or more of these active cores, remapping or migration of tasks to the nearest idle and non-failing cores should be applied without introducing excessive migration overhead. The migration cost is then defined as the sum of the distances between each processing core performing a task and the closest idle one (see [22]), given by(3)
 
 
 () denotes a given node in the NoC topology.

Obviously, the two objectives considered in our work are contradictory, since the minimization of communication energy consumption is obtained by mapping the active and the most communicating cores of the mesh network, in proximity to each other. At the same time, the minimization of the cost migration leads to inserting spare cores among the active ones. This may cause the most communicating cores to be moved away from each other, resulting in increased communication energy consumption. However, we are required to simultaneously minimize the two objectives. This type of problem is termed multi-objective problem, which can be mathematically formulated as follows [5], [54], [55]:
min/max 

Where:

•
 is a k-dimensional vector of objective functions.

•
k is the number of objective functions.

•
x is the solution.

•
U is the set of feasible solutions.

•
min/max is the combination of objectives.

Unlike single-objective problem that has a single optimal solution, multi-objective problem has more than one optimal solution to solve the objectives of the problem. In other words, it is hard to find a unique optimal solution that satisfies simultaneously all objectives, which can be conflicting. Because what increases the value of one objective may decrease the value of another. Therefore, the concept of one optimal solution becomes less relevant in the context of multi-objective optimization, where the optimal solution will be represented by a set of trade-off solutions that are compromised between the different objectives to be optimized.
Several multi-objective optimization methods have been proposed in the literature [31], [55]. The review presented in [54] proposes a classification of these methods into two fundamental categories:

•
Scalarization-based methods: in this category the multi-objective problem is transferred into a single-objective one, by assigning a weight to each objective. These weights indicate the priority and the importance of each objective, basing on the decision maker. The transferred single-objective problem is easily solved by any standard single-objective methods to optimize the result. However, the result will strongly depend on the weights chosen, and it is often difficult for designers to choose the adequate values of the weights to guarantee an acceptable final solution, this is in many practical applications. Alternatively, direct exploration in a multi-objective design space would be preferable. The most common approach in this category is the weighted sum technique.

•
Pareto-based methods: the idea of using these methods has been proposed first by Goldberg in [49], to solve the problems of Schaffer's approach [31]. Methods belonging to this category are based on a Pareto Optimality concept, which is closely related to the notion of dominance. The principle is based on non-dominated ranking and selection to obtain a set of Pareto front solutions composed of pareto-optimal solutions, also called pareto non-dominated solutions. Non-dominated solution means that this solution is not dominated by any other feasible solutions, which is expressed mathematically as [58]:

A solution 
⁎
 is said to dominate a solution , if and only if 
⁎
, and  such that 
⁎
.

The non-dominated solutions are ranked with the highest rank and excluded from the population, in every iteration of multi-objective optimization algorithm, until the population is suitably ranked [31]. Pareto-based methods have been applied to a wide range of real-world problems [54], [55]. This category is considered as the most promising in dealing with multi-objective problems. The most commonly used algorithms in this category are the multi-objective evolutionary algorithms (MOEA), such as: NSGA-II, MOBBO, SPEA-II, etc. More details on these algorithms are given in the next section (subsection 4.1).

3.3. Vector representation for mapping solutions and failure scenarios
In the following, the vector representations used throughout this article to express the mapping, spare cores, and failure scenarios are described. All vectors are indexed by their tile number (position) in the NoC.

•
•
•
Faulty core vector (Fig. 3 (b)): the values of the elements of this vector are either 1 for faulty cores, or 0 for active or inactive and non-defective (idle) cores.

4. Description of the proposed technique
The proposed technique is performed in different steps. Most of these steps are done at design-time to minimize the excessive delay overhead that is caused by running adaptive mapping at run time. The proposed technique is described in the following.

4.1. Step1: multi-objective optimization for task migration prediction
This step is carried out at design-time. The aim is to generate a set of the best mapping solutions which satisfy the two objectives mentioned above, and which can cover all possible failure scenarios in the NoC, for a given application. Note that one of these generated solutions is chosen as the initial mapping.

As it is the case for mapping, remapping in a NoC is identified as an NP-hard combinatorial optimization problem [69][71]. We therefore propose a MOBBO algorithm to perform this step. Two multi-objective optimization algorithms have also been implemented: NSGA-II and SPEA-II, which have been adapted to our problem. These two algorithms belong to the class of Pareto-based approaches which is promising [7]. They are already used in many works to solve the problem of multi-objective mapping in NoCs [7][110].

4.1.1. NSGA-II-based optimization for application mapping problem
The Non-dominated Sorting Genetic Algorithm (NSGA) proposed by [45] is currently one of the most popular multi-objective evolutionary optimization algorithms. The main elements of the NSGA-II algorithm are non-dominated sorting and crowding distance.

•
The principle of non-dominated sorting can be described as follows: given a set of solutions for a multi-objective problem, each solution in this set is compared to other solutions to determine whether it is dominated by others or not. If the current solution is not dominated by other ones, it is assigned to the first front and temporarily removed from the set of solutions. The previous operation is repeated for the remaining solutions for the upper fronts until all fronts are identified.

•
To select the best solutions, NSGA-II makes use of the crowding distance. This mechanism produces a better diversity of Pareto optimal solutions. According to [45], the crowding distance for a solution i is the average distance between the two points (i - 1) and (i + 1), including the largest cuboid containing only the solution i.

More details on Fast Non-Dominated Sort, the computation of the crowding distance and the elitism process are given in [45]. NSGA-II is based on Genetic Algorithms. The crossover and mutation operators are adapted to our problem. They are the same ones used in the literature to solve the quadratic assignment problems described in [106]. A uniform crossover is used with a constant percentage of gene exchange. This percentage should not exceed 20% in order to ensure a strong similarity between each of the two children and one of their parents. For more exhaustiveness, a two-point crossover [97] is also tested. Given the particularity of our problem, individuals are selected from the whole population with a uniform probability as explained in [94]. The mutation is then applied by randomly selecting two tiles and swapping the tasks they contain.
4.1.2. SPEA-II-based optimization for application mapping problem
Strength Pareto Evolutionary Algorithm II (SPEA-II) [112] is an improved version of SPEA [111]. It uses the same mechanism as k-Nearest Neighbors (kNN), as well as a ranking system to sort population members and to select the next generation from the combination of the current population and the solutions created by the genetic operators. Details on the principle of this algorithm, fitness assignment and environmental selection can be found in [112]. To solve our problem, we use a two-point crossover and the same mutation operator as for NSGA-II.

4.1.3. MOBBO-based optimization for application mapping problem
It was proposed by D.Simon [92]. It is an evolutionary optimization technique, inspired by biology and based on the biogeographic optimization model, more precisely, on the natural distribution of species in their habitats (islands) to find a solution to multimodal optimization problems.

4.1.3.1. The principle of BBO
In BBO, a solution is represented by a habitat. Each one measures its quality of performance by its HSI (Habitat Suitability Index) value. It is the equivalent of the fitness for other optimization algorithms. A high HSI indicates that the habitat is suitable as a home for biological species. Algorithm 1 presents the main steps of general algorithm of BBO.

Algorithm 1
Download : Download high-res image (66KB)
Download : Download full-size image
Algorithm 1. BBO algorithm.

Habitats are made up of solution features called Suitability Index Variables (SIVs). SIVs, which are equivalent to genes in genetic algorithms, determine habitat quality or habitability. The objective is to find an optimal solution in terms of SIV which maximizes the HSI [92]. The number of species in the habitat depends on two rates: the immigration rate λ and the emigration rate μ. An optimal solution is characterized by an upper μ and a lower λ. Immigration and emigration rates using the linear model are calculated as follows [92]:(4)
 
(5)
 
 Where:

•
: number of species in a given habitat

•
: the maximum number of species

•
: maximum rate of immigration

•
: maximum rate of emigration.

These rates can be calculated according to different mathematical models of migration such as: constant, sinusoidal or quadratic [16].
Mutation can improve the exploration and the diversification of the population. Mutations can be thought of as cataclysmic events (diseases, natural disasters, etc.) that can drastically change the HSI of a natural habitat. This HSI change is represented by a SIV mutation. The mutation rate can be calculated in terms of the species count probability given in [92]. We apply the same mutation process to the BBO algorithm as that used for NSGA-II and SPEA-II.

Migration process, in mapping problem, habitat (Island) represents a mapping solution. High-HSI habitat means a good mapping solution. The migration operator is used in BBO as an intensification strategy to improve the quality of each solution (mapping) in the population.

Elitism is also used to maintain only solutions with good potential in population, from one generation to the next.

4.1.3.2. MOBBO version
To solve our multi-objective problem, we take advantage of the selective mechanism which combines the Fast Non-Dominated Sorting Algorithm and the crowding distance of NSGA-II with multi-objective problem. This mechanism brings more improvements in terms of Pareto dominance and solution diversity [45]. Algorithm 2 gives the general algorithm of MOBBO by illustrating its main steps.

Algorithm 2
Download : Download high-res image (125KB)
Download : Download full-size image
Algorithm 2. MOBBO algorithm.

4.2. Step2: selection of optimal solutions
This is an important step in our proposed technique. It is also carried out at design-time. The idea is to select, among the mapping solutions generated, a set of solutions that can together cover the maximum number of failures. This means that the sum of the spare vectors of these solutions must result in a vector sum containing values greater than “0”. The multi-objective algorithm (NSGA-II, SPAE-II, or MOBBO) must therefore be run multiple times to achieve different placement positions of the spare cores. Note that initially, the vector sum contains elements with values of “0”, and solutions with the same spare core positions are discarded.

The main steps of selection algorithm are described in Algorithm 3. The Gamma parameter has a great impact on the quality of the selected solution. The “EXTRACT” selection function can take three different cases, depending on the Gamma value:

1.
Case 1, if Gamma is equal to 0, the best solution of the first front is taken. As a set of possible solutions is obtained for each execution of the multi-objective algorithm, we use the theory of “fuzzy sets” [109] as a decision maker to extract from this front the best solution while ensuring a good balance between the objectives. The degree of satisfaction of each objective function is represented by the fuzzy membership function 
, as indicated in the following equation (see [109]):(6)
 
  Where:

•
, represent respectively the minimum and maximum values of the objective function.

•
i denotes a given solution.

The best solution optimizes S, which is the average of the fuzzy membership of all the objectives given by the following equation:(7)
 
 
 
 represents the number of objectives, in our case 
=2.
2.
Case 2, if Gamma is equal to 1, the first front is taken to add more solutions.

3.
Case 3, if Gamma is equal to 2, the first two fronts are taken.

Algorithm 3
Download : Download high-res image (94KB)
Download : Download full-size image
Algorithm 3. Solution Selection algorithm.

4.3. Step3: reinforcement learning for NoC reliability problem
The aim of this step is to apply a reinforcement learning (RL) algorithm at design-time to train and to teach an artificial neural network agent how to select the appropriate and the optimal migration scenario for a given failure scenario, from those generated by the multi-objective algorithm. Firstly, some generalities on Machine Learning should be presented.

Machine learning is a branch of artificial intelligence that enables systems to learn in order to solve problems from data or from interactions with the environment, thereby improving performance and quality of results. There are numerous ways for the systems to learn, depending on what the machine learning algorithm is attempting to accomplish. Machine learning algorithms can be classified into three major machine learning categories: supervised learning, unsupervised learning and reinforcement learning [28], [105].

•
Supervised learning is based on a set of inputs and outputs to learn a set of rules that can map an input to an output based on labeled training datasets to conduct a classification or a regression. The training is accomplished by comparing the generated output with an expected one in order to detect and to minimize errors. This process should be repeated until the model achieves a satisfactory level of performance. The desired model should be able to generalize the previously learned rules and to predict outputs for any new input, including unseen inputs.

•
Unsupervised Learning is based on unlabeled datasets. Unlike supervised learning, the desired output is not given. The aim of this type of technique is not to predict specific outputs, but to find previously unknown patterns from unlabeled datasets. As a result, the data are classified into groups with similar types of attributes.

•
Reinforcement Learning differs from both supervised and unsupervised learning. It is based on trial-and-error approach, in which an autonomous agent learns to enhance its performance on a particular task and how to act optimally, based on a numerical reward value obtained in return, by interacting with the environment.

As can be observed from section 2, the heuristic search and optimization algorithms are the most commonly used in the literature to resolve the problem of remapping. Optimization algorithms attempt to explore the space of solutions in search of the best ones by employing operations related to the class of these algorithms. On the other hand, RL is the training strategy that explores the space of solutions and attempts to validate them by assessing their optimality at each iteration. It also enables multi-objective decision making [90]. Therefore, the most appropriate learning technique for replacing the mechanism of optimization algorithms is reinforcement learning, in which one can exploit its principle of exploring intelligently the space of solutions by interacting with environments through a series of actions following an optimal policy. Furthermore, the authors in [1] classified RL as an advanced prediction technique in multicore processor systems. RL is widely used in self-adaptive systems to handle uncertainty, based on the set of solutions obtained through dynamic feedback interaction with the environment [90]. According to the study conducted in [90], reinforcement learning is a top ML technique that is commonly used for model and behavior adaptation. The effectiveness of RL in addressing uncertainty and environment changes was also confirmed in [85]. Recently, Chen et al. [26] proposed using supervised learning to solve the problem of IP core mapping in networks on chip design, but they found that this sort of learning is not appropriate for this type of problem since it is difficult to obtain a sufficiently large and high-quality of training datasets with labeled data, especially for large-scale problems. In contrast, RL has been proven to be effective for solving IP core mapping while improving performance and saving energy [27].
Motivated by above research and reasons, we have chosen to use RL to solve our problem. RL category includes a wide range of algorithms, such as Asynchronous Advantage Actor-Critic (A2C/A3C), Actor Critic with Kronecker-factored Trust Region (ACKTR), Deep Q-learning (DQL), Proximal Policy Optimization (PPO), etc.

DQL or Q-learning with Neural Networks is the most suitable algorithm for our proposed technique, due to its strategy to teach the agent the optimal migration scenario (action) for each given failure scenario (state). The agent can easily interact with an environment that considers all failure scenarios at the same time. In this case, the agent learns the best action to take in each state of the environment. Because DQL is an off-policy algorithm, it evaluates and improves a target policy that is different from the behavior policy used for action selection.

In contrast, on-policy algorithms such as A2C, ACKTR, and PPO, use the same policy target to select actions [79], [91], [107]. They cannot interact with an environment that considers all scenarios of failure since each scenario of failure produces a different state, and for each, there will be prohibited acts that the agent must avoid. This indicates that there is a separate behavior policy for each failure scenario, implying that the agent must learn a different target policy for each failure scenario. In this case, all mapping solutions generated at design-time should be stored in the NoC to deal with different failure scenario that may occur during execution, which is not the purpose of the presented solution. More details on DQL algorithm are given in the following.

Q-learning is the basic reinforcement learning algorithm, belonging to the value-based type of learning. The value Q, represented as a state-action vector Q(s, a), is used to estimate the quality of taking an action a in a state s based on a reward r.

To modify the value of Q(s, a), the algorithm uses the Bellman equation, at each time step of the agent's interaction with the environment, to update and maximize the expected reward following an optimal policy. The equation is given by:(8)
 

 represents the new Q-value, r is the reward received from the environment in response to the current action in the current state, while 
 denotes the maximum expected future reward over all the possible actions in state 
.  is the learning rate and γ (>0 and ≤1) the discounting factor for the future rewards. It determines how much future rewards are important compared to immediate ones. If γ is closer to zero, this indicates that only the immediate rewards are being considered. If γ is closer to one, the agent considers the long-term rewards. For more details on Q-learning, we refer interested readers to [93].

As can be seen, the Q-learning algorithm requires a large memory space to store the Q-table which contains all the values of the state-action pairs. This is especially the case when it comes to complex problems that require a large environment, under limited storage space, as in our case. This is why it is essential to seek value approximation techniques to overcome this drawback. In our work, we adopt the Deep Q-learning (DQL) algorithm, based on neural networks to approximate the Q-values, i.e. the mappings of the input data to the output values through the neural network. However, using a neural network based function approximation can lead to RL instability. To deal with this problem, an experience replay technique is integrated into our algorithm.

This technique provides better sampling efficiency and reduces sample correlation. The use of experience replay also allows offline training of the agent from state transitions sampled in the environment and stored in a cyclic and limited size buffer, in the form of (
, 
, 
, 
) tuple. Note that the network is updated using a chunk of random mini-batches, which are sampled from the replay memory (the buffer). This prevents the agent from repeatedly learning from past experiences. It also provides good data distribution and generalization of learning in RL [6], [72], [99].

4.3.1. Fault-tolerance model based on DQL: training step
Like any DQL-based model, the agent and the environment are the two main components of our model. In Fig. 5, these two components and the interaction between them are shown. The detailed description of our model is presented in the following.

1.
Environment: our environment is represented by: the network (NoC), the various failure scenarios and the optimal remapping solutions generated and selected from the multi-objective optimization step. The environment behaves like a fault injector simulator. The number of failure scenarios generated depends on both the size of the NoC and the number of tasks in the mapped application.

2.
State: the state is represented as a vector to indicate the state of each PE core in the network. The PE in our case can take three possible states: inactive, active or faulty, as described above in subsection 3.3. If one or more failures occur, the new state is sent to the agent by the master core (manager). Note that the master core is assumed to be a faultless core.

3.
Agent: the agent returns the Q-value vector given by a state-action pair corresponding to the failure scenario sent by the master core. The elements of the vector indicate the different mapping solutions, which are estimated by the neural network.

4.
Action: the Q-value generated by the agent must be sent to the master core to inform it of the chosen mapping solution and the action to be taken.

5.
Reward: the action sent by the agent must be evaluated by the environment (core master) in terms of reliability, power consumption and migration cost. A feedback is then sent to the agent in the form of a reward value. This value is used by the agent to estimate a future action that maximizes the value of the reward.

Fig. 5
Download : Download high-res image (386KB)
Download : Download full-size image
Fig. 5. Reinforcement learning, training at design-time.

4.3.2. Creation of the remapping solutions adapted to the failures
As mentioned above, the environment can be thought of as a fault injector simulator. Various defects with different positions are generated to ensure the training of the neural network at the design-time. During this training, a set of adapted mapping scenarios is created. This is due to the environment-agent interaction and the value of the reward. When receiving the Q-value vector, the master performs an action among the four possibilities below. The behavior of the master core is also simulated:

1
Keep the actual mapping.

2
Adapt the actual mapping according to the failure.

3
Apply the mapping chosen by the RL agent.

4
Apply the mapping chosen by the RL agent after having adapted it to the failure.

Except for the first case, the master must calculate a new mapping and apply the task migration. The reward is calculated for all four possibilities. The best in terms of performance is then sent to the agent. The latter learns how to act in each failure scenario by approximating the Q-values, without having to store all of the “failure scenario set, mapping solution set and Q-values”.

At the end of the training step, the parameters of the neural network model and the optimal mapping scenarios (solutions) created during this step are stored in a memory on the NoC. At the start of operation, the NoC recovers the parameters (weights) with which it can reconstruct the model and calculate the Q-values of the various possible actions. Fig. 6 illustrates the interactions between the master core and the agent at runtime.

Fig. 6
Download : Download high-res image (301KB)
Download : Download full-size image
Fig. 6. Reinforcement learning, interaction at run-time.

5. Experimental evaluation
The results we obtained by simulating three real applications introduced in [81] are described in this section. These are the most widely used applications in the literature: the MPEG-4 [98] decoder which is mapped in 14 nodes, Video Object Plane Decoder (VOPD) in 12 nodes and picture in picture (PIP) in 6 nodes. We adopted deterministic XY routing in our tests for its simplicity of implementation, and we consider homogeneous 2D mesh with different sizes of NoCs. In this paper, we set the learning rate (α), the discount rate (γ), the epsilon (ϵ) and the epsilon decay to 0.001, 0.95, 1.0-0.01 and 0.995 respectively. Tests are performed on a 64 bit Intel i7-8565U CPU, operating at 1.80 GHz having 8.00 GB internal memory.

5.1. Test1: parameter settings for the implemented multi-objective evolutionary algorithms
The goal of this test is to find the appropriate parameter values for each algorithm (NSGA-II, SPEA-II and MOBBO). This leads to obtaining the best solutions for the problem being treated. The parameters concerned by this test are given in Table 3. The test is carried out by varying one parameter at a time. Table 4 summarizes the best values for different algorithms, benchmarks, and topology sizes. Recall that the “Fuzzy set” theory is applied for each execution of a given multi-objective algorithm, to extract the best and representative solutions for many different Pareto-optimal.

•
The population size and the number of generations: note that the values of the population size and the number of generations are related to the size of the application. This is true for all three algorithms. As can be seen, the cost migration and the communication energy present a better improvement for large NoCs. This is justified by the fact that a large number of spare cores relaxes the problem of minimizing the distance between active cores and spare ones. This allows the mapping method to more easily locate the most communicating nodes, thus reducing the communication energy.

•
Mutation probability: a high value of probability of mutation is not suitable for a good quality of the solution. This is confirmed by the tests we performed. A value of 0.01 for NSGA-II and MOBBO, and between 0.01 and 0.03 for SPEA-II is sufficient to obtain the best solutions.

•
Archive size: this parameter concerns the SPEA-II algorithm. The best solutions of each generation are stored in the archive. The size of the latter is therefore an important parameter. A value between 10 and 20 guarantees good results. However, it should not be too large in order to ensure a good exploration of the compromise space and to avoid falling into a local optimum.

•
Migration model and 
, 
 values: these parameters concern the MOBBO algorithm. From the results obtained, the sinusoidal migration model appears to be the best for all cases. The maximum value of “1” for immigration and emigration parameters offers a good compromise to balance intensification and diversification when searching.

•
Cost migration and communication energy consumption: we notice that in the majority of cases, MOBBO offers interesting results in terms of migration cost and communication energy consumption for different applications and sizes of NoCs, in comparison with NSGA-II and SPEA-II.


Table 3. Parameters Values/Types tested.

Parameters Values/Types tested
Parameters	NSGA-II	SPEA-II	MOBBO
Population size	50,75,100,150,200	10,20,30,50,100	50,75,100,150,200
Number of generations	10,20,20,100,200,300	10,30,50,75,100	10,20,50,100,200,300
Archive size	/	10,20,30	/
Mutation Probability	0.01,0.03,0.06,0.09,	0.01,0.03,0.06,0.06	0.01,0.03,0.06,0.09
Migration model	/	/	sinusoidal, quadratic,linear
Imax, Emax (Imax=Emax)	/	/	1,2,3

Table 4. Parameters setting for NSGA-II, SPEA-II and MOBBO algorithms.

Benchmarks	Topologies	Parameters	NSGA-II	SPEA-II	MOBBO
Parameters Values	Power consumptions (μJ)	Migration cost (Hops)	Parameters Values	Power consumptions (μJ)	Migration cost (Hops)	Parameters Values	Power consumptions (μJ)	Migration cost (Hops)
MPEG-4	4*4	Population size	100	1220.4185	24	100	1265.3174	24	100	966.7613	24
Number of generations	200	1279.9606	22	50	1265.3174	24	100	966.7613	24
Archive size	/	/	/	10	1265.3174	24	/	/	/
Mutation probabilty	0.03	1266.1538	25	0.03	1244.4392	24	0.01	996.7613	24
Migration model	/	/	/	/	/	/	Sinusoidal	996.7613	24
I_max=E_max	/	/	/	/	/	/	1	996.7613	24
5*5	Population size	150	1272.1291	15	100	1545.8342	15	150	945.8054	15
Number of generations	300	994.2441		75	1380.1569	15	200	927.0764	15
Archive size	/	/	/	10	1380.1569	15	/	/	/
Mutation probabilty	0.01	994.2441	14	0.03	1145.9726	14	0.01	927.0764	15
Migration model	/	/	/	/	/	/	Sinusoidal	927.0764	15
I_max=E_max	/	/	/	/	/	/	3	915.1786	15

VOPD	4*4	Population size	150	1503.7306	14	50	1318.9507	15	100	1151.7791	15
Number of generations	300	1401.6118	14	75	1289.4483	15	100	1115.7791	15
Archive size	/	/	/	10	1289.4483	15	/	/	/
Mutation probabilty	0.01	1401.6118	14	0.03	1239.4576	15	0.01	1180.6518	14
Migration model	/	/	/	/	/	/	Sinusoidal	1180.6518	14
I_max=E_max	/	/	/	/	/	/	1	1180.6518	14
5*5	Population size	100	1456.3617	13	50	1401.8545	16	150	1305.9478	13
Number of generations	300	1253.1033	13	50	1401.8545	16	200	1250.4852	12
Archive size	/	/	/	20	1296.9195	13	/	/	/
Mutation probabilty	0.01	1253.1033	13	0.01	1496.9195	13	0.01	1250.4852	12
Migration model	/	/	/	/	/	/	Sinusoidal	1250.4852	12
I_max=E_max	/	/	/	/	/	/	1	1250.4852	12

PIP	3*3	Population size	50	462.5530	7	50	462.5530	7	100	462.5530	7
Number of generations	50	462.5530	7	75	462.5530	7	50	482.1155	6
Archive size	/	/	/	20	462.5530	7	/	/	/
Mutation probabilty	0.01	462.5530	7	0.01	462.5530	6	0.01	482.1155	6
Migration model	/	/	/	/	/	/	Sinusoidal	482.115	6
I_max=E_max	/	/	/	/	/	/	1	482.1155	6
4*4	Population size	50	464.1505	7	50	513.6875	7	100	521.9041	6
Number of generations	50	464.1505	7	30	474.4806	6	50	464.1505	7
Archive size	/	/	/	30	464.1505	6	/	/	/
Mutation probabilty	0.01	464.1505	7	0.01	474.4806	6	0.01	464.1505	7
Migration model	/	/	/	/	/	/	Sinusoidal	464.1505	7
I_max=E_max	/	/	/	/	/	/	1,2	464.1505	7
5.2. Test2: performance assessment of NSGA-II, SPEA-II and MOBBO
For more precision and completeness, we decided to evaluate and compare the performances of the implemented evolutionary algorithms. We adopted two metrics: hypervolume and Spread, since two objectives are addressed, these metrics are suitable for the problem.

Hypervolume is the most widely used metric. It offers the possibility of taking into account three factors: accuracy, diversity and cardinality. A large hypervolume value indicates a good solution. The mathematical equation to calculate this metric is given in [111]. Spread, also known as extent, proposed by [44], is used to measure the diversity and distribution of non-dominated solutions. A small spread value indicates better diversity of the non-dominated set.

Although NSGA-II is known for its accuracy in solving multi-objective problems, the results show that MOBBO gives the best results in terms of accuracy (hypervolume) in most cases. On the other hand, SPEA-II is less efficient compared to the two other algorithms. The spread results indicate that NSGA-II and SPEA-II share approximately the same rates of diversification, which are both worse than MOBBO.

These results are justified by the fact that MOBBO uses a fixed population throughout the run. The good solutions influence and improve the bad ones using migration, thus allowing intense research around the current Pareto front. This may explain the accuracy and diversification of the fronts generated by MOBBO.

For NSGA-II and SPEA-II, the stochastic generation of a new population is a poor guide to the results obtained, especially since SPEA-II does not actually use the archive during the generation phase of the new population. This is why it presents a less interesting front compared to the other two algorithms. The diversification component of NSGA-II makes it more efficient, but it should be noted that its convergence is slow and requires many more iterations than MOBBO.

5.3. Test3: reinforcement learning evaluation
In this subsection, the performance of the reinforcement learning algorithm is first shown. The results of the tests conducted to demonstrate the benefits of using RL in our context are then presented.

The convergence quality of our agent during training step is depicted in Fig. 8, for the benchmark VOPD (12 nodes) and NoC size of 4*4, with three failures. According to the results, the agent starts with a low-quality solution and then keeps learning until it achieves excellent results even with a limited number of spare cores. During training, the average reward is increased from 0 to the maximum average reward per step, which should be close to 1. As can be seen from the graph, the RL agent has a good sample-efficiency and has shown great promise in solving the problem of fault-tolerance in NoC.

Fig. 8
Download : Download high-res image (66KB)
Download : Download full-size image
Fig. 8. Convergence graph of the agent for VOPD 4*4 with triple failures.

MOBBO has been shown to be effective in solving mapping problems considering reliability and performance, outperforming NSGA-II and SPEA-II. MOBBO is thus used in combination with RL (MBBORL) to generate the optimal mapping solutions at design-time and to ensure the training phase.

5.3.1. Execution time of remapping solution selection with and without RL
The objective of this test is to compare the time spent by the core master to sequentially search and verify each mapping solution stored in the NoC, to select and apply the correct one for a given failure scenario, versus the time spent using the MBBORL agent to directly choose the optimal and best solution among those stored in the NoC.

The results presented in Table 5 (a) confirm that the experience gained by the agent during the training phase boosted the selection step by 1.56 on average, compared to the sequential search.


Table 5. Storage space and Execution time with and without MBBORL.

(a) Execution time of run-time migration comparison.	(b) Storage space comparison in Kilo-Byte (KB) and Mega-byte (MB).
Benchmarks	Topology	Sequential search (seconds)	MBBORL (seconds)
MPEG-4	4 × 4	0.019	0.012
5 × 5	0.026	0.013

VOPD	4 × 4	0.017	0.012
5 × 5	0.024	0.013

PIP	3 × 3	0.015	0.013
4 × 4	0.019	0.014
Benchmarks	Topology	Storing all scenarios	Storing Neural Network and some scenarios)
MPEG-4	4 × 4	33.9 KB	25 KB
5 × 5	264 MB	25 KB

VOPD	4 × 4	110.2 KB	25 KB
5 × 5	307 MB	25 KB

PIP	3 × 3	5.8 KB	25 KB
4 × 4	484.85 KB	25 KB
5.3.2. Storage space of remapping solutions with and without RL
In this test, we compare the storage size required to store the remapping solutions in two cases: the first, without using RL, where all the optimal solutions generated in the multi-objective optimization step should be stored, as in the case of static remapping; in the second case, our MBBORL technique is used. We need to store only the weights of the neural network based agent and the solutions selected from the selection step, which can be approximated to deal with all the possible failures. This can justify the results obtained and presented in Table 5 (b). Our technique provides approximately a constant and reduced storage space size, compared to the one required to store all the possible solutions, especially for large problems.

5.4. Test4: reliability and performance evaluation of MBBORL
To validate our technique, we implemented and evaluated MBBORL on a REMNOC simulator. REMNoC is an open source remapping simulator, developed in C ++ and available on [88]. Two dynamic remapping techniques are already implemented in this simulator. The first is based on Simulated Annealing (SA) and the second proposed by Ababei et al. in [2] is based on the Hungarian algorithm. In this test, MBBORL is compared to SA and Hungarian techniques in terms of three metrics generated by REMNoC, namely: run-time remapping delay, average cost of migration and rate of change in communication energy consumption. The last metric is proportional to the communication volume given by the REMNoC simulator, it indicates the evolution of the communication volume between the initial mapping and the new one after migration [2]. For this test, different benchmarks and different sizes of NoCs are tested with single and multiple PE failures injected at random. k Failures in tests, indicate the maximum failures that the topology and / or the algorithm can withstand.

5.4.1. Run-time remapping delay
The results presented in Fig. 9 show that the Hungarian algorithm allows a faster migration than SA and MBBORL. This is because it is based on a constructive heuristic, unlike SA, which is based on an evolutionary heuristic. Note that MBBORL was on average 80 times faster than SA and 10 times slower than Hungarian, which is an acceptable result.

5.4.2. Average migration cost
On this criterion, Hungarian presents the least interesting performance in the majority of the tests (see Fig. 10), because the principle of this technique is to iteratively find a new remapping region, thus avoiding the affected PEs without taking into account the migration cost. Based on the diversification mechanism, SA provides good results because the algorithm takes a long time to find the best solution which reduces this parameter. The best results are obtained by MBBORL, since the optimal remapping solution is chosen among those stored and which ensure a reduced migration cost. A small adaptation could be made by migrating the tasks concerned to the nearest spare cores.

Fig. 10
Download : Download high-res image (257KB)
Download : Download full-size image
Fig. 10. Average migration cost for different application benchmarks and number of failures.

5.4.3. Change of communication energy rate
As can be observed from Fig. 11, the three techniques offer acceptable results on this criterion. For Hungarian, this is explained by the fact that it starts from an optimum and a good mapping. The nature of the algorithm makes it look for the new mapping region that is the closest to the convex region, which makes application tasks stay as close as possible. Simulated annealing gives good results, for the same reason cited in the cost of migration: the algorithm explores the solution space to find a good result. MBBORL offers fairly satisfactory results that are close to the best values obtained. This is explained by the fact that MBBORL chooses the appropriate mapping from the best mapping solutions that belong to the Pareto front, and adapts it by applying certain migrations. This leads to an optimal solution with a good result in terms of communication energy.

Fig. 11
Download : Download high-res image (245KB)
Download : Download full-size image
Fig. 11. Rate of change in communication energy consumption for different application benchmarks and number of failures.

These tests confirm that MBBORL achieves the best compromise between the three parameters: run-time delay, cost of migration, change of communication energy and reliability.

6. Conclusion
This paper presents a reliability-aware task mapping technique. It is based on a hybridization between multi-objective optimization and reinforcement learning (RL). It makes it possible to recover permanent failures in processing elements that could occur in a homogeneous 2D-Mesh NoC, while seeking the best compromise between reliability and performance.

A multi-objective biogeography-based optimization algorithm (MOBBO) is proposed to perform the step which consists in the generation of optimal mapping solutions. To our knowledge, this work is the first to present the application of the evolutionary BBO algorithm, whether in its single-objective or multi-objective version, both for mapping and optimizing reliability in the field of NoCs research.

A comparison is made between the MOBBO and the NSGA-II and SPEA-II algorithms. The results demonstrate that MOBBO outperforms these algorithms and is very competitive and more efficient at solving mapping problems while improving reliability.

The optimal solutions resulting from the MOBBO execution step are used to train an artificial neural network agent at design-time. The outputs from this step are used to select and adapt an optimal mapping to deal with failures that might arise at runtime. Our technique (MBBORL) is compared with two dynamic remapping techniques: the simulated annealing-based and the Hungarian-based techniques, using the REMNoC simulator. The results obtained clearly demonstrate the effectiveness of our technique in providing a good compromise between the cost of migration, the rate of change of the communication energy and the execution time. The necessary storage space is also reduced in MBBORL, avoiding the memorization of all remapping solutions generated at design-time.