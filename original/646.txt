Abstract
The over operator is commonly used for α-blending in various visualization techniques. In the current form, it is a binary operator and must strictly follow a specific composition order of all participating operands, hence posing a significant performance limit. In this paper, we derive a set of generic formulas for the over operator that work with any number of operands and completely remove the restriction on the composition order. We prove the correctness of these formulas and provide a step-by-step illustration in a blending context. We implement both a sequential and a parallel version of the improved over operator and apply them to the image composition process where operands are received out of order with different arrival time intervals. The performance superiority of the improved over operator over the original one is established by rigorous theoretical analyses and further validated by extensive experimental results.

Keywords
Over operator
Parallel visualization
Image composition

1. Introduction
As a fundamental operator in graphics, the over operator has been adopted in numerous visualization practices due to its simplicity and satisfactory blending performance [18]. For example, in image composition of sort-last parallel visualization, the over operator is used to composite final images [10], [11], [14], [15], [17], [22], [23]; in semi-transparent surface rendering, the over operator is used to determine the transparency of overlapped surfaces [3], [5], [7], [12], [13], [20], [21]; in volume rendering based on ray tracing/casting, the over operator is also used to blend the points sampled along a ray’s forward direction [2], [8], [9], [19]. Considering its ubiquitous use and indispensable role in visualization, this operator has oftentimes been integrated into modern operating systems and visualization frameworks/languages by default [1].

Although widely employed, the performance of the traditional  operator is largely limited by the following two facts: (i) It is a binary operator handling only two RGBA-formatted operands at a time, which means that  RGBA-formatted operands require  iterations to blend, hence posing a challenge on its scalability when  is large. (ii) It blends a pair of channels (either a color component or the transparency) in two input operands according to their relative positions, thus making itself order dependent. As such, the input operands need to be first sorted according to a certain criterion (e.g., the depth of a pixel in image composition) and then blended in the sorted order. Such order-dependency may halt the blending process at some point when two consecutive operands are not simultaneously available, regardless of the availability of their downstream operands.

As we step into the big data era, the aforementioned performance issues associated with the traditional over operator have become even more severe. For example, today’s extreme-scale e-science applications produce colossal amounts of data on the order of terabytes or even petabytes, which must be processed and analyzed in a timely manner for scientific discovery. In many scientific domains, visualization is considered as one of the most important techniques for data analysis. As a fundamental unit of these methods, the over operator has a significant impact on the overall performance of scientific visualization, especially for asynchronous parallel visualization. Unfortunately, the inherent limitations of the traditional over operator cause a critical bottleneck in handling ever-increasing data volumes.

In view of the significance of the problem, we propose a fully generalized over operator to address the performance issues associated with the original one. The proposed over operator is presented in the form of a set of generic formulas, which are not only -operator compatible but also completely order independent. We prove the correctness of these formulas and provide a step-by-step illustration in an -blending context. To demonstrate the advantages of this improved operator, we implement both a sequential and a parallel version, and apply them to the image composition process where operands may arrive out of order with different time intervals. The performance superiority of the improved  operator over the original one is established by rigorous theoretical analyses and further validated by extensive experimental results in the context of real-life scientific visualization. In addition, this improved operator has great potentials for many visualization applications in other domains involving big data such as film animations, 3D games, Computer Aided Design (CAD), Computed Tomography (CT) imaging, and autonomous driving.

2. Problem background and related work
The original  operator is a binary order-dependent operator, working on two operands at a time in a strict blending order. Given a sequence of input operands that arrive in an arbitrary order, the original operator may suffer from serious performance issues, because (1) it must wait until all the operands have arrived; (2) it can only perform a sequential blending process.

Various research efforts have been made to address the above performance limitations. One commonly considered strategy is to generalize the original operator. Meshkin [13] approximates the -composition result for  input pixels by ignoring the order-sensitive parts in their extended -composition formula. Bavoil and Myers [3] approximate -pixel -composition by calculating the average of all input pixels and substituting it for each pixel, which is a special case of the extended -pixel -composition formula with all the input pixels being identical. Patney et al. [16] propose a generalized formula for the color components without considering  channel of transparency. McGuire et al. [12] extend the operator in [3] by defining a precise form of  channel but leaving the color components in approximation.

On the other hand, the performance limitation due to order dependency still stands out in practice. In many existing blending frameworks, the operands must be pre-sorted before the actual composition can take place [6], [16], [21], hence causing a serious performance issue, especially in dynamic computing environments where a long delay may occur in generating all operands. Unfortunately, very limited efforts have been made to successfully resolve this issue. Our work removes the order dependency of the existing  operator and hence makes an advancement in the field.

The rest of the paper is organized as follows. Section 3 derives the blending formulas with rigorous theoretical proofs. Section 4 applies the new operator to image composition. Section 5 conducts a theoretical performance comparison with its predecessor. Section 6 presents the implementation details and experimental results. Section 7 concludes our work.

3. A fully generalized  operator
We denote  RGBA-formatted and order-predefined operands as, 
. To facilitate our explanation of the generalized  operator, we introduce another notation 
, , which represents the blending result of 
 and is a uniform representation for any possible (raw, intermediate, or final) blending results in the entire operating process. For example, when , it refers to the raw operand 
 or 
; when  and , it refers to the final blending result from all the  raw operands.

3.1. Extension from two to multiple operands
We propose a fully generalized  operator as follows: (1)
 (2)
where 
 represents the operand’s color component values with pre-multiplication by 
, i.e., 
. Note that Eq. (2) was presented in [16], and could be simply derived as follows: (3)

We provide a brief proof for Eq. (1) by means of induction. First, we know that 
Then, we assume that Eq. (1) holds for , i.e., (4)
For , we have (5)

Hence, Eq. (1) holds according to the principle of proof-by-induction. Note that the above derivation is based on a set of operands whose order has been predefined. However, the derived formula sheds light on the possibility of performing blending without any restriction of order dependency.

To represent 
 more concisely, we derive another formula for 
, i.e., (6)
which could be proved as follows: (7)

Based on Eqs. (1), (2), we summarize two significant properties of this generalized operator:

•
It provides a complete and accurate form of the composited result from  input operands and specifies the exact contribution of each operand to the final result according to its relative position on the to-be-blended list, which inspires the order-independent blending process.

•
For  available order-predefined operands, it reduces the number of blending steps from  to 1, by plugging each operand into its corresponding position and finishing all computations within one single step.

3.2. An in-depth illustration of the improved  operator
To justify the consistency with its predecessor, we illustrate the improved operator in an image composition scenario as [18], where the 
, , channel value is interpreted as the area of the sub-pixel region covered by 
’s sub-pixel geometry 
, . We extend the mutual division assumption from two geometries to  geometries as follows: given  pixels 
, 
, whose sub-pixel geometries and corresponding covered areas are 
), 
, respectively, in the composited pixel 
, for any  and , 
 divides both 
 and 
 into two areas of the same ratio, i.e., 
 
, and 
 also divides 
 and 
 into two areas of the same ratio, i.e., 
 
.

Following the generalized assumption, each geometry 
, , contributing to the composited pixel 
, intersects with every other geometry, hence dividing 
 into 
 non-overlapping subregions (divisions), as shown in Fig. 1. Each of these subregions is uniquely identifiable by a set of geometries that cover this subregion, denoted by 
, where 
 is either 
 or 
 
: 
 means that the sub-region is covered by 
, and 
 
 means not. To be more specific, we denote the 
 subregions as 
, and assign each of them a unique set of covering geometries (with 0, 1, …, -1, and  covering geometries) as follows

•
 
 
 
 
;

•
 
 
 
, 
 
 
 
, 
 
 
 
 
 
 
;

•
 
 
, 
 
 
 
 
 
;

•

•
.

Based on the 
-subregion division of a pixel, we generalize the calculation of the color components as (8)
where 
 is the area of sub-region 
 and 
 is the color component value assigned to sub-region 
. According to the definition of the  operator, the value of 
 is determined by the first covering geometry as follows: if there exists any  in 
’s covering (intersection) expression such that 
 and for any existing 
 
, then 
; otherwise 
.


Download : Download high-res image (78KB)
Download : Download full-size image
Fig. 1. A general illustration of dividing the pixel area by  geometries.

To facilitate the summation over the 
 subregions, we further categorize them into  groups 
, where all the subregions in the same group have the same color component value from the same geometry. The covering expression of each group is as follows:


:	
;
:	
 
;
:	
 
 
 
;
:	
 
 
 
 
;
:	
 
 
 
 
 
.
Also, we denote the total area summed over all the subregions in group 
 as 
. Under such grouping, we can rewrite Eq. (8) as (9)
Note that 
 as there is no geometry covering 
. For 
 in Eq. (9), we have (10)
 
 
where 
 and 
 
, for . We also have (11)
 
 
 
 
 
 
 
 
 
Thus, we can rewrite 
 as 
 
 
 
 and expand Eq. (9) as (12)
which is exactly the same as Eq. (2). The above analysis shows that the generalized  operator is extended from the original binary operator to work with multiple operands simultaneously.

To make the above analysis more concrete, we consider a specific blending case where 3 geometries, i.e., 
, 
, and 
, overlap with each other, as shown in Fig. 2. The entire pixel area is divided by these 3 geometries into 
 different subregions labeled from 1 to 8. According to the grouping criteria, we further classify these 8 subregions into  different groups, as follows:


:	
 
 
 
 
,
in Fig. 2, respectively;
:	
 
 
 
as 3 and 6, respectively;
:	
 
 
;
:	
 
 
 
In an image composition problem where the operands arrive in an arbitrary order, the th term 
 of Eq. (1) calculates the color component value of the th pixel 
 weighted by each of its  upstream pixels in the form of 
, and is free of dependency with any downstream pixels. Also, according to the associative law of multiplication, the order of the operand’s weight has no effect on the product. For a newly arriving pixel, it follows that the weight factor in the corresponding term is only determined by its relative depth relationship with all the other pixels that have arrived: (1) the current pixel will be affected by all of its upstream pixels that have arrived, and (2) it will make a contribution to each of its downstream pixels that have arrived.


Download : Download high-res image (82KB)
Download : Download full-size image
Fig. 2. A specific illustration of dividing the pixel area by 3 geometries.

It is worth pointing out that Eq. (6) for computing the  value does not have any order restriction since every operand in Eq. (6) makes the same contribution. Hence, when an operand (pixel) arrives, we can immediately multiply its  value with the accumulated one.

4. Algorithm design and analysis
To apply the proposed  operator to a blending scenario where the operands arrive in an arbitrary order, we design two versions of the algorithm for two different platforms: Sequential Generalized  Operator (SGOO) for sequential execution, and Parallel Generalized  Operator (PGOO) for parallel execution.

4.1. Sequential generalized  operator
In SGOO in Fig. 3, we use a data structure P_Pack to store the intermediate results for a pixel : a float array  for ’s 3 color components in the order of , a float variable  for ’s  channel, a float variable “” for ’s actual depth value, a float variable “” for ’s accumulated weight factor from upstream pixels, which is initialized to be 1.0. The pseudocode of SGOO is provided in Algorithm 1, which consists of three parts.

•
Part 1 (Lines 1 to 3): initialize the variables.

•
Part 2 (Lines 4 to 15): The th arriving operand 
 is assigned the th instance of P_Pack from . The “for” loop updates the  components of all the existing instances: for instances whose  components are larger than that of the new one, multiply their “” components by ; for instances whose  components are smaller than that of the new one, multiply the th pixel’s “” component by  from all those smaller instances one at a time.

•
Part 3 (Lines 16 to 18): subtract  from 1 to obtain the  channel of the composited pixel, and add up the color channels of all the existing instances to obtain the color channels of the composited pixel.

In Part 2, for the th iteration of the “for” loop, its embedded “for” loop runs in . Hence, the time complexity of Algorithm 1 is of 
.


Download : Download high-res image (179KB)
Download : Download full-size image
4.2. Parallel generalized  operator
We parallelize SGOO for further performance improvement. There exist several parallelizable operations in SGOO, for example, the variable updates as a new operand arrives and the final summation operations. Such parallelization improves time efficiencies of SGOO but does not change SGOO’s time complexity. In Algorithm 1, each “for” loop is to decide the relative order between the new operand and all existing ones to calculate their “” components. There are two cases: Case 1: the operands with larger “” component values than that of the new one are modified by the new one. Case 2: the new operand is modified by those with smaller “” component values than itself. In Case 1, the same weight factor is applied to all existing operands, which could be parallelized. In Case 2, different weight factors are applied to the same operand, which makes direct parallelization impossible due to the possible conflict in concurrently modifying the same variable. For parallelization, as shown in Fig. 4, we use a new ParaP_Pack structure with a pointer component “”, which represents the index of a ParaP_Pack instance whose “” component is the smallest among those with larger “” components than the current operand. By default, “” is set to be , indicating that there is no downstream operand found yet.

With the “” component, we are able to parallelize the modifications to the same new operand, by directly setting the arriving operand’s “” component to be , where  satisfies that 
 and  
. Here,  represents the existing immediate upstream (preceding) operand of 
,  stores the weight factors from all the existing upstream operands of , and  is the weight factors from all the existing upstream operands of 
.

The pseudocode of Parallel Generalized Over Operator (PGOO) is provided in Algorithm 2, which uses 3 MIMD-featured functions, i.e., MIMDMULTI, MIMDWEIGHT and MIMDSUM, given in Functions 3, 4 and 5, respectively. MIMDMULTI updates the  components of all existing instances in parallel in the embedded “for” loop and reduces the time complexity of each embedded “for” loop to the order of . MIMDWEIGHT and MIMDSUM together parallelize the previous -step summations at the end of SGOO by organizing them in a binary tree and reduces the time cost to the order of . Parallelizing these two time-consuming parts in PGOO results in a reduced overall time complexity of .


Download : Download high-res image (167KB)
Download : Download full-size image

Download : Download high-res image (143KB)
Download : Download full-size image

Download : Download high-res image (76KB)
Download : Download full-size image
5. Theoretical performance analysis
We consider  operands arriving in an arbitrary order with arriving intervals of 
.3 We use 
 and 
 to represent the time cost of the composition procedures based on the traditional and proposed  operators, respectively.

With the traditional  operator, the composition cannot start until all operands become available and are sorted globally. After sorting, the operands are composited one at a time in each channel in the sorted order. Hence, the total time cost using a traditional  operator contains three parts for waiting, sorting, and compositing, respectively, i.e., (13)
where 
 denotes the time for sorting, 
 denotes the time for compositing a single channel. Since there are 4 channels in each operand, the time for compositing all  operands is 
.


Download : Download high-res image (163KB)
Download : Download full-size image
Fig. 5. Composited images of Human Brain.


Download : Download high-res image (431KB)
Download : Download full-size image
Fig. 6. Composited images of HIPIP Surfaces.

With the proposed  operator, there is no clear distinction between the waiting and composition stages, which often overlap with each other. To facilitate the analysis of such mixture, we construct a pipeline model that exactly maps the waiting stage and the composition stage to two continuous steps of the pipeline. The time cost for the waiting step varies, depending on the operands’ arriving intervals, i.e., 
. In the composition step of each incoming operand, we create a separate thread for every existing operand. The time cost for the second step is determined by the thread, which composites with the existing immediate upstream (preceding) operand of the current operand, and hence takes the longest to complete among all.

The threads in PGOO are comprised of the same set of operations executed in possibly different orders. We thus introduce 
 to uniformly represent the time cost of the second step in all the running instances. The time cost for the entire composition process using the proposed  operator is (14)
where 
 is the time cost of the pipeline, and 
 denotes the time for the final summation.

Comparing Eq. (13) with Eq. (14), since in general 
, it is straightforward to see the performance advantage of the proposed operator over the traditional one.

6. Implementation and experimental results
For a high level of parallelism, we implement the new  operator in a heterogeneous computing environment comprised of both CPUs and GPUs. We use two languages to implement Algorithm 2, i.e.,  for CPU programming and CUDA for GPU programming. To be more specific, lines 12, 14 and 16 in Algorithm 2 are parallel functions, which are executed with a large number of threads and are hence implemented in CUDA. The rest of the code is sequential and is hence implemented in . Since there is no global memory addressing between CPUs and GPUs in the existing heterogeneous computing environment, explicit data transfer is needed to support communications between them, which inevitably incurs an overhead. In practice, we overlap such data transfer with other activities to minimize the cost.

To test and evaluate the proposed  operator, we apply it to the image composition process in parallel visualization of real-life volume datasets of 3D Human Brain, High-Potential Iron Protein (HIPIP), and Jet Ejections using ray casting. We plot the final images composited by the new  operator in Fig. 5, Fig. 6, Fig. 7, respectively, which illustrate the validity of the proposed operator and the correctness of our implementation.

For a practical performance evaluation of these two operators, we use the image composition task in Fig. 5 as a benchmark with a sequence of partial images of the same size without any blank pixels. For a comprehensive comparison, in the image composition experiments, we consider 2 image sizes: 
 and 
; 3 different numbers of input images: 8, 16, and 32; 6 image arriving intervals: 0 s, 0.1 s, 0.2 s, 0.3 s, 0.4 s, and 0.5 s; and 7 different image arriving (i.e., availability) orders, in each sequence of input images.

We define the -distance arriving order as an arriving order where the difference between the blending orders of any two subsequently arriving input images is . In the experiments, we generate 7 different arriving orders as follows. Given  operands (i.e., partial images), at time , their arriving order is generated as (15)
 
 
 
 
 
 
 where , , and .

We plot the experimental results in Fig. 8, which shows that given the same arriving interval and the same number of input images of the same size, but with different arriving orders, both algorithms exhibit relatively stable performance curves, which imply that both of the operators are immune to the arriving order. For the traditional operator, since it must wait for all the operands to become available, the arriving order does not affect the time cost; while for the proposed operator, whichever operand arrives, the composition is always performed in constant time in parallel, hence resulting in the identical total composition time.

However, the proposed operator takes consistently much less time than the original one in all the cases, which confirms our theoretical analysis. We further observe that the performance differences become more obvious as the image size and the number of input images increase, as shown in each subfigure (from a to h) of Fig. 8.

Furthermore, in Fig. 8, Fig. 8, as the arrival interval increases, the proposed operator’s relative performance gain over the original one remains quite stable, i.e., the gap between two performance curves does not vary much, which is justified by Eqs. (13), (14). For the proposed operator, the time to perform all the computations for a newly arriving operand is constant. As the arriving interval increases, such computing time becomes negligible, and Eq. (14) is dominated by the other two time cost components, i.e., (16)
Comparing Eq. (16) with Eq. (13), the difference only lies in 
 and 
, which are all fixed given the same number of input images and the same image size. Thus, the performance difference between two these operators as the arriving interval increases is essentially the difference of these two terms.


Download : Download high-res image (1MB)
Download : Download full-size image
Fig. 8. Comparisons of two operators on the image size of 
 and 
 with varying arriving intervals and numbers of input images using the 3D brain dataset. The three subfigures in each group correspond to the cases of 8, 16, and 32 input images, respectively, from left to right.

7. Conclusions and future work
In this paper, we designed an improved  operator that is capable of performing blending on any number of operands arriving in any arbitrary order. Such order independency overcomes the performance limitation of the traditional  operator. We implemented the proposed operator in both a sequential and a parallel mode, and apply it to the image composition problem in parallel volume visualization. Both theoretical analyses and extensive experimental results show its performance superiority over the traditional one.

The proposed operator still requires some more work in the following aspects: (i) the new operator has a high demand of memories, so it would be helpful if the memory utilization can be optimized; (ii) the proposed operator assumes that each operand be active in the blending, so it would also be helpful if we could filter out the blank portions of each operand in advance. There are several similar operators such as “under”, “in”, and “out” in [18], and it is of our future interest to apply the proposed generalization strategies to them for performance enhancement. We also plan to adapt the proposed parallelization strategy to video composition by exploiting overlap between neighboring frames.

