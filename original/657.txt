Abstract
Task offloading strategy optimization in mobile edge computing (MEC) has always been a hot issue. However, the mobility of a user equipment (UE) seriously affects the UE’s cost and performance. This paper proposes three mobility types depending on whether the mobility characteristic of a UE is known, and formulates an energy minimization problem and a latency minimization problem to optimize the cost and performance, respectively. We first develop greedy strategy based task offloading algorithms for UEs according to their mobility characteristics. However, accurately obtaining the mobility characteristics of the UEs over a long time in practice is a huge challenge, especially in a highly random environment like the MEC. To address the issue, we use a Lyapunov optimization method to develop the algorithms that do not require any prior knowledge of the mobility characteristics to minimize the long-term energy and latency of UEs. Experimental results show that the greedy strategy based algorithms can optimize the cost and performance of UEs by using their mobility characteristics, and perform better than the Lyapunov optimization based algorithms in a short-term. However, the Lyapunov optimization based algorithms perform better than the greedy strategy based algorithms over a long-term.


Keywords
Greedy strategy
Lyapunov optimization
Mobile edge computing
Mobility characteristic
Task offloading strategy

1. Introduction
1.1. Motivation
The rapid development of the mobile internet and related hardware has helped the advent of Internet of Things (IoT) era. With these new technologies, some complex applications, such as image recognition, virtual reality, augmented reality, and path navigation [1], can be executed by user equipments (UEs), such as mobile phone and other IoT devices. However, due to the limitations of the computing power, storage capacity, and battery life of UEs, these applications are sometimes not efficiently executed by the UEs, thus degrading the quality of experience (QoE) [19]. Mobile edge computing (MEC) is expected to emerge as a promising technology to mitigate these conflicts.

MEC is an architecture that provides limited resources, such as computing power, to UEs at the edge of network, thus improving the quality of service (QoS) and QoE. High-speed wireless network technologies implement the instant communication between UEs and MEC servers, reducing the communication delay and reliving the network jitter. The heavy tasks of UEs are uploaded to MEC servers for processing to optimize their cost and performance, i.e., minimize energy and latency (computational time) [2]. A lot of researchers worked on the task offloading strategy optimization problem in MEC [3], [5], [6], [7], [11], [12], [13], [29], [33], [34]. However, the above work ignored the impact of UE mobility on the strategy [30]. Moreover, ignoring the UE mobility is not suitable for the real-world scenario [27]. UEs are not always fixed at a certain location, and may be moving [1]. Meanwhile, the mobility of UEs seriously affects the strategy’s cost and performance [10]. The long distance between the UEs and MEC servers will significantly reduce QoS and QoE.

However, the optimization problem becomes even harder when it involves the mobility. To provide seamless service for UEs with mobility, the services of the UEs will be migrated among MEC servers to follow their movement. In this paper, the service of a UE refers to the fundamental environment for processing offloaded tasks of the UE, such as Docker [16] and virtual machine [15]. Thus, the process of making an offloading strategy will be more complicated. Intuitively, for service deployment, a service provider of MEC can deploy enough servers to improve QoS and QoE. However, it is impractical in the real world due to the budget constraint of a service provider. Meanwhile, for saving energy, a UE’s service in a server that does not respond to the UE will enter the sleep state. Therefore, after migrating the service, it needs additional waiting time for activating the service from the sleep state to serve the UE. Obviously, this is not suitable for many latency-sensitive tasks. Thus, if the mobility characteristics of UEs can be known in advance, we can deploy service to a UE accordingly in advance, thus improving QoS and QoE.

In addition, the UE mobility types are also diverse. Meanwhile, utilizing the mobility characteristics to optimize the cost and performance of UEs is only feasible in a short time. Accurately obtaining the mobility characteristics of the UEs over a long time in practice is a huge challenge, especially in a highly random environment like the MEC. In this paper, the short- and long-term are relative concepts, and represent the number of task offloading strategies made by UEs.

According to the above discussions, in this work, we investigate the following questions: (1) How to make the task offloading strategy to optimize the cost and performance of UEs with mobility? (2) How to optimize the offloading strategy by using the short-term mobility characteristics of UEs? (3) How to optimize the long-term offloading strategy without prior knowledge of mobility characteristics?

1.2. Our contribution
To address the above issues, we study the problems and optimize the short- and long-term cost and performance of UEs respectively. The main contributions of our work are as follows.

•
We first formulate the long-term cost and performance optimization problems, respectively. To deal with the challenge of acquiring UEs’ mobility characteristics over a long time, we then use a Lyapunov optimization method to decouple the original problems into two series of real-time optimization subproblems. Thus, the cost and performance of UEs can be optimized based on their current states.

•
We develop the algorithms based on the Lyapunov optimization method, which do not require any prior knowledge of the mobility characteristics to optimize the long-term cost and performance of UEs. Meanwhile, the algorithms proposed in this paper not only make the offloading decision, but also decide the resource allocation and service migration strategies.

•
Extensive simulation experiments are conducted to evaluate the effectiveness of the algorithms in the short- and long-term. Moreover, we explore the impact of various key parameters on the cost and performance of UEs through the experiments.

The rest of the paper is outlined as follows. Section 2 briefly reviews the related research of task offloading strategy optimization, and highlights the characteristics of this paper. Section 3 demonstrates the system model and problem formulations. Section 4 studies the energy minimization problem and develops the algorithms to optimize the cost of UEs. Section 5 studies the latency minimization problem and develops the algorithms to optimize the performance of UEs. Section 6 conducts the experiments to evaluate the effectiveness of the algorithms. Section 7 concludes this paper.

2. Related work
According to the optimization objective, the research of task offloading optimization can be divided into three categories, i.e., energy-optimal (EO), latency-optimal (LO), and others. EO focuses on the energy consumption or harvesting optimization problems [11], and has been extensively studied. For example, Li [13] formulated UEs and MEC servers as queueing models, and developed algorithms by using the Lagrange multiplier method to minimize the energy consumption of UEs. Chen et al. [7] developed an approach to determining how much energy should be harvested at UEs. Cao et al. [5] maximized the saving energy of UEs while satisfying the UEs’ latency requirements. Tout et al. [29] proposed a centralized selective and multi-objective algorithm to optimize the energy consumption of UEs. LO investigates the latency minimization problems [13]. For example, Yang et al. [33] minimized the average computation time of UEs through a heuristic algorithm. Li [12] developed a non-cooperative game theoretic algorithm to optimize the latency of UEs. The third category studies the optimization of other objectives. For example, Chen et al. [6] minimized the weighted sum of the energy consumption and computational time for multiple users with multiple wireless channels. Bhattacharya et al. [3] studied QoE improvement from four aspects, including completion time, energy consumption, monetary cost, and security. Yang et al. [34] compressed the transferred data size to reduce the transmission cost during the task offloading process.

Although the above work studied the computation offloading strategy optimization problem from different optimization goals, they assumed that UEs remain stationary and ignored the impact of mobility on the cost and performance of UEs. Moreover, except for [13], the other work only determined whether to offload the tasks of UEs to MEC servers, but did not decide the resources (i.e., CPU frequency and transmission power) allocation strategy for the UEs.

Several researchers have addressed the issue of UE mobility in the short-term. According to the mobility characteristic, we classify existing research into the following three categories: (1) For UE with random mobility, we know anything about the UE’s movement regularity, and can only make the strategy based on the current location of the UE. For example, Taleb et al. [28] proposed a Markov decision process based algorithm to optimize the strategy. (2) For UE with predictable mobility, we can predict some future locations of the UE, and make the strategy by using the current and future locations of the UE. For example, Wu et al. [32] and Plachy et al. [23] developed the location prediction method respectively. (3) For UEs with fully known mobility, we know everything about the UE’s movement regularity and its all future locations in advance. Therefore, we can make the strategy based on the whole movement path of the UE. For example, Wang et al. [31] optimized the cost of UEs based on their mobility regularities. Under the assumption that the task has been uploaded to the servers, the above work studied the impact of UE mobility on the task offloading optimization. Although Yu et al. [35] made the task offloading decision, but the resource allocation strategies are not considered in their work. Moreover, all the above work did not consider the impact of different mobility characteristics on the cost and performance of UEs.

Also, there is work that optimized the offloading strategy over a long time. Shen et al. [24] minimized the total energy consumption over a long time by reducing the number of service migrations. Sun et al. [26] minimized the average delay over multiple tasks of a UE while satisfying the energy consumption constraint. Ouyang et al. [22] investigated the cost-performance tradeoff of UEs in the long-term. Although the above work investigated the long-term cost and performance optimization problem, their assumption that all UEs stay in a certain area for a long time is too strong. Meanwhile, these work not only failed to study the impact of different mobility characteristics on the task offloading strategy, but also ignored the advantages of optimizing the strategy of UEs staying in a certain area for a short time by using their mobility characteristics. In addition, the above work did not involve the development of resource allocation strategies for UEs.

To address the above limitations, in our preliminary work [9], we analyzed different characteristics of UE mobility, and developed several greedy strategy based task offloading algorithms to optimize the strategy in a short-term based on these mobility characteristics. However, it is a huge challenge to obtain the mobility characteristics of UEs over a long time. Therefore, it is necessary and meaningful to investigate the long-term offloading strategy optimization problem, which solves the issue of UE mobility. This work significantly extends our preliminary work [9]. In this paper, we formulate the long-term cost and performance optimization problems respectively, and use a Lyapunov optimization method to decouple the original problems into two series of real-time optimization subproblems. Then, we develop the algorithms based on the Lyapunov optimization method, which do not require any prior knowledge of the mobility characteristics to optimize the long-term cost and performance of UEs. The algorithms proposed in this paper not only make the offloading decision, but also decide the resource allocation and service migration strategies. Moreover, we explore the impact of various key parameters on the cost and performance of UEs through extensive experiments.

3. System model and problem formulation
3.1. System model
The scenario studied in this paper is a time slot system. UEs move on a two-dimensional plane and execute a task at each time slot  [23], [31], [32]. We assume that the time interval between the two successive time slots is long enough to complete a task. UE
 represents th UE, where . The service of UE
 is represented by th virtual machine (VM), i.e., VM
. The location of UE
 is 
, where 
, 
 are the abscissa and ordinate of UE
 at . As shown in Fig. 1, we use some dots to represent the locations of UEs. Moreover, UEs have their own mobility characteristics. In the figure, UE
 has no dot, which means that it moves in a random manner and we know nothing about its mobility regularity except for its current location. UE
 has one dot, which means that it moves in a certain regularity and its location at  can be predicted at . UE
 has a set of dots, which means that it moves in a given route and we know everything about its mobility regularity and its locations at all time slots in advance. 
 represents an offloadable task of UE
 at . The number of CPU clock cycles required to complete 
 is denoted by 
 (cycles). The data size per CPU clock cycle of 
 is denoted by 
 (bits per cycle).


Download : Download high-res image (131KB)
Download : Download full-size image
Fig. 1. An example scenario investigated in this paper.


Download : Download high-res image (75KB)
Download : Download full-size image
Fig. 2. An example of service migration.

MEC
 indicates an MEC server, where . We assume that high-speed data transmission between the MEC servers is implemented through the backbone network. 
 represents MEC
’s location, where 
 are the abscissa and ordinate of the server. The deployment location of VM
 at  is denoted by 
. The binary variable 
 represents whether 
 is uploaded to MEC
. If 
 is executed by MEC
, then 
, otherwise 
. 
 indicates that 
 will be executed by UE
 itself. Because 
 can only be processed by one entity, thus 
. We use 
 to represent whether to migrate the service of UE
 form MEC
 to MEC
 at . If 
, then VM
 will be migrated from MEC
 to MEC
. We let 
. Meanwhile, we assume that there is only one server that can deploy VM
 at , thus 
.

It can be seen from Fig. 2 that if VM
 is deployed in MEC
 at time slot , the increase in distance between UE
 and the MEC server leads to the increase in transmission delay, thus degrading QoE and QoS. Thus, as shown in the figure, to provide seamless service for UE
, VM
 should be migrated among the MEC servers to follow the UE’s movement. However, as shown in Fig. 1, when UE
 moves back and forth between two locations, if VM
 follows the UE to move back and forth between the two MEC servers, it will cause frequent service migration. The frequent service migration can also lead to an increase in energy consumption and latency. As shown in Fig. 1, Fig. 2, when UE
 moves back and forth between MEC
 and MEC
, because we know the mobility characteristic of UE
, we can keep VM
 at MEC
, thereby reducing the number of unnecessary service migrations and improving QoE. This paper studies the offloading strategy optimization problem with different mobility characteristics, and develops algorithms based on these characteristics to improve QoE and QoS.

3.2. Communication model
We use 
 Watt (W) to represent the maximum transmission power of UE
. According to Shannon’s theorem [21], in the channel interfered by Gaussian white noise, the maximum transmission rate is determined by 
ϒ, where 
 is the transmission channel bandwidth and ϒ is the signal-to-noise ratio of the channel. Following the signal-to-noise ratio used in [5], [6], [11], we adopt the Rayleigh fading channel model [25]. Therefore, the signal-to-noise ratio is ϒ
, where 
, 
, 
 are the transmission power of UE
 to upload 
 to MEC
, the transmission channel fading coefficient, the distance between UE
 and MEC
 at , the channel path loss exponent, and the channel white Gaussian noise, respectively. Moreover, we also overlook the receiving latency of task result. Thus, the transmission rate of 
 from UE
 to MEC
 can be formulated as (1)
 

3.3. Computation model
3.3.1. Local computation model
The maximum CPU frequency of UE
 is denoted by 
 (cycles per second). Moreover, we assume that the UE can adjust its CPU frequency according to its demands. 
 represents the actual CPU frequency of UE
 when 
 is executed by the UE. The local computational time of 
 is (2)
 
Based on [36], then we have the local energy consumption of 
, i.e., (3)
where 
 is the coefficient factor of UE
’s chip architecture.

3.3.2. MEC server computation model
We use 
 (cycles per second) to denote the computing power of MEC
. Thus, the computational time of 
 executed by MEC
 is (4)
where 
, 
, 
, 
 are the transmission delay of 
, the computational time of 
 executed by MEC
, the average waiting delay of 
 in MEC
, the migration delay of VM
, respectively. In this paper, without loss of generality, we assume that the migration delay 
 is a constant related to task type of UE
. Accordingly, the UE
’s energy consumption of 
 executed by MEC
 can be formulated as (5)
where 
 (W) is the static power of UE
. Based on the above definitions, the latency of 
 can be formulated as (6)
The energy consumption of 
 can be formulated as (7)

3.4. Problem formulation
3.4.1. Energy minimization problem
According to the above definitions, we can formulate the energy consumption minimization problem of UE
 as the following: (8) 
  
 
 
 where 
 is the maximum average time latency of UE
’s task. 
, 
, 
, 
 are the service migration strategies, the offloading decisions, the transmission power strategies, and the CPU frequency strategies of UE
 at all . In P1, 
 are the constraints of CPU frequency and transmission power, respectively. 
 represents that 
 can only be processed by one entity at . 
 represents that VM
 can only be deployed at one MEC server at . 
 is the latency constraint of a task.

3.4.2. Latency minimization problem
The latency minimization problem of UE
 can be formulated as the following: (9) 
  
 
 
 
 where 
 
 is the maximum average time energy consumption of UE
’s task. 
 is the energy constraint of a task.

It is easy to know that P1 and P2 are not only the long-term optimization problems, but also mixed integer programming problems and NP-hard problems [17].

4. Energy minimization problem
4.1. Greedy strategy based algorithms
It is easy to know that the optimal solutions of P1 and P2 cannot be obtained at one time, but needs to be continuously adjusted to accommodate the dynamics of UEs based on the long-term knowledge. Therefore, to solve the mixed integer programming and NP-hard problems, we can use the greedy strategy, i.e., making offloading strategy with minimum cost at each time slot. Then, we can solve the problems task by task. Meanwhile, we can also use the following theorem to transform the original multiple-dimensional optimization problem into 1-dimensional optimization problem [4].

Theorem 1

, where 
.

If we know the deployment location of VM
, i.e., Eq. (6) can be transformed to (10)
and Eq. (7) can be transformed to (11)
Moreover, if 
 can be relaxed to be a continuous variable, i.e., 
, P1 and P2 can be transformed to the standard linear programming problems. Next, we first assume that 
 and decouple P1 into a subproblem of 
. Thus, the subproblem of P1 is (12) 
 

In P3, we use 
 to represent a task offloading strategy set consists of offloading decision, CPU frequency, and transmission power. Thus, we can decompose subproblem P3 into two subproblems based on the offloading decision, i.e., 
.

Based on Theorem 1, we can obtain the optimal task offloading decision, CPU frequency, transmission power, and service migration strategies according to the following theorem.

Theorem 2

For energy minimization problem, the optimal strategies of 
 can be obtained from the following equations: (13)
(14)
(15)
(16)
 where 
, and  is a boolean function. If  is true, then . Otherwise, . 
 where 
 and 
.

Proof

If 
 is executed by UE
 itself, then 
. Plugging Eq. (2) into 
, we have 
. Let 
. Thus we have 
. That is, there is a minimal CPU frequency 
 that can satisfy the latency constraint 
. According to 
, we can easily obtain the optimal CPU frequency strategy from 
.

If 
 is executed by MEC
, then 
. Plugging 
 into 
, we have an inequality 
. Then, plugging Eq. (1) into the inequality, we have 
, where 
 and 
. Thus, there is a minimal transmission power 
 between UE
 and MEC
 in order to satisfy the latency constraint 
. According to 
, we can easily obtain the optimal transmission power strategy from 
.

Since 
 is a linear function w.r.t. 
, we can obtain the offloading decision from 
, where MEC
 represents the optimal server.

When the cost of service migration is less than the benefit of service migration, the service migration operation is triggered. We can iterate all MEC servers and calculate the energy consumption of UE
. Then, we can obtain the service migration strategy from 
. Moreover, if we regard MEC
 with minimal cost as the optimal server, we can obtain the optimal service migration strategy from 
.  □

According to Theorem 2, we have a corollary, i.e.,

Corollary 1

For 
 and MEC
, MEC
 is an available server for UE
 when 
.

Proof

It is easy to know that if 
 can be completed within the latency constraint, the minimal transmission power must satisfy 
. Otherwise, the delay of the task executed by MEC
 violates the constraint 
.  □

In fact, we can use Corollary 1 to check the feasibility of an MEC server for executing 
. Thus, we can determine an available MEC server set of 
 in advance, i.e., 
, to reduce the server scale that needed to be searched. Then, we can get the optimal transmission power strategies for UE
 transmitting 
 to each MEC server (MEC
). Next, the corresponding cost for MEC
 executing the task can be calculated based on Eq. (5). Meanwhile, we regard MEC
 with minimal cost as the optimal server. The optimal CPU frequency and corresponding cost can be easily obtained from Eqs. (3), (13), respectively. By comparing the optimal cost of local execution and server execution, we get the optimal offloading decision 
. If 
, the service migration is triggered when 
. Hence, we obtain the optimal offloading strategy of 
.

Remark 1

In this paper, although the CPU frequency is assumed to be a continuous variable, the algorithms proposed in the paper can be easily adapted to discrete CPU frequencies. For instance, let us consider CPU frequency 
, where 
 are the possible CPU frequency values of UE
. For given 
 and 
, the optimal CPU frequency is determined. For the short-term energy-minimization problem, to meet the latency constraint of 
, the minimal CPU frequency is 
. If 
, we can conclude that UE
 is not capable to complete the task 
 within the latency constraint. That is, the task should be offloaded to the MEC servers for processing. If 
, the task can be executed locally. Moreover, if 
, then 
 is the optimal CPU frequency strategy, i.e., 
. If 
 and 
, although we cannot obtain the optimal CPU frequency strategy directly, it can be confirmed that the suboptimal CPU frequency 
 should satisfy 
. Hence, the suboptimal CPU frequency is the smallest element in  that is greater than 
, i.e., 
.

It should be noted that 
 may be a suboptimal solution of P3. However, 
 is the best CPU frequency strategy that UE
 can really adopt.

It is feasible to obtain the mobile characteristics of UEs in a short-term. Thus, we can use the mobility characteristics to optimize the strategies of the UEs. Next, we detail the three task offloading algorithms based on different mobility characteristics.


Download : Download high-res image (222KB)
Download : Download full-size image
4.1.1. The algorithm for UEs with random mobility
For UE
 with random mobility, we make the strategy based on the UE’s current informations, i.e., location and task informations. For the energy minimization problem, Algorithm 1 shows an energy-optimal algorithm to decide task offloading strategies for UE
 with random mobility. The algorithm is named EO-RM. When 
 and MEC
 are given, 
, 
, 
, and 
 can be obtained accordingly. Then, UE
 iterates 
 to try to find MEC
 while making the service migration strategy. That is, UE
 finds an optimal MEC server with minimum execution energy consumption among MEC
 at each time slot. The complexity of the algorithm is 
, where 
 is the number of MEC servers in this set.


Download : Download high-res image (260KB)
Download : Download full-size image

Download : Download high-res image (352KB)
Download : Download full-size image
4.1.2. The algorithm for UEs with predictable mobility
For UE
 with predictable mobility, we can predict some future locations of the UE, and make the strategy by using the UE’s current and future locations. We assume that the UE’s location at  can be predicted exactly at  [35]. Therefore, we can reformulate the subproblem of P1 as (17) 
 

Let 
 and 
 be the VM deployment policies for 
 and 
, which are gotten from Algorithm 1. Moreover, there is a common MEC server executing the two successive tasks, which may further reduce the cost of UE
. The rational of the assumption revealed by the following theorem.

Theorem 3

If 
 and 
, there may be a new optimal strategy for two tasks, i.e., 
 and 
, where MEC
. Otherwise, the original strategies are the optimal strategies for 
 and 
.

Proof

If 
, 
, and there is a new optimal strategy for the two tasks, i.e., 
, where 
, 
, and 
. Then, we have an inequality, i.e., 
, where MEC
 and MEC
. However, we know that 
 and 
, which contradicts with the premise. Thus, 
 should be true (i.e., the two tasks are executed at a common MEC server MEC
) when there is a new strategy for the two tasks. Moreover, if MEC
, which means that one of the tasks violates the latency constraint. Therefore, if 
 and 
, then MEC
 is the optimal execution location for the two tasks.

If 
, we assume that 
 and 
, we have inequalities 
 
 and 
 
. Thus, if we have 
, which contradicts with the premise. Based on the above, we have the conclusion.  □

For the energy minimization problem, Algorithm 2 shows an energy-optimal algorithm to decide task offloading strategies for UE
 with predicted mobility. The algorithm is named EO-PM. We can first obtain the optimal strategies of 
 and 
 from Algorithm 1, respectively. The services of two successive tasks are rescheduled in MEC
 
 according to Theorem 3. Meanwhile, the task offloading strategies of the two tasks are updated accordingly. The complexity of the algorithm is 
.

4.1.3. The algorithm for UEs with fully known mobility
For UE
 with fully known mobility, we know everything about the UE’s movement regularity and its all future locations in advance. For the energy minimization problem, Algorithm 3 shows an energy-optimal algorithm to decide task offloading strategies for UE
 with fully known mobility. The algorithm is named EO-KM. An example process of Algorithm 3 is illustrated in Fig. 3. The initial 
, 
, 
, 
, and 
 are obtained from Algorithm 2. As shown in the figure, we use 
 to represent the initial locations of UE
’s service. Since the whole movement and task informations of UE
 is know, to avoid confusion with the former two real-time algorithms, we use  instead of  to represent the subscript of parameters. We iterate 
 to update the task strategies of UE
, where 
  is th time slot task of UE
 and 
 represents the task set of the UE at all time slots (i.e., 
). 
 denotes the service location of 
. 
 is an offloading strategy (including offloading decision, CPU frequency strategy, and transmission power strategy) of 
. 
 is the available MEC server set of 
. 
 is the service migration strategy of 
.


Download : Download high-res image (164KB)
Download : Download full-size image
Fig. 3. An illustration process of Algorithm 3.

There are two iterations for updating the strategies of UE
 in Algorithm 3. The first iteration (Lines 4–25) is migrating the service of the UE in advance. Let 
, we use 
 () and 
 to represent the first task and the last task among the successive tasks executed by MEC
, respectively. Thus, the number of the successive tasks executed by MEC
 is . If , we try to migrate VM
 ahead to reduce the UE’s cost. As shown in Fig. 3, if we migrate VM
 from MEC
 to MEC
 when 
 is executed, and the cost of  tasks can be reduced, we will adjust VM
’s location and UE
’s task offloading strategies accordingly. Hence, we obtain 
. If the reduced cost is less than 
 or the iteration amount exceeds the maximum number of iterations 
, the early migration process is terminated. Therefore, we have 
.

The second iteration (Lines 26–33) is avoiding migrating the service of the UE. If 
, 
 and MEC
, we try not to migrate VM
 when 
 is executed. As shown in 
, if 
 is executed by MEC
, the UE
’s cost can be reduced. We can adjust VM
’s deployment strategy and UE
’s task offloading strategies accordingly. Finally, we obtain the optimal strategies. The complexity of the algorithm is 
.

4.2. Lyapunov optimization based algorithm
4.2.1. The background of Lyapunov optimization method
Lyapunov optimization is a method of using a Lyapunov function to optimal a dynamic system, and has low computational complexity and quantifiable worst-case performance [18]. The method has been widely used for task scheduling in queueing networks [14], [20]. In this section, we present the background of the Lyapunov optimization method.

Consider a queueing system that operates in discrete time with unit time slots , and let  be the workload of a new arrival task at . The workload  will be stored in a queue  to be scheduled. Meanwhile, the system is described by the queue backlog of . A schedule action is taken at every time slot , which affects the arrivals and departures of . The method defines a function  as the square of backlog multiplied by , i.e., 
. The function is named the Lyapunov function, and can be used to measure the system congestion. Next, the method defines the Lyapunov drift  as the difference in the Lyapunov function between two successive time slots. If schedule actions are made at every time slot to greedily minimize , then  is consistently pushed towards a lower congestion state, which intuitively maintains system stability. It should be noted that the specific meaning of system stability varies according to different problem definitions. For example, in this paper, the system stability means that the energy consumption and latency of UEs remain at a certain level.

For a schedule system, we want to minimize an objective function  while ensuring the system stability. Instead of taking actions to minimize , the actions are taken to minimize the drift-plus-penalty function at every time slot . The drift-plus-penalty function is formulated as , where  is a non-negative weight parameter that indicates the importance of how much we emphasize the optimization objective.

It can be known that the Lyapunov optimization method only requires the knowledge of current information. Therefore, we can use the Lyapunov optimization method to transform P1 and P2 into two series of online minimization subproblems respectively, which addresses the challenge of acquiring UE’s mobility characteristics over a long time.

4.2.2. The algorithm


Download : Download high-res image (192KB)
Download : Download full-size image
The greedy strategy based algorithms require that the mobility type of UEs is known in advance. However, it is unrealistic to obtain the mobility characteristics of UEs over a long time. Fortunately, the long-term constraints (i.e., 
) in the problems can be regarded as the queue stability control problem respectively [20]. The Lyapunov optimization method provides an efficient approach to decouple the long-term optimization problem. Next, we detail the transform process.

Let 
 represent a virtual discrete time queueing system of UE
 defined over time slot . In the paper, 
. The future state of the queue is derived by the current computational time 
 and the average latency constraint 
 according to the dynamic equation (18)
The virtual queue 
 is the backlog at  and can be represented the additional time required to process the tasks. Thus, 
 is used to enforce the strategies meet the constraint 
. We use Lyapunov optimization method to transform P1, then have the following theorem.

Theorem 4

P1 is equivalent to the following problem (19) 
 
(20)
 where 
 is the weight parameter that indicates the importance of how much we emphasize energy consumption of UE
.

Proof

Based on the definition of virtual queue, the Lyapunov function is 
. The change in Lyapunov function from one slot to the next slot is (21)
 
 
 where 
 and 
 is the maximum latency of task.

The conditional Lyapunov drift is (22)
where  represents the expectation. According to Eqs. (21), (22), and the law of iteration expectation [20], we have (23)
 And then, according to the law of telescoping sums [20] and 
, we have (24)
Hence, when , the above equation can be rearranged as (25) 
 
 
 
 
 

Based on Eqs. (24), (25),  is mean rate stable, that is the energy consumption constraint of MSP can be satisfied [20].

The Lyapunov drift-plus-penalty function is (26)
 Therefore, if we want to minimize the long-term energy consumption while satisfying the latency constraint 
, we can minimize 
. Equivalently, we can minimize 
 and have the theorem.  □

Theorem 4 unifies the energy consumption of UE
 and the latency constraint of UE
 into an equation. As shown in P5, the solution of P5 is an approximate optimal solution of P1. Meanwhile, the average time energy consumption deviates by at most 
 from the optimal solution of P1, with the average queue backlog bounded of 
 [20]. The optimal solutions 
, 
, 
, and 
 of P5 can be easily obtained according to the following theorem.

Theorem 5

For MEC
 and UE
, the optimal strategies of P5 can be obtained from the following equations: (27)
(28)
(29)
(30)
 where 
, and 
 is obtained from the following equation: (31)

Proof

Let 
. Plugging Eqs. (10), (11) into 
, we can get 
. It is easy to know that 
 is a convex function w.r.t. 
. Thus, we can get the optimal solution through 
 and obtain 
.

Let 
. We have (32)
 
 
 
 
(33)
 
 
 
 
 Let 
. We have (34)
 
Hence, we know that 
. Accordingly, we easily know that 
. Therefore, 
 is a convex function w.r.t. 
. Then, we can get the optimal value 
 through 
. Plugging 
 into Eq. (32), we can obtain Eq. (31). Thus, the optimal value 
 is the solution of 
 and can be obtained by using binary search method [4]. Based on the above optimal solutions, 
, and 
, we get the theorem.  □

Remark 2

As mentioned in Section 4.2.1, if the schedule actions are made at every time slot to greedily minimize the drift-plus-penalty function , then  is consistently pushed towards a lower congestion state, which intuitively maintains system stability. As shown in Theorem 5, the CPU frequency strategy satisfies 
, where 
 and 
 are constants. It can be easily known that 
 increase and decrease at the same time. Therefore, for the long-term energy minimization problem, if we use the discrete CPU model, we can first get the minimal CPU frequency through 
, i.e., 
. Unlike the short-term energy minimization problem, if 
, we set the suboptimal CPU frequency is 
. This is because the Lyapunov optimization method focuses on the long-term optimization. Meanwhile, the method tolerates that the latency of strategy is greater than the latency constraint 
 in a certain range. If 
, then 
 is the optimal CPU frequency strategy, i.e., 
. If 
 and 
, not only to maintain the same increase and decrease between 
 and 
, but also to maintain system stability, the suboptimal CPU frequency 
 must satisfy 
. Hence, the suboptimal CPU frequency is the smallest element in  that is greater than 
, i.e., 
.

Similarly, although 
 may be a suboptimal solution of P5, 
 is the best CPU frequency strategy that UE
 can really adopt.

Based on Theorem 4, Theorem 5, we develop the long-term energy-optimal algorithm for UE
 based on the Lyapunov optimization method. The algorithm is named EO-LY. As shown in Algorithm 4, it does not require any prior knowledge of the mobility characteristics to minimize the long-term energy consumption of UEs. The complexity of the algorithm is , where  is the maximum number of binary search iterations for obtaining 
.

5. Latency minimization problem
5.1. Greedy strategy based algorithms
Similar to P1, if 
, the subproblem of 
 is (35) 
 

5.1.1. The optimal solution of the latency minimization problem
For latency minimization problem, we can also obtain the optimal task offloading decision, CPU frequency, transmission power, and service migration strategies based on Theorem 1. The optimal strategies of 
 can be gotten according to the following theorem.

Theorem 6

For latency minimization problem, the optimal strategies of 
 can be obtained from the following equations: (36)
(37)
(38)
(39)
 where 
 
, and 
 is the solution of the following equation: (40)

Proof

If 
, 
 is executed by UE
. Plugging Eq. (3) into 
 
, we have 
 
. Let 
 
. Thus, we know that there is a maximum CPU frequency 
 that can satisfy the energy constraint 
. According to 
, we can easily obtain the optimal CPU frequency strategy from 
.

If 
, 
 is executed by MEC
. Plugging Eq. (5) into 
, we have the following inequality (41)
where 
 
. We then introduce (42)
where 
 and 
. As can be seen in Fig. 4, if 
, 
. Otherwise, 
, where 
 is the solution of 
. Moreover, because 
, then 
 and 
 is a monotonic non-increasing function w.r.t. 
 when 
. Therefore, we can obtain 
 by using binary search method [4]. According to 
, we get the optimal transmission power strategy from 
.

Since 
 is a linear function w.r.t. 
, we can obtain the offloading decision from 
.

When the cost of service migration is less than the benefit of service migration, the service migration operation is triggered. We can iterate all MEC servers and find the optimal MEC server with minimal latency MEC
. Then, we can obtain the optimal service migration strategy from 
.  □

Remark 3

Similar to the short-term energy minimization problem, if we use discrete CPU frequencies, for the short-term latency minimization problem, we can first obtain the maximal CPU frequency from 
 
. If 
, we can conclude that 
 will not exceed the energy consumption constraint. Thus, we have the suboptimal CPU frequency 
. Moreover, if 
, then 
 is the optimal CPU frequency strategy, i.e., 
. If 
 and 
, although we cannot obtain the optimal CPU frequency strategy directly, it can be confirmed that the suboptimal CPU frequency 
 should satisfy 
. Hence, the suboptimal CPU frequency strategy is the largest element in  that is less than 
, i.e., 
.

Similarly, although 
 may be a suboptimal solution of P6, 
 is the best CPU frequency strategy that UE
 can really adopt.

5.1.2. The algorithms for UEs with different mobility characteristics
Similarity, we can use the mobility characteristics to optimize the strategy of UE. We can adopt Algorithms 1, 2, and 3 to optimize the latency based on the UE’s mobility characteristics. However, in the algorithms, we replace the energy 
 with latency 
. Moreover, we name the algorithms as LO-RM, LO-PM, and LO-KM, respectively.

5.2. Lyapunov optimization based algorithm
Same as P1, we introduce virtual queue 
 
. We also assume that 
. Then, we have the following theorem.

Theorem 7

P2 is equivalent to the following problem (43) 
 
(44)
 where 
 is the weight parameter that indicates the importance of how much we emphasize latency of UE
.

Proof

Similar to Theorem 4, we first obtain Lyapunov function, conditional Lyapunov drift, and Lyapunov drift-plus-penalty function of P2. Then, we can get the conclusion with the help of the law of telescoping sums. Due to the space of paper, the detailed proof is omitted.  □

The solution of P7 is an approximate optimal solution of P2. Meanwhile, the average time service latency deviates by at most 
 from the optimal solution of P2, with the average queue backlog bounded of 
 [20]. The optimal solutions 
, 
, 
, and 
 of P7 can be obtained according to the following theorem.

Theorem 8

For MEC
 and UE
, the optimal strategies of P7 can be obtained from the following equations: (45)
(46)
(47)
(48)
 where 
, and 
 is obtained from the following equation: (49)

Proof

Compared with Theorem 4, we can easily find that the multipliers of 
 and 
 are reversed actually. We replace the task latency with task energy consumption as the backlog of the virtual queue that we want to make stable. Moreover, the above operations do not change the convex property of P7. Therefore, we can adjust the place of related parameters i.e., 
 and 
 of 
 and 
, thus obtaining the optimal solutions of P7. Therefore, we get the theorem.  □

Similarity, we can replace energy consumption used in Algorithms 4 with latency as the optimization objective to make the strategy for UEs. The algorithm is named as LO-LY accordingly.

Remark 4

Similar to the long-term energy minimization problem, if we use discrete CPU frequencies, for the long-term latency minimization problem, we can first get the minimal CPU frequency from Theorem 8, i.e., 
. If 
, we set the suboptimal CPU frequency is 
. If 
, then 
 is the optimal CPU frequency strategy, i.e., 
. If 
 and 
, the suboptimal CPU frequency is the smallest element in  that is greater than 
, i.e., 
.

Similarly, although 
 may be a suboptimal solution of P7, 
 is the best CPU frequency strategy that UE
 can really adopt.

6. Simulation experiments and results analysis
6.1. Experiment setting
In the experiment, referring to [12], we generate  UEs and  MEC servers according to the following parameters: 
 W, 
 W, 
 cycles/s, 
 s, 
 
 J, 
 is a random value taken from , 
 bits/cycle, 
, 
 Hz, 
, 
, 
, 
 s, 
. The computing power of MEC
 is given as 
 cycles/s. Without loss of generality, we set 
. UEs move on a 400 × 400 square meters two-dimensional plane and 
. To simulate the movement of UEs, we introduce a random variable  to indicate UE remains stationary, or moves 1 meters (m) forward or backward. The three UEs adopt the different transportation means, including walk, bike, and motorcycle. The horizontal and vertical speeds (i.e., 
 and 
) of UEs are as follows: 
, 
, and 
. The location of UE
 at  is 
, where 
 and 
. The MEC servers are located on the diagonal of the plane, and their horizontal and vertical coordinate intervals are the multiple of 4 m. In addition, due to different magnitude of energy and latency. For energy minimization problem, we simulate 
 time slots. For latency minimization problem, we simulate 
 time slots.

We use the following four task offloading schemes as baselines: (1) LM: UE
 executes all tasks locally by using 
. (2) LR: UE
 executes all tasks locally by using the CPU strategies proposed in this paper. (3) MM: All tasks will be offloaded to the MEC servers with 
. (4) MR: All tasks will be offloaded to the MEC servers for executing by using the transmission power strategies proposed in this paper.


Table 1. The average number of iterations comparison of UE
 using different algorithms.

Algorithms	Energy minimization (
)	Latency minimization (
)
EO/LO-RM	200	200	200	200	200	200
EO/LO-PM	205	211	218	212	233	221
EO/LO-KM	314	257	239	319	367	254
EO/LO-LY4	10,875	11,234	10,341	12,503	12,503	12,233
EO/LO-LY6	11,884	11,406	11,188	12,232	12,232	12,504
EO/LO-LY8	13,063	11,651	11,582	11,501	11,501	11,503

Table 2. The cost and performance comparison of UE
 using different algorithms.

Algorithms	Energy/cost (J, 
)	Latency/performance (s, 
)
LM	1E＋09	1E＋09	1E＋09	8E−08	8E−08	8E−08
LR	1.587E−03	1.587E−03	1.587E−03	6.35E−02	6.35E−02	6.35E−02
MM	1.145E−04	1.145E−05	1.14E−05	4.852E−06	4.852E−06	4.836E−06
MR	4.053E−07	4.031E−07	3.917E−07	4.208E−06	4.271E−06	4.384E−06
EO/LO-RM	3.945E−07	3.93E−07	3.819E−07	4.208E−06	4.271E−06	4.384E−06
EO/LO-PM	3.943E−07	3.925E−07	3.814E−07	4.188E−06	4.249E−06	4.384E−06
EO/LO-KM	3.941E−07	3.925E−07	3.814E−07	4.181E−06	4.249E−06	4.384E−06
EO/LO-LY4	3.182E−06	1.527E−06	4.258E−06	8.178E−05	8.168E−05	8.062E−05
EO/LO-LY8	3.995E−07	9.073E−07	9.139E−07	1.032E−05	1.053E−05	1.034E−05
EO/LO-LY12	8.569E−08	8.66E−08	8.642E−08	4.208E−06	4.271E−06	4.324E−06
6.2. The convergence of the algorithms
Table 1 shows the average number of iterations required for UE
 using different algorithms to obtain its optimal strategy. The number of iterations refers to the number of loops required to search 
, and 
. In the table, EO-LY4 represents EO-LY 
 and LO-LY4 is LO-LY 
. Other similar symbols indicate similar meanings. As shown in the table, for LO-RM/PM/KM, since the transmission power is obtained by using binary search method, the average number of iterations is more than what EO-RM/PM/KM needs. LO/EO-LY needs more iterations than LO/EO-RM/PM/KM. The reason lies in that LO/EO-LY does not determine the available MEC servers set in advance and should iterate all servers at each time slot. Meanwhile, the value of 
 or 
 is larger than 
, so LO/EO-LY takes more iterations to make transmission power strategy when using the binary search method. Therefore, we can also find that the value of 
 or 
 affects the number of iterations. For LO-LY, 
 decreases as 
 increases, thus the algorithm with smaller 
 requires less iterations. However, for EO-LY, increasing the value of 
 has opposite effects on the number of iterations.

6.3. The effectiveness of algorithms in the long-term
As shown in Table 2, although LM achieves the minimal latency among all the algorithms, the energy consumption of LM exceeds the energy consumption constraint of UEs. It can be seen from the table that compared with the four baselines, the four algorithms proposed in this paper perform better. Moreover, if the future location of the UE can be known in advance, the service migration strategy can be pre-determined to further minimize the cost. Thus, compared with EO/LO-RM, EO/LO-PM/KM can further reduce the energy and latency of UEs by using their mobility characteristics.


Download : Download high-res image (249KB)
Download : Download full-size image
Fig. 5. (a) The impact of 
 on the number of service migrations. (b) The impact of 
 on the number of service migrations.


Download : Download high-res image (297KB)
Download : Download full-size image
Fig. 6. (a) The impact of 
 on the energy consumption. (b) The impact of 
 
 on the latency.

 and 
 are the weight parameter that indicates the importance of how much we emphasize the energy and latency of UE
, respectively. Thus, we can see that the energy and latency of UE
 decreases as 
 and 
 increases. Moreover, as shown in Fig. 5, it can be seen that the number of service migrations decreases as 
 or 
 increases, thus reducing the service migration amount, energy, and latency of UEs.

Next, we analyze the impact of 
 and 
 
 on the energy and latency, respectively. Let us take UE
 as an example. From the perspective of the curves in Fig. 6, as the constraints tighten, the energy and latency gradually increase. However, EO/LO-LY performs better than EO/LO-RM/PM/KM.

It is well known that the short-term and long-term are relative concepts. Thus, in this paper, energy minimization problem is a long-term optimization problem when 
, and latency minimization problem is a long-term optimization problem when 
. Based on the above, we can conclude that EO/LO-LY performs better than EO/LO-RM/PM/KM in the long-term.

In addition, as shown in the above tables and figures, we find that the transportation means affects the velocity, resulting in different movement distance and 
. Therefore, the transportation mean affects the effectiveness of the algorithms.

6.4. The effectiveness of algorithms in the short-term
As can be seen from Fig. 7(a), the energy consumption of UE
 using EO-RM/PM/KM increases as  increases. In addition, in Fig. 7(b), the latency of UE
 increases as  increases. The reason is that the movement of UE
 increases the number of service migrations, thereby increasing the energy and latency. Let us take UE
 as an example. For EO-LY, the energy consumption of the UE decreases as  increases. However, as shown in Fig. 8(a), the latency of UE
 exceeds the 
 when 
. Thus, EO-RM/PM/KM performs better than EO-LY in the short-term (i.e., 
). Since the energy consumption constraint, it can also be seen from Figs. 7(b) and 8(b) that LO-RM/PM/KM performs better than LO-LY in the short-term (i.e., 
).

6.5. The impact of other variables
6.5.1. The impact of 
The data size per CPU clock cycle of 
 is denoted by 
 (bits per cycle). This means that the increase of 
 directly affects the latency and energy consumption during the data transmission process. It can be seen from Figs. 9(a) and 9(b) that as the increasing of 
, the average energy consumption and average latency per time slot are also increasing. Therefore, the optimal execution location for UE’s task with high 
 is not always in MEC servers, but sometimes in local.

6.5.2. The impact of 
As shown in Eq. (1), 
 represents the communication channel path loss between UE
 and MEC
. In addition, with the increase of 
, the transmission rate between the UE and the server decreases, thus increasing the transmission delay for the UE uploading its tasks. It can be seen from Figs. 10(a) and 10(b) that the increase of 
 causes an increase in energy consumption and latency of UEs. It can also be known from the figures that the stable and high-speed wireless communication greatly reduce the energy and latency for UEs performing various applications, thus improving QoS and QoE.

6.5.3. The impact of 
 represents the migration delay of VM
 and directly affects the quality of seamless service providing to UEs with mobility. We can see from Figs. 11(a) and 11(b) that the decrease of 
 causes the decrease in energy consumption and latency of UEs. The lightweight virtualization technology adopted by MEC, such as virtual network function [8], can make the fast service migration a reality.

6.5.4. The impact of 
In MEC, the servers with limited resources are deployed proximity to UEs to save energy or latency of the UEs. Intuitively, an increase in the number of MEC servers within an area can improve QoE. The reason is that increasing the number of servers will allow a UE to choose servers closer to itself, thereby reducing the latency and energy consumption for transmitting task. It can be seen from Figs. 12(a) and 12(b) that as  increases, the energy consumption and latency of UEs decrease, which is consistent with the real world.

6.5.5. The impact of 
Although the paper assumes that there are no resource competitions between UEs, it is meaningful to explore the effectiveness of the proposed algorithms in a multiple UEs scenario. In this experiment, we create more UEs randomly based on the former parameter generation equations. As shown in Fig. 13, due to the different workload and moving speed of UEs, it seems that the change in the number of UEs causes the change in the average energy consumption and latency of the UEs. It should be noted that the increase of  does not necessarily mean an increase in average energy consumption or a decrease in average latency. The reason lies in that there is no competition of MEC server resources between UEs, that is, a UE’s strategy is not affected by other UEs in this paper. However, constrained by the maximum energy or latency of UEs, it can be confirmed again from Figs. 13(a) and 13(b) that EO/LO-RM/PM/KM performs better than EO/LO-LY in the short-term. Moreover, it can also be known that EO/LO-LY performs better than EO/LO-RM/PM/KM in the long-term.

7. Conclusions
In this paper, we formulate an energy minimization and a latency minimization problems respectively, and develop algorithms to optimize the UE’s cost and performance in the short- and long-term. We propose three mobility types depending on whether the mobility characteristics of UEs are known, and develop the greedy strategy based task offloading algorithms for the UEs to optimize their cost and performance in a short-term by using their mobility characteristics. To deal with the challenge of acquiring UE’s mobility characteristics over a long time, we then use a Lyapunov optimization method to develop the algorithms that do not require any prior knowledge of the mobility characteristics to optimize the long-term cost and performance of UEs. Experimental results show that the greedy strategy based algorithms perform better than the Lyapunov optimization method based algorithms in the short-term. However, the Lyapunov optimization method based algorithms perform better than the greedy strategy based algorithms over the long-term, especially when the mobility characteristics of UE cannot be known in advance.

Deploying the algorithms on actual MEC system involves many challenging issues, such as caching, virtualization technology, creating interactive protocols between the different entities, and ensuring the stability of communication channel. Since the study of the above issues is beyond the scope of our work, we evaluate the algorithms through simulation experiments. Moreover, this paper only investigates three simple mobility types. Thus, more complicated mobility characteristics should be further investigated in the future. Furthermore, the above issues should be considered in the system model, thus developing algorithms that can be deployed in the real world.