Abstract
We address a practice-relevant optimization problem: optimizing multi-product batch plants, with a real-world use case study – optimal design of chemical-engineering systems. Our contribution is a novel approach to parallelizing this optimization problem on GPU (Graphics Processing Units) by combining two metaheuristics – Simulated Annealing (SA) and Ant Colony Optimization (ACO). We improve the implementation performance by tuning particular parameters of the ACO metaheuristic. Our tuning approach improves on the previous methods in two respects: (1) we do not have to rely on additional mechanisms like fuzzy logic or algorithms for online tuning; and (2) we use the high computation performance of GPU to speedup the tuning process. By parallelizing the tuning process on modern GPUs, we allow the user to experiment with large volumes of input data and find the optimal values of the ACO parameters in feasible time. Our experiments on NVIDIA GPU show the efficiency of our approach to parameter tuning for the ACO metaheuristic.


MSC
68R05
68T20
68U01
90C27

Keywords
Metaheuristics
Metaheuristics parameter tuning
Ant 
Colony Optimization tuning
Combinatorial optimization
Batch plant design

1. Motivation and related work
Optimal design of multiproduct batch plants is a practice-relevant optimization problem. In this paper, we conduct a case study of designing Chemical-Engineering Systems (CES), which consist of a set of equipment units (tanks, filters, reactors, etc.) manufacturing a variety of products. The problem is to determine, for the given input (production horizon, product demand, etc.), the number and main sizes of technological units to achieve the lowest possible capital and operating cost while meeting the design and production objectives.

Combinatorial optimization [12] is, in practical cases, very time-consuming due to the “combinatorial explosion” – the number of combinations to be examined grows exponentially. Because of problem’s high computational complexity, this paper addresses parallel implementation on high-performance systems comprising CPU and GPU (Graphics Processing Units). We achieve this two-fold: (1) we use metaheuristics that do not guarantee that the found solution is optimal, but solutions of good (and in practice acceptable) quality are obtained faster than when using precise methods, and (2) we further accelerate metaheuristics by means of tuning their parameters.

The performance of metaheuristics depends upon the suitable selection of parameters chosen by the user. Finding the most suitable values for the parameters (fine tuning) is a challenging problem [14]. The previous work on tuning metaheuristic parameters follows one of two directions: online or offline methods [4], [9], [21]. A general online parameter adaptation method based on estimating algorithm’s performance and gradient search in the parameter domain is presented in [22]. A combination of statistical and AI mechanisms is proposed in [3], while [17] suggests using fuzzy logic for adapting parameters. [13] is a comprehensive survey of automatic parameter tuning methods for metaheuristics. Parameter tuning utilizes the design of experiments in [10] and swarm optimization in [11]; sequential optimization of perturbed regression models is used in the tuning framework of [23]. In [19], parameters of a metaheuristic are found by an evolutionary metaheuristic. An ad hoc initialization and dynamic mutation that together improve the accuracy of ACO are proposed in [8].

In this paper, we make two main contributions: (a) a GPU-parallelized approach to solving the plant optimization problem by combining two metaheuristics: ACO and SA, and (b) a new approach to parameter tuning in ACO for the CSP (Constraint Satisfaction Problem) part of the optimization problem. Since we tune parameters not for the optimization problem as in [16], [17] but rather for CSP, this allows us to use frequency analysis that is not dependent on any specific information, like fuzzy logic, algorithms for online-tuning, etc. [7], [8], [17]. Due to the use of modern GPUs on the parallelized algorithm, we can run many experiments in order to accumulate statistical data in a reasonable amount of time. Another positive feature is the possibility to use the tuned parameters for either parallel or sequential algorithm version.

The paper is organized as follows. Section 2 describes our CES optimization use case. In Section 3 we describe our use of metaheuristics for optimizing multi-product batch plants, with a specific use case of CES. In our hybrid approach, we combine two metaheuristics: Simulated Annealing (SA) and Ant Colony Optimization. In Section 4, we further accelerate the GPU-parallelized ACO method by means of ACO’s parameter tuning using statistical analysis. Finally, we summarize our contributions.

2. The batch plant optimization: Problem formulation
We provide here a rather intuitive description of the batch plant optimization problem for a particular use case of CES; a detailed formulation is given in [6]. A CES consists of equipment units organized in  processing stages: the th stage has set 
 of equipment units, while 
 is the amount of units’ variants in 
. We write 
 
 for a CES variant, where 
 is the number of system variants.

In Fig. 1 a simplified CES with 4 stages is shown, where each stage has two devices (
); there are altogether 
 variants of such a system.

The optimization goal is – for the input data of the product demand, production horizon, and available equipment set – to compute the optimal units’ number and their sizes at particular processing stages. Each system variant has to be operable and meet the processing time constraint.


Download : Download high-res image (266KB)
Download : Download full-size image
Fig. 1. A simple Chemical-Engineering System (CES): An example.

Because of the “combinatorial explosion” – the number of combinations to be examined grows exponentially – even the fastest computers may require an intolerable time: e.g., if each process stage can be equipped with devices of  to  standard main sizes, then a CES consisting of  stages yields the total number of choices is 
 up to 
 (which is approximately 
 to 
). This requires an acceleration which is our topic in the remainder of this paper.

3. A parallel metaheuristic approach
Our approach to accelerating the solution of the CES optimization problem is to use metaheuristics and to develop a fast implementation of the metaheuristics using highly-parallel architectures, in particular Graphics Processing Units (GPU).

A heuristic algorithm for an optimization problem considers the most likely, rather then all possible states of the problem. Specific heuristics are usually problem-dependent. A metaheuristic is an algorithmic pattern for finding high-quality solutions for an optimization problem [4] by compromising between both global and local search. Randomization is used in metaheuristics in order to avoid local search and rather conduct search on the global scale, by efficiently exploring the space and reducing the size of the space. Experience shows that metaheuristic algorithms often converge to decent solutions in a reasonable amount of time, while the optimality of solutions is not guaranteed [24].

3.1. Combined metaheuristic
In this section, we describe our approach combining two popular metaheuristics: Simulated Annealing (SA) and Ant Colony Optimization (ACO).

The ACO metaheuristic describes a multi-agent system: the agents called ants achieve a global goal [24] by interacting with each other. ACO is inspired by the life of an ant colony: when moving from the source of food to the joint nest, ants leave on their paths a substance called pheromone, which is employed for interaction between ants. Pheromone helps in finding the shortest path between a nest and food, because ants follow, with particular probability, the path labeled with pheromone.

The SA metaheuristic is very popular [24]: it finds an optimal solution in many application areas and generally finds solutions of good quality. SA employs random search in which it may accept non-ideal changes in order to avoid local optima and thus eventually converge to a good-quality global solution.

We combine in our approach ACO and SA because, before using SA, we need a feasible initial solution, for finding which we use ACO. Unlike classical optimization problems that use a random initial solution, our CES optimization problem cannot accept random initialization, because of the constraints that have to be satisfied. The search for an initial solution can be considered as a Constraint Satisfaction Problem (CSP) [18]. We solve this CSP by using the ACO metaheuristic that was shown to yield good-quality results for numerous practical cases of CSP [20].

3.2. The Ant Colony Optimization (ACO) metaheuristic
In Listing 1, we demonstrate the basic structure of the ACO algorithm for solving our optimization problem. This code runs as an individual thread for every colony of ants. We parametrize the algorithm by the number of ants, as a compromise between the search breadth at each iteration and the iterations number: we need fewer iterations for a larger ants colony. In each thread, we use the local iteration counter as a non-stop operation protection (line 5): the thread terminates if it does not find a suitable solution after the maximum number of iterations, which is possible with randomized algorithms.


Download : Download high-res image (333KB)
Download : Download full-size image
Each ant in Listing 1 moves in the tree-like space from top to bottom. After an ant selects a node at some tree level, it picks then a next child node at the same level. In the leaves, ant’s movement terminates, so each path in the tree stands for a possible solution of the problem. The ant’s transition from node  to  is impacted by two variables: heuristic information 
 and pheromone trail 
: 
, where 
 are children of  [24], and  are children indices. Parameters  and  determine the pheromone and heuristic information, respectively.
In line 14 of Listing 1, we perform the pheromone evaporation in each iteration at a constant rate , such that the pheromone value cannot become too high, and we also “forget” previous choices of poor quality. We code it as follows: 
, where  is called a persistence parameter. Parameters  and  in our code impact both the pheromone and the heuristic value, and they determine their relative importance. Pheromone is updated as follows: 
, with constant , while  is the swarm size and 
 - the path length for th ant: for a shorter path we update the pheromone stronger. Fitness function 
 specifies how near is a solution to the required goal. When computing heuristic values, a unit with a larger main size satisfying the constraint for the beginning part of the CES is preferred to a unit of smaller size or with unsatisfied compatibility constraint.

Listing 2 shows the calculation o fitness: we compute the stages number in the beginning of CES, i.e., for which devices at stages  to  (lines 5–6) the constraints are satisfied. The fitness value is  (minimal) if not a single constraint is satisfied; the value is  (maximal) if, i.e., ll constraint are satisfied, i.e., the problem is solved.


Download : Download high-res image (158KB)
Download : Download full-size image
Here, W is the problem solution, function SatisfiedRestr- ictions() checks the compatibility constraint (CES has to be operable, i.e., it must satisfy the joint action conditions for all processing stages), function T() denotes the production rate, T_max is the total available production time (so-called horizon). The production rate has to be less or equal to the horizon (processing time constraint).
3.3. Simulated Annealing (SA)
The SA algorithm performs a search in the solution space and converge to the best solution by gradually restricting the space. An annealing parameter called “temperature” (in analogy to the process in nature) influences how the search proceeds, in particular a solution of lower quality can be accepted with some probability: this enables avoiding local optima.

Our SA implementation in Listing 3 is structured in two loops. The solution at stage  is W[i]; it is initialized by a solution W_init provided by ACO, as explained above.


Download : Download high-res image (378KB)
Download : Download full-size image
The outer loop of SA (line 3) decreases the probability of non-improving solutions in the inner loop (line 4); the latter loop is searching for a neighboring solution. To generate a new candidate solution W_cand, we use special procedure Permutation() (Listing 4). Due to randomly generating neighbors and allowing with some probability a solution that worsens the objective function, our SA implementation avoids local optima.


Download : Download high-res image (120KB)
Download : Download full-size image
At each iteration in Listing 4, procedure Permutation() computes a neighboring solution. We randomly take some CES stage  for generating a new solution, and we also choose randomly the unit number  from set 
. The iterations in SA run L_max times, where L_max is the equipment set size. We take a random unit in a random stage at each iteration, and we permute the feasible solution. At the end of each iteration, the temperature value t is decreased by means of a cooling procedure (line 3); we use the cheapest price of a unit for T_final. Effective cooling rule is essential for reducing the time needed by the algorithm. In (line 16) we apply the fast cooling rule  [24]; we choose , following the recommendation in [2].

3.4. Parallel implementation of the combined metaheuristic
Our combined (ACO+SA) parallel metaheuristic works on a system consisting of a CPU (host) and a GPU. The implementation code starts as the host code for the CPU, which calls multiple instances of the kernel code that run as parallel threads on the GPU.

There are 5 steps in our combined metaheuristic implementation, as follows:

1.
The host takes the input data, prepares the SA and ACO parameters, and starts multiple instances of the ACO kernel on the GPU.

2.
The GPU-Kernel for ACO finds an initial CES-variant that satisfies the problem’s constraints. We employ the approach with multiple ant colonies that independently run on parallel threads, until one thread finds a feasible solution. The more threads we employ, the shorter is the time for finding a solution.

3.
CPU takes the obtained initial solution, partitions it among the GPU threads as a start point for SA, and executes the SA kernel on the GPU.

4.
The kernel for SA on the GPU looks in parallel for the optimal solution. Note that we aim not at reducing the iteration runtime, but rather at increasing the grade of parallelism in the execution of iterations: we increase the probability of converging to the global optimum, even when the initial solution is the same in all threads. The more threads we start, the higher is the chance for some thread to find an almost optimal solution.

5.
CPU takes the solutions obtained by the SA GPU-threads, chooses the best of them and accepts it as the final solution of the problem.

On a parallel system comprising a CPU and a GPU, the CPU (host) takes the input data from a file, sends them to the GPU and starts there the ACO kernel function. To improve performance, CUDA kernels are launched asynchronously: after starting the kernel the control is immediately returned back to the CPU. We use cudaDeviceSynchronize() for synchronization: the host waits till the termination of the GPU kernel and obtains the result from it.

In our ACO program, threads simulate multiple ant colonies. At start, we assign small random values for pheromones. Threads are controlled by a local iteration counter and a global flag which is updated using atomicAdd() if the corresponding thread found a suitable solution. Each thread uses the local iteration counter as a non-stop operation protection: if thread’s ants cannot find a solution after the specified number of iterations then the thread stops.

The implementation of SA consists of two loops. The outer loop decreases the temperature and thus reduces the probability of taking non-improving neighboring solutions, search for which is performed in the inner loop. Note that our SA avoids local optimum in that it generates neighbors randomly and, with some probability, accepts solutions worsening the objective function; the probability of such acceptance decreases with lower temperature. Therefore, SA conducts a wide search at the beginning, and then it gradually restricts the solution space while converging to the optimal solution.

4. Parameter tuning for the ACO metaheuristic
The goal in this section is to improve the parallel ACO implementation by using the additional performance potential via tuning particular parameters of ACO. We employ offline parameter tuning according to the classification of [21]. The tuning task is to configure the ACO parameters, such that the CSP is solved as fast as possible. Our idea of improvement by tuning is to find the intervals of the parameter values in which the feasible solutions of the optimization problem (i.e., solutions that satisfy both compatibility and processing time constraints) are contained more frequently. As demonstrated in the next section, our tuning approach finds comparatively small intervals of parameter values, such that these intervals contain about 90% of feasible solutions. By using these small intervals, we can significantly reduce the run time of the optimization algorithm.

4.1. The general tuning idea and the parameters for tuning
Fig. 2 shows that our general tuning approach proceeds in five steps:

1.
The host takes the input data and initializes the parameters on device.

2.
The device initializes the parameters by one of the methods in Section 4.2.

3.
On the device, we start the kernel shown in Listing 1.

4.
The ACO kernel on device finds an initial solution for CES.

5.
The host takes the computed results and records them for further processing; if the solution is not obtained, step 2 or 3 are repeated depending on which particular tuning approach from Section 4.2 is adopted.

Parameter  expresses how important is the accumulated pheromone for the path selection by ants: the larger is , the more probable is that ants choose the same path as their predecessors on the path. On the one hand, the convergence of ACO increases in this case; on the other hand, the algorithm is more probable to trap into a local optimum.

Parameter  describes the mutual visibility of ants: how important is the heuristic information for selecting a particular path. If the value is small, it might bring ACO into stagnation or a local optimum, while a large value of  leads to the state transition probability similar to a greedy algorithm.

Parameter  expresses the evaporation rate of the pheromone. Low value of  allows to quickly forget previous choices, while high values mean that the pheromone persists longer. Therefore, small  restricts the global search ability, while larger values improve it, but they slow down the convergence.

4.2. Three specific tuning approaches
We design and evaluate three specific approaches to parameter tuning: Random, Constant and Multi-Constant, as shown in Listing  5. The parameter TUN_APP of SET() stands for TUNing APProach.


Download : Download high-res image (379KB)
Download : Download full-size image
Random approach
In this approach, we initialize algorithm parameters by uniformly distributed randoms from intervals 
, 
, 
, respectively. The bounds of the intervals are set as suggested in, e.g. [15]. We use the GPU-tailored random number generator available in the incuRAND library by NVIDIA [1]. The library function curand_uniform() computes uniformly distributed randoms in , so we use: rand(a,b) = curand_uniform() * (b-a) + a. The corresponding SET() function in the Random approach is shown in Listing 5 lines 6–8. If we find a combination of parameter values that yields a feasible solution then we save these values. Eventually, we find a set of tuples (, , ), for which ACO yields feasible solutions. If in step 4 of Random a feasible solution is not obtained after maxIterationNumber iterations then the approach moves to step 2 in Fig. 2.

Constant approach
In the Constant approach, all threads use same tuples of values , ,  as in Listing 5, lines 11–13. The starting values are set using a frequency analysis of the tuple set from Random. In the iterations afterwards, we determine a set of tuples for which ACO computes feasible solutions. If no feasible solution can be in step 2 after maxIterationNumber iterations, we go to step 3 in Fig. 2.

Multi-constant approach
This approach uses different initial values of tuples in the threads. In this approach, Listing 5, lines 16–18, we can view parallelized ACO as “learning” on the base of random tuning: we save only the parameter tuples for we already found a solution. If no feasible solution is found after maxIterationNumber iterations, we go to step 3.

5. Experimental results
Our experimental setup consists of: (1) a CPU: Intel Xeon 2.3 GHz with  hyper-threaded cores, and  GB of RAM, (2) a GPU: NVIDIA V100 T with  CUDA cores at 1.53 GHz, and  GB of global memory. We employ GNU C++ 6.4.0 and CUDA 10.0.

Our case study is to design a CES of  stages with  to  device variants per stage (i.e., from 
 to 
 variants). This size is significantly larger than was possible without parameter tuning [5]. We call the ACO algorithm  times for each problem size of 
 to 
 (i.e.,  series of experiments). We measure the run time till finding a feasible solution, calculate the average and record it with the values , , .

5.1. Random approach
In our first experiment, we assign  and  with random values of uniform distribution in , and  in , as suggested in [15]. In this series, we obtain  tuples , ,  with the sizes for which we found the solutions. The GPU run time for this Random series is approximately   h.

Fig. 3(a) shows the average run time of ACO for different problem sizes, and Fig. 3(b) – the frequency of the found solutions, expressed as histograms for particular intervals of parameter values. We observe from the histograms that about 90% of solutions are obtained when the parameters belong to the intervals: , , .

Our tuning approach reduces the intervals for , ,  by selecting values with higher solutions frequency. For that, we iterate the runs and thus find new  solutions for the reduced parameter intervals, and analyze the solution frequency again. We repeat this process times, such that parameter intervals reduce to a single point: , , , which we take as initial values for the Constant approach as described in Section 5.2.


Download : Download high-res image (177KB)
Download : Download full-size image
Fig. 3. Results of random parameters tuning: First iteration.

We conclude for Random approach that it decreases the run time of ACO on average by about  times (from about  s for ,  and  to about 1.7 s for , , ). The time for seven iterations of experiments is about  h. In the following, we describe how the found parameter values are further used in the Constant and Multi-constant approaches.

5.2. The constant approach
In the constant approach, we use the same value for , ,  obtained in the random approach, in every GPU thread.

Fig. 5 shows our measurements, where the first tuple , ,  is taken for comparison from [5] where it was chosen empirically.

An interesting observation is that, while it seems intuitively clear that by averaging the good parameter values we obtain good parameter candidates, this is not confirmed experimentally: the second tuple in  Fig. 5 (, , ) is the average of the parameter intervals found in the first iteration of Random, but these values increase the ACO run time by about 40%.


Download : Download high-res image (116KB)
Download : Download full-size image
Fig. 5. Constant approach: Measured run time vs. problem size.

In Fig. 5, the third tuple , ,  is obtained by analyzing the frequency data in Fig. 3(b) after Random’s first iteration: we select values providing the highest frequency. This reduces the run time by a factor of about . The fourth tuple , ,  is obtained after 7 iterations of Random: it shortens the run time of ACO by about . The total GPU-time for tuning is the same   hrs, like in Random.

5.3. The multi-constant approach
In this approach, we set for each GPU-thread its own parameter values , ,  which are found in the Random approach. The approach produces  parameter tuples for problem sizes of 
 up to 
, for which we found feasible solutions. By running our program on the GPU we cyclically initialize the ACO parameters: e.g., with  tuples of parameters, and then after every  threads on the GPU, the values of parameters are repeated.

In Fig. 6, we show the measurements for multi-constant approach. The shortest run time corresponds to the set of  tuples, and the longest — to the set of  tuples. The run time of ACO when beginning with  tuples differs from the run time for  tuples by only 16%. At the same time, the search time for  tuples is about 15.4 times longer than for  tuples.


Download : Download high-res image (139KB)
Download : Download full-size image
Fig. 6. Multi-constant approach: Measured run time vs. problem size.

5.4. Comparison of tuning approaches
In Fig. 7, we draw a comparison of the best run times for ACO achieved by our different tuning approaches. We observe that the Multi-constant approach, compared to the version with  tuples, brings good solutions in a significantly shorter tuning time.

Fig. 7(a) demonstrates that the lowest run time is obtained in the Constant approach with parameter values , ,  – run time about 1.1 s. We observe in Fig. 7(b) that the tuning time of the Multi-constant approach with 200 samples (about  min) is  times shorter, whereas the resulting ACO run time is about 2.5 times shorter.


Download : Download high-res image (212KB)
Download : Download full-size image
Fig. 7. Comparison of approaches.

6. Conclusion
This paper makes the following contributions to the state of the art in the batch plant design optimization. First, we design and evaluate a parallel combined implementation of metaheuristic-based optimization. Second, we develop three tuning approaches for the parameters of the parallel Ant Colonies Optimization (ACO) metaheuristic. The advantages of our approach compared to related work are as follows: (1) using the high computing power of GPU for tuning, and (2) avoiding any additional information like algorithms for online-tuning, functions mapping in fuzzy logic, etc.

