Abstract
The multi-replica strategy can create multiple data replicas for the edge cloud system and store them in different DataNodes, which improves data availability and data service quality. However, the storage resources of DataNodes are limited and the user demand for data is time-varying, the unreasonable number of data replicas will cause a high storage burden on the file system or low data service quality. Therefore, the number of data replicas needs to be dynamically adjusted according to the actual situation. Based on this, a dynamic replica creation strategy based on the gray Markov chain is proposed. If the number of replicas needs to be increased, the newly added replicas need to be placed on the DataNodes. Considering the problem of load balancing of the DataNode during replica placement, this paper proposes a replica placement strategy based on the Fast Non-dominated Sorting Genetic algorithm. In addition, considering the problem of data replica synchronization and the data recovery of failed DataNodes in the edge cloud system, this paper proposes a delay-adaptive replica synchronization strategy and a load-balancing based replica recovery strategy. Finally, the experiments prove the effectiveness of the proposed strategies.

Keywords
Edge-cloud
Replica synchronization
Replica placement

1. Introduction
Facing the connection of massive smart devices, the explosive growth of data traffic, the emergence of a large number of new applications and the increasing demand for service quality from mobile users, for computing platforms, some specific problems need to be considered [6], [26], [29], [45]. On the one hand, the network distance between the cloud computing platform and the users is relatively long, which will cause a large delay when users request computing and storage resources from a remote cloud computing center. On the other hand, the transmission and processing of a large amount of data in the cloud computing platform will lead to an increase in the load on the core network and a reduction in the data transmission and processing rate.

A reasonable solution is to use edge computing technology to solve the above problems. Without changing the network architecture, edge computing deploys a series of edge servers (Small cloud server, edge server, micro base station) near the edge of the network to provide computing and storage services to users. The data that needs to be transmitted to the cloud computing platform is transmitted to the edge server for local processing, which can achieve the purpose of reducing core network pressure and resource request delay [2], [32]. However, edge computing also has the disadvantage that the computing and storage capacity of the edge server is limited. Therefore, the Edge Cloud Computing (ECC) technology that combines cloud computing and edge computing can give full play to their respective advantages and provide users with better service quality [1], [36], [39].

In the edge cloud environment, a large amount of data access and the heterogeneity of storage devices and network devices may cause problems such as service interruption and data failure, and the multi-replica approach can effectively solve these problems [8]. However, the multi-replica method faces the problem of adjustment of the replicas number. An unreasonable number of replicas will cause the problem of high replica consistency maintenance costs or low data service quality. If the number of replicas needs to be increased, the new added replicas need to be placed on the DataNodes. How to ensure the load balancing of the edge cloud cluster during the replica placement process is a problem that needs to be studied. In the distributed file system, such as HDFS, a strong consistency strategy is usually used to update the replicas of written data. However, the strong consistency strategy is not suitable for application to edge cloud environments. This is because the DataNodes in edge cloud may be located in different geographical locations, which makes the strong consistency strategy be affected by the delay caused by insufficient bandwidth and network congestion. This will eventually make the replicas unable to synchronize in real time, increase data write latency, reduce data write throughput, and thus reduce data availability. Due to the heterogeneity of the nodes in the edge cloud, the DataNodes in the cluster may fail, which will cause the data stored on it to be lost, thereby reducing the data reliability.

For the problem of the number of replica adjustment, this paper proposes a dynamic replica creation strategy (RDA-GM). This strategy considers data block heat and data block access response time to calculate the replica creation factor, which is used to adjust the number of data replicas. The gray Markov chain is used to predict the access frequency of the data block, which is used for the calculation of the data block heat. For the problem of replica placement, this paper proposed a replica placement strategy (RPS-FNSG). This strategy considers DataNode performance, cluster storage load, and network distance to establish a multi-objective replica placement problem based on Pareto optimal solution and uses the fast non-dominated sorting genetic algorithm to solve this problem. To solve the problem of strong consistency replica synchronization strategy not suitable for edge cloud, this paper proposes a delay-adaptive replica synchronization strategy (DA-RS). This strategy does not update all replicas with a strong consistency, but only updates some replicas, then the written data blocks can be accessed, which improves the availability of the data. When the file system is idle or the Unupdated blocks become heat data, these non-updated replicas are updated, which guarantees the ultimate consistency of the replicas. To solve the problem of reduced data reliability caused by DataNode failure, this paper proposed a load-balancing based replica recovery strategy (LB-RR). In this strategy, first the failed DataNodes are detected through the heartbeat mechanism of the file system. Then the recovery benefit and recovery cost of the data blocks in the failed DataNode are calculated, and some data blocks to be recovered are selected based on them. Finally, the DataNode with the smallest load is selected as the target node for the data replica recovery.

The main contributions of this paper are shown below:

(1) The unreasonable number of data replicas will lead to the problem of low data availability. To solve this problem, this paper proposes a dynamic replica creation and placement strategy. This strategy comprehensively considers the data block heat and access response time to dynamically adjust the number of data replicas to improve the data service quality. It also considers network distance, node load performance, and cluster storage load to select the DataNodes for the place the new added data replicas to achieve the load balancing.

(2) In order to solve the problems of high data write latency and low data availability caused by the use of the strong consistent replica synchronization strategy in an edge cloud file system, the delay-adaptive replica synchronization strategy is proposed. This strategy does not update all replicas with a strong consistency, but only update some replicas, then the written data blocks can be accessed, which improves the availability of the data. The unsynchronized replicas will be synchronized at the appropriate time, which guarantees the ultimate consistency of the replicas.

(3) In order to solve the problem of data replica loss due to DataNode failure, the load-balancing based replica recovery strategy is proposed. This strategy selects the recovered data according to the data recovery benefits and costs, and then selects the data recovery nodes according to the load balancing principle. This strategy can ensure the load balance of the file system cluster on the basis of ensuring data reliability.

(4) The effectiveness of the proposed strategies is proved by experiments. The experimental results haveâ€‹ shown that the proposed replica dynamic creation strategy can effectively reduce the system response time while completing the adjustment of replicas number. The proposed replica placement strategy can effectively improve data read throughput and system storage space utilization while ensuring load balancing. The proposed replica synchronization strategy can reduce the data write latency and improve the write throughput of the file system on the basis of ensuring consistency of the replica, this effectively improves data readability. The proposed replica recovery strategy can reduce data write time and improve data read throughput, this effectively improves data reliability.

The rest of the paper is organized as follows: The related work is discussed in Section 2. The proposed replica management strategy and algorithm are presented in Section 3. The application scenario for the proposed replica management strategy is presented in Section 4. The experimental environment introduction and algorithm performance analysis are discussed in Section 5. The conclusions and future work are given in Section 6.

2. Related work
2.1. Replica management strategy
Replica management strategy is an important issue that needs to be studied in the edge cloud architecture, especially the dynamic replica adjustment and creation strategy, which can dynamically adjust the number of data replicas according to changes in the network environment and computing environment to meet the real-time requirements of users for data access. At present, many scholars have studied the management strategy from different perspectives.

Gopinath et al. [15] proposed a data replication dynamic management strategy in HDFS system, which comprehensively considers the popularity of data, the current replication factor, and the number of active nodes in the system to dynamically calculate the optimal replication factor, and according to the data factor replication factor to create or increase the number of data replicas to dynamically adjust the number of replicas. Gill et al. [21] proposed a cost-aware data replication strategy that dynamically calculates the minimum number of replicas by considering the availability of the file system and then optimizes the cost of replica creation based on the concept of a backpack. John et al. [20] proposed a novel dynamic data replication strategy to improve the access efficiency of cloud storage while remaining the QoS attributes of the cloud. Jayalakshmi et al. [17] proposed a dynamic data replication strategy in the cloud computing system, this strategy calculates the popularity of the file by using the principle of time locality principle to calculate the popularity of files. If the popularity of the file reaches a threshold, the replica creation operation of the file replica is triggered. Dieye et al. [12] proposed a genetic algorithm-based replica management strategy that dynamically adjusts the number of file replicas based on data access rates and disk characteristics over time. Suji et al. [9] proposed an effective data replication strategy, which replicates data dynamically based on data popularity. The strategy categorizes data into hot, warm, and cold by considering its access patterns, and dynamically manages the replication of each category. The replication factors for hot and warm data are maintained according to their availability requirements, and a minimum number of replicas is set for cold data. Sun et al. [35] presented a dynamic replica creation strategy based on node overheating similarity, which defines a fuzzy membership function of node overheating similarity based on node load. Shwe T et al. [38] proposed an enhancing replica synchronization strategy, in this strategy, whenever the client puts a write request, the one replica of the data block will be updated first and then the remaining replica immediately gets the update. Jyoti Kumari et al. [23] proposed a proactive re-replication strategy, this strategy comprehensively considers the CPU utilization of the target node, the disk usage, and the popularity of the replica to recover the data replicas of the failed DataNode to the target node. The summary of dynamic replica creation and adjustment strategy is shown in Table 1.


Table 1. Summary of dynamic replica creation and adjustment strategy.

Algorithm	Objective	Methods	Consideration
[15]	To reduce the storage space consumption and storage cost without affecting the reliability and availability requirements of the cloud storage system.	Data Replication, Erasure Coding	Data popularity, replication factor, and number of active nodes in the system
[21]	To guarantee data availability and reduce the cost of replica creation	The concept of the knapsack	File system availability, data replication costs
[20]	To improve cloud storage access efficiency and preserve cloud QoS attributes.	Smart water drop algorithm	File accesses and replica locations
[17]	To improve data availability and reduce the wait time for users to request a replica of a file.	Time locality principle	Data popularity, load balancing of replica placement nodes
[12]	To minimize energy costs and meet the data availability and access time in a cloud environment	Genetic algorithm	Data access rates and disk characteristics
[9]	To reduce storage space utilization and data storage costs without affecting data availability constraints	The replication factor for data is set based on data popularity degree, and the calculated threshold.	Data access model, data popularity
[35]	To improve the load balance and reduce user access latency	The fuzzy cluster analysis method	Node load
Our work	To reduce the task response time and improve storage service performance.	Greyâ€“Markov Chain	Data block access frequency, response time, file size, data block size
The above works have studied dynamic replica adjustment and creation strategies in cloud environments and edge cloud environments. They usually calculate the replica adjust factor based on the popularity, access times and overheating similarity of the file or data block, and use replica adjust factor to adjust the number of replicas of the file or data block in order to provide users with more reliable data access services. However, some works [9], [15], [20], [21] only consider the access frequency of file/data block in the current time period as the consideration for modeling the file heat model. Due to the data access frequency changes dynamically, the access frequency within the current time period cannot reflect the file/data block heat in the future time period. Some works [12], [17], [21] only consider the access frequency but ignore the access response time when modeling the file/data block heat model, which reduces the quality of service when user request data. Some works [20], [21] use file as the cache replica unit, which will lead to a reduction of resource utilization of the file system and an increase in consistency maintenance costs. In most cases, users are only interested in some data blocks in a file, not the entire file, which is proved experimentally in Section 5.1.5. For solving these problems, this paper proposed a dynamic replica creation strategy. Compared with previous works, the advantages of proposed strategy are as follows:

(1) For the problem that the access frequency within the current time period cannot reflect the data block heat in the future time period. The access frequency of data block in the future time period is used as one of the factors to model the data block heat model. At the same time, the gray Markov chain is used to predict the frequency of data access in the future time period to obtain accurate prediction results.

(2) In addition to considering the frequency of data access, the data access response time is also taken into account when modeling data block heat, which improves quality of service for users requesting data.

(3) This paper uses data blocks as the replica units, which solves the problems such as low file system cache utilization and high consistency maintenance costs caused by using file as cache replica units in edge cloud file system.

2.2. Replica placement strategy
At present, the goal of related researches on replica placement is mainly about selecting the appropriate placement nodes for the data replicas to achieve the purpose of load balancing between nodes. many scholars have achieved remarkable results in the research of the replica placement strategy.

Wu et al. [43] proposed a five-dimensional security model for replica placement. Then based on the fuzzy set and entropy weight theory, the security risk of the data center is evaluated, and a replica placement evaluation algorithm considering the security of the data replica is designed to establish a multi-factor fusion of the evaluation model. Xu et al. [44] proposed a replication placement mechanism with an adjustable replica deployment strategy, which considered the availability of data, the frequency of replication access, and the remaining capacity of storage nodes. Eslami et al. [13] proposed three kinds of web server replica placement algorithms, which used K-means, fuzzy C-means clustering, and self-organizing mapping neural network algorithms to select web servers to place the file replicas for balancing the load between replica placement nodes. Jin et al. [18] studied the content placement problem with optimal monetary cost, and transformed this problem into a constraint optimization problem with the goal of minimizing the total cost of content placement. Atrey et al. [5] studied the joint optimization problem of data and replica placement for data-intensive services in geographically distributed clouds. In response to this problem, the author proposed an overlapping correlation clustering algorithm. Liu et al. [24] proposed a group based genetic algorithm based data replica placement strategy, which considers the size of the data set and the network bandwidth between the data centers. Aral et al. [3] proposed a distributed data replica placement strategy. This strategy makes replica placement decisions based on the userâ€™s requirements, storage locations of replicas, and storage costs to reduce replica access latency and network overhead. Wu et al. [41] proposed a topology-based matching component service replica placement method, this method first finds the communication topology through multi-scale graph clustering and then obtains the topology of the computing node through spectral clustering. Finally, the replicas of component services are placed by matching the two topologies. The summary of the replica placement strategy is shown in Table 2.

The above work has studied replica placement strategies from different application environments and different aspects. Most of these works consider specific factors in different application environments to select appropriate target nodes for the data replica placement to achieve the purpose of load balancing. Although these works have been relatively perfect for the study of replica placement. However, some works [3], [5], [18], [43], [44] did not consider the network distance between the source node and the target node when designing the replica placement strategy. If the source node is too far away from the target node, it will cause unstable data transmission, longer data transmission latency, and increased network bandwidth consumption. Some works [13], [24], [41], [43] did not consider the hardware performance difference between the DataNodes. Differences in hardware performance will cause different load capacities between DataNodes. If the hardware performance of the DataNodes is not taken into account when performing replica placement operations, the load imbalance problems of the edge cloud file system are caused. Some multi-objective-based replica placement strategies [5], [13], [41], [43] use a linear weighting method to construct the objective function, which is to reduce the number of sub-objective problems to a main objective function by introducing weight coefficients. The difficulty of the linear weighting method is how to find reasonable weight coefficients. The optimization effect of the linear weighting method depends to a large extent on the choice of weight coefficients, which depends on the experience of experts. Therefore, the linear weighting method cannot meet the multi-objective optimization requirements under actual conditions. For solving these problems, this paper proposed an replica placement strategy. Compared with previous works, the advantages of the proposed replica placement strategy are as follows:


Table 2. Summary of replica placement strategy.

Algorithm	Objective	Methods	Consideration
[43]	To achieve a high probability of data replica availability, reduce the waiting time,	Fuzzy set and entropy weight theory	Data replica, storage security
[44]	To maintain the system load balancing and improve the rate of successful data access	Placing the data replicas based on the node spare capacity	Data availability, replication access frequency and remaining capacity of storage nodes
[13]	To minimize runtime and latency and balance load between replicas	K-means, fuzzy C-means clustering and self-organizing mapping neural network algorithms	distance between replicas and clients, load between replicas
[18]	To minimize the total cost of content placement	The KTT condition	The storage and bandwidth costs
[5]	To improve evaluation metrics and reduce execution time	Overlapping correlation clustering algorithm	latency, storage cost, inter data center traffic, and data center span.
[24]	To reduce data transmission in cloud	The genetic algorithm	The size of the data set and the network bandwidth between the data centers
[3]	To reduce replica access latency and network overhead	Making replica placement decisions based on user requirements, storage locations of replicas, and storage costs	Magnitude and location of user demand as well as storage pricing
[41]	To improve the performance of service-based applications	Multi-scale graph clustering, spectral clustering	The topology of the service-based application and the communication performance between computing nodes
Our work	To ensure load balancing between DataNodes on the edge cloud, improve data access efficiency, reduce data write latency, and improve data read throughput	Fast Non-dominated Sorting Genetic Algorithm	DataNode performance, File system cluster storage load, Network distance
(1) For some replica placement strategies that do not consider the network distance between the source node and the target node and the difference in load capacity between nodes. This paper establishes a multi-objective replica placement optimization strategy, which does not only considers traditional node load balancing factors such as file availability, node performance, relative node load, but also comprehensively considers node hardware heterogeneity and network distance between nodes.

(2) For the problem of existing replica placement strategies that rely too much on expert opinions to set the weight parameters of the objective function. In this paper, the fast non-dominated sorting genetic algorithm is used to solve the optimal replica placement problem. This algorithm can obtain the Pareto optimal solution of the multi-objective problem without relying on expert opinions, which meets the requirements of the multi-target replica placement problem optimization in practical situations.

3. Replica management strategy in edge cloud
3.1. Dynamic replica creation model
In this section, the RDA-GM is proposed in this section. This strategy comprehensively considers the data block heat and the data access response time to calculate the dynamic factor of the data block. The data block size and file size are used to calculate the static factor of the data block. The calculation of the data block heat comprehensively considers the access frequency of data blocks in the past, current and future three time periods. The gray Markov chain is used to predict the access frequency of data blocks in the future time period. The replica creation factor is calculated based on the dynamic factor and static factor. The replica creation factor is used to adjust the number of replicas of the data block to the optimal.

The motivation of this paper to use the Greyâ€“Markov chain model as the basis of the replica creation algorithm is as follows: The proposed replica creation strategy calculates the dynamic replica creation factor by predicting the data block access frequency in the future time period. The number of samples used for data block access frequency prediction cannot be too large, otherwise the workload of the node manager and the complexity of the transaction log will increase, and the availability of the file system will decrease. At the same time, the Data block access frequency changes dynamically over time, and the distribution regularity of these changes is not obvious, which is characterized by a non-stationary random process. The prediction model based on Grey GM (1, 1) does not have strict requirements on the sample distribution regularity, and it only requires less historical data for information prediction [42]. However, the data block access frequency has a certain fluctuation in the time periods, which will make the prediction performance of Grey GM (1, 1) worse. The Markov chain performs data prediction based on the transition probability between states, and it has a good prediction effect for data with large volatility [14]. Combining Markov chain with gray GM (1, 1) can make up for the shortcomings of the poor prediction effect of GM (1, 1) on volatile data, thereby obtaining good prediction results [22]. Based on this, this paper uses the gray Markov chain to accurately predict the data access frequency in the future time period, and uses the prediction result to model the data block heat model to make it more reflect the data replica popularity.

The model construction of the proposed dynamic replica creation strategy is specifically considered as follows:

3.1.1. The model of dynamic replica creation strategy
Assume that the access frequency of the data block x at the beginning of the Tth time period is expressed as 
, the number of access for the ith replica of data block x is expressed as 
. Let the number of replicas of data block x be n, then, the access frequency of data block x can be modeled as (1)

In this paper, the grayGM (l, 1) is used to predict the frequency of access of data blocks in the future time period. Assume that the original data sequence is composed of access frequency values of the data block x of n equal time intervals during the Tth time period. The specific modeling process of the original data sequence is as follows (2)
where, the element 
 indicates the access frequency value of the data block x of the kth time interval at the Tth time period, and 
. The first-order accumulated generating operation (1-AGO) sequence is as follows (3)
where 
. The GM (1, 1) model can be obtained by establishing a first-order differential equation for the 1-AGO sequence. The whitening differential equation of GM(1, 1) is modeled as (4)
 
where a and b are the traditional gray parameters. The estimated value of gray parameters is calculated using the least squares method, which is shown as follows (5)
 
where, (6)
 
 
 
(7)
 
 bringing the estimated value (5) into the whitening differential equation (4) we can get the following results (8)
 
 
(9)
 when k  n, 
 is the predicted value of the access frequency of the data block i in th time period. when k , 
 is an estimate of the original access frequency.

The prediction result of GM(l,1) may be greatly deviated due to the randomness of user access and the sudden change of user access frequency. The Markov chain predicts the state of the system in the future based on the initial state of the system and the state transition probability. This paper uses the Markov model to correct the prediction results of the GM(1,1) model. The relative residual  between the estimated value and actual values is modeled as (10)
 
where 
 indicates the estimated value and 
 indicates the actual value. Let the kth state of the relative residual value be expressed as 
, where 
 and 
 represent the upper and lower bounds of the kth state respectively, and they are modeled as (11)
(12)
 where 
 and 
 are constant. In the process of changing the data block, the state of the residual value is transferred to another state through k steps, i.e., the prediction residual value state transition probability of the data block can be modeled as (13)
 
where 
 indicates the number of times the state i has transferred to the state j through the k step. 
 indicates the number of times the state i appears. Therefore, the state transfer probability matrix can be obtained as follows (14)
 
where m denoted the number of types of states. The median value of the relative residual state interval is used as the correction value of the gray prediction value, and the specific formula is as follows: (15)
 

3.1.2. Calculation of dynamic replica creation value
Let 
 indicate the average access frequency of the data block x at the Tth time period, the 
 is modeled as (16)
 
where 
 denotes the access frequency value of the data block x of the kth time interval at the Tth time period. The heat of data block x in Tth time period is modeled as (17)
where 
 denotes the average access frequency of the data block x at the th time period, 
 is the predictive value of the access frequency of the data block x at the th time period, and 
. Let 
 indicate the access response time of the data block x of the kth time interval at the Tth time period, the average response time of the data block x at the Tth time period can be modeled as (18)
 
since the heat and response time of data blocks change dynamically over time, therefore this paper defines 
 as the dynamic factor for the data block x. Let 
 be the size of the file to which data block x belongs, 
 is the file system fragment data block size. Because the file size and the size of the data block fragments do not change over time, therefore, the static factor can be modeled as (19)
  based on this, the dynamic replica creation factor of data block x can be modeled as follows (20)
(21)
 where  denotes the impact factor for data block heat, and 
, 
 is the time difference from the initial time to the Tth time period. The dynamic replica creation factor 
 is the optimal number of replicas of data block x at the time period T.

3.1.3. Dynamic replica creation algorithm


Download : Download high-res image (678KB)
Download : Download full-size image
Algorithm 1 describes the process of a dynamic replica creation algorithm based on Greyâ€“Markovchain model. In this algorithm, the data series composed of n access frequency value of the data block x, the access response time, average access frequency, the size of the file and data block size are obtained (line 1). The gray prediction model is used to predict the access frequency of data block x at the future time period (line 4). The Markov chain is used to correct the prediction results (line 5). The heat of data block x in Tth time period is calculated (line 6). The average response time of the data block x at the Tth time period is calculated (line 7). The static factor is calculated according to (18) (line 8). The dynamic replica creation factor is calculated (line 9).

The time complexity analysis of Algorithm 1 is as follows: The time complexity on line 4 is O(N  T), The time complexity on line 5 is O(N  T
), The time complexity on line 69 is O(N  T
), where N denotes the number of the data blocks, T denotes the length of the time period. As mentioned above, time complexity of Algorithm 1 is O(N  T
).

3.1.4. Process to manage the data block access during the replica creation
Fig. 1 shows the process of the user accessing the data block during the replica creation process, this figure includes User A, Name node, Resources manager, and DataNode C, where DataNode C stores a replica of data block B that User A wants to access. The process of replica creation happens in Resource Manager, i.e., Resource Manager calculates the optimal number of data block replicas according to the proposed replica creation algorithm. during the process of replica creation, the process of User A access to the data block B is as follows: 1. User A first communicates with the NameNode to request access to data block B. After receiving the request from User A, the NameNode selects the DataNode C that is closest to User A and has a replica of Data block B to provide data access services for User A. 2. The NameNode returns the metadata to user A, where the access address of DataNode C is stored in the metadata. 3. After receiving the metadata, the user A establishes a network connection with the Datanode C based on the relevant information in the metadata. 4. User A downloads the replica of Data block B from DataNode C.

3.1.5. Discussion of the reason for using data block as replica unit
The advantages of using data blocks as replica units are as follows

(1) Dividing file into data blocks to store and read can improve the efficiency of random and concurrent reading of files. Saving several replicas of data blocks to different DataNodes can improve the concurrent reading efficiency of the same data block while achieving data reliability.

(2) Using data block replicas for data backup can provide the file system with better data fault tolerance and data availability [37].

(3) According to the data characteristics of the SaaS storage application and the userâ€™s access tendency, the replica placement algorithm using the file as the replication unit does not meet the actual situation. In most cases, the users are only interested in some data blocks in the files which are proved experimentally in Section 5.1.5. Therefore, if the replica is placed based on the entire file unit, this may reduce the utilization of cluster storage resources and increase the cost of maintaining data replica consistency.

The overheads added by using the data block as a replica unit to the process of replica creation areâ€‹ summarized as follows:

(1) Before the replicas of the data block are created, the Resource Manager needs to calculate the number of replicas of the data block according to the proposed replica creation algorithm, which causes the computing resource overhead of the Resource Manager. The introduction of the Resource Manager is shown in Section 3.2.5.

(2) The creation of replicas requires the migration of replicas between the source node and destination node, which causes in network traffic overhead between DataNodes. The source node is the DataNode where the replica of the created data block is located, and the target node is the DataNode to which the created replica needs will be placed.

(3) After the replicas are created, the related information (Metadata) of the new replicas need to be recorded in the NameNode, which mainly includes the address of the DataNode where the new replicas are located and the mapping relationship between the new replica and the file to which it belongs. Therefore, replica creation using data blocks as a replica unit causes the storage overhead on the NameNode.

However, the proposed replica creation algorithm only creates replicas of data blocks with high heat (high access frequency), and there are only a small number of high heat data blocks in the file, which is proved experimentally in Section 5.1.5. Therefore, using the data block as the replica unit does not cause a large overhead to the process of replica creation. As mentioned above, the advantages of using data blocks as replica units in this paper outweigh its disadvantages.

3.2. Replica placement model
According to the proposed dynamic replica creation strategy, if the number of replicas of the data block needs to be increased, the newly added replicas need to be placed on appropriate DataNodes to ensure the load balancing of the file system. To solve this problem, this section proposes the RPS-FNSG. This strategy comprehensively considers the DataNode performance, the File system cluster storage load and Network distance to establish a multi-objective replica placement problem based on Pareto optimal solution, and uses the fast non-dominated sorting genetic algorithm to solve this problem and obtain the optimal replica placement node.

The motivation of this paper to use the Fast Non-dominated Sorting Genetic algorithm (NSGA-II) as the basis of replica placement is as follows: As a heuristic algorithm, NSGA-II makes a good balance between runtime and solution quality [11]. With the NSGA-II algorithm, the Pareto optimal solution to the multi-object replica placement problem can be obtained. In addition, some works [5], [9], [15], [43] use a linear weighting method to build the objective function, i.e., multiple sub-objective functions are combined into one main objective function by introducing weight coefficients. However, the optimization effect of the linear weighting method depends largely on the setting of the weight coefficient, which depends too much on the experience of experts. Therefore, the linear weighting method cannot meet the requirements of multi-objective optimization in actual conditions. Based on this, this paper uses the NSGA-II to solve the replica placement problem based on multi-objective optimization. NSGA-II can obtain the Pareto optimal solution of a multi-objective optimization problem without introducing the weight coefficients, this meets the multi-objective optimization needs in practical situations. This meets the requirement of multi-objective optimization in practical situations.

3.2.1. Load balancing related sub-objective function
â‘  DataNode load performance

In this paper, the performance indicators of the DataNodes mainly consider the CPU processing capacity, disk read/write performance, memory load capacity, and disk load capacity. The CPU processing capacity of DataNode j is modeled as (22)
where 
 indicates the main frequency of CPU of the DataNode j, 
 denotes the number of CPU cores, 
 denotes the usage of CPU. The higher the CPU usage, the higher the CPU load. When the edge cloud file system performs data processing operations, the read/write performance of the disk has a direct impact on the execution time of the task. Therefore, the read/write performance of the disk is an important indicator of the replica placement strategy, which is modeled as follows (23)
where 
 indicates the read speed of the disk, i.e. the maximum number of bytes that the hard disk can read per second. 
 indicates the write speed of the disk,  (0, 1) indicates the weight parameter. The load capacity of the memory is modeled as (24)
where 
 indicates the size of the memory, 
 indicate the memory usage. The higher the memory usage of the DataNode, the higher the memory load of the DataNode. We then can obtain the load capacity of disk space by (25)
where 
 indicates the size of the disk, 
 indicates the used capacity of the disk. Considering CPU processing capacity, read and write speed of the disk, load capacity of the memory and load capacity of disk space, the node sub-objective function of DataNode j can be modeled as (26)

â‘¡ File system cluster storage load

Let 
 denote the total size of storage space for DataNode j. Assume that the size of each data block is equal, the usage of storage space of DataNode j can be modeled as follows (27)
 
where 
 denotes the number of data blocks stored in DataNode j, 
 denotes the uniform size of the data block in the file system. The average storage usage of the file system cluster is modeled as (28)
 
 
where 
 indicates the number of new added replica of all data block, 
 indicates the number of DataNodes. 
 denotes the number of data block i that already exists in the cluster. The sub-objective function of File system cluster storage load is modeled as (29)
 
 

â‘¢ Network distance

In this paper, the network distance in the edge cloud system is described as a tree topology, with leaf nodes as DataNodes, and internal nodes as network devices such as routers and switches. In the network topology, the distance between the child node and the parent node is 1, and the distance between any two DataNodes is the sum of their distance to the nearest common ancestor.

Assuming the network distance between the source node and the target node j is 
, and the maximum network distance in the network is 
, then the network distance coefficient between the source node and the destination node can be modeled as (30)
 
The network distance coefficient is proportional to the actual network distance between the DataNodes. Because the smaller the network distance between DataNodes, the greater the bandwidth, the higher the data transmission efficiency, and the shorter the time required to place the replica. Therefore, the network distance sub-objective function between DataNodes is defined as (31)
where 
 denotes the size of the data block, 
 denotes transmission cost per bit of data per unit time.

3.2.2. Multi-objective optimized replica placement problem based on pareto optimal solution
Taking into account DataNode performance, File system cluster storage load and Network distance, the multi-objective optimization problem of the replica placement problem can be modeled as (32) 
 where, 
, 
 and 
 are the sub-objective functions corresponding to (25), (28), (30) respectively.  is a multi-objective function for replica placement, an integration function that takes into account several sub-objective functions,  Represents the set of solutions that satisfy the constraints,  denotes a feasible solution that satisfies the constraints.

Generally, the global optimal solution cannot be obtained when solving the multi-objective optimization problem, but only a set of compromise solutions, which is the Pareto optimal solution [11]. NSGA-II is an improved multi-objective optimization algorithm based on NSGA [34]. The Pareto optimal solution obtained by NSGA-II has a uniform distribution, good convergence and robustness. Based on this, this paper uses NSGA-II to solve the multi-object replica placement problem.

3.2.3. Solution of replica placement problem based on fast non-dominated genetic algorithm
â‘  Chromosome coding and fitness function

The binary encoding method is suitable for the establishment of the data block placement model in this paper. Therefore, the chromosome coding is performed by binary coding. The coding scheme is shown in Fig. 2, where the chromosome coding length is expressed as the number of the DataNodes, a gene position in the chromosome is expressed as a DataNode. The gene value is a bool variable, can take a value of 1 or 0, which means that a replica of a data block is stored in the DataNode or the replica is not stored in the DataNode. The population represents the search space of the algorithm, which consists of a series of chromosomes.


Download : Download high-res image (193KB)
Download : Download full-size image
Fig. 2. Chromosome coding scheme.

According to the above-mentioned chromosome coding method, an initial population P composed of M binary coding chromosomes is generated. The fitness function will have a direct impact on the convergence of the algorithm and the optimization result of the solution. This article uses the objective function as the fitness function.

â‘¡ Fast non-dominant sort

The fast non-dominated ranking is based on stratifying the population according to the individualâ€™s non-inferior solution level. The fast non-dominated sorting need to calculate two parameters 
 and 
 for each individual i in the population P, where 
 is the number of individuals dominating individual i in the population and 
 is the set of individuals dominated by individual i in the population, F indicates non-dominated layer. The specific steps for stratifying populations with fast non-dominated sorting are as follows: (1) For each individual i  P and j  P, if i dominates j, then 
 j, else 
; if 
, then 
 i; (2) let , when 
, for each i 
, j 
, let 
, if 
, then  j; (3) Let set 
 be the first non-dominated set, and each individual in 
 is labeled with the same non-dominated sequence 
. (4) Perform the above three steps on the individuals in the set H until all the individuals are stratified.

â‘¢ Calculation of Crowding distance

Crowding distance represents how dense a certain solution is with other surrounding solutions. For each objective function of all individuals, the objective function values are sorted from small to large, and then the average side length of the cube composed of 
 and 
 is calculated for the individual 
, and the final result is the crowded distance of the solution 
. The calculation steps of the crowding distance are as follows: first let 
 = 0, i = 1, 2 , â€¦, N. Then for each objective function, setting the crowding distance of the boundary point to infinity, 
. The crowding distance of the ith individual is as follows: (33)
 
 
where, , , and  are consecutive Pareto front points, respectively, 
 and 
 represent the maximum and minimum values of the mth sub-objective function, respectively. For the population of each iteration, the individual with the smallest crowding distance is selected as the solution closest to the optimal target value.

â‘£ Selection, Crossover and Mutation

This paper selects the objective function as the fitness function and chooses the roulette selection method as the method of the selection operation. Suppose the population size is M, the fitness value of individual i is 
. The probability that individual i is selected in the selection operation is (34)
 

The optimal retention method and the roulette selection method are used to select, and the individual with the highest fitness value is retained by the optimal retention method, and then the roulette selection method is used to select the individuals. The new data block replica involves two parts in the cross-process: The number of DataNodes and whether the data replica is stored on a DataNode. This paper uses the uniform crossover for the placement of data replicas, and the single-point crossover is used to add a new replica of a data block on a DataNode.

This paper uses the uniform mutation and sets the mutation parameter as MP. The process of uniform mutation is as follows: (1) The odd digits in the chromosome code are designated as mutation points in turn, the random mutation occurs at the mutation point with PM as a probability. The length of the chromosome code does not exceed the number of DataNodes. (2) For the new added data replicas, the gene value range of which does not exceed the number of DataNodes.

â‘¤ The process of NSGA-II solving multi-objective replica placement problem

As mentioned above, the process of NSGA-II solving the multi-objective replica placement problem is as follows: Initialize the population 
, and then perform fast non-dominated sorting, selection, crossover, and mutation operations on the population to obtain the new offspring population 
. Let , merge parent population 
 and offspring population 
 into a new population R
. Perform fast non-dominated sorting on R
 to get Pareto front 
, 
, â€¦. For all Pareto front, individuals are selected according to the crowding distance to form the new population 
. The genetic algorithm operation is performed on the population 
 to obtain a new population 
. The above operation is repeated until the algorithm stop condition is satisfied, and the Pareto optimal solution is obtained.

3.2.4. Replica placement algorithm


Download : Download high-res image (844KB)
Download : Download full-size image
Algorithm 2 describes the process of replica placement algorithm based on the Fast Non-Dominated Sorting Genetic Algorithm. In this algorithm, the number of replicas of data block x, the optimal number of replicas of data block x calculated by Algorithm 1 are obtained (line 1). The dynamic replica creation value v, if v  0 then the  replicas from DataNodes are removed, else the replica placement operation is performed (line 36). If v  0 then the sub-objective functions 
, 
, 
. are constructed (line 7). The crossover operator, mutation operator, selection operator, population size M and termination condition T are configured (line 8). Population  with size M is generated and the fast non-dominated sort is performed on 
 (line 910). Selection, crossover, and mutation operations are performed on 
, and then obtain a new population 
 (line 11). Let  and the iteration loop is entered. The parent population 
 and offspring population 
 are merged into a new population 
. (line 1213). The fast non-dominated sort is performed on 
 and the crowding distance of individuals in 
 are calculated (line 1415). while the size of 
 M, the individual i is selected from 
 according to the crowding distance to add to the new population 
(line 1618). Let population 
 be the new parent population 
, and . If t  T, the iteration loop ends (line 1921). For each 
, the individual with minimum crowding distance is selected as the solution for the multi-objective optimization problem, and The data replicas are placed according to the optimal solution of the multi-objective optimization problem (line 2325). Algorithm 2 ends and returns the optimal replica placement scheme (2627).

The time complexity analysis of Algorithm 2 is as follows: The time complexity on line 36 is O(1). The time complexity on line 721 is O(s  M
), where s denotes the number of sub-objective functions and M denotes the size of the population. The time complexity on line 2225 is O(N M), where N denotes the number of the data blocks. As mentioned above, the time complexity of Algorithm 2 is O(N  M
).

3.2.5. Process to manage the data block access during the replica placement
Fig. 3 shows the process of the user accessing the data block during the replica placement process, this figure includes User A, NameNode, Resources manager, and DataNodes C and D, where DataNode C stores a replica of data block B that User A wants to access. At this time, the process of replica placement in the scene is in progress, i.e., the Resources manager selects node C as the target placement node for the replica of data block E according to the proposed replica placement algorithm, then let Datanode D transmit a replica of data block E to Datanode C. During this process, the process of User A access to the data block B is the same as the steps of data access process in replica creation in Section 3.1.4.

3.3. Replica synchronization strategy based on replica delayed update
In the HDFS file system, when a client writes new data, the written data can be accessed only after all replicas of the written data are synchronized. [7]. Although the default HDFS replica synchronization strategy has the advantages of strong consistency, user-friendliness, and good read performance, but it has the disadvantages of high data write latency and low write throughput. Especially in the edge cloud environment, because DataNodes may be located in different geographical locations, the default HDFS replica synchronization strategy may be affected by the Replica synchronization delay caused by insufficient bandwidth and network congestion. This will eventually make data replicas fail to synchronize in real time, resulting in higher write latency and low write throughput.

Based on this, this paper proposes a Delay-Adaptive Replica Synchronization strategy (DA-RS). The modeling process for this strategy is shown as follows.

3.3.1. Selective data replica synchronization
Assume that the number of redundant replicas of the data block is N. When the client writes a data block, the W replicas are synchronized before the write result is returned to the client. W is calculated as follows (35) (34) ensures that the client only receives the data write result after most of the replicas are successfully synchronized, so as to ensure the reliability of data access.

This strategy selects W DataNodes that hold a replica of the data block to be synchronized to form a data transmission channel for replica synchronization, these DataNodes have a closer network distance to the client. The distance between the client and the DataNode uses the default node distance calculation method in HDFS, i.e., the sum of the distances between the two nodes to the nearest common ancestor node. Then sort the W DataNodes according to the distance from small to large, and form a transmission channel from the client to the DataNode to synchronize the replicas of the written data.

3.3.2. Replica status table
According to the above steps, after W replicas are synchronized, there are  replicas that are not synchronized. For these unsynchronized replicas, this paper uses a data structure called Replica Status Table (RST) to record the synchronization status of the data block replicas to facilitate subsequent synchronization of these replicas. Each replica of the data block maintains an RST, and each RST has two entries, which are RST. Location and RST.Old respectively. Among them, Location indicates the DataNode that store replica of the data block, Old indicates whether the replica has not been updated, Old  1 indicates that the replica has not been synchronized, and Old  0 indicates that the replica has been synchronized. Fig. 4 shows the RST of a replica of data block A stored in DataNode1. It can be seen from this table, data block A has three replicas, and which are stored in DataNode1, DataNode2, and DataNode3 respectively. The replica stored in DataNode3 has not been synchronized. The replicas stored in DataNode1 and DataNode2 have been synchronized.


Download : Download high-res image (130KB)
Download : Download full-size image
Fig. 4. RST of a replica of block A in DataNode3.

Fig. 5 shows the RST update process during a client write operation. As shown in the figure, when the client initiates a request for writing data block A to the NameNode, the NameNode allocates the new replicas of the data block, and decides DataNode1, DataNode2 and DataNode3 can be used to store the replicas. According to formula (34), the NameNode can be obtained that when , , so two of the three replicas and their RST need to be selected for update, and the other replica only needs to update the RST. The NameNode calculates the network distance between the client and the three DataNodes and finds that the client is closest to node 1, the farthest from DataNode 2 and DataNode 3, and the distance between the client and DataNode 2 and DataNode 3 is the same. Then the NameNode returns the above information to the client. After the NameNode returns the above information to the client, the client first writes a replica on DataNode1 and updates the RST, then DataNode1 writes a replica to DataNode2 and updates the RST, and DataNode1 updates the RST to DataNode3. Finally, DataNode3 returns a data write success message to the client. All of the above operations are considered as a transaction.


Download : Download high-res image (618KB)
Download : Download full-size image
Fig. 5. Updating process of the RST when the client writing data.

3.3.3. Delay-adaptive synchronization
For those unsynchronized replicas, i.e., the Old of RST of these replicas is 1, Their synchronization update will be postponed to subsequent periods, and the synchronous updates of these replicas will be triggered in the following two cases: (1) The data block that has not been synchronized becomes the hot data. (2) The load performance of the DataNode where the replica has not been synchronized is strong.

For the first case, take the replica a of data block A as an example. According to the judgment of DA-RS, the replica a is not synchronized after the client writes data block A, but only the Old of RST of the replica a is set to 0. DA-RS calculates the access frequency 
 of data block A at the Tth time period according to (16). Assuming that N data blocks are stored in the edge cloud file system, the average access frequency of all data blocks in the file system at the Tth time period can be modeled as (36)
 
If the access frequency of data block A at the Tth time period is greater than the average access frequency of all data blocks, i.e., 
, then data block A is defined as the hot data, its replica a will be synchronized, and the Old of RST of replica a is set to 0.

For the second case, take DataNode i as an example, this DataNode stores the replica of data that is not synchronized. Calculate the load capacity 
 of the DataNode i at the Tth time period according to (25). Assuming that the total number of DataNodes is J, then the average load capacity of all DataNodes at the Tth time period can be modeled as (37)
 
If 
, then the load capacity of DataNode i is determined to be strong, and then the unsynchronized replicas on this DataNode will be synchronized, and set the Old of RST of these replicas to 0.

The proposed algorithm achieves eventual consistency from the client perspective. Selective replica synchronization reduces the latency of write operations. Delayed synchronous update of replicas ensures the reliability of data, and adaptive synchronous update of replicas can get better Read/write throughput.

3.3.4. Replica synchronization algorithm based on replica delayed update
Algorithm 3 describes the process of the replica synchronization algorithm based on delayed updates. In this algorithm, the number N of replicas of data blocks written is obtained (line 1). while a client sends a write request for data block k to NameNode, the number W of synchronized replicas is counted (line 4). W DataNodes are selected according to the network distance to synchronize the replicas of data block k and set these replicasâ€™ RST.Old to 0 (line 512).  DataNodes are selected to set the RST.Old of replicas of data block k to 1 without synchronizing these replicas (line 1218). The average access frequency of all data blocks and the average load capacity of all DataNodes are calculated (line 1920). When the DataNode load capacity is high or the replica becomes hot data, the unsynchronized data replicas in  DataNodes are synchronized (line 2124). The algorithm ends and returns the message of replica synchronization success.

The time complexity analysis of Algorithm 3 is as follows: The time complexity on line 515 is O(W  N), the time complexity on line 1626 is O(()  N), The time complexity on line 2933 is O(), where W denotes the number of synchronized replicas, N denotes the number of replicas. As mentioned above, the time complexity of Algorithm 1 is O(N  T
).


Download : Download high-res image (720KB)
Download : Download full-size image
3.4. Replica recovery strategy based on load-balancing
In the edge cloud f, due to the heterogeneity and low cost of the nodes and the unreliability of the network, the DataNode failure in the cluster may occur. When the DataNode is failure, the data stored on it will be lost. The data is distributed in the edge cloud file system in the form of multiple replicas, this allows other DataNodes to continue to provide data access to the data on the failed DataNodes. However, the failure of DataNodes will lead to an increase in the access of other non-failed DataNodes, which will increase their load, and eventually cause the load imbalance of the entire file system cluster. In order to ensure the load balance of the edge cloud file system, the data replicas on the failed DataNode should be restored to the non-failed DataNode with a strong load capacity in the cluster. Based on this, this article proposes a Load-Balancing based Replica Recovery strategy (LB-RR) to solve the above problem.

3.4.1. Failure datanode detection
This paper uses HDFS as the edge cloud file system. in HDFS, the DataNodes periodically generates heartbeat packets according to its node status and storage status, and sends the heartbeat packets to the NameNode at a certain interval, so that let NameNode know its running state. If the DataNode fails, it cannot generate the heartbeat packet and send it to the NameNode. If the NameNode does not receive the heartbeat packet from the DataNode within a certain period of time, then the NameNode will determine the failure of the DataNode and then start the data recovery strategy.

3.4.2. Selection of data blocks to be recovered
Assume data block x is a data block stored on a failed DataNode. Let 
 denote the access probability of data block x at the Tth time period, then 
 can be molded as follows (38)
 
where 
 denotes the number of the access of data block x at the Tth time period; 
 denotes the total number of accesses for all data blocks at the Tth time period.

Considering the block size, block replica location time, and bandwidth, the block recovery costs of data block x can be modeled as follows: (39)
 
where 
 indicates the size of the data block x, and 
 indicates the time required for the HDFS system to locate other replicas of the data block x. 
 represents the maximum available network bandwidth between the target node and other DataNode that store the replica of the data block x. Considering the data block recovery benefit and the data block recovery cost, the replica selection factor for the data block x is modeled as follows (40)
 
Suppose there are N data replicas on the failed DataNode. The average value of replica selection factor for all data block in the failed DataNode can be modeled as (41)
 
If 
, then the data block x is selected as the data block that needs to be recovered.

In this way, on the one hand, the data blocks with higher block recovery benefits and block recovery costs can be quickly recovered, so that HDFS system performance can be rapidly improved. On the other hand, restoring only a part of the data replicas allows the storage burden on the target node to be reduced.

3.4.3. Selection of the target node
In HDFS systems, load balancing between nodes is affected by many factors, such as the Disk space of the DataNode, CPU capacity, and cache capacity. This paper comprehensively considered the above factors when selecting the target DataNode for replica recovery.

The greater the remaining amount of node disk space, the stronger the node disk space load capacity. The disk space availability of DataNode can be expressed as (42)
where 
 denotes the using rate for the disk of node. The CPU load capacity of the DataNode can be modeled as follows (43)
where 
 denotes the frequency of the CUP of the DataNode, 
 indicates the number of cores of the CPU, 
 indicates the remaining usage rate of the CPU. 
 indicates the bus speed of the CPU. For data blocks that are frequently accessed, the DataNodes can put these data into memory, which can significantly increase the speed of data access. Therefore, the cache capacity of the node also has a significant impact on load balancing, which can be modeled as follows (44)
 
where 
 denotes cache remaining capacity, 
 denotes the time required to access data,

Considering the load capacity indicators of the DataNode mentioned above, the comprehensive load capacity of the DataNode can be defined as (45)
where the 
, 
 and 
 are the weight coefficients for disk space availability, CPU load capacity, cache capacity, and they satisfy 
.

When selecting the target node, LB-RR first calculates the CP of all DataNodes that do not store a replica of the data block to be recovered according to (45). Then the DataNode with the highest CP value is selected as the target node for data replica recovery.

3.4.4. Replica recovery algorithm based on load-balancing


Download : Download high-res image (445KB)
Download : Download full-size image
Algorithm 4 describes the process of Load-Balancing based Replica Recovery algorithm. In this algorithm, List tb of data blocks in the failed DataNode x is obtained (line 1). For each data block x  tb, the replica selection factor 
 for the data block x is calculated (line 35). The average value  of replica selection factor for all data block is calculated (line 6). The data blocks to be recovered from the failed DataNode x are selected into the set 
 (line 711). The load capacity  of DataNode k is calculated, where the replica of data block x is not stored in DataNode k (line 1214). The DataNode k* with the smallest load capacity  is selected from the cluster (line 15). The data blocks in set 
 is restored to DataNode k* (line 16). The algorithm 4 ends and returns the message of data recovery success (line 17).

The time complexity analysis of Algorithm 4 is as follows: The time complexity on line 36 is O(n), where n denotes the number of data blocks in failed DataNode. the time complexity on line 711 is O(n). The time complexity on line 1214 is O(m), where m denotes the number of DataNodes, these DataNodes without store the replica to be recovered. the time complexity on line 15 is O(m
). As mentioned above, time complexity of Algorithm 4 is O(m
).

4. Application scenarios: Car navigation system for edge cloud architecture
Computing platform based on edge cloud can provide powerful and real-time computing and storage resources for car navigation system [30]. In the process of car driving, the car navigation system can obtain traffic data from the edge cloud computing platform to plan the optimal car driving path in time to improve the driving efficiency of the car and reduce traffic pressure [16]. The architecture of the computing platform based on the edge cloud is divided into three layers, as shown in Fig. 6, which includes the core cloud layer, the edge cloud layer and the car user layer. The car user layer mainly includes the car equipped with smart mobile devices. The edge cloud layer is composed of roadside access points and edge servers deployed on the side of the network near the car user layer. The core cloud layer is composed of the large cloud computing center and the nodes monitor. The node management and status monitoring of the edge cloud layer are mainly implemented by the core cloud layer. The traffic data generated by the car user layer can be uploaded to edge servers via roadside access points. The traffic data that needs to be processed in a car navigation system is usually related to specific car navigation tasks, such as driving route planning, traffic accident warning and road condition analysis. This paper uses driving route planning as an example to discuss the application of the proposed algorithms in the car navigation system based on the edge cloud platform.

Dynamic replica creation strategy: as shown in Fig. 6, after receiving the userâ€™s request, the node monitor in central cloud collects and records the userâ€™s related data access information and checks the performance of the edge server, then select and start the edge server that needs to perform the route planning task, and perform the replica creation process. According to the information of the user data access, i.e., the data access frequency during the current time period, computing server in the central cloud uses the gray Markov model to predict the data access frequency in the future time period. Because data access frequency and data access response time change over time, they are called dynamic factors, and they are considered for the calculation of the dynamic replica creation factor. In addition, the factors such as the size of the data block and the size of the file to which the data block belongs are also considered in the calculation of the replica creation factor. These factors are not time-varying after the data block or file is created, so they are called static factor. The computing server considers the dynamic and static factors to calculate the optimal number of data block replicas. According to this value, the computing server can increase or decrease the number of data block replicas accordingly to meet the userâ€™s access requirements for these data.


Download : Download high-res image (554KB)
Download : Download full-size image
Fig. 6. The car navigation system in edge cloud architecture.

Replica placement strategy: The central cloud calculates the dynamic replica creation value according to the optimal replica number calculated by the dynamic replica creation strategy and the number of replicas currently existing in the DataNode. If the dynamic replica creation value is positive, it means that the number of replicas of the data block needs to be increased. Then, the manager server in the edge cloud formulates a corresponding replica placement sub-objective function based on the transmission cost, the relative load of the nodes, and the performance of the nodes. The fast non-dominated sorting genetic algorithm is used to solve these sub-objective functions, and finally the best placement nodes of the replicas are derived, then the replicas of the data blocks are placed on these nodes according to the data block dynamic creation values. If the dynamic replica creation value is negative, it means that the user access demand of the data block is reduced, and the number of data block replicas needs to be reduced to reduce the burden on the storage resources of the DataNode. At this time, the manager server deletes the data block replicas from the DataNodes, and the DataNode with the highest load is preferentially selected to delete the data block replica until the optimal number of data block replica is satisfied. When a user performs route planning through the car navigation system, the car navigation system can quickly obtain the required data from the nearby edge servers where the replicas of the data are placed and then perform real-time route planning.

5. Performance evaluation
5.1. Experimental environment
5.1.1. Experimental setup
The performance test of the algorithm proposed in this paper is mainly run in the Linux environment, the operating system uses Ubuntu 14.04LTS, and the file system uses HDFS. The hardware environment of the experimental platform includes an edge cloud composed of 19 hosts and a central cloud composed of 2 high-performance hosts. The central cloud and the edge cloud are connected through a VPN network. Among them, the edge cloud includes two racks, each rack deploys 8 DataNodes. The network topology of the edge cloud architecture is described as follows: the nodes in the cluster exchange information through the TCP/IP protocol and the Ethernet bandwidth shared by each DataNode node is 100M. Based on the above network topology, this paper uses 21 heterogeneous server nodes to set up a test environment to obtain better experimental results. The node hardware parameters used in this paper are shown in Table 3, Table 4:


Table 3. Hardware parameters of the edge cloud environment.

Rack	Node	CPU	Memory size (GB)	Hard disk size (GB)
â€“	NameNode	Intel Core i5	8	500
R1	DataNode1	Intel Core i5	4	500
DataNode2	Celeron E1500	4	500
DataNode3	Celeron E1500	4	500
DataNode4	Pentinum E5300	3	1000
DataNode5	Pentinum E5300	3	1000
DataNode6	Intel Core i3	1.5	300
R2	DataNode1	Intel Core i3	1.5	300
DataNode2	Intel Core i5	4	1000
DataNode3	Intel Core i5	4	1000
DataNode4	Intel Core i5	8	500
DataNode5	Intel Core i5	4	500
DataNode6	Celeron E1500	4	500
R3	DataNode1	Celeron E1500	4	500
DataNode2	Pentinum E5300	3	1000
DataNode3	Pentinum E5300	3	1000
DataNode4	Intel Core i3	1.5	300
DataNode5	Intel Core i3	1.5	300
DataNode6	Intel Core i5	4	1000

Table 4. Hardware parameters of the central cloud.

Node	CPU	Memory size (GB)	Hard disk size (GB)
Node1	Intel Xeon E5-2695 v2	16	1000
Node2	Intel Xeon E5-2680 v2	8	500
5.1.2. Performance testing framework
This paper uses the Apache JMeter to evaluate the proposed replica creation algorithm. The Apache JMeter is an application designed to load test functional behavior and measure performance [19]. Apache JMeter can be used to test performance both on static and dynamic resources (files, Servlets, Perl scripts, Java Objects, Data Bases and Queries, FTP Servers and more). It can be used to simulate a heavy load on a server, network or object to test its strength or to analyze overall performance under different load types. It can be used to make a graphical analysis of performance or to test the server/script/object behavior under heavy concurrent load. In this paper, Apache JMeter is used to simulate the data access situation in the edge cloud system. The access frequency of data blocks is calculated according to these data access situations. The access frequency of the data block is used to calculate the data heat in the proposed replica creation algorithm.

As a public benchmark for load testing in cloud computing and edge computing environment, Apache JMeter is suitable for evaluating the performance of the proposed algorithm, the reason is as follows:

Many related works [3541] have used Apache JMeter as a benchmark to test the performance of their algorithms, where [28], [40] is the related works in the cloud computing environment, [3841] is the related works in the edge cloud environment. The author of [28] uses Apache JMeter to evaluate the response time and throughput performance of serverless frameworks in edge computing environments by configuring the Apache JMeter to perform 10 requests with various levels of concurrency. The author of [25] uses the Apache JMeter to simulates a large amount of user access to the system in the edge computing environment. In [40], the Apache JMeter is used to evaluate packet throughput in the cloud network environment by generating and sending legitimate HTTP packets to the target node. The authors of [27] use Apache JMeter to simulate user requests for data in the cloud computing environment. The author of [10] evaluates system throughput in a cloud computing environment by using Apache JMeter to simulate user requests for services. The author of [4] used Apache JMeter to simulate user requests to perform performance testing on the proposed public cloud based recommendation algorithm. The authors of [33] propose a novel Software-defined storage framework in the cloud environment, and uses Apache JMeter to test the automated prefetching performance of the proposed framework by simulating the HTTP requests and generating the workload. As mentioned above, Apache JMeter, as a public benchmark widely used in cloud computing and edge computing environments, is suitable for evaluating the performance of the proposed in this paper.

5.1.3. Performance metrics
In this paper, the system response time is used to evaluate the performance of the proposed dynamic replica creation algorithm. The system response time (SRT) and Storage Space Utilization (SSU) is modeled as (46)
 
where, 
 indicates the time when the job was submitted, and 
 indicates the time when the job was completed,  indicates the number of jobs. The SSU is modeled as (47)
 
where  indicates the number of DataNodes, 
 represents the total storage capacity of the DataNode i, 
 indicates used storage space of DataNode i.

The number of replicas, average read throughput (ART) and Update Cost (UC) are used to evaluate the performance of the proposed replica placement algorithm. The ART is modeled as (48)
 
 
where 
 indicates the size of data block i, 
 indicates the number of times the data block was read. 
 indicates the total time for reading data block i. The UC is expressed as the network distance from the source node to the destination node. The source node is the DataNode where the replica of the created data block is located, and the target node is the DataNode to which the created replica needs will be placed. the network distance in the edge cloud system is described as a tree topology, with leaf nodes as DataNodes, and internal nodes as network devices such as routers and switches. In this network topology, the distance between the child node and the parent node is 1, and the network distance between any two DataNodes is the sum of their distance to the nearest common ancestor.

The read response time (RRT), ART, SSU and SRT are used to evaluate the performance of the proposed replica reconstruction strategy. The RRT is modeled as (49)
 
where 
 indicates the time required by the client to read data block i, i.e., the time interval from the client request to read data block i until the client has read data block i. The  indicates the total number of data blocks.

The Time for Data writing (TDW) and ART are used to evaluate the performance of the proposed replica synchronization strategy. The TDW is modeled as (50)
 
where 
 indicates the time required to write data block i.

5.1.4. Benchmark algorithms
In this paper, WDRM [15] and NDRS [20] are used as benchmark algorithms to evaluate the proposed dynamic replica adjustment algorithm. ARDS [44] and GAPS [24] are used as benchmark algorithms to evaluate the proposed replica placement algorithm. The proposed replica synchronization strategy is compared with two benchmark algorithms which are the HDFS default replica synchronization strategy and the ERS [38]. The HDFS default replica recovery strategy and PRS [23] as the benchmark algorithms for evaluating the proposed replica recovery strategy. The benchmarks used in this paper are shown as follows:

A Weighted Dynamic Replication Management (WDRM): This strategy comprehensively considers the popularity of data, the current replication factor, and the number of active nodes in the system to dynamically calculate the optimal replication factor, and according to the data factor replication factor to create or increase the number of data replicas to dynamically adjust the number of replicas.

A Novel Dynamic data Replication Strategy (NDRS): This strategy improves the access efficiency of cloud storage while remaining the QOS attributes of the cloud. This strategy takes into account the number of file accesses and replica locations to dynamically create data replicas.

A novel data replica placement mechanism with the adjustable replica deployment strategy (ARDS): this mechanism initializes the number of replicas. The number of replicas will then be adjusted based on how often the replicas are accessed. The replica placement mechanism is based on the remaining storage capacity of the node, and tends to place the replica on the node with higher current capacity.

A Group Based Genetic Algorithm Data Replica Placement Strategy (GAPS): This strategy considers the size of the data set and the network bandwidth between the data centers to place the replica of the data to the correct data center, which can reduce the cost of data transmission.

The default replica recovery strategy in HDFS: the replicas of the data on the failed DataNode is restored to the random target nodes.

A Proactive Re-replication Strategy (PRS): This strategy comprehensively considers the CPU utilization of the target node, the disk usage, and the popularity of the replica to recover the data replicas of the failed DataNode to the target node.

The default replica synchronization strategy in HDFS: When the client writes data, all replicas of the written data are synchronized before the data write result is returned to the client.

An Enhancing Replica Synchronization strategy (ERS): Whenever the client puts a write request, the one replica of the data block will be updated first and then the remaining replica immediately gets the update.

5.1.5. Data block access frequency difference experiment
In order to prove that the access frequency of different data blocks in a large files is different, this paper analyzes the Sandia Lab file storage system [31]. Among them, 16,566 access to a data files by users within 4 h are recorded, and the proportion of access frequency of data blocks in this file is also recorded. The proportion of the access frequency of different data blocks in a large file is shown in Fig. 7. It can be seen from the figure that 43% of the data blocks are accessed less than 30 times, while only 4% of the data blocks are accessed more than 400 times. Experimental results show that most data blocks in the file are accessed infrequently, and a small number of data blocks are accessed in large numbers. Therefore, the proposed replica creation algorithm uses data block as the replica unit to create replicas only for the data blocks with high heat, which does not cause large overhead.


Download : Download high-res image (185KB)
Download : Download full-size image
Fig. 7. The access frequency of different data blocks in the large file.

5.2. Result and analysis
5.2.1. Performance comparison between RDA-GM and the existing replica creation algorithms
Fig. 8 shows the evaluation of SRT performance under changes in the number of data block accesses. It can be seen from the figure that the SRT of the three algorithms increases with the number of data block accesses. The main reason is that as the frequency of users accessing data blocks increases, the occupancy of the computing resource and storage of edge cloud clusters also increases, this leads to increased time required to complete the jobs. When the access frequency is low (2030 times of data access per minute), the proposed algorithm is not better than the benchmarks in terms of SRT performance. With the increase of access frequency, the proposed algorithm creates replicas for data blocks with high heat, and these replicas provide users with better data services, which improves the performance of SRT and makes the SRT performance of the proposed algorithm is gradually better than the benchmarks. In addition, it can be seen from the figure that the proposed algorithm is better than WDRM and NDRS by about 10% and 6% in terms of SRT performance.

Fig. 9 shows the SSU performance evaluation of the three algorithms under the change of the number of submitted jobs. It can be seen from the figure that the SSU of the three algorithms increases as the number of submitted jobs increases. In addition, the proposed algorithm is about 7% and 4% higher than ARDS and GAPS respectively in terms of SSU. The reason is that the proposed dynamic replica creation algorithm can satisfy data access under the premise of creating fewer data replicas, which increases the remaining space capacity of the DataNodes.

5.2.2. Performance comparison between RPS-FNSG and the existing replica placement algorithms
Fig. 10(a) shows the distribution of data blocks in remote racks under the HDFS default replica placement strategy. It can be seen from the figure that the replicas of data blocks are randomly placed, and the number of replicas in the DataNodes in each rack is different. This means that HDFS default replica placement strategy does not consider the performance of DataNodes and its load balancing, which greatly affects the load balancing of the file system. Fig. 10(b) shows the distribution of the data blocks in the remote rack under the proposed replica placement strategy. It can be seen from the figure that the number of data replicas distributed in rack 1 is obviously more than that in rack 2 and rack 3. This is mainly because the proposed algorithm fully considers the data transmission network distance and the load balancing. Under the condition that the load of the cluster is unchanged, the replicas are placed on rack 1 with a strong load capacity of the DataNode, which can improve the overall performance of the HDFS system and ensure system load balancing. It can be seen that the load balance of the proposed replica placement strategy on the remote rack is significantly better than the default replica placement algorithm of HDFS, which makes the proposed replica placement strategy make full use of the computing and storage resources.

In Fig. 11 (a)(d) is shown how the different access frequency of data block (times of data block access per minute) affects the ART performance by setting the data block size from 16 MB to 128 MB. It can be seen from the figure that the ART of the three algorithms increases with the increase of the data block access frequency. The reason is that the increase of the access frequency of data block increases the probability that users successfully access the data block, which will increase the ART. As the size of the data block increases, the ART of three algorithms decreases. This is mainly because the storage capacity of DataNodes is limited. The larger the size of the data block, the fewer replicas can be placed on the DataNode by the replica placement algorithm. This reduces the quality of data services, and thus reduces the ART. At the same time, the ART of the three algorithms decreases as the size of the data block increases. This is mainly because the storage capacity of DataNodes is limited. The larger the size of the data block, the fewer replicas can be placed on the DataNodes by the replica placement algorithms, this reduces the quality of data services, and thus reduces the ART. In addition, it can be seen from the figure that the proposed algorithm is about 10% and 14% higher than ARDS and GAPS on average in terms of ART, respectively. The reason is mainly because that the proposed algorithm can place replicas on the more suitable DataNodes to meet the requirement of data access of users.


Download : Download high-res image (339KB)
Download : Download full-size image
Fig. 10. Distribution of block replicas in the remote racks.


Download : Download high-res image (766KB)
Download : Download full-size image
Fig. 11. Performance evaluation of ART for replica placement algorithm.

Fig. 12 shows the UC performance evaluation of three replica placement algorithms. The UC is expressed as the network distance from the source node to the destination node, the source node is the DataNode where the replica of the created data block is located, and the target node is the DataNode to which the created replica needs will be placed. In this experiment, this paper expands the number of DataNodes to 100, and observes the change in UC in the case of the number of DataNodes changing from 10 to 100 to evaluate the scalability of the proposed replica placement algorithm. It can be seen from the figure that the UC of the three algorithms increases with the number of DataNodes. The main reason is that as the number of DataNodes increases, the number of network devices (routers, switches) between DataNodes increases, which increases the network distance between DataNodes. It can be seen from the figure that the proposed replica placement algorithm is lower than ARDS and GAPS by about 13% and 9% in terms of UC. This is mainly because the proposed algorithm considers the transmission cost between nodes, which allows the proposed algorithm to place the data blocks to nodes with a smaller update cost. This is mainly because the proposed algorithm takes into account the network distance between DataNodes when performing the replica placement operation, which makes the UC of the proposed algorithm lower.

5.2.3. Performance evaluation of the proposed replica reconstruction algorithm
Fig. 13 shows the effect of the failure of a DataNode in the cluster on the RRT performance. As shown in this figure, before the DataNode fails, the RRT of the three algorithms remains at a normal level (about 120 s). At 20 min, a DataNode failed, which increased the RRT of the three algorithms. After the DataNode fails, the proposed algorithm can restore RRT performance to normal level faster than the two benchmarks. This is mainly because the proposed algorithm prioritizes the recovery of data block replicas with high access frequency, which enables these data replicas to provide users with data services faster, thereby reducing data read response time.

Fig. 14 shows the evaluation of ART performance of the proposed algorithm when a DataNode failure. As can be seen from this figure, the DataNode failure occurred at the 20 min, this reduced the ART of the three algorithms from 1418 to 36. After the DataNode fails, the ART of the three algorithms increases with the time increase. This is mainly because the three algorithms perform data recovery operations. Among them, the increase in ART of the proposed algorithm is faster than the two benchmarks. The reason is the same as the RRT experiment above, the proposed algorithm preferentially restores replicas of the data block with high access frequency, which improves data read throughput.

Fig. 16 shows the performance evaluation of the SRT of three algorithms under the change in the number of submitted jobs. It can be seen from the figure that the SRT of the three algorithms increases with the increase in the number of submitted jobs. This is mainly because as the number of jobs submitted increases, the computing load in the cluster gradually increases, and the available computing resources gradually decrease, which makes the system response time increase. In addition, the proposed algorithm outperforms HDFS and PRS by about 13% and 9% in terms of SRT. This illustrates that the proposed algorithm can place the data replicas in the suitable DataNodes to improve the performance of the file system.

5.2.4. Performance evaluation of the proposed replica synchronization algorithm
Fig. 17 describes the TDW performance evaluation of the three algorithms under the changes of the data block size. It can be seen from the figure that the TDW of the three algorithms increases with the increase of the data block size. The main reason is that under a fixed hardware configuration, the larger the size of the data block written to the DataNode, the more time it takes. In addition, it can be seen from the figure that the proposed algorithm is better than HDFS and ERS by about 12% and 9% in terms of TDW. This is mainly because the proposed algorithm returns the write success message to the user after synchronizing a part of the replicas, which reduces the time required for data writing.

Fig. 18 evaluates the ART performance of the proposed algorithm with changes in the number of concurrent reads. As can be seen from the figure, ART increases with the number of concurrent reads. The main reason is that the more concurrent reads, the more data is read, which leads to an increase in read throughput. In addition, the HDFS default algorithm has the highest ART, which is mainly because the HDFS default policy updates all data block replicas with strong consistency, which makes all data replicas to be up-to-date and they can all be read, so this makes the ART of the HDFS default algorithm the highest. The ART of the proposed algorithm is only slightly lower than the HDFS default strategy by about 4%, and higher than ERS by about 17%. The reason is mainly because the proposed algorithm only synchronously updates a part of the data replicas when writing data, at this time, only this part of the data replicas can be read, which reduces the performance of ART to a certain extent. After the system is idle or unsynchronized replicas become hot data, these data replicas are synchronized, this improves the ART performance of the proposed algorithm.


Download : Download high-res image (183KB)
Download : Download full-size image
Fig. 15. Performance evaluation of SSU for replica reconstruction algorithm.


Download : Download high-res image (177KB)
Download : Download full-size image
Fig. 16. Performance evaluation of SRT for replica reconstruction algorithm.


Download : Download high-res image (164KB)
Download : Download full-size image
Fig. 17. Performance evaluation of TDW for replica synchronization algorithm.


Download : Download high-res image (153KB)
Download : Download full-size image
Fig. 18. Performance evaluation of ART for replica synchronization algorithm.

6. Conclusion and future work
Aiming at the problem of dynamic replica creation in the edge cloud system, this paper proposes a Dynamic Replica Creation strategy. Experimental results show that the proposed dynamic replica creation strategy effectively reduces system response time. Aiming at the problem of replica placement, this paper proposes a Replica Placement Strategy. Experimental results prove that the proposed replica placement strategy can reduce system response time, improve data read throughput and system storage space utilization while ensuring load balancing. In addition, considering the problem of data replica synchronization and the data recovery of failed DataNodes in the edge cloud system, this paper proposes a delay-adaptive replica synchronization strategy and a load-balancing based replica recovery strategy, and through experiments proved their effectiveness. In the future, we will evaluate the effectiveness of the proposed algorithms in a larger experimental environment and test the performance of the proposed algorithms in more public benchmarks. In addition, we will study replica migration strategies to further reduce replica migration time during replica placement and improve network resource utilization.