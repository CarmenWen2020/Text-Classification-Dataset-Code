Abstract
Failure detectors (FD)s are celebrated for their modularity in solving distributed problems. Algorithms are constructed using FD building blocks. Synchrony assumptions to implement FDs are studied separately and are typically expressed as eventual guarantees that need to hold, after some point in time, forever and deterministically. But in practice, they may hold only probabilistically and temporarily. This paper studies FDs in a realistic system , where asynchrony is inflicted by probabilistic synchronous communication. We first address a problem with , the weakest FD to solve consensus: an implementation of “consensus with probability 1” is possible in  without randomness in the algorithm, while an implementation of “ with probability 1” is impossible in . We introduce 
⁎
, a new FD with probabilistic and temporal accuracy. We prove that 
⁎
 (i) is implementable in  and (ii) can replace , in several existing deterministic consensus algorithms that use , to yield an algorithm that solves “consensus with probability 1”. We extend our results to other FD classes, e.g., , and to a larger set of problems (beyond consensus), which we call decisive problems.

Keywords
Failure detectors
Probabilistic links
Message loss
Consensus
Modular algorithms

1. Introduction
The failure detector abstraction is an elegant means to solve difficult distributed computing problems, such as the fundamental consensus problem,1 in a modular manner. Roughly speaking, a failure detector is a distributed “oracle” augmented to an asynchronous system. The purpose of this oracle is to provide hints (possibly incorrect) about which processes of the system have crashed [2] (see Fig. 1). A failure detector is formally defined by high-level axiomatic properties which, in turn, encapsulate synchrony assumptions that allow problems like consensus to be solved. The task of implementing a given failure detector using synchrony assumptions becomes a separate, lower-level task.

Fig. 1
Download : Download high-res image (65KB)
Download : Download full-size image
Fig. 1. Failure detector modular approach to solve consensus in asynchronous systems.

A large body of work [3], [4], [5], [6], [7], [8] has been devoted to determine which synchrony assumptions are sufficient to implement for instance the  failure detector, established to be the weakest, in a precise sense [9], to solve consensus-like problems. Roughly speaking,  represents a failure detector that guarantees that all correct processes will eventually detect all the failed processes in the system and that all correct processes will be able to converge on identifying a single correct process. The underlying synchrony assumptions typically adopted in the distributed algorithm community to implement  take for example the form of some links being eventually timely, i.e., after some point in time, these links never “delay” messages. Such assumptions, besides placing the failure detector approach under scrutiny in the distributed computing community itself [10], are questionable from the networking perspective. We elaborate further on this.

Questioning Failure Detectors. As discussed by Dwork et al. in [11] as well as Lamport in [12], consensus requires the system to be “good” only sufficiently long, while the weakest failure detector to implement consensus requires parts of the system after some point to be “good” forever [3], [4], [5], [6], [7], [8]. The mismatch between requiring good networking conditions only for “sufficiently long” versus requiring them after some point in time forever is arguably due to the failure detectors definitions [9], which are built for asynchronous systems, where no timing assumptions can be made, e.g., regarding the timeliness of message delivery. Due to the absence of time, failure detector properties were defined independent of time, which makes it very challenging to quantify how long this “sufficiently long period” should be. In fact, traditional failure detector properties, including , are defined to hold at some point during the algorithm's execution and forever thereafter to ensure that any “long-enough” period is captured. In that sense, implementing failure detectors would conceptually require some network timing assumptions to hold at some point during an algorithm's execution and to hold forever.

From a networking perspective, the dependence of failure detectors on a synchrony condition that should hold “forever”, suggests that failure detectors may be practically unfit, especially for networking systems in the realm of the cyber-physical domain, where multiple heterogeneous electronic devices (requiring different communication technologies to connect) monitor, control, and operate physical structures. Examples include large continuous process plants, manufacturing shop-floors, power grid installations (smart grids), building and city automation (smart cities), and even ecosystems of connected cars. Networks of such systems, often heterogeneous in terms of the underlying communication technologies, can typically provide some time guarantees on message deliveries under certain anticipated workloads. However, such timing guarantees may be violated due to many random disturbances, e.g., bandwidth limitation, bad channel quality, interference, collisions, and stack overflows [13], [14], [15], [16], [17], which are often probabilistically modeled.

Motivation and Approach. The motivation of this work is to bridge the gap between the modular distributed computing approach, based on failure detectors to circumvent the impossibility of fundamental distributed problems, and the networking view of communication link characteristics in the cyber-physical domain. In this view, link characteristics are probabilistic and temporary, rather than deterministic and perpetual – as desired by traditional failure detector definitions [9], e.g., . To this end, our approach aims at refining failure detector definitions to formally remove their theoretical reliance on forever holding network assumptions. This level of formalism in defining failure detector properties and quantifying the duration of “long-enough stable periods” inevitably required introducing the notion of time within the failure detector properties as well as the underlying system.

We define a probabilistically synchronous system  that replaces the traditional asynchronous system (where no timing assumptions can be made). In system  some timing assumptions exist, however, these assumptions might be violated and neither the time at which these violations happen nor the duration for which they last is known. In other words, system , encapsulates a large degree of “uncertainty” but still captures the notion of having transient stable periods which could be capitalized to evolve an algorithm's execution towards termination. System  is hence inspired from the behavior of networks in the cyber-physical domain.

Interestingly, we can have an implementation of “consensus with probability 1” in  without the use of randomization in the algorithm itself,2 i.e., by merely relying on the non-determinism in communication, e.g., [18], [19]. However, we prove that an implementation of “ with probability 1” is impossible to achieve in system  (see Theorem 1 for the meaning of “ with probability 1”). This suggests two things: (i)  is somehow too strong for consensus,3 at least in a probabilistic environment as  and (ii) deterministic algorithms solving consensus using , cannot be practically put in use to solve consensus in systems like , as  itself cannot be guaranteed in .

We propose a way to refine the failure detector notion itself, while preserving its usefulness as an algorithmic building block (see Fig. 2). We define a probabilistic failure detector ⁎. Roughly speaking, ⁎ requires, with probability 1, that the properties of  are satisfied for periods that are arbitrary long. Interestingly, we prove that ⁎ can be implemented in , which implies, at least from a failure detector perspective, that our system  is weaker than the systems considered so far to build -like failure detectors [3], [4], [5], [6], [7], [8]. More importantly, we show that the celebrated rotating coordinator algorithm [2] to solve consensus using , actually solves “consensus with probability 1” in , when ⁎ is used instead of . We then generalize this result, in three directions: (i) to hold for all deterministic consensus algorithms satisfying some -bounded condition (defined in Section 3), (ii) to hold for all decisive problems (Section 7), not only consensus and (iii) to hold for other failure detectors, e.g.,  (Section 7).

Fig. 2
Download : Download high-res image (53KB)
Download : Download full-size image
Fig. 2. Overview of our results on implementing  and ⁎.

In particular, we show that any deterministic algorithm, which solves a decisive problem using  () and is  ()-bounded, can be re-used in system  to solve the same problem, ensuring termination with probability 1: the result is reached by using ⁎ (⁎) instead (see Fig. 3).

Fig. 3
Download : Download high-res image (60KB)
Download : Download full-size image
Fig. 3. Overview of how ⁎ can replace  in existing deterministic algorithms to still solve “consensus with probability 1” in system .

Practicality of Approach The reader might wonder that our approach, albeit guaranteeing termination with probability 1, might require a long time to terminate. Termination in our model is linked to the system's ability of behaving synchronously for a period of time that allows some processes to deliver some messages in transit and exchange some other messages that permit processes to decide. In fact, how fast termination happens is dependent on two main factors: (i) the consensus algorithm's convergence speed on reaching a decision, when favorable conditions are met and (ii) the ability of the system to adhere to the those favorable conditions for a period of time as required by the algorithm itself. We do not see this aspect of our model as problematic. In particular, note that our results hold for a category of consensus algorithms that use failure detectors, such as those suggested by the general indulgent framework and which are proved to be efficient and zero degradable [20].

Besides, this concern (regarding how fast termination happens) applies to systems that assume partial synchrony. In partially synchronous systems, the algorithm is safe, but may not decide until after the Global stabilization time (GST) happens. GST being the point in time after which some synchrony assumptions hold forever. However, there is no bound on the duration of the asynchronous period prior to GST. More importantly, for those algorithms using failure detectors termination, even after GST, will depend on how fast the failure detector output stabilizes. This means that algorithms in the partial synchronous model may take a long time before reaching termination (as termination itself is linked to GST and failure detector output). However, our approach goes one step beyond partial synchrony and allows failure detector definitions to have properties that can be implemented in more realistic systems (like system ), independent of the convergence speed4 of the consensus algorithm.

Contributions. To summarize, our main contributions are: 1. We propose a way that preserves the usefulness of failure detectors as software building blocks in systems with probabilistic synchronous communication (): we define ⁎ a probabilistic failure detector with accuracy ensured for periods that can be arbitrary long. ⁎ can be implemented in systems like . 2. We show that ⁎ can be implemented efficiently and we present an optimal algorithm for ⁎, which we believe is interesting on its own. The optimal algorithm hinges on a logical linear arrangement of the processes. When links behave in a timely manner (i.e., the delay of a reliable message transmission respects some bound), the number of links carrying messages infinitely often converges to using  (the number of correct processes), possibly . In the best case, i.e., , our algorithm of ⁎ achieves, to the best of our knowledge, the lowest communication overhead compared to all known  algorithms.

3. For all decisive problems P, beyond consensus (defined in Section 7.2), we enable existing deterministic protocols which use  and  and which are ()-bounded, to be reused in  to solve “P with probability 1”: simply using ⁎ and ⁎ instead of  and  respectively leads to the desired result. Our approach hence succeeds in encapsulating the randomization of the probabilistic link behavior in the very abstraction of failure detection (without affecting the deterministic algorithms built on top), bridging the gap between distributed computing and networking practices.

Road map. Section 2 discusses related work. Section 3 presents our distributed system . Section 4 proves the impossibility of implementing “ with probability 1” and introduces ⁎. Section 6 derives communication lower bounds for implementing ⁎ and presents an optimal algorithm for ⁎. In Section 7, we show that an existing consensus algorithm with  can guarantee “consensus with probability 1” in system  when ⁎ is used instead. We then generalize our result to a larger set of problems. In Section 7 and Section 8 we respectively study (i) the feasibility of extending our probabilistic and temporal notion of accuracy to other existing failure detector classes and (ii) the solvability of distributed problems using probabilistic and temporal failure detectors besides ⁎. Section 10 summarizes our results and concludes the paper.

2. Related work
Fault-tolerance has been addressed in many domains [21], [22], [23], e.g., to predict failures and figure out their sources and patterns [24], [25], [26], to detect transient process failures [27], etc.

We discuss, in more details, closely related work addressing specifically failure detectors and consensus. In these works, many different system models have been considered mainly differing in the timeliness assumptions of processes and/or links. To better illustrate the differences between the system models adopted in the related works, we summarize the timing assumptions of each categorically in Table 1 and we discuss their results in text in what follows. The first column of the table indicates the name of the system model (in case papers do not provide names for their models, then a reference of the related work that used that model is used instead). The second column of the table lists the corresponding assumptions made for each model.


Table 1. Summary of the process and link assumptions considered in the systems discussed in Section 2.

System name [paper Ref.]	System description: list of assumptions about processes and links
Processes: have negligible delays and up to n − 1 can crash
 [this paper]	Links
  • all links lose messages probabilistically and fairly
  • in case of no loss, propagation delay is bounded
Processes: are synchronous, and up to n − 1 can crash
S [4]	Links
  • all links can delay and/or lose messages indefinitely without being fair
  • however, all outgoing links of an unknown correct process are eventually timely
Processes
  • have bounded delays that hold eventually (bounds not known) and up to n − 1 can crash
System of [29], [30], [31]	Links: all links are reliable and eventually timely
Processes
  • each process is equipped with a drift-free local clock (synchronized)
  • process have negligible delays and only a minority can crash
System of [7]	Links
  • all links are reliable
  • f incoming links of a single correct process become timely after some finite time interval
  since system initialization (f being the maximum number of process failures)
Processes: process delays are negligible, and some can crash
System of [8]	Links
  • all links can lose or delay messages
  • all outgoing links of a single unknown correct process are eventually timely
Processes
  • processes have local clocks not necessarily synchronized
  • process delays are lower and upper bounded, and some processes can crash
System of [3]	Links
  • all links are fair
  • f outgoing links of a single unknown correct process are eventually timely
Minimal Synchrony. There has been a lot of focus on Ω, a failure detector abstraction equivalent to  [28]. Malkhi et al. [7] considered a system where all links are reliable. Their implementation of Ω assumed the existence of some time interval δ, a correct process p and a time after which, if p broadcasts a query, then p receives replies from at least f other processes within δ (where f is the maximum number of processes that can crash). Aguilera et al. [3] considered a system where all links are fair and assumed the existence of some correct process p with f output links that are eventually timely (such a process is called an eventual f-source). Mostefaoui et al. [5] considered an asynchronous system with reliable links and defined a specific query response mechanism to implement Ω. The mechanism itself however relies on other work [6] which requires the existence of an eventual f-source in the system. Jiménez et al. [8] considered a system where links can lose or delay messages. To get an implementation of Ω, they require a correct process that can reach all other correct processes through eventually timely links. Along this line of work as well, Aguilera et al. [4] described a system where links can be arbitrarily slow and lossy but there exists at least one eventually timely source, a timely process whose output links are eventually timely.

Compared to the work above, we focus on , a system which, from the failure detection point of view, is weaker than the systems considered so far [3], [7], [8], [5]: While the Ω failure detector (equivalent to ) can be implemented in the aforementioned systems [3], [7], [8], [5],  properties cannot be implemented, even with probability 1, in . We rather investigate properties of failure detectors that are implementable in system .

Minimal Communication. Another track of research addressed the communication overhead of failure detector algorithms [4], [29], [30], [31], [32]. Aguilera et al. [4] showed that an algorithm for Ω in a system S (see Table 1) requires all processes to periodically send messages and the minimum number of links carrying messages forever can be at least . On the other hand, stronger systems allow efficient algorithms, where only one process broadcasts messages forever on  links. For systems with eventually timely correct processes and links (also reliable), Larrea et al. [31], [33] provided algorithms for  and , where 2n links carry messages forever in the worst case, and for Ω where  links carry messages forever respectively. Follow-up work [29], [30] defined communication optimality: in systems with at least one faulty process, the number of correct processes  equals the minimum number of links necessary to implement ,  and Ω. If the correct process with the smallest id has eventually timely output links, communication-optimal algorithms of  and  exist [32].

Our work is different in that it investigates the communication overhead of ⁎, a weaker variant of , in system , where links never become timely forever. We show that when links in  start behaving in a timely fashion for some interval, the number of links carrying messages in our ⁎ algorithm will converge to , possibly . Thus in the best case (i.e., ) our algorithm for ⁎ in system , where  processes can crash, circumvents the bound for  when at least one process crashes using  links [30].

Omission Faults. Some researchers explored consensus in systems with message losses without relying on eventual guarantees. Santoro and Widmayer [34] showed that consensus is impossible if  of the  possible messages sent in a round can be lost. In contrast, Schmid et al. [35] showed that consensus can be solved even in the presence of  moving omission and/or arbitrary link failures per round, provided that both the number of affected outgoing and incoming links of every process is bounded and that all processes are correct. Soraluze et al. [36] considered the general omission model, where processes can fail either by permanently crashing or by omitting messages. They defined a failure detector requiring the existence of a majority of well-connected processes, which do not crash, and are able to communicate in both directions and without omissions, either directly or indirectly, with a majority of processes.

In contrast, our work does not bound the number of messages lost at any point in time and does not require any process to be connected at all times with any other process, yet we can implement failure detectors and consensus.

Randomized Consensus Algorithms. Randomized algorithms ensuring “consensus with probability 1” have also been explored. Approaches based on coin-flips [37], [38], [39], [40] or probabilistic schedulers [18], [19] lead to consensus algorithms with probabilistic factors. Algorithms that use coin flips [37], [38], [39], [40] rely on the existence of a shared coin which processes can “flip”. Based on the coin's random outcome processes may take steps that help converge to a decision. Hence such algorithms induce randomness in the algorithm itself. Algorithms relying on probabilistic schedulers [18], [19] typically induce randomness in the system model, i.e., the environment rather than the algorithm itself. This includes randomness, for example, in scheduling processes on a uniprocessor for a shared memory context [19] and randomness in communication system for message passing contexts [18]. Similar to what we assume in this work, the latter (i.e., message passing probabilistic schedulers) enforces fairness by having a non-zero probability at every time instant in delivering a message that is still in transit (buffered in a queue). However, unlike our approach, the work of Bracha and Toueg [18] studies building new consensus algorithms that satisfy termination with probability 1.

In slightly different contexts, e.g., in systems with dynamic communication failures, multiple randomized algorithms [41], [42] addressed the k-consensus problem, which requires only k processes to eventually decide. Moniz et al. [41] considered a system with correct processes and a bound on the number of faulty transmission. In a wireless setting, where multiple processes share a communication channel, Moniz et al. [42] devise an algorithm tolerating up to f Byzantine processes and requires a bound on the number of omission faults affecting correct processes.

Our work does not employ randomization in the algorithm, we focus on deterministic algorithms in probabilistic networks. Moreover, we re-use existing deterministic algorithms relying on failure detectors to solve “consensus with probability 1” in .

Failure Detectors with Probabilistic Guarantees. A different line of research explored failure detector implementations with probabilistic guarantees. Chen et al. in [43] studied the quality of service (QoS) of failure detectors in systems where message delays and message losses follow probability distributions. They proposed a set of metrics, among them (i) how fast actual failures are detected and (ii) how well false detections are avoided. In [44], Bertier et al. proposed an implementation supporting a short detection time based on estimations of the expected arrival of monitoring messages, and on adapting QoS to the specific application needs. In [45], Gupta et al. quantified the optimal network load of failure detector algorithms as a function of the failure detection time and the probability of falsely suspecting a correct process. Hayashibara et al. [46] proposed φ-failure detectors capable of adapting to the application requirements and network conditions dynamically, by assigning a value to every known process representing the confidence that it is alive.

In contrast, we evaluate the eventual guarantees of (binary5) failure detectors implemented in systems with probabilistic message losses. In particular we investigate implications of such guarantees to solving distributed computing problems, namely consensus. We also study the efficiency of implementing these failure detectors from a communication overhead perspective, defining optimality in terms of the number of links that need to carry messages forever rather than evaluating the real-time performance.

Rethinking Failure Detection. Several researchers challenged (directly or indirectly) the failure detection approach. Biely et al. [47] showed that the asynchronous model augmented with Ω is equivalent to several models where the links from at least one process (the source) are timely. In comparison with Biely et al. [47], our work avoids the necessity of eventually timely link(s), for the solvability of problems such as consensus in the presence of asynchrony.

Charron-Bost et al. [10] highlighted a problem with the failure detection approach which we re-affirm, in a probabilistic environment, in this paper: Dwork et al. [11] and Lamport [12] showed that sufficiently long finite “good” periods make consensus solvable while Chandra et al. [9] show that consensus cannot be solved without permanent agreement on a leader from some time on. Given this inconsistency in results, Charron-Bost et al. [10] showed that the “discrepancy” is due to the two-layered structure of the failure detector approach itself. Precisely, authors attribute this “artificial difficulty” to the interface between the failure detector layer and the asynchronous system layer to which the failure detector is augmented and the lack of timing control by failure detectors on the asynchronous system. Charron-Bost et al. [10] concluded that it may be better to look at consensus without using failure detectors. Avoiding any dependence on real time, Cornejo et al. [48] proposed asynchronous failure detectors (AFDs) and used them to address challenges related to the hierarchy robustness of failure detectors. They also investigated the relationship between the weakest failure detector and partial synchrony. They showed that a large class of problems, termed as finite problems, such as consensus, do not encode the same information about process crashes as their weakest failure detectors do (another validation of the observation in [10]).

In this paper, we take an opposite route compared to [10] and [48]. We refine the notion of a failure detector with explicit dependence on real time to address the following: “consensus with probability 1” can be implemented in system  (without the need for randomization within the algorithm) while “ with probability 1” is impossible to implement in . We define ⁎, a variant of  implementable in  and show that such a transformation in the failure detector notion allows deterministic consensus algorithms based on failure detectors to solve “consensus with probability 1” in poorly behaved systems. In this sense, we succeed to repress the “artificial difficulty” highlighted in [10] about the failure detector model, showing that “consensus with probability 1” can be solved in poorly behaving systems (as viewed from a networking perspective) using failure detectors, without requiring an eventually forever agreement on a process that will never crash.

3. System model
We consider a distributed system  consisting of a finite set Π of  processes, , which communicate by message passing. We assume, without loss of generality, that processes have access to a global clock with discrete time events denoted by .

Processes can send and/or receive a message, at these discrete time events. The time interval between consecutive events in t is assumed to be an upper bound on the propagation delay () over any link connecting any two processes. Processing delays are assumed to be negligible compared to communication delays.

Communication Links. The links interconnecting processes are assumed to be uni-directional uni-cast links. In particular, every pair of processes  is connected by two uni-directional links:  and . These links exhibit changes in their transmission quality, as the quality of the underlying channels might depend on various propagation conditions. We thus assume that a link  has a probability  of losing the message sent at time t (if any is sent). This captures the very idea that a link is not always reliable and can lose messages for an unbounded but finite period.6 We assume that message loss probabilities across links are independent and that the value of  can change with time; at each time , while still adhering to .

We refer to such links as probabilistic. A probabilistic link thus constitutes an instance of the fair-loss link [49], where a message sent infinitely often is received infinitely often.

As such, our system can be viewed as communication-closed lock step system with probabilistic message losses. In this context, all correct processes can take a step at every discrete time instant, where a step can be any of the following events:

•
To send and/or receive a message and/or

•
To do some computation

The reader might argue that in practice, losses and delays can be correlated and may usually come in bursts, i.e., periods where messages are consecutively lost/delayed. Burst lengths can be arguably well anticipated (with high coverage) especially for industrial networks. We refer readers to studies like [50], [51] that elaborate on how to estimate link burstiness. Accordingly, we can still model burstiness in our system similar to what we have done with individual losses. Namely, we can denote by k the maximum burst lengths (in time units) that are expected to be observed in our network and we can assign a probability  for having bursts larger than k. The failure detectors definitions, as well the consensus algorithms expected latencies, can then be adapted relative to k. Regarding the correlation of losses, we have observed in other studies [52], [53] that despite considering correlation between losses for example time correlations (modeling links as Gilbert-Elliot Markov channels), such correlation effects fade negligibly when considering multiple message re-transmissions that aim at increasing the reliability of message delivery.

Faulty Processes. Processes can fail by crashing, i.e., by halting prematurely. We consider that process crashes are permanent, i.e., no crashed process can recover. We use  to denote the number of correct processes, i.e., processes that do not fail. We assume that . When a process  sends a message m to process  (for ) and m is successfully propagated by link ,  receives/delivers m. However if m is lost by link ,  receives nothing.

Reliable Message Transmission. Despite probabilistic losses, a reliable message transmission, be it a unicast or a broadcast can still be achieved in  [54], [18], [17]. Reliable transmissions can be provided via abstractions running on top of the probabilistic links of system . For example, a reliable link abstraction would guarantee the following with probability 1: a message sent by a correct process  to another correct process , will be delivered by  at some future point in time.

CRUCIAL: The phrase “the following is guaranteed with probability 1: there is a time when event X occurs” (used throughout this paper) does not mean that there is a point in time where event X occurs with probability 1 but rather that over the infinite course of time event X will certainly occur. For example, if a fair coin is flipped an infinite number of times, then with probability 1, there is a time when the coin lands on head, however there is no point in time where flipping the coin lands on head with probability 1. We provide next the complete specifications of a reliable link and a reliable broadcast primitive in .

A reliable link abstraction guarantees:

1.
Reliable delivery: If a correct process p sends a message m to a correct process q at time t, then with probability 1 the following is guaranteed: there exists some time  where q delivers m. In particular, q can deliver m at  with positive probability .

2.
No duplication: No message is delivered by a process more than once.

3.
No creation: If some process q delivers a message m with sender p, then m was previously sent to q by p.

A reliable broadcast primitive can also be defined in :
1.
Validity: If a correct process p broadcasts a message m at time t, then with probability 1 the following is guaranteed: at some time  all correct processes will have delivered m. Precisely, all correct processes can deliver m at  with positive probability .

2.
No duplication: As for a reliable link.

3.
No creation: If some process q delivers a message m with sender p, then m was previously broadcast by p.

4.
Agreement: If a message m is delivered by some process at time t, then with probability 1 the following is guaranteed: at some time , m will be delivered by every correct process.

The reliable link abstraction can be achieved over a probabilistic link , for example by deploying buffers and message retransmissions [54], [18], [17]. Typically, process  keeps retransmitting a message m forever or in practice until some acknowledgment is obtained for m. In this sense, the message transmission delay of a message m is measured by the number of time slots elapsed from 's first attempted transmission of m until the time when m is successfully received by . We do not elaborate on implementation details of such an abstraction, as existing work already addresses this problem in systems where links lose messages [54], [17]. Clearly, such a reliable link abstraction does not provide any deterministic bounds on message transmission delays, as message losses may span unbounded duration. However the reliable link abstraction in  offers instead a probability distribution on the delay of a message.

The reliable broadcast primitive can be built for example using the reliable link abstraction in system . Algorithms such as those detailed in [55] can be directly applied and will result also in a reliable broadcast where the delay to deliver a broadcast message, despite possibly being arbitrarily long, admits a probability distribution.

4. Probabilistic temporal failure detection
In a system augmented with a failure detector, each process has access to a local failure detector module [2]. This module monitors other processes in the system and typically maintains a set of those that it currently suspects to have crashed. Chandra and Toueg [2] defined various kinds of failure detectors based on their achievable properties, namely completeness and accuracy. Roughly speaking, completeness describes the failure detector's ability to suspect crashed processes, while accuracy defines the failure detector's ability of not suspecting correct processes.

The , for instance, failure detector guarantees the following two properties: (i) strong completeness: eventually every process that crashes is permanently suspected by every correct process and (ii) eventual weak accuracy: there is some time instant  after which some correct process is never suspected by any correct process.

4.1. The impossibility of eventual weak accuracy
We establish several lemmata ensuring certain guarantees on message delivery and process failures.

Lemma 1

In system , for any finite period Δt and at any time instant , all messages that are sent on link  during the interval , can be lost with positive probability.

Proof

Recall that  is the probability with which the link  loses a message at time t. Let  be the probability that  loses the messages (if any is sent) at time t and time . Since  ∀t, then(1)
 
 By (1),  (and ). By induction, we have  . Denote by  the event that  losses all messages (if any is sent) for the interval , for any finite period Δt. Then the probability of  happening is: Given , then we have .

Lemma 2

Consider any finite period Δt, any time instant  and any subset of processes ΔP. In system , all processes  can lose, with positive probability, all messages sent in the interval  from and to processes in ΔP.

Proof

The probability to have any subset of processes losing all messages exchanged with all remaining processes for any finite period Δt, depends on the individual probabilities of the relative individual links losing all sent messages during the interval Δt. Following from Lemma 1, any link in the system can drop all messages (if any were sent) for a finite but unbounded time, with a positive probability. Denote by  the event that  losses all messages (if any were sent) in the interval , for any finite period Δt. Then by Lemma 1, . Following the arguments as in proof of Lemma 1, we have: 
  where n is the total number of processes in the system. This concludes the proof.

With these lemmata, we can prove that  cannot be implemented in system .
Theorem 1

It is impossible to implement “ with probability 1” in  even if at most one process can crash. That is, in the presence of processes crashes, it is impossible to have an algorithm in  that guarantees strong completeness deterministically and which ensures, with probability 1, the following: there is a time after which some correct process is never suspected by all correct processes.

Proof

We proceed by contradiction. Without loss of generality, assume a system  of  processes,  and . Suppose that there exists an algorithm , that guarantees both strong completeness and eventual weak accuracy. Consider three executions: (i) e1: an execution where  fails at some time instant  in , (ii) e2: an execution where  fails at  and (iii) e3: an execution where  and  are both correct but all messages exchanged between  and  are lost during the interval . By the strong completeness property of , in executions e1 and e2 there is a finite period, say , after which  suspects  and  suspects  respectively. By Lemma 2, execution  is a valid execution in  and Δt can be arbitrarily long, specifically . Thus, by the strong completeness of ,  suspects  and  suspects  in e3. By Lemma 2, execution e3, such that , can occur with positive probability at any time instant in . This implies that  cannot guarantee with probability 1 the following: there exists some time after which some correct process is never suspected (i.e., remains trusted forever) by any correct process. This violates the eventual weak accuracy of .

As a consequence of Theorem 1, we study how to vary the properties of , defining a variant ⁎, which is implementable in our system .

5. Probabilistic & temporal failure detectors
We define a new probabilistic weak accuracy property that holds temporarily for periods that can be arbitrary long. Combined with strong bounded completeness, these two properties define a new failure detector ⁎.

Definition 1

Failure detector ⁎ guarantees:

(i) strong bounded completeness: every process that crashes is permanently suspected by every correct process after a maximum of  time slots of the actual crash and

(ii) probabilistic & temporal weak accuracy: Consider any finite duration Δt. With probability 1 the following occurs: there exists infinitely many time instants , such that a unique correct process is not suspected by any correct process during the interval .

The bounded strong completeness is the strong completeness property with an upper bound on the time to detect a failure. While the probabilistic finite weak accuracy property can be viewed as a weaker form closer of the accuracy of . Roughly speaking, the accuracy of ⁎ can be described as a property where the eventual weak accuracy of  is required to hold, with probability 1, infinitely often for any finite period rather than forever.
Theorem 2

It is possible to implement ⁎, in system , assuming  processes can crash.

Proof

Let  be any time instant in  and Δt be any finite duration.

Lemma 3

There is a positive probability that all messages sent by a correct process to all other correct processes, in the interval , are not lost (i.e., successfully received).

Proof

Let  be the following predicate: All messages sent by a correct process  to a correct process , in the interval , are not lost, i.e., successfully received by . The probability that predicate  occurs is: . This can be easily deduced from the proof of Lemma 1, given that the probability of a message (sent from  to ) being not lost at any time instant  is . Let  be the following predicate: All messages sent by a correct process  to every correct process , in the interval  are not lost. Since , the probability of predicate  happening, as in the proof of Lemma 2, is .

Assume algorithm  executing the following: (i) all processes periodically, at every time event , broadcast messages (i.e., they send messages to all other processes in the system) and (ii) initially all processes trust (do not suspect) each other. At every time instant in , process  suspects another process  only if  receives no new message from , otherwise  trusts .

The strong bounded completeness of ⁎ is ensured by . A process that crashes at time instant  stops sending messages and thus by (ii) will be suspected at all times  by all correct processes forever (that is with ). Let's denote by  the following predicate: during the interval , all messages sent by a correct process p are successfully received by all correct processes. By (ii) of algorithm ,  implies that process p is not suspected by any correct process during the interval . Following from Lemma 3, the probability of observing  is greater than zero. Note that in  any correct process can be selected as the unique correct process.

Since in  processes keep sending messages to all other processes forever (infinitely) and since for any time instant  , then with probability 1 the following is satisfied: there exists infinitely many time instants  when predicate  happens.  thus guarantees the accuracy of ⁎, concluding the proof.

For presentation simplicity, we focus now on  and ⁎ failure detectors. Later in Section 7, we discuss the implementability of other types of probabilistic failure detectors; namely ⁎, a probabilistic variant of the perfect failure detector , and ⁎, a probabilistic variant of .

6. ⁎ bounds and algorithms
We study in this section the communication overhead of ⁎ and present an optimal algorithm for implementing it.

6.1. Lower bounds
First, we identify the bounds on the number of processes and links required to respectively send and carry messages forever for any algorithm implementing ⁎.

Theorem 3

Consider any algorithm  that implements ⁎ in system  of  processes, where  processes can crash. Then,  distinct processes send messages infinitely often in  with probability >0.

Proof

Assume that  is any time instant in  and Δt is any finite duration. If no correct process sends messages infinitely often, i.e., all correct processes stop sending messages at some point in time, say t, then ⁎ cannot be implemented. This holds, since after time t every correct process becomes indistinguishable from a crashed process (w.r.t. to all other processes in ). By the strong bounded completeness of ⁎, every correct process suspects all processes in  after some bounded duration. This violates the probabilistic eventual weak accuracy property of ⁎.

Thus to implement ⁎ in  some correct process(es) should send messages infinitely often. We now prove Theorem 3 by showing that in system  with  processes, where  processes can crash, it is impossible to have with probability 1 an implementation of ⁎ where eventually, only  correct processes send messages infinitely often.

Consider 
 to be the subset of correct process that stop sending messages after time instant  and consider the following two executions: (i) e1: all processes in c crash at time instant  and (ii) e2: all messages exchanged between processes in c and processes in 
 in the interval  are lost. By Lemma 2, execution e2 is valid, as it has a positive probability of happening. For processes in 
 executions e1 and e2 cannot be distinguishable in any finite amount of time (since Δt is any finite duration). Therefore, after some time () processes in 
 suspect all processes in c. If no process in 
 starts to send a message afterwards then if all processes in c did crash no correct process in the system will send messages (a violation). Thus some process(es) in 
 should send messages, which in the case of e2, i.e., if processes in c are still alive, results in more than c process sending messages. Since execution e2 occurs with a positive probability, then it is impossible to guarantee with probability 1 that only  correct processes send messages infinitely often. This concludes the proof.

N.B. Theorem 3 does not mean that each process sending messages infinitely often, needs to do so by broadcasting (i.e., by sending the message to all other processes in the system). A process may send messages to any subset of the processes in the system. We show now that Theorem 3 can be circumvented, in the sense that ⁎ algorithms can be implemented such that, with probability 1, less than  processes send messages infinitely often. It can be done by limiting the maximum number of processes that can crash. The introduced limit on process crashes in the following theorem guarantees that a majority of processes remains correct, which is typically needed to implemented consensus alongside failure detectors, e.g., .

Theorem 4

Given an algorithm  that implements ⁎ in  with  processes of which at most 
 
 processes may crash, then the number of processes sending messages infinitely often in  can be less than .

Proof

Consider an algorithm  which deterministically selects any  processes to keep sending messages infinitely often after some point in time to all processes in , while all other processes stop sending messages completely. Since the maximum number of processes that may fail is f, then  guarantees that at least one correct process will send messages infinitely often and at maximum  will send messages infinitely often. By the proof of Theorem 2, it is clear that ⁎ can be implemented in  even if only one correct process sends messages, to all other processes in , infinitely often. This means that  implements ⁎ such that at most  processes send messages infinitely often. 
 
 (since ).

We now determine the number of links that need to carry messages infinitely often in algorithms implementing ⁎. Despite the probabilistic message loss, links in system  can, with positive probability, behave in a timely manner (i.e., ensure that the delay of a reliable message transmission respects some bound) for any finite duration. We define next what it means for algorithms to be optimal in . Let  be the minimum number of links required to carry messages forever to implement failure detector  in a synchronous system.7 Let  be an algorithm that implements failure detector , then:

Definition 2

 is optimal, if L, the number of links carrying messages infinitely often in , satisfies: , where Δt is an interval in which links are timely.

Theorem 5

The minimum number of links which need to send messages forever to implement ⁎ in a synchronous system where  processes may crash is  (possibly  depending on what processes crash).

Proof

First we prove that it is impossible to implement ⁎ if  links send messages infinitely often. The proof is by contradiction. Assume an implementation  of ⁎ in which only  links carry messages forever. Then there is in  at least one correct process p which eventually (i.e., at some point t in time) does not exchange messages with any other correct process.

Assume an execution e1 of  with  correct processes (including p) and another execution e2 of  similar to e1 however where p crashes after time t (the time when p eventually stops exchanging messages). e1 and e2 are indistinguishable to all processes (other than p) and thus processes in e2 will keep using the same number of links. However in e2 since the number of correct processes is less, then  links should be used which contradicts that e1 and e2 are indistinguishable.

Now assume an implementation  of ⁎ in which only  links carry messages forever. Since there is  correct processes, such an implementation is only possible if correct processes are arranged in a tree topology (of which a star and a linear list are a special case). In such an arrangement the root of the tree sends heartbeat messages, indirectly, to the rest of the correct processes. Consider an execution e1 of  in which  processes are correct and let t be the point in time after which only  links carry messages forever. Consider now e2, an execution identical to e1 up to t, but where a leaf process p (assumed correct in e1) crashes at time t (a leaf process has no successor processes). e1 and e2 are indistinguishable, to all processes above p in the tree (in this case all processes since p is a leaf node). Hence the process sending messages to p will not stop sending messages to p in e2, although the number of correct processes in e2 is one less than in e1, resulting in  links being used forever. However, if the process p (which crashes in e2) is not a leaf node, then p can be suspected by processes lower in the tree (or following it in a linear list) and initiate a procedure to eliminate communication with p and restore the fact that  links are used, concluding our proof.

We present next an optimal algorithm for ⁎ in system .

6.2. An optimal ⁎ implementation
We now present an optimal algorithm (Algorithm 1) implementing ⁎. We assume that processes are given sequential IDs in . When links in the system are timely for some finite interval, the number of links carrying messages infinitely often converges to  if at least one process crashes (possibly to  if process  does not crash) and to  when no crashes occur. Recall that a timely link ensures that the delay of a reliable message respects some bound; in Algorithm 1, we assume that bound to be the selected time-out (line 11).

Algorithm 1
Download : Download high-res image (151KB)
Download : Download full-size image
Algorithm 1. An Optimal ⁎ Algorithm.

The basic idea underlying Algorithm 1 is that a process with ID x always suspects all processes with higher indices, i.e., processes at indices . The goal of Algorithm 1 is to achieve two things:

1.
Every correct process permanently suspects all crashed processes with lower indices after  time slots of the crash.

2.
When links are timely (e.g., when they operate with no losses), no correct process suspects the correct process with smallest ID.

Every process  maintains a set of suspected processes  and two variables  and  to respectively refer to the process which is monitored by  and the process to which  periodically (e.g., every t) sends heartbeat messages of the form  (see Fig. 4). Note that process  has  whereas process  has . We assume that processes have unique identifiers (names) and that they know their IDs. Also, a process  always suspects all processes with an ID greater than i, i.e.,   (see Fig. 5).
Fig. 4
Download : Download high-res image (76KB)
Download : Download full-size image
Fig. 4. Overview of how processes send heartbeats to processes that monitor them.

Fig. 5
Download : Download high-res image (87KB)
Download : Download full-size image
Fig. 5. Example of how process p4's set of suspected processes Sc(p4) evolves. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)

A process  monitors  by listening to the heartbeats sent by  and resets a time-out whenever it receives a heartbeat from . The duration of the time-out can be, for example some multiple of the period t at which  sends heartbeats. Process  suspects  when the time-out expires. In case of suspicion,  sends through a reliable link abstraction (as discussed in Section 3), a message  to , adds  to , and sets its  to the process an ID  in the list. Upon its receipt of a  message, a process  which is alive sets  and starts sending  to . In addition,  also sends a message  to all the processes , as  knows that  suspected all these processes ().

When a process  receives a message ,  replies by sending to , through a reliable link abstraction, .

When a process  receives ,  checks if  or if . If  and , then  and the set of suspected processes  are updated accordingly. Similarly, if  and , then  is updated.

Proof of Correctness of Algorithm 1

We first prove that Algorithm 1 implements ⁎, then we prove it is optimal. From the description of the algorithm, strong completeness is guaranteed if a crashed process  is suspected by all correct processes  within  time slots.

Lemma 4

Given a crashed process , the first correct process  eventually suspects  permanently.

Proof

Let us denote by t the time at which  crashes. By lines (11-14) of Algorithm 1 guarantees that  will eventually set  as its predecessor and will monitor it. If  suspects  before time t then if  hears no messages from  it will suspect it forever. However if  hears a message from , then by lines (26-33) of Algorithm 1  will monitor  again and will eventually suspect  by (11-14) some time after t. Since after time t,  will no longer send any messages, then  will be suspected forever by .

Lemma 5

Given a correct process ,  will eventually be (when links behave timely) the process with the smallest ID .

Proof

Let us denote by  the correct process with the smallest ID such that . By lines (11-14)  will stop monitoring  and will monitor other processes only if  suspects . However,  sends suspicion messages through reliable link abstraction. Since both  and  are correct the suspicion will eventually reach  which by lines (16-21) will send  a heartbeat message through a reliable link abstraction and will set  as . Again by the fact that the two processes are correct  will receive this heartbeat message and by lines (26-33) will monitor  again. Thus if links are timely  will not “time-out” on .

By Lemma 5 and lines (26-33), the set of suspected process of a correct process  () is propagated to all correct processes with IDs . By lines (35-37), given some crashed process , all process  will eventually suspect that crashed process permanently ensuring strong completeness. Now we prove the strong bounded completeness property of Algorithm 1, i.e., a failed process is permanently suspected by all correct processes after some bounded duration of having failed. The longest delay of suspecting a crashed process would be when  has to detect the crash of . It is important to note the following: if process  is monitoring process , then  can detect the failure of  after “timeout” time slots of not hearing from . For presentation simplicity, we consider a network of three process . We accordingly show that  detects the failure of  within a bounded duration which we compute. By induction and transitivity this could be extended to a general network of n processes.

Assume that  fails at time t. Recall also that every process  sends a heartbeat message at each time slot to . In that case, , the process monitoring , permanently suspects  after “timeout” time slots of not hearing from . Given that a successful message transmission (not lost) between a pair of processes takes one time slot. This means that  suspects  in the interval  and thus within a bounded delay of “”.  can detect the crash of  in two cases: (i) via  (by seeing that  is in the suspected set of ) or (ii) directly from . The time taken for  to detect  in case (i) would be , where . While in case (ii)  has to suspect  first, after which it monitors  and suspects it. In that case  would suspect  in  time slots of not hearing from . The worst-case delay for  to permanently suspect  would thus that  keeps hearing from  until time instant “” and then does not hear from  for a duration longer than . This results in  permanently suspecting  in the interval . As a consequence, a failed process would be permanently suspected by all correct processes within a maximum of  time slots after having failed. This proves the strong bounded completeness of Algorithm 1, given three processes.

Lemma 6

When links are timely, all correct processes will trust the correct process with the smallest ID.

Proof

By Lemma 4, when links are timely every correct process  is monitored by the correct process with the smallest ID greater than i.

Since the correct process with smallest ID does not get suspected by the processes monitoring it (as a consequence of links being timely), by Lemma 5 all correct processes eventually adapt their set of suspected processes to not include the correct process with the smallest ID - lines (35-37).

The probabilistic accuracy can be insured by Lemma 6. At any point in time Lemma 6 has a positive probability of happening. Since we consider infinite time instants, then with probability 1 the following happens: there are infinitely many time instants  such that after each instant links in the network behave timely for the interval , where Δt is any finite duration.
Now we show that Algorithm 1 is optimal. Let T be the time after which all faulty processes have crashed. Then after T and by Lemma 5, whenever the links become timely for any finite time the set of links sending heartbeat messages will be either  if process  is correct or  if  is faulty.

7. Decisive problems
In this section, we discuss what happens to deterministic algorithms using  to solve decisive problems, e.g., consensus, when put in  which provides ⁎ guarantees instead (we give examples of decisive problems beyond consensus in Section 7.2).

Definition 3

A decisive problem is a problem which can be solved when a single irrevocable global decision is reached. Any decisive problem P requires that both of the following two properties are satisfied: (i) Termination: there is a point in time after which every correct process will have decided and (ii) Integrity: No process can decide more than once.

Clearly consensus is one such problem, as the consensus abstraction guarantees: (i) Validity: A value decided is a value proposed, (ii) Integrity: No process decides more than once, (iii) Agreement: No two processes decide differently and (iv) Termination: there is a point in time after which all correct processes would have decided. For illustration, we first focus on consensus, then we discuss decisive problems.

7.1. Consensus with ⁎
We first show, for an exemplary existing consensus algorithm, that ⁎ can replace : the result would be solving “consensus with probability 1”, in system . Then we present a general form of this result.

A Rotating Coordinator Algorithm. The basic idea behind the rotating coordinator algorithm of [2] is that processes alternate in a role of “leader” until one of them succeeds in imposing a decision. The algorithm assumes a correct majority and uses two abstractions: (i) reliable links and (ii) reliable broadcast. Both reliable links and reliable broadcast can be implemented in our system  (in the sense specified in Section 3).

The algorithm is round-based, i.e., the processes move incrementally from one round to the other. Process  is the “leader” of every round . In such a round, process  does the following: (i)  selects among a majority the latest adopted value (latest w.r.t. round), (ii)  sends that value to all processes and waits for the acknowledgment of the majority and (iii) once  succeeds in imposing that value on a majority,  uses reliable broadcast to send its decision to all and decides. It is important to note that  succeeds if it is not suspected by the majority (processes that suspect  inform  and move to the next round, including ).

Theorem 6

The algorithm of [2] implements “consensus with probability 1” in  using ⁎ (instead of ).

Proof

It is easy to see that ⁎ guarantees the strong completeness of  and that the reliable links and reliable broadcast in system  (see Section 3) guarantee respectively the properties of the reliable links and reliable broadcast depicted in [2]. Thus the proof of correctness provided in [2] remains true, except for the parts relying on the accuracy of , namely termination. Thus it is sufficient to prove that the accuracy of ⁎ guarantees that all processes decide.

Consider  to be any point in time after all faulty processes have crashed. Since the algorithm of [2] operates in asynchronous rounds, then at time  processes might be at different rounds. We denote by r the largest round among all processes at time  and by  the maximum difference between the rounds of the processes at time . Note that from [2], , n being the total number of processes in the system.

In the algorithm of [2], after time , a process, be it a leader or not, completes a round when a bounded number of messages (unicast or broadcast messages) is sent/received or when it suspects the leader of that round. Let M be the maximum number of messages for a process to complete a round. Let  be the amount time for exchanging the M messages, such that the probability of exchanging M messages in  time slots is positive (the properties of reliable links and reliable broadcast primitive defined in Section 3 guarantee the existence of such a ). Recall that the accuracy of ⁎ guarantees that with probability 1 the following holds: for any finite duration Δt, there exists infinitely many time instants  such that some correct process, say q, is not suspected by all correct processes for the interval .

Consider now  to be the round in which q becomes the leader. Thus with positive probability, all processes can reach round  after  time slots from . If q is not suspected by any of the processes, then with positive probability every process decides after  time slots from reaching round . In other words, if process q is not suspected by any correct process in the interval , then there is a positive probability that all processes decide.

Since  is any point in time, after all processes have crashed, then we can assume , such that . By the accuracy of ⁎, with probability 1: there exists infinitely many  time instants (after all faulty processes have crashed) such that process q is not suspected by all correct processes for the interval . Since there is a positive probability of all processes deciding in time slots after  and there are infinitely many  time instants, then with probability 1 we have the following: there is a point in time after which all correct processes would have decided.

Definition 4

An asynchronous algorithm  that solves a decisive problem P is said to be -bounded if  satisfies the following properties:

1.
 uses as external blocks only the failure detector  and communication primitives implementable in , such as reliable links and reliable broadcast (see specification in Section 3).

2.
Consider that there exists a point in time, , after which some correct process is never suspected by all correct processes. Then  needs a bounded number of messages to be sent after  and until P is solved (i.e., all correct processes decide).

In fact many of the consensus algorithms using  in the literature are -bounded. This makes our results applicable to wide range of existing algorithms.
Theorem 7

Any asynchronous algorithm that uses  to solve consensus and is -bounded, solves “consensus with probability 1” in  when using ⁎ instead.

Proof can be seen for the more general result of Theorem 8.

7.2. Decisive problems with ⁎
Now we generalize the result of Theorem 7 for decisive problems in general.

Theorem 8

Any asynchronous algorithm  that uses  to solve a decisive problem P and is -bounded, solves “P with probability 1” in , when ⁎ is used instead.8

Proof

⁎ guarantees the strong completeness of . Thus w.r.t. , the difference between ⁎ and  is in the provided accuracy property. The accuracy of  is a property which holds at some unknown point in time. As a result, any algorithm  that solves a decisive problem P using , guarantees all safety properties required by P regardless of the accuracy of ⁎.  hence uses the accuracy of  to guarantee liveness, in particular termination, i.e., there is a time after which all correct processes decide. It thus suffices to prove that with respect to  and with probability 1 the following is satisfied: the accuracy of ⁎ guarantees that there is a point in time after which all processes decide.

Assume the existence of an external clock (not accessible but merely used as a reference to clarify the proof construction). Let  denote the time instant at which  starts executing. Using  in  to solve P implies that after  there is a time when all processes decide and P is solved (see Definition 3). Precisely, after time  (the point in time when all faulty processes have crashed and some correct process is never suspected by all correct processes), all correct processes executing  should exchange a finite bounded number of messages after which P would be solved. Let M denote the upper bound on the number of messages (be them uni-casts or broadcasts) sent by  from time  and until P is solved. All events that could occur have a bounded delay (process speeds, crash detection, etc.), except for reliable message transmissions (be them uni-casts or broadcasts). Using communication primitives as the reliable links and reliable broadcast in , the delay for delivering a single message may be arbitrarily long. However it is possible, with positive probability, that a message gets delivered after a known fixed delay, e.g., in x time slots after being sent (see reliable transmission Section 3). Thus and without loss of generality, at any point in time where some correct process in never suspected by all correct processes (and after all faulty processes have crashed), it is possible (with positive probability) for the M messages to be exchanged within a known fixed duration, say , after which all processes would have decided.

From Definition 1, the accuracy of ⁎ guarantees with probability 1 that: there exists (after all faulty processes have crashed) infinitely many time instants  after which a unique correct process is not suspected by any correct process for the interval . Since there are infinitely many such  time instants and at each  there is a positive probability for the M messages to be exchanged within , then with probability 1 the following happens: there is a time after which all processes would have decided within  time slots and thus P would be solved.

Other Decisive Problems. Besides consensus, there can be many other decisive problems, e.g., non-blocking atomic commit (NBAC), k−set agreement, fast consensus. Some of these decisive problems, such as NBAC, are solved using . In Section 8 we show that it is possible to formulate ⁎, a variant of . We also show in Section 8 that Theorem 8 can be extended to the set of decisive problems solvable with ⋄P when replaced by ⁎, thus covering a wider set of problems, besides consensus.
8. Other probabilistic failure detectors
We now study the possibility of implementing probabilistic and temporal variants of other failure detector classes that noticeably simplify the design of distributed algorithms. We precisely study perfect failure detectors () and eventually perfect failure detectors ().

8.1. Perfect failure detectors
A perfect failure detector module, , guarantees in addition to strong completeness, the strong accuracy property, which says that no process is suspected before it crashes. Distributed algorithms, specifically those solving consensus, using  are easy to design due to their implicit reliance on the strong accuracy property of  to guarantee some safety property [55]. The liveness of such algorithms typically relies on the strong completeness. It is important to note that on the contrary consensus algorithms based on unreliable failure detectors [2] usually rely on the eventual accuracy to guarantee liveness of the algorithm. We thus define ⁎, a probabilistic variant of , as follows.

Definition 5

The failure detector ⁎ guarantees strong accuracy and probabilistic strong completeness, where the latter can be formally defined as:

Probabilistic Strong Completeness: Eventually every process that crashes is suspected, with positive probability, by every correct process.

Theorem 9

It is impossible to implement the failure detector ⁎ in , even if at most one process can fail.

Proof

Consider a network of  processes,  and , and the following executions:

e1.
an execution where process  fails at time t.

e2.
an execution where processes  and  are both correct but get partitioned at time t.

By the probabilistic strong completeness there is a time after which  in execution e1 has a positive probability of suspecting . Executions e1 and e2 can be indistinguishable to  for any finite duration after t. Accordingly there is a time where  has a positive probability of suspecting  in execution e2. By the strong accuracy property of ⁎ a correct process is never suspected. Thus the probability of  suspecting  in e2 should be 0 at all times, a contradiction concluding the proof.
8.2. Eventual perfect failure detectors
We now define a probabilistic variant ⁎ of the eventual perfect failure detector .

Definition 6

Failure detector ⁎ guarantees: (i) strong bounded completeness and (ii) probabilistic eventual strong accuracy: Consider any finite duration Δt. With probability 1 the following occurs: there exists infinitely many time instants , such that after each all correct processes are not suspected by any correct process for the interval .

Theorem 10

It is possible to implement ⁎, in , even if  processes can crash.

Proof

The proof is similar to that of Theorem 2. Following from Lemma 3, if all correct processes broadcast messages forever (send an infinite number of messages), then with probability 1, the following will be observed: any finite number of consecutive messages, e.g., Δt messages, is successfully transmitted, i.e., with no losses.

As such, an algorithm which satisfies both characteristics below for example implements ⁎:

1.
All processes periodically (say with period  chosen arbitrarily) broadcast messages forever.

2.
Process  suspects another process  only if  receives no message form  for a period strictly greater than .

9. ⁎ algorithms for decisive problems
Since Section 7 shows that the ⁎ failure detector can be indeed implemented in systems like , we extend in this section Theorem 8 for the set of algorithms that solve decisive problems using ⋄P. First we recall the definitions of ⋄P and ⁎.

Failure detector  guarantees: (i) strong completeness and (ii) eventual strong accuracy: There exists a time after which all correct processes are never suspected by any correct process.

Failure detector ⁎ guarantees: (i) strong bounded completeness and (ii) probabilistic eventual strong accuracy: Consider any finite duration Δt. With positive probability, all correct processes are not suspected by any correct process for the interval , .

Definition 7

An asynchronous algorithm  that solves a decisive problem P is said to be -bounded if it satisfies the following properties:

1.
 uses as external blocks only the failure detector  and communication primitives implementable in , such as reliable links and reliable broadcast (see specification in Section 3).

2.
Assume that there exists a point in time  when all correct processes are never suspected by any correct process. Then  needs a bounded number of messages to be sent after  and until P is solved (i.e., all correct processes decide).

Theorem 11

Any algorithm  that uses  to solve a decisive problem P and is -bounded, solves P in  guaranteeing termination (i.e., all processes decide) with probability 1, when ⁎ is used instead.

Proof

We follow similar steps as those adopted in the proof of Theorem 8.

⁎ provides (in a stronger form) strong completeness as . It thus suffices to prove that with respect to  and with probability 1 the following is satisfied: ⁎ provides the same accuracy as .

Assume the existence of an external clock. This clock is not accessible but merely used as a reference to clarify the proof construction. Let  denote the time instant at which  starts executing. Using  in  to solve P implies that after  there is a time when all processes decide and P is solved (see Definition 3). Precisely, after the time when all correct processes are never suspected by any correct process, all correct processes executing  should exchange a finite bounded number of messages after which P would be solved. Let M denote the upper bound on the number of messages (be them uni-casts or broadcasts) needed by  from the time all correct processes are never suspected by any correct process until P is solved. All events that could occur after  have a bounded delay (process speeds, crash detection, etc.), except for reliable message transmissions (be them uni-casts or broadcasts). Using communication primitives as the reliable links and reliable broadcast in , the delay for delivering a single message may be arbitrarily long. However it is possible, with positive probability, that a message gets delivered after a known fixed delay, e.g., x time slots of being sent, at any time instant at which it might be sent (see specifications of reliable transmission Section 3). Thus and without loss of generality it is possible (with positive probability) for the M messages to be exchanged within a known fixed duration, say , after which all processes would have decided and thus P would be solved.

Therefore, P can be solved with ⁎ if we prove that ⁎ can with probability 1 provide the following: there is some time instant  after which all correct processes are not suspected by any correct process for the interval . From Section 8, the accuracy of ⁎ guarantees that: with positive probability, all correct processes are not suspected by any correct process for the interval , . Since this holds for every , then ⁎ can with probability 1 provide that: there is some time instant  after which all correct processes are not suspected by any correct process for the interval .

10. Concluding remarks
We investigated failure detection in systems embodying asynchrony via probabilistic synchronous communication. In contrast to the conventional distributed computing assumptions when building failure detectors, which hinged on link synchrony guarantees that need to hold deterministically forever, we adopted a more realistic link behavior motivated by networking views on actual packet loss. We show that “ with probability 1” cannot be implemented given such link behavior ( being established as the weakest failure detector to implement consensus), despite the fact that “consensus with probability 1” can be implemented without requiring any randomness in the algorithm itself. We accordingly refine the notion of failure detectors defining ⁎ which does not require any “forever” guarantee from the underlying network. We show that ⁎ can be implemented in system  and even efficiently. In addition, we show that ⁎ can replace  in several deterministic consensus algorithm and yields an algorithm that solves “consensus with probability 1”. We also generalize this result to encompass a more general set of problems and failure detectors.

Limitations and future directions. Despite being able to solve “consensus with probability 1” without requiring failure detection properties to provide any forever guarantees, the solution presented in this paper is not a sliver bullet. Namely, the new failure detector definitions do not provide any performance guarantees regarding latency for the algorithms using them, as our failure detector convergence depends on how fast the underlying network provides the required stable periods. One way to mitigate this issue, would be to have a proper understanding of the network's ability to frequently adhere to desirable stable periods when designing consensus algorithms. Some potential future directions work may investigate the weakest probabilistic system to implement ⁎ or the solvability of problems, besides the decisive set, using our new notion of failure detectors, in an attempt to increase the applicability of our results.

CRediT authorship contribution statement
Rachid Guerraoui: Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – review & editing. David Kozhaya: Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – review & editing. Yvonne-Anne Pignolet: Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Software, Supervision, Validation, Visualization, Writing – original draft, Writing – review & editing.