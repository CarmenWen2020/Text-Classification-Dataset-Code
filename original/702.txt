Abstract
Modern virtualized data centers often rely on virtual machine (VM) migrations to consolidate workload on a single machine for energy saving. But VM migrations have many drawbacks, including performance degradation, service disruption etc. Hence, many approaches have been proposed to minimize the overhead when migrations occur. In contrast, this work aims to proactively avoid migrations from happening in the first place. We have proposed a novel consolidation aware scheduling algorithm to minimize the number of migrations for batch processing systems by taking advantage of the prior knowledge of consolidation strategy and job information. We show the problem can be formulated as an integer linear programming (ILP) problem, and an effective heuristic solution can be found by a genetic algorithm. Both real and synthetic workload traces were used to evaluate our methods. Experimental results showed that, after comparing with two popular job scheduling algorithms, our approach has reduced the number of migrations by more than 25%.

Previous
Next 
Keywords
Virtual machine

Consolidation

Migration

Genetic algorithm

Data center

1. Introduction
Data centers have become the essential computing infrastructure to drive the modern digitized economy across all industries. But the fast growing number and the scale of data centers also raise high energy consumption problems. According to the 2016 United States Data Center Energy Usage Report [31], the data centers in U.S. accounted for 70 billion kilowatt hours of electricity consumption in 2014. That is around 1.8% of the total U.S. consumption or equivalent to the amount consumed by about 6.4 million average American homes that year. Hence building green data centers with higher energy efficiency is a necessary mean to address many urgent needs, including environmental protection, operation cost reduction, and computing performance per watt improvement.

One of the key factors for causing low energy efficiency is the inefficient resource utilization of data centers [5]. Due to the dynamic nature of computing workload, data centers provide resources according to the peak demand. As a result, many studies [2] have indicated that the average resource utilization of a data center is only between 10% to 50%, while an idle server could consume energy as high as a 50% fully utilized server [9]. To address this issue, many modern data centers have been virtualized by employing virtualization techniques to host user applications and jobs in a virtual machine (VM). A server virtualization technique, like KVM, allows the resource allocation of a VM to be configured according to the workload, and enables a VM to be migrated freely among physical machines (PMs) at runtime. Hence multiple VMs can be packed on a single PM to let the PM run in a more energy efficient condition, and under-utilized PMs can be turned-off during the off-peak hours for energy saving. This energy management technique is called VM consolidation, and it is an effective and widely used approach to improve the energy efficiency of data centers. However, applying VM consolidation comes with a price that is the negative impacts from VM migrations, such as performance degradation [7], [19] and service disruption [24], [49] of applications, additional resource consumption [34], [41] and the risk of failure to its hosted applications [17]. Therefore, minimizing the overhead of VM migrations during consolidation has drawn increasing interests.

While live migration techniques [11], [15], [24] are available to reduce migration time by minimizing the memory footprint of VM, they cannot avoid VM migrations from happening. Hence, most recent consolidation strategies [16], [18], [32], [39] have aimed to minimize energy (the number of active PMs) and VM migrations cost at the same time. However, all these approaches assume workload variations are unpredictable, so they only attempt to find the best VM placement under the current system workload, and the VM migration cost is modeled as the differences between the VM placements before and after a consolidation action occurs. We call them “reactive” consolidation aware strategies, because their goal is to minimize the migration cost from the current consolidation action without considering how to avoid migrations in the future. As a result, when a VM is migrated to a soon-to-be-inactive PM, the VM might be forced to be migrated again. Therefore, in contrast to previous work, we made a first attempt to propose a proactive approach that can avoid VM migrations over future time intervals.

Indeed, without prior knowledge of the system workload, it is difficult to avoid VM migrations. Hence, in this work, we address our problem on batch processing systems [13], [20], like the HPC (High Performance Computing) systems [19] or in Map Reduce production clusters [37]. These systems often exhibit periodic workload patterns, and the job execution time is given by users during job submission. Therefore, we believe these prior workload information can be used to design a proactive approach for minimizing VM migrations. The intuition of our approach is to schedule a job on a machine that will remain active throughout the job execution time, so possible VM migration can be avoided. To achieve that, we first use a semi-static consolidation strategy to determine the number of active machines according to the periodic workload variation pattern. Then we design a consolidation aware scheduling algorithm that schedules jobs to machines based on the future machine turn-on/off time and remaining job execution time. To the best of our knowledge, we are the first to propose consolidation aware scheduling algorithm for minimizing VM migrations in batch processing systems.

Our main contributions are:

•
we recognize the importance of co-design between consolidation and scheduling in batch processing systems. With prior knowledge of the machine turn-on/off time, we design a scheduling algorithm to avoid future VM migrations.

•
our scheduling algorithm aims to minimize the number of VM migrations over future scheduling intervals, while previous approaches only reduce the migration cost of current consolidation action.

•
we formulate our consolidation aware scheduling problem as an integer programming optimization problem and construct a genetic algorithm to find a near optimal solution. Therefore, our approach is called MIRAGE, which stands for {Mi}g{r}ation {A}voidance {Ge}netic algorithm.

•
Furthermore in order to demonstrate the efficiency of our approach, we have compared our algorithm with two efficient job scheduling algorithms [8], [46]. Our experimental results show that our algorithm outperforms these scheduling algorithms with 25% fewer VM migrations. Even comparing to our previously proposed consolidation aware greedy scheduling algorithm [38], MIRAGE still can reduce the number of VM migrations by more than 33%.

The remaining paper is constructed as follows. Related work is given in Section 2 and Section 3 describes the consolidation aware scheduling problem and defines our ILP (Integer Linear Programming) formulation. Section 4 introduces our proposed MIRAGE algorithm. The experimental setup and results are presented in Section 5 and Section 6, respectively. Finally the paper is concluded in Section 7.

2. Related work
2.1. Migration aware VM consolidation
There are some works that have extended their VM consolidation strategies to be migration aware. For dynamic consolidation strategies, VM migrations are triggered according to the monitoring workload on a machine when the workload is too low or too high. As a result, VM migrations could occur at anytime, but their decisions only need to be made on one machine at a time. Therefore, dynamic consolidation strategies [3], [14], [43] could be easily extended to be migration aware by choosing the migration move with the minimum cost when consolidation is triggered according to a cost model in terms of migration time, VM size, and network bandwidth, etc. [8] has proposed a dynamic consolidation strategy by using Ant Colony Optimization technique for reducing migration and energy consumption. However, because dynamic consolidations can only react to migration requests, they can only minimize the cost of each migration [46] but not the number of migrations. So it is difficult to reduce the migration degradation of dynamic consolidations in general. Moreover Verma et al. [40] have done extensive analysis that dynamic consolidation does not provide significant savings in resource and energy, specially when the workload has high memory contention. They have come to a conclusion that an intelligent semi-static consolidation can perform better than dynamic consolidation in this case.

Semi-static strategies only perform consolidations periodically. So they often assume the VM workload variations are stable or stochastic, and decide the placements of all the VMs simultaneously by formulating the problem as an optimization problem, like bin-packing, to minimize the number of active servers. Therefore, a considerable number of semi-static consolidation strategies have extended their work by introducing migration cost as part of their optimization objective functions and adjusting their greedy algorithms. For instance, [16] aimed to maximize the ratio between the energy saving and the performance slowdown from a VM migration, and [39] aimed to minimize both the power consumption and number of migrations. [18] formulated the placement decision as a Class Constrained Multiple-Knapsack Problem and prioritized the objectives of minimizing energy ahead of minimizing the number of migrations. [32] formulated the problem as a Variable Item Size Bin Packing for handling multi-dimensional resource constraints, and a proof is given to show the number of VM migrations from their greedy algorithm can be bounded.

Aforementioned consolidation strategies were all discussed for data centers with persistent workloads where VMs are essentially applications that run for a long period of time (i.e., weeks or even months), like a web server. In contrast, our work targets on batch processing systems running in virtualized data center where VMs are short living jobs which arrive and depart systems continuously. Although batch processing systems are widely used for offline processing of large volume of data [13], [20], [37], only a few papers have discussed the consolidation and job scheduling strategy for such systems. [48] is one of them, which models a data center as a queuing system, so that queuing theory can be applied to determine the minimum active servers that is needed to maintain a desired job waiting time. On the other hand, [10] proposed a job scheduling algorithm for virtualized clusters where Dynamic Voltage/Frequency Scaling (DVFS) is used for energy saving. Our work is the first job scheduling approach that is designed for batch processing systems by coupling both consolidation and scheduling strategy in order to reduce VM migrations.

2.2. VM live migration
VM can be either migrated offline or online. The offline migration requires VM to be shutdown at the source location and restarted at the target location. In contrast, online migration, also called live migration, allows VM to be moved between different physical machines without disconnecting the client or application. Hence, studies [7] have shown that live migration can significantly reduce the cost of VM migration in terms of the total migration time and application downtime. In particularly, various live migration techniques [11], [15], [24] have been developed to further reduce the migration cost by minimizing the memory pages that need to be transferred during migrations. Many works [1], [22], [33], [41], [45], [50] have also been done to model and characterize the cost of VM migrations (i.e., mostly live migration). In general, they all claimed the migration time can be modeled by the memory size of VM, the dirty page rate, and the network bandwidth. In addition, [50] studied the overheads of migrating multiple VM simultaneously, and [33] modeled the energy consumption of VM migration as well. All these works focused on minimizing the cost of a single migration operation, while our work aims to reduce the migration impact from the overall system performance perspective.

2.3. Genetic algorithm for scheduling
Most job scheduling problems are known to be NP-complete. Genetic algorithm is one of the most popular heuristic technique to obtain near optimal solutions. There are several works [6], [12], [27] that have used genetic algorithms to achieve promising results in a scheduling problem. Hamidinia et al. [12] have used genetic algorithms for scheduling jobs in batch delivery systems. They generated the initial population randomly and then top-k chromosomes are selected for a one-point crossover and dynamic mutation operation to generate new offspring. Chaudhry et al. [6] have used a order crossover operation for scheduling multiple jobs in parallel machines. They found that genetic algorithms perform considerably better than traditional branch and bound algorithms. On the other hand [27] did an analysis of multiple crossover and mutation techniques for open-shop scheduling problem. In their problem, they found that two-point crossover and displacement mutation operations give the best results.

The convergence time to find the global optimum for a genetic algorithm has even been discussed extensively in the literature. Although some studies [28], [47] state that stochastic randomized algorithms like random walk Markov Chain Monte Carlo (rw-MCMC) or Metropolis–Hastings search(MHS) can have faster convergence time than genetic algorithms, but rw-MCMC or MHS [28] are local search algorithms that can have solutions getting trapped in local optima and moreover they do not perform well with discrete parameters too [25]. Moreover there are some works [21] that have used a combination of local and global optimization algorithms, involving MCMC and genetic algorithms in order to converge faster but we will pursue this further in our future work. We have chosen genetic algorithm as our approach since we have discrete parameters in our fitness function and moreover it has been proven to converge to global optimum in scheduling problems with discrete parameters [4], [42]. Genetic algorithms even produce high-quality solutions when the problem space is large and contains a large number of parameters. In this work, we consider job scheduling problem on a data center for batch processing systems, and our goal is to minimize the number of VM migrations across future time intervals.

3. Consolidation aware job scheduling problem
3.1. System model
In this work, we consider a consolidation aware job scheduling problem in a virtualized data center for running batch processing jobs which is one of main workloads from many application domains, such as data analytic and scientific computing. We describe how the resource management and energy management are controlled by a job scheduler and a semi-static consolidation strategy in our system model as follows.

A key resource management component in a batch processing system is its job scheduler. A job scheduler is responsible for allocating the resource requested by jobs and dispatching them to compute nodes for execution. Different models could be considered to virtualize a batch processing system. In this work, we consider one of the most commonly seen approach that is to encapsulate each job into an individual VM. In such an environment, jobs and VMs can be seen as equal which means that VMs are dynamically provisioned according to the job resource requirements, and VMs have the same life time as their corresponding jobs. Hence, a scheduler simply manages resource allocations by dispatching VMs instead of jobs. The terms job and VM are also used interchangeably in the rest of paper.

Many studies [29], [48] have shown that data centers often exhibit rather stable and periodic workload patterns over a longer period of time, such as a day or a week. Hence, we assume that a semi-static consolidation strategy is applied in our system model to predetermine the number of active PMs per scheduling interval according to the periodic workload patterns of a virtualized data center. For instance, Fig. 1 is the workload patterns of a batch processing systems called LLNL Atlas. We can observe that the workload over two different days has a similar pattern where peak loads occur at noon, and off-peak loads occur at midnight. Hence, a semi-static consolidation strategy can pre-determine the number of turn-on machines for each hour to ensure the available capacity is more than the workload demand as indicated by the brown line in the plot. Therefore, the turn-on/off time of each PMs can be known in advance.


Download : Download high-res image (134KB)
Download : Download full-size image
Fig. 1. LLNL Atlas Workload Pattern.

3.2. Scheduling example
Here we use an example in Fig. 2 to illustrate how job scheduling decisions can impact the number of VM migrations under our system model. In the example, there are 5 jobs hosted in VMs ({VM1, , VM5}) that needs to be scheduled in a system with 3 PMs ({PM1, PM2, PM3}). We use the number of CPUs to denote computing capacity of PMs, and the capacity units of PMs can be varied. Each job requests a number of CPUs, and its arrival time and execution time is indicated by AT and ET as shown in Fig. 2(a). For instance, job VM1 arrives at time 0, requests 2 CPUs and executes for 3 time units. A semi-static consolidation strategy is applied to the system to pre-determine the turn-off time of each PM, and as a result PM1 never turns off, but PM2 turns off at time 6 and PM3 turns off at time 3.


Download : Download high-res image (412KB)
Download : Download full-size image
Fig. 2. Comparison of the number of migrations between different scheduling results.

Fig. 2(b)(d) shows the VM placements and compares the number of VM migrations under three different scheduling algorithms: random, greedy, and optimal. The random algorithm is unaware of the PM turn-off time and arbitrarily places jobs on PMs when they arrive. The heuristic algorithm, proposed in our previous work [38], places a job to the available PM whose turn-off time is closer but no earlier than the job termination time (i.e., AT + ET). The intuition behind it is we can prevent a VM from migrating if the PM turns off after the VM terminates. Finally, the optimal algorithm is the desired solution resulting in the minimum number of VM migrations.

Both the random and greedy algorithms schedule jobs in First In First Out order. Moreover they migrate the jobs between PMs only when their hosted PMs are turned off. These migrations are indicated by the red arrows in the figure. Take the random algorithm in Fig. 2(b) as an example, VM2 has to be migrated from PM3 to PM2 when PM3 is turned off at time 3. Similarly, when PM2 is turned off, it forces both VM4 and VM5 to be migrated from PM2 and PM1 at time 6. As shown by the results, random scheduling causes 3 migrations, and greedy scheduling causes 1 migration. But, there exists an optimal scheduling decision that can avoid all migrations from happening as shown in Fig. 2(c).

From the example, some key observations can be seen as below. (1) Scheduling can significantly affect the number of VM migrations. (2) By taking advantage of the prior knowledge of PM turn off time, the greedy algorithm shows that a co-design between consolidation strategy and scheduling can effectively reduce the number of VM migrations. (3) The number of VM migrations could be further minimized if we have knowledge of all the arriving jobs. For example, the greedy scheduling algorithm cannot avoid VM5 from migration because it is unaware of the arrival jobs VM3VM5 when VM2 is scheduled. As a consequence, VM5 is forced to be executed on PM2 and migrated at time 6. Therefore, the goal of our work is to find an optimal scheduler for minimizing VM migrations of a given set of jobs.

3.3. ILP formulation
We formally formulate our consolidation aware job scheduling problem as an ILP problem in this section. The variables used in our formulation are summarized in Table 1.


Table 1. Notations in the scheduling problem formulation.

A set of physical machines.
A set of virtual machines.
A set of resource types on PMs,
such as computing capacity, memory size, storage space.
The capacity of a resource type  on PM .
The demand of a resource type  from VM .
 is the job arrival time of VM .
 is the job end time of VM .
 where	 represents scheduling intervals.
The th scheduling interval is from time  to .
 is the number of scheduling intervals.
 where	 is a consolidation strategy
 if PM  is active in scheduling interval 
Otherwise, .
 where	 is a scheduling strategy
, if VM  is executed on PM 
in scheduling interval .
Otherwise, .
Let  be a set of physical machines (PMs).  denotes a set of resource types on PMs, including computing power, memory size, storage space, etc.  is the capacity of a resource type  on PM . Similarly, let  be a set of jobs/VMs that needs to be scheduled to the PMs . The usage demand of a resource type  from VM  is denoted by 
. We use  and  to denote the set of start time and end time of VMs, where 
 and 
 are the start time and end time of a VM 
, respectively.

In a batch processing system, scheduling decisions only need to be made when a job arrives or a job leaves. Therefore, we use  to represent the set of time intervals for scheduling. Specifically,  is an increasing sequence of time that contains the union of start time and end time of all jobs, so that a scheduling interval  is from time 
 to 
. In other words, there will a total of  scheduling intervals, where  is  (i.e., ). Accordingly, a scheduling decision must be made at the starting time of each scheduling interval to reconfigure the mappings between PMs and VMs. Take the scheduling problem in Fig. 2 as an example, we have , and , which means there are only 7 scheduling intervals for 5 jobs, and scheduling decisions are made at each of the time 
.

In each scheduling interval , we use boolean variables 
 and 
 to denote the decisions of consolidation and scheduling during the scheduling interval. Consolidation strategies determine the number of active machines in each scheduling interval. Hence, if a consolidation strategy  decides a machine 
 should be active during scheduling interval , then 
; otherwise 
. On the other hand, scheduling strategies decide the mapping between VMs and PMs. Hence, if a scheduling strategy  decides to schedule VM 
 to PM 
 in scheduling interval , then 
; otherwise 
.

As mentioned in Section 3.1, we assume the system has applied a consolidation strategy to determine the number of active PMs in each scheduling interval according to the aggregated resource capacity demand from VMs. Therefore, in our problem formulation, the values of 
 are given as problem inputs, and our goal is to find a scheduling strategy , so that the number of migrations across scheduling intervals can be minimized. The complete ILP formulation is given as follows: (1)
 In subject to (2)
(3)
 (4)

Our objective function in Eq. (1) maximizes the number of scheduling intervals without VM migrations. This is the same as minimizing the number of VM migrations because the total number of intervals with VM execution is a constant value. A VM is not migrated if it is placed on the same PM for consecutive scheduling intervals. Therefore, a VM 
 on PM 
 is not migrated at scheduling interval , if and only if 
.

The optimization is subjected to several constraints as follows. Eq. (2) ensures that the resource usage of a PM cannot exceed its resource capacity. This resource capacity constraint must be applied to any PM 
, any resource type , and any scheduling interval . Noted, the usable resource capacity of a PM, 
, is multiplied by the status of the machine, 
, because a non-active PM should not have any usable resource capacity. Eq. (3) forces each VM 
 to be placed on exactly one PM during each scheduling interval. Finally, Eq. (4) ensure 
 is a binary variable.

4. MIRAGE:migration avoidance genetic algorithm
The problem formulated in the previous section is NP-hard. Hence, we construct a genetic algorithm as a heuristic solution to solve this problem. A genetic algorithm is an optimization technique that tries to follow a natural biological process in order to find the strongest individuals from a population of individuals. It is used to find near optimal solutions for complex problems, when we have a large problem space and a greater number of variables. Genetic algorithm initially starts with a population of random individuals, where each individual represents a solution. Then the algorithm improves these individuals to be a better solution by using genetic operators in each population generation. The larger the population, the better solution a genetic algorithm can return. In fact the population size and number of generations are important parameters of a genetic algorithm [47] and hence we have carefully determined the value of these parameters through experimentation. At last when the terminating condition is reached, a genetic algorithm returns the top ranked solution with the help of a fitness function.

It is important to ensure that we do not lose our good individuals upon generation of a new population. And hence we adopt the process of elitism in this paper. Elitism is the transferring of best individuals across populations. Furthermore, it is proven that elitism selection of individuals from a population helps to converge faster to a global solution [30], [42] and hence we have even adopted a similar approach in our algorithm. The elitist chromosomes when subjected to crossover and mutation will produce good quality offspring. This will eventually lead to genetic convergence, where the computation time of the genetic algorithm will reduce ultimately.

The basic steps of a genetic algorithm are an iterative process as shown in Fig. 3. For better understanding, each step in the figure is referenced to a section of our algorithm. After we generate random initial population, the iteration begins by evaluating the fitness function of each individual or a chromosome. Eq. (1) is our fitness function and its objective is to reduce the number of migrations. Our fitness function represents the number of VM migrations that has not occurred for a chromosome in the population and hence we intend to maximize it. Thus, our fitness function will help us to find an optimal VM-to-PM mapping solution which gives us the least number of migrations. If the total number of generations is equal to our terminating condition, it outputs the final result. Otherwise we select the best two individuals from our current population and apply the crossover operation to it. Mutation is even applied to some individuals in the population to generate further randomness in it. This type of genetic operators helps to generate better offspring from their fittest chromosomes and it even ensures that the best solution is not stuck in local optima.

We have discussed in detail about our genetic algorithm in the upcoming sections. In Section 4.1, we have explained the encoding structure of our genetic algorithm, i.e. the structure of our chromosome. In Section 4.2 we have described our random heuristic algorithm for generating the initial population. Section 4.3 and  4.4 describe our crossover and mutation operators. In Section 4.5 we have described our repair function which will try to repair the chromosomes from excessive migrations due to crossover and mutation.

4.1. Chromosome
A chromosome represents the placement decision of a VM on a PM at scheduling interval . A chromosome can give us the most favorable placements of all the VMs where the overall number of migrations is less. We first need to propose an encoding scheme which represents each chromosome or individual in our solution space. A chromosome consists of genes and in our problem each gene 
 is encoded as a two-dimensional matrix representation of  rows and  columns. The  PMs are represented in  rows and  VMs are represented in  columns. Each gene represents a scheduling decision at scheduling interval . Each element of the array 
 is represented as 
, which is a binary value that represents if a VM 
 is allocated to PM 
 at scheduling interval . Each gene is represented as shown below:- 
 
A chromosome 
 is a collection of these genes as shown below. In our paper we have opted for this kind of encoding structure because we believe this is an efficient way to represent the placement mappings of VMs on PMs with respect to time. Simply put at any scheduling interval , we can know the placement status of a VM on a PM and if there has been a migration for that VM. 
 

4.2. Initial population generation
The genetic algorithm starts with an initial population of scheduling solutions. We generate a set of scheduling solutions in the initial population using a random scheduling algorithm shown in Algorithm 1. First, in Line 1, we define a variable 
 to keep track of the resource usage status on PM 
 at scheduling interval  for any resource type . No VMs have been placed on PMs at the beginning, so all the values of  is set to 0 in Line 2. From Line 3 to 18, we iteratively place each VM to PMs. For each VM 
, we randomly select a PM 
 as its initial hosting PM in Line 4. Then we attempt to keep scheduling 
 on 
 throughout its execution time as long as 
 is active and has sufficient resource capacity to host 
 as shown in Lines 8 to 13. If the current hosting PM 
 cannot host 
, we randomly select the next hosting PM in Line 15. Therefore, our algorithm can generate a random but also valid scheduling solution  at the end. Finally, in Line 19, we convert the scheduling solution  into the representation form of a chromosome. As explained in the previous subsection, each gene in our chromosome has a value of 
, and it is same as the value of 
 in .


Download : Download high-res image (716KB)
Download : Download full-size image
4.3. Crossover operation
Crossover is a genetic operator which accepts one or more parent chromosomes from the existing population and produces new child chromosomes in the new population. In our paper, the crossover function generates a new offspring in the new population from two selected parent chromosomes in the existing population. As shown in Algorithm 2, we adopted a two-point crossover [26] in this work. In Lines 1 and 2, we first decide the crossover points, which is the scheduling interval for the crossover operation to take place. Then in Lines 3–5, the segments of genes from the parents are selected and concatenated together to produce the new offspring chromosome 
. Since VM migrations are likely to occur at the crossover points, we attempt to reduce VM migrations at crossover point by calling the repair function in Lines 6 and 7. The details of repair function is explained later in Section 4.5.


Download : Download high-res image (396KB)
Download : Download full-size image

Download : Download high-res image (385KB)
Download : Download full-size image

Download : Download high-res image (727KB)
Download : Download full-size image
4.4. Mutation operation
Mutation introduces more randomness in the individuals to generate mutated offspring. We are optimistic that if we chose the candidates for mutation from the elitist chromosomes, we have more chances of producing good quality mutated children. In our algorithm 3,  is the mutation rate which states the total number of genes that is going to be mutated in the chromosome 
. That means a fraction () of the total number of genes in the selected chromosome 
 will be mutated. As shown in Line 1,  is the mutation point computed based on the mutation rate . We use Rand_VM_Placement algorithm to regenerate the values of genes before the mutation point  as shown in Line 3. Then we append the re-scheduled genes before  with the unchanged genes after  to produce the mutated chromosome 
. Similar to the crossover operations, unnecessary VM migration could occur at the mutation point, so we call the repair function at the mutation point as well.

4.5. Repair function
Crossover/mutation operations generate the genes (scheduling decisions) in their scheduling intervals independently. VM migrations are more likely to occur at the crossover/mutation points. Therefore, we design a repair function to reduce the VM migrations at the crossover/mutation points. As shown in Algorithm 4, the repair function simply attempts to move a VM to its hosting PM in the previous scheduling interval if possible. In Line 6, we first filter out the VMs that do not have executions across the crossover/mutation point . Then in Lines 9 and 10, we find the PMs that are hosting a VM before and after the crossover/mutation point. If the hosting PMs 
 and 
 are different, that means a VM migration has occurred. Hence, in Lines 13–18, we try to avoid this migration by moving 
 from 
 to 
 in the current scheduling interval as long as the previous hosting PM 
 is active and has sufficient resources to continue hosting VM 
. We repeat the above attempt for all the following scheduling intervals until the last scheduling interval of the VM. If VM 
 can move its hosting PM to 
 for all the scheduling intervals after the crossover/mutation point, a VM migration is avoided.

5. Experimental setup
In this section, we briefly explain our realistic workload traces and synthetic workload. In this paper, we have utilized two real workload traces which are PIK and LLNL Atlas workload. We have even generated a synthetic workload trace by using a publicly released synthetic generator [23]. We show the CDF trace and nature of all the workloads in this section. Let us begin with the explanation of the two real traces.

•
PIK: The PIK workload [35] is a collection of 3 years of data from Potsdam Institute for Climate Impact Research (PIK) in Germany. The cluster at PIK consisted of 320 IBM nodes. This trace includes execution of a set of jobs from April 2009 to July 2012. Each job in this trace has information about its arrival time, waiting time, execution time, required number of CPU cores, memory size and its status which states that if a job has been killed or completed during its execution. The execution time distribution of PIK workload is shown in Fig. 4. As you can observe from the figure, that only 22% of jobs run less than a minute. Most of the jobs are long-running jobs, i.e. almost 60% of them have execution time between 1 h to 25 h.

•
LLNL Atlas: The LLNL Atlas [36] trace is collected from a Linux cluster which is called Atlas and it is installed at Lawrence Livermore National Lab (LLNL) in United States of America. This cluster consisted of 1152 nodes and 9216 processors in total, with 8 processors per node. This real trace ranges from November 2006 to June 2007. Similar to PIK workload, each job in this trace even has similar information like arrival time, number of required processors etc. The execution time distribution of LLNL Atlas workload is shown in Fig. 5. In this trace, almost 75% jobs are shorter running jobs with execution time less than a minute. There are less than 10% jobs running more than one hour.

The reason for choosing two real workload traces is because of the difference in the nature of the jobs. The PIK trace has more longer running jobs and on the other side the LLNL Atlas log has more shorter running jobs. This kind of characteristic will have an impact in our experiment and this will be shown in our results in the next section.

The workload variation is uniform across days in LLNL Atlas trace. After analyzing the trace for two consecutive days as shown before in Fig. 1, we observed that the total number of physical machines required for two days of workload follows a similar pattern. The peak of both days of workload is mostly around noon and the traffic decreases as the day passes by. Since the variation of the workload is predictable, we can use our consolidation algorithm from our previous paper to calculate the turn-on/off time for all the PMs. Hence based on the workload pattern, the PMs can be reserved in advance.

We have even used a synthetic workload generator. This synthetic workload trace is used to further test our algorithm by customarily generating a set of jobs. Similarly as the information provided by the realistic traces, the synthetic trace even has arrival time, execution time and required number of processors. However, there is no information about the memory usage and hence we have assumed that each job gets allocated a fixed amount of memory. This assumption does not have any impact in our overall result.

The parameters used for synthetic workload generation is same as proposed by the authors [23] of the generator. The authors have used a Poisson distribution for setting the inter-arrival time of jobs, i.e. 30.8 s. The job execution time is generated by a hyper gamma distribution and we have observed that there are many shorter-running jobs in the generation. As used in the code, almost 25% of the jobs are serial that requests a single processor and the rest are parallel which request for multiple processors.

•
Best-Fit: It is a widely used consolidation oblivious job scheduling algorithm that aims to reduce resource fragmentation.

•
Time-Driven: It is a consolidation aware job scheduling algorithm previously proposed our work [38]. It is an online algorithm that does not have prior knowledge of the future jobs.

•
MVC (Migration Cost aware VM Consolidation): This is a scheduling algorithm [46] that aims to reduce the migration cost of VMs. It first sorts the PMs in increasing order of their resource capacities and then places the VM requests arriving at current time interval. In order to reduce VM migrations, it avoids migrating VMs that finishes its execution at current time interval.

•
ACS-VMC (Ant Colony System VM Consolidation): This is another popular VM scheduling algorithm [8] that uses a meta-heuristic technique known as Ant Colony Optimization. Their objective is to reduce VM migrations while preserving the QoS requirements. Their search mechanism even avoids getting stuck in local optima by directing the search process using a global approach.

•
MIRAGE: It is the genetic algorithm described in Section 4 that aims to find an optimal consolidation aware schedule.

•
ILP: It is the scheduling decision returned by solving the ILP formulation shown in Section 3.3 using a ILP solver, called CPLEX.

In order to demonstrate the efficiency of our scheduling algorithm (MIRAGE), we have considered two popular migration-aware scheduling algorithms for comparison as mentioned in previous paragraph. Since we have used a meta-heuristic technique to find a near optimal solution, our first paper (ACS-VMC) for comparison uses a popular meta-heuristic approach known as Ant colony Optimization [8] in order to reduce VM migrations while consolidating virtualized datacenters for improved energy consumption. Their results show that their approach has significantly lower migrations when compared to other scheduling algorithms. Moreover since the primary objective of MIRAGE is to reduce VM migration while consolidating PMs, our second paper for comparison is a migration-aware scheduling algorithm known as MVC [46]. This paper has proposed a greedy algorithm that considers two important parameters for reducing VM migrations: (i) a concrete migration cost model and (ii) remaining VM execution time. In order to have a fair comparison with both of these scheduling algorithms, we have kept similar number of active PMs for each time interval as determined by our semi-static consolidation approach.

6. Experimental results
In this section, we first analyze the impact of several tuning parameters in our genetic algorithms to find the best setting. Then, we compare the number of migrations between MIRAGE and several previous job scheduling strategies, including the optimal results from an ILP solver. Finally, we show the robustness of MIRAGE by achieving consistent results over various workload patterns.

6.1. Parameters analysis
MIRAGE has a couple of parameters that can be tuned to obtain better results for minimizing migrations. Here, we use the PIK trace to analyze the impact of these parameters and justify their settings in the rest of our experiments.

The number of populations and generations are the two parameters that control the number of scheduling solutions searched by a genetic algorithm. As expected, a better result is more likely to be found if larger solution space can be searched, but more computation time will also be required. Fig. 6, Fig. 7 show the trade off between computational time and number of migrations caused by these two parameters. The number of migrations in the -axis is normalized by the maximum results obtained from the experiments. For instance, Fig. 6 shows the number of migrations can be reduced by 52% when we increase the setting of generations from 40 to 360, but the computational time also grows about 3 times with a total time of 32.18 s. Similar results can be observed from Fig. 7. To find an appropriate number of generations and population size from this trade off, we define a metric to measure the ratio between the migration reduction (benefit) and computational time (cost): 
, where 
 is the normalized number of migrations and 
 is the normalized total computational time. A higher value of  indicates a better computation efficiency. Fig. 8, Fig. 9 show the performance ratio from the results plotted in Fig. 6, Fig. 7. As observed, the highest value of  occurs when population=200, and generations=240, and hence we use these settings for the rest of experiments.

Next, we analyze how the knowledge of future arrival jobs that can impact the results by controlling how long the future can be seen by MIRAGE. In practice, a scheduler may not be aware of all the future jobs in an online system. But near future job could be known in advanced, especially for reservation-based system. Here, we define the metric “job visibility” as the percentage of the nearest jobs that is known by MIRAGE during scheduling. For instance, if there are 100 jobs in our evaluation workload trace, a job visibility of 5% means MIRAGE has prior knowledge of the next 5 jobs arriving in the future. A 100% job visibility means all jobs are known in prior, so its results can be seen as a theoretical baseline for comparison. Fig. 10 shows the number of migrations under varied job visibility. The number of migrations at -axis is normalized by the result of 0% job visibility. As shown from the figure, MIRAGE has the ability to minimize VM migrations when more job knowledge is given. For instance, the number of migrations is gradually reduced from 90% to 70% and then 55%, when the job visibility increases from 10% to 30% and 60%, respectively. We also observed that the improvement will eventually converge after certain point, so 100% job visibility is not necessary for our method. In the case of this experiment, only 60% job visibility is needed to obtain a result close to 100% job visibility. Hence, we choose 60% job visibility for our method in the rest of experiments.

Finally, we analyze the benefit of applying the repair function in our algorithm. As described in Section 4.5, the repair function is a method to refine the random search solutions generated from the genetic algorithm by avoiding the unnecessary VM migrations during crossover. In Fig. 11, we show the comparison results from both PIK and Atlas traces. In PIK trace, the number of migrations can be reduced by 30% with repair function. In Atlas trace, the number of migrations can be reduced by 38% with repair function. Therefore, the repair function is a necessary and effective strategy to further improve the results of our genetic algorithm.

6.2. Algorithms comparisons
We compare the results of MIRAGE with ACS-VMC, MVC, time-driven method and ILP approach and summarize the results of all the workloads in Fig. 12. The result of ILP solution is also plotted for the synthetic workload as a theoretical baseline. We could not obtain the ILP solution for the two real workloads because the problem scale is too large. Throughout all the workload traces, we observe that MIRAGE can significantly reduce VM migrations over all the algorithms. MIRAGE can reduce migrations up to 12% and 25% when compared with ACS-VMC and MVC respectively. This happens because both ACS-VMC and MVC do not take into consideration the turn-off time of PM and information of future arriving jobs, however MIRAGE takes advantage of these information to find better solutions by applying genetic search algorithm. ILP achieved the best results as seen from the synthetic workload, i.e. it has 10% fewer migrations than MIRAGE but it took 8 times of computational time than MIRAGE. Therefore, MIRAGE is still a more efficient algorithm with acceptable computation complexity in practice.

To further analyze the results of Fig. 12, we study how job length could affect the decision of different scheduling algorithms. Job execution time plays a critical role because longer running jobs have much higher chances to encounter migrations than short running jobs. In Fig. 13, we classify jobs into five groups according to their execution time on an hourly basis. The last group contains any job that has execution time of more than 4 h. The number of migrations of each group is normalized by its corresponding results from best fit. As shown in Fig. 13, time driven strategy and MVC have consistent improvement over best fit strategy throughout any job length. ACS-VMC has better results for shorter running jobs since longer running jobs are more prone to getting migrated and moreover the ants do not have information of future arriving jobs while deciding the VM placement plan. But interestingly we also found that MIRAGE has greater improvement when job length is shorter. It is likely due to the following two reasons. The first reason is that the migrations of short jobs are more easily be avoided if more proper scheduling decisions are made. Hence MIRAGE tends to minimize the total number of migrations by reducing the migrations from this shorter job first. The second reason is that both time driven strategy and MVC do not reschedule a job once it is placed on a machine unless the machine is shut down or the machine is over-utilized. On the other hand, MIRAGE will reschedule a job at anytime as long as this decision can benefit more jobs in the future and reduce the total number of migrations at the end. This situation is more likely to happen on the longer running jobs, because a long job occupies its resource for a longer period of time and the status of machines has changed over time. So, the resource released from a long running job can be used to avoid migrations of those new arrival short jobs. That is why MIRAGE can effectively minimize the total number of migrations, especially for short jobs.

6.3. Workloads analysis
To show MIRAGE can have robust performance across various workloads, we generated a set of synthetic workloads by adjusting the setting of our workload generators, including job arrival rates, job execution time, and job resource demands. We discuss the impact from each of these workload characteristics as follows. Fig. 14(a) compares the number of migrations from workloads with varied mean job arrival rates. As the job arrival rate increases, we found that the number of migrations increases proportionally to the total number of jobs for all the scheduling strategies. But the probability of VM migrations does not change because the total number of active physical servers also has to increase for all the scheduling algorithms accordingly. In other words, job arrival rate has similar effect on all scheduling strategies, and it does not affect the improvement of MIRAGE. This result also shows that MIRAGE can be scaled to handle a system with more jobs and nodes.

Fig. 14(b) compares the results from workloads with varied mean job CPU demand (i.e. the number of cores requested per job). As the job CPU demand increases, the total number of active physical servers again has to increase proportionally according to the semi-static consolidation strategy. But the total number of jobs remains the same. As a result, the job CPU demand does not even affect the number of migrations at all, and hence the improvement from MIRAGE remains the same as well. This result also shows that MIRAGE can be applied to a system with arbitrary number of cores per node, or jobs with varied degree of parallelism.

Fig. 14(c) compares the results from workloads with varied mean job execution time. As the mean job execution time increases, the number of migrations grows because longer jobs have higher chances to be migrated. We found that both ACS-VMS and MVC have better improvement for shorter jobs rather than longer jobs. For instance compared to MIRAGE, ACS-VMC has just 7% more migrations at factor 1, whereas 15% more migrations at factor 4. On the other hand, MIRAGE has better improvement than all other algorithms, even when the mean job execution time becomes larger. This is likely because the optimization problem becomes more difficult as the job length increases. Moreover ACS-VMC and MVC do not have prior information of workload and turn-off time of PMs and hence longer running jobs are more prone to migrate frequently. Therefore, the other scheduling strategies cannot perform as well as MIRAGE.


Download : Download high-res image (92KB)
Download : Download full-size image
Fig. 15. Number of times a job gets migrated .


Download : Download high-res image (112KB)
Download : Download full-size image
Fig. 16. Computational Time of algorithms.

Next in Fig. 15 we see that most of the VMs are migrated only once for all the algorithms. MIRAGE has the least number of migrations since it effectively places the jobs whose execution time is less than the turn-off time of PM. In order to prevent migrations of re-migrated VMs, MIRAGE takes advantage of future arriving jobs and places those re-migrated VMs based on their remaining execution time. That is why almost no VMs has to be migrated 3 times or more for MIRAGE but that is not the same case for other algorithms. Both ACS-VMC and MVC have VMs that are migrated more than 3 times, specially for longer running jobs since they place the jobs irrespective of their execution time.

Fig. 16 depicts the computation time for each of the algorithm. Both MVC and Time-Driven are faster than the meta-heuristic algorithms since they have a simple greedy searching technique. On the other hand ILP becomes computationally expensive as the search space grows larger. MIRAGE runs a bit faster than ACS-VMC and both of their runtime increases with higher number of jobs. Even if MIRAGE has a higher computation time than MVC and Time-Driven, it has a better solution with least number of migrations. Moreover if the dynamism of the job demands are low to moderate, the benefits (VM migrations) gained from consolidation can be maximized; even with a little higher computational time. In this case the quality of solution (MIRAGE) is more important and hence higher runtime of scheduling algorithms can be even acceptable [44].


Download : Download high-res image (274KB)
Download : Download full-size image
Fig. 17. Correlation between VM execution time and the hosting PM’s remaining execution time.

Finally in order to analyze the strategy of our algorithm behind reducing VM migrations, Fig. 17 shows the correlation between VM execution time and remaining turn-on time of PM. The red diagonal line shows when the VM execution time is equal to the PM remaining turn-on time. Since a VM gets migrated if its hosting PM turns off before it finishes execution, any black dot placed above the red diagonal line represents a VM migration. Fig. 17, Fig. 17 show that MIRAGE has a similar strategy as compared to Time-Driven. Both of these scheduling algorithms intend to place the VMs on those PMs whose remaining turn-on time is close to and larger than the VM’s execution time. However MIRAGE still has fewer number of migrations compared to Time-Driven and has a better correlation, since it takes advantage of the future arriving jobs while making the scheduling decision. On the other hand Time-Driven does not change the placement of a VM once it is placed and there might be a case where many longer running jobs will prevent resources to be available for future arriving jobs. Furthermore MIRAGE has a better correlation when compared to MVC (Fig. 17(a)) since it does not take into consideration the job execution time and PM remaining turn-on time.

7. Conclusion
This paper aims to address the VM migration problem in a virtualized data center. We proposed a novel consolidation-aware job scheduling algorithm called MIRAGE to minimize VM migrations with prior job information. We made the following contributions. First, we proposed the idea of consolidation-aware job scheduling problem, and formally formulated it into an ILP problem. So, an optimal solution could be found using an ILP solver. Second, since the optimal formulation is NP-hard we designed a genetic algorithm to find a near-optimal scheduling solution in a more time efficient manner. Third, we evaluate our approach and compare it with some popular scheduling methods (i.e. ACS-VMC, MVC, time-driven) using both real and synthetic data center workload traces. The results show that comparing to other scheduling algorithms, MIRAGE can reduce the number of migrations by more than 25%. Through a set of synthetic workloads, we also show the improvement can be robust and consistent across a wide range of workloads and system environments. As part of our future work, we are motivated to pursue the consolidation aware job scheduling problem using some randomized algorithm like Markov Chain Monte Carlo and we can have a rigid comparison with our genetic algorithm.

