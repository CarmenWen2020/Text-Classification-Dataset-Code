Abstract
We study the problem of task reallocation for load-balancing of MapReduce jobs in applications that process large datasets. In this context, we propose a novel strategy based on cooperative agents used to optimize the task scheduling in a single MapReduce job. The novelty of our strategy lies in the ability of agents to identify opportunities within a current unbalanced allocation, which in turn triggers concurrent and one-to-many negotiations amongst agents to locally reallocate some of the tasks within a job. Our contribution is that tasks are reallocated according to the proximity of the resources and they are performed in accordance to the capabilities of the nodes in which agents are situated. To evaluate the adaptivity and responsiveness of our approach, we implement a prototype test-bed and conduct a vast panel of experiments in a heterogeneous environment and by exploring varying hardware configurations. This extensive experimentation reveals that our strategy significantly improves the overall runtime over the classical Hadoop data processing.

Previous
Next 
Keywords
Artificial Intelligence

Multi-agent systems

Negotiation

MapReduce

BigData

1. Introduction
Data science involves the processing of large volumes of data which requires distributed file system and parallel programming. This emerging distributed computing topic brings new challenges related to task allocation and load-balancing. The adaptivity of these systems to various settings without configuration requiring user expertise, and their responsiveness to rapid changes need to be improved.

This paper is concerned with a class of practical applications where (a) the resources (e.g. data) required to successfully execute a task are distributed among nodes, (b) some of these nodes may encounter potential execution hazards, e.g. slowing down nodes or communication lags and (c) the number of tasks prevents from using a centralized approach to compute the allocation. As several resources are necessary to perform a task, any allocation inevitably requires fetching some of these resources from other nodes, thus incurring an extra time cost for task execution [21]. In this class of applications the task allocation can be challenged during their executions and should capitalize upon the way resources are distributed in the system.

In this class of practical applications, we consider here MapReduce [12] which is the most prominent distributed data processing model for tackling vast amount of data on commodity clusters. Tasks are divided into a set of map tasks and reduce tasks that are distributed on nodes. The task allocation among the reducers is a priori fixed by the partition function. For instance, the partition number is the hash value of the key modulus the number of partitions according to the default partition of the most popular implementation Hadoop [40]. Such a task allocation can be problematic. Firstly, several data skews in the MapReduce applications lead to an unbalanced workload during the reduce phase [27], [28]. Secondly, an unfair allocation can occur during the reduce phase due to the heterogeneous performance of nodes. Thirdly, the load-balancing can be challenged by some rapid performance variations due to exogenous reasons.

In order to tackle the problem of load-balancing and task allocation in applications such as those that motivate this work, multi-agent technologies have received a lot of attention [1]. A multi-agent system is a decentralized system where multiple agents take local decisions based on their perceptions of the environment such that a solution to a complex problem can emerge from the interactions between simple individual behaviours [14]. Most of the existing works adopting the market-based approach [38], [41], [42] model the load-balancing problem as a non-cooperative game in order to optimize user-centric metrics rather than system-centric ones such as the global runtime considered in this paper. We assume that agents are cooperative, viz.: they share the same objective, minimizing the global runtime. We also assume there is no shared knowledge, including any knowledge about the whole task allocation. However, agents have a model of their peers, i.e. they are able to compute the cost of tasks for their peers. We further assume, as required by our practical application, that a task can be performed by any single agent without preemption and precedence order. A task is indivisible, with no deadline and not shareable i.e. a task belongs to only one agent at a time.

In this paper, we formalize the multi-agent situated task allocation problem. We propose a dynamic and on-going task reallocation process which takes place concurrently with the task execution and so the distributed system is adaptive to disruptive phenomena (e.g. slowing down nodes). When agents locally identify opportunities within a current unbalanced allocation, they trigger concurrent and one-to-many negotiations to reallocate some tasks. Apart from decentralization, i.e. avoiding performance bottlenecks due to global control, we show here that a multi-agent approach for situated task allocation supports two additional crucial requirements (a) concurrency – where task reallocation and task executions are concurrent, and (b) adaptation – where task reallocation is triggered when a disruptive event is performed. This paper significantly extends our previous works. Contrary to [5], we do not assume that each task has an intrinsic cost (e.g. the number of data to process) but the location of resources is taken into account. Beyond [7], we introduce here a multi-auction process which allows an agent to bid in several concurrent negotiations in order to improve the responsiveness of the system. Additionally, we present a vast panel of experiments in order to empirically evaluate (a) the adaptivity of our multi-agent system in an heterogeneous environment, (b) the responsiveness of the multi-agent system due to the multi-auction process, and (c) the adequacy of the agent strategy with respect to the computing infrastructure.

Specifically, our contributions are as follows:

•
We formalize the multi-agent situated task allocation problem where tasks have different costs for different agents due to the resource locality.

•
We design a multi-agent version of the MapReduce pattern in a distributed system setting which solves the partitioning data skew problem. The task reallocation process based on concurrent negotiations between agents occurs all along the MapReduce job processing to cope with a continuously evolving environment.

•
We conduct extensive experiments on real-world datasets. The experimental results show that our method improves the runtime with a negligible computational overhead and it mitigates the heterogeneity of the computational environment.

The paper is structured as follows. Section 2 overviews relevant related works. Section 3 defines the socially rational task delegation considered by the agents in order to locally improve the task allocation. Section 4 sketches the negotiation process which is concurrent with task consumptions. Section 5 specifies the strategies, i.e. how agents choose which task to perform/negotiate. Our practical application and empirical evaluation are described in Section 6. Finally, Section 7 summarizes our contribution and outlines our future work.

2. Related work
The context of this paper is a single MapReduce job. In this context the problem of task scheduling consists of assigning map and reduce tasks as suggested by Selvitopi et al. in [37]. This problem should not be confused with that of job scheduling, where one considers the allocation and the usage of the resources in case of multiple MapReduce jobs as discussed by Banerjee and Hecker in [8]. Several common data skews in the MapReduce applications are identified in [27], [28] which lead to an unbalanced workload during the data processing. In this paper, we focus on the partitioning skew leading to an unbalanced allocation among the nodes where the reduce phase is slowed down since it is penalized by the most loaded reducer. This data skew is tackled by [11], [31] using parametrization based on prior knowledge about the data and the distributed computing environment. Every reduce task is scheduled in [17] according to the data skew and the data locality without modifying the partition. In this paper, we address the partitioning data skew with the dynamic and adaptative task reallocation which is concurrent with the task consumption. Thus, reallocation is adaptative to the data processing. This enables us to tackle the following real-world issues: (a) the lack of prerequisite knowledge over the data and the processing, (b) the inaccurate estimation of task execution time, and (c) the execution hazards (slowing down nodes, communication lag). To the best of our knowledge, no other proposal is scalable and responsive, like ours.

We provide here a comparison of our work with the most significant existing methods for task allocation and load-balancing which is summarized in Table 1. This analysis grid classifies these works according to the crucial aspects which are requested by our practical application: the deployment of the MapReduce design pattern for processing large datasets.

Classical scheduling problems have been the subject of extensive research producing offline schedulers for some simple models [10]. The problem of minimizing the makespan (the completion time of the last task to perform) with  tasks on  unrelated machines (i.e. with different capabilities), denoted 
, is NP-hard [19]. Pseudo-polynomial algorithms developed for this problem include: the earliest completion time heuristic (ECT) proposed by Ibarra and Kim in [20], two-phase heuristics based on linear programming suggested by Lenstra et al. in [29], the local search heuristics proposed by Hariri and Potts in [18], and the branch and bound algorithm applied by Martello et al. in [32]. These centralized algorithms and the most recent ones [33], even the ECT heuristic which is an approximation algorithm giving acceptable results with very small computational requirements, cannot be applied to our scenario with a large number of tasks (e.g. 100,000 keys in Section 6). The strategies presented in Section 5 are decentralized local search heuristics.


Table 1. Analysis grid of related works according to the main aspects.

Decentralization	Adaptation		Cooperation	Distribution	Objectives
Ibarra and Kim [20]	–	–		–	–	Makespan minimization
Lenstra et al. [29]	–	–		–	–	Makespan minimization
Hariri and Potts [18]	–	–		–	–	Makespan minimization
Martello et al. [32]	–	–		–	–	Makespan minimization
Jiang [25]	✓	✓		–	✓	Response time
Selvitopi et al. [37]	✓	–		–	✓	Makespan minimization
Di and Wang [13]	✓	✓		✓	✓	Throughput
Turner et al. [41]	✓	✓		✓	–	Throughput
Schaerf et al. [35]	✓	✓		✓	✓	Throughput
Jiang and Jiang [23]	✓	✓		✓	✓	Throughput
Jiang and Li [24]	✓	✓		✓	✓	Response time minimization
Jiang and Zhichuan [22]	✓	✓		✓	✓	Response time minimization
Walsh and Wellman [42]	✓	✓		–	✓	An allocation
Kraus et al. [26]	✓	✓		–	–	An allocation
An et al. [3]	✓	✓		–	✓	Response time minimization
Penmatsa and Chronopoulos [34]	✓	–		–	–	Response time minimization
Shehory and Kraus [38]	✓	✓		✓	–	Makespan minimization
MAS4Data	✓	✓		✓	✓	Makespan minimization
Multi-agent scheduling [1] has received significant attention for load-balancing problems in distributed systems, but it is different from the classical scheduling problems due to the following aspects:

•
Decentralization: global control causes a performance bottleneck as it must collect status information of the entire system in real time. Instead, task allocation can be negotiated by agents representing the nodes. For instance, Jiang et al. propose in [25] a negotiation reputation-based allocation mechanism for load-balancing in order to reduce the resource access time and so the responding time.

•
Adaptation: classical scheduling problems are static. The inaccurate estimation of tasks execution time and the disruptive phenomena (task consumption, slowing down nodes, etc.), may require major modifications in the existing allocation to stay optimal. Di and Wang introduce in [13] a self-adaptive system to implement a high adaptable task allocation to a dynamic environment. Turner et al. combine in [41] supervised classification learning with an internal decision-making process for task assignments. Schaerf et al. investigate in [35] the adaptive behaviour of agents for efficient load-balancing using multi-agent reinforcement learning. These methods cannot be used for the class of practical applications we are concerned since neither generalizable predictive patterns nor prior model of the data/environment is available.

The enormous amount of varying related studies (see [21] for a recent survey) mainly distinguish themselves through the following aspects:

•
Objectives: the makespan minimization is the most widely applied optimization objective for task allocation. Selvitopi et al. [37] propose a task scheduling to minimize the makespan however the allocation is made once for all before the reduce phase while our method challenges the allocation all along the process. Minimizing the total or mean response time of all tasks means minimizing the waiting time of tasks. The throughput measures the number of tasks completed per time unit. The reliability measures the probability that the tasks can be successfully executed. Attiya and Hamam distinguish in [4] the node-related reliability, i.e. the reliability of resources/computation and the path-related reliability, i.e. the reliability of communications.

•
Distribution: some resources are placed at the nodes and can be accessed and shared to execute the tasks. For this purpose, the location of agents and the accessibility of required resources should be considered which is not the case of most of the task allocation algorithms. In [23], Jiang and Jiang consider that the number of allocated tasks on a node is proportional to its own resources and the resources of its interacting nodes. Jiang and Li propose in [24] a locality-sensitive resource allocation model which takes into account the distance between the nodes and the locality of resources. Jiang and Zhichuan present in [22] a task allocation mechanism based on the contextual resources: if a node has richer experiences of executing tasks, the node may have higher access to the resources. In this paper, the nodes are equidistant from each other in a fully connected physical and social network. The efficiency of a task allocation depends both on the proportion of resources (data) which are local and their intrinsic talent (CPU).

•
Cooperation: Garg et al. distinguish in [16] the meta- schedulers which optimize system-centric metrics and the most recent ones focusing on user-centric metrics. Most of the latter adopts the market-based approach: they model the load-balancing problem as a non-cooperative game. Walsh and Wellman present in [42] a task allocation protocol among agents which acquire and provide goods on behalf of consumers or producers. Kraus et al. consider in [26] that, even if each agent tries to maximize its benefits, they need to cooperate to perform tasks. An et al. propose in [3] a distributed negotiation mechanism where selfish agents negotiate over resources both a contract price and a decommitment penalty. Penmatsa and Chronopoulos formulate in [34] the load balancing problem as a non-cooperative game among the users who try to minimize the expected response time of their own tasks. Fewer works are based on cooperative agents which negotiate to address system-centric metrics such as the global runtime we consider in this paper. For instance, Shehory and Kraus consider in [38] that task assignments to groups of agents as necessary since tasks cannot be performed by a single reliable agent. By contrast, we assume here that a task, which can be performed by any single agent without preemption and precedence order, is indivisible, not shareable (i.e. a task belongs to only one agent at a time) and with no deadline.

3. Situated task allocation
We formalize here the multi-agent situated task allocation (MASTA) problem where tasks have different costs (runtime) for different agents due to the resource locality.

Definition 1 MASTA

A multi-agent situated task allocation problem of size  with ,  and  is a tuple  such that:

•
 is a set of  nodes;

•
 is a set of  agents;

•
 is a set of  tasks to perform;

•
 is a function which returns the location of an agent;

•
 is a function which specifies how many resources for a task are on a particular node;

•
 specifies the cost of a task  at a given location such that the tasks are cheaper when the required resources are more local ones: (1)

In the rest of the paper, 
, 
 and 
 denote , 
 and 
, respectively. Similarly, we denote 
. We say that  is local, partially local, or distant for agent  if 
, 
, or 
, respectively.

In the following of this section, we consider a particular MASTA problem and we evaluate the task allocation from a collective viewpoint by considering the maximum completion time, i.e. the makespan.

Definition 2 Task Allocation, Workload and Makespan

A task allocation  is a partition of tasks among agents, i.e. a set of  task bundles  such that: (2)
(3) The workload of the agent  in the allocation  is defined as: (4)
The makespan of  is defined as: (5)

Let us consider the following walk-through example.

Example 1 Task Allocation, Workload and Makespan

Let 
 a problem of size , where 
,  and 
 with 
 and 
. The locations of the tasks and their costs are represented in Table 2. Let  and  be two task allocations such that 
 and 
.  is optimal since 
 and 
 and so 
. As shown at top of Fig. 1, it is not the case of  since 
, 
 and so 
.

The agents modify the task allocation by negotiating task delegations. The delegation  of the task  from agent  to agent  aims at improving the makespan, i.e. the load-balancing between the two agents. The following definition formalizes the required conditions for an effective task delegation.


Table 2. Locations and costs of tasks.

1	0	3	6	1	6	0
0	4	6	12	4	1	7
1	8	15	30	9	8	14
2	4	12	24	6	13	7
Definition 3 Socially Rational Task Delegation

Let  be a task allocation. The delegation  of the task  from agent  to agent  is defined s.t. the resulting allocation 
 is as follows: 
(6)
 The delegation is socially rational iff: (7)

Since a socially rational task delegation  strictly decreases the local makespan between the two agents, it does not increase the global makespan (
).

We can now denote 
 the set of socially rational task delegations that an agent  can trigger: (8)
A task allocation  is said stable if no agent can trigger a socially rational task delegation.

Example 2 Socially Rational Task Delegation

Let 
 be the delegation of the task 
 from agent 1 to agent 2 in Example 1 which leads to the task allocation 
. Since 
 and 
, 
 improves the makespan: 
. However 
 is not stable.

Let 
 be the task allocation where 
 is the delegation of 
 from agent 2 to agent 1. Even if 
 is not optimal (
), 
 is stable. Fig. 1 depicts the workloads of the two agents after the delegations 
 and 
.

Property 1 Load-balancing Process

An unstable task allocation can always lead to a stable one using a finite number of socially rational task delegations.

Proof Load-balancing Process

Let  a task allocation and 
 the vector of the workloads in decreasing order where 
 denotes the th largest workload. If  is not stable, there exists a socially rational task delegation  which leads to 
. Formally, (9)
 It implies that 
 in the lexicographic order. Formally, 
Since there is a finite number of allocations and the order is strict, there is a finite number of socially rational task delegations.

4. Negotiation process
We sketch here the repeated negotiations process which is concurrent with task execution. When a task is consumed, it will be removed from the set of tasks, and so the multi-agent system aims at minimizing the makespan of the current allocation for this new MASTA problem.

The execution of a task is a disruptive event which modifies the MASTA problem and the task allocation. Formally,

Definition 4 Task Consumption

Let  be the current task allocation for the problem . The consumption  of the task  by the agent  leads to the task allocation 
 for the problem 
 such that: (10)
(11)
(12)

A sequence of task consumptions removes all the tasks from the initial allocation until a final empty one, denoted . Obviously, a task consumption may decrease the makespan.

Decentralized task delegation process .
Agents operate in concurrent, one-to-many and single-round negotiations for task delegations. Each negotiation, which is based on the Contract Net Protocol [39], includes three decision steps: (a) the choice of the task to negotiate by the strategy of the initiator described in Section 5, (b) the refusals/bids from the peers which check the social rationality of the task delegation, and (c) the selection of the winning bid by the initiator. We consider here that the initiator selects the bidder with the smallest workload in order to decrease the makespan. Since there is no shared knowledge, an agent has partial and not necessarily true beliefs about the current allocation . Indeed, agent  knows its own workload 
 and it has a belief base: (13)
where 
 is the belief of the agent  about the workload of agent  in the allocation .

The set of potential socially rational task delegations 
 that an agent  can initiate in the task allocation  is based on its belief base 
. Formally, (14)
If 
, then agent does not initiate negotiations. The computation of the local makespan by the initiator of a negotiation is also based on its belief base, possibly inaccurate. This is the price to pay for decentralization. However, an agent informs its peers about its workload when it is triggered for the first time, within the negotiation messages, and after each task execution. Therefore, the belief base of the peers is updated. It follows that a successful negotiation can only reach a socially rational task delegation, and so tends to improve the makespan. When an agent, according to its belief base, identifies opportunities within a current unbalanced allocation, it initiates negotiations. These local decisions promote the adaptivity of the multi-agent system.

Concurrent consumptions and delegations .
Task delegations and task consumptions are concurrent and complementary operations since a task removal may be an opportunity for new socially rational task delegations. Fig. 2 represents the influence of these operations over the path from the initial allocation 
 until the final one . Agents perform socially rational task delegations to improve the makespan (e.g. the path from 
 to 
) until a task consumption (e.g. the edge from 
 to 
), which eventually interrupts the path toward a stable allocation (e.g. the path from 
 to 
 represented in grey). A task consumption may occur when the agents have reached a stable allocation (e.g. 
) or not (e.g. 
).

Multi-auction .
First of all, even if an agent which is involved in a negotiation as a bidder cannot initiate another negotiation and conversely, several negotiations involving different groups of agents may concurrently occur. Additionally, we introduce here a multi-auction process which allows agent to bid in several concurrent negotiations as in [2] in order to improve the responsiveness of the system. In this way, as stated by our empirical results in Section 6, the gap between the most loaded reducer and the least loaded one is filled faster and so the load-balancing process is faster.


Download : Download high-res image (98KB)
Download : Download full-size image
Fig. 2. Concurrent task consumptions (vertical edges) and task delegations (horizontal edges).

In order to tackle the eager bidder problem [36], we adopt a conservative approach which warrants that the task delegations are socially rational. For this purpose, a bidder computes an overhead.

Definition 5 Overhead

Let  be an allocation,  the tasks which are currently negotiated and 
 the set of pending tasks for which the agent  has made proposal. The overhead of the agent  is: (15)

The potential workload of the agent , which represents its workload if it wins all the auctions in which it is involved (
), allows a bidder not to be too optimistic and to make proposals which only lead to socially rational task delegations. In order to evaluate the delegation of the task  from the agent , the bidder  adopts the following strategy:

•
either 
 so the bidder declines the delegation which is not socially rational;

•
or 
 so the bidder postpones the evaluation of the delegation which depends on the outcomes of the pending negotiations;

•
or 
 so the bidder makes a proposal since the task delegation is socially rational whatever the outcomes of the pending negotiations are. Then, (16)
Moreover, the bidder informs the initiator about its potential workload.

In the latter case, when the negotiation closes:

•
either the bidder is selected (
) and its workload is updated 
;

•
or it is not the case (
), its workload remains the same 
.

In both cases, the overhead is updated: (17)
Finally, the pending delegations are re-evaluated.

Example 3 Multi-Auction

Let  be an allocation among the set of agents  such that the workloads are:


We focus here on the overhead of the agent  and it influence over the negotiations. We assume the agents , , ,  and  ask for the delegation of the tasks 
, 
, 
, 
 and 
 respectively. The cost of these tasks for the agent  are:


Fig. 3 illustrates the evolution of the overhead for the agent  during its interactions with its peers. The agent  can make a proposal to the agents  and  (messages  and ). However, the delegation requested by the agent  (message ), which is not socially rational, is declined (message ). The agent  must postpone the evaluation of the delegations from the agents  and  (messages  and ) which depends on the previous pending negotiations. When the delegation of the task 
 is confirmed (message ), the agent  can decline the delegation of 
 (message ) but the social rationality of the delegation of the task 
 is neither excluded nor confirmed. Finally, when the delegation of the task 
 is rejected (message ), the agent  can make a proposal about 
 (message ).

5. Strategies
Since task delegations and task consumptions are concurrent, the strategy of an agent must select the next task to perform/delegate.

Definition 6 Strategy

Let  be an allocation, the strategy of the agent  is the couple 
 where:

•
, selects the next task to perform or none (denoted ) if ;

•
, selects the next task to negotiate or none if 
.

It is worth noticing that the delegation which is selected by the strategy must be a potential socially rational one. In the following, we propose two strategies. While the local agnostic strategy is only based on the cost function, the location-aware one takes into account the location of the required resources.

Local agnostic strategy .
By adopting the principle “consume small, delegate big”, an agent performs the smallest task in its bundle and negotiate the largest one which may lead to a potential socially rational delegation. For this purpose, this strategy only requires that the agent sorts the tasks according to their costs. We can notice that the consideration of the resource fetching time by this strategy is implicit since an agent should perform first the local tasks which may cost more for its peers and delegate first the distant tasks which may cost less for its peers. The following strategy makes this principle explicit.

Location-aware strategy .
According to this strategy, an agent performs first the large local tasks and it negotiates first the large distant ones based on its local beliefs and knowledge. This strategy is built on a data structure, called local-aware bundle.

Firstly, the local availability ratio measures the locality of tasks:

Definition 7 Local Availability Ratio

The local availability ratio of the agent  for the task  is defined as: (18)
 
The maximum local availability ratio for the task  is: (19)ô

The local availability ratio of an agent  for a task is the ratio between the number of local resources and the total number of resources for this task.

Secondly, the local-aware bundle of agent , which is depicted in Fig. 4, is divided in three subbundles in accordance with the local availability ratios of the agent for the tasks:

1.
The maximum local bundle contains the tasks such that agent  owns at least one resource and there is no other agent which owns more resources for this task. The tasks are sorted by decreasing order of cost (cf. left of Fig. 4);

2.
The intermediate local bundle contains the tasks which are partially local. The tasks are sorted by decreasing order of local availability ratio and the tasks with the same local availability ratio are sorted in decreasing order of cost (cf. centre of Fig. 4);

3.
The distant bundle contains the tasks which are distant. The tasks are sorted by increasing order of cost (cf. right of Fig. 4).

When an agent looks for a task to perform, it starts from the top of the maximum local bundle, i.e. the largest local task. When an agent looks for a task to negotiate, it starts from the bottom of the distant bundle (i.e. the largest distant task) and it selects the first potential socially rational delegation.

6. Results and discussion
After introducing our practical application, we describe our prototype and we discuss our empirical results.

6.1. Practical application
We consider as a practical application the distributed deployment of the MapReduce design pattern in order to process large datasets on a cluster [12], as with Hadoop [40]. A MapReduce job consists of two successive phases: map and reduce. During the map phase, nodes filter in parallel input data and generate key–value pairs written into data chunks. Each data chunk is located on the same node as the mapper which has generated it. During the reduce phase, nodes process in parallel the keys and their individual lists of values.

The reduce phase of a MapReduce job can be formalized by a MASTA problem  (cf. Definition 1) where:  is the set of nodes in the cluster,  is the set of reducer agents,  is a set of reduce tasks,  captures the fact that we put one reducer per node in our experiments and  considers the data location. In conformance with Eq. (1), we specify the cost of a task  for an agent  as follows: (20)
 where  denotes the number of values for the chunk  and  captures the resource fetching time. We empirically set up  for a cluster and  when we use a network of computers. Our experiments show that the cost function does not need to be carefully tuned since the adaptivity of our dynamic task reallocation process allows to mitigate an inaccurate cost function.

6.2. Implementation
We have developed a multi-agent version of the MapReduce pattern in a distributed system setting using the MAS4Data testbed [6]. MAS4Data is implemented in Akka [30] for highly concurrent, distributed, and resilient message-driven applications. Even if fault-tolerance of nodes is out of the scope of this paper, we assume that the message transmission delay is arbitrary but not negligible and that messages may be lost. These are the reasons why we have included acknowledgements and deadline mechanisms in the interaction protocol. In order to decrease the complexity related to the design of a reducer agent, we have adopted a modular agent architecture that allows the concurrency of the negotiations and the tasks performance, as well as the separation between communicative and decision-making behaviours.

6.3. Empirical results
This section starts by explaining the experimental setting in details, which includes the choice of the metrics, the datasets and the jobs. Then, we report on the experimental results.

Metrics .
In order to evaluate the runtime and the fairness of our experiments we have introduced in our previous works [5], [7] the following metrics:

•
The contribution of a reducer is the sum of the costs of the tasks it has performed;

•
The contribution fairness is the ratio between the minimum and the maximum contributions of the agents;

•
The runtime of the reduce phase is the runtime of the reducer which finished last;

•
The time fairness is the ratio between the runtime of the slowest reducer and the runtime of the fastest one.

While the contribution of a reducer corresponds to its ex-post workload (see Definition 2), the runtime effectively measures the makespan. The closer to  the contribution fairness and time fairness are, the fairer is the allocation. In other words, we want to keep every agent as busy as all the other ones, thus sharing as much as possible the workload of the application.

Setup .
We consider here two different hardware configurations: (a) a cluster with 10 blades, each having 10 CPUs with 512Go RAM; (b) a network of  PCs with 4 cores Intel(R) i7 and 16GB RAM each. Since we obtain similar results with the second configuration, we present here the experiments on the cluster with an exception for the last experiment which compares the two configurations. We use two distinct real-world datasets. The first dataset (2.4 Gb) contains  ratings that 480,189 users gave to 17,770 movies [9] [dataset]. The job, called RecByMov, counts the number of rankings per movie. The second dataset ( Mb) contains  weather records (station id, timestamp, temperature, rainfall, etc.) from 62 stations taken during the last 20 years [15] [dataset]. The job, called RecByTempSta, counts the number of records per half degree of temperature and per station. In order to increase the volume of data without slowing down the mapping phase (which is out of the scope of this paper) and without changing the data distribution, we replicate  times the number of values for each key:  for the job RecByTempSta and  for the job RecByMov. Whatever the job and the datasets are, we use as many mappers as reducers and each experiment is run  times. Due to the observable nondeterminism of distributed execution, we comment distinctive runtimes.

Fig. 5 shows the initial workloads for these two jobs with the default Hadoop partition function, i.e. the hashcode of the key modulo the number of reducers. While the first partition is well balanced, the second one is intentionally caricatural1 since half of the reducers have no task to perform. The latter highlights the partitioning skew [27], [28] since half of the reducers execute no task.

Empirical results.
Firstly, our experiments aims at validating our approach. We show that: (a) the negotiation improves the makespan and so the runtime with a small overhead cost for the negotiation, and (b) our multi-agent system is adaptive to performance variations and heterogeneous environments. We adopt by default the local agnostic strategy and the multi-auction process. Secondly, we evaluate these choices.


Download : Download high-res image (182KB)
Download : Download full-size image
Fig. 5. The allocation for our two jobs with the classical Hadoop.

Negotiation improves the runtime .
Negotiation is beneficial whether or not the initial allocation is fair. In order to validate this hypothesis, we compare the contribution fairness, the time fairness and the runtime of jobs with/without negotiations. Note that, throughout the paper, whenever we use the term “without negotiation” we refer to results obtained “with the classical Hadoop”.

Empirical result 1

The negotiation improves the runtime due to the load-balancing of the reducers contributions.

Fig. 6 shows that a job can strongly benefit from the negotiations. Starting from an initial unfair allocation (cf. Fig. 5(b)), we execute  times the job RecByMov with  reducers on  homogeneous nodes. During the data processing, task delegations occur since the workloads are unbalanced. The most loaded reducers propose tasks which are accepted by the less loaded ones. Finally, the contributions are fairly distributed among the nodes and all the reducers terminate at the same time since the fairnesses are close to 1 (cf. Fig. 6, Fig. 6). Therefore, the makespan (cf. Fig. 6(d)) and so the runtime (cf. Fig. 6(c)) are more than halved.

Empirical result 2

When the initial allocation is fair, the overhead of the negotiation is negligible and it does not affect the runtime.

Fig. 7 shows that a job cannot be penalized by the negotiations. Starting from an initial fair allocation (cf. Fig. 5(a)), we execute  times the job RecByTempSta with  reducers on  homogeneous nodes. Since the initial allocation is fair, it is not surprising that the contribution fairness (cf. Fig. 7(a)) and the time fairness (cf. Fig. 7(b)) are quite good even without negotiation, i.e. close to 0.85. However, they are still improved by negotiation since the makespan can be slightly decreased (cf. Fig. 7(d)). Therefore, the runtime is about 7% faster with negotiation (cf. Fig. 7(c)). It is worth noticing that no negotiation is triggered when the agents believe that the allocation is stable.

These two experiments validate that our adaptive dynamic process based on concurrent negotiations for tasks reallocation improves the runtime even if the initial allocation is fair. The first experiments demonstrates how MAS4Data tackles the partitioning skew. The second one highlights that the overhead of negotiation is negligible with respect to the benefit of the load-balancing.


Download : Download high-res image (239KB)
Download : Download full-size image
Fig. 7. The median metrics and their standard deviations depicted in boxplots (a, b, c) and the contributions after negotiation for a distinctive execution of the job RecByTempSta (d).

Negotiation mitigates heterogeneity .
The heterogeneity of a computational environment comes from a permanent non- uniformity of the processing capabilities of the nodes or a temporary one due to exogenous reasons (e.g. the slowdown of a node).

Empirical result 3

The negotiation allows in an heterogeneous environment to reallocate the tasks to the fastest nodes in order to improve the runtime.

Fig. 8 shows that the multi-agent system adapts the allocation to runtime hazards. Starting from an initial fair allocation (cf. Fig. 5(a)), we execute  times the job RecByTempSta with  reducers. Indeed, only one CPU is activated on each node and the first reducer cannot use more than 50% of the CPU time. Therefore, the seven other reducers run faster. The initial fair allocation is challenged by the slower reducer. Without negotiation (cf. Fig. 8(c)), seven reducers terminate after  seconds while the slower reducer ends after  seconds and so the time fairness is low (around 0.43). By contrast, the negotiation allows the slower reducer to terminate after  seconds like the other ones (cf. Fig. 8(d)). The time fairness is very close to  since some negotiations are triggered during the job processing for load-balancing. Thanks to this dynamic and continuous task reallocation process, the job is not penalized by the slower node and the job runs two times faster due to the negotiations. Finally, the contribution of the slower reducer is lower than the contributions of the other ones (cf. Fig. 8(b)), and so the contribution fairness is low, approximately 0.35 (cf. Fig. 8(a)).


Download : Download high-res image (316KB)
Download : Download full-size image
Fig. 8. The median contribution fairness and its standard deviations depicted in boxplots (a), the contributions (b) for a distinctive execution of the job RecByTempSta when a node is slowed down, the evolution of the workloads without negotiation (c) and with negotiation (d).

This experiment shows that the negotiation process mitigates the impact of a runtime hazard which slows down one reducer. A reducer which is slowed down can delegate some tasks in order to execute the job as soon as possible.

Fig. 9 shows that the multi-agent system adapts the allocation to heterogeneous environment. Starting from an initial fair allocation (cf. Fig. 5(a)), we execute  times the job RecByTempSta with  reducers. Indeed, only one CPU is activated on each node, four reducers run on the same node and four reducers run on separate nodes. As previously, the contribution fairness with negotiation is worst since the four slower reducers perform less task than the others. Once again, the dynamic and continuous task reallocation process allows the time fairness to reach approximately  and the job runs five times faster due to the negotiations. Finally, the contribution of the slower reducers is lower than the contributions of the others (cf. Fig. 9(d)), and so the contribution fairness is low.

These two experiments validate that a job running in an heterogeneous environment benefits from the adaptivity of our multi-agent system. When a performance variation brings to an unbalanced allocation, our continuous and dynamic process detects it and triggers the reallocation of tasks toward the fastest nodes leading to the speedup of the runtime.


Download : Download high-res image (251KB)
Download : Download full-size image
Fig. 9. The median metrics and their standard deviations depicted in boxplots (a, b, c) and the contributions after negotiation for a distinctive execution of the job RecByTempSta in an heterogeneous environment (d).

Single-auction versus multi-auction .
We assume that our multi-auction process, which allows agents to bid in several concurrent negotiations, improves the responsiveness of the multi-agent system.

Empirical result 4

The multi-auction process reaches faster stable allocation.

Fig. 10 shows that the multi-agent system adapts the allocation faster with a multi-auction process. We have generated a dataset ( Mb) with  lines such that the initial task allocation is unfair. The job, called RecByKey, counts the number of values per key. We use  reducers in an homogeneous environment where none task is assigned to the first reducer while 100,000 tasks with 1000 values per task are assigned to the others reducers which have similar workloads (cf. Fig. 10(a)). As in the previous experiments, the negotiation improves the load-balancing (cf. Fig. 10, Fig. 10). However, the multi-auction process is more efficient. While the multi-auction process needs  seconds to reach a fair allocation (cf. Fig. 10(e)), the workload of the first agent remains close to  during the whole reduce phase with the single-auction process (cf. Fig. 10(d)). Actually, the tasks are delegated in the single-auction process to the first reducer one after the other and they are instantly performed. By contrast, this agent continuously bids in seven simultaneous auctions during the multi-auction process. Therefore, the data processing with a single-auction process ( s) is around 10% slower than with a multi-auction one ( s). Finally, the contribution fairness is around 0.3 with a single-auction while it is close to 0.85 with a multi-auctions process.

This experiment shows that the multi-auction process speeds up the load-balancing process and so improves the responsiveness of the multi-agent system.


Download : Download high-res image (505KB)
Download : Download full-size image
Fig. 10. The initial workloads, the contributions and the workloads for a distinctive execution of the job RecByKey with single-auction (b and d) or multi-auction (c and e).

Adequacy of the strategy with respect to the infrastructure.
We assume that the efficiency of the location-aware strategy depends on the resource fetching time.

Empirical result 5

The location-aware strategy improves the runtime when the extra cost for fetching resources is significant.

Fig. 11 shows that the efficiency of the negotiation strategy depends on the hardware configurations. We have generated a dataset ( Gb) with 82,283 keys such that the initial task allocation for the job RecByKey can be challenged. In order to evaluate the impact of the proximity between data resources and processing nodes on the runtime, most of the data required for a task are not located on the same node as the assigned reducer. (See [7] for more details.) With a network of computer, the location-aware strategy significantly improves the runtime with respect to the local agnostic strategy, around  (cf. Fig. 11(a)). By contrast, the local agnostic strategy is more efficient within a cluster (cf. Fig. 11(b)). Indeed, the cost of fetching distant resources from other nodes in a network of computers has a real impact and so the local execution of tasks speeds up the runtime. By contrast, this extra cost for task execution is low within a cluster. We experimentally measure it to be around 10%. Moreover, it is worth noticing that the locality is implicitly taken into account in the local agnostic strategy since the underlying cost function is defined such that the tasks are cheaper when the required resources are more local ones (cf. Eq. (1)).

7. Conclusion
In this paper, we have proposed a multi-agent system for task reallocation among distributed nodes based on the location of the required resources to perform these tasks in order to minimize the makespan. In particular, we have applied our negotiation framework for load-balancing the reduce phase in the distributed MapReduce model in order to process large datasets.

Our prototype has been empirically evaluated. Our experiments show that MAS4Data is adaptive to the partitioning skew, an heterogeneous computing environment, and any potential execution hazards. This is due to the fact that the negotiation process improves the runtime due to the load-balancing of the reducers contributions. Some of our experiments suggest that future work should consider: (a) task swaps to improve the makespan of stable allocations and (b) task bundles in order to speedup the negotiation process. MAS4Data is scalable since it tackles a large number of tasks due to the local decisions of agents about the next task to delegate/perform. Moreover, the overhead of the negotiation is negligible with respect to the benefit of the load-balancing since the task reallocation is concurrent with the task consumption and no negotiation is triggered when the agents believe that the allocation is stable. Indeed, our method is not a scheduling algorithm which allocates the tasks once and for all but an ongoing distributed strategy attempting to repair a potential unbalanced partition.

From the user perspective, even if our adaptive and dynamic approach tackles the problem of performance drop, the fault tolerance can still be achieved through data replication. It is worth noticing that MAS4Data does not require expertise for the parametrization due to its adaptivity. Even if the choice of the strategy depends on the hardware configuration, no other parameter needs to be carefully tuned such as the replication factor (by default the value 3 in HDFS [40]). A sensitivity analysis to study the influence of this parameter has been beyond the scope of this work, but it is certainly worth further investigation.

Generally, future work must consider here the continuous arrival of complex jobs concurrently submitted by several users. Our study focuses on the reassignment of independent fine-grained tasks in a single job during their execution. In order to fill this granularity gap, the formal framework must be extended and the optimization objective to be considered should be the mean flowtime of several concurrent jobs i.e. the mean of the maximum completion times of dependent tasks in these jobs.