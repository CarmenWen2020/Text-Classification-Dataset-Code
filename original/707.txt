Abstract
In a newly emerged fog computing environment, various user equipments (UE) enhance their computing power and extend their battery lifetime by computation offloading to mobile edge cloud (MEC) servers. Such an environment is distributed and competitive in nature. In this paper, we take a game theoretical approach to computation offloading optimization in a fog computing environment. Such an approach captures and characterizes the nature of a competitive environment. The main contributions of the paper can be summarized as follows. First, we formulate a non-cooperative game with both UEs and MECs as players. Each UE attempts to minimize the execution time of its tasks with an energy constraint. Each MEC attempts to minimize the product of its power consumption for computation and execution time for allocated tasks. Second, we develop a heuristic algorithm for a UE to determine its “heuristically” best response to the current situation, an algorithm for an MEC to determine its best response to the current situation, and an iterative algorithm to find the Nash equilibrium. Third, we prove that our iterative algorithm converges to a Nash equilibrium. We demonstrate numerical examples of our non-cooperative games with and without MECs' participation. We observe that our iterative algorithm always quickly converges to a Nash equilibrium. The uniqueness of our non-cooperative games is that the strategy set of a player can be discrete and the payoff function of a player can be obtained by a heuristic algorithm for combinatorial optimization. To the best of the author's knowledge, there has been no such investigation of non-cooperative games based on combinatorial optimization for computation offloading optimization in a fog computing environment.

Keywords
Computation offloading
Fog computing
Heuristic algorithm
Mobile edge cloud server
Non-cooperative game

1. Introduction
1.1. Motivation
In a newly emerged fog computing environment, various user equipments (UE) enhance their computing power and extend their battery lifetime by computation offloading to mobile edge cloud (MEC) servers. Such an environment is distributed and competitive in nature, in the sense that each UE finds its best computation offloading strategy to the MECs and its best computation and communication speeds, such that both execution time and energy consumption can be minimized. Furthermore, each UE is aware of the existence of other UEs, and adjusts its strategies according to the current situation of an environment.

Computation offloading optimization faces the following important concerns and challenges. First, computation offloading optimization should include both cost and performance into consideration. While performance (e.g., execution time) is an important target for optimization, cost (e.g., energy consumption) is an equally important target for optimization. Second, computation offloading optimization should be performed for each UE individually and separately. Globalized, collective, and centralized optimization for all UEs is not very interesting to each UE. On the other hand, localized, individualized, and distributed optimization for each UE is more appropriate. Third, computation offloading optimization for a UE should be based on other UEs' behavior and the current workload already offloaded to the MECs, so that the best reaction and action can be taken. Fourth, computation offloading optimization should involve both UEs and MECs. While most cost and performance optimizations are conducted for UEs, the MECs also need to try to provide the highest quality of service with the lowest cost of service.

The best way to handle competition and conflict is negotiation to reach a win-win situation. While each UE or MEC is conducting its optimization, other UEs and MECs are also doing so. Each change to a UE's or an MEC's strategy causes other UEs and MECs to adjust their strategies. One immediate question is: “Is there a stable situation when no one wants to make further change, since any further change brings no benefit?”

1.2. New contributions
In this work, we adopt a game theoretical approach to computation offloading optimization in a fog computing environment. Such an approach captures and characterizes the nature of a competitive environment and can handle the multiple challenges mentioned above simultaneously. It is clear that both cost and performance can be incorporated into the payoff functions of the players, who can choose different methods to deal with the cost-performance tradeoff. Furthermore, both UEs and MECs can join a game and each UE or MEC optimizes its own payoff function individually and separately and maximizes its benefit.

The main contributions of the paper are summarized as follows.

•
First, we formulate a non-cooperative game with both UEs and MECs as players. Each UE attempts to minimize the execution time of its tasks with an energy constraint. Each MEC attempts to minimize the product of its power consumption for computation and execution time for allocated tasks.

•
Second, we develop a heuristic algorithm for a UE to determine its “heuristically” best response to the current situation, an algorithm for an MEC to determine its best response to the current situation, and an iterative algorithm to find the Nash equilibrium.

•
Third, we prove that our iterative algorithm converges to a Nash equilibrium. We demonstrate numerical examples of our non-cooperative games with and without MECs' participation. We observe that our iterative algorithm always quickly converges to a Nash equilibrium.

The uniqueness of our non-cooperative games is that the strategy set of a player can be discrete and the payoff function of a player can be obtained by a heuristic algorithm for combinatorial optimization. To the best of the author's knowledge, there has been no such investigation of non-cooperative games based on combinatorial optimization for computation offloading optimization in a fog computing environment.
The rest of the paper is organized as follows. In Section 2, we present the execution models for both offloaded and non-offloaded tasks and the power consumption models for both computation and communication. In Section 3, we describe a non-cooperative game played by all the UEs and MECs. In Section 4, we develop a group of algorithms to find the Nash equilibrium. In Section 5, we prove the existence of and convergence to a Nash equilibrium and give some characterizations of the Nash equilibrium. In Section 6, we demonstrate numerical examples. In Section 7, we review related research. In Section 8, we conclude the paper.

2. Models
In this section, we present the execution models for both offloaded and non-offloaded tasks and the power consumption models for both computation and communication. Table 1 gives a summary of notations and definitions in the order introduced in this paper.


Table 1. Summary of Notations and Definitions.

Notation	Definition
m	the number of UEs
UEi	the ith UE
n	the number of MECs
MECj	the jth MEC
Li	
, a list of independent tasks of UEi
ti,k	=(ri,k,di,k), a task of UEi
ri,k	the computation requirement of ti,k
di,k	the communication requirement of ti,k
si	the computation speed of UEi
the computation speed of MECj
ci,j	the communication speed between UEi and MECj
Pd,i	
, dynamic power consumption of UEi for computation
ξi, αi	technology dependent constants
Ps,i	static power consumption of UEi for computation
Pi	=Pd,i + Ps,i, power consumption of UEi for computation
, dynamic power consumption of MECj for computation
, 
technology dependent constants
static power consumption of MECj for computation
, power consumption of MECj for computation
Pt,i,j	the transmission power of UEi to MECj
wi,j	the channel bandwidth
βi,j	a combined quantity that encapsulates various factors
Si	=(Li,0,Li,1,Li,2,...,Li,n), a computation offloading strategy of UEi
Li,0	a sublist of tasks not offloaded and executed locally on UEi
Li,j	a sublist of tasks offloaded to MECj and executed remotely on MECj
Ri,j	total computation requirement of tasks in Li,j
Di,j	total communication requirement of tasks in Li,j
Rj	total computation requirement of tasks in MECj
the execution time of all tasks in UEi
the execution time of all tasks in MECj
Ti	the execution time of all tasks in Li, and the payoff function of UEi
Ei	the energy consumption of UEi for both computation and communication
the energy consumption of MECj for computation
Fj	
, the payoff function of MECj
Ai	=(Si,si,ci,1,...,ci,n), the action UEi
 the action of MECj
, an action profile
the existing workload on MECj
T	the same task completion time
⁎
the part of the execution time of MECj that UEi cannot change and control
⁎
⁎
⁎
⁎
⁎
⁎
⁎
, a Nash equilibrium
2.1. The execution models
The execution models for both offloaded and non-offloaded tasks are described in this section.

We consider a fog computing environment with multiple heterogeneous UEs and multiple heterogeneous MECs. Assume that there are m UEs, i.e., UE1, UE2, ..., UEm, and n MECs, i.e., MEC1, MEC2, ..., MECn.

UEi has a list of independent tasks 
, where 
, for all 
 and . Each task 
 is specified as 
, where 
 is the computation requirement (i.e., the amount of computation, measured by the number of billion processor cycles or the number of billion instructions (BI) to be executed) of 
, and 
 is the communication requirement (i.e., the amount of data to be communicated between UEi and an MEC, measured by the number of million bits (MB) to be transmitted) of 
.

UEi has computation speed 
 (i.e., the processor execution speed, measured by GHz or the number of billion instructions that can be executed in one second), for all , and MECj has computation speed 
, for all . If 
 is not offloaded and executed locally on UEi, the computation time (measured by seconds) of 
 on UEi is 
. If 
 is offloaded to an MECj and executed remotely on MECj, the computation time of 
 on MECj is 
.

The communication speed between UEi and MECj is 
 (i.e., the data transmission rate, measured by the number of million bits which can be transmitted per second), for all  and . If 
 is not offloaded and executed locally on UEi, there is no communication time. If 
 is offloaded to an MECj and executed remotely on MECj, the communication time (measured by seconds) between UEi and MECj for 
 is 
.

The execution time of a task is its computation time plus its communication time. If 
 is not offloaded and executed locally on UEi, the execution time of 
 is 
. If 
 is offloaded to an MECj and executed remotely on MECj, the execution time of 
 is 
, for all , , and 
.

2.2. The power consumption models
The power consumption models for both computation and communication are described in this section.

There are two components in the power consumption 
 (measured by Watts) of UEi for computation, i.e., dynamic power consumption and static power consumption. The dynamic component 
 is usually expressed as 
, where 
 and 
 are technology dependent constants. The static component 
 is usually a constant. Therefore, we have 
, for all . If 
 is not offloaded and executed locally on UEi, the energy consumption for computation (measured by Joules) of 
 on UEi is
 for all  and 
.

Similarly, the power consumption 
 of MECj for computation is calculated by 
, where 
, 
, and 
 are some constants, for all . If 
 is offloaded to an MECj and executed remotely on MECj, the energy consumption for computation of 
 on MECj is
 for all , , and 
.

A UE also incurs power consumption for communication. Let 
 be the transmission power (measured by Watts) of UEi to MECj, where  and . Then, we have
 
 for all  and , where 
 is the channel bandwidth and 
 is a combined quantity that encapsulates various factors such as (1) the channel gain between UEi and MECj, (2) the interference on the communication channel caused by other devices' data transmission to the same MEC, (3) and the background noise power.

The energy consumption for communication (measured by Joules) of 
 from UEi to MECj is
 
 for all , , and 
.

3. A non-cooperative game
In this section, we describe a non-cooperative game played by all the UEs and MECs.

A computation offloading strategy of UEi is a partition of 
 into  sublists
 such that all tasks in 
 are not offloaded and executed locally on UEi, and all tasks in 
 are offloaded to MECj and executed remotely on MECj, where  and . Define
 
 for all  and , and
 
 for all  and , and
 
 for all .

The execution time of all tasks in UEi is
 for all . The execution time of all tasks in MECj is
 
 for all . The execution time of all tasks in 
 is
 
 for all . Note that if 
, the execution time of all tasks in 
 is the execution time of all tasks in MECj, since the schedule of all tasks in MECj is not known. In other words, we should consider the execution times of all tasks in 
, plus the possible waiting time in the worst case. This is consistent with existing scheduling models [8], [9]. Furthermore, we do not consider overlap of computation and communication times.

The energy consumption of UEi for both computation and communication is
 
 
 for all . The energy consumption of MECj for computation is
 for all .

Our non-cooperative game includes  players, i.e., UE1, UE2, ..., UEm, and MEC1, MEC2, ..., MECn (see Fig. 1).

Fig. 1
Download : Download high-res image (71KB)
Download : Download full-size image
Fig. 1. A non-cooperative game with (m + n) players: UE1, UE2, ..., UEm, and MEC1, MEC2, ..., MECn.

Each UEi has an energy constraint 
. The payoff function of UEi is 
, i.e., the execution time of all tasks in 
. UEi has  variables to manipulate, i.e., the computation offloading strategy 
, the computation speed 
, and the communication speeds 
 for all . The objective of UEi is to find 
, 
, and 
 for all , such that 
 is minimized and that its energy consumption does not exceed the given budget 
.

Each MECj has one variable to manipulate, i.e., its computation speed 
. The payoff function of MECj is the power-time product (measured by Watts-seconds), i.e., 
 [32]. The objective of MECj is to find 
, such that 
 is minimized. (Notice that the power-time product is actually the cost-performance ratio, if we treat 
 as the cost (the lower, the better), and 
 as the performance (the higher, the better).)

Notice that the MECs are resources shared by all UEs. In other words, UEs compete for MECs. When the UEs offload more tasks to the MECs, the processing times on the MECs become longer. Therefore, the UEs will adjust their computation offloading strategies to process more tasks locally. When the UEs offload less tasks to the MECs, the processing times on the MECs become shorter. Therefore, the UEs will adjust their computation offloading strategies to process more tasks remotely. This process continues until a stable situation is reached, i.e., a situation when no UE wants to make further adjustment to its computation offloading strategy, because such change brings no more benefit.

The above process certainly becomes more complicated if the UEs can also adjust their computation and communication speeds. The process becomes even more complicated when the MECs also join the game. If MECj increases 
, more tasks will be offloaded to MECj. If MECj decreases 
, less tasks will be offloaded to MECj. When so many factors are involved and evolving in such a dynamics, we are definitely interested in whether the above dynamics eventually reaches a stable situation.

The action 
 of UEi is the combination of all its variables, i.e., 
. Similarly, 
 is the action of MECj. The combination of actions of all UEs and MECs, i.e., 
, is an action profile. A stable situation, i.e., a situation when any change to 
 makes 
 longer for all , and any change to 
 makes 
 greater for all , is called a Nash equilibrium, which is an action profile  with the property that no single player UEi or MECj can benefit from a unilateral deviation from , if all other players act according to it.

Our non-cooperative game is very unusual. Typically, the domain of a payoff function (i.e., the strategy set of a player) is a closed and convex set, and a payoff function is a continuous and twice differentiable function, whose optimal value can be obtained by multi-variable calculus. It is well known that if every player has a convex payoff function, then there exists a Nash equilibrium [28]. However, in our case, the strategy set of a player includes 
, which is a partition of a list of tasks, and is certainly discrete. Furthermore, as we will see soon in the next section, the payoff function of a UE is calculated by a heuristic algorithm for combinatorial optimization, which does not necessarily produce an optimal solution (i.e., the optimal response of a UE to the current situation). Under the above circumstance, it becomes unclear whether our non-cooperative game has a Nash equilibrium. Even if there exists a Nash equilibrium, it is not clear whether our iterative algorithm converges to a Nash equilibrium. It is interesting to know under what conditions there exists a Nash equilibrium for our game and the game converges.

4. The algorithms
A group of algorithms are developed in this section to find the Nash equilibrium.

4.1. A heuristic response of a UE
In this section, we give a heuristic algorithm for a UE to find its “best” response to the current situation.

First of all, we would like to mention that it is an NP-hard problem for a UE to find its optimal response to the current situation, even if there is only one UE, one MEC, and the UE is the only player [17]. Therefore, the best we can hope is a heuristic response of a UE.

When UEi makes its decision, the MECs are already preloaded with tasks from other UEs. Let
 
 which is the existing workload on MECj, for all .

We take two steps to develop a heuristic algorithm for UEi to decide an action 
. Thus, our algorithm, which is presented in Algorithm 1, includes two stages. In the first step (which is actually the second stage of our algorithm, i.e., lines (9)–(13)), we consider the following problem, i.e., for a given computation offloading strategy 
, how to minimize the execution time 
 by choosing the computation speed 
 and the communication speeds 
, for all . In the second step (which is actually the first stage of our algorithm, i.e., lines (1)–(8)), we consider how to generate a computation offloading strategy 
.

Note that our algorithm is generalized from the heuristic algorithm for optimal computation offloading with energy constraint developed in [17] for a single UE without preloaded tasks from other UEs to a competitive fog computing environment with multiple UEs.


Image 1
For the first step, we observe that UEi should allocate its energy budget 
 in such a way that all MECj's with 
 and UEi complete their tasks at the same time (see Fig. 2), i.e.,
 where 
 are indices such that 
, 
, ..., and 
. The above equation gives rise to
 and
⁎
 where
⁎
 for all  and 
. Note that 
⁎
 is the part of the execution time of MECj that UEi cannot change and control. If the above condition is not satisfied, we can shift some energy from an MEC/UE which completes the earliest to an MEC/UE which completes the latest, thereby reducing 
 without increasing 
. Hence, to most efficiently utilize the energy budget 
, we must have(1)
 
 
⁎
 
⁎
 for all . (Notice that the above equation holds even if 
 and 
, i.e., UEi does not offload any task to MECj for some j.) The value of T can be obtained numerically by using a bisection search and noticing that the left-hand side of the above equation is a decreasing function of T.

Fig. 2
Download : Download high-res image (104KB)
Download : Download full-size image
Fig. 2. Illustration of Algorithm 1: All MECj's with Li,j ≠ ∅ and UEi must complete their tasks at the same time. Black areas mean preloaded tasks.

For the second step, we employ a greedy method to gradually construct
 Let
 be the T obtained by solving Equation (1). In the beginning, no task is offloaded (lines (2)–(4)). Then, the tasks in 
 are scanned one by one (line (5)). For each task 
, we choose the MECj (for convenience, UEi is treated as MEC0) in such a way that if 
 is offloaded to MECj, the new 
, i.e.,
 in line (6), is the minimum, for all . (Notation: We define 
 to be the index j such that 
.) This is the key idea of the greedy method, and the most important part of the algorithm is in lines (6)–(7).

Once T is determined (line (9)), the computation speed 
 and the communication speeds 
 can be computed routinely (lines (10)–(13)).

The time complexity of Algorithm 1 is analyzed as follows. The most time consuming part of the algorithm is the for-loop in lines (5)–(8), which is repeated 
 times (line (5)). Line (6) needs to solve Equation (1)  times. Lines (6) and (9) solve Equation (1) by using the bisection method, which needs to reduce a search internal of length I to certain accuracy requirement ϵ and requires  repetitions. Each repetition needs to calculate the left-hand side of Equation (1) and requires  time. Therefore, the overall time complexity of the algorithm is 
, fairly efficient.

Finally, we make the following important assumption, namely, a UE does not take any action if it is not able to find an action to reduce its payoff. Since the best response of a UE is obtained by using a heuristic algorithm, it is not necessarily the optimal response. Such a heuristic response may even increase the payoff of a UE, which may prevent our game from reaching a stable situation or make the convergence process longer and slower. If that is the case, a UE would rather do nothing than making its payoff greater.

4.2. The best response of an MEC
We now give an algorithm for an MEC to find its best response to the current situation.

Notice that
 
 for all . Let
 
 Then, we have
 and
 
 
 To minimize 
, we only need to find 
 such that 
, i.e.,
 Although there is no closed-form solution of 
, it can be easily found by a bisection search in the interval
 
 by noticing that the left-hand side of the above equation is an increasing function of 
.


Image 2
Our algorithm for MECj to decide an action 
 is presented in Algorithm 2. It is easy to see that the time complexity of the algorithm is , very efficient.

4.3. An iterative algorithm for Nash equilibrium
We develop an iterative algorithm to find the Nash equilibrium in this section, which is presented in Algorithm 3.

A game is initialized with 
, for all  and . The computation and communication speeds are set to any reasonable values. A Nash equilibrium can be found by allowing the players to play in rounds (lines (2)–(16)). In each round, UE1, UE2, ..., UEm, and MEC1, MEC2, ..., MECn play in turn. Each UEi applies Algorithm 1 to find its action 
 (lines (3)–(5)), which is its “heuristically” best response to the current situation. Each MECj applies Algorithm 2 to find its action 
 (lines (6)–(8)), which is its best response to the current situation. A game is over when the difference between the action profiles of two successive rounds, i.e., 
 and , is within certain accuracy requirement ϵ (lines (10)–(15)). The final converged action profile
⁎
⁎
⁎
⁎
⁎
⁎
⁎
 is produced as the Nash equilibrium, i.e., a strategy profile with the unique property that no player can have better payoff from a unilateral deviation from 
⁎
 or 
⁎
, if all other players act according to 
⁎
.


Image 3
The termination detection condition in line (10) is
 
 
 
 
 
 
 Since Algorithms 1 and 2 are invoked m and n times in each round, the time complexity of each round is 
, where 
, and the overall time complexity of Algorithm 3 is 
, where N is the number of rounds (i.e., the number of repetitions of the loop in lines (2)–(16), which is essentially determined by the accuracy requirement ϵ in line (10). (We set 
 in this paper.)

We would like to mention that the above iterative algorithm can be implemented in a centralized or decentralized way.

5. Nash equilibrium
5.1. Existence of and convergence to the Nash equilibrium
In this section, we show that our game has a Nash equilibrium and our iterative algorithm converges to the Nash equilibrium, no matter whether the MECs join the game.

Theorem 1

Our game with or without MECs' participation converges to a Nash equilibrium.

Proof

Recall that an action 
 of UEi contains a computation offloading strategy 
 (i.e., the assignment of tasks to the UE and the MECs) and an energy allocation strategy (i.e., the determination of the computation speed 
 and the communication speeds 
 based on an energy constraint 
). The payoff function of UEi is
 
 where 
, for all . Each UEi takes an action by using the heuristic Algorithm 1. We emphasize that UEi takes no action if it cannot find a better computation offloading strategy or a better energy allocation strategy to reduce its payoff 
. A Nash equilibrium is a situation where no UEi (and no MECj of course) would take any more action.

Assume that before and after UEi takes an action (i.e., a heuristic response to the current situation), tasks in 
 are assigned to the UE and the MECs according to 
 and 
 respectively. The quantities 
, 
, 
, 
, 
, and 
 can be defined accordingly.

To take the action, UEi needs to withdraw its tasks from MECj with 
, leading to reduced execution time of these MECs, i.e.,
 for all 
. Then, tasks in 
 with 
 are assigned to MECj, leading to increased execution time of these MECs, i.e.,
 for all 
.

Let us define 
, and 
, for . Then, we have 
 and 
. We notice that 
; otherwise, UEi would not take the action.

All MECj's with 
 are affected by the action of UEi. We can show that for these affected MECs, we have
 To this end, we observe that
 where we notice that (1) 
; (2) 
, since each MECj with 
 losses some tasks of UEi; (3) 
, since 
; (4) 
, so that MECj with 
 can receive tasks from UEi.

The above discussion essentially means that each action of UEi reduces its payoff 
 (i.e., 
 or the maximum execution time of all affected (i.e., 
) MECs), while 
 of MECj with 
 is not affected. We define
⁎
 
 
 which is the makespan, i.e., the time to complete all tasks of all UEs on the m UEs and n MECs. If 
⁎
, an action of UEi reduces 
⁎
. It is clear that this cannot happen forever, since there is a lower bound for 
⁎
, which depends on the 
's (i.e., the energy constraints), the 
's (i.e., the computation speeds), and the computation and communication requirements. At certain point, no UEi can take any action to reduce 
⁎
. Note that although 
 is never increased by UEi, 
 can still be changed (either increased or decreased) by MECj. However, 
⁎
 is never increased by a UE, and cannot be reduced by the UEs forever.

When 
⁎
 cannot be reduced further, any UEi with 
⁎
 will not take any further action. However, other UEi's may still reduce their payoffs. We remove the UEi's with 
⁎
 and the MECj's with 
⁎
, plus the UEi's that have tasks on these MECs from further consideration, since all these UEs and MECs will not be involved in the game anymore, and apply the same argument on the remaining UEs and MECs. Eventually, no UEi can take any action to reduce its 
 (i.e., its payoff). When all UEs stop taking any more action, all MECs do not take further action either. Therefore, the game eventually terminates and reaches a Nash equilibrium. The theorem is proved. □

The above discussion implies that if each UE could find its optimal response (which is unlikely to be obtained efficiently due to NP-hardness), so that it never increases its payoff, an iterative algorithm eventually converges to a Nash equilibrium. However, what will happen if each UE is only able to take a heuristic action? Is there a Nash equilibrium? Can it be reached? Our answer is that a heuristic algorithm should be applied in a protective way (e.g., to make sure that a heuristic response does not make things worse).

5.2. Characterizations of the Nash equilibrium
In this section, we give some characterizations of the Nash equilibrium.

Let us define 
, for all . We construct an undirected graph G, which has m vertices, i.e., 
, where 
 stands for UEi, for all . There is an edge between 
 and 
 if and only if 
, for all 
.

The following result shows how a Nash equilibrium looks like.

Theorem 2

In a Nash equilibrium, all UEi's in the same connected component of G have the same 
, i.e., we have 
, if and only if 
 and 
 are connected in G (i.e., there is a path between 
 and 
).

Proof. Let 
 and 
. Then, Algorithm 1 guarantees that 
, and 
. It is clear that 
 if 
, i.e., there is an edge between 
 and 
. By the transitivity of equality, we know that 
, if and only if 
 and 
 are connected in G.  □

Likewise, we define 
, for all . We construct an undirected graph 
, which has n vertices, i.e., 
, where 
 stands for MECj, for all . There is an edge between 
 and 
 if and only if 
, for all 
.

Similar to Theorem 1, we have the following result.

Theorem 3

In a Nash equilibrium, all MECj's in the same connected component of 
 have the same 
, i.e., we have 
, if and only if 
 and 
 are connected in 
 (i.e., there is a path between 
 and 
).

Proof. Let 
 and 
. Then, Algorithm 1 guarantees that 
, and 
. It is clear that 
 if 
, i.e., there is an edge between 
 and 
. By the transitivity of equality, we know that 
, if and only if 
 and 
 are connected in 
.  □

6. Numerical examples
Numerical examples are demonstrated in this section.

First, we give an example without MECs' participation of a game. We consider a fog computing environment with  UEs and  MECs. The parameters of the UEs are set as follows: 
, 
, 
 Watts, for all . The parameters of MECj are set as follows: 
 BI/second, 
 MB/second, 
 Watts−1, for all  and . Each UE generates a list of 
 random tasks. Tasks are randomly generated, such that the 
's are independently and identically and uniformly distributed in the range , and the 
's are independently and identically and uniformly distributed in the range . The energy constraint is 
 Joules, for all .

In Table 2, we show one instance of the game. We demonstrate the 
's, the 
's, and the 
's in the Nash equilibrium. The game terminates after only  rounds (very fast speed of convergence). The Nash equilibrium results in 
 seconds, for all  and . (Both G and 
 are connected.) We observe that it is possible for a UE not to offload any task to an MEC, i.e., 
, for some  and . Furthermore, at least half of the tasks are processed locally in a UE, and each UE consumes most of its energy on computation.


Table 2. A Numerical Example of Nash Equilibrium without MECs' Participation (N = 17 Rounds).

UEi	MEC1	MEC2	MEC3	MEC4	MEC5	MEC6	MEC7	Ei/Ri/Di
i = 1	Ei,j	5.68799	0.38135	0.50962	0.00000	0.00000	0.00000	0.00000	0.42104	7.00000
si,ci,j	1.95025	1.35922	2.52615	0.00000	0.00000	0.00000	0.00000	0.94539	
Pi,Pt,i,j	0.43035	0.18448	0.39956	0.00000	0.00000	0.00000	0.00000	0.14260	
Ri,j	25.77680	2.27151	4.49176	0.00000	0.00000	0.00000	0.00000	7.60496	40.14503
Di,j	17.55529	2.80977	3.22203	0.00000	0.00000	0.00000	0.00000	2.79126	26.37834

i = 2	Ei,j	5.39995	0.21755	0.30548	0.00000	0.50669	0.42040	0.64992	0.00000	7.50000
si,ci,j	1.89356	1.52729	2.12690	0.00000	1.39705	0.95892	2.21070	0.00000	
Pi,Pt,i,j	0.40856	0.21158	0.32049	0.00000	0.20061	0.13494	0.36621	0.00000	
Ri,j	25.02744	1.92336	2.07679	0.00000	5.31335	3.58355	6.79737	0.00000	44.72187
Di,j	14.19977	1.57036	2.02733	0.00000	3.52862	2.98742	3.92340	0.00000	28.23690

i = 3	Ei,j	5.45696	0.42203	0.84080	0.92559	0.17214	0.00000	0.00000	0.18249	8.00000
si,ci,j	1.90492	2.71551	9.94725	2.42037	1.05162	0.00000	0.00000	0.58882	
Pi,Pt,i,j	0.41287	0.43638	4.33987	0.38291	0.14540	0.00000	0.00000	0.08575	
Ri,j	25.17753	2.69918	4.85196	11.04108	1.84395	0.00000	0.00000	3.37927	48.99295
Di,j	14.06798	2.62618	1.92716	5.85068	1.24500	0.00000	0.00000	1.25309	26.97010

i = 4	Ei,j	4.99659	0.35577	0.38041	0.22704	0.42045	0.81869	0.86454	0.43651	8.50000
si,ci,j	1.81118	1.04458	0.95544	0.95618	1.44519	1.58518	1.71558	1.55584	
Pi,Pt,i,j	0.37804	0.13648	0.12535	0.12785	0.20863	0.23843	0.26974	0.24948	
Ri,j	23.93868	2.85925	1.52239	4.99490	4.17004	5.18175	5.55364	4.34410	52.56474
Di,j	11.99328	2.72288	2.89956	1.69804	2.91249	5.44287	5.49864	2.72228	35.89002

i = 5	Ei,j	6.30643	0.40702	0.15424	0.20772	0.40631	1.07164	0.44665	0.00000	9.00000
si,ci,j	2.06674	1.55248	0.71009	0.91500	1.81438	6.66156	1.23532	0.00000	
Pi,Pt,i,j	0.47714	0.21573	0.09056	0.12178	0.27288	1.80543	0.18478	0.00000	
Ri,j	27.31636	4.23057	4.62199	4.45530	4.88139	7.02861	2.19925	0.00000	54.73347
Di,j	17.04167	2.92904	1.20934	1.56071	2.70154	3.95408	2.98600	0.00000	32.38238
Next, we give an example with MECs' participation of a game. We use the same parameter setting as the above example, with MECj further set with 
, 
, 
 Watts, for all .

In Table 3, we show one instance of the game. We demonstrate the 
's, the 
's, and the 
's in the Nash equilibrium. The game terminates after  rounds (relatively slower speed of convergence due to more players and more complicated dynamics). The Nash equilibrium results in 
 seconds, for all  and . (Both G and 
 are connected.) We also display the 
's and the 
's. We observe that to optimize the power-time product, each MECj chooses a speed slower than the one in the last example. The reduced computation speeds of the MECs result in increased execution times. Furthermore, each UE tends to offload tasks to fewer MECs, and the computation offloading strategy produces less balanced workload and energy distributions.


Table 3. A Numerical Example of Nash Equilibrium with MECs' Participation (N = 22 Rounds).

UEi	MEC1	MEC2	MEC3	MEC4	MEC5	MEC6	MEC7	Ei/Ri/Di
i = 1	Ei,j	5.31642	0.36574	0.00000	0.00000	0.73928	0.00000	0.57855	0.00000	7.00000
si,ci,j	1.80240	1.69892	0.00000	0.00000	1.69947	0.00000	7.58096	0.00000	
Pi,Pt,i,j	0.37486	0.24036	0.00000	0.00000	0.25234	0.00000	2.32516	0.00000	
Ri,j	25.56210	3.42505	0.00000	0.00000	7.24179	0.00000	2.61635	0.00000	38.84530
Di,j	20.10906	2.58508	0.00000	0.00000	4.97888	0.00000	1.88632	0.00000	29.55934

i = 2	Ei,j	4.55158	0.33437	0.15172	0.00000	0.00000	0.69901	1.35604	0.40727	7.50000
si,ci,j	1.64601	6.84598	0.92205	0.00000	0.00000	2.69819	8.43559	1.26943	
Pi,Pt,i,j	0.32093	1.93175	0.12050	0.00000	0.00000	0.45836	2.87691	0.19777	
Ri,j	23.34415	3.54072	4.20739	0.00000	0.00000	6.37446	9.77021	4.13530	51.37223
Di,j	17.25935	1.18499	1.16092	0.00000	0.00000	4.11479	3.97614	2.61418	30.31037

i = 3	Ei,j	5.66227	0.39815	0.38011	0.52740	0.52930	0.50278	0.00000	0.00000	8.00000
si,ci,j	1.86882	7.73635	1.52798	1.14391	4.10586	2.84006	0.00000	0.00000	
Pi,Pt,i,j	0.39925	2.48718	0.21435	0.15621	0.80522	0.49015	0.00000	0.00000	
Ri,j	26.50415	4.77339	2.14072	6.69743	7.68104	3.37654	0.00000	0.00000	51.17328
Di,j	15.75653	1.23843	2.70959	3.86206	2.69893	2.91321	0.00000	0.00000	29.17876

i = 4	Ei,j	6.95541	0.59644	0.14925	0.00000	0.43851	0.00000	0.00000	0.36039	8.50000
si,ci,j	2.09864	4.97265	0.59590	0.00000	4.62322	0.00000	0.00000	1.18492	
Pi,Pt,i,j	0.49043	1.07740	0.07501	0.00000	0.96518	0.00000	0.00000	0.18305	
Ri,j	29.76351	4.68410	1.54925	0.00000	4.05923	0.00000	0.00000	1.67294	41.72904
Di,j	23.77262	2.75283	1.18562	0.00000	2.10045	0.00000	0.00000	2.33293	32.14444

i = 5	Ei,j	6.56155	0.30264	0.39649	0.39218	0.00000	0.41044	0.54923	0.38746	9.00000
si,ci,j	2.03140	1.76494	1.36840	0.91048	0.00000	0.99194	1.46789	0.84029	
Pi,Pt,i,j	0.46266	0.25174	0.18839	0.12112	0.00000	0.14008	0.22491	0.12544	
Ri,j	28.80988	4.61703	2.49474	4.87807	0.00000	4.60810	9.13011	4.01971	58.55764
Di,j	15.08625	2.12176	2.87998	2.94817	0.00000	2.90651	3.58457	2.59555	32.12279

1.99024	1.47288	1.52952	1.87182	1.65021	1.95249	1.39103	

3.18832	2.52911	2.45504	2.64601	2.30803	2.45305	1.86439	
Our extensive experiments reveal the fact that our game always converges to a Nash equilibrium. However, if the heuristic algorithm employed by the UEs is not protected, our game may not converge or take much longer time (i.e., more rounds and more iterations) to converge to a Nash equilibrium. A non-cooperative game involving combinatorial optimization, especially heuristic algorithms, is a truly interesting and challenging research topic.

We would like to mention that strictly speaking, our non-cooperative game played by the UEs equipped with a heuristic algorithm H can only reach a Nash equilibrium with respect to H, i.e., a stable situation where no UE wants to make further change by using H. However, by using another heuristic, especially an optimal algorithm, further changes are still possible, and eventually, another equilibrium may be reached.

7. Related research
Related research is reviewed in this section.

Computation offloading optimization in fog computing and mobile edge computing has been a very active and productive research area in the last few years, with extensive investigation performed. Refs. [1], [13], [14], [23], [29], [30] provide some recent comprehensive surveys.

Game theoretical techniques have been widely adopted and applied by many researchers in fog computing and mobile edge computing. In particular, the game theoretical approach has been used to investigate computation offloading strategies of several competitive and selfish mobile users. Many game models have been developed to study various environments of computation offloading.

Several researchers have considered fog computing environments with multiple mobile users, where each user possesses only one task to process. For cloudlet based mobile cloud computing in a multi-channel wireless contention environment, the problem of multi-user computation offloading was investigated by Cao and Cai, who formulated a non-cooperative game for the multi-user computation offloading decision making problem, where every user has a single task with the same amount of computation and aims to minimize a weighted sum of energy consumption and execution time [2]. A decentralized computation offloading game was formulated by Chen for decentralized computation offloading decision making among multiple mobile device users, where each user has a computation intensive and delay sensitive task and minimizes a weighted sum of energy consumption and computation time [5]. For mobile edge cloud computing in a multi-channel wireless interference environment, the multi-user computation offloading problem was studied by Chen et al., and it was shown that it is NP-hard to compute a centralized optimal solution, and a game theoretic approach was adopted to achieve efficient computation offloading in a distributed manner [6]. A cooperative game based framework for quality of service (QoS) guaranteed offloading in a multiple MECs environment was constructed by Liu et al. to maximize the number of tasks whose QoS requirements are satisfied, where each UE has one task and both UEs and MECs are players of the game [19]. By including both energy consumption and delay (i.e., computing and transmission delay) into consideration, computation offloading strategies of multiple users via multiple wireless access points were researched by Ma et al., who conducted a game-theoretic analysis of the computation offloading problem with the consideration of the selfish nature of the players [22]. Using a game theoretic framework resulting in a nonconvex generalized Nash game, Nowak et al. considered several mobile users with a splittable computation task each, which try to minimize their own computation times by offloading fractions of their tasks to a central access point with a cloudlet [26].

Fog computing environments with multiple users, where each user has multiple tasks, have also been explored. A usage scenario was considered by Cardellini et al., where multiple non-cooperative mobile users share the limited computing resources of a close-by cloudlet and can selfishly make decisions in sending computations to three available tiers, i.e., a local tier of mobile computing devices, a nearby tier of fog computing nodes, and a remote tier of cloud computing servers [3]. A non-cooperative game model was constructed by Chen et al. to find an optimal computation offloading policy for each UE, with the objective to minimize a weighted sum of time consumption and energy consumption [4]. A non-cooperative game framework was established by Li to systematically study stabilization of a competitive mobile edge computing environment involving multiple UEs and a single MEC, with a set of seven non-cooperative games among the UEs and the MEC, each attempts to minimize its cost-performance ratio [16]. The problem of multi-user computation offloading under a dynamic environment, wherein mobile users may become active or inactive dynamically, and the wireless channels for users to offload computation may vary randomly, was investigated by Zheng et al., using a stochastic game which is proved to be equivalent to a potential game [33]. However, in all the above studies, only a single MEC was considered.

There has been investigation concerning fog computing environment with multiple MECs. Based on the evolutionary game theory to deal with task offloading to multiple heterogeneous edge nodes and central clouds among multiple users, Dong and Wen studied a dynamic and decentralized resource allocation strategy [7]. Ge et al. proposed a game-theoretic approach to optimizing the overall energy in a mobile cloud computing system, where the energy minimization problem is formulated as a congestion game, in which, each mobile device selects a server to offload computation while minimizing the overall energy consumption [10]. From the perspective of a non-cooperative game, Hu et al. constructed a mechanism of task offloading for a system with multiple MECs and multiple UEs with delay constraints to optimize the benefits of both MECs and UEs [11]. Using a game theoretic model, Jošilo and Dán considered autonomous devices, each optimizes its own performance by choosing a wireless access point for computation offloading [12]. Multiple heterogeneous mobile users competing for resources from multiple heterogeneous mobile edge clouds were considered by Li, who used the game theoretic approach to finding the optimal computation offloading strategy for each mobile user in a stabilized fog computing environment [15]. Li et al. proposed a Stackelberg computing offloading game for mobile devices and edge cloud servers and proposed two algorithms for delay-sensitive and compute-intensive applications [18]. Under situations involving complete and incomplete information, Liwang et al. developed a two-player Stackelberg-game-based opportunistic computation offloading scheme, that primarily considers task completion duration and service price [21].

Game theory based means and methods have also been employed to study various other issues in mobile edge computing. Liu et al. formulated the interactions among a cloud service operator and edge server owners as a Stackelberg game, which attempts to maximize the utilities of the cloud service operator and edge server owners by obtaining the optimal payment and computation offloading strategies [20]. Messous et al. tackled the problem of offloading heavy computation tasks of unmanned aerial vehicles while achieving the best possible tradeoff between energy consumption, time delay, and computation cost, using a non-cooperative theoretical game [24]. By using the theory of minority games, Ranadheera et al. developed a novel distributed server activation mechanism for computation offloading, which guarantees energy-efficient activation of servers as well as satisfaction of users' quality-of-experience requirements in terms of latency [27]. Based on the framework of prospect theory (PT), Tang and He formulated users' decision making of whether to offload or not as a PT-based non-cooperative game, and proposed a distributed computation offloading algorithm to achieve the Nash equilibrium of the game [31].

It is noticed that game theory has also been extensively used for mobile data offloading in heterogeneous networks [25].

8. Concluding remarks
In this paper, we have established a non-cooperative game played by multiple UEs and multiple heterogeneous MECs, each has its own variables to manipulate and its own payoff function to minimize. A unique feature of the game is that each UE can only find a heuristic response to the current situation. We have proved the convergence of our non-cooperative game involving NP-hard combinatorial optimization.

We would like to mention that the existence of a Nash equilibrium and the convergence of an iterative algorithm for a game, where the payoff function of a player is calculated by a heuristic algorithm for NP-hard combinatorial optimization, which does not necessarily produce an optimal solution (i.e., the optimal response of a player to the current situation), are very challenging issues and deserve further investigation.

It is interesting to consider other fog computing environment with multiple competitive UEs. For instance, the UEs may be divided into groups, where UEs in the same group have common interest and are willing to collaborate. As one example, a group of UEs may want to minimize the total execution time of all their tasks, where each UE has its own energy constraint. In such a situation, a cooperative game (or a coalitional game) can be formulated to optimize the collective payoff of each group which take joint actions, where there are conflict and competition among coalitions. It is likely that the algorithms and analysis in this paper are applicable and extensible to such an environment.