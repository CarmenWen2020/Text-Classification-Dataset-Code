Abstract
This paper investigates the power of randomization in general distributed algorithms in dynamic networks where the network's topology may evolve over time, as determined by some adaptive adversary. In such a context, randomization may help algorithms to better deal with i) “bad” inputs to the algorithm, and ii) evolving topologies generated by “bad” adaptive adversaries. We prove that randomness offers limited power to better deal with “bad” adaptive adversary. We define a simple notion of prophetic adversary for determining the evolving topologies. Such an adversary accurately predicts all randomness in the algorithm beforehand, and hence the randomness will be useless against “bad” prophetic adversaries. Given a randomized algorithm P whose time complexity satisfies some mild conditions, we prove that P can always be converted to a new algorithm Q with comparable time complexity, even when Q runs against prophetic adversaries. This implies that the benefit of P using randomness for dealing with the adaptive adversaries is limited.


Keywords
Derandomization
Distributed algorithms
Adversary
Dynamic networks

1. Introduction
Background. Understanding the power of randomization has long been a key goal in algorithms research. Over the years, researchers have obtained many interesting results on the power of randomization, such as in centralized algorithms (e.g., [25]), in parallel algorithms (e.g., [21]), and in algorithms in static networks (e.g., [7], [8], [10], [12], [22]). This paper aims to gain deeper insights into the power of randomization in general distributed algorithms in dynamic networks with adaptive adversaries. Dynamic networks [4], [6], [16], [23] model communication networks whose topologies may change over time, and have been a growing research topic in distributed computing. While randomization has been used extensively to solve various specific problems in dynamic networks (e.g., [16], [17]), prior works have not focused on the power of randomization in general distributed algorithms in dynamic networks (i.e., to what extent randomized algorithms can outperform deterministic ones).

Our setting. We consider a synchronous dynamic network with a fixed set of n nodes. The network topology in each round is some arbitrary connected and undirected graph as determined by an adaptive adversary, and we adopt the following commonly-used model [18], [19], [26]: The adaptive adversary decides the round-r topology based on the algorithm's coin flip outcomes so far (i.e., up to and including round r). The adaptive adversary does not see the coin flip outcomes in round  or later. We follow the communication model in [14], [26]: In each round, a node may choose to either send an  size message (i.e., the broadcast  model [24]) or to receive. A message sent is received, by the end of that round, by all the receiving neighbors of the sender in that round. Each node has some input of arbitrary size and a unique id between 0 and . We consider general distributed computing problems modeled as some arbitrary function of the n input values (as an input vector). The output of the function is also a vector of length n, and node i should output the -th entry of that vector. There is no constraint on the output size. An algorithm in this paper always refers to some algorithm for solving some distributed computing problem as modeled in the above way. Note that many problems that are not typically defined as functions, such as computing a unique minimum spanning tree (of some input graphs) and token dissemination [9], [17], can nevertheless be modeled as a function. The time complexity is defined to be the number of rounds needed for all nodes to output. An algorithm P's time complexity, denoted as 
, corresponds to its time complexity under the worst-case scenario. Here the worst-case scenario consists of i) the worst-case input (vector), and ii) the worst-case adaptive adversary for generating dynamic networks with at most n nodes and at most d dynamic diameter. The dynamic diameter [18] of a dynamic network, intuitively, is the minimum number of rounds needed for a node u to causally influence another node v, when considering the worst-case u and v in the dynamic network. Section 2 gives a full description of the model.

Practical relevance. Before proceeding further, we quickly comment on the practical relevance of research on dynamic networks. Research on dynamic networks (e.g., [18], [19], [26], as well as this work), in its current stage, is still mostly of theoretical nature. These theoretical research results might eventually benefit for example, applications running over mobile ad hoc networks that need to provide provable performance guarantees. The topology of a mobile ad hoc network can naturally change over time, due to mobility and changing channel conditions. If provable performance guarantees are needed in such a context, we will have to consider the worst-case topologies/adversaries. In turn, the theoretical results on dynamic networks could become applicable.

Randomness in dynamic networks. For any given deterministic algorithm, informally, let us call its corresponding worst-case scenario as a “bad” scenario. A “bad” scenario for one deterministic algorithm may very well not be a “bad” scenario for other deterministic algorithms. Since a randomized algorithm is a distribution of deterministic algorithms, intuitively, randomization potentially helps to better deal with all those “bad” scenarios. For algorithms in dynamic networks, a “bad” scenario consists of a “bad” input and a “bad” adaptive adversary.

For dealing with “bad” inputs in dynamic networks, it is not hard to see that randomization can help to reduce the time complexity exponentially. For example, consider the two-party communication complexity (CC) problem Equality [20]. Let m be the size of the input, then Equality has a randomized CC of  bits, and a deterministic CC of  bits [20]. Under our setting of dynamic networks with congestion, this exponential gap in the CC of Equality directly translates to an exponential gap in the time complexity.

A quick conjecture? For dealing with “bad” adaptive adversaries, on the other hand, one may quickly conjecture that randomness has limited power: On the surface, since the randomness in round r is already visible to the adaptive adversary when it chooses the round-r topology, such randomness offers no help for better dealing with the round-r topology. But a deeper look shows that the randomness in round r could potentially help the algorithm to better deal with round-
 (
) topologies: Consider an example algorithm that uses the first  rounds to flood a certain token in the network, where  can be smaller than the network's dynamic diameter d. Let S be the set of nodes that have received the token by the end of round . In round r and later, the algorithm may want to estimate the size of S (e.g., to estimate whether the token has reached some constant fraction of the nodes). The adaptive adversary can influence S, by manipulating the topologies in the first  rounds. But by the end of round , the set S will be fixed — effectively, the adaptive adversary has now committed to S. The algorithm's randomness in round r and later is independent of S. Thus for the remainder of the algorithm's execution (i.e., the part starting from round r), S can be viewed as a “midway input”. The randomness in the remainder of the algorithm's execution can potentially help to better deal with such “midway inputs”, and hence help indirectly to better deal with the adaptive adversary's “bad” behavior in the first  rounds.

Given such possibility, it is unclear whether the earlier quick conjecture holds or whether it may even be wrong. Resolving this will be our goal.

Our results for LV algorithms. As our main novel result, we prove that the earlier conjecture does hold, subject to some mild conditions on the algorithm's time complexity. (We will fully specify these mild conditions later.) As one will see later, proving this conjecture is far from trivial. We first need to expose the power of randomization for dealing with adaptive adversaries, and in particular, to properly isolate such power from the power of randomization for dealing with inputs. It is not immediately obvious how to do this since the same randomness may be used for dealing with both inputs and adaptive adversaries. To this end, we define a simple notion of prophetic adversary for determining the dynamic network. A prophetic adversary first sees (accurately predicts) all coin flip outcomes of a randomized algorithm in all rounds, and then decides the dynamic network (i.e., topologies in each round). This enables a prophetic adversary to always choose the worst-case dynamic network for the given coin flip outcomes. Hence the randomness in the algorithm can never help to better deal with dynamic networks generated by “bad” prophetic adversaries.

Now let us consider adaptive adversaries that generate dynamic networks with at most n nodes and at most d dynamic diameter. Let P be any Las Vegas (LV) algorithm whose time complexity (under the worst-case among all such adaptive adversaries) is 
, for some  and  where there exists some constant a such that 
 and 
.2,3 We prove (Theorem 7, Theorem 8) that P can always be converted into another LV algorithm Q whose time complexity under worst-case prophetic adversaries is 
. This means that even when the adversary accurately predicts all randomness in Q, Q's time complexity is still only 
. In turn, the benefit of randomization (in P) for dealing with the adaptive adversaries is at most to reduce the complexity by a  factor. This proves the earlier conjecture affirmatively (under the previous mild conditions).

The more general version (Theorem 8) of our results actually holds for P as long as P's time complexity is upper bounded by some polynomial — namely, as long as there exists some constant a such that 
, and without any other constraints on 
. Here for any given LV algorithm P, we can construct another LV algorithm Q whose time complexity under prophetic adversaries is 
 for some constant 
. Hence in this more general case, our results imply that the power of randomization (in P) for dealing with adaptive adversaries is at most a 
 multiplicative factor when 
.

Finally, the above shows that for dealing with adaptive adversaries, the power of randomization is inherently limited. This suggests that if an algorithm is not using randomness for better dealing with the inputs, we should be able to derandomize it efficiently. We show how this can be done for a certain class of LV algorithms in Section 4.2.

Our results for MC algorithms. We have also obtained similar results for Monte Carlo (MC) algorithms. Consider any constant  and any δ-error Monte Carlo (MC) algorithm P such that 
, where there exists some constant a such that 
 and 
. Then we can always construct another -error MC algorithm Q for solving the same problem and whose time complexity under worst-case prophetic adversaries is 
. A more general version of this result holds for P as long as there exists some constant a such that 
, and without any other constraints on 
. In this more general version, our algorithm Q will have a time complexity of 
.

Challenges and our techniques. To obtain Q from P as in the above results, we essentially need to “derandomize” the part of P's randomness used to deal with the adaptive adversaries. It turns out that such randomness is less amenable to typical derandomization methods such as pairwise independence, conditional expectation, or network decomposition. This motivated us to take a rather different route from prior derandomization efforts [5], [7], [8], [10], [12], [21], [22], [25], as follows.

At a high level, in our approach, we have Q simulate the execution of P against some adaptive adversary 
 that we carefully construct. (Namely, Q simulates both P and 
.) Let ψ be the prophetic adversary against which Q runs. A node u running Q will internally invoke P, and check what messages P needs to send from u. Next, if u has any receiving neighbors in the dynamic network generated by 
, then u will flood these messages in the dynamic network generated by ψ, so that all nodes receive these messages. Finally, those nodes that are u's neighbors in the dynamic network generated by 
 will deliver the messages to their respective P invocation, so that those nodes can continue the simulation of P in the next round.

In our above approach, note that Q only does flooding over the dynamic network generated by ψ, and the performance of each such flooding does not depend on the randomness in P or the behavior of the adaptive adversary 
. Putting it another way, even if the prophetic adversary ψ sees all the coin flip outcomes in P beforehand, there is nothing ψ can do to further bring down the performance of such flooding. This eventually leads to possible “derandomization” of the part of P's randomness used to deal with the adaptive adversaries.

However, there are several key technical challenges we need to overcome for this approach to be efficient. First, each flooding needs to be done separately. This means that the complexity of Q's simulation grows with the number of floodings that need to be done. To keep this number low, we need to design 
 such that in each round, by the topology in that round, only messages sent by a small number of nodes need to be flooded. At the same time, we need to also design 
 such that the diameter of the corresponding dynamic network is small (e.g., ). This helps to reduce the time complexity of P's execution against 
. We achieve these two (somewhat conflicting) properties by carefully constructing the topologies based on the probabilities of each node sending in a round (see Section 3).

A second key technical challenge in the simulation is that Q does not know the dynamic diameter of the dynamic network over which it runs (i.e., the dynamic network generated by ψ). Naively using n as an upper bound of the dynamic diameter would result in considerably weaker end results. Instead, our algorithm Q makes increasingly larger guesses on the dynamic diameter d. The key challenge is that Q does not know whether the current guess is correct or not (i.e., larger than d or not). Specifically, an incorrect guess will cause two problems. The first problem is that a flooding (as explained above) done by Q may fail to reach all nodes. In such a case, some nodes will see that something is wrong. But other nodes may not realize this, and may happily generate a result. As a key technical step, we will show that the result from such “partial execution” remains correct. The second problem caused by an incorrect guess is that in the dynamic network generated by 
, certain nodes are special centers, and an incorrect guess may prevent Q from finding the correct centers. We overcome this problem by leveraging the property that if all nodes have the same view on the centers, then this view must be correct, regardless of whether the guess is correct (see Section 4).

Finally, in our own previous works [14], [26], we have proved some lower bounds on the time complexity of several specific distributed computing problems, when the diameter of the dynamic network is not known beforehand, as compared to when the diameter is known. (In this work, we always assume that the diameter is not known beforehand.) Those previous lower bounds [14], [26] are not about the power of randomization, and do not contradict with any of the results in this work either. The techniques used in [14], [26] are rather unrelated to the techniques in this work as well. Specifically, [14], [26] obtain the lower bounds by reducing various two-party communication complexity problems to distributed computing problems in dynamic networks. The dynamic networks constructed in such reductions [14], [26] are completely different from the dynamic networks constructed in this paper. This is not surprising: The dynamic networks constructed in [14], [26] serve to facilitate reductions from two-party communication complexity problems, while the dynamic networks constructed in this paper serve to enable Q to efficiently simulate P's execution by doing simple flooding. Also, the specific challenges in this paper regarding guessing the dynamic diameter are not relevant in [14], [26]. In particular, the central results in [14], [26] do not involve guessing the dynamic diameter.

Other types of adversaries. The adaptive adversaries in this paper (also called strongly adaptive adversaries [2], [9], [18], [19]) are not the only type of adversaries in dynamic networks. A more general notion is z-oblivious adversaries [1], which can see all randomness up to and including round  when deciding the round-r topology. Prophetic adversaries and strongly adaptive adversaries correspond to z-oblivious adversaries with  and , respectively. Researchers have also considered 1-oblivious adversaries (also called weakly adaptive adversaries [9], [11]) and ∞-oblivious adversaries (also called oblivious adversaries [2], [3], [11]). The results in this paper are only for 0-oblivious adversaries, but our proofs are already non-trivial. The power of the algorithm's randomization will likely increase as z increases. On the other hand, we suspect that our conjecture could potentially be extended to 1-oblivious adversaries — we leave this to future work.

Related work. Randomization has been extensively used for solving various specific problems in dynamic networks (e.g., [16], [17]). However, prior works have not focused on the power of randomization in general distributed algorithms in dynamic networks. On the other hand, there have been many works on the power of randomization in other settings, and we discuss the most relevant ones in the following.

In centralized setting, an online algorithm processes a sequence of requests, one by one. In this context, an adaptive adversary generates the i-th request after seeing the algorithm's behavior (and coin flips) on request 1 through . It is well-known [5] that randomized online algorithms against adaptive adversaries can always be effectively derandomized. However, the measure of goodness for online algorithms is competitive ratio, and hence the derandomized algorithm can afford to have exponential computational complexity. In our distributed setting, adopting the techniques from [5] would require us to collect all the n input values to one node, which would result in unbounded time complexity (i.e., number of rounds) since the sizes of our inputs are not constrained. Due to these fundamental differences, our results and techniques are all quite different from [5].

More recently, there have been a series of breakthrough results on derandomizing distributed algorithms in static networks [7], [8], [10], [12], [15], [22]. These derandomization results are all for local algorithms, where the output (or the correctness of the output) of a node only depends on its small neighborhood instead of on the entire network. In fact, many of them consider algorithms with  time complexity. Such a notion of local algorithms is perhaps no longer well-defined in dynamic networks, where a node's neighborhood changes over time. In comparison to these works, this paper considers i) general distributed algorithms that are not necessarily local, and ii) dynamic networks instead of static networks. Also because of this, our results and techniques are all quite different. For example, some of the key methods used in [7], [8], [10], [12], [15], [22] include network decomposition and conditional expectations, while we mainly rely on a novel simulation against a novel adaptive adversary.

2. Model
Table 1 summarizes our key notations.


Table 1. Key notations.

n	number of nodes
d	(dynamic) diameter
αϵ,t, βϵ,t	specific adaptive adversaries – defined in Section 3.2 and 3.3
γG	specific adaptive adversary that always generates the given dynamic network G
τ	(general) adaptive adversary
ψ	(general) prophetic adversary
P	(general) randomized algorithm in dynamic network
Q	the randomized algorithm converted from P
I	input vector
C	coin flip outcomes in all rounds
C[1:r]	coin flip outcomes in round 1 through r
Cr	coin flip outcomes in round r
τ(P,I,C)	the dynamic network generated by τ under P, I, and C
cp(P,I,τ,C)	communication pattern of P when running under I, τ, and C
[r1:r2]	integers from r1 (inclusive) to r2 (inclusive)

tc(P,I,τ,C)	time complexity of P when running under I, τ, and C
tcP(n,d)	time complexity of P when running against adaptive adversaries with at most n nodes and at most d diameter
⁎
time complexity of Q when running against prophetic adversaries with at most n nodes and at most d diameter

err(P,I,τ,C)	error of P when running under I, τ, and C
errP(n)	error of P when running against adaptive adversaries with at most n nodes and arbitrary diameter
⁎
error of Q when running against prophetic adversaries with at most n nodes and arbitrary diameter
Dynamic network and adversary. We consider a synchronous network with a fixed set of n nodes, where the nodes proceed in lock-step rounds. Throughout this paper, we assume that n is publicly known and that . All nodes start execution, simultaneously, from round 1. The nodes have unique ids from 0 through . Each node has some input value, and there is no constraint on the size of each input value. We will view the n input values as an input vector of length n. We consider general distributed computing problems where the n nodes aim to compute a certain function of the input vector. The output of the function is a vector of length n, where node i should output the -th entry in that vector. There is no constraint on the size of each output entry. An algorithm in this paper always refers to some algorithm for solving some problem that can be modeled as the above way.

The topology among the n nodes may change from round to round. Following [18], [19], [26], we assume that the topology is determined by some adaptive adversary. An adaptive adversary τ is an infinite sequence of functions 
 for . Here 
 takes as parameters the randomized algorithm P, the input vector I, and P's coin flip outcomes 
 in round 1 (inclusive) to round r (inclusive). The function 
 then outputs some connected and undirected graph with n nodes, as the topology of the network in round r. There is no other constraint on the graph. We also call this infinite sequence of graphs (starting from round 1) as a dynamic network, and say that τ is an adaptive adversary with n nodes. With a slight abuse of notation, we use  to denote the dynamic network produced by τ, under algorithm P, input vector I, and P's coin flip outcomes C across all rounds. (This is a slight abuse since τ is not a function.) For any given dynamic network 
 where 
 is the round-r topology of G, we define the special adaptive adversary 
 to be 
 for all r, P, I, and 
. A prophetic adversary ψ is a function mapping the tuple (P, I, C) to a dynamic network . Since ψ is a single function (instead of a sequence of functions), ψ can see all coin flip outcomes of P in all rounds (i.e., C), before deciding the topology in each round.

We follow the communication model in [14], [26]: In each round, a node may choose to either send an  size message (i.e., the broadcast  model [24]) or to receive, as determined by the algorithm running on that node. A message sent in round r is received, by the end of round r, by all the receiving neighbors of the sender in round r.

Diameter. We adopt the standard notion of dynamic diameter [18] (or diameter in short) for dynamic networks. Formally, we define  if either  or v is u's neighbor in round r. Let the relation “↝” be the transitive closure of “→”. The diameter is defined as the smallest d such that ↝ holds for all u, v, and . Trivially, the diameter of a dynamic network with n nodes is at most . Since the diameter is controlled by the adversary, it is not known to the algorithm beforehand. The diameter of an adaptive adversary τ (prophetic adversary ψ) is the smallest d where the diameter of  () is at most d for all P, I, and C.

Time complexity and error. For the time complexity of an execution, we define the function  to be the number of rounds needed for all nodes to output in P, when algorithm P runs with input vector I, adaptive adversary τ, and coin flip outcomes C. For the error of an execution, we define the binary function  to be 1 iff P's output is wrong (on any node), when P runs with I, τ, and C.

In the following, 
 will be taken over all adaptive adversaries τ with at most n nodes and at most d diameter. Unless otherwise specified, an algorithm in this paper can be either a Las Vegas (LV) algorithm or a Monte Carlo (MC) algorithm. We define a randomized algorithm P's time complexity against adaptive adversaries as 
 if P is an LV algorithm, or 
 if P is an MC algorithm. We define an MC algorithm P's error against adaptive adversaries as 
.

We will need to reason about the properties of algorithm Q running against prophetic adversaries. Given Q's coin flip outcomes C in all rounds, since prophetic adversaries always see C beforehand, the worst-case prophetic adversary can always choose the worst-case dynamic network H for such C. Hence if Q is an LV algorithm, we define its time complexity against prophetic adversaries to be 
⁎
. Note that here 
 is taken after C is given, and is taken over all dynamic networks with at most n nodes and at most d diameter. If Q is an MC algorithm, then its time complexity / error against prophetic adversaries will be 
⁎
 and 
⁎
, respectively.

Input-stability. We next define the notion of input-stability. Before giving a formal definition, we first give some intuition behind this notion. Intuitively, P is considered input-stable if under any given dynamic network and any given coin flip outcomes, P's time complexity/error and communication pattern are independent of the input. (This implies that P uses randomness only for dealing with adaptive adversaries, and we will eventually show how such P can be derandomized.) Note that P's output and P's messages' contents can, and probably should, depend on the input. Under different dynamic networks and different coin flip outcomes, P can still have different time complexities/error and communication patterns. For example, consider the token dissemination problem [9], [17] where each node has a token as its input, and where we need all nodes to output all tokens. Here as long as P treats the tokens as opaque, P will be input-stable. On the other hand, treating the tokens as opaque is not necessary for P to be input-stable.

The following gives the formal definition of input-stability. Given any algorithm P, input vector I, adaptive adversary τ, and coin flip outcomes C, we define P's communication pattern (denoted as ) to be a sequence of sets, where the r-th set is the set of nodes that are sending in round r (for all ) in P's execution under I, τ, and C. An algorithm P is input-stable if for all dynamic networks G, coin flip outcomes C, input vectors 
 and 
, the following holds: i) 
 (if P is an LV algorithm), ii) 
 (if P is an MC algorithm), and iii) 
. Several aspects of the definition are worth elaborating. First, the constant “2” in the first property above can be easily replaced by any constant larger than 1. Second, under different G and C, an input-stable P can have different time complexities, error, and communication patterns. For example, a node may decide to send with a larger probability iff it has received a larger number of distinct messages so far in the execution, which depends on G. Finally, the equations do not need to hold for all adaptive adversaries τ — they only need to hold for 
.

Need for input-stability. Some of the results in this paper hold regardless of whether P is input-stable, while other results require P to be input-stable. Whenever a result requires P to be input-stable, we always explicitly state that assumption, for example, in the lemma/theorem statements and also when discussing the intuitions. If no such assumption is explicitly stated, then the corresponding result holds regardless of whether P is input-stable.

Conventions. All logarithms in this paper are base 2. We sometimes consider round 0 for convenience, where the algorithm does nothing and all nodes are receiving.

3. Adaptive adversary simulated by Q
As mentioned in Section 1, given some arbitrary randomized algorithm P, we want to construct algorithm Q that simulates the execution of P against some novel adaptive adversary 
. We want 
 to have small diameter so that P's time complexity (when running against 
) is small. Let H be the dynamic network over which Q runs. We further need Q to have good complexity and error guarantees, even if H is constructed by prophetic adversaries.

3.1. Intuition in the construction of 
Starting point. Recall that in any given round r, an adaptive adversary knows whether each node in P will be sending or receiving in that round (since the adaptive adversary sees 
), before the adversary decides the topology in that round. Let us consider the following trivial topology as a starting point. In this topology, all nodes that are sending in the round form a clique, and all nodes that are receiving in the round form a clique. Some of the sending nodes will be chosen as centers for that round. A center will be connected to all other nodes (including all other centers) directly. To simulate P for one round over such a topology, we only need to deliver the message sent by each center to each of the receiving nodes. To do so, for each center, Q will flood the message (sent by the center) in the dynamic network H. Such flooding will obviously still work even if H is generated by a prophetic adversary. It takes total  rounds to simulate one round of P, where x is the number of centers and d is the diameter of H.

But there are several issues. Since only sending nodes can be centers and since a node may not always be sending in all rounds, we may be forced to keep switching the centers from round to round. This may then cause the (dynamic) diameter of the dynamic network to be large, despite the topology in each round having a small static diameter. One naive way to avoid this problem is to choose all sending nodes as centers. But doing so would result in too many centers, rendering the simulation inefficient. The following explains how we overcome these issues.

Choosing the centers. Our design of 
 uses only a logarithmic number of centers in each round. To obtain some intuition, consider any two consecutive rounds  and r, where . We define 
 receives (hence the superscript “R”) in round  and sends (hence the superscript “S”) in round r}. Here “sends”/“receives” refers to u sending/receiving in the execution of P against 
. We similarly define the remaining three sets 
, 
, and 
. We hope to choose the centers in such a way that for some small d (e.g., ), we have ↝ for all u and v. We will soon see that it will be convenient to consider u's in the 4 sets separately.

For round r, we will first pick some (arbitrary) node 
 as a center. Such a center will ensure that for all 
 and all v, we have . Similarly, we will pick some (arbitrary) node 
 as another center, to take care of 
. Next, for any 
, note that u must be in either 
 or 
. If we chose the centers in round  also according to the earlier rules, then such a u has already been taken care of as well.

The trickier case. The case for 
 is trickier. In fact, to get some intuition, consider a node u that continuously receives in round 1 through round d. We want to ensure that ↝ for all v. Let 
 be the set of nodes that are sending in round r and let 
 be the set of centers in round r, for . For all 
, we clearly have ↝. For all 
, v must be receiving in some round , and hence we have  and we are done.

The case for 
 is more complicated. Such a v has always been sending, but is never chosen as a center. Now consider such a v, and observe that if some center w in round r sends (again) in some round i where , then we must have ↝↝↝. Based on this observation, we will want to choose 
 from 
 such that some node in 
 will send in some round . But whether a node sends in future rounds may depend on future coin flip outcomes of P, as well as the incoming messages in those rounds. An adaptive adversary (for P) does not have the incoming messages in future rounds. It is not supposed to see future coin flip outcomes either.

Our next observation is that the adaptive adversary in round r, before deciding the round-r topology, can actually determine the probability that a node u will be sending (again) in round , if the node u is currently already sending in round r. The reason is that u will not receive any incoming messages in round r, no matter what the topology is. Hence the probability is uniquely determined by u's state at the beginning of round r. Now given such probabilities for all the nodes in 
, when choosing the centers, we will choose those nodes from 
 whose probabilities (of sending in round ) are at least 0.5, and we call such nodes as promising nodes. If we include a logarithmic number of promising nodes in 
, then with good probability, there will exist some 
 that sends in round . Due to some technicality, the number of promising nodes in 
 will actually need to increase with r, so that we can eventually take a union bound across even an infinite number of rounds.

Finally, it is possible that we never have a sufficient number (i.e., logarithmic number) of promising nodes. In such a case, we will show that 
 will be empty with good probability.

3.2. Details of our adaptive adversary 
We now formally define 
 for  and . The adaptive adversary 
 always generates a clique as the topology for round r when . If , then consider the given algorithm P, input vector I, and coin flip outcomes 
. Based on 
 and the state of P at the beginning of round r, 
 can infer which nodes will be sending in round r, and which nodes are promising nodes. For all pairs of nodes u and v where either they are both sending in round r or they are both receiving in round r, the adversary 
 adds an undirected edge between them. Next 
 chooses up to 
 
 nodes as centers for round r. For every center w and every node v, 
 adds an edge between w and v, if there is not already such an edge.

The centers are chosen in the following way. First, among all the nodes that were receiving in round  and are sending in round r, if there are such nodes, choose the one with the smallest id as a center. Second, among all the nodes that were sending in round  and are again sending in round r, if there are such nodes, choose the one with the smallest id as a center. Third, among all the nodes that were centers in round  and are sending in round r, if there are such nodes, choose the one with the smallest id as a center. Finally, rank all the promising nodes in round r, by their ids from smallest to largest. Choose the first 
 
 nodes from this sequence as centers. If the sequence contains less than 
 
 nodes, choose all of them. Since these 4 criteria are not necessarily exclusive, a node may be chosen as a center multiple times.

3.3. Details of our adaptive adversary 
To facilitate our later reasoning on the diameter of 
, we further need to introduce a second adaptive adversary 
, as a stepping stone. We will prove that 
 always has 
 
 diameter, and that 
 generates the same dynamic network as 
 with at least  probability, with the probability being taken over the algorithm's coin flips. Our simulation will still simulate 
 instead of 
. But we can easily draw a connection between the time complexity/error of P when running against 
 and when running against 
.

Just drawing this connection alone is not yet enough. In the simulation, the algorithm Q will also need to efficiently determine, in a distributed fashion, whether 
 behaves exactly the same as 
. In particular, Q should not be forced to directly check the diameter of the dynamic network generated by 
. To achieve this property, we first define the concept of 
 being favorable, and then define 
. Being favorable will be a sufficient condition for 
 to behave the same as 
. The algorithm Q will directly check whether 
 is favorable, which can be done efficiently.

In a dynamic network generated by 
, we say that a node is a twice-center for round r () if it is a center in both round  and round r. Round r has a twice-center if there exists some node that is twice-center for round r. In the next, we will use “rounds 
” to denote all rounds from round 
 (inclusive) to round 
 (inclusive).

Definition 1

 being favorable
For any given algorithm P, input vector I, and coin flip outcomes C, we say that 
 is favorable up to round 
 if for each r where 
 
, at least one of the following two properties holds in the dynamic network generated by 
 under P, I, and C: i) some round in rounds 
 
 has a twice-center, or ii) no node in P sends continuously for 
 
 rounds in rounds 
 
.

Definition 2

In each round r, the adaptive adversary 
 behaves exactly the same as 
 except that if 
 is not favorable up to round r (i.e., 
 can examine the topologies generated by 
 in the first r rounds), then 
 will use a clique as the topology in round r.

3.4. Diameters of 
 and 
One can easily verify that the topologies generated by 
 and 
 in every round are always connected. The next two theorems show that the diameter of 
 is small, and that with probability at least , 
 behaves the same as 
. Such small diameter helps to make Q's simulation of P over 
 more efficient.

Theorem 3

For all , , algorithm P, input vector I, and coin flip outcomes C, the dynamic network 
 has a diameter of at most 
 
.

Proof

Recall that “rounds 
” denotes all rounds from round 
 (inclusive) to round 
 (inclusive). We will also use 
 to denote all integers from 
 (inclusive) to 
 (inclusive). Define function 
 
. Consider any round  and any two nodes u and v in the dynamic network. It suffices to prove that ↝. Recall that by the design of 
, the topology in round  must be a clique. Hence the claim will trivially hold if , and we will only prove for . If 
 is not favorable up to round , then 
 must have started using a clique as the topology, starting from round  or earlier. In such a case, we immediately have ↝.

The only remaining case is where  and where 
 is favorable up to round . We trivially have , , and . Since  and since 
 is favorable up to round , 
 must be favorable up to round . By Definition 1, we know that at least one of the following two properties must hold:

•
Some round in rounds  has a twice-center.

•
No node sends continuously for 
 
 rounds in rounds .

If there exists a round 
 with a twice-center node w, then we directly have ↝
↝↝, and we are done. If no node sends continuously for 
 
 rounds in rounds , then u must be receiving in some round 
 where 
 
, and v must be receiving in some round 
 where 
 
. We separately consider two possibilities in the following.

First, if u is always receiving in rounds 
, then we have ↝
↝
↝↝. Second, if u sends in some round within rounds 
, let round 
 be the earliest such round, where 
. This means that u receives in round 
 and sends in round 
. By the design of the adaptive adversary 
 (and hence 
), we know that round 
 must have a center w where w (w can be u itself) receives in round 
 and sends in round 
. Hence we have ↝
↝
↝↝. □

Theorem 4

For any given , , algorithm P, input vector I, define 
 is favorable up to round t for P, I, and C (which implies 
) }. Then A contains at least a  fraction of all possible coin flip outcomes.

Proof

Consider any , we will prove that under any given P and I, 
 satisfies at least one of the two conditions in Definition 1 with probability at least 
 
, with the probability taken over C. A union bound across all r will then show that 
 is favorable up to round t, with probability at least 
 
.

Recall that “rounds 
” denotes all rounds from round 
 (inclusive) to round 
 (inclusive), and that 
 denotes all integers from 
 (inclusive) to 
 (inclusive). Let 
 
. First, we consider the case where there exists some 
 such that round 
 has at least 
 
 promising nodes. By the design of 
, at least 
 
 of these promising nodes will be centers in round 
. With probability at least 
 
 
, at least one of these centers will be sending again in round 
. Let the non-empty set of such centers be W. Again by the design of 
, some node in W will become a center again in round 
. Hence round 
 will have a twice-center, hence satisfying the first property in Definition 1.

Next, we consider the case where every round in rounds  has less than 
 
 promising nodes. By the design of 
, in such a case all promising nodes will be centers. If there exists some 
 such that some promising node in round 
 sends (again) in round 
, then round 
 will have a twice-center node by the design of 
. This will then again satisfy the first property in Definition 1.

Now the only remaining case is that for every round in rounds , all promising nodes in that round will receive in the next round. Based on this, we will later prove 
 and 
 and 
 and 
 
, where 
 means that no node sends in every round in rounds 
 
 
 for . Since , one can easily verify that every 
 
 consecutive rounds in rounds  must contain all the rounds in 
 
 
 for some i. This then implies that with probability at least 
 
, no node sends continuously for 
 
 rounds in rounds , hence satisfying the second property in Definition 1.

To prove 
 
, it suffices to show that 
 
 for . We only prove for 
, since the other cases are similar. By our earlier argument, a promising node in any round 
 
 must be receiving in round 
, and hence can never send in every round in rounds 
 
. Hence we only need to consider those nodes who are never promising nodes in any round in rounds 
 
. A non-promising node in a round will, with probability less than 0.5, send in the next round. Hence 
 
 
. □

3.5. Input-stability under 
 and 
If P is input-stable (see Section 2 for definition), we will eventually be able to derandomize P. Our derandomization of P will need to reason about P's behavior under different inputs, when P runs against 
 and 
. Obviously, we should leverage the fact that P is input-stable during such reasoning — namely, when running over a given dynamic network G, P's time complexity/error and communication pattern are independent of P's input. However, when P runs against 
 (
), it is not immediately clear whether these properties will continue to hold, since the dynamic network generated by 
 (
) adapts to (i.e., depends on) the randomness in P, and may or may not be the same dynamic network every time P runs.

Theorem 5 in the next will prove that these properties will indeed continue to hold, when P runs against 
 (
). Intuitively, our proof relies on the following arguments. First, the round-r topology generated by 
 partly depends on which nodes are sending and which nodes are the promising nodes in round r. This in turn depends on the probabilities of certain nodes sending in round . We will be able to prove that these probabilities are independent of P's input, via an induction. Second, we will repeatedly invoke a simple indistinguishability argument: In round r, so far as P is concerned, 
 is indistinguishable from 
 for some dynamic network G, even though we do not know beforehand what G is. Formally, the following theorem states that if P runs against 
 (
), then P's time complexity/error, as well as the dynamic network generated by 
 (
), will not depend on P's input.

Theorem 5

For all input-stable algorithm P, input vectors 
 and 
, coin flip outcomes C, and adaptive adversary 
, we have:
 Furthermore, for all , 
 is favorable up to round r for P, 
, and C iff it is favorable up to round r for P, 
, and C.

Proof

We first prove for 
. Note that 
 directly follows from Lemma 6 (proved next). Let 
. Since P is input-stable, if P is an LV algorithm, then 
. If P is an MC algorithm, we have 
.

Finally, Lemma 6 (proved next) implies that 
 is favorable (see Section 3.3 for definition) up to round r for P, 
, and C if and only if it is favorable up to round r for P, 
, and C. Together with the fact that 
, we have 
.

The remaining case of 
 is similar to the above proof for 
. □

Lemma 6

Let P be any input-stable algorithm. Consider any input vectors 
 and 
, and coin flip outcomes C. Let 
, 
, and 
 be the topology in round r, the set of nodes that are sending in round r, and the set of promising nodes in round r, respectively, when P runs under 
, 
, and C. Define 
, 
, and 
 similarly, under 
 instead of 
. Then we have 
, 
, and 
 for all r.

Proof

We will use an induction on r. The induction base for  obviously holds. Assume that 
, 
, and 
, for all . Now consider round r:

•
We first prove 
. Define dynamic network G such that in round i, G's topology is 
 for  and is a clique for . Let 
 denote the set of nodes sending in round r when P runs under input I, adaptive adversary τ, and coin flip outcomes C. Note that given P, I, and C, the value of 
 is uniquely determined by the topologies generated by τ in the first  rounds. Combining with the fact the P is input-stable, we have 
.

•
Given 
, we next prove 
. Consider any node 
. Whether 
 depends on whether in the execution of P under 
 and 
, node u's probability of sending in round  is at least 0.5. Note that when defining this probability, 
 is already given, and the probability is defined over 
 (i.e., the coin flips in round ).

To prove 
, we will prove that in the execution of P under 
 and 
, the probability of u sending in round  is exactly the same as in the execution of P under 
 and 
. To facilitate our following proof, under any given coin flip outcomes in the first j rounds, we will use the boolean function  to denote whether u will send in round j in the execution of P under I, τ, and those coin flip outcomes. Thus to prove that the probability of u sending in round  is the same in the two executions, it suffices to show that under any given 
, 
, and 
, 
.

Consider any given 
, and define the dynamic network G as defined earlier, where in the first  rounds, G has the same topologies as the topology generated by 
 under the given 
. Under the given 
, any given 
, and any given 
, we claim that 
. To see why, note that by the end of round , u's behavior is exactly the same under 
 and under 
. Hence under the given 
 and 
, we have 
 (since 
). Now since u is sending in round r, its behavior in round r is unaffected by the round-r topology of the dynamic network. In turn, u's behavior by the end of round r must be exactly the same under 
 and under 
. Hence under the given 
, 
, and 
, we have 
.

By a similar argument, under the given 
, any given 
, and any given 
, we have 
. Finally, since P is input-stable, we must have 
. This gives us 
.

•
Finally we will prove 
. By the design of 
, one can easily verify that 
 is a function of 
 and 
 (), while 
 is a function of 
 and 
 (). Hence 
 immediately follows from 
, 
, and our inductive hypothesis. □

4. Conversion from LV algorithm P to LV algorithm Q
4.1. Pseudo-code and intuition
Overview. We have shown the construction and properties of the adversary 
. Given any LV algorithm P, our algorithm Q (pseudo-code in Algorithm 1 through 5) will simulate the execution of P against 
. (Effectively, Q will be simulating both P and the adversary 
.) We will ensure that Q works even against prophetic adversaries. In the following, a simulated round refers to one round of P in its simulated execution.

Algorithm 1
Download : Download high-res image (85KB)
Download : Download full-size image
Algorithm 1. LV-P-Converted-To-Q(). /* This algorithm Q simulates P's execution against αϵ,t. For clarity, the pseudo-code does not explicitly include the input to Q (which is relayed to P). Without loss of generality, P's output on a node (when viewed as a numerical value) is assumed to be always non-negative. A node outputs only once in this algorithm. A node will suppress output if it previously has already outputted. */

Recall that in each simulated round, the adversary 
 chooses 
 
 centers. For each center, Q will do a binary search (via logarithmic number of sequential floodings) to find the id of that center. For example, for the first center, Q will use a binary search to find the node with the smallest id, among all nodes that were receiving in the previous simulated round and are sending in the current simulated round. Next, for each center (which must be sending in P for the current simulated round), Q will determine the message it should send in P. Q will then flood this message, and then feed this message into all nodes that are receiving in P for the current simulated round.

Challenges and our solutions. A key difficulty in the above simulation is that Q does not know the diameter d of the dynamic network over which it runs. This means that Q does not know how long it takes for each flooding to complete. Of course, Q can naturally use the standard doubling-trick and maintains a guess 
 for d. Recall that Q uses flooding i) for finding the centers via binary searches, and ii) for disseminating the messages of the centers. When 
, obviously both steps can be incorrect. We need to design Q so that it can deal with such incorrect behavior.

As a starting point, for each binary search, we have a designated node (node 0) flood for 
 rounds its result of the binary search. If 
, then it is possible that i) node 0 does not find the correct center in the binary search, and ii) the flooding from node 0 does not reach all nodes. We will design our binary search such that as long as the binary search returns the same value on all nodes, that return value must be correct, regardless of whether 
. Intuitively, it is possible to achieve such a property because the center (i.e., what the binary search should return) itself also participates in the binary search. Regardless of whether 
, the center must always see itself as the return value of the binary search. So if node 0 sees the same return value, that return value must be correct. This guarantee will be formalized in Lemma 9.

Based on the above discussion, if a node does not see the flooding from node 0, or if its binary search result is different from that of node 0, it knows that something is wrong and flags itself. Next each center, if not flagged, will flood the message (that it should send in P) for 
 rounds. Again, whoever not seeing this flooding will flag itself. All the 
 
 centers will sequentially do such flooding one by one. In our design, once a node gets flagged, it will not participate in any of the flooding or binary search anymore (for the current 
 value), but will nevertheless spend the corresponding number of rounds doing nothing, so that it remains “in sync” with the non-flagged nodes.

At this point, we have three possibilities: i) 
 and no node gets flagged, ii) 
 and no node gets flagged, iii) 
 and some nodes get flagged. For the second case, because 
, it is not immediately clear what guarantees the simulation can offer — for example, whether the binary search still finds the smallest id. Fortunately, we will be able to prove that as long as no node gets flagged, the simulation is still “correct”. Specifically, for disseminating the centers' messages, it is obvious that if no node gets flagged, then all nodes must have received those messages, regardless of whether 
. For the binary search part, we will be able to prove the following strong property: As long as the binary search returns the same value on all nodes (which is a necessary condition for no nodes being flagged), the result of the binary search must be correct, even if 
. Putting these together, this means that the second case still corresponds to a proper execution of P against 
.

The third case (i.e., 
 and some nodes get flagged) is trickier. The challenge is that the non-flagged nodes may think everything is fine and then happily generate a potentially wrong output. To deal with this, our design first lets the flagged nodes send a special message — whoever receives this message will get flagged as well. For each simulated round of P, our algorithm Q will allocate exactly one dedicated round in Q to do this.

Next, as a key technical step, we will be able to prove that with such a mechanism, somewhat interestingly, those non-flagged nodes actually still constitute part of a valid execution of P against some prophetic adversary ψ (but not a valid execution of P against 
). Our proof will explicitly construct this prophetic adversary ψ. Let G be the dynamic network generated by ψ. We will prove that G's topology is always connected in every round, while leveraging the fact that the topology of the dynamic network H (over which Q runs) is always connected. It is important to note that here we need to use a prophetic adversary (instead of an adaptive adversary) to generate G, since G depends on H, and since H is generated by some prophetic adversary.

To quickly summarize, we effectively have that i) if no node gets flagged, then Q must have properly simulated P's execution against 
, and ii) if some nodes get flagged, then Q (on the non-flagged nodes) must have properly simulated P's execution against some prophetic adversary ψ. Now since P is an LV algorithm, it will never have any error when running over any G, even if G is generated by a prophetic adversary. The reason is that G could also be generated by some adaptive adversary (e.g., by the adaptive adversary that always outputs G, regardless of P's inputs and P's coin flip outcomes), and P promises zero error under all adaptive adversaries. Thus the outputs of those non-flagged nodes will never be wrong, and can always be safely used. Of course, P's time complexity guarantee will no longer hold when running against ψ. But this will not cause any problem — if P takes too long to output, Q will increase 
 and retry.

Using fresh coins. Finally, since we are using the doubling-trick to guess d already, we will use the same trick to guess the number of rounds needed for P to output. This will make our proof on Q a constructive proof, instead of an existential proof. It is worth mentioning that for each 
 (the guess on d) and t (the guess on the number of simulated rounds needed for P to output), Q will simulate P using a fresh set of random coins. This is necessary because for a given set of coin flip outcomes, the adversary 
 may happen to have large diameter, causing P to take too many rounds to output. Finally, for each pair of 
 and t values, the simulation of P takes about 
 rounds. To make the guessing process efficient, we maintain a budget k that keeps doubling. For a given budget k, we simulate P for all (
, t) pairs where 
 and that are constant factors apart from each other.

4.2. Final results on conversion from LV algorithm P to LV algorithm Q
Theorem 7 next states that Q's output will never be wrong:

Theorem 7

For any LV algorithm P, the output of Q (Algorithm 1) will never be wrong.

Theorem 8 next is our key result on Q's time complexity. It states that even when Q runs against a prophetic adversary, its time complexity is not much larger than P's time complexity when P runs against an adaptive adversary. Furthermore, if P is input-stable, then Q can be further derandomized into a deterministic algorithm without increasing Q's time complexity.

Theorem 8

Let Q be Algorithm 1, and let P be any LV algorithm where 
 for some constant 
.

•
There exists constant 
 (independent of n) such that for all d, we have 
⁎
, where 
 is taken over all dynamic networks H with at most n nodes and at most d diameter. Furthermore, if P is input-stable, then there exist some coin flip outcomes 
 such that for all d, we have 
.

•
If 
 for some  and  where there exists some constant 
 such that 
 and 
, then we have 
⁎
. Furthermore, if P is input-stable, then there exist some coin flip outcomes 
 such that for all d, we have 
.

To derandomize any given input-stable LV algorithm P, we combine Theorem 7, Theorem 8 while plugging 
 into Q. This gives a deterministic algorithm with the desired time complexity.
4.3. Proofs for Theorem 7 and 8
This section gives the full proofs for Theorem 7, Theorem 8. In the following, Section 4.3.1 first proves a number of technical lemmas, and then Section 4.3.2 and Section 4.3.3 prove Theorem 7, Theorem 8, respectively.

4.3.1. Technical lemmas
Theorem 7, Theorem 8 are both about Algorithm 1 (i.e., the algorithm Q). Algorithm 1 invokes the subroutine SimulateP() in Algorithm 2. SimulateP(), in turn, invokes Algorithm 3 through Algorithm 5. At a high level, Algorithm 2 simulates P's execution against 
 for t simulated rounds — to do so, Algorithm 2 essentially simulates both the algorithm P and the adaptive adversary 
. Algorithm 3 obtains a certain number of centers, for the simulation of 
. Algorithm 4 uses a binary search to find out the minimum value among all nodes, while Algorithm 5 is a simple utility subroutine. In the next, we prove several useful technical lemmas from the pseudo-code.

Algorithm 2
Download : Download high-res image (291KB)
Download : Download full-size image
Algorithm 2. SimulateP(ϵ, d′, t, 
). /* This subroutine simulates P's execution against αϵ,t for t simulated rounds, while feeding coin flip outcomes 
 into P, and while using d′ as the guess for the diameter of the dynamic network over which Q runs. Without loss of generality, P's output (if viewed as a numerical value) is assumed to be non-negative. A node, once flagged, will do nothing in all steps except Step 19 and 23, but the node will still spend the same number of rounds to go through each step as other nodes. When the pseudo-code says a node u “floods” something for d′ rounds, it means that the flooding originates from u, and all nodes in the system will spend exactly d′ rounds participating in this flooding. */

Algorithm 3
Download : Download high-res image (160KB)
Download : Download full-size image
Algorithm 3. GetCenters(ϵ, r, d′). /* This subroutine returns an array of 
 
 centers, some of which can be ⊥. The centers are chosen according to the construction of αϵ,t in Section 3.2. The subroutine does a binary search to find out the value for each entry in the array. It uses d′ as the guess for the diameter of the dynamic network, and takes total 
 
 rounds. */

Algorithm 4
Download : Download high-res image (59KB)
Download : Download full-size image
Algorithm 4. FindMin(z, d′). /* The input parameter z is an integer in [0,n]. This subroutine tries to use a binary search to find out the minimum input value among all nodes. It uses d′ as the guess for the diameter of the dynamic network, and takes total 
 rounds. */

Algorithm 5
Download : Download high-res image (28KB)
Download : Download full-size image
Algorithm 5. ExistValue(z, x, d′). /* This subroutine tries to check whether any node in the dynamic network has invoked this subroutine with z = x. It uses d′ as the guess for the diameter of the dynamic network, and takes total d′ rounds. */

Lemma 9 in the next proves the properties of Algorithm 4 (i.e., FindMin()). In this lemma, it is crucial (for our later proof) that even when 
, certain parts of the lemma still hold.

Lemma 9

Consider any dynamic network H with n nodes and at most d diameter.

•
For all i and 
, if node i in H invokes FindMin(
, 
) with some 
, then the invocation must return some integer value in 
. (This is regardless of whether/which/when other nodes are invoking FindMin.)

•
Fix any 
, and let every node i in H invoke FindMin(
, 
) for some 
, simultaneously.

–
If FindMin() returns the same value on all nodes, then the value returned must be 
.

–
If 
, then FindMin() must return the same value on all nodes.

Proof

•
In Algorithm 4, the bits 
 start with a value of 
. The only place where 
 can later get modified is at Step 4. Each such modification always changes 
 from 1 to 0, while further setting the remaining less significant bits (i.e., 
) to 1. Hence each such modification always decreases the value of the binary string 
. Finally, it is obvious that the return value must be a non-negative integer.

•
For any value x, we will use 
 to denote its binary form, with 
 being the most significant bit. Let j be any integer where 
.

–
Let v be the common value returned by FindMin() on all nodes. Consider the condition at Step 4 of Algorithm 4. Let 
 be the first s for which this condition is satisfied, during the execution of FindMin(
, 
) by node j. If such 
 does not exist, then we must have 
 and we are done. If such 
 exists, the following will derive a contradiction.

We will have a number of properties by the definition of such 
. First, we must have 
, 
, …, 
. Second, we must also have 
, 
. Finally, ExistValue(1, 0, 
) must returned true on node j at Step 3 when 
. This means that there must exist some node , such that node k invoked ExistValue(0, 0, 
) when node j invoked ExistValue(1, 0, 
).

Since node k invoked ExistValue(0, 0, 
) during its iteration for 
 in Algorithm 4, we claim that during node k's execution of FindMin(
, 
), the condition at Step 4 of Algorithm 4 is never satisfied for any 
. Otherwise on node k, the bit 
 would have been set to 1 at Step 4. From this claim, we further know that i) the value of 
 must be 0, and ii) 
, 
, …, 
. Now we have 
, 
, and further 
, 
, …, 
. This implies that 
 is smaller than 
, contradicting the fact that 
.

–
When 
, ExistValue(
, 0, 
) at Step 3 must return the same value on all nodes, and the return value must be true if there exists some node invoking ExistValue(0, 0, 
). It can then be easily verified that FindMin() must return the same value on all nodes. □

Lemma 10 in the next bounds the number of rounds incurred during an invocation of SimulateP():

Lemma 10

For any constant , there exists some constant 
 such that for all 
 and  that are both power of 2, , protocol P, and coin flip outcomes 
, SimulateP(ϵ, 
, t, 
) takes at most 
 
 rounds.

Proof

Directly from the pseudo-code of SimulateP() in Algorithm 2. □

Lemma 11 in the next proves that when SimulateP() is invoked with a sufficiently large guess 
 on the diameter, then no node will ever be flagged during that invocation:

Lemma 11

Consider any given algorithm P, , 
, t, 
, and dynamic network H with at most 
 diameter. If all nodes in H invoke SimulateP(ϵ, 
, t, 
) simultaneously, then no node will ever get flagged (i.e., the flagged variable can never be true) during the execution of SimulateP(ϵ, 
, t, 
).

Proof

First, the return values of GetCenters(ϵ, r, 
) (at Step 9 of Algorithm 2) come (indirectly) from various invocations of FindMin(). Since the diameter of H is at most 
, Lemma 9 tells us that FindMin() must return the same value on all nodes. Hence all nodes will have the same return value from GetCenters(ϵ, r, 
) at Step 9 of Algorithm 2, and the  array must be the same on all nodes. For any given non-⊥ entry in the array, the corresponding FindMin() invocation must have returned some value v where  on all nodes. By Lemma 9 and since H's diameter is at most 
, this implies that some node must have invoked FindMin(v, 
). By the pseudo-code in Algorithm 3, it is easy to verify that v must be the id of this node, and this node must be sending in the current simulated round of P. This in turn means that on this node, the condition at Step 3 of Algorithm 2 must have been satisfied, and hence .

With all the above properties, together with the fact that H's diameter is at most 
, one can easily verify that the conditions at Step 12, Step 16, and Step 20 of Algorithm 2 will never be satisfied. Hence no node will ever get flagged during the execution of SimulateP(ϵ, 
, t, 
). □

Lemma 12 in the next proves that SimulateP() properly simulates the execution of P against 
, when no node gets flagged:

Lemma 12

Consider any invocation of SimulateP(ϵ, 
, t, 
), by every node simultaneously, for any given algorithm P, , 
, t, and 
. If no node ever gets flagged (i.e., the flagged variable is never true) during such invocation, then the invocation must have properly simulated the first t rounds of P's execution under 
 and 
, in the following sense: For all , the behavior of P in round r of its execution under 
 and 
 is exactly the same as in Step 4 and 18 of SimulateP(). Furthermore, the centers selected by 
 in round r of the above execution are exactly the same as the centers selected at Step 9 of SimulateP().

Proof

We will do a simple induction on r. Assume that the lemma holds for all rounds before round r, and we now consider round r.

If no node ever gets flagged, then immediately after Step 9 of SimulateP(), the  array on all nodes must be identical. Recall that each entry in the array is set to be the return value of an invocation of FindMin(). Consider any given entry in the array. Then for that entry, all the nodes must have the same return value from their respective invocations of FindMin(). Lemma 9 then tells us that such return value must be the minimum value across all nodes. Based on our inductive hypothesis and also the pseudo-code in Algorithm 3, one can easily verify that the entries in the  array must be exactly the same as the centers chosen by 
, if P runs against 
.

Furthermore, since no node ever gets flagged, it means that each node has received the message flooded by each center. Hence a node that is receiving in the simulated round can properly feed such a message as an incoming message into its simulation of P. The remainder of the proof easily follows from the pseudo-code of SimulateP() in Algorithm 2. □

4.3.2. Proof for Theorem 7
We are now ready to prove Theorem 7 (restated in the following). Its proof mainly relies on the intuition in the previous section. The proof is involved, because it is not sufficient to just consider whether a node is flagged at a certain time point in each simulated round — we actually consider two separate time points in each simulated round.

Theorem 7

For any LV algorithm P, the output of Q (Algorithm 1) will never be wrong.

Proof

Consider any given invocation of SimulateP() at Step 5 of Algorithm 1 on any given node u. We will refer to the iteration with  in SimulateP() (i.e., Step 3 to Step 21 in Algorithm 2) as round i of the simulated execution. Unless otherwise mentioned, all steps in the remainder of this proof refer to steps in Algorithm 2. We use 
 and 
 to denote that node u is already flagged by Step 19 and Step 21, respectively, in round i of the simulated execution. We use 
 
 and 
 
 to denote the negation of 
 and 
, respectively. We define that 
 
 and 
 
 holds for all u. We say that u sends (receives) in round i of the simulated execution if 
 
 and if u satisfy the condition at Step 3 (Step 18). For all i, we define  is in the  array on node 0 immediately after Step 9 in round i of the simulated execution}, if 
 
 holds. We define , if 
 holds.

Reference dynamic network. To facilitate proof, we will define a reference dynamic network: Let 
 be the topology of the reference dynamic network in round i, constructed in the following way. Consider any two nodes u and v. First, if 
 and 
, then there is an edge between them in 
. Second, if 
 
 and 
 
, then there is an edge between them iff they either are both sending or are both receiving in round i of the simulated execution. Finally, there is an edge between u and v if 
 
 and . Note that these three cases are not necessarily mutually exclusive.

For all i, 
 is connected. We want to prove that 
 is connected for all i. Consider any given i. Define 
 and 
 
 
. Since 
 implies 
, F always forms a clique in 
.

Next, if both F and 
 
 are non-empty, we claim that there must exist an edge in 
 connecting some node  to some node 
 
. The reason is that all nodes in F send m_flag in Step 19, while all nodes in 
 
 receive in Step 19. Since the dynamic network over which Q runs is connected, in Step 20 there must be some node 
 
 receives m_flag from some node . Then we will have 
, and by design of 
, this will result in an edge between u and v (since 
 must hold as well).4

If 
 
, we will need to also reason about the nodes in 
 
. If all nodes in 
 
 receive in round i of the simulated execution, then 
 
 obviously also forms a clique in 
 and we are done.

The only remaining case, which is also the most complex case, is where 
 
 and some node 
 
 sends in round i of the simulated execution. Consider the  array on node u immediately after Step 9. We claim that the array must contain at least one non-⊥ entry. We will prove the claim for the case where u receives in round  in the simulated execution — the case where u sends in round  is rather similar. When u invokes GetCenters() at Step 9, it will invoke Algorithm 3. Now since u receives in round  and sends in round i, at Step 3 of Algorithm 3, it will invoke FindMin(z, 
) with z being u's id. Lemma 9 then implies that on node u, FindMin(z, 
) will return some value that is in . This value will then become a non-⊥ entry in the  array on node u.

We have proved that the  array on node u immediately after Step 9 contains at least one non-⊥ entry. Note that 
 
 must imply 
 
. Also since 
 
 holds, we know that immediately after Step 9, the  array on node 0 must be exactly the same as the  array on node u. In turn, by the definition of , we have . Now consider any . All nodes in 
 
 will have any edge to w. Hence 
 
, together with w, must form a connected component in 
. Putting everything together, we have shown that 
 is always connected.

Simulated execution = reference execution. Now consider the reference execution of P over the above reference dynamic network, where we feed the same input vector and coin flip outcomes into P as in the simulated execution. We will prove that for all node u, if 
 
 holds, then in round i, node u's behavior in the reference execution and in the simulated execution must be exactly the same. We prove via an induction on i. Assume that the claim holds for round . Now consider round i and any node u such that 
 
 holds. If u is sending in round i of the reference execution, then u's behavior in round i of the reference execution is entirely determined by u's state at the end of round  of the reference execution and the coin flip outcomes in round i. Applying our inductive hypothesis then immediately tells us that u's behavior in round i of the simulated execution must be the same as its behavior in the reference execution.

If u is receiving in round i of the reference execution, then applying our inductive hypothesis tells us that u must also receive in round i of the simulated execution. We will need to prove that the messages received in round i by u in the two executions are the same. Let 
 in round i of the reference execution, v is sending and v is u's neighbor in 
, and 
 in round i of the simulated execution, v is sending and at Step 18 in Algorithm 2 on node u, the set S contains v's message}.

We will first prove that 
. Consider any 
. In order for v's message to be included in the set S on u at Step 18, v must be in the  array on node u at Step 15.5 Note that 
 
 must imply 
 
. Also because 
 
 holds, we know that v must also be in the  array on node 0 immediately after Step 9, and hence . Since 
 
 implies 
 
, together with , we know that there is an edge in 
 connecting u and v. Hence 
.

Next consider any 
. We know that v is sending in round i, u is receiving in round i, and 
 
 holds. Given how 
 is constructed, we know that either  or . If , since 
 
 holds, we know that u itself must be in the  array on node u immediately after Step 9. Since u is receiving in round i, at Step 14, u will flood its msg where . This would imply 
, and hence it is impossible for . Then the only remaining possibility is . We claim that v must be in the  array on node u immediately after Step 9, and also that u must have included v's message in S at Step 18 — otherwise 
 
 would not hold. This implies that 
 and hence 
.

So far we have proved that 
. Consider any 
. We need to further prove that in round i, the message sent by v in the reference execution is the same as the one in the simulated execution. We first claim that 
 
 must hold. The reason is that otherwise in round i of the simulated execution, v would not flood its message and hence v would not belong to 
. Now since 
 
, we can invoke our inductive hypothesis, which shows that v's behavior must be the same in round  in the two executions. Since v is sending in round i in both executions, and since a sending node's behavior is not affected by the topology or the behavior of other nodes in that round, we know that v's behavior must be the same also in round i of the two executions. Hence v will send the same message in the two executions. In turn, the messages received in round i by node u in the two executions are the same.

Output of Q will never be wrong. We have just proved that as long as 
 
 holds, u's behavior is the same in the two executions up to round i. In turn, this means that if u outputs in the simulated execution, it must also output the same value in the reference execution. Furthermore, in each round of the reference execution, the topology of the dynamic network is always connected. Since P is an LV protocol, all outputs in the reference execution (and hence in the simulated execution as well) must be correct. Thus Q's output will never be wrong. □

4.3.3. Proof for Theorem 8
We next restate and prove Theorem 8.

Theorem 8

Let Q be Algorithm 1, and let P be any LV algorithm where 
 for some constant 
.

•
There exists constant 
 (independent of n) such that for all d, we have 
⁎
, where 
 is taken over all dynamic networks H with at most n nodes and at most d diameter. Furthermore, if P is input-stable, then there exist some coin flip outcomes 
 such that for all d, we have 
.

•
If 
 for some  and  where there exists some constant 
 such that 
 and 
, then we have 
⁎
. Furthermore, if P is input-stable, then there exist some coin flip outcomes 
 such that for all d, we have 
.

Proof

Since 
, there exists positive constant 
 such that 
 for all . Let , and let 
 be any constant such that 
 
 for all . Consider any given , and let 
. We will only prove for the case where H has exactly n nodes and where both 
 and d are power of 2 — generalizing to other cases is trivial. For any input vector I, define:
 
 Theorem 4 tells us that for all I, the set 
 contains at least 0.9 fraction of all coin flip outcomes. Next by Theorem 3, we have 
 
 
 
. Hence by Markov's inequality, we know that for all I, the set 
 contains at least 0.9 fraction of all coin flip outcomes. We next prove the various claims in the theorem one by one.

Proof for 
⁎
. Consider any given I. We will prove that 
 always hold. By the properties of 
 and 
, we know that for every 
, we have 
 
.

Throughout all invocations of SimulateP(ϵ, 
, 
, 
) where 
, Lemma 11 tells us that no nodes will ever be flagged. In turn by Lemma 12, when running over any dynamic network H with at most d diameter, SimulateP(ϵ, 
, 
, 
) must return P's output, if P would output within the first 
 rounds when running under 
 and 
. Hence for all 
, all d, and all H with at most d diameter, SimulateP(ϵ, 
, 
, 
) will return a non-negative value on all nodes when 
.

Recall that 
 contains at least 0.8 fraction of all coin flip outcomes for P. Hence for all 
, with probability at least 0.8, SimulateP(ϵ, 
, 
, 
) will return a non-negative value. Further note that for different 
 (and hence different 
), the probability of SimulateP(ϵ, 
, 
, 
) returning a non-negative value is independent. Once SimulateP(ϵ, 
, 
, 
) returns a non-negative value, Q will output at Step 7 of Algorithm 1. Putting everything together and by Lemma 13 (proved next), we have: 
.

Proof for 
. For this part, P is known to be input-stable. Consider any fixed input vector 
. For all 
, we have 
 
. Theorem 5 then tells us that for all input vector I and all 
, we have 
. Same as earlier, this then means that for all I, all dynamic networks H with at most d diameter, and all 
, SimulateP(ϵ, 
, 
, 
) will always return a non-negative value on all nodes once 
 reaches d. This will in turn cause Q to output at Step 7 of Algorithm 1.

Now let 
 be any coin flip outcomes for Q, such that when Q generates 
 at Step 4 of Algorithm 1, we always have 
. Since 
, such 
 must exist. Lemma 13 (proved next) then tells us that under such 
 and for some constant 
, algorithm Q spends at most 
 to finish executing SimulateP(ϵ, 
, 
, 
) with 
 and some 
. Q will then immediately output. Hence we have 
.

Proof for 
⁎
. For this part, we have the condition that 
 with 
 and 
. We already proved that 
⁎
. With the new condition, we now have 
⁎
.

Proof for 
. The proof is similar to the above case and hence omitted to avoid redundancy. □

The following proves Lemma 13, which was used in the above proof, and which bounds the number of rounds needed for Q to finish executing SimulateP(ϵ, 
, t, 
):

Lemma 13

Let Q be Algorithm 1. There exists some constant 
 such that for all 
 and  that are power of 2, all LV algorithm P, and all coin flip outcomes C for Q, by the end of the complete execution of SimulateP(ϵ, 
, t, 
) in Q, Q has spent at most 
 rounds since the beginning of Q's execution.

Proof

We use the 
 from Lemma 10. It suffices to prove that by the time when Q completes its iteration (i.e., Step 3 to Step 8) for 
, it has spent at most 
 rounds since the beginning of its execution. For all i that is a power of 2, let 
 be the largest power of 2 such that 
. Let 
 be the total number of rounds needed to execute SimulateP(ϵ, i, t, 
) for all t where t is a power of 2 and . By Lemma 10, we have 
 
 
 
 
. The total number of rounds needed for Q to completes its iteration (i.e., Step 3 to Step 8) for 
 will be at most 
. □

5. Conversion from MC algorithm P to MC algorithm Q
Section 4 focused on converting any given LV algorithm P to another LV algorithm Q that has nice properties against prophetic adversaries. This section moves on to consider MC algorithms, and shows that we can also convert any given MC algorithm P to another MC algorithm Q that has nice properties against prophetic adversaries.

5.1. Pseudo-code and intuitions
As in Section 4.1, our algorithm Q here simulates P multiple times, for different values of 
 (i.e., guess on diameter) and t (i.e., guess on the number of simulated rounds needed for P to output). Section 4.1 used fresh coin flips for each such simulation. But here since P is an MC algorithm, using fresh coin flips would amplify P's error excessively. Hence here Q will have to feed the same coin flip outcomes C into all the simulations. Now if 
 happens to be not favorable under the given C, it may generate a dynamic network with large diameter, causing P (and in turn Q) to take too many rounds to output. To avoid this problem, we will have Q explicitly check whether 
 is favorable, in a distributed fashion. If Q finds 
 to be not favorable, Q will generate some arbitrary output immediately. For checking whether 
 is favorable, Q will also use the guess 
 as the diameter of the dynamic network over which Q runs. If 
 is no smaller than the actual diameter, the checking will be error-free. Otherwise the checking may have one-sided error — interestingly, our proof will still go through despite such error.

When some nodes are flagged, Section 4.1 showed that on all the non-flagged nodes, Q has nevertheless still properly simulated P's execution against some prophetic adversary ψ. This trick unfortunately no longer works for an MC algorithm P, because when running against the prophetic adversary ψ, P's error guarantee no longer holds. Thus here, after each simulation of P (for any 
 and t values), we will have Q explicitly check whether there are any flagged nodes in the system. Each such checking takes  rounds. Hence our final result for MC algorithms will have an extra additive 
 term.

5.2. Final results on conversion from MC algorithm P to MC algorithm Q
The following theorem is our final result for MC algorithms:

Theorem 14

Let P be any MC algorithm where for some constants 
 and δ, we have 
 and 
. Let Q be Algorithm 6 with constant .

•
There exists constant 
 (independent of n) such that for all d, we have 
⁎
. Here 
 is taken over all dynamic networks H with at most n nodes and at most d diameter. Furthermore, if 
 for some  and  where there exists some constant 
 such that 
 and 
, then 
⁎
.

•
For all n, we have 
⁎
. Furthermore, if P is input-stable, then there exist coin flip outcomes 
 such that 
, with 
 being taken over all dynamic networks H with at most n nodes.

The above theorem also captures our derandomization result: To derandomize any given input-stable MC algorithm P, we simply take 
 
 and then plug 
 into Q in the above theorem. We will then get an algorithm Q with no error and with the desired time complexity.
5.3. Proof for Theorem 14
Theorem 14 directly follows from Theorem 15 and Theorem 16, which we state and prove in the next.

Theorem 15

Let P be any MC algorithm where for some constant 
 and δ, we have 
 and 
. Let Q be Algorithm 6 with constant . Then there exists constant 
 (independent of n) such that for all d, we have 
⁎
. Here 
 is taken over all dynamic networks H with at most n nodes and at most d diameter. Furthermore, if 
 for some  and  where there exists some constant 
 such that 
 and 
, then 
⁎
.

Proof

Recall that 
⁎
. Hence to prove the first part of the theorem, we only need to show that for any given I, C, and H, we always have 
 for some universal constant 
. We only prove the case where H has exactly n nodes and where H's diameter d is a power of 2 — generalizing to other cases is trivial.

Since 
, there exists positive constant 
 such that 
 for all n. Let constant 
 be such that 
 
 for all . Let 
. We first prove that Q must output by the time that Q executes Step 8 in Algorithm 6 after it completes the execution of SimulateP(ϵ, d, 
, C).

Consider the iteration (i.e., Step 4 to Step 8) in Algorithm 6 during which SimulateP(ϵ, d, 
, C) is invoked. Since H has a diameter of at most d, Lemma 11 tells us that throughout the execution of SimulateP(ϵ, d, 
, C), no node ever gets flagged. In turn by Lemma 12, SimulateP(ϵ, d, 
, C) must have properly simulated the execution of P against the adversary 
 up to round 
. Furthermore, since no node gets flagged, we must have  on all nodes, and hence ExistValue(return_v, −2, n) must return false on all nodes. This means that  on all nodes. Next, if on any node  immediately after Step 6, then on that node Q must output at Step 7. Now consider any node u where  immediately after Step 6 on u. Then CheckFavorable
 must have returned  on u. Since i) the diameter of the dynamic network H is at most d, ii) CheckFavorable
 returned true on u, and iii) SimulateP(ϵ, d, 
, C) has properly simulated the execution of P against 
 up to round 
, one can easily verify that 
 is favorable up to round 
 for the given P, I, and C. We hence have 
, by the construction of 
 (see Definition 2 in Section 3.3 for 
). By Theorem 3, the adversary 
 has a diameter of at most 
 
 
. Hence we have 
. Against because SimulateP(ϵ, d, 
, C) has properly simulated the execution of P against 
 up to round 
, this means that on node u, the condition at Step 21 of Algorithm 2 must have been satisfied at least once during the execution of SimulateP(ϵ, d, 
, C). In turn, this means that on node u, SimulateP(ϵ, d, 
, C) must return some non-negative value, and Q will then output at Step 8.

We have proved that Q must output by the time that Q executes Step 8 in Algorithm 6 after it completes the execution of SimulateP(ϵ, d, 
, C). We next reason about the number of rounds needed for Q to complete the execution of SimulateP(ϵ, d, 
, C) as well as Step 5 to Step 8 in Algorithm 6 after that.

Let 
. For all i that is a power of 2, let 
 be the largest power of 2 such that 
. Note that since 
, we must have 
 and 
. Let 
 be the total number of rounds needed to complete the execution of SimulateP(ϵ, i, t, C) as well as Step 5 to Step 8 after that, for all t where t is a power of 2 and where . By Lemma 10, for some constant 
, we have 
 
 
 
 
. The total number of rounds needed to complete the execution of SimulateP(ϵ, d, 
, C), as well as Step 5 to Step 8 in Algorithm 6 after that, will be at most 
 for some universal constant 
.

We have finished proving that 
⁎
. Finally, if 
, we will have:
⁎
 □

Theorem 16

Let P be any MC algorithm where for some constant 
 and δ, we have 
 and 
. Let Q be Algorithm 6 with constant . Then for all n, we have 
⁎
. Furthermore, if P is input-stable, then there exist coin flip outcomes 
 such that 
, with 
 being taken over all dynamic networks H with at most n nodes.

Proof

Theorem 15 showed that for any given n and for all d, all nodes running Q must output within some fixed number of rounds. Within these rounds, a node can only invoke SimulateP(ϵ, 
, t, C) at Step 4 of Algorithm 6 for finite number of times. Let 
 be the largest t such that before all nodes output in Q, some node has invoked SimulateP(ϵ, 
, t, C) for some ϵ, 
, and C.

Definitions and properties of 
 and 
. For the first part of the theorem, recall that 
⁎
. Hence we need to prove that for any give I, we have 
. For any given I, define:
 

Since 
, the set 
 must contain at least a  fraction of all possible coin flip outcomes. By Theorem 4, the set 
 contains at least a  fraction of all possible coin flip outcomes. For all 
, we immediately have 
 and 
. By the design of 
, we further know that for all 
 and 
:

•
The topologies generated (and the centers chosen) by 
 in the first t rounds are exactly the same as the topologies generated (and the centers chosen) by 
 in those rounds.

•
The adversary 
 is favorable up to round t for P, I, and C.

•
When P runs against 
, it will never generate a wrong output within the first t rounds. (Otherwise P would generate the same wrong output within the first t rounds when running against 
, causing 
 to be 1.)

Outputting at Step 7 and 8. Now consider any given input vector I, any given 
, any given node u, and any given iteration (i.e., Step 4 to Step 8) in Algorithm 6 on node u, during which SimulateP(ϵ, 
, t, C) is invoked. Note that u may generate an output at either Step 7 or Step 8. We consider the value of has_flag on u, at Step 7 and Step 8. If , then u will output in neither Step 7 nor Step 8.

If , then ExistValue(return_v, −2, n) must have returned  on node u. Because the diameter of the dynamic network H can be at most n (since the topology of H is a connected graph in each round), we know that no node invoked ExistValue(−2, −2, n) in this iteration — otherwise the invocation of ExistValue(return_v, −2, n) on node u would have returned . This then implies that on every node, SimulateP(ϵ, 
, t, C) returned some value that is larger than −2. Thus no node ever got flagged during its respective execution of SimulateP(ϵ, 
, t, C). By Lemma 12, we now know that SimulateP(ϵ, 
, t, C) must have properly simulated the first t rounds of P's execution under 
 and C. In particular, the centers selected by 
 in round r () must be exactly the same as the centers selected at Step 9 of Algorithm 2.

By our earlier argument, since 
, we know that 
 is favorable up to round t for P, I, and C. Together with the fact that the centers selected by 
 in round r () must be exactly the same as the centers selected at Step 9 of Algorithm 2, we know that the condition at Step 1 of Algorithm 7 will never be satisfied on any node. One can then verify that, regardless of the relation between 
 and d, CheckFavorable(t, 
) must return true on all nodes. This means that on node u, we will have  at Step 7 of Algorithm 6. Hence u will not output at that step.

Next also by our earlier argument, since 
, we know that P never generates a wrong output in the first t rounds when running under I, 
, and C. Now since SimulateP(ϵ, 
, t, C) has properly simulated the first t rounds of P's execution under 
 and C, if SimulateP(ϵ, 
, t, C) returns a non-negative value, that value must be the correct output for the problem. Hence u will not generate a wrong output at Step 8 of Algorithm 6.

Putting it altogether. We have proved that under any given input vector I and any given 
, a node u (running Q) will generate a wrong output neither at Step 7 nor at Step 8. Since these two steps are the only steps in Algorithm 6 where u may output, and since 
 contains at least a  fraction of all possible coin flip outcomes, we must have 
 for the given I.

For input-stable P. We next prove the second part of the theorem, which is for input-stable P. Consider any fixed input vector 
 and let 
 be any given coin flip outcomes in 
. Our proof above has already shown that 
, with 
 being taken over all dynamic networks H with at most n nodes. Now consider any other input vector I. Since P is input-stable, Theorem 5 immediately tells us that 
 must be in both 
 and 
 as well. Hence 
. Again by our proof above, we know that 
, with 
 being taken over all dynamic networks H with at most n nodes. This in turn means that 
. □

6. Conclusions and future work
This paper considers distributed algorithms in dynamic networks whose topologies are determined by adaptive adversaries. We have shown that within such a context, randomness offers limited power to better deal with “bad” adaptive adversary. More specifically, given a randomized algorithm P whose time complexity satisfies some mild conditions, we prove that P can always be converted to a new algorithm Q with comparable time complexity, even when Q runs against prophetic adversaries. Since prophetic adversaries accurately predict all randomness in the algorithm beforehand, this implies that the benefit of P using randomness for dealing with the adaptive adversaries is limited.

Our work has left several research questions open. First, currently our model assumes that the nodes have ids from 0 through . It would make our results much more general if we allow the ids to be arbitrary as long as their are of  size. The obstacle is that once the nodes can have arbitrary ids, they may potentially use the ids as “inputs” to the algorithm. Given that randomness can help better deal with “bad” inputs, this makes it hard to derandomize P. Nevertheless, we feel that imposing certain natural restrictions on how the ids can be used might overcome this problem. Second, our final results for MC algorithms have an additive 
 term, and are not as strong as our results for LV algorithms. It would be interesting to investigate whether those results can be further strengthened. This additive 
 term comes from the overhead of checking the existence of flagged nodes. If one can find a better way to control the accumulation of error probability in the simulation of the MC algorithm P, then such checking may no longer be needed, and hence the 
 term can potentially be avoided. We leave these research questions to our future work.