Abstract
Sparse matrix-vector multiplication (SpMV) has always been a hot topic of research for scientific computing and big data processing, but the sparsity and discontinuity of the nonzero elements in a sparse matrix lead to the memory bottleneck of SpMV. In this paper, we propose aligned CSR (ACSR) and aligned ELL (AELL) formats and a parallel SpMV algorithm to utilize NEON SIMD registers on ARM processors. We analyze the impact of SIMD instruction latency, cache access, and cache misses on SpMV with different formats. In the experiments, our SpMV algorithm based on ACSR achieves 1.18x and 1.56x speedup over SpMV based on CSR and SpMV in PETSc, respectively, and AELL achieves 1.21x speedup over ELL. The deviations between the theoretical results and experimental results in the instruction latency and cache access are 10.26% and 10.51% in ACSR and 5.68% and 2.91% in AELL, respectively.

Keywords
ARM
NEON
SIMD
SpMV
Storage formats

1. Introduction
1.1. Motivation
Sparse matrix-vector multiplication (SpMV) is one of the core subroutines in numerical computation. The solution of large-scale linear equations is one of the major applications, and an exact solution is usually accessed by an iterative method. SpMV, a key step in solving systems of linear equations, may be performed thousands of times in the solution process. However, the complexity of the associated hardware and the load imbalance caused by the sparsity of sparse matrices can lead to memory bottlenecks, making it challenging to optimize the SpMV performance.

SpMV computes 
 as given by(1)
 where A is a fixed sparse matrix in the iterative method. To improve the utilization of processors when calculating SpMV, the zero elements of A should be ignored in the calculation. Therefore, many sparse matrix storage formats are delivered, which reflect the distribution characteristics of nonzero elements in a sparse matrix. Some of these formats are suitable for the structural characteristics of the computing platform. Although researchers have performed many studies on SpMV, most of them are aimed at the x86 multicore platform or other accelerators, and little work has addressed ARM processors for SpMV.

ARMv8-A is an architecture for high-performance computing introduced by ARM. An increasing number of researchers have been drawn to the ARMv8-A architecture, as it supports 64-bit instruction sets, improving the double-precision floating-point arithmetic capability, and supporting single instruction multiple data (SIMD) operations via NEON, which is a SIMD instruction extension architecture of ARM. In addition, with the advent of the intelligent era, ARM processors have been widely used in mobile devices with their small size, low energy consumption, low cost, and good performance. Moreover, in the latest global supercomputer list released in November 2020, Fugaku with a 48-core A64FX SOC based on ARMv8-A retains the title, which is the first system supported by ARM processors to top the list.

1.2. Our contributions
In this paper, we

•
propose the aligned storage formats ACSR and AELL, which are suitable for NEON in double-precision calculations on ARM processors.

•
put forward a parallel SpMV algorithm based on ACSR and AELL formats.

•
evaluate the performance of our ACSR and AELL formats and compare them with the CSR and ELL formats, and PETSc on Kunpeng 920 processors.

Our aligned compressed storage formats can improve the performance of SpMV with NEON on the ARMv8-A platform, and the acceleration of SpMV based on ACSR and AELL compared with general CSR and ELL is obtained from theoretical analysis and experimental verification.

First, we present the aligned storage formats ACSR and AELL based on the CSR and ELL formats, which align the SIMD registers of ARM processors. Second, we demonstrate four parallel algorithms of SpMV with NEON acceleration. Third, we conduct a performance analysis for the impact of two aligned formats, two general formats, and the difference between them on the execution latency of SIMD instructions, the cache access, and the cache misses. Fourth, we select 20 sparse matrices from the SuiteSparse Matrix Collection for experiments, which come from a wide range of practical application scenarios. Moreover, we examine the calculation performance of SpMV based on CSR and ELL with NEON and compare the SpMV based on ACSR and AELL with NEON accelerated SpMV in CSR, ELL, and SpMV in PETSc. Finally, we compare and analyze the experimental results with our performance analysis results. For the 20 matrices, the average performance improvements of NEON accelerated SpMV reach 19.91% in CSR and 19.15% in ELL. For the use of NEON, compared to ELL, AELL achieves an average performance improvement of 20.54%, 34.10%, and 28.85% in estimating time, cache access, and cache misses in double precision, respectively, while those of ACSR are 18.17%, 18.59%, and 18.00% compared to those of CSR. In addition, the average acceleration is 56.46% higher for SpMV based on ACSR than for SpMV in PETSc.

The experiment shows that our ACSR and AELL storage formats are well suited for NEON SIMD operations on ARM processors.

2. Related work
2.1. Compressed storage formats for sparse matrices
In general, to enhance the performance, the operations of zero elements in a sparse matrix must be reduced. Therefore, a sparse matrix can be compressed to store the nonzero elements, such as the original coordinate (COO) format and the compressed sparse column/row (CSC/CSR) [19]. Although these formats are widely used, they may not be adaptable enough for some special sparse matrices. Therefore, some storage formats for the specific sparse matrices have been introduced. For example, the diagonal (DIA) [14] format stores only the nonzero elements of a sparse matrix diagonally, and the ellpack (ELL) [5] format is suitable for the matrix with relatively uniform rows of nonzero elements. Designing a storage format aimed at the hardware features of a specific processor can maximize the performance [1]. Examples include the hybrid ELL/COO (HYB) [3], the sliced ellpack (SELL-C-σ) [13], compressed sparse row 5 (CSR5) [10], the blocked stored format mixed CSR and ELL (BCE) [21] and so on. All of the above formats are in full use as massive parallel computing features of the GPU or the SIMD device of the x86 CPU.

Nevertheless, the scale of the sparse matrix obtained from practical applications is getting increasingly large, which may preclude obtaining the results immediately. As a consequence, matrix partitioning has become a valuable approach that ensures all elements in a block can be efficiently calculated immediately [12]. Karakasis et al. [7] compared the performance of several blocked storage formats. The blocked compressed sparse row (BCSR) [5] was used to exploit the computational performance of dense subblocks in a sparse matrix. Subsequently, Vuduc et al. [18] optimized the BCSR format to the unaligned block compressed sparse row (UBCSR) format and developed a better performance of dense subblocks of different sizes. In addition, to explore the substructures in a sparse matrix, the compressed sparse extended (CSX) [8] storage format was proposed to compress the index arrays.

2.2. ARMv8-A architecture
For far too long, mobile devices have been equipped with ARM cores because of the low price, high performance, and low power consumption [4]. With the debut of the ARMv8-A architecture, ARM has become a key research object for solving energy consumption in high-performance computing. Moreover, compared to the previous ARM architecture, 64-bit ARMv8-A benefits from increased support of double-precision and SIMD operations [9], making it more compelling [2], [6], [11], [17].

Many companies worldwide have purchased an ARMv8-A license and have developed their cores based on ARM. Examples include the United States companies Cavium and Qualcomm, the Japanese company Fujistu, the Chinese companies Huawei and Phytium, etc. All of these companies have already released several server-level chips based on the ARMv8-A architecture shown in Fig. 1. Furthermore, there are four supercomputers equipped with ARM processors in the latest TOP500. Fugaku with 48-core A64FX SOC produced by Fujistu [22] tops the list among them.

Fig. 1
Download : Download high-res image (89KB)
Download : Download full-size image
Fig. 1. ARMv8-A architecture.

3. Sparse matrix compression and NEON technology
In this section, we introduce two general formats, CSR and ELL, which our aligned formats are based on. Because our algorithms are designed to deliver the performance of NEON on ARM processors, we provide a brief illustration of NEON in Section 3.2.

3.1. General storage formats for sparse matrices
To show the general storage formats visually, we assume that there is a sparse matrix(2)
 
 Then, we define three parameters, namely, M is the number of rows, N is the number of columns, and  is the number of nonzero elements in the sparse matrix A.

3.1.1. Compressed sparse rows (CSR)
CSR, the most commonly used storage format, is not sensitive to the characteristics of a matrix. This format stores the nonzero elements in rows and stores the row information of the sparse matrix by indexing the first nonzero element of each row. Therefore, the CSR format employs two arrays of length “” to store all of the nonzero elements and the corresponding column index of nonzero elements, and another array of length “” is used to store the row index. Therefore, the sparse matrix A can be represented by CSR as 
  
  
 

In addition, the memory space for the CSR format in double-precision  is given by(3)

3.1.2. Ellpack (ELL)
In ELL format, a sparse matrix is compressed into two smaller dense matrices that contain the filled nonzero elements and the corresponding column indices. Assume that the maximum number of nonzero elements in a row in the sparse matrix is “k”, so the size of two dense matrices is “”. Moreover, the vacant places should be filled with zeros in the dense matrices. Thus, the sparse matrix A can be shown in ELL as
 
 

The size of the ELL in the memory in double precision is(4)

3.2. NEON technology
As an extended architecture of ARM, NEON offers 128-bit SIMD operations. For ARMv8-A, there are 32 128-bit NEON SIMD vector registers that support multiple data types and up to 64-bit double-precision floating-point precision as shown in Fig. 2. Moreover, using the NEON SIMD registers allows users to process data efficiently and minimize memory access.

Fig. 2
Download : Download high-res image (61KB)
Download : Download full-size image
Fig. 2. NEON SIMD registers.

When using NEON to accelerate SpMV, the vector x needs to be loaded into NEON SIMD registers one after another because of the discontinuity of column indices in CSR and ELL formats. In contrast, while applying the ACSR and AELL formats in SpMV, an SIMD register can be filled immediately both in sparse matrix A and in dense vector x.

For example, V0.2D, V1.2D, and V2.2D in Fig. 3 represent three SIMD registers, where “2D” means that a register stores a 2 × 64-bit vector. Suppose V1 stores the value of a sparse matrix A and V2 stores the value of the vector x in general SpMV. Therefore, the value of the vector should be assigned to the components of V2 sequentially in scalar form. Subsequently, the SIMD operator simultaneously calculates two multiplication steps (, ) and stores the result in register V0.2D.

Fig. 3
Download : Download high-res image (59KB)
Download : Download full-size image
Fig. 3. Double-precision floating-point SIMD operation.

4. Aligned compressed storage formats
When using the SIMD units for vector calculation, several consecutive elements are usually immediately loaded into the vector registers in the form of vectors. However, in SpMV, since the distribution of nonzero elements is discontinuous as a whole, the constituent of the corresponding vector x can only be loaded to the vector register sequentially [20]. The increase in load steps for the vector registers leads to the efficiency of the SIMD unit degradation. Therefore, to improve the utilization of SIMD units, we design the aligned compressed storage formats ACSR and AELL for sparse matrices to fit the ARM advanced SIMD architecture. After the compression of a sparse matrix, if the column indices of two adjacent nonzero elements are also adjacent, the corresponding two elements in the vector multiplied by the two nonzero elements are adjacent when calculating the SpMV. If the column indices of the two nonzero elements are not adjacent, the corresponding two elements in the vector are also not adjacent. If the distance between the two nonadjacent elements exceeds the width of the cache line, it is impossible to load two elements into a vector register at one time. If the deviation between the column indices of the two is less than 8, we consider that they lie on the same cache line and insert zeros before the current nonzero element. If not, zeros are inserted after the current nonzero element, which guarantees that the filling operation does not cause redundant cross-cache lines as much as access permits.

The matrix A in Section 3 is an example to be used for ACSR and AELL storage formats as follows.

4.1. Aligned CSR (ACSR)
The  stores the vector values (including the filled zero elements) by rows,  stores the first column index of each vector, and  stores the first index of  of each row. Assuming that the zero filling rate is “FR” (), there are  elements in ACSR, and the storage space size of the sparse matrix compressed by the ACSR format is(5)

According to the calculation formulas (3) (5) of the occupation space, we can conclude that the ACSR format needs more space than CSR while .

4.2. Aligned ELL (AELL)
Similar to ELL, AELL uses two matrices to store the vectors in Fig. 5. The values of vectors are stored in , and  stores the index of each vector. We set the number of vectors of each row as  in the two matrices of AELL so that the space occupied by AELL is(6)

Fig. 5
Download : Download high-res image (55KB)
Download : Download full-size image
Fig. 5. AELL format.

Equally, we can find that the AELL formats occupy more space, while  by Eqs. (4) and (6).

5. Parallel algorithms of SpMV
In the experiments in this paper, we use the NEON intrinsics provided by ARM to achieve NEON acceleration. The functions are shown in Table 1, where the letter “q” in the operation instruction indicates the use of 128-bit vector registers.


Table 1. NEON SIMD operations for 64-bit double-precision floating-point operation.

Function	Meaning
float64 × 2_t vector	Declare a vector of size 64 × 2
vdupq_n_f64(0.0)	Initialize the vector
vld1q_lane_f64(x+j,0)	Take x[j] to the 0th lane of vector register
vld1q_f64(x+j)	Take two elements from x[j] to vector register
vmlaq_f64(temp,v_A,v_x)	Execute vector operation: temp + =v_A × v_x
vget_lane_f64(temp,0)	Get the 0th component of the vector temp
6. Performance analysis
Although our ACSR and AELL formats are filled with zeros based on the CSR and ELL formats that increase the amount of calculation, this can improve the efficiency of memory access by loading a vector to the vector register in one step. Therefore, with different filling rates, the performance of SpMV may have varying degrees of fluctuation. In this part, we analyze the execution latency of NEON SIMD instruction, the impact of cache access, and the cache miss in SpMV based on different compressed storage formats.

6.1. SpMV performance analysis for ARMv8 architecture
To perform performance analysis, some variables are shown in Table 2.


Table 2. Variables for analyzing.

Variable	Meaning
T	The computation time of SpMV
L	The execution time of instructions
A	The data access time
Li	The register fetch instruction latency
Ci	The calculation instruction latency
ACnum	The number of cache access
ACt	The latency of cache access
missnum	The times of cache misses
AMt	The latency of memory access
For a computing program, the computing scale depends mainly on the number of instructions and the amount of data to be accessed. For an SpMV computation, the number of instructions is determined by the number of nonzero elements in the sparse matrix, and the amount of data accessed is related to the storage format of the sparse matrix and the access method of a right vector. However, different storage formats may have different proportions of zero elements filling and additional auxiliary data storage, resulting in different data access. Therefore, the actual running performance of a parallel program is related not only to the calculation scale of the program itself but also to the processor's instruction execution cycle, parallel execution of instructions, utilization efficiency of cache data, number of reads and writes of memory data, bandwidth utilization, and utilization rate of all computing cores of the processor, etc. To reduce the execution cycle of instructions, the instructions with a short execution cycle can be chosen. In addition, we can distribute the instructions to different computing cores for parallel execution. This can also improve the data amount of instructions by pipeline and SIMD. The performance of SpMV serial operation on the ARMv8 processor can be described by(7) where L and A are the instruction execution time and data access time, respectively. The performance T of a program is positively correlated with the number of instructions and the number of data accesses. Thus, the function f is an increasing function. L is determined by the total number of instructions and the instruction latency of the processor. For a program, the execution latency mainly includes the latency of register loading and calculator operation. For the ARMv8 processor, the register loading includes data loading of a general register and vector loading of a vector register. Calculation instructions include general calculation instructions and vector calculation instructions. Thus, the execution latency time L can be calculated by(8) where , , , and  are the latency of general register loading, vector register loading, general calculation instructions, and vector calculation instructions, respectively. There are mainly addition and multiplication steps for SpMV, and the number of operating instructions is related to the nonzero elements of the sparse matrix. The number of multiplication and addition steps are  and , respectively. Therefore, the total number of instructions for SpMV operation is determined according to the sparse matrix. However, the calculation time can be reduced by choosing instructions with short execution delay and using more instruction units simultaneously. Table 3 shows the clock cycles of different computing instructions on the ARMv8 processor. Instruction pipelining and SIMD technology can improve the concurrent operation of multiple instructions, which leads to the improvement of the throughput of instruction execution. For example, if the length of the vector arithmetic unit is M bytes and the floating-point number is 4 bytes, M/4 floating-point numbers can be calculated in a vector operation. In this way, it is equivalent to the SpMV requirement to calculate  multiplication steps to perform /(M/4) vector multiplication steps. If the data access is limited to the cache data read by the instruction execution and the memory access caused by cache miss, A can be calculated by(9) where , , , and  are the number of accesses to the cache, the delay of cache access, the number of cache misses, and the delay of memory access, respectively. For the processor, the latency of accessing the cache and memory is fixed. Therefore, to improve the performance of data access, the program should reduce the number of cache accesses and the cache miss rate.


Table 3. Latency of main instructions in SpMV.

Function	Instruction	Latency
LDR	4
vld1q_lane_f64(x + j,0)	LD1	5
vld1q_f64(x + j)	LD1	5
vmlaq_f64(temp,vA,vx)	FMLA	7(3)
6.2. The execution latency of instructions
According to the execution latency described in the ARM official document, the minimum latency can be obtained by analyzing an operation dependent on an instruction in the described group. We analyze the difference of ASIMD instructions latency between the SpMV based on ACSR and AELL formats as well as CSR and ELL formats.

The main latency of instructions is shown in Table 3. The column indices of nonzero elements are loaded into the normal register by “LDR”, and a 64-bit number or a 128-bit vector is loaded into the vector register by “LD1”, which uses function vld1q_lane_f64(,0) or vld1q_f64(). Two vectors are multiplied and added to the third vector to be evaluated by “FMLA”, the function vmlaq_f64(,,) that evaluates

In addition, for “FMLA”, the number 3 in brackets in Table 3 indicates that the calculation result can be applied after only three cycles when the calculation is complete.

For SpMV using double precision, the column index of each nonzero element must be loaded into the normal register to perform an addressing instruction to obtain the corresponding element in the vector x. Therefore, it is necessary to execute the “LDR” instruction  times. Moreover, in CSR formats, the nonzero elements can be loaded in vector, and there are 
 
 “LD1” instructions because the 128-bit vector register can load two nonzero elements at a time. However, the elements in vector x can be loaded only sequentially because the two nonzero elements loaded into the 128-bit vector register may not be continuous, which causes the discontinuity of the corresponding two elements in the vector x. Therefore, there are  “LD1” instructions for loading x into the vector register sequentially. Two nonzero elements in a row of the sparse matrix can multiply by two corresponding elements in vector x, and the results of two multiplication steps may be added to the corresponding elements of the result vector by the “FMLA” instruction at the same time. Therefore, there are 
 
 “FMLA” instructions for SpMV because there are two ASIMD units on a Cortex-A72 processor, which is used by the tested computer in the paper. According to Eq. (8), we have(10)
 
 

There are 
 
 elements to be stored in ACSR format, which include zero elements filled by the alignment operation. Therefore, it is necessary to execute the “LDR” instruction  times. However, in ACSR format, the two nonzero elements loaded into the vector register are continuous, so the corresponding two elements of x can also be loaded into a vector register because the corresponding two elements in the vector x are continuous. Therefore, there are 
 
 “LD1” instructions for ACSR format. Because the ARMv8 pipeline has two ASIMD units, two vectors can be calculated in one calculation instruction, so there are 
 
 “FMLA” instructions for SpMV, and the latency of instructions in ACSR can be given by(11)
 
 
 
 

A sparse matrix is stored in two  dense matrices in ELL format, where one of the dense matrices stores the values, and the other stores the column indices of the nonzero elements. Therefore, there are  “LDR” instructions to load column indices to the general register, and 
 
 “LD1” instructions to load the values matrices to the vector register. However, the elements in vector x can only be loaded sequentially because the two nonzero elements loaded into the 128-bit vector register may not continuously cause the discontinuity of the corresponding two elements in the vector x. Therefore, there are  “LD1” instructions for loading x into the vector register sequentially. Finally, there are 
 
 “FMLA” instructions for SpMV as with the CSR format. Because the ARMv8 pipeline has two ASIMD units, the execution latency of the “FMLA” is 
 
 
; then, we have(12)
 
 
 

For the AELL format, there are  “LDR” instructions to load the column indices to the general register. Due to the alignment operations, every two nonzero elements loaded into the vector register are continuous. Therefore, a row of data is divided  times and loaded into the vector register, and there are  “LD1” instructions to load the value matrix. The corresponding two elements of x can also be loaded into a vector register because the corresponding two elements in the vector x are continuous. Therefore, there are  “LD1” instructions for AELL format. Finally, there are 
 
 “FMLA” instructions for SpMV as with ELL format, and we have(13)
 

As a result, we can obtain the latency of ASIMD instructions of SpMV in different formats.

Using the above formulas to analyze the performance of SpMV operation based on different storage formats, we can obtain the following propositions.

Proposition 1

When 
 
 in ACSR, the number of cycles spent in SpMV based on the ACSR format is less than that in the CSR format.

Proof

With the increase in zero paddings, the amount of redundant data that needs to be read into the vector register increases, increasing the number of “LD1” and “FMLA” instructions. FR is the fill ratio of zero elements. Eqs. (10) and (11) represent the clock cycles of all operation instructions of SpMV using CSR and ACSR formats, respectively. The upper bound of FR can be obtained by(14)
 
 
 
 which calculates the difference between Eqs. (10) and (11).

To make the performance of SpMV based on the ACSR format not lower than that of SpMV based on the CSR format,  should be less than or equal to 0, so we can determine the range of FR as
 
 
 
 □

Proposition 2

When 
 
 in AELL, the number of cycles spent in SpMV based on the AELL format is less than that of the ELL format.

Proof

The storage space of the sparse matrix with ELL format depends on the row with the most nonzero elements. With the increase in zero padding, the number of redundant data points that need to be read into the vector register increases, increasing the number of “LD1” and “FMLA” instructions.  is the width of the row with zero paddings. Eqs. (12) and (13) represent the clock cycles of all operation instructions of SpMV using ELL and AELL formats, respectively. The upper bound of  is obtained by(15)
 
 
 which calculates the difference between Eqs. (12) and (13).

To make the performance of SpMV based on AELL format not lower than that of SpMV based on ELL format,  should be less than or equal to 0, so we can determine the range of  as
 
 
 □

Through these formulas, we can obtain a general trend of the cycles changing with the zero element filling rate during the SpMV calculation based on ACSR and AELL.

6.3. Cache access times
Taking CSR and ACSR as an example, SpMV based on these two formats is required to access the row offsets 2M times to determine the nonzero elements corresponding to each row. Then, in the calculation process, the nonzero elements are accessed in vector form for 
 
 and 
 
 times in CSR and ACSR, respectively. The column indices are all ordinary accesses, which are  and 
 
 times. However, the access to the vector x is fundamentally different in the load mode with the vector register; this access needs  times in CSR, but only 
 
 times in ACSR because it accesses x consecutively after aligning the data to the vector register. Finally, the results must be stored in a vector y M times. Thus, we can obtain the number of cache accesses  and  as(16)
 
 
 and(17)
 
 
 
 

For SpMV using ELL format, the value matrix can be accessed in vector form, but the column index matrix, the vector x, and the result vector y can only be accessed sequentially. Therefore, the access cache times of SpMV using ELL format  are calculated by(18)
 
 

However, for SpMV using AELL format, the value matrix, the column index matrix, and x can be vectors. Therefore, the access cache times of SpMV using AELL format are , given by(19)

Then, we can obtain the ratio of the reduction in cache access in our ACSR and AELL formats compared with the CSR and ELL formats, respectively:(20)
 
 
 
(21)
 
 

Thus, we can use the above formulas to analyze the times of cache access of SpMV operation in different storage formats and obtain the following propositions.

Proposition 3

When 
 
 of ACSR, the number of cache access in SpMV based on ACSR format is less than in CSR format.

Proof

With the increase in zero paddings, although more time is needed to access the nonzero elements, every two elements in x can be read in a vector continuously with ACSR format, which is fewer than in CSR format. FR is the fill ratio of zeros. Equation (20) represents the reduction in cache access in ACSR compared with CSR.

To make the performance of SpMV based on the ACSR format not lower than that of SpMV based on the CSR format,  should be less than or equal to 0, so the upper bound of FR can be obtained by
 
 
 
 □

Proposition 4

When 
 
 in AELL, the number of cache access in SpMV based on the AELL format is less than that based on the ELL format.

Proof

The times of cache access depend on the data size and the access mode. AELL has a larger matrix to store the values than ELL, which leads to more cache accesses. However, in the column index matrix, this number may decrease, and the load of x is now continuous.  is the width of the row with zero paddings.

To make the times of cache access of SpMV based on AELL format not lower than that of SpMV based on ELL format, according to Equation (21),  should be less than or equal to 0, so the upper bound of  is given by
 
 
 □

Thus, according to these formulas, we can find a general trend of the times of cache access with the zero element filling rate during SpMV calculation based on ACSR and AELL.

6.4. Cache miss times
As described in the previous part of this paper, SpMV using NEON acceleration can operate two vectors in a calculation instruction. It is necessary to access the cache ten times for nonzero elements in SpMV based on CSR and ELL formats and to include the nonzero elements in vector form only twice, the column index four times, and the vector x four times as well. However, we need only six times using ACSR and AELL formats in which values and x are accessed in vector form only twice, and the column index needs only the starting column index of two vectors.

In every calculation, in the worst case, four x values loaded in CSR and ELL may be distributed in four cache lines, while there are only two cache lines in ACSR and AELL. Our experiment is carried out on Kunpeng 920 with 4 cache lines of size 64 B at one set in the L1 cache. Therefore, during the calculation process, the CSR and ELL formats may have cache line conflicts and may be replaced for access to the cache 6 times in the worst case, while only 4 times for the ACSR and AELL formats. For this cause, we can infer that compared with SpMV based on CSR and ELL, the ACSR and AELL formats may reduce the probability of cache conflict and cause a decrease in cache misses [16], [23].

7. Experimentals
7.1. Experiment platform
Our experiment is based on Kunpeng 920 produced by Huawei. Kunpeng 920 supports multiple parallel instructions based on ARMv8.2 architecture equipped with two floating-point units (FPUs). As shown in Table 4, the peak performance of Kunpeng 920 in double-precision floating-point computation achieves 665.6 Gflops. Moreover, Kunpeng 920 supports eight channels of memory, but only four channels are used in our experiment.


Table 4. Experiment environment.

Processor	Kunpeng 920
Architecture	ARMv8.2
Frequency	2.6 GHz
Cores	64
L1 cache	64 kB L1l and 64 kB L1d
L2 cache	512 kB private per core
L3 cache	64 MB shared for all
Memory	4 × 2666 DDR4
OS	Centos 7.8
Linux kernel	4.18.0
Compiler	gcc 4.8.5
NUMA	nodes with 32 cores
We have examined the effect on the performance of nonuniform memory access (NUMA) architecture on Kunpeng 920. Failure to consider NUMA may cause crossnode access to memory due to OS process switching, which will cause greater delays. Moreover, in this case, the experimental results are inaccurate. Therefore, to obtain a stable and reliable result in the experiment, we bind the threads and data through the tool for NUMA called “numactl”, which can guarantee a thread to access the memory on a fixed node. Moreover, we use the perf tool on Linux to obtain the cycles, cache references, and cache misses in the calculation process.

Although the Algorithm 1, Algorithm 4 show the SpMV algorithms with NEON SIMD acceleration in single-threaded, they are also suitable for multi-threaded parallelism. All experimental procedures are implemented in C language with openMP and “-O2” complier option.

Since the non-zero elements of each row in the ACSR format are not uniform, and the operating system may schedule threads to ensure load balancing when using openMP automatic parallelism, which impact is not easy to predict in performance evaluation. In the experiments, all experiments choose the number of threads when the performance is optimal. And for the comparison experiment of each sparse matrix, the final number of threads executed is the same, which significantly reduces the impact of multi-threading on performance evaluation.

7.2. Experiment data
In this experiment, we selected 20 sparse matrices from the SuiteSparse Matrix Collection. They are all collected from a wide range of applications and are listed in Table 5, where “ ” is the name of the sparse matrices; “”, “”, “NNZ”, and “K” indicate the rows, columns, number of nonzero elements of the sparse matrices, and threshold “K” in ELL, respectively.


Table 5. Sparse matrices in the experiment.

sparse matrix	rows	columns		K	FRACSR	VK	FRAELL
bbmat	38744	38744	1771722	126	24.16%	80	26.98%
car4	16384	33052	63724	111	56.32%	62	11.71%
cavity08	1182	1182	32747	62	2.20%	31	0.00%
Chebyshev2	2053	2053	18447	2053	55.50%	1027	0.05%
Chevron1	37365	37365	330633	9	33.34%	6	33.33%
EPA	4772	4772	8965	175	54.20%	95	8.57%
FEM_3D_thermal	17880	17880	430740	27	26.62%	18	33.33%
hangGlider_3	10260	10260	49201	4558	53.45%	2280	0.04%
hvdc1	24842	24842	159981	181	4.45%	100	10.50%
iprob	3001	3001	9000	3000	66.64%	1500	0.00%
lhr71	70304	70304	1528092	63	14.14%	32	1.59%
model4	1337	4962	45753	493	13.33%	248	0.61%
mycielskian10	767	767	22196	383	56.85%	192	0.26%
OPF_10000	43887	43887	255799	64	13.65%	32	0.00%
reorientation_1	677	677	3861	394	64.83%	197	0.00%
rosen10	2056	6152	64192	3886	6.51%	1996	2.73%
TSOPF_RS_b2383	38120	38120	16171169	983	0.90%	493	0.31%
viscorocks	37762	37762	1162244	42	0.00%	21	0.00%
water_tank	60740	60740	2035281	63	30.99%	36	14.29%
xenon1	48600	48600	1181120	27	27.37%	18	33.33%
8. Experimental results
The experimental results are divided into three parts:

•
The acceleration of SpMV in CSR and ELL formats with NEON.

•
The analysis of experimental data.

•
Performance comparison of ACSR and AELL with CSR, ELL, and PETSc.

8.1. NEON acceleration for CSR and ELL
Fig. 6 shows the performance improvements of SpMV in original CSR and ELL formats after using NEON. The ordinate represents the relative performance improvements of NEON.

Fig. 6
Download : Download high-res image (162KB)
Download : Download full-size image
Fig. 6. Performance improvements of NEON in CSR and ELL formats. (For interpretation of the colors in the figure(s), the reader is referred to the web version of this article.)

Through this experiment, we find that the performance of SpMV using NEON can achieve 19.91% and 19.15% improvements in CSR and ELL, respectively.

However, for some sparse matrices, we may find that the effect of NEON acceleration is not obvious. Combining the instruction delay in Table 3 and the number of nonzero elements in sparse matrices, we can infer that the access to the vector x is still not continuous. Because the number of accesses has not decreased but the instruction delay has increased, and because there is still waiting time for the NEON operation instruction itself, an increasing amount of data may lead to excessively high memory access instruction delays that reduce the performance of SpMV. For example, “bbmat” and “FEM_3D_thermal” in ELL and “TSOPF_RS_b2383” in both CSR and ELL. Moreover, the SpMV based on CSR and ELL with NEON may cause more cache misses because it needs extra two times of cache access.

In further experiments, the SpMV based on CSR and ELL are all accelerated by NEON.

8.2. Analysis of experimental data
In this part of the experiment, we obtain the cycles, cache references, and cache misses of SpMV for different formats through the perf performance profiling tool.

The ratios of the number of zero elements filled in ACSR and AELL based on the CSR and ELL are shown in Table 5.

8.2.1. Reduction in the execution latency of SIMD instructions
The experimental results are consistent with our theoretical analysis. According to the chart, it can reduce cycles by 7.30% on average in ACSR compared with CSR, and the AELL value is 21.08% less than that of ELL.

However, there is a 10.26% average difference for ACSR and 10.51% for AELL between the theoretical and experimental results because we analyze only the main instructions. In the actual implementation process, we directly use the encapsulated NEON functions to use SIMD technology, but there are still some unknown instructions. Therefore, if the filling rate of ACSR theoretically reaches approximately 47%, an adverse effect arises, and there are some matrices whose filling rate reaches more than 56%, such as “iprob”, “mycielskian10”, and “reorientation_1” in the experiment too. Moreover, due to load unbalancing, the OS scheduling of threads may cause additional overhead in parallel SpMV calculations based on ACSR format.

For example, the distribution of nonzero elements in “TSOPF_RS_b2383” is too scattered, which may increase the number of memory accesses for ACSR and AELL. In the parallel SpMV calculation of some matrices in CSR format, the main performance depends on the long rows with the maximum non-zero elements. Although the instruction clock cycle of the serial calculation is theoretically increased compared to the CSR format, the opposite of the theory may occur in the parallel calculation for the zero-element filling rate of long rows in ACSR format may be zero. Such as “car4”, “Chebyshev2”, “hangGlider_3”, and “EPA”. The average length of their non-zero rows is hundreds or thousands of times different from their long rows, while the zero filling rate of long rows is almost zero. Therefore, the experimental results of these sparse matrices disagreed with the theoretical analysis in Fig. 7.

8.2.2. Cache improvements
Fig. 9, Fig. 10 present the number of cache access events reduced by ACSR and AELL formats, which is respectively 18.59% and 34.10% compared with those of CSR and ELL, and the deviation between the theoretical value and the actual value is 5.68% for ACSR and 2.91% for AELL.

Although the impact of cache access for ACSR and AELL formats is consistent with the theoretical analysis, there are still large deviations in the experimental results of a few matrices in ACSR. By analyzing the distribution of the nonzero elements in these matrices and comparing it with AELL, the reason for the large deviation may be the unbalanced load during the calculation, such as “bbmat” and “TSOPF_RS_b2383”.

In addition, we find that the ACSR and AELL formats can reduce the cache hit conflicts in a single calculation. As shown in Fig. 11, ACSR and AELL can reduce the number of cache misses of SpMV by 28.85% and 18.00%, respectively.

The ACSR and AELL formats can reduce the probability of cache conflict in each calculation process because the added zero elements and the previous nonzero elements usually remain on the same cache line. However, there are vectors across cache lines due to cache conflict. Therefore, when a sparse matrix has a relatively concentrated distribution of nonzero elements, the filling of zero in AELL format may cause the extra cache misses [15]. For example, “Chevron1” is a diagonal sparse matrix, and all nonzero elements are gathered on the diagonal line. Therefore, there are fewer nonzero elements across the cache line, such that the extra filling of zeros leads to more cache misses.

8.3. Performance of ACSR and AELL
In this part of the experiment, we compare the calculation time of SpMV using ACSR and AELL formats using CSR and ELL accelerated by NEON. We find that the ACSR format is the best in most cases. Fig. 12 records the performance improvements of SpMV based on ACSR compared with SpMV in CSR format and PETSc and makes a comparison between AELL and ELL on Kunpeng920 processor. At the same time, Fig. 13 shows the experimental results on FT2000+ processor to verify the performance improvements of our aligned storage formats.

Fig. 12
Download : Download high-res image (156KB)
Download : Download full-size image
Fig. 12. Performance improvements of ACSR and AELL on Kunpeng920 processor.

Fig. 13
Download : Download high-res image (167KB)
Download : Download full-size image
Fig. 13. Performance improvements of ACSR and AELL on FT2000+ processor.

The final experimental results are consistent with the analysis in Section 6. In this experiment, we find that SpMV in ACSR and AELL formats can achieve better performance than in the CSR and ELL formats. Compared with CSR and PETSc, ACSR can achieve an average performance improvement of 18.17% and 56.46%, and AELL achieves an average performance improvement of 20.54% over ELL on Kunpeng920 processor, while the average performance improvements are 24.83%, 61.14%, and 22.55% on FT2000+ processor.

However, the sparse matrix “car4” is a diagonal matrix with local continuity and the filling rate in ACSR reached 56.32%. The calculations of SpMV based on ACSR show almost no improvement in instruction latency, cache access and cache misses compared with SpMV using CSR.

9. Conclusions
In this paper, we propose two aligned storage formats, ACSR and AELL, which focus on the 128-bit SIMD operator to parallel optimize SpMV in double precision on ARM processors. Then, we analyze the improvement of ACSR and AELL formats in terms of the instruction delay, cache access, and cache miss that the deviations from the experimental results are 10.26%, 10.51% and 5.68%, 2.91% in execution latency of instructions and cache references, respectively. Moreover, as the experimental results show, SpMV based on ACSR can achieve an average improvement in the executive latency of instructions, cache references, cache misses, and calculation time of 7.3%, 18.59%, 28.85%, and 18.17%, respectively, compared with SpMV in CSR formats; the corresponding AELL parameters are 21.08%, 34.10%, 18.00%, and 20.54% higher than those of ELL. In addition, we choose PETSc for comparison and find that SpMV based on ACSR exhibits a 56.46% performance improvement compared to PETSc. In the future, we plan to consider more instruction types, and prefect the cache performance in performance analytical models of SpMV on ARM processors to predict more accurately and achieve better performance optimization.

CRediT authorship contribution statement
Yufeng Zhang: Conceptualization, Investigation, Methodology, Software, Validation, Writing – original draft. Wangdong Yang: Conceptualization, Methodology, Project administration, Resources, Writing – original draft. Kenli Li: Supervision. Dahai Tang: Software, Validation. Keqin Li: Writing – review & editing.