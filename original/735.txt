Abstract
The problem of using cloud computing resources for services is related to planning the amount of resources needed and their subsequent reservation. This problem occurs both on the side of the customer who tries to minimize the cost of the service and on the side of the cloud provider who wants to make the best use of existing infrastructure without introducing any modifications. In our article, we want to show how the problem of overestimating the utilization of resources for services which use cloud computing can be handled. Solving this problem will allow significant savings to be made by both the customer and the cloud infrastructure provider. The system we have developed demonstrates the considerable utility of machine learning methods when planning cloud resource reservation for network services. The models proposed, which use a multilayer perceptron, have yielded good results for both short- and long-term reservations.


Keywords
Cloud computing
Cloud-based service
Predicting resource consumption
Adaptive planning
Machine learning

1. Introduction
The option of using cloud computing resources provides users with a number of potential benefits [2], such as transferring to the service provider the responsibility for physical equipment, the ability to freely and quickly scale the user’s proprietary solutions depending on the needs, or to release unused resources and thus reduce maintenance costs. These benefits and the popularity of both public and private cloud computing options [4] account for the emergence of the phenomenon of “softwarization”, i.e. the use of software-based solutions instead of physical hardware.

The use of available cloud resources and independence from dedicated physical hardware has had a particular impact on the creation of the ETSI NFV specification [7]. This specification puts forward ideas for replacing existing network services, which are maintained using dedicated and often proprietary hardware solutions, with their counterparts in the form of standardized software that can be run on any server. This approach allows for scaling of network services and their simple updates.

The problem of using cloud computing resources for services is related to planning the amount of resources needed and their subsequent reservation. This problem can be observed both on the side of the customer who tries to minimize the cost of the service but still wants to meet SLA (Service Level Agreement) conditions vis-à-vis its own customers, and on the side of the cloud provider who wants to make the best use of the existing infrastructure without having to expand it needlessly. It is also important in private clouds where resources are usually much more limited. In the case of providers offering a “pay-as-you-go” model, the problem of reservation on the customers’ side disappears — they pay for what they need while the provider is required to guarantee adequate infrastructure. Providing a sufficient number of physical machines without under- or over-estimating how many are needed allows maintenance savings, but requires accurate prediction of future demand for resources.

In the time-based subscription model, customers often opt for overprovisioning to maintain stable service quality and avoid breaching SLAs during periods of higher system load. As a result of this approach, a large part of the reserved resources remain unused, causing additional costs for both the provider and the customer.

The main contribution of our article is a novel approach allowing for both short- and long-term reservations that can resolve the problem of overestimating the utilization of resources in services that use cloud computing. Solving this problem will enable significant savings by both the customer and the cloud infrastructure provider. Also, importantly, the experiments are performed using real-life infrastructure and real-life usage data. In most of the research we have found in the literature, simulations are used and exclusively short-term reservations are considered. In our opinion, both aspects are important.

Long-term reservation detects patterns/regularities in resource usage based on the characteristics of the period which the prediction concerns (e.g. working day/weekend, vacations, holidays). The patterns discovered (e.g. VoD traffic is high in the evening and low during the night with the exception of New Year’s Eve) make it possible to prepare infrastructure for changing demand. A comprehensive reservation plan is especially important in the case of private clouds (e.g. 5G infrastructure) where resources are limited. The ability to discover potential problems with insufficient resources in advance makes it possible to add resources from another (public) cloud or transfer them from another tenant or application where lower demand is predicted.

Short-term reservation detects patterns in trends, which may be unexpected and irregular, like slashdot (flash crowd workload) effects, which occur too rapidly for auto-scaling techniques, and the latency between the resource reservation request being issued and the resources requested being actually allocated may result in infrastructure overload and a Service Level Agreement breach. This can be discovered by observing changes in resource consumption within a certain time window (e.g. the last 15 min) [16]. The detection of increasing demand ensures sufficient time to allocate resources, while peak demand discovery makes it possible to free them.

The rest of this paper is structured as follows: Section 2 contains a description of related work, Section 3 focuses on the description of an adaptive resource planning system, Section 4 describes the experiments performed, and Section 5 contains the conclusion and further work.

2. Related work
While there are some recent studies on the possibility of reserving the optimal amount of resources for services using cloud computing, the topic has not yet been widely studied. One approach to reserving resources is the conclusion of an agreement between the customer and the provider [9] in which the customer declares demand for a specific amount of resources and, in addition to actual consumption, is also billed for the entire amount reserved. Under this solution, the customer specifies its requirements and the provider gains information about the customer’s possible needs and is able to better use the existing infrastructure (and possibly extend it as needed). In [9], the authors discuss the benefits of declaring the amount of reserved resources (for both the customer and the provider) using game theory, proposing that providers enter into long-term contracts for average customer demand and short-term contracts for periods of higher resource demand. However, the use of such a solution requires the customer to be charged for the entire reservation, not just the part that was actually used. An example of a problem resulting from this billing mode is the instances having unnecessarily high performance relative to the software running on them — this situation is disadvantageous both for the customer (additional costs of using resources for the service) and for the provider (blocked unused resources).

In order to achieve a solution more flexible than booking a fixed amount of resources, it is possible to create a reservation system which allows the customer to specify its needs within a given period. While such a system does not solve the fundamental problem of over-reserving, it provides the opportunity to create a more precise mechanism that is able to automatically select optimal reservation values without the need for interference by the provider.

One implementation of such a system is Blazar — a component belonging to the OpenStack project, which allows for earlier reservation of resources and their subsequent use [11]. It enables both entire physical and virtual computing units to be reserved. If, in a given period, the reservation cannot be completed, it also makes it possible to attempt reservation at a later date or use best-effort reservation. In addition, as it stores booking history, Blazar enables the use of collected data to account for the cost of resources used by customers. However, in [11] the authors developed a solution that only allows resources to be reserved and managed (using, among others, the Blazar component) without the option of predicting the consumption of cloud resources and planning their use in the future.

Another area of interest for research concerns efficient resource allocation in the context of Quality of Service (QoS). In [1] the authors deal with the important issue of allocation of resources in cloud data centers and present a genetic algorithm for the effective task allocation problem. The results of the tests show that the solutions proposed improve QoS in the cloud (and fog) computing environment in terms of the allocation cost. In another article [18], the authors present an overview of various research in the field of resource allocation and resource availability in the cloud computing environment based on QoS requirements. However, these publications are primarily concerned with methods of efficiently allocating resources (at a given moment) in the context of QoS rather than with planning future resource consumption.

A solution similar to the one presented in [9] is the environment presented in [5] where the service is a database (Database as a Service, DBaaS) and the customer wants to optimize the price/hour ratio of the query. That article describes methods for training several machine learning (ML) models (linear regression, M5Rules, multilayer perceptron (MLP)) based on query execution plans and execution time collected from performing identical query sets on database containers with different hardware specifications. Thanks to this information, the customer receives a notification about the estimated execution time for each future query execution plan and can decide to temporarily migrate the database to a container with a better specification. In this manner, the predicted task execution speed depends on the resources rather than on resource consumption per task. This solution allows the use of resources to be optimized by enabling the customer to temporarily increase demand.

The reverse approach where the consumption of resources is predicted during task execution is presented in [15]. It is based on the collection and aggregation of measurement data on a process or group of processes (representing the application) and related system calls. This approach makes it possible to support multiple application classes without making unnecessary interventions in their structure. The prepared data are merged (treated as the state of the entire system) and used to train the machine learning model. Based on the current system state, the trained model facilitates predicting system parameter values in the future. Despite the lack of a direct reference in this work to the problem of resource reservation, it offers the possibility of predicting the resource consumption of a single instance of the entire service. This approach may be used for reserving resources if it is assumed that the state models of an application instance group can be treated as a single state model of the entire service.

Most resource consumption prediction approaches use ML techniques. For example, in [14], the authors use an algorithm based on learning automata, which accurately predicts the load of the virtual machines. The solution developed was tested on real-life data covering over a thousand VMs in 5-min intervals for 24 h. Information of these VMs is gathered from 500 hosts. However, the solution developed was only tested for short periods of time and was neither designed nor tested for long-term prediction.

The Intelligent Regressive Ensemble Approach for Prediction (REAP) presented in [10] enables (also with the use of ML techniques) the integration of feature selection and resource usage prediction techniques to achieve high performance. The authors also present a review of the work related to resource usage prediction techniques that mostly use ML techniques for real-life cloud computing platforms (such as the Amazon EC2 cloud) and simulation environments (such as the CloudSim cloud simulator). However, this comparison does not include (apart from one case) an analysis of the suitability of these solutions for short-term and long-term predictions. The REAP approach developed was tested in a real-life cloud environment and the results obtained show that the proposed approach outperforms the existing models significantly, improving the accuracy rate and reducing execution time. The authors developed an effective method for predicting resource usage in cloud computing and compared it to several other solutions. Unfortunately, the article does not include an analysis of the suitability of that solution for short-term and long-term predictions. From the results presented, it can be assumed that the prediction method developed can only be used in the short term. Our intention in conducting the research was, among other things, to determine the possibility of predicting resources in the long term, which issue was not discussed in this and most other research we analyzed.

A method similar to the one presented in our article is presented in [16], in which the author discusses the impact of sudden changes in network traffic used by services on the overall quality of service and meeting the SLA. The author proposes the use of recurrent neural networks (RNN), in particular the Long Short-Term Memory (LSTM) model, to detect rapid increases in network traffic at an early phase and preventively scale service instances. The article presents two approaches: with dedicated models for normal movement and sudden jumps, and with a single model that supports both cases. In addition, the obtained predictions also serve to change resource use limits, which are used for up- and downscaling. The results presented in the article demonstrate a much faster increase in the number of instances in the event of a network traffic spike and faster stabilization of the average service response time compared to other methods adopted as a reference. The solution presented in the article focuses on short-term prediction, using only consumption values of the monitored resource from the last few minutes in contrast to the long-term predictions proposed in our article. Moreover, our method, in addition to the resource consumption value, uses additional metadata related to the time at which the measurement was made. This is used to discover certain regular patterns of system behavior related to specific times of day or days of the week. A more detailed comparison of our solution with [16] has been discussed in Section 4.4.

Recently, a lot of research on optimizing cloud resource consumption has been related to 5G technology. Our proposed solution also uses ETSI MANO which enables the dynamic orchestrating of the 5G network service. In [3] the authors propose a framework that handles spectral resources based on user requirements and network behavior. The article introduces a new Cloud Radio Access Network (C-RAN) architecture modified as multitier heterogeneous C-RAN in a 5G environment. Also in [8] a resource allocation method for C-RAN was presented, taking into account, inter alia, QoS and power constraints. However, both articles only consider the allocation of resources at a given moment, omitting the issue of future planning, and tests of those solutions were carried out exclusively in the form of simulations.

As can be seen from this analysis, the topics of resource consumption prediction and reserving cloud resources have been discussed in the literature. However, much of the research is concerned with the efficient, immediate allocation of cloud resources at a given point in time, and not with future resource planning. Although there are publications that deal with the topic of resource consumption planning in the future, they are almost always concerned with the short term. Our research fills this gap by showing the possibilities of planning and reserving cloud resources used by services in both the short (up to 12 h) and long (up to 14 days) terms based on resource usage predictions made with the help of machine learning algorithms. It builds upon our work presented in [17] where a simpler prediction model was considered and tested on Wikipedia load data.

3. Adaptive resource planning system
As part of our research, we have developed the Adaptive Resource Planning System (ARPS) that enables the management of service resources, including resource consumption planning and reservation in cloud computing. The system developed uses machine learning and makes it possible to build a model, based on historical data, of the consumption of cloud resources by a specific service, and train that model continuously using new data. The solution developed enables collecting telemetry data, model learning, and periodically modifying the reservation plan.

3.1. System concept
Fig. 1 shows system architecture including the interaction between reservation and learning modules as well as the virtualized infrastructure manager and resource monitor.

The first element of the system is the Virtualized Infrastructure Manager (VIM), which is designed to provide basic cloud computing functionalities such as the allocation and release of resources, the management of instances running as part of allocated resources (including scaling their quantity) and the collection of telemetry data (1) directly from an instance or through a monitoring service. In order to monitor system status, a resource monitor is used, which is responsible for the periodic collection and aggregation of telemetry data from all observed instances and saving them in a unified form in a common database (2). The machine learning module uses the telemetry data collected (3) to periodically train selected models (4) during system operation. The reservation module is responsible for reserving resources in cooperation with VIM (5). It determines the availability of resources based on all known reservations stored in the database (6) and sets resource limits. In addition, it makes decisions on the possibility of up- or downscaling selected groups of instances based on previously made reservations and predictions from the machine learning module (7), which uses trained models (8) to provide predictions.


Download : Download high-res image (167KB)
Download : Download full-size image
Fig. 1. ARPS system concept.

Resource planning is adaptive because the Machine learning module is executed repeatedly online during system operation. New monitoring data are added to the database and the Models learned by this module in step (4) reflect the current behavior represented by these new data.

In order to obtain the current state of the system and monitor the resources used, a cyclical telemetry measurement is performed at the level of a single instance of a given service at constant intervals (
). Vector  presents a single telemetry record for an instance  in a given timestamp : (1)

This vector includes information concerning the time of measurement (), and observed metrics: average CPU load (
), average memory consumption (
) and average input/ output traffic on the network interface (
). Telemetry measurement 
 for the entire service  in a given period  constitutes the sum of vectors 
 of all  instances belonging to the given service: (2)

The set 
 for all readings of service  at timestamps  constitutes the base for a model that makes it possible to predict resource consumption: (3)

Model learning consists of two stages: supplementing telemetry data with additional information and the actual learning process of the model. Depending on the model adopted, input data for the test may be different, while regardless of the model the result is the expected consumption of cloud resources.

In our solution, in the first stage, the collected telemetry data are supplemented with additional metadata with the aim of improving the quality of model learning. Timestamp  for each reading 
 has been replaced by elements of vector 
, obtained from the variable value : (4)
where:

•
dayOfWeek — the day of the week, starting from Monday, values ;

•
workday — information whether the day in question is a workday, values  — false,  — true;

•
weekend — information whether the day in question falls on a weekend, values  — false,  — true;

•
holiday — information whether the day in question is a holiday, values  — false,  — true;

•
vacation — information whether the day in question falls in a (school or academic) vacation period, values  — false,  — true;

•
season — information about the season, starting from winter, values  in natural order of the seasons.

Additionally, it is assumed that for each pair  of the service type  and the observed resource  a separate machine learning model will be developed. For the short-term model that uses resource usage data just before the prediction time, the vector 
 was enhanced by these data: (5)
 (6)

Based on the data prepared, ML models were trained and used to predict the future consumption of individual resources. To select the machine learning algorithm, we compared the efficiency of various supervised machine learning algorithms (neural networks, linear regression and regression trees — REPTree and M5P) in the context of cloud resource reservation (details can be found in [17]). In the case of short-term reservations, the results obtained for neural networks and REPTree were similar (the neural network exhibited Q values that were 7% worse, which was statistically insignificant). The use of the other two ML algorithms (linear regression and M5P) yielded much worse results in testing (200% and 72% worse, respectively). In the case of long-term reservations, neural networks achieved a prediction quality over 50% higher than that of other algorithms. Our previous research [13] related to mobile cloud computing also pointed to better results achieved by neural networks compared to traditional machine learning models. Therefore, we decided to use a multi-layer perceptron (MLP) trained by a backward propagation mechanism in our system. The MLP model used consists of two boundary layers of neurons: the input and output layers, and a minimum of one hidden layer between the boundary layers. In the model used, each neuron is connected to all neurons of the neighboring layers.

To be able to create a long-term reservation plan, one needs a model enabling the prediction of resource usage for a given time , which may be distant from current time 
. For a short-term plan, we take into account time 
, which is close to 
. We assume that  is a constant representing the next timestamp. Depending on the granularity of time adopted, it may be one hour or one day ahead. Importantly, one can use  values of resources usage at 
 and before (
) to improve the prediction. We call  the size of the time window. Therefore, we propose two types of ML models:

•
long-term: 
 — answering whether a given resource  is consumed within the time specified by the parameters 
 (formula (4));

•
short-term: 
 — predicting the future consumption of resource  at time  based on current service status 
 (corresponding to formula (5)).

While the result of the prediction consists of a continuous random variable, a discrete variable is needed for the reservation itself, preferably related to the size of a single instance of the service. This variable should describe the maximum amount of resources required in relation to all the service’s instances. In addition, to determine the metric describing the quality of the prediction, it is possible to specify the minimum amount of reserved resources. As a result, it is possible to propose a reservation error metric  (defined in formula (9)), which describes actual resource consumption exceeding the maximum or being lower than the minimal assumed demand threshold — the lower that value, the better the prediction at any given moment.

Formulas (7), (8) set respectively the lower and upper limits of the estimated demand for resources. Coefficient  determines the level of granularity of the prediction result: (7)
(8)
 In our experiments, we apply  given the technical limitations regarding the infrastructure and possible traffic amount. While the value of  may be set to any arbitrary positive value, in production-ready environments 0.5 appears to be an appropriate default (as popular cloud technologies such as Docker or Kubernetes make it possible to request fractional parts of a CPU, which is often used by instances of microservices). As a result, 
 is the highest multiple of  not larger than 
 value, and 
 is higher by . Resource demand should fall in the band between 
 and 
.

It is important to note that one can increase the probability of both the actual value and the predicted value falling within the same interval described by formula (8) by using greater  values. This involves a trade-off when both values do end up in different intervals — we are then effectively over- or underprovisioning resources. (9)
 where  means the model input data and  represents the real resource usage.

In order to improve the matching of the resource reservation plan to the actual resource requisition, its modification should be based on the prediction result obtained from the learned model. Additionally, such a modification may include current reservation values. It should be assumed that the reservation value is a discrete value directly related to the specification of a single virtual machine (VM) on which a single instance is running. In other words, reservation can be done in amounts that are multiples of the resources assigned to a single virtual machine.

We assume that reservation of resource  is defined as a pair 
, similar to the 
 and 
 values described before. The reservation module allows the scaling of service instances within this range. The system developed uses a variant in which the reservation value depends on the prediction result of the ML model. Maximum and minimum values of reservation  of resource  after the correction are: (10)
(11)
 where  means input data for the learned model, 
 represents a selected model, and 
 means a constant amount of resources available on an individual virtual machine. These values are identical to the limits for the  metric (formula (9)).

3.2. Implementation
The architecture of the implemented ARPS system is shown in Fig. 2. The implementation of the ARPS system is based on a private cloud created using the OpenStack system in the Stein version, and a shared implementation of the ETSI MANO — Open Baton specification. The Open Baton project was configured with the autoscaling engine and all its dependencies. Additionally, implementations of instances of the selected network service have been developed together with the client, generating traffic based on VoD data in order to create a load for the emulated system, and allowing tests of the ARPS system. At the same time, Zabbix software was used as the telemetry data aggregator.

The solution developed contains three modules: for reservation, learning, and monitoring resources. To implement these modules, the Javalina project and Kotlin language were used. The system also used the PostgreSQL database, with separates base schemes for the purposes of various modules. Communication between elements of the system is implemented via the REST API interfaces.

In order to collect information concerning consumption with the external resource monitor selected (Zabbix) and process it for the purposes of machine learning, a resource monitor module has been developed. The collected data are saved in a shared database.


Download : Download high-res image (176KB)
Download : Download full-size image
Fig. 2. Architecture of the implemented system ARPS.

The machine learning module was implemented using the Weka platform [19] and its DeepLearning4J package [12]. Two modes of operation have been implemented: pretraining the model on the basis of a given data set and retraining the model periodically during service operation. The multilayer perceptron was chosen as the basis for the implementation — at the outset, the machine learning module loaded the previously prepared model and subsequently used it to predict resource consumption. Cyclically (every 24 h), a copy of the model was retrained using previous historical data as well as the latest data from the last 24 h. The model thus obtained was saved on the drive and replaced the original model.

The final (reservation) module in the developed ARPS system is responsible for managing reservations and deciding whether the autoscaling engine can perform the action. The number of virtual processors and the amount of RAM have been assumed to be reservable resources. The need for interaction between the autoscaling engine that is part of the Open Baton project and the reservation module required modifications to the engine (Extension* in Fig. 2). An additional step has been added to the scaling logic which, in the event of a positive decision regarding scaling (based on the rules defined in virtual function configuration), sends a query to the reservation module if this action is possible within the current reservation defined by boundaries (10).

4. Evaluation
In order to check the efficiency of the ARPS system developed, a number of experiments were performed, using traffic from a real video sharing service (Peer-to-Peer IPTV) [6]. For the purposes of these experiments, a test environment was prepared in which individual components of the ARPS system were launched.

4.1. Testing environment
The environment used in the experiments consisted of two physical machines and one virtual machine. All machines were connected to a common local area network (the virtual machine — through a virtual bridge). The machines used had the following configurations:

•
The first machine was a computing unit equipped with 16 logical cores, 32 GB of RAM and a single physical network interface (Gigabit Ethernet); on this unit, two sets of system components were launched:

–
The OpenStack environment and reservation system were configured directly on the machine. For this part of the system, 12 logical cores and 20 GB of RAM were allocated (in total for the manager’s elements, the Nova computing node and the reservation system), and CentOS 7 was used as the operating system;

–
The Open Baton project was configured on a separate virtual system allowing virtualization based on a KVM (Kernel-based Virtual Machine), which was allocated 3 logical cores and 8 GB of RAM, and Ubuntu 16.04 was used as the operating system.

•
The second machine was a NUC (Next Unit of Computing) computing unit equipped with 4 logical cores, 8 GB of RAM and a single physical network interface (Gigabit Ethernet). This unit was configured as a client generating traffic to a video on demand (VoD) service.

4.2. Video-on-demand data
The data set used in the experiments [6] consisted of traffic lists for the Peer-to-Peer IPTV service offering users both live and on-demand content. This service was made available to students and employees of the University of Lancaster in Great Britain over a period of six months. The collection contained two lists: one for user traffic from PC applications, and the other for TV user traffic.

The analysis of this data set showed that the Peer-to-Peer IPTV service was more popular among PC users. In addition, there was a decrease in the number of requests in the middle of the study period, which was the result of the winter break at the university. Further analysis of the data indicated that a decrease in the number of requests occurs on Friday and Saturday of each week, which can be explained by the absence of some users (students) on weekends.

In order to use the existing data for the Peer-to-Peer IPTV service and emulate real traffic, the authors created an environment to share video data and a client receiving such data. An nginx HTTP server was used as the basis for the service. The HLS (HTTP Live Streaming) protocol enabled downloads of VoD content. Previously prepared fragments of the sample video material together with a manifest file were placed on each instance of the Peer-to-Peer IPTV service. The client, after downloading the manifest file, requested another fragment of the video material and simulated the time needed for a user to “view” it. The next fragment request was sent immediately before the end of the previous transmission.

The data set with network traffic lists contained real-life traffic characteristics and patterns; however, it was devoid of information on, for example, processing time, response content, etc. In order to obtain the information necessary from the point of view of the system, we developed a client application that was able to create a test plan based on the traffic log and recreate the traffic to the Peer-to-Peer IPTV service. Based on the service traffic list obtained, a configuration file was prepared that was later used by the developed application to create the test plan (in the form of a list). The indexes of the list thus prepared corresponded to the following days of the experiment, with each day consisting of a certain number of buckets. Each bucket aggregated a number of actual traffic queries (traffic over a period 
 was aggregated, where 
 representing traffic aggregation bucket length was defined by the user) which were executed in the same second by the client. Each day consisted of 
 buckets, which corresponds to the number of seconds per day divided by the length of the aggregation window.

The plan was used in experiments in the following way. The service retrieved the next bucket of the day from the queue every second (or proceeded to the next day after retrieving all buckets) and created new users for each query, with the use of a concurrency model based on actors and implemented using coroutines (from the Kotlin language). Each actor had information on all the requests to be sent during his lifecycle (based on the received HLS manifesto), along with intervals between them (determined empirically or based on data, if possible). In addition, it was possible to specify a traffic amplification factor , which caused an -fold increase in the number of queries generated for each bucket.

In experiments, 
 seconds and traffic amplification factor  were assumed. Readings from the resource monitor were taken every minute. The fifty-fold increase in traffic (as compared to actual data) in each bucket was dictated by the desire to generate a load sufficiently large to force the action of the autoscaling engine. Such increase in traffic did not distort characteristics of user behavior over time.

To reduce the statistics generation time, traffic aggregation in buckets of size  was used. Instead of 6 months for 1:1 traffic mapping, this duration of the experiment was about 13 days in total. Due to the selection of the max() aggregate function when calculating resource consumption in a given period (see formula (13)) and the relatively small aggregation window (from the point of view of hourly and daily consumption), the overhead on traffic characteristics alone was found to be small.

Collected telemetry data contained timestamps for the period when the emulation itself was performed. Although it was not a problem during normal system operation, in the case of emulation it was necessary to shift the timestamps to the period presented in actual data (years 2011/2012). This was significant because of the need to supplement the data collected with time metadata.

Ultimately, with the selected settings, each single measurement of resource consumption by a single instance over a 1-min period (conducted as part of the emulation) corresponded to a measurement of resource consumption over a 20-min period (for the actual system). Time metadata were calculated based on shifted timestamps. Holiday and off-day metadata were taken from the UK holiday calendar and the Lancaster University academic calendar. The obtained measurements were aggregated again in order to obtain data sets for hourly and daily consumption according to formulas (12)–(15): (12)
(13)
(14)
(15)
(16)
 where:

 — a single record corresponding to a period of 20 min;

 — the output set for the instance of the service ;

 — the width of the aggregation window, taking into account that before the aggregation a single record 
 corresponded to a period of 20 min, for hourly consumption , and for daily consumption ;

 — data set for the instance  after aggregation within a single instance;

 — a single record for a single instance after aggregation;

 — data set for the entire service after the aggregation of all instances;

 — a single record for the entire service after aggregation.

The process conducted rendered data sets containing four resources: processor load, the amount of RAM used, and inbound and outbound network traffic. Three data sets were generated: telemetry data for each instance before aggregation, data after aggregation within hourly periods and data after aggregation within daily periods.

4.3. Results
As part of the experiments using machine learning, several models were prepared, based on the multilayer perceptron, which were then trained using the prepared data. All models were based on the basic set of parameters (determined empirically and presented in Table 1), and differed in their attributes, the shape of the hidden layer and parameters used by the optimization function — learning rate and momentum.

In the first stage of experiments, two long-term models (
) were proposed, both predicting resource consumption on the basis of time metadata only, for daily and hourly consumption respectively.


Table 1. Common parameters used by the models.

Optimization algorithm	Stochastic Gradient Descent (SGD)
Update function	Nesterovs
Weight initialization	ZERO
Bias initialization	ZERO
Max. number of epochs	1000
Hidden layer activation function	f. sigmoid function
Output layer activation function	linear function
Cost function	Mean Squared Error (MSE)
As part of the experiment for daily resource consumption, processor load was selected as the tested resource. Several learning rates (from the 0.1–0.0001 range) and momentum (from the 0.1–0.5 range) parameter configurations as well as several sizes of the single hidden layer were considered. It was observed that for a number of hidden layers greater than 1 the prediction error was significantly higher (at least 3 times greater than the error of the best model with a single hidden layer). For the selected best model (daily prediction; parameters: , , ), the set of metric values (Table 2) was calculated (based on the test data set). The  parameter value selected was 0.5. Additionally, the daily prediction summary presented in Table 2 was supplemented with the field presenting the sum of the  metric for static reservation selected in such a way as to cover the maximum consumption of resources over the period examined. The sum equal to 0.33, maximum equal to 0.21 and median equal to 0 mean that during the two weeks in question, under- or over-estimation of needs amounted to one-fourth of a single VM’s resources during a single day and much less during the other days.

Fig. 3 presents the calculated metric showing the expected lower and upper limits of optimal reservation, represented by a dark gray band, along with actual consumption (the black line). A successful reservation should result in this line falling inside the band. In addition, static reservation is shown (a constant value equal to 4) in order to compare both approaches. Real-life consumption should fall inside the light gray band for this static reservation to be adequate. While the  parameter value was set to 0.5, reservation values were scaled to integer numbers (0.5 
 2, 1.5 
 3, etc.).


Table 2.  metric calculated for daily prediction.

 metric	Daily prediction	Static reservation
Sum	0.33	3.27
Average	0.024	0.23
Maximum	0.21	0.56
Minimum	0	0
Median	0	0.23
As in the previous experiment, the sum of the  (for ) metric value was calculated for the best model (hourly prediction; parameters: , , ) and presented in Table 3. Fig. 4 shows the calculated metric, including the estimated lower and upper reservation limits along with actual consumption. For comparison, static reservation was used, which met maximum requirements in the time window examined (starting on day 137 and ending on day 150 of the daily experimental data set). The sum was 8.81, the maximum was 0.47, the average was 0.026 and the median was 0, which means that during the period in question, most predictions were accurate. However, there are still several cases where demand was under- or over-estimated by less than half of a single VM’s resources (the black line falling outside the dark gray band). The results are much better than for static reservation. However, short-term reservation could be improved.

In the second stage of the experiments, in order to improve prediction results, historical consumption of a given resource in a time window was added to the existing attributes derived from time metadata for the last  days or hours (depending on the model). The resulting models were meant for short-term reservations as they required recent usage data. The models were trained and evaluated on the same sets as in the previous experiments.


Table 3.  metric calculated for hourly prediction.

 metric	Hourly prediction	Static reservation
Sum	8.81	289.97
Average	0.026	0.86
Maximum	0.47	1.45
Minimum	0	0
Median	0	0.93
Fig. 5 shows minimum and maximum reservation values for daily prediction (taking into account historical data), which are represented by a dark gray band between 2 and 3, and static reservation with a constant value equal to 4. Likewise, Fig. 6 shows these values for hourly prediction (taking into account historical data). It can be observed than when compared to Fig. 4, which presents a model that does not account for consumption from previous hours, reservation boundaries better reflect the actual value (the black line representing actual resource consumption falls inside the dark gray band).


Download : Download high-res image (451KB)
Download : Download full-size image
Fig. 4. Estimated reservation values along with actual consumption; hourly prediction.

Table 4, Table 5, respectively, present  metric values for the best models of daily (parameters: , , ) and hourly (parameters: , , ) prediction using historical data for a two-week test period (daily — between day 137 and 150 of the daily experiment data set; hourly — between hour 3237 and 3260 of the hourly experiment data set). For the daily model (), 
 values (formula (5)) consisted of resource usage values for the 3 previous days; for the hourly model (),  consisted of resource usage values for the 6 previous hours.


Download : Download high-res image (138KB)
Download : Download full-size image
Fig. 5. Estimated reservation values vs. actual consumption; daily prediction (taking into account historical data).

The tables also include a comparison for models without historical data and static reservation.

While for daily prediction only a slight improvement can be observed as compared to the model without historical data, the improvement for hourly prediction is more than twofold — the average error value is around half that for the model without historical data, while the value of the  metric is eight times smaller. Additionally, it can be seen that even a small number of additional attributes enables the result to be improved. However, we observed that for time-window lengths  greater than 6 (in our case — 12 and 24) there was no improvement in prediction.


Table 4.  metric calculated for daily prediction (with historical consumption).

 metric	Daily prediction using historical consumption	Daily prediction	Static reservation
Sum	0.27	0.33	3.27
Average	0.019	0.024	0.23
Maximum	0.21	0.21	0.56
Minimum	0	0	0
Median	0	0	0.23
As part of the experiments conducted, the quality of expected resource reservation over the period examined was also checked. The idea was to simulate a real-world scenario in which training data is collected while the ARPS system is in use and the models can be periodically retrained. For this purpose, a set of trained ML models (based on the best hourly prediction model, using historical consumption from the previous six hours and parameters — a learning rate equal to 0.001, momentum equal to 0.2 and hidden layer size equal to 6) was prepared; the training was based on data collected at 7 days’ intervals. Each subsequent set contained data from all the preceding sets and data from the next 7 days. Next, the average for the  () metric was calculated from prediction results for the selected 24 h (starting at hour 4005 and ending at hour 4028 of the hourly experiment data set; identical for all models, but not used to teach these models). The model was trained every 7th day with the use of increasing amounts of data, which translated into better quality of predictions and thus better matching of reservation limits.


Table 5.  metric calculated for hourly prediction (with historical consumption).

 metric	Hourly prediction using historical consumption	Hourly prediction	Static reservation
Sum	1.57	8.81	289.97
Average	0.0047	0.026	0.86
Maximum	0.12	0.47	1.45
Minimum	0	0	0
Median	0	0	0.93
For the parameters used, the quality of the reservation ( metric) for the examined set of data improved (Table 6) together with the number of days taken into account when training the model (i.e. the value of the  metric decreased by 0.0438 in 4 months). The average value of the reservation error  in the later period was lower (at the level of approx. 0.01) than the assumed reservation size step 0.5 of the processor (parameter ).


Download : Download high-res image (465KB)
Download : Download full-size image
Fig. 6. Estimated reservation values vs. actual consumption; hourly prediction (taking into account historical data).


Table 6. Average quality of anticipated reservation over a 24-h period.

Days	Average  metric
7	0.0483
28	0.0087
49	0.0083
91	0.0075
112	0.0045
140	0.0045
4.4. Summary
In our solution, we propose the metric , which represents the size of under- and over-provisioned resources. The evaluation shows that hourly prediction is 33 times better than static reservation (  0.026 vs.   0.86). Extending the input by adding historical consumption values yields even better results:   0.0047 (183 times better). The evaluation of hourly prediction while increasing training data size demonstrates that  improves up to a certain point, after which it plateaus (from   0.0483 for 7 days to   0.0045 for 112 days and upwards).

There are few other solutions which deal with a similar problem. One of the most important among them is [16] where the author discusses cloud resource scaling and compares his own solution to two other methods in terms of running virtual machines. As our solution is similar, we would like to compare our results further. Both papers describe solutions related to cloud resource scaling but focus on different aspects of this topic. The problem is that the approaches are different both in their scope and in the extent to which the evaluation undertaken is comprehensive, which hinders precise comparisons.

In our work, we compare the quality of the solution  to static reservation. In [16], no similar solution quality metrics are defined and there is no comparison to a system working without scaling, and only partial comparison to the results achieved by other scaling algorithms. The learning process is different as well. In our solution, the system is periodically retrained online, using increasing amounts of training data. As a result, it adapts to the conditions, while in [16] the models are trained offline before the system is launched. Moreover, only CPU usage counts in terms of predicted resources, while in our solution we use RAM and incoming/outgoing network data apart from the CPU. Additionally, the author of [16] did not provide a complete solution which could be implemented in a real-life environment, while we describe an entire ARPS system which has been implemented. Our evaluation is conducted in a real-life environment using the OpenStack and Open Baton solutions instead of a CloudSim simulator as in [16].

Another difference is that in [16], load data are developed artificially by using just one anomalous instance multiple times, which does not appear entirely realistic. We consider a combination of different data representing unusual demand or real-life test data with usage anomalies (which we used in our study) to be a better approach, and therefore our solution has been tested on real-life traffic data.

Finally, the solution proposed in [16] corresponds to a short-term model with an empty context 
. Our solution makes it possible to take into account periodic changes related to weekends, vacations etc. We have also proposed a novel long-term model based exclusively on 
 values which allows reservations to be made a day or more ahead.

5. Conclusion
The study conducted by the authors demonstrates the considerable utility of machine learning methods for planning cloud resource reservation for services. The proposed models using MLP yielded good prediction results, in particular in the case of the hourly short-term prediction model using consumption information from preceding hours. The long-term model yielded worse results but it did not use current resource usage data. Its advantage is that it makes it possible to generate long-term plans with sufficient accuracy and may enable resource shortfalls to be discovered in advance.

There are several issues that can be investigated in future research. During our work the problem of the actual maximum processor load not being fully covered has sometimes been observed, which may result in, for example, slower service performance. This problem could be solved by the appropriate selection of the  coefficient (which would result in increased distance between the anticipated consumption boundaries and at the same time affect the overall size of the reservation), increasing the amount of data used to teach the model or searching for a model that provides more accurate results. Anomaly detection methods can also be used, allowing for filtering of boundary values while improving the quality of predictions for standard cases. For boundary values, a separate model could be developed (as in [16]) whose main task would consist in short-term prediction of sudden spikes in resource consumption (larger than those covered by the current reservation). Additionally, to solve this problem one can reserve more resources than predicted by applying a simple rule that the maximum amount of reserved resources is always sufficient for  service instances where  is a number based on the resource consumption prediction model. This would enable the handling of increased system load at the upper limit of the reservation value.

Despite the problems mentioned, the proposed solution offers valuable information both to the customer who provides the services in question and to the cloud computing provider. It enables better planning and utilization of available infrastructure and sets certain limits on the cost of renting part of this infrastructure.

CRediT authorship contribution statement
Piotr Nawrocki: Supervision, Conceptualization, Methodology, Writing - review & editing. Mikolaj Grzywacz: Software, Investigation, Writing - original draft. Bartlomiej Sniezynski: Methodology, Formal analysis, Writing - review & editing.