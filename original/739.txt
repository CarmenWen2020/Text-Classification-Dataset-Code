General/local reachability properties are in NL/NC1 if the input length is n.


Abstract
Reachability in parallel finite-state programs equipped with interleaving semantics is an inherently difficult, important problem. Its complexity in the number of threads n, while keeping the thread-local–memory size and the shared-memory size bounded by constants, has been explored only poorly. We significantly narrow this gap by measuring: (i) the diameter, i.e., the longest finite distance realizable in the transition graph of the program, (ii) the local diameter, i.e., the maximum finite distance from any program state to any thread-local state, and (iii) the computational complexity of finding bugs. We prove that all these are majorized by polynomials in n and, in certain cases, by linear, logarithmic, or even constant functions in n; we make the bounds explicit whenever possible. Our results shed new light on the widely expressed claim that one of the major obstacles to analyzing parallel programs is the exponential state explosion in the number of threads.

Keywords
Multithreading
Transition graph
Diameter
Interleaving
State-space explosion

0. Introduction
Since 2004, the CPU-clock limit has been stagnating, which has immensely increased the demand for multithreading [80]. Conceptually, a multithreaded program consists of a batch of threads running in parallel; each thread can access only its private memory and the memory shared among the threads. The semantics of accessing the shared memory can be cumbersome [65], [74]; to simplify writing and analyzing multithreaded code, the code is typically written in such a way that every execution on a parallel machine can be viewed as an execution on a sequential machine that interleaves the steps of different threads. Even given this simplified framework, programming errors are widespread [40], [82], and the effects of failures can be devastating [5], [51], [68], [69]. In practice, almost every such failure can be viewed as a violation of a so-called safety property, which is, informally speaking, a property of the form “nothing bad happens in all executions.”

We focus on the most basic safety properties of the form “a program state is not reachable from another program state”; any safety property can be reduced to such a state-to-state unreachability property [63]. Deciding such properties of programs in practice often incurs the infamous state-explosion problem, which is the phenomenon whereby the number of program states grows exponentially with the number of threads (hereinafter n) of the program analyzed [7], [18], [32], [36], [37], [71]. It is a practical “problem” because the program analyzer often runs out of resources while reasoning about these states and, much to a user's disappointment, fails to deliver a conclusive answer. In fact, reachability in finite-state multithreaded programs equipped with interleaving semantics is PSpace-complete (cf. § II.3). Since PSpace is a very robust class [76, § 8.2 and Exercise 8.4] containing a wealth of complete decision problems [41], [86], the PSpace-completeness characterization is rather unenlightening. It does not reveal too many details about the exponential blow-up with respect to n from a theoretical viewpoint (and the strictness of the inclusion  is only a conjecture so far anyway).

To study the state-explosion phenomenon, we consider a parametrized setting with a variable number of threads n and two constant parameters: the size of the local memory per thread and the size of shared memory. In this setting, we ask how the following quantities asymptotically grow with n: the diameter and the local diameter (both of which we define later) and the complexity of two natural reachability problems. At the core of our work is the informal question of whether the growth is fast (as suggested by the aforementioned PSpace complexity and by the state explosion occurring in the tools) or slow (sometimes occurring in the parametrized-complexity field).

As we will show, the second case holds. For reachability tasks that can be formulated in the parametrized setting described, the aforementioned blow-up and high complexity can be asymptotically avoided; we will quantify this statement.

The variable number of threads and the bounded sizes of local memory per thread and of shared memory might be observed in several areas; here, we name three. The first of these areas is high-performance computing; we consider applications in which the threads themselves are fixed in size, whereas what changes is the number of threads executed in parallel when a program is moved from one supercomputer to another (or, to a lesser extent, from one GPU to another) or when a program goes from a test setup to a fully parallel setup. (At the time these lines were written, Web search [33] returned numerous occurrences of “char thread_id;” and “char threadId;” in real-world C code, which allocated 8 bits for the thread identifier. Such pieces of code are likely to be of limited use or even erroneous on a system with more than 256 threads.) The second area is the modeling of memory limitations in dynamic systems. (A typical bug example is a thread-identifier overflow [83]: a server starts a new thread upon a new query from a client while using fixed space for thread identifiers. After the server runs for a sufficiently long time, the thread-identifier variable overflows, wreaking havoc. Modeling dynamic thread creation in a static-threaded finite-state program would have exposed the issue.) The third area is the modeling of Edge Computing, in which parallel computations (e.g., in the cloud) are given to a variable number of small-size computational nodes (for instance, embedded and mobile devices) which access a single server. For the purpose of modeling, the small nodes can be viewed as threads, the server can be viewed as shared memory, and various types of message passing can be replaced with the interleaving shared-memory semantics.

To proceed, let us introduce some terminology. Intuitively, a program state is a valuation of all the variables of the program, including the control-flow counters of all the threads. The distance from a program state s to a program state 
 is the minimal number of program steps needed to reach 
 from s along an execution (or ∞ if 
 is unreachable from s). The diameter of a program is the maximal finite distance present in the program. If a bug finder outputs an error trace of the program analyzed, this trace is, in the worst case, at least as long as the program diameter. So the diameter of a program is a lower bound on the worst-case running-time of a bug finder on this program. At the same time, the diameter is equal to the number of steps that an ideal search (i.e., a search equipped with an oracle for the exact heuristic) would take to travel from a source program state to a target program state if these states are furthest apart but still connected. So the diameter is an upper bound on the running time for a successful, ideal search, in which the bug finder would always choose the right walk. These lower and upper bounds also apply to the searches in program models (and not only in original programs), e.g., models produced by predicate abstraction or in the inner loops of counterexample-guided abstraction refinement (CEGAR) schemes.

We are interested in the worst-case diameter among all the programs with the same number of threads (recall that the sizes of shared and local memory are fixed; to simplify our analysis, we assume that all threads have equally many local states). Thus, we concentrate on the function that, given a natural number n, returns the largest diameter over all programs with n threads. We call this function . To the best of our knowledge, nothing is known about this function yet (except [55], [57], [58]). Certainly,  is majorized by the size of the state space, which is singly exponential in n. In a more general context, the conventional wisdom so far has been that the dependence between the worst-case distances in the transition graph of a (not necessarily multithreaded) program and the number of the components of the program (whether these are variables or threads) is exponential. In place of accepting this informal, conventional piece of wisdom, we prove a (much better) linear lower bound and a polynomial upper bound for multithreaded programs. Further, we demonstrate a stronger, linear upper bound for a certain subclass of programs. Moreover, we prove that, for a rather general class of probability distributions, the diameter of a random program is asymptotically almost surely at most linear. We also show that the program-state–to–program-state (non-)reachability problem belongs to the complexity class .

As the above notion of the (maximal) diameter is based on the program-state–to–program-state distance, this notion targets “nonlocal” properties concerning more than one thread, such as deadlock freedom or mutual exclusion. Still, many interesting nonreachability properties (of, for instance, real operating-system code) are “local,” meaning that they are, simply put, of the following form: “a particular state of a given thread does not occur in any execution” (hereinafter, a state of a thread, shortly, a thread state, stands for a valuation of all the variables that the thread can access directly, including its control-flow counter). Such a property could, e.g., be specified by an assert statement of the programming language C (such a statement can refer to the shared and the thread-own variables). Moreover, program transformations and modeling may turn local properties into nonlocal ones or vice versa, sometimes producing intricate objects, e.g., internal models generated by automatic CEGAR loops.

Therefore, we also consider a related notion, the so-called local diameter. Roughly speaking, the local diameter of a program is the length of the shortest counterexample to any of the worst (i.e., hardest to refute, but still refutable) local safety properties. (A formal definition appears in § II.2.) If a bug finder outputs an error trace to a thread state, this output is, in the worst case, at least as long as the local diameter of the program. So the local diameter of a program is a lower bound on the worst-case time for finding local bugs in that program. At the same time, the local diameter is the number of steps that an ideal search (i.e., a search equipped with an oracle for the exact heuristic) would take to arrive from a source program state at a target thread state of a target thread in the worst case, i.e., maximizing over all triples (source program state, target thread, target thread state). So the local diameter is an upper bound on the running time for the successful, ideal thread-state search in which the bug finder always chooses the fastest walk. Again, these lower and upper bounds also apply to searches for local bugs in program models (and not only in original programs), e.g., the models produced by predicate abstraction or in the inner loops of the CEGAR schemes.

We show that the maximum local diameter for n-threaded programs is bounded above by a value independent of n, and that the least upper bound can be explicitly constructed (meaning, we can actually write, to any level of detail, an algorithm computing the least upper bound). Though it is possible to derive the boundedness through a careful interpretation and extension of results in the literature (cf. § I), explicit computability is not immediate. In contrast to this, we propose a mostly self-contained proof in § IV, parts of which are general enough to be potentially reusable in other contexts. Moreover, we show that the program-state–to–thread-state (non-)reachability problem belongs to the complexity class NC1 [76, Definition 10.38] (again, considering the shared and thread-local memories bounded).

The fact that the lower bound on the diameter asymptotically exceeds the upper bound on the local diameter is, to the best of our knowledge, among the strongest non-algorithmic, asymptotic, formal arguments supporting the conventional wisdom that local safety properties are easier to deal with than nonlocal ones.

Summarizing, our major contributions are as follows:

•
The definitions of the diameter and the local diameter of a multithreaded program (extending [58]).

•
Constructively bounding the maximum local diameter from above for the parametrized case by an explicitly computable value independent of n (Definition and Corollary IV.3.8).

•
Bounding  between a linear and a polynomial function in general (Theorem V.1.3, Theorem V.2.1.22). The polynomial is of lower degree than previously known ones (Note V.2.1.23).

•
A class of programs for which we show a linear upper bound in n on the diameter (Theorem V.2.2.3), and which matches the lower bound in certain cases (Note V.2.2.5).

•
For rather general probability distributions on thread transitions, the diameter of a program is asymptotically almost surely at most linear in n (Theorem V.2.3.2).

•
Deciding whether a program state is reachable from another program state is possible in  (Theorem VI.1).

•
Deciding whether a state of a specified thread is reachable from a program state is possible (assuming that n is the only variable parameter) in NC1 (Theorem VI.2).

The picture would be imperfect without reviewing a contrasting result in our context: (non-)reachability for finite-state interleaving-semantics multithreaded programs is PSpace-complete in the whole input length, i.e., for the unparametrized case, with respect to logspace reductions (Corollary II.3.3).
We conclude by discussing the growth of the  function (§ VII), including the theoretical benefits of its low growth to verification and bug finding.

Limitations
First, it is not the goal of this paper to empirically measure or directly improve contemporary techniques for verification or finding bugs. Rather, the paper contributes to the classification of the asymptotic complexity of search, with and without an oracle for the exact heuristic, in the parametrized setting in which the contribution of the variable number of threads n is singled out. For this purpose, we measure the distances in the transition graphs and use traditional complexity classes. (The classification in the parametrized-complexity class hierarchy is a separate topic by itself and is thus relegated to a later report.) Since we are interested in the dependency on n, the expressions that do not depend on n (“constants,” especially those hidden in the asymptotic notation) are of minor importance here. Still, we sometimes get these constants for free and, as a service to the interested reader, we track or even optimize them if the corresponding proof methods easily permit this. Whether these constants are “optimal enough” (which would depend on the purpose and is often subjective) is not essential for our classification efforts: tooling and practicable techniques are orthogonal to the goals of this paper.

Second, it is not our intention to consider program families created from thread templates for which the sizes of shared and thread-local state spaces depend on parameters such as the number of threads n (e.g., [81]). For thread-template–based families, there is no standard dependency of the sizes of shared and thread-local state spaces on n (depending on the example, the dependency may not exist [60, §§ 7,8] or be anywhere between linear [61, Example 13] and, for instance, 
 [85]). Moreover, some parametrized programs (e.g., Readers-Writers) come with two or more independent variable parameters which together determine n and the sizes of shared and local state spaces. Investigations of such families would necessarily be more family-specific; results obtained for one family may not transfer to others. In contrast, this paper aims to deal with only one variable parameter and generically with the whole class of multithreaded programs rather than with particular families of multithreaded programs.

Third, the main purpose of §§ V.2.2 and V.2.3 is not large applicability areas (though we mention certain application scenarios in the two sections). The main purpose is, rather, a demonstration that the possibility of the existence of an elementary, explicit, and low-degree polynomial, even a linear one, as a general upper bound on  cannot be excluded.

I. Related work
In the narrowest sense, the complexity of deciding reachability in finite-state shared-memory multithreaded programs equipped with interleaving semantics has to the best of our knowledge not yet been determined with a formal proof. The (presumably) closest-related result published with a formal proof is the PSpace-completeness of the emptiness of the intersection of regular languages given by finite automata [46, Lemma 3.2.3]. The author claimed the relevance of the result on regular-language intersection as early as 2006 (cf. [61], [62]) and stated the PSpace-completeness of deciding reachability in multithreaded programs in 2010 (cf. [54]) without proof. Some other researchers mentioned vaguely the same result without proof (we are aware only of later claims, e.g., [11, p. 4]) or related results with proofs (e.g., on LTL for concurrent programs [77]).

As for singling out the contribution of the number of threads n, [53, p. 126] already observed that “symmetrization reduces the growth of [the description of the transition graph] from exponential with respect to [n] to polynomial with respect to [n].” To our knowledge, the polynomial degree has never been determined precisely in general; that is where we step in. In the special case that all the threads of a program execute the same code, it has been observed [9], [10], [25] that the symmetrized program has roughly 
 program states, where L is the number of the local states.

In a wider sense, a concise review of the reachability in parametrized concurrent programs based on only one template is given in [26, § 3.2]. Relaxing the communication model leads us to [17], [78], [79] (for rendezvous communication) or [12] (for token ring) among replicated processes.

Our results on local reachability are grounded in the finite-basis and Petri-net theories [35], [43]. The set of programs can be seen as a single well-structured transition system [2], yielding the decidability of thread-state reachability via a constant bound on the distances to a target state. However, [2] fixes the target state (not the initial state) and is formulated abstractly rather than in terms of shared-memory multithreaded programs equipped with interleaving semantics; therefore, additional work has to be invested in order to prove that the bound does not depend on the state we commence with (whether initial or target; both depend on n themselves), to transfer their results into the local-diameter graph-theoretic terminology for programs, and to prove the explicit computability of the local diameter.

Related practical reachability deciders employ symmetry reductions, which work well if , and counter abstractions of various kinds. Symmetrization is possible, e.g., in the context of plain search [23] or in combination with a CEGAR loop and context inference [34]. Introducing counters is the main way symmetrization is implemented; sometimes the counter is abstracted to reduce the size of the state space [67]. For parametrized programs, cutoff techniques are applied. For example, [24] considers a computation model in which multiple copies of multiple process templates are concurrently executed, the shared state is absent, but each process executes specifically guarded transitions of restricted forms depending on the local state of other processes. Dynamically detecting cutoffs for identical copies of a single thread template starting in a fixed set of initial states is possible [42]; searching in the parallel composition of infinitely many copies can be reduced to searching in the parallel composition of a finite number of copies. The authors of [42] do not generalize their technique to copies of more than one template in their paper but mention that such generalizations are possible. A (non–counterexample-based) abstraction refinement for parametrized multithreaded programs consisting of copies of one thread is described in [3]. Assuming a bounded number of shared and local states as well as thread-local error states, we conjecture that the number of refinements from [3, Theorem 1] and the cutoff from [42] can roughly be bounded from above by the maximum local diameter. Searching in multithreaded programs can also be reduced to Petri nets [88, p. 14].

In general, all practical reachability deciders face the state-space–explosion problem (in the sense that the state space blows up exponentially with the number of threads); they exhaust space or time limits in a tool-dependent way or return an inconclusive answer. (However, on a set of carefully chosen templates, the tools performing symmetrization sometimes achieve exponential reductions.) We see claims such as, “The main obstacle to finite-state verification of concurrent systems is the state explosion problem: the number of states a concurrent system can reach is, in general, exponential in the number of concurrent processes in the system” [75] and “For fundamental reasons, we cannot avoid the exponential explosion in the number of threads” [29] spread throughout research-level texts. Such claims, taken literally, lead to asking whether the variable number of threads is in the exponent of a mathematical expression related to the computational difficulty of a reachability problem, rather than to the running time of a particular tool or to the size of a particular representation of the state space. This question is resolved in this paper in the negative, thereby positively resolving Open Problem 1.12.3 in [54]. We also show that several other straightforward mathematical formulations of the above quotations are all embarrassingly wrong: in these formulations, n is never in the exponent of the expressions obtained.

We mention five works which are closest to this paper. The first of these is [58], which handles most topics of the present paper for the special case of binary programs (a binary program is a program with two shared states and two local states). The present paper eliminates the restriction to binary programs, considering all finite-state multithreaded programs equipped with interleaving semantics. Further, all results in this paper, when restricted to the binary case, are at least as strong as, or stronger than, those of [58]. The second work is [59], which is [58] with all proofs. Being a generalization, our paper intentionally follows [58], [59] concerning the structure, terminology, and certain examples and claims. The reader might find similar formulations which are, unless otherwise stated, to be interpreted here in the parametrized context rather than in the binary one.

The third work, [55], is the conference version of this very paper and its direct precursor. The present paper enhances and sharpens [55]:

•
This paper contains most low-level details and background material, whereas [55] contains a high-level, abridged presentation.

•
We prove the PSpace-completeness of reachability in the unparametrized case w.r.t. the logspace reductions in Corollary II.3.3, whereas [55] only refers to [46, Lemma 3.2.3].

•
We tighten the upper bound on  in Theorem V.2.1.22 by improving the degree by the factor of L compared to [55, Theorem IV.2.1.10] (Theorem IV.2.1.13 in the technical report accompanying [55]).

•
We strengthen the upper bound on the diameter of programs from the special class in § V.2.2 compared to [55, § IV.2.2].

•
We slightly extend the probabilistic analysis in § V.2.3 compared to [55, § IV.2.3].

The fourth work is an ongoing experiment [57] which motivates the research presented.
Due to space constraints, this paper contains proof ideas; the proof details are in the fifth work [56].

Broadly speaking, our solutions have been partially inspired and influenced by the insights from symmetry reduction [25], process replication [78], finite-base arguments [35], vector addition systems and Petri nets [50], counter abstraction [67], low-complexity arguments in case the shared memory cannot read-and-write as a single atomic operation [27], pattern-based verification [28], linear interfaces [47], and other research directions [6], [13], [14], [21], [22], [66].

Outside formal methods, the diameter is sometimes defined as the maximal distance, being infinity for not strongly-connected graphs [84], whereas we consider the maximal finite distance, since the transition graphs need not be strongly connected. Defined more widely, the notion of graph diameter is important in, e.g., [4] (standard algorithms on graphs), [15] (an old survey on diameter-related problems mostly for undirected graphs), [16] (spectral graph theory, restricted to strongly connected graphs), [19] (strongly connected Eulerian directed graphs without 2-cycles), [49] (networks), [1], [39] (centrality computation), and [20] (the best-case performance of the simplex method in linear programming).

II. Preliminaries
We now introduce the formal notation used throughout the paper.

II.1. General conventions
As an aid for the reader, we sometimes put an exclamation mark above the relation sign of a claim that yet has to be proven. For instance, 
 means: we claim  and proceed to prove it.

In a Boolean formula, the underscore _ denotes an innermost existentially quantified anonymous variable; different underscores correspond to different variables.

We write 
 for the set of positive integers, 
 for the set of nonnegative integers,  for the set of rationals, and 
 for the set of nonnegative rationals. Unless otherwise stated, the implicit universe of variables is 
. To simplify the notation, we view natural numbers as ordinals, so

Image 1
. (We thus escape additional notation for the set of thread identifiers such as Tid often seen in the literature [30]: Tid gets unnecessary, since the number of threads n can be viewed as the set of thread identifiers . Moreover, formulas such as “
Image 2
” are simpler than “
Image 3
.”)
Our map-constructor is right-associative, meaning that  (where X, Y, and Z are variables representing arbitrary sets) is read as , which is the set of functions mapping each element of X to some function from . Maps are sometimes written in λ-notation [8]. We write  for the set of partial maps from X to Y,  for the set of injective (in other terminology, one-to-one) maps from X to Y,  for the set of surjective (in other terminology, onto) maps from X to Y, and

Image 4
for the set of bijections (in other terminology, one-to-one correspondences) from X to Y. The inverse of a bijection f is written as 
.
Given a partial map , we write for the domain and image of f, respectively.

For finite functions mapping to some set of numbers (naturals, rationals, …), 
 denotes the 1-norm and 
 the maximum norm: 
 and 
, where 
.

For a sequence σ with an index set I and , we mostly use the right subscript or the right superscript in square brackets to write the ith element as 
 or 
; the whole sequence is written as 
 or 
, respectively. If the index set is some initial segment of natural numbers, we may write  or  instead of  or  in the right subscript position of the closing paren; the version with the weak inequality “⩽” additionally implies the nonemptiness of σ. The context determines which notation is most convenient.

For an ordinal n and a set X, the set of n-tuples over X is denoted by 
, which is simply another expression for . Thus we maintain the convention that the indexes of the components of a tuple start with 0.

By a slight abuse of notation, a plain number in the right superscript position of a symbol denotes the power of that symbol (where the multiplication operation is understood from the context), e.g., 
 or 
.

For a set X, we write 
 for the identity relation on X.

Given binary relations  and , we write  to denote the right composition “g after f,” which is the relation “Right” refers to the fact that the right symbol is applied first.

If → is a binary relation, we write 
⁎
 for its reflexive-transitive closure (on a set taken from the context).

A preorder on a set X is a binary relation ≲ on X such that ≲ is reflexive on X and transitive. A preordered set is a pair  of a set X and a preorder ≲ on X. A function  on a preordered set  is antitone iff .

Given an equivalence relation ∼ on a set X, we write

Image 7
for the set of equivalence classes. The index of an equivalence relation is the number of the equivalence classes.
The term  denotes the logarithm of x in base 2.

II.2. Program notation
For 
, an (n-threaded) program is a tuple(1)
 such that  and  are finite nonempty sets and
(Adapted from [31].) Such a program is called binary iff . Elements of  are called shared states (also called global states), elements of  local states, elements of

Image 8
thread states, elements of
Image 9
thread transitions. A program state is an element of
 For , we call g its shared part and 
 its ith local part (
Image 10
). The transition graph induced by p is a directed graph  wherefor all 
. A walk in the graph is a sequence 
 of states connected by program transitions, i.e., such that 
 for all i with ; a path is an injective walk, i.e., a walk 
 satisfying
Image 12
(adapted from [49], [84]). The length of a nonempty walk is the number of times the walk takes an edge of the transition graph:
 where “⩽” in the subscript imposes an implicit requirement that the walk is nonempty, containing 
. The distance from a program state s to a program state 
 in the transition graph is the length of a shortest walk from s to 
 (or infinity, if 
 is unreachable from s): where 
. The local distance from a program state s to a thread state  of a thread i in the transition graph is the length of the shortest walk from s to a program state with local part a of thread i and shared part g (or infinity, if no such walk exists):where again 
.
From now on, if the program referred to in the above definitions is unclear from the context, we add a right subscript to specify the program; e.g., 
 is the distance in program p, and 
 is the local distance in program p.

II.3. PSpace-completeness of (unparametrized) reachability w.r.t. logspace reductions
Now we are going to show that reachability of program states and thread states in a multithreaded program (in the full, unparametrized case) is PSpace-complete with respect to logspace reductions.

(For the sake of clarity: no proofs of the PSpace-completeness of the above problems have been published so far to the best of our knowledge, but similar results have become folklore (cf. § I) at least as far as the schoolbook definition of PSpace-completeness via polynomial-time reductions (cf. [38, § 11] and [76, § 8.3]) is concerned. Therefore, § II.3 is merely provided for purpose of the logical consistency of the paper as a service to the reader, rather than as our outstanding contribution, and may be skipped without ill effects on first reading.)

Though one way to prove this would be to reuse [46, Lemma 3.2.3], we do not do this, since Kozen leaves checking that the reduction is logspace to the reader, and further, reusing Kozen's result would provide no significant savings.

For the purpose of defining the aforementioned reachability problems as formal languages and for the sake of simplicity, we make, without loss of generality, the following pretty ordinary assumptions within this section:

•
In a program, the set of shared states is a subset of 
.

•
In a program, the set of local states is a subset of 
.

•
A natural number is encoded in binary.

•
A finite set of items (e.g., a thread transition relation) is stored as a list of items (in some order) between the braces { and }.

•
The separator inside a list of items is the usual comma ,.

•
A tuple is stored as a list between parens ().

In particular, we let the alphabet Σ contain 0, 1, a comma, a left paren, a right paren, a left brace, and a right brace. We expect that minor variations (e.g., making the shared states and local states tuples of numbers instead of numbers) would not change the complexity result.
Let

First, we present an upper bound:

Lemma II.3.1

.

Proof idea

For  and 
, perform a nondeterministic search in the transition graph. For  and 
, apply Savitch's procedure [72]. ■

Now we present a lower bound:

Lemma II.3.2

, ,

Image 16
, and 
 are PSpace-hard with respect to logspace reductions.
Proof idea

For  and 
, let each thread “simulate” a unique cell of the semi-open Turing tape. For  and 
, use . ■

We combine Lemma II.3.1, Lemma II.3.2:

Corollary II.3.3

, ,

Image 16
, and 
 are PSpace-complete with respect to logspace reductions. □
Since every logarithmic-space reduction is a polynomial-time reduction, this result implies PSpace-completeness with respect to the (slightly more schoolbook) polynomial-time reductions.
II.4. Diameter and local diameter
The diameter of a program is the largest finite distance realizable in the transition graph:
 The local diameter of a program is the largest finite local distance realizable in the program's transition graph:

Since we are interested in the dependency of the measured quantities on n, we fix , , 
, and 
 for the rest of the paper, unless explicitly stated otherwise. We thus write programs such as p in (1) more shortly as
 The maximal possible diameter for an n-threaded program is denoted by The maximal possible local diameter for an n-threaded program is denoted by

We say that a program ↝
 is a subprogram of a program 
 if there is an injective map  such that

Image 19
; every such map is called an embedding of h into p.
Lemma II.4.1

The subprogram relation is a preorder on the set of programs.

III. Examples
Before turning to the main results of this paper, we present some small examples (mostly taken from [58]). For simplicity, we show a few binary n-threaded programs whose diameter is  for .

We therefore give some names to the shared and local states, e.g., αβ and , where

Image 20
are some literals. For brevity in the binary case, we sometimes omit commas and parens when writing thread or program states: we occasionally typeset thread states
Image 21
as gl and program states
Image 22
as strings 
.
The (local) diameters of following examples are all computed directly from the definitions; double-checking the numbers is an exercise for the reader.

III.1. 
Consider the program with exactly one thread and transitions α
α, α
β, and β
β. The diameter and the local diameter of this program are both 3. The transition graph of the program is depicted below right.


Since the total number of program states is 4, no single-threaded program can have a diameter larger than 3. In total, there are six programs that have diameter 3 and exactly three transitions and whose diameter-realizing paths start in α0.	
Image 23
III.2. 
Now we depict some two-threaded programs of maximal diameter.

In the following tables, we omit the index at the arrows in thread transitions. In each transition graph, solid arrows constitute a shortest path from α00 to a state at the largest distance, dashed arrows are program transitions that do not contribute to the path, and dotted gray lines simply help to visualize the set of states as a geometric cube.

A program with a total of 5 thread transitions is depicted below.



Download : Download high-res image (89KB)
Download : Download full-size image
It has diameter αβ, and, since the total number of states in any two-threaded program is 8, no two-threaded program can have a larger diameter. Omitting any thread transition would yield a program with a lower diameter. Adding copies of existing threads does not, in general, produce programs with a maximal diameter: 
 and 
, which, as we will see, are less than the lower bound from Theorem V.1.3. The local diameter is 
αβ. Note that for each thread every thread state occurs twice as part of some program states (e.g., the thread state α1 of thread 1 occurs in α01 and α11). Thus, for any source program state, the two occurrences cannot both have distance 7 from this source: if any of these occurrences is reachable from the source, at least one of these occurrences must have distance not exceeding 6. Thus, no two-threaded program can have a local diameter exceeding 6.

Adding thread transitions or copies of existing threads may change the diameter, but this is not always the case.

Let us consider some cases:

In N2T6A, adding α
β shrinks the diameter. Instead, adding any combination of the thread transitions α
α, β
α, and β
α does not change the diameter. We have 
 and 
. The local diameter is 
αβ.

The transition graph of N2T6B is strongly connected. Adding any combination of the thread transitions

Image 25
,
Image 26
,
Image 27
, and
Image 28
would not change the diameter, but adding
Image 29
would shrink it. Duplicating the threads slightly increases the diameter: 
 and 
. The local diameter is 
αβ.
In N2T6C, adding any combination of the transitions

Image 26
,
Image 30
, and
Image 27
would shrink the diameter. Adding the thread transition
Image 25
would not change the diameter. We have 
, 
, and 
. The local diameter is 
αβ.
The transition graph of N2T7B is strongly connected. Three paths realize distance 7:

Image 31
(denoted by thick arrows),
Image 32
, and
Image 33
. Adding any combination of
Image 34
,
Image 35
, and
Image 36
would retain the diameter 7, but the only path realizing the longest distance would be
Image 32
. Instead, adding
Image 37
would keep all three paths realizing the longest distance. Thread duplication increases the diameter in some cases: 
 and 
. The local diameter is 
αβ.
III.3. 
This program has local diameter 
αα and diameter αβ. The transition graph is strongly connected. Adding a copy of each thread would shrink the diameter: 
. It can be shown (cf. [59, Theorem 6.2.1.1] or [58, Theorem 5.1.1]) that N3T9 has the maximal diameter among all three-threaded binary programs.

IV. Local diameter
In this section we prove that the local diameter is bounded above by a constant independent of the number of threads, and that the least upper bound is computable by an explicit algorithm. Informally, this means that the shortest counterexamples to violated local safety properties are short, and, given enough computational resources, we can even say how short. In theory, a constant bound is far better than the trivial bound 
 for all 
.

(This section represents a strengthening and generalization of the corresponding result from [58].)

From an intuitive standpoint, the proof relies on the observation that the local-distance function is antitone in the program argument (i.e., roughly speaking, adding threads to a program reduces the local distances), as well as on any of the known coverability procedures for Petri nets.

We start with well-known order-theoretic background, continue with new order-theoretic results, and finally apply what we learned to programs.

IV.1. Preliminaries from general order theory
Informally, an antichain is a preorder in which no elements are comparable. More formally, given a preordered set , a subset  is called an antichain iff

Image 38
.
Given an arbitrary set I and arbitrary posets 
 for , the componentwise partial order on the product 
 is given by

We call a map  between preordered sets 
 and 

•
an order-homomorphism iff

Image 40
and
•
an order-epimorphism iff φ is a surjective order-homomorphism.

The following popular result is essential for the whole section:

Proposition IV.1.1 Dickson's Lemma

Let 
. Let the set 
 of m-tuples of natural numbers be equipped with componentwise partial order over the standard order on natural numbers. Then every antichain in 
 is finite.

IV.2. Well-foundedness and antitone maps
We recall that a partial order ⪯ on a set X is well-founded iff each nonempty subset of X has a minimal element, i.e.,

Image 41
.
The following fact is also well known:

Proposition IV.2.1

For each 
, the componentwise partial order on 
 is well-founded.

We combine this fact with Proposition IV.1.1:

Lemma IV.2.2

Let 
 be equipped with the standard order on natural numbers. Let 
, the set 
 be equipped with componentwise partial order, and 
 be an antitone partial map. Then:

a)
 is finite.

b)
Assume that explicit algorithms solving the following problems exist:

1)
Decide, given a tuple of pairs

Image 42
, whether some  exists satisfying
Image 43
.
2)
Evaluate f at a point of its domain.

Then there is an explicit algorithm determining whether  is empty or not, and, in case of nonemptiness, computing .
Proof idea

In the interesting case that , consider the antichain of minimal elements of  and let M be the maximal value of f on this antichain. All the values of f are bounded by M from above; there are finitely many such values. As for computability, construct any antichain in  first, and then enumerate the tuples below that antichain. ■

IV.3. Application of order theory to programs
In the following, let  be the set of all programs, equipped with the subprogram preorder (cf. Lemma II.4.1).

Lemma IV.3.1

There is some

Image 44
and some order-epimorphism 
, where the codomain is equipped with the componentwise partial order.
(Since k is an ordinal, the above notation
Image 45
means, set-theoretically, simply  
 
 
 , a vector of k copies of a.)
Proof idea

Let 
 be the number of different thread transition relations. We choose some enumeration 
 of these relations. Let φ map a program 
 to 
. ■

Moreover, all order-epimorphisms as in Lemma IV.3.1 are of the same form:

Lemma IV.3.2

Let 
 be an order-epimorphism, where the codomain is equipped with the componentwise partial order. Then 
, and there is an enumeration 
 of thread transition relations such that 
 for all programs 
. Moreover, φ is computable, and the preimage of each vector under φ is finite and computable.

Proof idea

Induction on the number of threads. ■

(As an aside, notice that Lemma IV.3.2 says that the order-epimorphisms from  onto the set of non–all-zeros tuples of natural numbers of the same dimension are the same up to permuting the components. This is slightly more general than needed by the following proofs. We added the above characterization to show that it might be difficult to work out a real-world implementation of the algorithm of this section by reducing the dimension.)

The above preparations imply:

Theorem IV.3.3

Let 
 be an antitone partial map. Then:

a)
 is finite

b)
Assume that there are explicit algorithms solving the following problems:

•
Membership of a given program in .

•
Decide, given functions

Image 46
and
Image 47
, whether some
Image 48
exists satisfying
Image 49
.
•
Evaluate f at a point of .

Then there is an explicit algorithm determining whether  is empty or not, and, in the case of nonemptiness, computing .
Proof idea

Consider φ from Lemma IV.3.1, Lemma IV.3.2. Let . The map 
,  for any 
 is well defined. Its image is finite due to Lemma IV.2.2a) and equal to . Apply Lemma IV.2.2b) to g. ■

In the following, states of a particular form play an important role. We call a program state

Image 50
of any n-threaded program uniform if all components of l are the same, i.e.,
Image 51
.
Now we instantiate a particular antitone map in Theorem IV.3.3:

Lemma IV.3.4

For all 
, 
, and ↝
, there is some 
 satisfying the following property: for all 
, all n-threaded programs 
, and all , if 
↝ and 
, then 
. Moreover, the function mapping a tuple 
↝
 to the smallest c satisfying the above property possesses an explicit algorithm.

Proof idea

Fix arbitrary 
, 
, and ↝
. Define 
 with domain

Image 52
such that f maps a program 
 from that domain to 
↝
. Apply Theorem IV.3.3 to f using a coverability procedure for Petri nets simulating multithreaded programs. ■
Since there are only finitely many shared states, local states, and thread transition relations, a maximal c from Lemma IV.3.4 can be computed:

Corollary IV.3.5

There is some 
 such that, for all 
, 
, 
, all n-threaded programs p, and all , if 
, then 
. Moreover, there is an explicit algorithm constructing the smallest such c.

Proof idea

Take the maximum of the pointwise smallest function from Lemma IV.3.4. ■

In Corollary IV.3.5, the source program state is uniform. Before we remove this restriction, we argue that local distances stay invariant under renaming of local states. More formally:

Lemma IV.3.6

Let 
 be a program. For each  let 
 be a permutation of . Moreover, for each  let a thread transition relation

Image 53
be defined via↝
 for all 
 and 
; let ↝
.
Then, for all 
,

Image 54
,
Image 55
, and
Image 56
, we have
Proof idea

Show the equality by proving “⩽” and “⩾” separately. To prove any of the inequalities, consider the interesting case of finite 
 on the “greater-equal” side. ■

Applying the above result, we obtain:

Theorem IV.3.7

There is some 
 such that

Image 57
. Moreover, the smallest such c can be constructed by an explicit algorithm.
Proof idea

Take c from Corollary IV.3.5. Handle arbitrary source states using Lemma IV.3.6. ■

Due to Theorem IV.3.7, the maximal local diameter for programs can be determined:

Definition and Corollary IV.3.8

Image 58
exists and is computable by an explicit algorithm. □
The top level of computing  is “compute ” as Algorithm 1 demonstrates, where 
 is taken from the proof of Corollary IV.3.5. The function ζ is the pointwise smallest function such that, for all 
, 
, and

Image 59
, we have: for all
Image 60
, all n-threaded programs 
, and all
Image 61
, if 
↝ and 
, then 
↝.
Algorithm 1
Download : Download high-res image (13KB)
Download : Download full-size image
Algorithm 1. Computing the maximal local diameter .

Following the involved lemmas, this algorithm can be written out to any level of detail.

Although this paper does not aim to determine the numerical values of  given numerical values of G and L, three remarks are to be made. First, “explicit” means that our algorithm computing  can be easily converted to a runnable implementation in some real-world programming language (although actually obtaining the numerical representation of  in acceptable time would require more effort); this is strictly better than a pure computability claim (in which case we would know that an algorithm exists but might not know what it is). Second, a general lower bound on  is : we obtain it by considering a single-threaded program whose transition relation is 
. Third, a further lower bound stems from the example N3T9 in § III.3: from 
 we obtain that for  we have .

V. Diameter
Now we provide a lower and an upper bound on , an upper bound on the diameter of programs from a particular class, and an upper bound on the diameter of a randomly chosen program.

V.1. A lower bound on 
Within this section, without loss of generality, let the elements of  be  and the elements of  be .

We start with a few special cases.

Lemma V.1.1

If

Image 62
, then
Image 63
for all
Image 64
.
Proof idea

To show ⩽, note that the transitions taken by different threads can be reordered. To show ⩾, consider the program

Image 65
. ■
Lemma V.1.2

If

Image 66
, then
Image 67
for all 
.
Proof idea

To show ⩽, note that . To show ⩾, consider the program 
 where 
 and 
 for . ■

Theorem V.1.3

 for all 
.

Proof idea

For  consider the following n-threaded program. Let the transitions of thread 0 be

Image 68
. Let the transitions of each thread
Image 69
be
Image 70
. Then
Image 71
. ■
Using Knuth's Big-Omega notation [45], we obtain: .

The proof of Theorem V.1.3 cannot be strengthened by better counting using the same program family:

Notea V.1.4

The above proof computed a certain distance between two program states of a particular n-threaded program (). These states are the unique source and sink of the acyclic transition graph of the program, which is, informally speaking, the breadth-first search tree of itself rooted at the source, with each edge going exactly one level down, and with the sink in the last level. There is no larger finite distance in such a graph. □

Of course,  is only a lower bound and in general not the exact value of the  function. We already saw in § III.2 examples, such as N2T6B or N2T7A, of diameter  for . Duplicating existing threads in these examples did not raise the diameter above the lower bound. As we will see in Corollary V.2.2.4, adding arbitrarily many arbitrary threads to these examples would not raise the bound beyond  anyway. A few more exceptions, i.e., n-threaded programs (for small n; in the binary case, for ) for which the diameter exceeds the lower bound, are known. No such exception is known to have generalizations for infinitely many n that could asymptotically improve Theorem V.1.3. Further, on a set of over 
 n-threaded binary programs with , no deviations from the lower bound have been observed [57].

V.2. Upper bounds
V.2.1. An upper bound on 
We are going to show that  is asymptotically majorized by a polynomial function.

We start the proof by fixing an arbitrary program 
 and an arbitrary state  of this program until (but not including) Proposition V.2.1.21. We are going to prove that 
 for all

Image 72
, where
Image 73
, and neither c nor the constant hidden in the -notation depend on g, l, s, n, or the program. From a high-level view, our proof will exploit symmetries between the threads.
As a first step, we “confuse” thread indexes if the local parts corresponding to these thread indexes in the initial state are equal and the threads' transition relations are equal up to self-loops. Formally:

Definition V.2.1.1

Consider the diagonal 
. Fix for each  a permutation

Image 74
such that 
. (For example, for each
Image 61
choose the transposition we call such a choice standard.) Let the 
 normalized thread transition relation be for each
Image 61
. Thread identifiers  are called confusable, written
Image 77
, iff ↝
↝
. □
Next, we define which program states should be considered indistinguishable for our purposes: such states result from each other by re-indexing threads with confusable identifiers, provided that the local parts corresponding to these thread identifiers match properly. Formally:

Definition V.2.1.2

A map  is called confusion-invariant, or shortly ∼-invariant, iff

Image 78
. Vectors of local states 
 of dimension n are called confusable, written 
, iff there is a ∼-invariant
Image 79
such that
Image 80
. Program states 
 are called confusable, written 
, iff 
. □
Intuitively speaking, φ in the above definition re-indexes threads with confusable identifiers provided the corresponding local parts match properly.

Example V.2.1.3

Consider the binary case αβ and  and a two-threaded program ααααααββ. Let the initial state be α. Choose 
 and

Image 81
. Then ↝
αα and ↝
αα. So
Image 82
and
Image 83
. The transposition
Image 84
, which swaps the indexes of the threads, is ∼-invariant. Let 
β and 
β. From 
 and 
 we get 
. As 
, the program states 
 and 
 are confusable. Here, ≈ is not a classic bisimulation [7, Definition 7.1]: 
 has a successor program state (namely, itself), whereas 
 has no successors. □
We obtain the ∼-invariance of certain maps easily:

Lemma V.2.1.4

Image 85
is ∼-invariant.
Lemma V.2.1.5

If

Image 86
is ∼-invariant, so is 
.
Lemma V.2.1.6

If  are ∼-invariant, so is .

Confusion of n-vectors of local states is an equivalence relation:

Lemma V.2.1.7

≍ is an equivalence relation on 
.

Proof idea

Follows from Lemma V.2.1.4, Lemma V.2.1.5, Lemma V.2.1.6. ■

To show that confusion of program states is an equivalence relation, we recall a well-known fact:

Lemma V.2.1.8

Let X and Y be sets, ≒ an equivalence relation on X, ≓ an equivalence relation on Y,

Image 87
, and ≑ a binary relation on Z defined via
Image 88
(
, 
). Then:
a)
≑ is an equivalence relation on Z, and

b)
Image 89
.
Lemma V.2.1.7, Lemma V.2.1.8a) imply directly:
Corollary V.2.1.9

≈ is an equivalence relation on . □

For computing distances, the self-loops in the transition graph are irrelevant, which motivates the following notion:

Definition V.2.1.10

A simple thread transition relation is a member of

Image 90
. □
Above, E stands for “edges”. Using this shorthand for simple thread transition relations, we can express the notion of state confusion differently; instead of mentioning bijections we can say that certain sets are equally large:

Lemma V.2.1.11

For all 
, we have

Image 91
iff
Image 92
.
Proof idea

Two sets have the same cardinality iff a bijection between them exists. ■

Lemma V.2.1.11 implies directly:

Corollary V.2.1.12

For all 
 we have 
 iff

Image 93
. □
So program states are confusable iff they are the same up to renumbering the threads with confusable identifiers and renaming local states according to the permutations 
 ().
In the proofs of the following claims, both views of state confusion come in handy.

The next lemma, which says that confusable program states have the same distance from the fixed one, is crucial for the whole section.

Lemma V.2.1.13

Image 94
.
Proof idea

Induction on 
. ■

From this result we directly conclude:

Lemma V.2.1.14

Image 95
.
Proof idea

Take a shortest path from  to s. Lemma V.2.1.13 implies that any two program states on this path are nonconfusable. Hence, the index of the equivalence relation ≈ exceeds the path length. ■

Computing the index of ≈ can be reduced to computing the index of ≍:

Lemma V.2.1.15

Image 96
.
To get a polynomial upper bound on the index of ≍, we establish an injection from the set of equivalence classes to another set for which the cardinality will be easy to determine.

Let V be the set of the maps

Image 97
such that, for each simple thread transition relation ⇉, the sequence of values of
Image 98
forms a partition of the number of all the threads that have ⇉ as the normalized thread transition relation. Formally:(2)
Lemma V.2.1.16

There is an injection from

Image 100
to V.
Proof idea

Using Lemma V.2.1.11, construct a map from 
 to V which delivers equal values for two local-state vectors iff they are confusable. Lift this map to an injection from

Image 101
to V. ■
To estimate the cardinality of V, we employ a generalization of the binomial coefficients in which the upper argument can take arbitrary rational values: with the convention that the empty product evaluates to 1.
We need a standard combinatorial lemma:

Proposition V.2.1.17

There are  
  ways to arrange k indistinguishable balls into m distinguishable baskets. Formally:
 
 

(Remark: in the above formulation,  is the number of balls in basket c, where the baskets are enumerated by integers from 0 up to but not including m.)
The definition of V in (2) depends on the transitions of the threads. Now we bound  by an expression over G, L, and n that does not involve this dependency:

Lemma V.2.1.18



Proof idea

Apply Proposition V.2.1.17. ■

Now we prepare to simplify the maximum from Lemma V.2.1.18. Recall that a product of constantly many nonnegative integers with a constant sum is maximal when these integers coincide. We require a similar result:

Lemma V.2.1.19

Let 
 and

Image 104
. Then
Proof idea

Generalize the claim to 
 (

Image 106
) and prove it by induction on
Image 107
. ■
Now we can bound the index of ≈ by a less complicated term:

Corollary V.2.1.20

Image 108
⩽  
 
 where 
.
Proof idea

Combine Lemmas V.2.1.8b), V.2.1.16, V.2.1.18, and V.2.1.19. ■

Now the computation for a fixed, arbitrary program is over and we turn to the whole class of programs.

We recall a standard, simple combinatorial lemma:

Proposition V.2.1.21

Image 109
.
This helps to asymptotically bound  by a polynomial in n:
Theorem V.2.1.22

Image 110
.
Proof idea

Follows from Lemma V.2.1.14, Corollary V.2.1.20, and Proposition V.2.1.21. ■

To the best of our knowledge, 
 is the lowest known polynomial upper bound for . Comparing the degree 
 to bounds from [73] from a theoretical viewpoint, we feel it comforting to see that our degree is relatively small: it involves only one exponentiation operation. Tightening Theorem V.2.1.22 is an open problem, but we expect that the degree could be lowered further by reducing E from Definition V.2.1.10 and considering distance-preserving bisimulations. Sections V.2.2 and V.2.3 will be encouraging: in the setups described there, the degree is provably 1.

Note V.2.1.23

The current degree of the upper bound on  has been improved over the previously known degree from [55] by the factor of L. In the binary case we obtain 
, which is an improvement over the 
 bound from [58] by the factor of 32 in the degree. □

V.2.2. Strongly connected subprograms
Now we show a linear upper bound for families of programs that have a subprogram with a strongly connected transition graph. A graph is strongly connected if, for each pair of nodes of the graph, there is a walk from the first node to the second node. Slightly abusing the terminology, we say that a program is strongly connected if its transition graph is strongly connected.

Models of real-world programs may possess strongly connected subprograms. This may happen when we produce an abstraction of a system. For example, the coarsest abstract thread [48] uses only one local state and changes the shared memory arbitrarily. Another way in which strongly connected subprograms may occur is via the automatic generation of models inside abstraction-refinement loops: it starts with the coarsest thread. Even more-refined thread abstractions may be strongly connected, e.g., when we model a reactive thread running an infinite loop which responds to the environment by changing the shared state in different ways.

For a program with transition relation ⟶, we write 
 iff the state 
 is reachable from σ in at most k steps.

While the cases of low values of G (or L) will be easy to handle, for the most general case

Image 111
we will need some preparation. Let  be the maximal local diameter (cf. Definition and Corollary IV.3.8) for the rest of this section. Now, we determine how long it takes in a strongly connected program to achieve a given shared part in the worst case:
Lemma V.2.2.1

Let h be an m-threaded strongly connected program with at least two shared states and  a state of the program. Let

Image 112
. Then each shared state can be reached from  in at most δ steps. Formally:
Image 113
∧ h is strongly connected ∧ the transition graph of h is
Image 114
⇒
Image 115
.
Proof idea

Take a shortest path from  to a program state with the shared part 
; consider the interesting case 
. Each state from 
 occurs in the path at most once. In the interesting case , the thread transition taken last cannot be taken earlier in the path due to its minimality, which implies the absence of a certain thread state of a certain thread earlier along the path. ■

As we will see, a strongly connected subprogram is in some sense a “universal helper,” since, if h is a strongly connected subprogram of program p, then h may “help” to lift certain sequences of local states of p (that are almost walks in the transition graph p induced by a single thread, but the shared states do not match properly) to actual walks in the transition graph of p:

Lemma V.2.2.2

Let  and h be a strongly connected, m-threaded subprogram of an n-threaded program

Image 116
via an embedding f. Let
Image 117
. Let ⟶ be the transition relation of p,
Image 118
,  a state of p,
Image 119
,
Image 120
a sequence of local states that starts with 
 and satisfies
Image 121
. Then there is a program state 
 of p such that
Image 122
,
Image 123
, and
Image 124
.
Proof idea

Drop cycles from σ. In the obtained sequence, use Lemma V.2.2.1 to inject path segments that convert the shared state in such a way that a walk emerges. ■

Due to Lemma V.2.2.2, a strongly connected subprogram can “help” more than one thread to change shared states “quickly”:

Theorem V.2.2.3

Let

Image 125
, and let h be a strongly connected, m-threaded subprogram of an n-threaded program p. If , then . If , then . If , then
Image 126
.
Proof idea

Given a walk from one program state to another, construct a (potentially different) path from the former state to the latter state in which the number of indices in which the local parts of the two states differ is gradually reduced via Lemma V.2.2.2. ■

Let us restate the contents of Theorem V.2.2.3 for program families:

Corollary V.2.2.4

Let

Image 127
and 
 be a family of multithreaded programs such that
•
the program 
 is strongly connected, and

•
for all

Image 128
, the program 
 has exactly n threads, and
•
for all

Image 128
, the program 
 is a subprogram of 
.
If
Image 129
, then
Image 130
. If
Image 131
, then
Image 132
. If
Image 133
, then for 
 and
Image 134
we have
Image 135
. □
Note V.2.2.5

On the tightness of upper bounds mentioned in Theorem V.2.2.3 and Corollary V.2.2.4
In case , the upper the bound  is tight, as can be demonstrated by a program in which the graph of transitions of some thread is a directed Hamiltonian cycle on , and the transitions graphs of the other threads are non-circular directed Hamiltonian paths on .

In case , the upper the bound  is also tight, as can be demonstrated by a program in which the graph of transitions of some thread is a directed Hamiltonian cycle on , and the thread transition relations of the other threads are empty.

In case  and , the upper bound

Image 136
is likely to be tight. We expect that it can be demonstrated by an adaptation of the family from the proof of Theorem V.1.3, in which thread 0 additionally obtains a reverse transition for each transition it already has; we skip the corresponding proof in this paper.
For the most general case of

Image 137
, the question whether the bound is tight is open. □
Other examples for Theorem V.2.2.3 and Corollary V.2.2.4 can be obtained by adding more threads to N2T6B, N2T7B, or N3T9 from § III: each of these programs is strongly connected.

Notice that the upper bounds in Theorem V.2.2.3 and Corollary V.2.2.4 are (sub-)linear in n, as the coefficient with which n is multiplied can be bounded above by , which does not depend on the family of programs.

Also remark that for , the if-then-else expression inside the aforementioned coefficient can be simplified to its “else” branch which is at least as large as the “then” branch. The cost paid is a loosening of the inequality for .

V.2.3. Probabilistic analysis
We proceed by considering a random process of creating a multithreaded program in which each transition of each thread is chosen independently with a probability that depends only on the thread transition.

Due to Lemma V.1.1, Lemma V.1.2, in case  the diameter of an n-threaded program is at most linear in n with probability 1 regardless of the random process. So from here to the end of this section, we consider the general case .

First, we show that the existence of a thread with a special set of transitions leads to a polynomial bound on the diameter which is linear in n.

Lemma V.2.3.1

If the graph of thread transitions of some thread in a program is strongly connected, then the diameter of the program does not exceed

Image 138
. Formally: for every n-threaded program
Image 139
, we have
Proof idea

Follows from Theorem V.2.2.3. ■

Lemma V.2.3.1 is our main ingredient in proving a linear diameter of programs for which the number of threads becomes sufficiently large—given a rather general probability distribution for the existence of thread transitions as mentioned before.

Theorem V.2.3.2

Let

Image 141
be a probability distribution on thread transitions for which
Image 142
. Then
Proof idea

An infinite monkey argument [87] using Lemma V.2.3.1. ■

Note V.2.3.3

In the above claims, the bound  on the diameter is linear in the number of threads, and can be simplified to a mathematically larger but conceptually easier expression 
. □

The probability distribution above is given, e.g., when the probability of each thread transition is positive, no matter how small it is.
Informally, the consequence is that trying to find programs with “large” diameter by generating n-threaded programs, for instance, uniformly at random would most likely fail for large n: we would likely get only at-most–linear values. In contrast, the search from [58], for example, is nonrandom, structured, and informed.

Theorem V.2.3.2 models the risks of a large number of threads being affected externally. Examples are radiation in high-performance computing and row-hammering attacks on server memory [44]. Assuming that the operating system with the scheduler is stored in better-protected memory (which is a reasonable requirement on system builders) and that user-space threads are less protected, and assuming sufficiently long running-times, irreparable bit-flips are likely to turn the threads into random pieces of code while still maintaining their parallel execution. In particular, Theorem V.2.3.2 is an indication that if an “error” program state ever becomes reachable from the current execution state due to bit-flips, it is also likely to become reachable “quickly,” i.e., in time linear in n. Our argument even extends to deterministic threads (in which each thread state has at most one successor, and which can be actually executed as opposed to their nondeterministic counterparts) if we additionally assume that the probability of each thread transition is strictly below 1: then, a program asymptotically almost surely contains a thread whose transition graph is a Hamiltonian cycle on

Image 144
(such a cycle is both deterministic and strongly connected), and we can apply Theorem V.2.2.3.
VI. Complexity of (non-)reachability
Now we determine the complexity of proving or refuting the reachability of a target program state or a target thread state from a source program state.

For the purpose of defining these reachability problems as formal languages, we assume without loss of generality the following:

•
A shared state is an ordinal below G, and it is encoded in binary occupying exactly  bits.

•
A local state is an ordinal below L, and it is encoded in binary occupying exactly  bits.

•
A thread identifier is an ordinal below n, and it is encoded in binary occupying exactly  bits.

If some binary number actually needs fewer bits than allocated, it is padded with zeros.
In the language definitions below, “a program over G and L” is a program such that its set of shared states is G, and its set of local states is L (we emphasize this to create a textual difference to the language definitions in § II.3):The letter  starting the names of the languages above indicates that G and L are the hidden constant parameters of these languages; the number of threads is implicitly existentially quantified in the class terms.

First, we deal with program-state–to–program-state reachability:

Theorem VI.1

.

Proof idea

Nondeterministically search in a Petri net created to simulate an input program. In this Petri net, a place corresponds to the number of threads that started in a particular local state, have a particular thread transition relation after normalizing the initial local state to 
, and currently have yet another particular local state after normalizing the initial local state to 
 (cf. Corollary V.2.1.12). Keep track of the shared state separately. ■

For program-state–to–thread-state reachability, recall that low-complexity problems tend to be sensitive to the input format. So we now provide the details of the encoding of 
 and 
 into bitstrings. A thread transition relation is encoded using a bitstring of length 
. An n-threaded program p is stored as a list of thread transition relations in a self-delimited way. (For example, insert 0 between each pair of thread transition relations and append 1 at the end. This encoding uses 
 bits. Using a slightly more compact self-delimiting encoding [52] would not change the complexity class.) An element of 
 is represented as a string of  bits assuming that n is known. A program state 
 is formed by prepending the encoding of g to the encoding of l, again assuming that n is known. The number i from the third component of the quadruple 
 is stored in binary and not in a self-delimiting way in the bits right after s. The encoding of i is followed by an encoding of τ using the final  bits.

We expect that slight encoding variations (e.g., in the self-delimiting encoding of p) will not change the complexity class.

Theorem VI.2

Image 146
.
Proof idea

The number of threads participating on a path can be bounded using Definition and Corollary IV.3.8, allowing for storing a finite table of answers in the state space of a regular automaton. Syntax checking is done by an NC1-circuit. ■

We do not expect the complexity to drop significantly below NC1, since checking whether a unary-encoded number is larger than a binary-encoded number ( in the problem formulation) cannot be performed by a finite automaton.

VII. Discussion and conclusion
In the present paper, we tackled the case of arbitrary but constant shared and local state space. We derived the bounds

Image 147
, where
Image 148
, on the maximum diameter of an n-threaded program with G shared states and L local states for all n. Notice that the exponent does not depend on the number of threads. The lower bound was proven by constructing an infinite family of explicit programs such that the 
 program has n threads and diameter . The upper bound is both a strengthening and a generalization of the corresponding bound from [58]. The mathematical computations behind these bounds are tight in the following sense: if better yet simple bounds exist, they would require genuinely new proof ideas. Moreover, we discovered the following results:
•
a polynomial upper bound for the diameter for a subclass of multithreaded programs; this bound is linear in n and, in certain cases, agrees with the lower bound;

•
a polynomial upper bound for a rather general class of probability distributions and a randomly chosen program; this bound is linear in n and matches the lower bound;

•
an upper bound on the local diameter that does not depend on n; the function mapping G and L to the least upper bound is computable, and the computation algorithm can be readily extracted from the proofs;

•
(non-)reachability of target program states from source program states is decidable in ;

•
(non-)reachability of target thread states from source program states is decidable in NC1 (which strengthens and generalizes the corresponding result from [58]).

(Sub-)polynomial characterizations of this type are desirable as they, besides being aesthetically pleasing, give hope for practical algorithms.
(Besides, in the unparametrized case, we formally proved PSpace-completeness of reachability and nonreachability of program states and thread states in multithreaded programs with respect to logspace reductions.)

So far, no infinite family of n-threaded programs with constant shared and local space sizes and superlinear diameter (in n) is known. This is in stark discrepancy to the presence of examples of sequential programs whose diameter is exponential in the number of variables and in extreme discrepancy to the presence of Petri nets computing non-primitive recursive functions [64]. The polynomial bound on  implies that the distances in the transition graph of a program are at most polylogarithmic in the size of this graph (whereas the general upper bound on the distances in an arbitrary graph is linear rather than polylogarithmic).

From a purely theoretical viewpoint, searching for counterexamples (to certain non-reachability properties) in certain programs with depth-first search (DFS) can be improved now: the search depth can be bounded by 
 for some

Image 149
not depending on n for nonlocal properties and by a constant for local properties. Thus, the worst-case time for look-ups in the DFS stack can be improved from linear to logarithmic or constant in n. If all reachable states up to depth 
 for nonlocal properties are explored, full coverage holds even if the bug finder at hand thinks that more reachable states might still exist, but does not know it for sure due to, for example, not having the ability or enough space to store already visited states. Similarly, if all reachable states up to some constant depth independent of n are explored, full coverage for local non-reachability properties is achieved, making bounded verification complete. These search-depths bounds for non-local and local properties are asymptotically negligible relative to the number of states. Moreover, if a good upper bound on  (or  for local properties) is ever provided, the modulus of the difference between this upper bound and the (e.g., default worst-case) search depth of a bug finder might be used to better estimate the quality of the bug finder. This would help to coarsely rank the bug finders.
Low complexity of (non-)reachability has some asymptotic ramifications in terms of classical complexity theory (again, n being the only variable). First, reachability queries are probably efficiently parallelizable in n due to 
. Second, finding bugs in even huge input programs is probably tractable due to using only 
 additional memory cells (because of 
).

From an algorithmic viewpoint, our proofs of the complexity bounds demonstrate that symmetry reduction in tools is more than just a heuristic: when suitably performed, it diminishes the resource consumption also in the worst case.

To the practical tool builder, on the one hand, our results show that implementations could consider paying a little bit more attention to avoiding the state-space explosion in n in the worst case (since the exponential blow-up in n is theoretically avoidable in the setting described). On the other hand, large or unknown constants in our upper bounds emphasize a well-known warning: theoretical advances primarily say only that certain improvements could probably be achieved asymptotically in principle, not that any advance translates into practice directly.

Concerning research on verification, our results show that, in certain natural mathematical setups, the exponential state-explosion phenomenon in the number of threads has reduced or no bearing on the reachability analysis for parallel programs. Further, if a modeling step bounds the sizes of the shared and thread-local state spaces in the abstraction when they are unbounded in the concrete, unexpected mathematical artifacts may emerge. One such artifact is the state-explosion problem turning out to be asymptotically a nonproblem, informally speaking. Depending on the application, this artifact might be considered helpful (e.g., if small values of the fixed parameters turn out to allow for specialized but fast verifiers, for instance, using caching) or detrimental (e.g., hidden large constants might fool the developers). Also, the widely stated claim that the exponential blow-up of the state space in the number of threads is a major obstacle to verification should not be blindly interpreted in a mathematically straightforward way. Sometimes this blow-up is an empirical phenomenon occurring in the tools that do not perform symmetry reduction properly or at all, and sometimes the set of programs on which the state explosion is observed simply does not have constant local and shared state spaces.

As a next theoretical-research step, we plan to tighten the aforementioned inequalities. While we do not know whether  can be majorized, for instance, by a linear function, we expect that the upper bound could be lowered in principle; one way could start with determining a possibly large class of threads that do not occur in -realizing programs and subtracting this class while defining E in Definition V.2.1.10 and another way could be using distance-preserving bisimulations to reduce the index of ≈. An interesting research direction is searching for an explicit upper bound on the maximal local diameter  (perhaps, using [70]). Locating the general and local reachability problems in the hierarchy of parametric complexity classes is a further, orthogonal line of research. Finally, a mathematical study of the state-space explosion problem in the number of parallel components is important also for other models of parallel computation.