Abstract
In prior works, stochastic dual coordinate ascent (SDCA) has been parallelized in a multi-core environment where the cores communicate through shared memory, or in a multi-processor distributed memory environment where the processors communicate through message passing. In this paper, we propose a hybrid SDCA framework for multi-core clusters, the most common high performance computing environment that consists of multiple nodes each having multiple cores and its own shared memory. We distribute data across nodes where each node solves a local problem in an asynchronous parallel fashion on its cores, and then the local updates are aggregated via an asynchronous across-node update scheme. The proposed double asynchronous method converges to a global solution for L-Lipschitz continuous loss functions, and at a linear convergence rate if a smooth convex loss function is used. Extensive empirical comparison has shown that our algorithm scales better than the best known shared-memory methods and runs faster than previous distributed-memory methods. Big datasets, such as one of 280 GB from the LIBSVM repository, cannot be accommodated on a single node and hence cannot be solved by a parallel algorithm. For such a dataset, our hybrid algorithm takes less than 30 s to achieve a duality gap of 10−5 on 16 nodes each using 12 cores, which is significantly faster than the best known distributed algorithms, such as CoCoA+, that take more than 160 s on 16 nodes.


Keywords
Dual coordinate descent
Distributed computing
Optimization

1. Introduction
The immense growth of data has made it important to efficiently solve large scale machine learning problems. It is necessary to take advantage of modern high performance computing (HPC) environments such as multi-core settings where the cores communicate through shared memory, or multi-processor distributed memory settings where the processors communicate by passing messages. In particular, a large class of supervised learning formulations, including support vector machines (SVMs), logistic regression, ridge regression and many others, solve the following generic regularized risk minimization (RRM) problem: given a set of instance-label pairs of data points 
, (1) 
 ≔
 
 
where 
 is the label for the data point 
, 
 is the linear predictor to be optimized,  is a loss function that is convex with respect to its first argument,  is a regularization parameter that balances between the loss and a regularizer , which for instance can take the squared 
-norm 
.

Many efficient sequential algorithms have been developed in the past decades to solve (1), e.g., stochastic gradient descent (SGD) [25], or alternating direction method of multipliers (ADMM) [2]. Especially, (stochastic) dual coordinate ascent (DCA) algorithm [18] has been one of the most widely used algorithms for solving (1). It efficiently optimizes the following dual formulation (2) (2) 
 ≔
 
 
 
where 
, 
 and 
 are the convex conjugates of  (or in short  where the scalar 
) and , respectively. The conjugate of the loss function  is defined as 
. Let 
 be the gradient of 
 with respect to  where 
 
. We have (3)
It is known from duality theory that if 
 is an optimal dual solution, then the vector 
 is an optimal primal solution and 
. The dual objective has a separate dual variable 
 associated with each training data point 
. The stochastic DCA updates dual variables, one at a time, while maintaining the primal variables by calculating (3) from the dual variables.

Recently, much effort has been undertaken to solve Problem (1) in a distributed or parallel framework. It has been shown that distributed DCA algorithms have comparable and sometimes even better convergence than SGD-based or ADMM-based distributed algorithms [23]. The distributed DCA algorithms can be grouped into two sets. The first set contains synchronous algorithms in which a random dual variable is updated by each processor and the primal variables are synchronized across the processors in every iteration [8], [11], [23]. This approach incurs a large communication overhead. The second set of algorithms avoids communication overhead by exploiting the shared memory in a multi-core setting [7] where the primal variables are stored in a primary memory shared across all the processors. Further speedups have been obtained by using (asynchronous) atomic memory operations instead of costly locks for shared memory updates [7], [16]. Nevertheless, this approach is difficult to scale up for big datasets that cannot be fully accommodated in the shared memory. This leads to a challenging question: how do we scale up the asynchronous shared memory approach for big data while maintaining the speed up?

We address this challenge by proposing and implementing a hybrid strategy. The modern HPC platforms can be viewed as a collection of  nodes interconnected through a network as shown in Fig. 1(a). Each node contains a memory shared among  processing cores. Our strategy exploits this architecture by equally distributing the data across the local shared memory of the  nodes. Each of the  cores within a node runs a computing thread that asynchronously updates a random dual variable from those associated with the data allocated to the node. Each node also runs a communicating thread. One of the communicating threads is designated as a master and the rest are workers. After every round of  local iterations in each computing thread, each worker thread sends the local update to the master. After accumulating the local updates from  of the  workers, the master broadcasts the global update to the contributing workers. However, to avoid a slower worker falling back too far, the master ensures that in every  consecutive global updates there is at least one local update from each worker. Fig. 1(b) shows how our scheme is a generalization of the existing approaches: for , our setup coincides with the shared memory multi-core setting [7] and for  our setup coincides with the synchronous algorithms in distributed memory setting [8], [11], [23]. With a proper adjustment of the parameters  our strategy could balance the computation time of the first setting with the communication time of the second one, while ensuring scalability in big data applications.


Download : Download high-res image (289KB)
Download : Download full-size image
Fig. 1. (a) A simplified view of the modern HPC system and (b) Algorithms on this architecture.

Thus, our contributions are (1) we propose and analyze a hybrid asynchronous shared memory and asynchronous distributed memory implementation (Hybrid-DCA) of the mostly used DCA algorithm to solve (1); (2) we prove a strong guarantee of convergence for -Lipschitz continuous loss functions, and further linear convergence when a smooth convex loss function is used; and (3) the experimental results using our light-weight OpenMP+MPI implementation show that our algorithms are much faster than existing distributed memory algorithms [8], [11], and easily scale up with the volume of data in comparison with the shared memory based algorithms [7] as the shared memory size is limited.

2. Related work
Sequential Algorithms. SGD is the oldest and simplest method for solving problem (1). Though SGD is easy to implement and converges to modest accuracy quickly, it requires a long tail of iterations to reach ‘good’ solutions and also requires adjusting a step-size parameter. On the other hand, SDCA methods are free of learning-rate parameters and have faster convergence rate around the end [14], [15]. A modified SGD has also been proposed with faster convergence by switching to SDCA after quickly reaching a modest solution [18]. Recently, ‘variance reduced’ modifications to the original SGD have also caught attention. These modifications estimate stochastic gradients with corrections to reduce the estimation variance. Mini-batch algorithms are also proposed to update several dual variables (data points) in a batch rather than a single data point per iteration [22]. Mini-batch versions of both SGD and SDCA have slower convergence when the batch size increases [17], [19]. These sequential algorithms become ineffective when the datasets get bigger.

Distributed Algorithms. In the early single communication scheme [5], [12], [13], a dataset is ‘decomposed’ into smaller parts that can be solved independently. The final solution is reached by ‘accumulating’ the partial solutions using a single round of communications. This method has limited utility because most datasets cannot be decomposed in such a way. Using the primal–dual relationship (3), fully distributed algorithms of DCA are later developed where each processor updates a separate 
 which is then used to update , and synchronizes  across all processors (e.g., CoCoA [8]). To trade off communications vs computations, a processor can solve its subproblem with  dual updates before synchronizing the primal variable (e.g., CoCoA＋ [11], DisDCA [23]). In [11], [23], a more general framework is proposed in which the subproblem can be solved using not only SDCA but also any other sequential solver that can guarantee a -approximation of the local solution at a processor for some . Nevertheless, the synchronized update to the primal variables has the inherent drawback that the overall algorithm runs at a speed of the slowest processor even when there are fast processors [1].

Parallel Algorithms. Multi-core shared memory systems have also been exploited, where the primal variables are maintained in a shared memory, removing the communication cost. However, updates to shared memory requires synchronization primitives, such as locks, which again slows down computation. Recent methods [7], [10] avoid locks by exploiting (asynchronous) atomic memory updates in modern memory systems. There is even a wild version in [7] that takes arbitrarily one of the simultaneous updates. Though the shared memory algorithms are faster than the distributed versions, they have an inherent drawback of being not scalable, as there can be only a few cores in a processor board.

Other Distributed Methods for RRM. Besides distributed DCA methods, there are several recent distributed versions of other algorithms with faster convergence, including distributed Newton-type methods (DISCO [28], DANE [20]) and distributed stochastic variance reduced gradient method (DSVRG [9]). It has been shown that they can achieve the same accurate solution using fewer rounds of communication, however, with additional computational overhead. In particular, DISCO and DANE need to solve a linear system in each round, which could be very expensive for higher dimensions. DSVRG requires each machine to load and store a second subset of the data sampled from the original training data, which also increases its running time.

The ADMM [2] and quasi-Newton methods such as L-BFGS also have distributed solutions. These methods have low communication cost, however, their inherent drawback of computing the full batch gradient does not give computation vs communications trade-off. In the context of consensus optimization, [27] gives an asynchronous distributed ADMM algorithm but that does not directly apply to solving (1).

To the best of our knowledge, this paper is the first to propose, implement and analyze a hybrid approach exploiting modern HPC architecture. Our approach is the amalgamation of three different ideas – (1) CoCoA＋/DisDCA distributed framework, (2) asynchronous multi-core shared-memory solver [7] and (3) asynchronous distributed approach [27] – taking the best of each of them. In a sense ours is the first algorithm which asynchronously uses updates which themselves have been computed using asynchronous methods.

3. The proposed algorithm
At the core of our algorithm, the data are distributed across  nodes and each node, called a worker, repeatedly solves a perturbed dual formulation on its data partition and sends the local update to one of the workers additionally designated as the master which merges the local updates and sends back the accumulated global update to the workers to solve the subproblem once again, unless a global convergence is reached. Let 
 denote the indices of the data and the dual variables residing on node  and 
. For any 
 let 
 denote the vector in 
 defined in such a way that the th component 
 if 
,  otherwise, so that 
. Let 
 denote the matrix consisting of the columns of the 
 indexed by 
 and replaced with zeros in all other columns, so that 
.

Ideally, the dual problem solved by node  is (2) with  replaced by 
, respectively, and hence is independent of other nodes. However, following the efficient practical implementation in [11], [23], we let the workers communicate among them a vector 
, an estimate of 
 
 that summarizes the last known global solution . Also following [11], [23] for faster convergence, each worker in our algorithm solves the following perturbed local dual problem, which we henceforth call the subproblem: (4) 
 
≔
 
 
 
 
 
 where 
 denotes the local (incremental) update to the dual variable 
, the bounding barrier parameter  denotes the number of workers from which the updates would be merged by the master in a global iteration and the scaling parameter  measures the difficulty of solving the given data partition (see [11], [23]) and must be chosen such that (5)
≔ 
 
 
where the aggregation parameter 
 
 is the weight given by the master to each of local updates from the contributing workers while computing the global update. Unlike the synchronous all reduce approach in [11], our asynchronous method merges the local updates from only  out of  nodes in each global update and the second term in the objective of our subproblem (4) has denominator  instead of . By Lemma 3.2 in [11], ≔ is a safe choice to hold condition (5).

3.1. Asynchronous updates by cores in a worker node
In each communication round, each worker  solves its subproblem using a parallel asynchronous DCA method [7] on the  cores. Let the data partition 
 stored in the shared memory be logically divided into  subparts where subpart 
, is exclusively used by core . In each of the  iterations, core  chooses a random coordinate 
 and updates 
 in the th unit direction by a step size  computed using a single variable optimization problem: (6) 
 
which has a closed form solution for SVM problems [4], and a solution using an iterative solver for logistic regression problems [24]. The local updates to  are also maintained appropriately. Because the coordinates used by any two cores are randomly chosen in parallel, the corresponding updates to 
 are independent of each other. Thus, there might be conflicts in the updates to  if the corresponding columns (the allocated examples in different cores) in  have nonzero values in the same row (resulting in different updates at the same element position of ). We use lock-free atomic memory updates to handle such conflicts. When all cores complete  iterations, worker  sends the accumulated update  from the current round to the master; waits until it receives the globally updated  from the master; and repeats for another round unless the master indicates termination.


Download : Download high-res image (153KB)
Download : Download full-size image
3.2. Merging updates from workers by master
If the master had to wait for the updates from all the workers, it could compute the global updates only after the slowest worker finished. To avoid this problem, we use bounded barrier: in each round , the master waits for updates from only a subset 
 of workers of size , and sends them back the global update 
. However, due to this relaxation, there might be some slow workers with out-of-date . When updates from such workers are merged by the master, it may degrade the quality of the global solution and hence may cause slow convergence or even divergence. We ensure sufficient freshness of the updates using bounded delay: the master makes sure that no worker has a stale update older than  rounds. This asynchronous approach has two benefits: (1) the overall progress is no more bottlenecked by the slowest processor, and (2) the total number of communications is reduced. On the flip side, convergence may get slowed down for very small  or very large .


Download : Download high-res image (141KB)
Download : Download full-size image
Example

Fig. 2 shows a possible sequence of important events in a run of our algorithm on a dataset having  data points in  dimensions using  nodes each having  cores such that each core works with only 
 data points. The activities in solving the subproblem using  local iterations in a round are shown in a rectangular box. For the first subproblem, core 1 and core 2 in worker 1 randomly select dual coordinates such that the corresponding data points have nonzero entries in the dimensions  and , respectively. Each core first reads the entries of  corresponding to these nonzero data dimensions, and then computes the updates  and , respectively, and finally applies these updates to  (where 
 is first updated to be  from both of the cores, then 
 is updated to 0.5 from core 2 while 
 is updated to 0.7 from core 1, and then 
 is augmented by 0.4 from core 2 to reach ). The atomic memory updates ensure that all the conflicting writes to , such as 
 in the first write-cycle, happen completely. At the end of  local iterations by each core, worker 1 sends  to the master, the responsibility of which is shared by one of the  nodes, but shown separately in the figure. By this time, the faster workers 2 and 3 already complete 3 rounds. As , the master takes first 2 updates from 
 and computes the global updates using . However, as , the master holds back the third updates from workers 2, 3 until the first update from worker 1 reaches the master. The subsequent events in the run are omitted in the figure.

3.3. Communication cost analysis
In each communication round, the algorithms based on synchronous updates on all  nodes require  transmissions, each consisting of all values of  or . Half of these transmissions are from the workers to the master and the rest are from the master to the workers. Whereas, our asynchronous update scheme requires  transmissions in each round.

4. Convergence analysis
In this section we prove the convergence of the global solution computed by our hybrid algorithm. We prove for the case of regularizer 
 as an example; the proof can be similarly extended to other regularizers . For this special case, 
, 
, the simplified dual formulation is the following (7) 
 ≔
 
 
 
and the corresponding subproblem formulation is the following (8) 
 
≔
 
 
 
 
 
 The analysis is divided into two parts. First we show that the solution of the subproblem computed by each node locally is indeed not far from the optimum of the subproblem. Using this result on the subproblem, we next show the convergence of the global solution. Though our proofs for the two parts are based on the works [7] and [11], respectively, we need to make significant adjustments in the proofs due to our modified framework handling two cascaded levels of asynchronous updates.

In our analysis we focus on all the events that are important for the local updates that are merged by the master in global update . Fig. 3 shows an example where the master merges local updates from  workers.

4.1. Near optimality of the solution to the local subproblem
In this section we prove that the solution returned by the parallel asynchronous stochastic DCA solver used by each worker  in Algorithm 1 is not far from the optimal solution for the subproblem (4).

Definition 1

-approximate
For given 
, a solution 
 to the subproblem (4) is said to be -approximate, , if (9)
where 
 is an optimum solution to (4).

Though our proof is based on the results in [7], the main challenge here is to tackle the following two modifications in our approach: (1) the solver here solves only a part of the dual problem and (2) the subproblem is now perturbed (Section 3). While the first modification is simply handled by considering the updates by the cores in worker  only, the second modification needs changes in each step of the proof in [7]. We give below the complete details of each of the steps.

Worker  solves subproblem (4) by applying total  updates, each of its  cores makes  updates. To show -approximate, we need to show that sufficient progress is made between any two successive updates. However, each of the cores makes multiple atomic memory writes in an update, the updates made by different cores are interleaved and hence it is difficult to demarcate two successive updates. Nevertheless, depending upon the order cores select a data point 
 as in step 6 of Algorithm 1 we assign a node-level counter  for each of the total  updates in node  and let the index  denote the data point selected for update . Fig. 3 shows an example of local updates .

In each update, a worker core computes step size  using line 6 of Algorithm 1 and then applies  in th axis to 
. However, there are a few subtle points to notice that happen due to the atomic updates. Firstly, when a core computes  it starts with a  but by the time it reads a coordinate of  some other core might have already modified some other coordinates. So the effective  that a core uses to compute the increment  might not be the actual  at the memory, and in fact it might not exist at all in the memory at any time. Let 
 denote the effective  that a core uses to compute , and let 
 denote the actual  value in the memory. Fig. 4 helps readers connect the different notation and updates used in the proofs in this section.

For all 
, we have the following definitions: 
≔
 
 
 
 
 
≔ 
 
 
≔ 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 where 
 denotes any fixed vector, , and  denotes the proximal operator. We can see the connection of the above operator to the proximal operator: 
 
. Here both 
 and 
 were revised from (()) to satisfy the subproblem (4).


Download : Download high-res image (189KB)
Download : Download full-size image
Fig. 4. Relationship among different approximations of .

Let 
 denote the normalized data matrix at th local atomic solver with omitted notation 
 where each row is 
. Define 
, 
 over all the local atomic solvers, where  is the set of all the feature indices, and 
 is the th column of 
. Moreover, 
 is defined as the minimum value of global data matrix, i.e., 
. Then, we define that:

Definition 2 Local Atomic Dual Variables

Here we omit 
 in the proofs of the local atomic solver. 
 
 where 
 denotes the th sequence generated by a specific th local atomic solver, 
 denotes the actual values of  maintained at update  in the local atomic solver;  indicates the index selected at th update; and 
 refers to the “accurate”  if all cores are synchronously updated at iteration . Note that, 
 and 
 
. Since  and 
 will not be changed when solving the local subproblem 
, we denote 
 as the objective value of the dual subproblem at th update and omit the subscripts 
.

Assumption 1 Lipschitz Continuous

The global problem objective (2) is 
-Lipschitz continuous and therefore, its local subproblems objective (4) are at most 
-Lipschitz continuous.

The following propositions are cited from (()), and we use these results in our proof.

Proposition 1 Expectation of Dual Variables

(10)
 

Proposition 2 Boundary of Asynchronous Variables

(11)
 

Proposition 3

(12)
 

Proposition 4

Let , 
 
, 
, and 
. If  and , then 
, and (13)
 
 
 
 

Proposition 5 Properties of Dual Concave Function

For all , we have (14)
 
(15)
 

Proof

Two properties of dual concave function are stated as follows.

•
the strong convexity of 
: as all conjugate functions are convex, it is clear that 
 is 
-strongly convex.

•
the Lipschitz continuous gradient of 
: refer to Assumption 1. □

Because of the atomic updates, the step size computation may not include all the latest updates, but we assume all the updates before the ()-th update have already been written into .

Assumption 2

Bounded Delay of Local Updates, 
(16)
 

This assumption restricts the maximum allowed local delay  by  and 
.

Lemma 6

Under Assumption 2, Definition 2, and
 
. Then, the local subproblem satisfies: (17)
Not that , represents the th update to  in a local solver but not the th iteration of one core.

Proof

We omit the subscript 
 in the notations, which specifies the th data partition, in the proof. We prove Eq. (17) by induction. As shown in (()), we have (18)
The second factor on the r.h.s. of Eq. (18) is bounded as follows with the revisions: (19)
 
 
 
 
 
 
 
 
 
 
 
(20)
 
 
 Now we start the induction. Although some steps may be the same as the steps in (()), we still keep them here to make the proof self-contained.

Induction Hypothesis. We prove the following equivalent statement. For all , 
Induction Basis. When , 
 
 By Proposition 1 and AM–GM inequality, which for any 
 and any , we have (21)
 
Therefore, we have 
 
 
 
 
 
 
 Therefore, 
 
 
which implies 
 
 
where the last inequality is based on Proposition 4 and the fact .

Induction Step. By the induction hypothesis, we assume (22)
To show 
we firstly show that for all , (23)
 
 
 
 
 
 
 
 
 
 
 
 Let 
. We have 
 
 
 
 
 
 
 
 
 
 
 which implies that 
 
 
 
by Proposition 4. □

Lemma 6 implies that the asynchronous updates will not pull the solution away from the optimal solution too much even if the directions of the updates are wrong.

Definition 3 Global Error Bound

For a convex function 
, the optimization problem: 
 admits a global error bound if there is a constant  such that (24)
where 
 is the Euclidean projection to the set of optimal solutions, and 
 is the operator defined as 
 
The optimization problem admits a relaxed condition called global error bound from the beginning if (24) holds for any  satisfying  for some constant .

Assumption 3

The local subproblem formulation (4) admits the global error bound from the beginning for 
 and any update .

The global error bound in the local subproblem helps prove that our subproblem solver achieves significant improvement after each update. It has been shown that when the loss functions are hinge loss or squared hinge loss, the global problem formulation (2) does indeed satisfy the global error bound condition [7]. Then, for the local subproblem (4), it still satisfies the global error bound within the subset 
.

Assumption 4

Bounded 
 
 

Lemma 7 Convergence for Subproblem

When Assumption 2, Assumption 3, Assumption 4 hold, the solutions computed in two successive updates by the local subproblem solver have a linear convergence rate in expectation, i.e., 
where 
 is the 
 after the th update, 
 
 
 
 
 
 is the size of the largest data part, and (25)

Proof

We also omit the subscript 
 of the notations in the proof. We can bound the expected distance 
 by the following derivation. (26)
 
 
 
 
 
 
 
 
 
 Moreover, (27)
 
 The bound of the increase of local objective function value by 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Therefore, 
 Let us assume that 
 is the optimal solution of the subproblem (4) denoted as: (28)
 
According to above proof of Lemma 7, the local atomic solver has a linear convergence rate in expectation, that is, 
It is obvious that 
. Thus, we can easily get the induction as 
 Notice that 
 are the starting points of the local atomic solver and 
 are the final results of 
 of the local atomic solver. So the following equations hold for the global problem: 
 Therefore, we have: 
with 
. □

4.2. Convergence of global solution
Although we have shown that the local subproblem solver outputs a -approximate solution, we cannot directly apply the results of (()) for the global solution because our algorithm uses updates from only a subset  of workers which is unlike the synchronous all-reduce of the updates from all workers used in [11]. We need to handle this asynchronous nature of the global updates, just like we handled asynchronous updates for the local subproblem.

Let us consider the global updates in the order the master computed them (at global time  in Fig. 3). To prove convergence, it is customary to show that the global objective progresses sufficiently in each round, i.e., there is sufficient change from 
 to 
 where 
 denotes the value of the dual variable  distributed as 
 across all the workers  at the time master computed th global update 
. For simplicity we assume that each worker updates 
 in step 11 of Algorithm 1 as soon as it receives global update from the master. Thus, 
 where 
 and 
 denotes the increment to 
 computed by worker  if 
,  otherwise.

If 
 then the update 
 has already been included in 
. However, if 
 then it may not be included. Let  be such that for all  and for all , 
 has been included in 
. By the design of our algorithm, . Let 
 be defined as follows: 
 and 
 for the latest  for which the update is already included in global , 
. Let 
 be 
 and 
 respectively. Note that 
 
. For a vector expression , let 
 represent the th element of the vector resulting from the expression .

Lemma 8

For any dual 
, primal 
 and real values  and  satisfying (5), it holds that (29)
 
 
 
 
 

Proof

Assume that 
. Then, we have 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Assumption 5

Bounded Delay of Global Updates, 
There exists a 
 
 such that (30)

Lemma 9 Global Convergence at Each Iteration

If 
 are all -strongly convex and Assumption 2, Assumption 3, Assumption 4, Assumption 5 are satisfied then for any , any round  of Algorithm 2 satisfies (31)
 
 
where (32)≔
 
 
(33)
≔
 
 for 
 with 
.

Proof

For the sake of notation, we will write  instead of 
,  instead of 
, 
 instead of 
, and  instead of 
.

Now, the expected change of the dual objective is 
 Thus, it is a summation of two parts. Let us estimate both parts as follows, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Therefore, 
 
 
 
 
 
 
 
 
 
 
 
 
 Before bounding the term , we need the following proposition:

Proposition 10

 
 

Now, let us bound the term . We have 
 
 
 
 
 
 
 where 
. Thus, Eq. (9) can be rewritten as, (34)
 Then,  can be bounded as, 
 
 
 
 
 By substituting , we have 
 
 

Using Eq. C in the proof of Lemma 5 in (()), we can show that 
 
 
 
 
 
 

Remark

When  (the minimal number of workers required to update before a global update is communicated) is fixed in (32),  will approach  when  (the maximal delay allowed for the slowest worker) becomes larger and larger since 
. In other words, the improvement from 
 to 
 at iteration  becomes smaller when a larger delay is allowed among the workers.

When  is fixed in (32),  will be larger when  is set larger. The improvement from 
 to 
 at iteration  will be more significant when more updates from different workers are taken into account. However, when ,  will be independent from  because all updates have to be gathered by the master.

Using the main results in [11] and combining Lemma 7 with Lemma 9 we get the following two convergence results for two types of loss functions: (i) smooth and (ii) Lipschitz continuous. The theorems use the following quantities: 
, and 
 where 
.

Theorem 11

Global Convergence for -Smooth Functions
If the loss functions 
 are all -smooth, then in 
 iterations Algorithm 2 finds a solution with objective at most 
 from the optimal, i.e., 
 whenever 
 
 where 
 
 
 and  is given by (25). Furthermore, in 
 iterations, it finds a solution with duality gap at most 
,i.e., 
 whenever 
 
.

Theorem 12

Global Convergence for -Lipschitz Functions
If the loss functions 
 are all -Lipschitz, then in 
 iterations Algorithm 2 finds a solution with duality gap at most 
, i.e., 
 for the average iterate 
 
 whenever 
 
 
, and 
 
 
 
 
 and  is given by (25).

Theorem 12 establishes the convergence for -Lipschitz continuous loss functions, and Theorem 11 proves a linear convergence rate for smooth convex loss functions.

5. Experimental results
We implemented our algorithm in C＋＋ using Open MPI and OpenMP. All our experiments were conducted on the Biowulf cluster at the National Institutes of Health, USA, using up to  nodes where each node has 58 GB main memory and  cores each with a 2.6 GHz Xeon E5-2650v2 processor and 20 MB secondary cache. Though the cores in the cluster are hyperthreading enabled, we did not use hyperthreading mode for our experiments. Each node in the cluster runs exactly one MPI task corresponding to a worker which in turn runs one OpenMP thread on each core available within the node. The main thread in a worker handles the inter-node communication and the root MPI task works as the master. For MPI node scheduling we used the slurm task scheduler with the settings --ntasks-per-node=1 and --threads-per-core=1 whereas for OpenMP thread scheduling we used a simple CPU affinity scheduler that always assigned thread  to physical core  where .

5.1. Datasets
We evaluated our algorithm against three other algorithms on four binary classification datasets, rcv1, webspam, kddb and splicesite from the LIBSVM [3] website ( https://www.csie.ntu.edu.tw/ cjlin/libsvmtools/datasets/binary.html) as shown in Table 1. For datasets rcv1 and kddb we used separate training and test data files downloaded directly from the website. As there was no separate test data file for webspam, we divided the data file into two parts and used the first part containing  of the datapoints as the training set and the remaining as the test set. For splicesite we used the test file on the website as our training set (to better test the scalability of our algorithm as the test file was bigger). We chose the datasets in such a way that we had representatives of several scenarios: data sample-heavy rcv1 where , feature-heavy webspam where , both sample and feature heavy kddb where both  are high, and the big dataset splicesite which was more dense in both ways.


Table 1. Datasets.

Dataset details	rcv1	webspam	kddb	splicesite	
Training set	rcv1_train.binary	webspam_*_trigram	kddb	splice_site.t	
File size	1.2 GB	20 GB	5.1 GB	280 GB	
Training size 	677,399	280,000	19,264,097	4,627,840	
Number of features 	47,236	16,609,143	29,890,095	11,725,480	
Non-zero entries 	49,556,258	1,045,051,224	566,345,888	15,383,587,858	
Test set	rcv1_test.binary	webspam_*_trigram	kddb.t	–	
Test size	677,399	69,632	748,401	–	
5.2. Comparison of algorithms
We experimented with the following four algorithms:

•
Baseline: a sequential implementation of stochastic dual coordinate ascent (DCA) [6] which runs on a single core of a single node

•
CoCoA＋: a MPI based distributed implementation of stochastic DCA [11] which runs on multiple nodes, however, each node uses a single core

•
PassCoDe: an OpenMP based parallel implementation of stochastic DCA [7] which runs on a single node, however, the node uses multiple cores

•
Hybrid-DCA: an OpenMP ＋ MPI implementation of our hybrid parallel distributed approach for stochastic DCA which runs on multiple nodes and each node uses multiple cores.

5.3. Parameter settings
We evaluated all the four algorithms for the hinge loss, though other loss functions could be tested too, with the regularization parameter . In our experiments with three values 
, we observed similar patterns of results and we reported the results for 
 only. All the three parallel/distributed algorithms, namely PassCoDe, CoCoA＋, Hybrid-DCA, have a global parameter  denoting the number of basic updates to the dual variable  that are made in each global round. The parameter  acts as a tradeoff between the progress on the dual objective and the time taken in each global round. In the original implementation in [7] PassCoDe sets  equal to the number of datapoints  in the dataset whereas CoCoA implementation in [11] uses a smaller  than .

We experimented with different values of  and found  for the datasets rcv1, webspam, kddb, respectively, gave the best results in our empirical study. In our implementation, for PassCoDe on  cores each thread made about  local updates, for PassCoDe on  nodes, each MPI task made  local updates and for Hybrid-DCA on  nodes each with  cores, each thread within an MPI task made  local updates so that all the three algorithms made total  updates in a global round. Though the sequential algorithm Baseline did not have any local iteration parameter, for better comparison we computed performance metrics such as time taken after every  update and treated such  updates as a global round. We set aggregation parameters , and the scaling parameter  for both CoCoA＋, Hybrid-DCA as recommended in [11].

Our Hybrid-DCA algorithm has additional parameters, the bounded barrier  and bounded delay  so that updates from only  out of  workers are incorporated in each global round with a maximum delay of  rounds for any update from the workers. In our implementation of Hybrid-DCA, we treated the two cases slightly differently: synchronous Hybrid-DCA with  where the updates from the workers were merged using the collective operation MPI_Allreduce, and asynchronous Hybrid-DCA with  where the updates from a subset of  out of  workers were merged and distributed using basic MPI “send and receive” commands. For all our experiments, we ran algorithms  times for each setting and reported the average of measured values.

5.4. Optimization performance
Fig. 5 shows the progress of duality gap achieved by the four algorithms on the three relatively smaller datasets rcv1, webspam and kddb. We chose the number of nodes () and the number of cores () per node such that the total number of worker cores () was the same (16) for all algorithms except Baseline. For Hybrid-DCA we set the parameters as the bounding barrier  and the delay  so that updates from all workers were incorporated in each global round. However, for  we also experimented with  and  to compare how Hybrid-DCA performed when updates from only  out of  workers were incorporated in each round with a maximum delay of  rounds for any update from the workers. The duality gap was measured as  where the primal estimate  was computed as ()  at the end of each global round. However, when  it was not possible for the master in Hybrid-DCA to gather the parts of  from all workers at the end of each global round. To workaround in such a case, we let the master temporarily store  in disk after each round and at the end of all stipulated rounds, the workers computed the respective parts of  from the stored  and the master computed the duality gap using a series of synchronous all-reduce computations from all the workers.

The bottom row of Fig. 5 shows the progress of the duality gap over time, while the top row shows the progress after each global round. In terms of progress across global rounds, the algorithms performed somewhat equally except for  where Hybrid-DCA had slightly slower progress on duality gap as the updates from one of the workers was missing in each round. In terms of time, there was no clear winner of the three parallel/distributed algorithms. CoCoA＋ showed an advantage over PassCoDe on datasets with a smaller number of datapoints , such as rcv1 and webspam, because the costly inter-node communication complexity was  per round. For kddb where the dataset had more non-zero data elements, PassCoDe performed better. For all the three datasets the performance of Hybrid-DCA came in between CoCoA＋ and PassCoDe by balancing inter-core and inter-node communications. Since the asynchronous Hybrid-DCA with  missed updates from some of the workers, took longer time as expected than synchronous Hybrid-DCA with .

5.5. Test accuracy
To compare the quality of the solution obtained by each algorithm we used test datasets from LIBSVM binary repository the details of which are given in Table 1 and in Section 5.1. Note that the webspam dataset in LIBSVM did not have a separate test dataset. We divided it into two parts and took the first 280,000 datapoints in training and the remaining 69,632 datapoints for test. For each of the empirical datatsets, we computed the accuracy, i.e., the fraction of test datapoints that were classified correctly by each of the algorithms and plotted the results in Fig. 6. In terms of the progress on accuracy across rounds, all the algorithms performed somewhat equally except for Hybrid-DCA with  which missed updates from one of the workers. Though, CoCoA＋ apparently worked better on kddb, the margin was about 0.0005. However, in the long run all algorithms reached the same accuracy level. The progress on accuracy across time can be explained by the progress on duality gap across time as explained in Section 5.4.

5.6. Speedup
Speedup evaluates the improvement in performance of an algorithm as a function of the number of cores used. However, the exact definition of speedup varies in the literature. For example, PassCoDe computes speedup as the improvement in runtime to execute a fixed number of rounds, whereas CoCoA＋ uses a more refined notion of speedup for an optimization problem like RRM defined in Eq. (1) and computes speedup as the improvement in runtime to achieve a fixed level of duality gap. In our experiments, we evaluated the algorithms using both notions of speedup. Let 
 and 
 denote the time taken by an algorithm  using  nodes each with  cores to complete  rounds and to achieve duality gap , respectively. We formally define the two notions of speedup as follows2 : 
 
 

We ran sufficient rounds () of each of the four algorithms and computed 
 and 
 for all algorithms  except Baseline, as shown in the top two rows of Fig. 7. PassCoDe can be run only on a single node; so we varied only the number of cores. Because CoCoA＋ could use only 1 core per node. We ran CoCoA＋ and Hybrid-DCA with  cores on  nodes and plotted the results separately. We also ran synchronous Hybrid-DCA on  nodes each with  cores,  and plotted the results separately for each  fixed and varying . For  nodes and the same set of possible number of cores, we additionally plotted the results for asynchronous Hybrid-DCA with .

Our first observation on the results of speedup experiments was that though proficiency and speedup were computed differently, they turned out to follow a similar trend. In fact, speedup was slightly higher than proficiency as the merging of parallel/distributed updates in every global round reduced the quality of the merged update in comparison with the pure updates of Baseline. We also observed that the speedup and proficiency of the algorithms followed a trend similar to the performance seen in Section 5.4, i.e.,CoCoA＋ performed better on datasets that were either sample-heavy or feature heavy but not both, PassCoDe performed better on dataset that was both sample-heavy and feature heavy, and Hybrid-DCA performed in between. Furthermore, asynchronous Hybrid-DCA ran slower than synchronous Hybrid-DCA.


Download : Download high-res image (1MB)
Download : Download full-size image
Fig. 7. Speedup of different parallel or distributed solvers with respect to the sequential implementation Baseline.

While investigating why Hybrid-DCA was slower than our expectation, we observed that the overhead of OpenMP in maintaining the parallel threads was significant on the datasets rcv1 and webspam as evident from the performance of CoCoA.1 and Hybrid-DCA.1 where their only difference was the overhead of maintaining a single OpenMP thread. However, this overhead was relatively small in comparison with the overall computation in the sample and feature heavy kddb dataset. However, we also noticed that CoCoA＋ and PassCoDe did not scale well beyond  nodes and  cores, respectively.

Further investigation revealed two drawbacks of our implementation of MPI based inter-node communication. Firstly, MPI was inherently single threaded. Even for , for the whole duration when the workers in Hybrid-DCA sent their local updates to the master and received back the merged global update from the master, only the main thread in the workers was active and all other threads were idle. Though there has been academic research such as [21] on making MPI communications multi-threaded taking advantage of OpenMP threads available within the same task, the research has not been incorporated in the standard MPI implementations. This inherent drawback hindered Hybrid-DCA to take full advantage of all the cores available. The second drawback was the way we implemented asynchronous inter-node data transfers in Hybrid-DCA for . In the absence of a collective operation for receiving updates from only a subset of all workers in the standard MPI implementation, we implemented such a collective operation using primitive MPI “send and receive” operations that lacked the performance improvement of CoCoA＋ that utilized the optimized MPI collectives such as MPI_Allreduce.

To mask the effect of the two drawbacks in the MPI, we drew the plots for speedup and proficiency, as shown in the bottom two rows of Fig. 7, after ignoring the time involved in MPI communications. Though CoCoA＋ also received the advantage of ignoring MPI time and showed better performance for datasets rcv1 and webspam, it became totally outperformed by Hybrid-DCA on the sample-heavy kddb dataset. We also observed better performance of asynchronous Hybrid-DCA than synchronous Hybrid-DCA. In summary, as expected theoretically, we see almost the same speedup for a fixed number of total  cores irrespective of individual values of  and . The drop in performance of Hybrid-DCA on  cores could be due to (1) the increase of time taken in an atomic memory update as the number of threads increase, and (2) for higher number of threads the delay bound of local updates may violate the assumption in (16). Both the aspects of atomic memory writes for higher number of threads have been investigated and worked around in a follow-up paper [26] of original PassCoDe paper [7], however, the incorporation of a similar fix in our implementation is out of scope for this paper.


Download : Download high-res image (812KB)
Download : Download full-size image
Fig. 8. Effect of varying  on  worker nodes, with  fixed at 10.

We ignored MPI time for the computation of speedup and proficiency only for the experiments described in the section, for the experiments elsewhere we do include MPI time while measuring the wall time.

5.7. Effects of the parameter 
Fig. 8 shows the results of varying  with fixed  on  nodes each with  cores. When , only a minority of the workers contributed in a round and the duality gap did not progress smoothly below some certain level. On the other hand, when at least half of the workers contributed in each round, it was possible to achieve the same duality level obtained using all the workers. However, the reduction in time per round was eventually eaten by the larger number of rounds required to achieve the same duality gap. Nevertheless, we will see in a later section that the approach was useful for HPC platforms with heterogeneous nodes, unlike ours, where the waiting for updates from all workers had larger penalty per round, or for the case, where the need was to run for a specified number of rounds and quickly achieved a reasonably good duality gap.

5.8. Effects of the parameter 
Fig. 9 shows the results of varying  with fixed  on  nodes each with  cores. We did not see much effect of  as the HPC platform used for our experiments had homogeneous nodes. Our experimentation showed that even if we used , the stale value at any worker was for at most  rounds. We expect to see a larger variance of staleness in case of heterogeneous nodes.

5.9. Effects of workload and processing power
When the HPC system had homogeneous nodes, our experimental results showed that asynchronous Hybrid-DCA did not change much when varying  and . To show usefulness of asynchronous Hybrid-DCA on heterogeneous systems, we introduced imbalance in the setup for an experiment on  nodes each with  cores in two different ways: (1) by varying workload and (2) independently varying processing power. To vary workload, instead of distributing the datapoints equally on all  nodes, we loaded one of the nodes heavily by distributing the datapoints in the ratios 1:1:1:10. Similarly, to see the effect of heterogeneous processing speed, we introduced 10 s of delay in one of the nodes.

We compared the performance of synchronous Hybrid-DCA () and asynchronous Hybrid-DCA () in the two imbalanced scenarios as well as on the usual balanced-load, homogeneous-speed scenario by plotting the progress on duality gap across rounds and wall time as shown in Fig. 10. For both scenarios of imbalanced load and heterogeneous speed the performance of synchronous Hybrid-DCA degraded significantly in terms of both across round and across time. However, the asynchronous Hybrid-DCA was able to mitigate the effects of imbalance completely in terms of performance across rounds in both scenarios and across wall time in heterogeneous speed scenario. For imbalanced load, asynchronous Hybrid-DCA was not able to improve performance as the time taken by the heavily loaded node dominated the overall time.

5.10. Performance on a big dataset
We experimented our hybrid algorithm on the big dataset splicesite of size about 280 GB and compared with the previous best algorithm CoCoA＋. Because of the enormous size, the dataset could not be accommodated on a single node and hence PassCoDe could not be run on this dataset. In this experiment, we used the number of global iterations . The results are shown in Fig. 11 where the progress of duality gap across the rounds of communication is shown on the left and across the wall time on the right. To achieve a duality gap of at least 10−5 on 16 nodes, CoCoA＋ took about 165 s. On the other hand Hybrid-DCA on  nodes each using  cores took about  seconds to achieve the same duality gap giving approximately -fold improvement, showing enough evidence about the scalability of our algorithm. One could also argue that CoCoA＋ can be run on all these  cores, treating each core as a distributed node. However, when we experimented with this mode of CoCoA＋, we found that CoCoA＋ did not reach the duality gap 10−5 in a stipulated  rounds. We also experimented CoCoA＋ on  cores treating each core as a node and found out that though it performed better than 16 × 1 cores in the initial few rounds but worse in the later rounds. Moreover, it was outperformed by Hybrid-DCA in terms of both the number of rounds and the time taken even on  nodes each using  cores.

6. Conclusions
In this paper, we have presented a hybrid parallel and distributed asynchronous stochastic dual coordinate ascent algorithm utilizing modern HPC platforms with many nodes of multi-core shared-memory systems. We analyze the convergence properties of this novel algorithm which uses asynchronous updates at two cascading levels: inter-cores and inter-nodes. Experimental results show that our algorithm is faster than the state-of-the-art distributed algorithms and scales better than the state-of-the-art parallel algorithms. The effectiveness of our approach in practical implementations can be increased further by a combination of (1) optimizing overhead of OpenMP threads, (2) incorporating multi-threaded implementation [21] of MPI operation, and (3) fixing the issues of larger delays in atomic memory writes for larger number of threads as given in [26].