Abstract
There is some evidence that labeling schemes as employed for instance in the famous Coffman-Graham algorithm may provide superior worst-case approximation guarantees than purely path- or level-based list schedules in the presence of (delayed) precedence constraints. In 1989, Bernstein, Rodeh, and Gertner proved that this also holds true for their labeling scheme targeting unit execution time tasks on a single processor provided that all delays imposed by a single task on all of its successors are uniformly either zero or some fixed positive integer. They further conjectured that this superiority is preserved when allowing the delays imposed by a task to differ successor-wise. It is shown in this note however that their labeling scheme as well as more general ones may perform as bad as any list schedule in this case. Moreover, a new lower bound on the worst-case performance of labeling methods in the multiprocessor setting is derived.

Previous articleNext article
MSC
68W25
68W40
90B35

Keywords
List scheduling
Worst-case approximation analysis
Coffman-Graham algorithm
Pipeline scheduling

1. Introduction
Let  be a set of tasks and let 
 denote the non-negative processing or execution time of each task . We consider the problem of scheduling the tasks  subject to delayed precedence constraints so as to minimize the makespan. In this setting, we are given a partial order ≺ resembling tasks dependencies each of which is accompanied by a delay or latency. More precisely, if  and  then the associated delay 
 imposes that if i starts at some time , then j can start no earlier than at time 
. We will employ this more general notation whenever applicable although the focus will be on the case of unit execution times (UET), i.e., 
 for all .

In the three-field-notation proposed in [12], the problem under consideration is denoted as 
. It is known to be NP-hard if the delays 
 can be arbitrary non-negative, even on a single processor [8], [13]. It remains NP-hard even if all delays are fixed to some positive integer,1 and if the precedence relationships form a chain [25] or a bipartite graph [17].

Delayed precedence constraints arise for instance from the pipelined structure of real-world processors implementing one particular form of instruction-level parallelism. Therefore, the problem and algorithms to solve it have been intensively studied in this context (see e.g. [2], [3], [8], [13], [21], [22], [24]), albeit not as intensively as in the related settings without delays or with communication delays.

The major focus in this note is on so-called labeling methods that strongly relate to (or are even derived from) the famous Coffman-Graham algorithm [7] and that are specialized list scheduling techniques to be precisely defined in Sect. 2. One reason for this focus is that there is some evidence for the superiority of labeling methods compared to other list scheduling algorithms as will be discussed more comprehensively in Sect. 3.

As one example that is not entirely resolved so far, Bernstein, Rodeh and Gertner show in [3] that, if each single task can impose only a delay of zero or some fixed integer  on all of its successors, then the makespan of any schedule derived with their labeling method is at most 
 
 times larger than the makespan of an optimal schedule. This is a bit better than the tight ratio of 
 
 achieved in this setting by arbitrary and “critical path”-oriented list schedules [3] to be described in Sect. 2.2. Moreover, the authors also argue that this superiority is preserved if the delays zero or L a task imposes may differ successor-wise. They further left as an open question whether the superiority even extends to the case where more general delays 
 are allowed.

In this note, the suggestion mentioned first is however disconfirmed. To this end, an instance is given where, for any fixed , each task imposes only (both) the delays 0 and L on its successors, and such that the labeling by Bernstein, Rodeh and Gertner from [3] as well as the one used in the Coffman-Graham algorithm may lead to a solution whose quality approaches the bound of 
 
 times the optimum. That is, as soon as delays are allowed to differ successor-wise, these labelings may be as bad as with an arbitrary list schedule which then also extends to delays 
. Moreover, due to the structure of our instance, the bound of 
 
 also extends to some further list scheduling variants that refine their list order based on predecessor or successor counts.

Finally, the worst-case approximation ratio of labeling methods in the multiprocessor setting is investigated. In all conscience, it appears to be unknown whether the upper bound of 
 
 proved in [21], [24] for arbitrary list scheduling on  processors can be improved for labeling methods. Also, a lower bound on the worst-case approximation guarantee of labeling methods appears to be unknown. Here, we provide an instance together with the corresponding analysis that induces a lower bound of 
 
 for .

The outline of this manuscript is as follows: In Sect. 2, we briefly classify general, level-based, and labeling-based list scheduling algorithms in the presence of delayed precedence constraints. We then give an overview of the prior and novel approximation results for these techniques in Sect. 3. Sect. 4 deals with a worst-case analysis of the introduced labeling methods proving the announced new results on their approximation guarantees. We close with a conclusion (Sect. 5).

2. Latencies, lists, levels and labels
In order to formally define the extensions of list scheduling and some of its specializations to the case of delayed precedence constraints, let us first denote an instance I of problem 
 by the triple ≔. We will also employ the common directed acyclic graph (DAG) representation of an instance. In such a DAG , the vertices V model the set of tasks , and there is an arc  with weight 
 whenever . We will identify each task with its representing vertex without explicit distinction. Moreover, we denote the set of successors of a vertex  by , and by 
⁎
 the set of immediate (i.e., non-transitive) successors of . If  for some  then i will be called a sink. Finally, a task  will be called ready at time t, if 
 for all , , where  denotes their respective starting times.

It is worth mentioning that the referenced literature mainly deals with three different forms of pipeline latencies or delayed precedence constraints, namely that either the same latency applies to all task dependencies, or that latencies may differ but still a single task imposes the same latency to all of its successors, or finally that each task may impose an individual latency to each of its successors. The prescribed DAG model associating latencies to edges clearly captures the last variant that generalizes on the former ones (that correspond to the restriction of either all arcs leaving a single vertex or of even all arcs of the DAG to have the same weight).

2.1. List scheduling
Since the algorithmic frame of a (general) list scheduling approach as proposed by Graham in [10] is well-known, its description is kept brief here. Given an ordered list  of , it operates as follows:

1.
If , terminate.

2.
Let t be the earliest time unit such that a task is ready at t and a processor is idle.

3.
Remove the first ready task from , and assign it to the idle processor that has the smallest index with starting time t. Go to step 1.

2.2. Level-based list scheduling, critical-path list scheduling
An important refinement of the general list scheduling algorithm is to order the list  based on levels of the tasks in terms of the DAG .

While there are several possible level definitions, we here concentrate on those related to critical paths, employed most prominently in Hu's Highest Level First (HLF) [14] algorithm for UET tasks and, its natural generalization to arbitrary processing times, Highest Level First with Estimated Times (HLFET) [1]. We will call the following straightforward further extension to integrate delays into the level map 
 a CP-leveling:

1.
Set 
 for all sinks , and mark all other vertices as “unleveled”.

2.
Let 
 be the set of unleveled vertices whose successors have all been leveled. For each 
, set its CP-level to 
.

3.
Go to step 2 unless all vertices are leveled.

4.
Create a task list  in non-increasing order w.r.t. h.

5.
Perform a list schedule using .

Moreover, in [3], Bernstein, Rodeh, and Gertner propose a leveling 
 that neglects the (unit) processing times and restricts attention to immediate successors only. While the authors assumed vertex-based latencies, an according variant generalized to edge-based latencies is to initialize 
 for all sinks  in step 1, and to calculate 
⁎
 in step 2. We will refer to this alternative as a BRG-leveling.

2.3. Label-based list scheduling
While in general several vertices of a DAG  may be assigned the same level, labeling methods assign a unique label to each task. The most prominent labeling method is the Coffman-Graham algorithm [7] for UET tasks and  processors. The corresponding CG-labeling  where ≔ is defined as follows:

1.
Initialize the labels  of all  to “unlabeled” and set .

2.
Let 
 be the set of unlabeled vertices whose successors have all been labeled. Compute for each 
 the set 
⁎
. Sort the values in each 
 such that they appear in decreasing order.

3.
If 
, find a task 
 such that 
 is lexicographically minimum. Set , , and go to step 2 unless all vertices are labeled.

4.
Create a task list  in decreasing order of the labels λ.

5.
Perform a list schedule using .

It is apparent that a CG-labeling does not take delays into account. One way to incorporate these is proposed again by Bernstein, Rodeh, and Gertner in [3]. Their alternative that we refer to as a BRG-labeling 
 is defined as follows:

1.
Compute the BRG-level 
 for all . This partitions V into subsets 
, , such that for all 
 one has 
.

2.
Initialize the labels 
 of all  to “unlabeled” and set .

3.
Let r be the smallest index such that 
 has some unlabeled vertex, and suppose that the labels 1, 2, …,  have been assigned so far. For each job 
 whose immediate successors 
⁎
 have all been labeled, compute 
⁎
. Sort the values in each 
 such that they appear in decreasing order.

4.
Find a task 
 such that 
 is lexicographically minimum. Set 
, , and go to step 3 unless all vertices are labeled.

5.
Create a task list  in decreasing order of the labels 
.

6.
Perform a list schedule using .

It can be immediately observed that a BRG-labeling is a refinement of a BRG-leveling, and that a BRG-labeling is also a valid CG-labeling.

3. Approximation guarantees for labeling methods
As already indicated in the introduction, there is some evidence that labeling methods can provide a superior worst-case performance compared to purely level-based or even arbitrary list schedules.

In the absence of delays (problem 
) for example, the labeling algorithm by Coffman and Graham [7] is optimal for , and for  it has a worst-case approximation guarantee of 
 
 [4], [11], [20].2 As opposed to that, the one for critical-path schedules is 
 
 for  [6] and lies within 
 
 
 for  [5], [16], [18], [21], while arbitrary list schedules may even approach a quality of 
 
.

In the presence of delays, there are three superiority results for single processor scheduling: Firstly, if each precedence has an associated delay of one (
), Finta and Liu [8] showed that a CG-labeling is optimal even for arbitrary processing times. Secondly, for UET tasks and 
, Bernstein and Gertner [2] show that an optimal schedule is obtained when adapting the CG-labeling to be derived from the sets 
⁎
 instead. As opposed to that, BRG- and CP-levelings (and thus also arbitrary list schedules) may approach a worst-case approximation bound of 
 
 for UET tasks in both cases (the instance employed in [3] to show this for BRG-levelings perfectly applies also for CP-levelings). Thirdly, for UET tasks and 
 where , and if all delays imposed by a single task on each of its successors are uniform, Bernstein, Rodeh and Gertner [3] show that their BRG-labeling achieves a worst-case approximation ratio of 
 
. Once more, the aforementioned instance in this reference shows that BRG- and CP-levelings as well as arbitrary list schedules may approach the worst-case approximation bound of 
 
 in this special setting.

In the conclusion of [3], Bernstein, Rodeh and Gertner argue that the superiority of the BRG-labeling could also be generalized to the case where the delays a task imposes on its successors are allowed to differ. Further, they left open whether the superiority even extends to the case where arbitrary delays 
 are allowed.

In the next section it is however shown that schedules produced by the BRG-labeling can approach the general list scheduling bound of 
 
 for delays 
, , as soon as delays are allowed to differ successor-wise. Consequently, in this case, the superiority of the BRG-labeling compared to level-based and more general list schedules does also not extend to arbitrary positive delays from the set .

For UET tasks, latencies from  and  processors, Palem and Simons [24] showed that the approximation ratio of any list schedule is no worse than 
 
. The same upper bound was also proven by Lawler et al. [21] for the case where all tasks impose the same latency on all their successors. Of course, this translates also to an upper bound for CP- and BRG-levelings, as well as for CG- and BRG-labelings. On the lower bound side, an instance class from [21] can be used to show that CP- and BRG-levelings (and thus also arbitrary list schedules) may attain a worst-case performance of 
 
.3 Lower bounds for BRG-labelings (or CG-labelings in the presence of delays) are, in all conscience, yet unknown for the multiprocessor case. Here, we provide an instance and its corresponding analysis in the next section showing that a BRG-labeling may induce a schedule with a makespan of 
 
 times the optimum. As pointed out in Sect. 2.3, this bound extends also to CG-labelings as well as BRG-levelings, and already due to the instance structure, it also extends to CP-levelings.

For a comprehensive overview beyond the list scheduling variants studied here, the corresponding taxonomy, and references to more complexity and approximation results, we refer the interested reader to the two surveys by Kwok and Ahmad [19], and Fujita and Yamashita [9].

4. Worst-case analysis
We first consider exactly the problem studied by Bernstein, Rodeh and Gertner in [3], i.e., a single processor and delays 
 for an arbitrary  – except that the delays are here defined arc-based instead of vertex-based. This precisely reflects the difference that the delays a task imposes on its successors may be non-uniform.

Theorem 4.1

If arc-wise different delays are permitted, the worst-case approximation ratio of a list schedule based on a BRG- or CG-labeling for problem 
, , is at least 
 
, i.e., no better than in the case of general list scheduling.

Proof

The proof is carried out by describing a corresponding worst-case instance4 that is made up of complete bipartite subgraphs (when ignoring arc directions) as depicted in Fig. 1. We will refer to the respective vertex partitions as “rows” of the instance. They also correspond to its CP- or BRG-levels. The precedence and delay structure is such that each task is a predecessor of all tasks in the subsequent row, while every black arc (downward or rightward) refers to a delay of L and every gray arc (leftward) refers to a zero delay.

Fig. 1
Download : Download high-res image (618KB)
Download : Download full-size image
Fig. 1. Structure of the instance I employed in Theorem 4.1.

For a scaling parameter , consider the instance I consisting of  rows. Since each row consists of  tasks, I has  vertices in total.

To construct a worst-case CG- and BRG-labeling 
⁎
, we proceed as follows: The labels of the sink vertices may be assigned freely, so we choose them as 
⁎
, 
⁎
, …, 
⁎
. Since each vertex in the k-th row is connected to all vertices in the final one, we have 
 for all 
. As hence all of these sets are lexicographically equal, we may again choose the labels in row k arbitrarily, and set them in the same manner as in the last one. By applying this scheme to each row, we obtain a complete labeling 
⁎
.

Now if the vertices are scheduled using a list  ordered decreasingly w.r.t. 
⁎
, there will be exactly L idle cycles after each row. This is because each vertex in row  has an L-weighted arc to every vertex in row  with a right-or-equal position, and 
 – which is the only task imposing a delay of L on all vertices in row  – is always scheduled last. Let us denote the corresponding makespan as 
.

However, the instance is such that in any row j, the numbers of successors in row  with delay L decrease monotonically from left (
, ) to right (
, 1). So if we reverse the λ-order of each row starting with the sinks, then in each row , after first scheduling 
, the other L tasks 
 to 
 (all imposing zero delay to 
) exactly cover the delay of L until 
 is ready. Also 
 and the tasks 
 to 
 cover exactly the delay of L between 
 and 
, and so on. Hence, an optimal schedule without any idle cycles results whose makespan we denote as 
.

We now evaluate the ratio between both schedules in the same way as in [3]:
 
 
 
 

The last equation holds since . By increasing the number of levels k, we obtain: 
 
 
 
 □

Remark 4.1

This proof works also for  and is still no contradiction to the optimality result for  by Bernstein and Gertner [2] as a different lexicographical criterion is used there. Conversely, this criterion cannot be straightforwardly extended to the case of arbitrary positive L.

Corollary 4.1

If arc-wise different delays in , , are allowed, the worst-case approximation ratio of a list schedule based on a CG- or BRG-labeling is no better than the general list scheduling ratio of 
 
.

Corollary 4.1 follows directly from Theorem 4.1 as the latter considers a special case. For BRG-level-based list scheduling, the same lower bound is known from [3], and it applies as well to CP-levels due to the instance structure used there.

Moreover, since the instance I in the proof of Theorem 4.1 consists of uniformly oriented complete bipartite subgraphs, the result also extends to any other level-based list scheduling algorithm where the levels are computed as a combination of critical-path lengths and the numbers of predecessors or successors of a task. An example is the CP/MISF (most immediate successors first) method [15].

For multiple processors, we have the following result.

Theorem 4.2

The worst-case approximation ratio of a list schedule based on a BRG- or CG-labeling for problem 
, , and  processors, is at least 
 
, even in the special case where all delays are equal to L.

Proof

To show that the bound holds even if only delays L are used, we employ a composition of our previous ideas with an instance presented in [4]. The corresponding instance I has  “A”-vertices and two “B”-vertices per row, as indicated in Fig. 2. Moreover, for a scaling factor , it is supposed to have  rows (again equivalent to BRG- as well as CP-levels), and thus  tasks in total. The precedence structure is as follows: In each row , task 
 precedes all tasks 
, , and also task 
. All the other tasks in row  only precede task 
.

Fig. 2
Download : Download high-res image (567KB)
Download : Download full-size image
Fig. 2. Structure of the instance I employed in Theorem 4.2.

To construct a worst-case CG- and BRG-labeling 
⁎
, suppose that the sinks are labeled increasingly from right to left, i.e., 
⁎
, …, 
⁎
, 
⁎
. Then, 
 while the Ω-sets of all other vertices in row  only contain the single value . Thus, all the latter are lexicographically equal, and larger than 
, so we can repeat an increasing labeling from right to left until the whole instance is labeled. If the tasks are then scheduled on m processors using a corresponding list, each row  will occupy  time units ( dense ones and one where only the tasks 
 and 
 are scheduled). Moreover, each of the first  rows is followed by L idle cycles since 
 precedes all tasks in row  except 
 (in particular, 
), and 
 precedes 
. The sustained makespan is denoted as 
.

On the other hand, when labeling the sinks increasingly from left to right, we have 
 while all the other vertices in row  have Ω-sets containing only the value 1. Thus the left-right-increasing labeling can as well be continued row-by-row. Creating a corresponding list , the tasks are scheduled in a dense fashion on m processors from right to left, starting with 
 and ending with 
 in each row j. The optimum makespan is denoted as 
.

We hence have the ratio:
 
 
 
 
 which approaches 
 
 for . □

5. Conclusion
We answered in the negative the open question whether on a single processor the labeling proposed by Bernstein, Rodeh and Gertner [3] leads to superior list schedules compared to other techniques when confronted with arc-wise different precedence delays of zero or a fixed positive integer L. To the contrary, for problem 
, and delays , the worst-case performance is bounded from below by 
 
, i.e., no better than in the case of general list scheduling. Moreover, for 
, , the worst-case performance is bounded from below by 
 
 for  processors, even if all delays imposed are equal to L.

CRediT authorship contribution statement
Sven Mallach: Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Resources, Validation, Visualization, Writing – original draft.