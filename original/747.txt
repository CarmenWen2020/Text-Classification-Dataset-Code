Abstract
Record Linkage (RL) is the task of identifying duplicate entities in a dataset or multiple datasets. In the era of Big Data, this task has gained notorious attention due to the intrinsic quadratic complexity of the problem in relation to the size of the dataset. In practice, this task can be outsourced to a cloud service, and thus, a service customer may be interested in estimating the costs of a record linkage solution before executing it. Since the execution time of a record linkage solution depends on a combination of various algorithms, their respective parameter values and the employed cloud infrastructure, in practice it is hard to perform an a priori estimation of infrastructure costs for executing a record linkage task. Besides estimating customer costs, the estimation of record linkage costs is also important to evaluate whether (or not) the application of a set of RL parameter values will satisfy predefined time and budget restrictions. Aiming to tackle these challenges, we propose a theoretical model for estimating RL costs taking into account the main steps that may influence the execution time of the RL task. We also propose an algorithm, denoted as , for evaluating the feasibility of RL parameter values, given a set of predefined customer restrictions. We evaluate the efficacy of the proposed model combined with regression techniques using record linkage results processed in real distributed environments. Based on the experimental results, we show that the employed regression technique has significant influence over the estimated record linkage costs. Moreover, we conclude that specific regression techniques are more suitable for estimating record linkage costs, depending on the evaluated scenario.


Keywords
Record linkage
Theoretical model
Data quality
Cloud computing

1. Introduction
Record linkage (also known as deduplication, entity resolution and entity matching) is the task of identifying entities (e.g., people, companies or digital objects) in a dataset (or multiple datasets) that refer to an identical real-world object. This problem is often originated by database integration tasks, input errors and the usage of heterogeneous schemes for representing real-world objects [7]. An RL task becomes particularly challenging when datasets get large, since a naive solution for this problem involves the comparison between each entity with all other entities of the dataset, which leads to a quadratic complexity with respect to the size of the dataset.

Many works have investigated different approaches for speeding up solutions for RL tasks. One of these approaches, denominated indexing, consists in identifying entities that share a similar property1 based on the value of predefined functions (often called blocking key functions). For doing so, it is possible to employ one (single) or more (multiple) blocking key functions. After this step, the indexing techniques limit the comparison between entities that share at least one common property. The most known indexing techniques [7] are Blocking, Sorted Neighborhood and Canopy Clustering. In practice, since the indexing phase is responsible for determining the amount of comparisons between entities to be performed in the comparison phase, the efficacy of the employed indexing technique (and its respective parameter values) has a strong influence over the record linkage costs.

In turn, several works [15], [16], [20], [25] have investigated how to parallelize the execution of RL tasks using a distributed environment. These works usually employ consolidated frameworks, such as Hadoop [11] and Spark [2], and/or cloud computing capabilities in order to allocate virtual machines on-demand to meet predefined Quality of Service (QoS) requirements. Besides dealing with the distribution of the comparisons between entities (usually taking into account the input generated by the indexing phase), these works also tackle problems that are inherent to distributed environments, such as load unbalancing [11], [20], [22]. The experimental results carried out by these works show that an RL task may greatly benefit from cloud computing environments. Also, the execution time of such solutions is quite dependent on the configuration of the employed cloud infrastructure (i.e., the amount and configuration of the virtual machines).

In practice, business managers may prefer to outsource the execution of record linkage tasks to specific cloud services designed to evaluate the quality of data stored in cloud databases, which are denominated Data Quality-aware Services (DQaS) [24]. By using such service, the contracts between the service and its customers are defined using a Data Quality SLA (DQSLA) [25], which specifies: (i) a set of parameters regarding the rules for evaluating the data; (ii) time restrictions associated with the executions of data quality algorithms; and (iii) penalties that may be applied to the service (when the predefined QoS is not respected). In this context, the service customers can be interested in accessing: (i) the estimated cost for executing a record linkage task, given a set of parameter values defined in a DQSLA; and (ii) the feasibility of a set of parameter values for executing a record linkage task, taking into account time and/or budget restrictions associated with the task. These two challenges motivate the investigation addressed in this work.

We offer mainly five contributions in this paper. First, we present practical motivations for estimating record linkage costs. Second, we present an approach to measure record linkage costs. Third, we propose a model for performing theoretical estimations of record linkage costs, taking into account the main steps that may influence the computed costs. Fourth, we present an algorithm that aims to evaluate the feasibility of executing a record linkage task, considering budget and/or time restrictions. Finally, we present an experimental evaluation of the proposed model, using results from real-world datasets, by combining the proposed equations with speedup values predicted by a number of regression techniques.

The rest of the paper is structured as follows. In Section 2, we describe motivations for tackling the investigated problem. In Section 3, we present the notation adopted throughout the paper. In Section 4, we describe an approach for measuring RL costs. In Section 5, we propose a theoretical model for estimating record linkage costs, considering both serial and distributed environments. In turn, in Section 6 we propose an algorithm, denominated , which aims to evaluate the feasibility of a set of parameter values for executing a record linkage task, taking into account budget and/or time restrictions. In Section 7, we present an experimental evaluation of the proposed theoretical model combined with regression techniques for estimating speedup values. In Section 8, we present related works. Finally, in Section 9 we conclude the paper and discuss perspectives for further works. A glossary of the notation adopted in this work is presented in Appendix.

2. Motivation
There are many advantages in outsourcing the execution of data quality tasks for a DQaS. First, instead of implementing a vast amount of data quality algorithms, a company may simply configure a set of parameters for assessing the quality of its data and outsource the implementation complexity to the service. Second, by contracting a DQaS, it becomes easier to scale the execution of data quality tasks over large datasets (Big Data) by means of the cloud computing provisioning capabilities. Third, by using the pay-per-use cloud model, a company may execute data quality tasks on demand according to its budget restrictions.

Following the DQSLA notation proposed in [25], by interacting with a DQaS, the parameters that yield more influence over the record linkage costs are:

•
: the monitored dataset;

•
: the set of parameter values for evaluating the quality of the dataset, including thresholds, rules, algorithms and their respective parameter values;

•
: a time restriction associated with the task execution, which in turn influences the infrastructure that is employed to execute the task.

As shown in Fig. 1, after a DQSLA is settled between the parts, the customer may interact with the DQaS in order to estimate the costs of a record linkage task () and evaluate the feasibility of its execution taking into account time and/or budget restrictions. The cost estimations may need to be performed using only a portion of the dataset (and the metadata of the entire dataset). This scenario may happen either because the customer is not willing to provide full access to the dataset for estimation purposes or because it is cheaper for the service to estimate the costs by processing only a portion of the monitored dataset. We summarize these interactions, along with their respective restrictions, in Table 1. We tackle these challenges in the following sections by proposing a model to perform theoretical estimations of record linkage costs in cloud computing environments. Also, we propose an algorithm for assessing the feasibility of parameter values according to predefined customer restrictions.


Download : Download high-res image (421KB)
Download : Download full-size image
Fig. 1. Overview of the customer interactions with the DQaS.


Table 1. Client interactions with the DQaS regarding cost estimations.

Client interaction
Given my dataset, what is the estimated cost of the task  using the set of parameter values defined in the DQSLA?
Given this sample of my dataset and the metadata of the full dataset, what is the estimated cost of task  using the set parameter values defined in the DQSLA?
Given these time and budget restrictions, is it feasible to execute task  using the set of parameter values defined in the DQSLA?
3. Adopted notation
In this section, we present the notation adopted throughout the paper. Let  be a record linkage task. We represent the set of parameters of the task 2 by . In , we summarize the parameters that yield more influence over the costs of , and thus, we define  as a -tuple in the form 
, such that:

•
 is the dataset (represented by a set of entities) to be processed by the task ;

•
 is the set of blocking key functions employed in order to index 
. The output of the index phase determines the amount of comparisons to be performed in the comparison phase, which is denominated aggregated cardinality ();

•
 is the comparison rule employed to compare the entities in 
 (taking into account the comparisons generated by the indexing phase). In turn, the set  is composed of the similarity functions3 employed to compare attribute values. For instance, if 
, then we could define 
 
, s.t., 
 and 
, 
 and 
 are attributes. It is also possible to define weights for each employed similarity function . Besides, one can use only portions of the entity values to compute similarities (instead of using the entire values);

•
 is the indexing algorithm employed to index 
 using the set of key functions 
. If 
, then 
 needs to be run 
 times in order to index 
. Since an indexing algorithm may have specific parameters (for instance, the size  of the window of the Sorted Neighborhood [8] technique), we denote the set of specific parameters values associated with the indexing algorithm by 
;

•
 is the classification algorithm used to classify the duplicated entities based on the similarity values generated by the comparison phase (which, in turn, takes into account the result of the indexing phase). The classification algorithms may employ threshold- [7], rule- [34], machine learning- [28] or collective classification-based [13] techniques to determine duplicate entities. Similarly to the indexing algorithms, we denote the set of specific parameters associated with a classification algorithm by 
. In order to classify duplicate entities, a classification algorithm may process a similarity graph [12], denoted by 
, which is generated after the comparison phase;

•
 is the set of virtual machines employed to execute . Let 
 be a set of virtual machine configurations. We denote the set of virtual machines employed to execute  as 
, such that  is a virtual machine and  is a machine configuration. If the cloud computing environment defined by 
 is homogeneous (i.e., 
), then we represent 
 by a pair  (i.e., 
 is composed of a set of  virtual machines with configuration ). Note that, using a predefined set , we can generate all possible homogeneous cloud computing environments using the set 
. Finally, we denote the price ($/) of a single virtual machine 
 by .

In Section 4, we present a model to measure record linkage cots based on the notation presented in this section.

4. Measuring record linkage costs
In this section, we employ the adopted notation (Section 3) in order to present a model which measures record linkage costs. The total execution time of a record linkage task is equivalent to the sum of the execution times generated by the indexing, comparison and classification phases, as shown in Eq. (1). (1)

Each one of the execution times presented in Eq. (1) is influenced by the employed algorithms (and their respective parameter values) and the cloud computing environment. Thereby, we can detail the individual execution times generated by the indexing, comparison and classification phases as shown in Eqs. (2), (3), (4), respectively. (2)
(3)
(4)

In Eq. (2), the execution time of the indexing phase is mainly influenced by the employed indexing algorithm (
) and its additional parameter values, the size and characteristics (e.g., the size of the attribute values) of the dataset (
), the set of blocking key functions (
) and the cloud computing environment (
). As stated in Section 3, this phase will determine which pairs of entities must be compared in the comparison phase, and thus, we can derive the aggregated cardinality of the task (). In turn, in Eq. (3), the execution time of the comparison phase is mainly dependent on the amount of comparisons to be performed (output of the previous phase), the employed comparison rule (
) and the cloud computing environment (
). The output of this phase is usually a similarity graph (
) that contains an edge between all pairs of entities that have been compared in the previous phase. Lastly, in Eq. (4), the execution time of the classification phase is mainly influenced by the employed classification algorithm (
), the size and characteristics of the similarity graph (
) and the employed cloud computing environment (
).

Given the total execution time of an RL task shown in Eq. (1), we can derive the overall cost of the task in two scenarios: (i) in Eq. (5), using a single virtual machine with configuration , i.e., 
; and (ii) in Eq. (6), using a cloud computing environment that employs 
 virtual machines with configuration , s.t. 
. (5)
(6)

Thereby, by replacing Eq. (1) in Eqs. (5)–(6), we have: 
 

Note that the cost model proposed in this section is only useful for aggregating RL costs using the real execution time of the task phases. In Section 5, we use the model presented in this section in order to propose a theoretical model for estimating RL costs.

5. Generic model for theoretical estimations of RL costs
In this section, we propose generic approaches that may be employed in order to perform theoretical estimations of record linkage costs. The main goal of the proposed model is to estimate a value 
, given the set of parameter values , without executing the task. Thus, we want to minimize the difference between the real (Eqs. (5)–(6)) and estimated costs, i.e., 
.

In order to properly estimate RL costs, we need to tackle two main challenges: (i) given a set of parameter values, how to estimate the execution time of the individual phases of an RL task executed by a single virtual machine? and (ii) how to measure the influence of a distributed cloud computing environment over the executed phases? Concerning the first challenge, we propose generic theoretical models for estimating each one of the RL phases. In other words, given  and , we need to estimate 
 + 
 + 
, such that 
 is minimized. Thereby, using the estimated execution times, we replace the estimations in Eqs. (5)–(6) to calculate the estimated RL costs (
). In turn, regarding the second challenge, we propose the usage of a function to estimate a speedup value based on the employed algorithm and the cloud computing environment. The aim of the proposed function is to quantify the influence of distributed environments (
) over the executed phases.

5.1. Estimating indexing costs (serial environment )
In order to estimate the indexing costs, we need to consider the time required for reading the dataset and executing the indexing algorithm. The reading phase is dependent on the size, the virtual machine configuration and the data access approach.4 In turn, the execution time of the indexing algorithm is influenced by the size and characteristics of the dataset as well as by the employed set of blocking key functions. Both steps present an inherently linear complexity with respect to the size of the dataset. Therefore, a possible approach to estimate indexing costs is to execute small subtasks and then extrapolate their costs based on the size of the full dataset.

Let 
 be the dataset to be processed by the task  and 
 be a random subset of 
, such that 
 
. In Eq. (7), we present a model for estimating the execution time of the indexing phase (
) using a single virtual machine 
. It is noteworthy that the time required for executing additional steps required by the indexing algorithm, such as the generation of blocks (performed by Blocking approaches [7]) or the sorting of the blocking key values (performed by Sorted Neighborhood-based approaches [21]) is considered in the execution time of the subtask reported by 
. (7)

We can simplify Eq. (7) (aiming to reduce estimation costs) by assuming that the costs to execute the employed indexing algorithm are approximately equal for all blocking key functions. Based on this assumption, we can simplify Eq. (7) as shown in Eq. (8). (8)
 
 

Note that the higher the employed value of , the more accurate becomes the estimation and the more costly becomes the generation of the input data required for the model (i.e., the costs of executing 
 and 
). Thus,  must be tuned according to these two competing objectives (i.e., estimation accuracy and estimation costs).

5.2. Estimating aggregated cardinality
Some works [7], [8] have investigated how to estimate the amount of comparisons to be performed by an RL task, taking into account the employed indexing algorithm, its respective parameter values, the set of blocking key functions and the size of the dataset. Following [8], if we assume that the entities are uniformly distributed amongst the blocks generated by the Standard Blocking technique [7], then we can calculate the estimated aggregated cardinality (
) as: 
 
 
, such that  is the amount of blocks generated by a single blocking key function. Similarly, we can estimate the aggregated cardinality by the (fixed window size) Sorted Neighborhood technique [8] as: 
 
, such that  is the pre-configured fixed window size.

If multiple blocking key functions are employed (i.e., ), then these calculations have to be aggregated for each employed blocking key function. In [8], the authors also investigate theoretical estimations of aggregated cardinality assuming a predefined distribution of the entities in the dataset, such as Zipf. Thus, one can either assume an approximately uniform distribution of the entities amongst the blocks or evaluate the distribution of the entities in the dataset in order to estimate the generated aggregated cardinality.

5.3. Estimating comparison costs (serial environment)
The estimation of costs generated by the comparison phase can be performed using the aggregated cardinality of the task (
) and the cost () of comparing a pair of entities from 
. Hence, in Eq. (9) we present an approach for estimating the time required to execute the comparison phase, i.e., the estimated amount of comparisons to be performed multiplied by the cost of comparing a single pair of entities using a virtual machine 
. In turn, in order to calculate , we need to measure the time required to compute the similarity between a pair of entities in 
, taking into account the comparison rule 
, as shown in Eq. (10). (9)
(10)

Note that the execution time required to compute 
 using  may vary significantly depending on the employed pair of entities. This is explained by the fact that the size and characteristics of the attribute values in the dataset may vary considerably. For this reason, aiming to improve the accuracy of the model, we may use a random set of  entities (
, s.t. 
 and 
) from 
 to compute the similarity costs (instead of using a single pair of entities), as shown in Eq. (11). (11)
 

5.4. Estimating speedup (distributed environment)
The models for estimating execution time proposed in Sections 5.1–5.3 are associated with a serial environment, i.e., when 
. As discussed in Section 5, one of the challenges of performing theoretical estimation of RL costs consists in measuring the influence of a distributed cloud computing environment over the total RL execution time. In practice, the execution of a task in a distributed environment is influenced by network delays and/or the load unbalancing problem [11], [20], which is caused when the subtasks are not distributed evenly amongst the virtual machines. For these reasons, we measure the efficacy of a distributed execution using the speedup metric [11].

In order to estimate the execution time of an RL task in a distributed environment, we propose the usage of a function (
) for estimating speedup. Let 
 be a function employed to estimate the speedup result generated by the execution of an algorithm 
, using the parameter values (
) and employing a cluster 
, such that 
.

Using a function 
, we can estimate the execution time of the indexing, comparison and classification phases of an RL task in a cloud computing environment as shown in Eq. (13), Eq. (15) and Eq. (17), respectively. (12)
(13)
 
(14)
(15)
 
(16)
(17)
 

6. Feasibility of RL parameters
In this section, we propose an algorithm to evaluate the feasibility of a set of parameter values for executing an RL task using a specific cloud computing environment, taking into account predefined time and budget restrictions. The proposed algorithm, named evaluator of Time and Budget Feasibility of  (), is presented in Algorithm 1. The algorithm receives as input an RL task () to be executed, a set of candidate parameter values for executing , a cluster configuration (
) and time (
) and/or budget (
) restrictions.

The  algorithm works as follows. An initially empty map () is created for storing the viable sets of parameter values (line 2). Then, for each received set of parameter values  (line 3): (i) the estimated execution time of  is theoretically estimated in line 6 (serial environment) or in line 9 (distributed environment); (ii) the estimated execution time of  is used to compute the estimated cost of the task (line 11); (iii) the algorithm checks the feasibility of the parameter values regarding the time (line 14) and budget (line 17) restrictions; and (iv) if the configured restrictions are met (line 20), then the set  is added (line 21) to the  as a feasible set of parameter values along with the estimated cost generated by .


Download : Download high-res image (376KB)
Download : Download full-size image
Note that the efficacy of the proposed  is strongly tied to the accuracy of the theoretical estimations performed in lines 6 and 9. For this reason, in this paper we evaluate a number of different approaches for implementing a function (
) to estimate proper speedup values (Section 5.4).

7. Evaluation
In this section, we evaluate five different techniques for implementing a function (
) to estimate speedup results. Based on the estimated speedup, we can estimate the RL execution time based on Eqs. (13), (15) and (17). In this paper, we employ regression techniques [30] to implement the function 
 (Section 5.4). To this end, we generated a training set in the form 
 (see Section 5.4) and then employed the regression techniques to estimate the speedup result to be employed in the theoretical model.

We explore the following regression techniques: REP Tree [35]: a fast decision tree learner which uses information gain /variance and prunes it using reduced-error pruning (with backfitting); SMO Regression [32]: a support vector machine-based approach for regression; Multilayer Perceptron [3]: a classifier that employs backpropagation to classify instances; Gaussian Processes [10]: a regression technique that considers  observations in an arbitrary dataset as a sample from some multivariate (-variate) Gaussian distribution; and Linear Regression [30]: a regression technique that aims to generate a best-fitting straight line through the points by minimizing the residual sum of squares.

As a baseline, we employed the machine learning model Random Forest (RF). This model has been chosen mainly because it has produced the best result regarding the tradeoff between estimation accuracy and the number of SLA violations, according to the state-of-the-art results presented in [25].

7.1. Implementation and metrics
We have implemented the predictive regression models for estimating speedup results using the WEKA [35] Java API. To evaluate them, we consider the accumulated percentage error between the predicted RL execution time (using the estimated speedup) and the real RL execution time. This metric is defined as follows.

Let 
 be a set of record linkage tasks, 
 be the real execution time of task  and 
 be the estimated execution time of task  using the estimated speedup value. Based on this notation, the accumulated percentage error is formalized in Eq. (18). (18)
 

Intuitively, the smaller the  generated by the regression model, the more precise are the speedup values estimated by the predictive model.

7.2. Datasets and configuration parameters
We have generated three training sets based on Block Slicer [19], a state-of-the-art algorithm for distributed execution of record linkage tasks using Standard Blocking. This algorithm tackles load balancing by slicing large blocks into several match tasks using a greedy optimization approach. Also, we used execution time results produced by Block Slicer using two consolidated distributed frameworks: Hadoop and Spark. Hadoop is the most popular implementation of the MapReduce programming model [21]. In turn, Spark is a MapReduce-based engine built with a focus on efficiency and complex data analysis [2].

In the Spark environment, we utilized two real-world datasets.5 The first dataset DS1 is a sample of the Ask’s database that contains about 214,000 question records. The second dataset, DS2, is by an order of magnitude larger and contains about 1.46 million publication records. In turn, in the Hadoop environment, we also employed dataset DS2.

To generate the ER results in the real distributed environments, we compared the attribute values using the Jaro–Winkler function [7]. In turn, for DS1, we compared the description of the questions. For DS2, we considered the publication titles.

Each virtual machine employed in the experiments runs the Linux operation system and it presents the following configuration: CPU 2.2 GHz; 4 GB of RAM; and 1 TB of hard disk. According to the number () of virtual machines in the distributed environment, we configured  and  map and reduce tasks for executing the RL process, respectively. For each framework (Hadoop and Spark), we considered the execution times generated by 20 RL tasks (varying the number of virtual machines). Finally, we have employed Apache Hadoop version 2.7 and Apache Spark version 2.4.

7.3. Evaluation scenarios
We used the training sets combined with the evaluated regression techniques for predicting speedup values (Section 5.4) and then employed the proposed theoretical model (Eqs. (12)–(17)) to estimate the execution times of the record linkage tasks. For doing so, we consider two evaluation scenarios:

•
Scenario A: we assume an accurate estimation of the number of comparisons to be executed in the comparison phase. This scenario may occur when we employ an indexing technique that allows an a priori calculation of the number of comparisons, such as Sorted Neighborhood with fixed window size [8]. This estimation is also accurate if the entire dataset may be indexed in the evaluation phase (see Fig. 1);

•
Scenario B: we assume an inaccurate estimation of the number of comparisons to be executed in the comparison phase. This scenario may occur when we employ an indexing technique that does not allow an a priori calculation of the number of comparisons, such as adaptive Sorted Neighborhood [21]. Furthermore, this estimation may also be inaccurate when the entire dataset is not available to be indexed in the evaluation phase (see Fig. 1).

7.4. Results
We present the results generated by the regression techniques in the Spark environment in Fig. 2, Fig. 3, Fig. 4. In turn, the results generated by the regression techniques in the Hadoop environment are depicted in Fig. 5, Fig. 6.

7.5. Discussion
First, note that the regression techniques have produced significantly different efficacy results, depending on the evaluated scenario. Hence, a proper choice of a regression technique for estimating speedup results is an important task to estimate record linkage costs in distributed environments.

Considering Scenario A (Fig. 2, Fig. 4, Fig. 6), note that the techniques SMOReg, Linear and MLP have generated better efficacy results than the other evaluated approaches. Moreover, the approaches SMOReg, Linear and MLP have increased the  linearly with respect to the number of estimations. On the other hand, in Scenario A, the approaches GP and REPTree have augmented the  quadratically with respect to the number of estimations.

More specifically, both the approaches SMOReg and Linear were able to estimate highly accurate speedup values, especially when dealing with the results from the Spark environment. Therefore, these approaches are more suitable to be employed for predicting record linkage costs when the number of comparisons to be performed is accurately predicted.

In turn, regarding Scenario B (Fig. 3, Fig. 5, Fig. 7), the REPTree and GP have produced superior efficacy results than the remaining approaches. In practice, this result is explained by the fact that the former approaches tend to estimate higher speedup results, and thus, they are more suitable when the number of comparisons to be performed is not accurately predicted. The difference between the  results generated by the regression techniques is more significant when we employed the DS1 dataset in the Spark environment and assumed Scenario B (Fig. 3).

Comparison with baseline. In the great majority of the evaluated scenarios, the regression techniques outperformed the baseline machine learning model (Random Forest). RF has produced satisfactory estimations when dealing with Scenario B (Fig. 3, Fig. 7). Nevertheless, considering the accurate estimation of the number of comparisons (Scenario A), the regression techniques have produced better accuracy than RF. This behavior is best explained by the fact that the regression techniques are able to estimate speedup results different from the existing speedup results in the training set. This is accomplished by combining or aggregating the available speedup results in the training set. For this reason, we conclude that the regression techniques can adapt the estimations effectively for a variety of estimation scenarios.

8. Related work
The estimation of the costs generated by tasks executed in cloud computing environments is very useful for tackling challenges such as maintenance and automatic provisioning of cloud services. In turn, these features are employed to guarantee predefined customer QoS, taking into account models for pricing [1] and capacity planning [27]. In this context, many models have been proposed in order to tackle specific classes of cloud-related problems, such as cloud-based dataflow [6], query dispatching and scheduling in cloud databases [33], service selection [18], cloud simulation [4], [5], maximization of energy efficiency [17], evaluation of security costs [26] and cloud elasticity [29], [31]. In [4], the authors propose a theoretical model to estimate the processing capacity of cloud computing environments that is used by a tool to simulate task executions, network behavior and power consumption of a server. In [17], two task consolidation heuristics are proposed in order to maximize resource utilization and energy efficiency, taking into account active and idle energy consumption. The authors of [31] propose a cost-aware provisioning model that aims to minimize the transition time for new configurations and the costs by optimizing the virtual server configurations. These objectives are formulated as optimization problems and tackled using an integer linear programming solution.

In turn, the authors of [18] propose a theoretical model to tackle the selection of appropriate cloud computing services offered by different providers. Their proposed solution is based on a decision function that takes into account the risks associated with aspects such as integrity, confidentiality and availability. The authors of [9] propose a generic simulation framework that can be instantiated to capture the dynamics of diverse data grid protocols. Their framework also provides simulation and machine-learning techniques, which are employed to capture the dynamics of the data-exchange layer across the cache servers. In [14], the authors design a simulated cloud monitoring framework, which can collect performance information of simulated clouds, provide ranking information regarding resource consumption and detect anomalous behaviors in real-time. Note that the works conducted in [4], [9], [14], [17], [18], [31] propose models for investigating other cloud computing problems. Our work is similar to those proposed by [4], [9], [14], [17], [18], [31], since we also investigate a cloud-related problem associated with the estimation of task costs executed in a cloud computing environment. However, we propose a specific theoretical model for estimating costs generated by RL solutions executed in cloud computing environments.

Task-related models have been investigated in [6], [26], [33]. In [33], the authors investigate a model for tackling query-related QoS in cloud databases using cloud elasticity, which supports unpredictable workloads and uses information about query interactions. In [6], two algorithms are proposed to tackle a cloud-based data flow, which aims to minimize the costs of intermediate storage of datasets in cloud computing environments. The work conducted in [26] proposes a multi-level security model, which uses the distribution of partitioned workflows upon hybrid clouds, taking into account predefined security requirements to be met. Our work is similar to those conducted in [6], [26], [33] because we also propose approaches for modeling solutions related to specific tasks executed in cloud computing environments. Nevertheless, we investigate a different problem (estimation of RL costs in cloud computing) and propose solutions based on theoretical and sample-based models.

Simplified theoretical models for estimating RL costs have already been used in the experimental evaluations conducted in [23], [25] to evaluate machine learning-based provisioning algorithms. In [23], the authors propose a cost model for aggregating costs of a DQaS, but they adopt a simplified model to estimate the costs of record linkage tasks that considers only comparison costs and random speedup results. In turn, in [25] a theoretical model is proposed to estimate RL costs based on speedup results generated by a linear regression technique. Our work is similar to [23], [25] because we also propose a model for estimating RL costs in cloud computing environments. Nevertheless, our work proposes a much more sophisticated and generic theoretical model than those proposed in [23], [25], since our solution model considers the following aspects of RL costs: (i) reading and indexing costs; (ii) estimation of aggregated cardinality; (iii) classification costs; (iv) comparison rules; (v) multiple blocking keys; and (vi) the parameter values of the employed algorithms. Furthermore, we also tackle the problem of assessing the feasibility of RL parameter values, which is not addressed in [23], [25].

9. Conclusions
In this paper, we have investigated how to perform theoretical estimations of RL costs in the context of a Data Quality-aware cloud Service. The theoretical estimations are useful to provide a preview of the service costs for the customers as well as to evaluate the feasibility of RL parameter values regarding predefined time and budget restrictions.

We have presented a model to measure record linkage costs and then proposed generic approaches for performing theoretical estimations of the costs generated by the RL phases. We have also proposed an approach to measure the influence of a distributed cloud computing environment over the estimated execution times. In practice, the estimated RL costs may be used by a DQaS to execute the proposed  algorithm in order to assess the feasibility of RL parameter values, taking into account predefined customer restrictions.

Since the efficacy of the  algorithm is quite dependent on the accuracy of the theoretical estimations, we have evaluated the efficacy of a number of regression techniques for estimating proper speedup values, to be used in the theoretical model. Based on the experimental results using real-world datasets, we concluded that the regression approaches SMOReg and Linear are more suitable for tackling scenarios in which the number of comparisons to be performed may be accurately predicted. In turn, the approaches GP and REPTree produced superior efficacy results when the number of estimations of comparisons is inaccurately predicted. This is due to the fact that GP and REPTree tend to estimate higher speedup values. Furthermore, in the majority of the scenarios, the evaluated regression techniques have generated more accurate predictions than those produced by the baseline machine learning model (Random Forest).

For future works, we intend to evaluate the proposed theoretical model using more datasets, aiming to increase the generalization of the results. Furthermore, we plan to extend and evaluate the theoretical model considering more complex classification techniques, such as collective classification and machine learning.