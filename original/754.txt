Abstract
This paper presents a novel leaderless protocol (FPC-BI: Fast Probabilistic Consensus within Byzantine Infrastructures) with a low communicational complexity and which allows a set of nodes to come to a consensus on a value of a single bit. The paper makes the assumption that part of the nodes are Byzantine, and are thus controlled by an adversary who intends to either delay the consensus, or break it (this defines that at least a couple of honest nodes come to different conclusions). We prove that, nevertheless, the protocol works with high probability when its parameters are suitably chosen. Along this the paper also provides explicit estimates on the probability that the protocol finalizes in the consensus state in a given time. This protocol could be applied to reaching consensus in decentralized cryptocurrency systems. A special feature of it is that it makes use of a sequence of random numbers which are either provided by a trusted source or generated by the nodes themselves using some decentralized random number generating protocol. This increases the overall trustworthiness of the infrastructure. A core contribution of the paper is that it uses a very weak consensus to obtain a strong consensus on the value of a bit, and which can relate to the validity of a transaction.

Keywords
Voting
Consensus
Decentralized randomness
Decentralized cryptocurrency systems

1. Introduction
Increasingly, distributed systems need to provide a consensus on the current state of the infrastructure within given time limits, and to a high degree of accuracy. At the core of cryptocurrency transactions, for example, is that miners must achieve a consensus on the current state of transactions. This works well when all the nodes are behaving correctly, but a malicious agent could infect the infrastructure, and try and change the consensus [28].

Suppose that there is a network composed of  nodes, and these nodes need to come to consensus on the value of a bit. Some of these nodes, however, may belong to an adversary, an entity which aims to delay the consensus or prevent it from happening altogether. This paper focuses on this situation – and which is typical in the cryptocurrency applications – when the number  of nodes is large, and where they are possibly (geographically) spread out. This makes the communicational costs important whereas computational complexity and the memory usage are often of a lesser concern.

1.1. Key contributions
The key contribution of this paper is a protocol which allow a large number of adversarial nodes which may be a (fixed) proportion of the total number of nodes, while keeping the communicational complexity low (see Corollary 4.3). It then guarantees fast convergence for all initial conditions. It is important to note that here we do not require that with high probability the consensus should be achieved on the initial majority value. Rather, what we need, is:

(i)
if, initially, no significant majority1 of nodes prefer , then the final consensus should be  whp2 ;

(ii)
if, initially, a supermajority3 of nodes prefer , then the final consensus should be  whp.

Along with these assumptions, another important assumption that we make is that, among the totality of  nodes, there are  adversarial (Byzantine) nodes,4 who may not follow the proposed protocol and who may act maliciously in order to prevent the consensus (of the honest nodes) from being achieved.

1.2. Context
To understand the importance of this work to cryptocurrency applications, consider a situation when there are two contradicting transactions. For example, if one transfers all the balance of address 
 to address 
, while the other transfers all the balance of address 
 to address 
. If those two transactions appear roughly at the same time, then neither of the two transactions will be strongly preferred by the nodes of the network, they can then be declared invalid — just in case. On the other hand, it would not be a good idea to always declare them invalid, as a malicious actor (Eve) could be able to exploit this. For example, Eve could place a legitimate transaction, such as buying some goods from a merchant. When she receives the goods, she publishes a double-spending transaction – as above – in the hope that both will be canceled, and so she would effectively receive her money back (or at least take the money away from the merchant). To avoid this kind of threat, it would be desirable if the first transaction (payment to the merchant) which, by that time, would have probably gained some confidence from the nodes, would stay confirmed, and only the subsequent double-spend gets canceled.

2. Related work
There is a wide range of classical work on (probabilistic) Byzantine consensus protocols [1], [4], [5], [15], [16], [24]. The disadvantage of the approach of these papers is, however, that they typically require that the nodes exchange 
 messages in each round (which means  messages for each node). In the situation where the communicational complexity matters, this can be a major barrier.

A good deal of work focuses on failures within a network infrastructure, rather than on malicious agents. The work of Liu [20] defines FastBFT, and which is a fast and scalable BFT (Byzantine fault tolerance) protocol. Within this, the work integrates trusted execution environments (TEEs) with lightweight secret sharing, and results in a low latency infrastructure. Crain et al. [11] define Democratic Byzantine Fault Tolerance (DBFT) and which is a leaderless Byzantine consensus. This provides a robust infrastructure where there is a failure in the leader of the consensus network. The core contribution is that nodes will process message whenever they receive them, instead of waiting for a co-ordinate to confirm messages. Another Byzantine Fault Tolerant method which does not require a leader node is Honey Badger [21]. This method is asynchronous in its scope and can cope with corrupted nodes. Unfortunately, it does not actually make any commitments around the timing of the delivery of a message, and where even if Eve controls the scheduling of messages, there will be no impact on the overall consensus.

There has also been much research on the probabilistic models where, in each round, a node only contacts a small number of other nodes in order to learn their opinions, and possibly change its own. This type of models is usually called voter models, and which were introduced in the 70s by Holley and Liggett [18] and Clifford and Sudbury [8]. A very important observation is that, in most cases, voter models have only two extremal invariant measures: one concentrated on the “all-” configuration, and the other one concentrated on the “all-” — we can naturally call these two configurations “consensus states”. Since then, there has been a range of work on voter models; in particular, let us cite [3], [9], [10], [12], [13], [14] which are specifically aimed at reaching consensus and have low communicational complexity (typically, ). However, in these works, the presence of adversarial nodes is usually either not allowed, or is supposed to be very minimal (the system can admit only roughly  adversarial nodes, so the allowed proportion of the adversarial nodes is asymptotically zero).

3. Model definition
The developed model assumes that adversarial nodes can exchange information freely between themselves and can agree on a common strategy. In fact, they all may be controlled by a single individual or entity. We also assume that the adversary is omniscient: at each moment of time, he is aware of the current opinion of every honest node. While this assumption may seem a bit too extreme, note that the adversarial nodes can query the honest ones a bit more frequently to be aware of the current state of the network; also, even if the “too frequent” queries are somehow not permitted, the adversary can still infer (with some degree of confidence) about the opinion of a given honest node by analyzing the history of this node’s interactions with all the adversarial nodes.

The remaining  nodes are honest, i.e., they follow the recommended protocol. We assume that they are numbered from  to ; this will enter into several notations below.

Our protocol will be divided into epochs which we call rounds; for now, let us assume that the end of the previous round (which coincides with the beginning of the next round) occur at predetermined time instances.5 The basic feature of it is that, in each round, each node may query  other nodes about their current opinion (i.e., the preferred value of the bit). We allow  to be relatively large (say,  or so), but still assume that . We also assume that the complete list of the nodes is known to all the participants, and any node can directly query any other node. For the sake of clarity of the presentation, for now we assume that all nodes (honest and adversarial) always respond to the queries; in Section 6 we deal with the general situation when nodes can possibly remain silent. This, by the way, will result in a new “security threshold” 
 (where  is the Golden Ratio), different from the “usual” security thresholds 
 
 and 
 
.

With respect to the behavior of the adversarial nodes, there are two important cases to be distinguished:

•
Cautious adversary6 : any adversarial node must maintain the same opinion in the same round, i.e., respond the same value to all the queries it receives in that round.

•
Berserk adversary: an adversarial node may respond differently to things for different queries in the same round.

To explain the reason why the adversary may choose to be cautious, first note that we also assume that nodes have identities and sign all their messages; this way, one can always prove that a given message originates from a given node. Now, if a node is not cautious, this may be detected by the honest nodes (e.g., two honest nodes may exchange their query history and verify that the same node passed contradicting information to them). In such a case, the offender may be penalized by all the honest nodes (the nodes who discovered the fraud would pass that information along, together with the relevant proof). Since, in the sequel, we will see that the protocol provides more security and converges faster against a cautious adversary, it may be indeed a good idea for the honest nodes to adopt additional measures in order to detect the “berserk” behavior. Also, since  would be typically large and each node is queried  times on average during each round, we make a further simplifying assumption that a cautious adversary just chooses (in some way) the opinions of all his nodes before the current round starts and then communicates these opinions to whoever asks.

3.1. Random numbers
The protocol we are going to describe requires the system to use, from time to time (more precisely, once in each round), a random number available to all the participants (this is very similar to the “global-coin” approach used in many works on Byzantine consensus, see e.g. [1]). For the sake of cleanness of the presentation and the arguments, in this paper we mainly assume that these random numbers are provided by a trusted source, not controlled by the adversary.7 We observe that such random number generation can be done in a decentralized way as well (provided that the proportion  of the adversarial nodes is not too large), see e.g. [7], [19], [23], [26], [27]. If a “completely decentralized” solution proves to be too expensive (from the point of view of computational and/or communicational complexity), one can consider “intermediate” ones, such as using a smaller committee for this, and/or making use of many publicly available RNGs. It is important to observe that (as we will see from the analysis below), even if from time to time the adversary can get (total or partial) control of the random number, this can only lead to delayed consensus, but he cannot convince different honest nodes of different things, i.e., safety is not violated. Also, it is not necessary that really all honest nodes agree on the same number; if most of them do, this is already fine. This justifies the idea that, in our context, both decentralization and “strong consensus” are not of utter importance for the specific task of random number generation. We postpone the rest of this discussion to Section 6, since the methods we employ for proving our results are relevant for it.

Before actually describing our protocol, it is important to note that we assume that there is no central entity that “supervises” the network and can somehow know that the consensus was achieved and therefore it is time to stop. This means that each node must decide when to stop using a local rule, i.e., using only the information locally available to it. A quick example of such a decision rule might be the following: “if during the last  rounds at least  of my queries were answered with opinion ‘’, then I consider this opinion to be final”.

3.2. Parameter setup
The protocol depends on a set of integer and real parameters:

•
, the threshold limits in the first round8 ;

•
, the threshold limit parameter in the subsequent rounds;

•
, the cooling-off period;

•
, the number of consecutive rounds (when the cooling-off period is over) with the same opinion after which it becomes final, for one node.

Now, let us describe our protocol. First, we assume that each node decides on the initial value of the bit, according to any reasonable rule.9 Then, we describe the first round of the protocol in the following way:

•
in the first round, each honest node  randomly queries other nodes  times (repetitions and self-queries are allowed10 ) and records the number 
 of -opinions it receives;

•
after that, the value of the random variable 
 is made available to the nodes11 ;

•
then, each honest node uses the following decision rule: if 
, it adopts opinion , otherwise it adopts opinion .

In the subsequent rounds, the dynamics is almost the same, we only change the interval where the uniform random variable lives:

•
in the round , each honest node  randomly queries other nodes  times, and records the number 
 of -opinions it receives;

•
after that, the value of the random variable 
 is made available to the nodes;

•
then, each honest node which does not yet have final opinion uses the following decision rule: if 
, it adopts opinion , otherwise it adopts opinion .

As mentioned above, if an honest node has the same opinion during  consecutive rounds after the cooling-off period (i.e., counting from time 
 on) this opinion becomes final.

3.3. Consensus mechanism
Let us now explain informally what makes our protocol converge fast to the consensus even in the Byzantine setting. The general idea is the following: if the adversary (Eve) knows the decision rules that the honest nodes use, she can then predict their behavior and adjust her strategy accordingly, in order to be able to delay the consensus and further mess with the system. Therefore, let us make these rules unknown to all the participants, including Eve. Specifically, even though Eve’s nodes can control (to some extent) the expected proportion of -responses among the  queries, she cannot control the value that the “threshold” random variable assumes. As a consequence, the decision threshold 
 will likely be “separated” from that typical proportion.

When this separation happens, the opinions of the honest nodes would tend very strongly in one of the directions whp. Then, it will be extremely unlikely that the system leaves this “pre-consensus” state, due to the fact that the decision thresholds, however random, are always uniformly away from  and . Also, we mention that a similar protocol with intended cryptocurrency applications was considered in [25]. However, there only “fixed thresholds” were used, which gives Eve much more control, so that, in particular, then she could delay the consensus a great deal. As a last remark, it is important to note that having “independently random thresholds” (i.e., each node independently chooses its own decision threshold) is not enough to achieve the effect described above — these “locally random” decisions will simply average out; that is, having common random numbers is indeed essential.

4. Results
We define two events relative to the final consensus value: (1)
Thus, the union 
 stands for the event that all honest nodes agree on the same value, i.e., that the consensus was achieved.

For 
 
, abbreviate 
 
 
In the following, we assume that  is large enough so that 
 (indeed, the first term in the above display is strictly positive, and the second one converges to  as ). Let us also denote, for 
 as above and a generic non negative integer  (2)
 
 
 
 
 and (3)
 
 
 
(4)
 
 
 
 
 (in the above notation, we omit the dependence on  and ). As it will become clear shortly, we will need 
 to be small, and ’s (which, as the reader probably have noted, relate to cautious and berserk adversaries) to be strictly less than . It is not difficult to see (we elaborate more on that below) that (recall that ) the value of the expression in (2) will be small indeed if  is large and  is at least  for a large  (indeed, with other parameters fixed, note that each of the two terms in the second parentheses will be polynomially small in , with the factor  entering to the negative power; a fixed 
 works for all large enough ). Then, the first term in the expression in (3) will be very small for large , while the second term will also be small for a sufficiently large . As for (4), it shares the same first term with (3); the second term, however, will be of constant order, and if we want it to be strictly less than  for a large , we need the constraint  to hold.

Now, we begin formulating our main results. Let  be the number of rounds until all honest nodes achieve their final opinions. The next result controls both the number of necessary rounds and the probability that the final consensus is achieved (i.e., the event 
 occurs):

Theorem 4.1

(i)
For any strategy of a cautious adversary, it holds that (5)

(ii)
For any strategy of a berserk adversary, we have (6)

Note that the first term in (2) decreases in  while the second one increases in ; however, the second term is typically of much smaller value (since it has an exponentially small in  factor) and therefore one may obtain better estimates in (5), (6) with some strictly positive values of . Note also that the only difference between (5), (6) is in the second terms of (3), (4). As we will see in the proofs, these terms enter into the part which is “responsible” for the estimates on the time moment when the adversary loses control on the situation which permits one of the opinions to reach a supermajority; from that moment on, there is essentially no difference if the adversary is cautious or berserk.

Corollary 4.2

For a cautious adversary we need that , while for a berserk adversary we also need that . Recalling also that  must belong to , it is not difficult to see that

•
for a cautious adversary, for any  and all large enough  we are able to adjust the parameters 
 in such a way that the protocol works whp (in particular, a -value sufficiently close to  would work);

•
however, for a berserk adversary, we are able to do the same only for  (here,  would work).

Corollary 4.3

One may be interested in asymptotic results, for example, of the following kind: assume that the number of nodes  is fixed (and large), and the proportion of Byzantine nodes  isacceptable (i.e., less than  for the case of cautious adversary, or less than  for the case of berserk adversary, as discussed above). We then want to choose the parameters of the protocol in such a way that the probabilities in (5), (6) are at least , where  is polynomially small in  (i.e., 
 for some ).

First,  works in both cases; then, a quick analysis of (5)–(6) shows that one possibility is: chose  (with a sufficiently large constant in front),  (the number of consecutive rounds with the same opinion before finalization) of constant order, and 
 
 for cautious adversary or 
 for a berserk one.

That is, the overall communicational complexity will be at most 
 
 for a cautious adversary and 
 for a berserk one.

Next, let 
 be the initial proportion of -opinions among the honest nodes. Our second result shows that if, initially, no significant majority of nodes prefer , then the final consensus will be  whp, and if the supermajority of nodes prefer , then the final consensus will be  whp (recall (i)–(ii) in Section 1.1), and it is valid in the general case (i.e., for both cautious and berserk adversaries).

Theorem 4.4

(i)
First, suppose that 
, and assume that  is sufficiently large so that 
 
Then, we have (7)
 
 

(ii)
Now, suppose that 
, and assume that  is sufficiently large so that 
 
Then, the same estimate (7) holds for 
.

We also mention that the estimates (5), (6) are usually not quite sharp because we have used some union bounds and other “worst-case” arguments when proving them. In practice, one might resort to simulations to possibly achieve better estimates; since the present paper is mostly devoted to a theoretical analysis of the protocol in the simplest setting, we defer this discussion to Section 8. For a quick concrete example on the number of necessary rounds until consensus (with different parameters), see Fig. 1 (courtesy of Sebastian Müller). It is interesting to observe that, in most cases, the protocol finalizes after the minimal number 
 of rounds and the probability that it lasts for more than  rounds seems to be very small.


Download : Download high-res image (263KB)
Download : Download full-size image
Fig. 1. Number of rounds till the protocol finalizes, with , , , 
, , and . Here, 
 is the initial proportion of -opinions among honest nodes; the round counts are on the horizontal axes, and on the vertical axes are numbers of nodes that have finalized on the -opinion after that number of rounds.

Before starting with the proofs, let us mention that, for reader’s convenience, we provide the list of most important notations of this paper in Section 7.

5. Proofs
We start with some preliminaries. Denote by  the Binomial distribution with parameters  and . Let us recall the Hoeffding’s inequality [17]: if  is a parameter and 
 with , then (8)
the same estimate also holds for 
 in the case .

To better understand the difference between cautious and berserk adversaries, look at Fig. 2. Here, 
 is the initial proportion of -opinions between the honest nodes, and the crosses mark the proportion of -responses to the  queries that the honest nodes obtain. The cautious adversary can choose any 
 (by adjusting the opinions of his nodes appropriately, so that the overall proportion of -opinions would be 
), and then those crosses will be (mostly) concentrated in the interval of length of order 
 around 
. On the other hand, the berserk adversary can cause the crosses to be distributed in any way on the whole interval 
, with some of them even going a bit out of it (on the distance of order 
 again).


Download : Download high-res image (61KB)
Download : Download full-size image
Fig. 2. What cautious and berserk adversaries can achieve.

Next, we need an auxiliary result on a likely outcome of a round in the case when the adversary cannot make the typical proportion of -responses to be close to the decision threshold. Let  be the number of -responses among  queries that th honest node receives; in general, the random variables  are not independent, but they are conditionally independent given the adversary’s strategy. (Note that 
 with some possibly random 
 if the adversary is cautious, but the situation may be more complicated for a berserk one.) For a fixed , define a random variable 
 
so that 
 is the new proportion of -opinions among the honest nodes, given that the “decision threshold” equals . Then, the following result holds:

Lemma 5.1

(i)
Assume that, conditioned on any adversarial strategy, there are some positive  and  such that  is stochastically dominated by  for all , and . Then, for any  (9)

(ii)
Assume that, conditioned on any adversarial strategy,  stochastically dominates  for all , and . Then, for any  (10)

Proof

For (i), we observe that 
 is stochastically dominated by , and then (9) follows from (8). The proof of the part (ii) is completely analogous.  □

Note that, by (8), 
 (and the same holds for ), so we will normally use Lemma 5.1 with 
.

Another elementary fact we need is

Lemma 5.2

Let 
 be  sequences of independent Bernoulli trials12 with success probability . For  define 
 
and 
 
to be the first moments when runs of  ones (respectively, zeros) are observed in th sequence. Then, for all , (11)
 
for all , and (12)
 

Proof

First, it is clear that (13)
(divide the time interval  into  subintervals of length  and note that each of these subintervals is all- with probability 
). Then, the following is an easy exercise on computing probabilities via conditioning (for the sake of completeness, we prove this fact in the Appendix): (14)
 

Observe that (14) implies that (since 
 and 
) 
 
and so, using the above together with (13) and the union bound, we obtain (11). The relation (12) is then a direct consequence of (11) (again, with the union bound).  □

To prove our main results, we need some additional notation. Let  be the round when the th (honest) node finalizes its opinion. Denote 
to be the subset of honest nodes that finalized their opinions by round . Let also 
 be the opinion of th node after the th round and (15)
 
be the proportion of -opinions among the honest nodes after the th round in the original system.

Proof of Theorem 4.1

Let us define the random variable (16)
 
 
to be the round after which the proportion of -opinions among the honest nodes either becomes “too small”, or “too large”. We now need the following fact:

Lemma 5.3

For all 
, it holds that (recall (3), (4)) (17) 
 

Proof

Observe that 
 implies that a node cannot finalize its opinion before round . Consider first the case of a cautious adversary. Abbreviate (for this proof) 
 
. Let  and observe that, for any fixed  we have (recall that 
) (18)
 
 
 
 
 Now, assume that 
. Under this, using (8), (18), we obtain by conditioning on the value of 
 (19)
 recall (3). This implies the first comparison in (17).

For a berserk adversary, the calculation is quite analogous (recall Fig. 2), so we omit it.  □

Next, we need a result that shows that if one of the opinions has already reached a supermajority, then this situation is likely to be preserved.


Download : Download high-res image (66KB)
Download : Download full-size image
Fig. 3. Transition from 
 to 
: after th round, being 
 
, the adversary may “grow” the proportion of s to 
 
. Then, since the difference between that and “the least possible threshold”  is at least 
 
, the probability that an undecided node would have opinion  in the next round is at most 
 
. Then, with overwhelming probability 
 will be at most 
 
, and so it goes.

Lemma 5.4

Let ; in the following,  will denote a subset of .

(i)
Let 
 be the event that 
 
, 
, and 
 for all . Then (20)
 

(ii)
Let 
 be the event that 
 
, 
, and 
 for all . Then (21)
 

Proof

We prove only part (i), the proof of the other part is completely analogous. Now, look at Fig. 3: essentially, this is a direct consequence of Lemma 5.1 with 
 
 
 and 
. Observe also that, if some honest nodes already decided on  definitely, it holds that 
 is stochastically dominated by 
 
.  □

Now, we are able to conclude the proof of Theorem 4.1. Let us introduce the random variable (22)
 
 
 
 
 to be the first moment after  when the honest nodes’ opinion has drifted away from supermajority. Denote also 
and 

Next, observe that 
where 
 To obtain the estimates (5), (6), it is enough to note that the lower bounds on, respectively, 
, 
, and 
, follow from, respectively, Lemma 5.3, Lemma 5.4, and Lemma 5.2 (and also the union bound).  □

Proof of Theorem 4.4

We prove only the part (i); the proof of the other part is completely analogous. In fact, to obtain the proof it is enough to observe that, if 
 and 
 
, then, by (8), with probability at least 
 
 
 it happens that 
 
 (so, in particular, ); next, the same argument as in the proof of Theorem 4.1 does the work.  □

6. Further generalizations
In this section we argue that our protocol is robust, that is, it is possible to adapt it in such a way that it is able to work well in more “practical” situations. Specifically, observe that nodes may not always respond queries, and the adversarial nodes sometimes may do so deliberately. The protocol described in Section 3 is not designed to handle this, so it needs to be amended. There are at least two natural ways to deal with this situation:

(i)
let each node to take the decision based on the responses that it effectively received (i.e., instead of 
 use 
, where 
 is the number of responses that the th node received in the th round);

(ii)
each node queries more than  nodes, say,  or more; since whp the number of responses received will be at least  (for definiteness, let us assume that the probability that a query is left unresponded is less than 
 
), the node then keeps exactly  responses and discards the rest;

and it is of course also possible to combine them. The practical difference between these two options is probably not so big at least in the case of reasonably large values of  (because then the proportions of s in the responses should be roughly the same in most cases due to the Law of Large Numbers); for the sake of formulating the results in a more clean way, let us assume that a node simply issues queries sequentially until getting exactly  responses.

Now, we define the notion of a semi-cautious adversary: every node it controls will not give contradicting responses (i.e.,  to one node and  to another node in the same round) but can sometimes remain silent; since it does not make sense for a node to remain silent altogether in a given round (that would just reduce the fraction of the adversarial nodes in the network), there are two possible adversarial node behaviors:

•
a node answers “” to some queries and does not answer other queries;

•
a node answers “” to some queries and does not answer other queries.

Here is the result we have for a semi-cautious adversary:

Theorem 6.1

If the adversary is semi-cautious, assume that 
 
 
. Then, for any adversarial strategy, we have (23)
where (24)
 
 
 
 
 

In this situation, the fact corresponding to Corollary 4.2 will be the following (in particular, note the new “security threshold” 
 
 
 that we obtain here):

Corollary 6.2

For a semi-cautious adversary, we need that 
 
, or, equivalently, 
 
 (it is only in this case that we will be able to find large enough  such that the hypothesis of Theorem 6.1 is satisfied). Since we also still need that , solving 
 
, we obtain that  must be less than 
 
 
, where 
 
 is the Golden Ratio. Then, as before, it is straightforward to show that, for a semi-cautious adversary, for any 
 
 and all large enough  we are able to adjust the parameters 
 in such a way that the protocol works whp (in particular, a -value sufficiently close to 
 
 would work).

Proof of Theorem 6.1

As observed before, an “always-silent” strategy is not interesting for an adversarial node, since this will, in practice, only reduce their quantity. Now, assume that, for some ,

•
 adversarial nodes reply “” or remain silent;

•
 adversarial nodes reply “” or remain silent.

Then, if the adversary wants to decrease a honest node’s confidence in the -opinion, those nodes who may answer “” will remain silent, and so with probability 
 
 the response will be obtained from a honest node, while with probability 
 
 the response will be obtained from an adversarial node. This gives 
 
 
as the “lower limit” for the (expected) proportion of s in the queries. Analogously, if the adversary wants to increase an honest node’s confidence in the -opinion those nodes who may answer “” will remain silent, and so with probability 
 
 the response will be obtained from a honest node, while with probability 
 
 the response will be obtained from an adversarial node. This gives 
 
 
 
as the corresponding “upper limit”. So, analogously to Fig. 2, the semi-cautious adversary can achieve the “crosses” to be distributed on the interval (25)
≔
 
 
in any way. Now, it is elementary to see that both endpoints of the above interval decrease when  increases; if we want to make it symmetric (around 
 
), we need to solve 
 
 
or, equivalently 
 
 
for . This gives the solution 
. After substituting 
 to (25), the symmetrized interval becomes 
 
 
(somewhat unexpectedly, because it does not depend on 
 anymore). It is actually worth noting that 
 does not necessarily belong to  (so it is not always possible to make this interval symmetric), but it does not pose a problem due to the following. Look at Fig. 4: due to the monotonicity, (26) 
 
 
indeed, for all  we see that either the interval 
 
 or the interval 
 
 is a subset of 
.

This essentially takes care of the argument in the proof of Lemma 5.3 (since we now understand what is the minimal length of the interval that the adversary cannot control), and the rest of the proof is completely analogous to that of Theorem 4.1: indeed, as observed before, the adversary loses control after the random time .  □


Download : Download high-res image (21KB)
Download : Download full-size image
Fig. 4. The “intervals of control” of a semi-cautious adversary, for 
.

We also observe that Theorem 4.4 remains valid also for a semi-cautious adversary.

Next, let us discuss what do we really need from the (decentralized) random number generator. In fact, it is not so much: we need that, regardless of the past, with probability at least  (where  is a fixed parameter) the next outcome is a uniform random variable which is “unpredictable” for the adversary; this random number is seen by at least (1-) proportion of honest nodes, where  is reasonably small. What we can prove in such a situation depends on what the remaining  honest nodes use as their decision thresholds: they can use some “second candidate” (in case there is an alternative source of common randomness), or they can choose their thresholds independently and randomly, etc. Each of such situations would need to be treated separately, which is certainly doable, but left out of this paper. Let us note, though, that the “worst-case” assumption is that the adversary can “feed” the (fake) decision thresholds to those  honest nodes. This would effectively mean that these nodes would behave as cautious adversaries in the next round (which matters if the random time  did not yet occur). Therefore, for the sake of obtaining bounds like (5)–(6), (23) we can simply pretend that the value of  is increased by .

Now, assuming that , it is easy to figure out how this will affect our results: indeed, in our proofs, all random thresholds matter only until . It is then straightforward to obtain the following fact:

Proposition 6.3

Assume the above on the random number generation (with  and ). Then, the estimates (5)–(6), (23) remain valid with 
 on the place of 
 (with ).

In view of the above result, let us stress that one of the main ideas of this paper is: we use a “rather weak” consensus (on the random numbers, as above) to obtain a “strong” consensus on the value of a bit (i.e., validity of a transaction). Also, let us observe that a partial control of the random numbers does not give access to a lot of power (in the worst case the adversary would delay the consensus a bit, but that is all), so there is not much need to be restrictive on the degree of decentralization for that part13 : a smaller subcommittee can take care of the random numbers’ generation, and some VDF-based random number generation scheme (such as [19]) may be used to further prevent this subcommittee from leaking the numbers before the due time.

7. Notations used in this paper
Here, for reader’s convenience, we provide a list of most important notations used in the paper.

•
 is the total number of nodes in the system,  is the number of queries each node makes in one round,  is the proportion of adversarial nodes;

•
 are the threshold limits in the first round,  is the threshold limit parameter in the subsequent rounds;

•
in the same round, a cautious adversarial node always responds the queries in the same way, a berserk one can give any responses (including not responding at all), and a semi-cautious one may ignore some of the queries but has to respond the others in the same way;

•
for our protocol to work, for all cases we need to assume that ; additionally, we also need to assume that  for berserk adversary and 
 
 for semi-cautious adversary;

•
, the cooling-off period,  is the number of consecutive rounds with the same opinion after which it becomes final;

•
 is the number of -opinions that th node receives in th round;

•
 is the Uniform probability distribution of the interval  and  is the Binomial distribution with parameters  and ;

•
 is defined in (2), 
 and 
 are defined in (3)–(4), and 
 is defined in (24);

•
 is the “consensus event” (i.e., either all honest nodes finalize on  or all honest nodes finalize on );

•
 is the number of rounds until all honest nodes finalize their opinions;

•
 is the initial proportion of -opinions among the honest nodes;

•
 is the proportion of -opinions among the honest nodes after the th round;

•
 is the set of honest nodes that finalized their opinions by round ;

•
 is the (random) moment when the adversary “looses control” (formally defined in (16)).

8. Conclusions and future work
In this paper we described a consensus protocol which is able to withstand a substantial proportion of Byzantine nodes, and obtained some explicit estimates on its safety and liveness. A special feature of our protocol is that it uses a sequence of random numbers (produced by some external source or by the nodes themselves) in order to have a “randomly moving decision threshold” which quickly defeats the adversary’s attempts to mess with the consensus. It is also worth noting that the “quality” of those random numbers is not critically important – only the estimates on  (Lemma 5.3) will be affected in a non-drastic way. In particular, one can permit that the random numbers might be biased, or even that the adversary might get control of these numbers from time to time. Also, it is clear from the proofs that there is no need for the honest nodes to achieve consensus on the actual values of these random numbers: if some (not very large) proportion of honest nodes does not see the same number as the others, this will not cause problems. All this is due to the fact that, when the proportion of -opinions among the honest nodes becomes “too small” or “too large” (i.e., less than 
 
 or greater than 
 
 in our proofs), the adversary does not have any control anymore.

As mentioned above, this paper primarily contains a rigorous analysis of the simplest version of the protocol. It is of course tempting to consider other versions, in particular, where the neighborhood relation between nodes is not that of a complete graph. However, as is frequently the case, introducing a nontrivial graph structure makes the problem hardly tractable in a purely analytic way, which means that it has to be approached via simulations. For that approach, we refer to the paper [6], which can be considered as a complementary work to the present one (note that simulations also permit one to obtain better estimates the failure probabilities since, as noted above, the estimates (5), (6) of the present paper are usually not quite sharp).

Also, when considering the behavior of the adversary nodes, a number of “worst-case” assumptions were made (notably, that all the adversarial nodes are controlled by a single entity and that the adversary is omniscient). Again, analyzing a system with independent adversaries with possibly incomplete information is an interesting but analytically difficult program; in this case the simulations approach seems to be more adequate as well.

We need to comment on anti-Sybil measure in practical implementations: indeed, it would be quite unfortunate if the adversary is able to deploy an excessively large number of nodes, thus inflating the value of . One of the possible approaches is using a variant of Proof-of-Stake; with it, when querying, one needs to choose the node proportionally to its weight (stake). This is partly the subject of an ongoing research effort [22].