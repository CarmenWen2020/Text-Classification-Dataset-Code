We report on our discovery of an algorithmic aw in the construction of primes for RSA key generation in a widely-used library
of a major manufacturer of cryptographic hardware. e primes
generated by the library suer from a signicant loss of entropy.
We propose a practical factorization method for various key lengths
including 1024 and 2048 bits. Our method requires no additional
information except for the value of the public modulus and does
not depend on a weak or a faulty random number generator. We
devised an extension of Coppersmith’s factorization aack utilizing
an alternative form of the primes in question. e library in question is found in NIST FIPS 140-2 and CC EAL 5+ certied devices
used for a wide range of real-world applications, including identity
cards, passports, Trusted Platform Modules, PGP and tokens for
authentication or soware signing. As the relevant library code was
introduced in 2012 at the latest (and probably earlier), the impacted
devices are now widespread. Tens of thousands of such keys were
directly identied, many with signicant impacts, especially for
electronic identity documents, soware signing, Trusted Computing and PGP. We estimate the number of aected devices to be in
the order of at least tens of millions.
e worst cases for the factorization of 1024 and 2048-bit keys
are less than 3 CPU-months and 100 CPU-years on single core of
common recent CPUs, respectively, while the expected time is half
of that of the worst case. e aack can be parallelized on multiple
CPUs. Worse still, all susceptible keys contain a strong ngerprint
that is veriable in microseconds on an ordinary laptop – meaning
that all vulnerable keys can be quickly identied, even in very large
datasets.
KEYWORDS
RSA, factorization, smartcard, Coppersmith’s algorithm
1 INTRODUCTION
RSA [69] is a widespread algorithm for asymmetric cryptography
used for digital signatures and message encryption. RSA security
is based on the integer factorization problem, which is believed
to be computationally infeasible or at least extremely dicult for
suciently large security parameters – the size of the private primes
and the resulting public modulus N. As of 2017, the most common
length of the modulus N is 2048 bits, with shorter key lengths
such as 1024 bits still used in practice (although not recommend
anymore) and longer lengths like 4096 bits becoming increasingly
common. As the private part of the key is a very sensitive item, a
user may use secure hardware such as a cryptographic smartcard
to securely store and use the private key value.
Successful aacks against RSA based on integer factorization
(nding the private primes p and q from the public modulus N) enable the aacker to impersonate the key owner and decrypt private
messages. e keys used by secure hardware are of special interest
due to the generally higher value of the information protected –
e.g., securing payment transactions.
RSA requires two large random primes p and q, that can be
obtained by generating a random candidate number (usually with
half of the bits of N) and then testing it for primality. If the candidate
is found to be composite, the process is repeated with a dierent
candidate number.
However, there are at least three reasons to construct a candidate
number from several smaller (randomly) generated components
instead of generating it randomly: 1) an improved resistance against
certain factorization methods, such as Pollard’s p − 1 method [65];
2) certication requirements such as the NIST FIPS 140-2 standard,
which mandates that for all primes p, the values of p − 1 and p + 1
have at least one large (101-bit or larger) factor each; and 3) speedup
of keypair generation, since testing random candidate values for
primality is time consuming, especially on restricted devices like
smartcards.
Yet, constructed primes may bring new problems as demonstrated in our work. In the past, practical aacks against RSA
exploited the use of insecurely short key lengths susceptible to
factorization via NFS [67] (e.g., 512-bit, still found on the Internet [38]); faulty or weak random number generators producing
partially predictable primes, as in the electronic IDs of Taiwanese
citizens [9]; soware bugs causing primes to be generated from an
insuciently large space, as in the Debian RNG aw [7]; or seeding
with insucient entropy, leading to multiple keypairs sharing a
prime [38]. e knowledge or recovery of all bits of a private key is
not always required for a successful aack thanks to the powerful
technique proposed by Coppersmith [22]. If at least one half of
the bits of one of the primes is known, the remaining bits can be
computationally recovered. en, even otherwise secure designs
can be aacked by various side-channel and implementation-based
aacks or by introducing faults into the computation.
Only on very rare occasions is an aacker potentially able to
recover the private primes of a chosen key of a seemingly su-
cient bit length, without physical access to the target device or a
large amount of side-channel information. One notable aack that
comes close is a simple GCD computation [10], which can quickly
factorize a collection of moduli, but only if they happen to share a
common prime, making the aack less likely to succeed on a single
targeted keypair. e cause of such vulnerability is typically insuf-
cient entropy during the keypair generation, as demonstrated for
a large number of TLS and SSH keys [36, 38], therefore requiring
multiple public keys to be created with the same malfunctioning
implementation of a random number generator.
We present our aack against keys generated in cryptographic
smartcards of Inneon Technologies AG (further denoted as Manufacturer), and our aack is not based on any weakness in a random
bit generator or any additional side-channel information. Instead,
the aack utilizes the specic structure of the primes as generated
by Manufacturer’s on-chip cryptographic library (further denoted
as RSALib1
). We had access neither to the RSALib’s source code
nor to the object code (since it is stored only in the secure on-chip
memory and is not extractable), and the whole analysis was performed solely using RSA keys generated and exported from the
Manufacturer’s cards and tokens.
In short, the paper has the following contributions:
1. Recovery of the internal structure of the primes: We
identify the structure of RSA primes as produced by a black-box
cryptographic library by a manufacturer of widely used cryptographic smartcards. e structure was recovered solely from our
observations of statistical properties of large number of private
keys generated in accordance with the specication of the product.
2. Practical factorization: We propose and implement a technique for the factorization of such RSA keys, with lengths including
1024 and 2048 bits, using our derivation of the methods by Coppersmith and Howgrave-Graham.
3. Fast detection algorithm: We design a very fast algorithm
to verify whether a particular key originates from the inspected
library based on the properties of the public modulus. e implementation was released2
to allow users to check their own keys.
4. Analysis of impacted domains: We analyze multiple usage
domains (TLS, PGP, eID, authentication tokens, soware signing,
etc.) for the prevalence of vulnerable keys and discuss the impact
of key factorization.
e specic structure of the primes as generated by RSALib (most
likely introduced to speed up prime generation) allows us to quickly
identify keys generated by the library using only the public modulus
(regardless of the length of the key) and to practically factorize RSA
keys with various key lengths up to 2048 bits. e factorization
1Likely RSA v1.02.013 library and later revisions.
2
Full details and a tool for the detection of vulnerable keys can be found at
hps://crocs..muni.cz/papers/rsa ccs17.
method uses knowledge of the specic structure of such primes to
apply our derivation of Coppersmith’s method. Furthermore, we
devised an alternative representation of the primes in question to
make the aack computationally feasible on consumer hardware.
e impact is signicant due to Manufacturer being one of the
top three secure integrated circuit (IC) producers. Furthermore,
the weakness lies in an on-device soware library; hence, it is not
limited just to a particular range of physical devices. e weakness
can be traced back to at least the year 2012, increasing the number
of aected domains. We assessed the impact in a several important
real-world usage scenarios and made some recommendations for
mitigation.
e ngerprinting method is fast, requiring just microseconds
to run on a modulus. We successfully used the ngerprinting technique on large datasets of certicates, such as those submied to
Certicate Transparency logs, collected in Internet-wide TLS scans
and stored on public PGP keyservers. is led to a discovery of
thousands of keys in the wild with primes of the form in question.
Our method has negligible false negative and false positive rates
(observed as zero), as guaranteed by the very rare properties.
Where datasets with public RSA keys were not available (e.g.,
Trusted Platform Modules or EMV payment cards), we collected
sample keys from dierent devices to get an idea about the typical
key lengths used for the domain and to estimate the prevalence of
devices producing potentially vulnerable keys.
Although the RSALib is not automatically shipped with every
chip, the developers are motivated to deploy it in order to benet
from ready-to-use higher-level functions (such as the RsaKeyGen
method in question) and to get an implementation designed with
protections against side-channel and fault induction aacks in mind.
However, even for certication, the RSALib is provided only as
object les, without the source code [20].
e rest of our paper is organized as follows: Section 2 is intended for readers with interest in the mathematical details of the
discovered aw and the proposed factorization and ngerprinting
methods. e readers interested mainly in the practical impacts
should focus on the specics of the implementation of the factorization method covered in Section 3 and the survey of impacted
usage domains and the analysis of vulnerable keys found in the
wild, as provided in Section 4. e possible approaches to shortand long-term mitigation are discussed in Section 5. Related work
and conclusions are provided in Sections 6 and 7, respectively.
2 FINGERPRINTING AND FACTORIZATION
To use the RSA algorithm, one must generate a key:
(1) Select two distinct large primes3 p and q.
(2) Compute N = p ∗ q and φ(N) = (p − 1) ∗ (q − 1).
(3) Choose a public exponent4
e < φ(N), e coprime to φ(N).
(4) Compute the private exponent d as e
−1 mod φ(N).
e pair (e, N) is the public key; either (d, N) serves as the secret
private key, or (p,q) can be used ((d, N) can be calculated from
(p,q, e) and vice versa).
3Generated randomly, but possibly constructed to achieve certain required properties.
4Usually with a low Hamming weight for faster encryption.
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1632
A factorization aack aempts to obtain p and q from the knowledge of N. Such an aack is believed to be computationally infeasible for suciently long N. e factorization can be sped up if some
additional information about the private exponent d or about the
primes p or q is known by the aacker.
2.1 Format of the constructed primes
Our motivation for a deeper analysis of the keys produced by Manufacturer’s devices stemmed from the observation of interesting
statistical properties extracted from a large number of keys as described in [73]. When compared to other implementations and
theoretical expectations on distribution of prime numbers, the keys
exhibited a non-uniform distribution of (p mod x) and (N mod x)
for small primes x. In this work, we recovered the structure responsible for the properties. All RSA primes (as well as the moduli)
generated by the RSALib have the following form:
p = k ∗ M + (65537a mod M). (1)
e integers k, a are unknown, and RSA primes dier only in
their values of a and k for keys of the same size. e integer M
is known and equal to some primorial M = Pn# (the product of
the rst n successive primes Pn# =
Qn
i=1
Pi = 2 ∗ 3 ∗ · · · ∗ Pn).
e value of M is related to the key size, where the key size is a
multiple of 32 bits for keys generated by the RSALib. e value
n = 39 (i.e., M = 2 ∗ 3 ∗ · · · ∗ 167) is used to generate primes for an
RSA key with a key size within the [512, 960] interval. e values
n = 71, 126, 225 are used for key sizes within intervals [992, 1952],
[1984, 3936], [3968, 4096].
e most important property of the keys is that the size of M is
large and almost comparable to the size of the prime p (e.g., M has
219 bits for the 256-bit prime p used for 512-bit RSA keys). Since
M is large, the sizes of k and a are small (e.g., k has 256 − 219 = 37
bits and a has 62 bits for 512-bit RSA). Hence, the resulting RSA
primes suer from a signicant loss of entropy (e.g., a prime used in
512-bit RSA has only 99 bits of entropy), and the pool from which
primes are randomly generated is reduced (e.g., from 2256 to 299 for
512-bit RSA).
e specic format of the primes has two main consequences:
1. Fingerprinting: e keys are ngerprinted based on the
existence of a discrete logarithm log65537 N mod M. While the
size of M is large, the logarithm can be computed easily since M
has small factors only. e keys generated by the RSALib can be
identied with a negligible error and within microseconds.
2. Factorization: During the factorization of N, we are looking
for values of a, k. A na¨ıve approach would iterate through dierent
values of a (treating the value of 65537a mod M as the “known bits”)
and apply Coppersmith’s algorithm to nd the unknown k, but the
number of aempts is infeasibly large, as shown in Table 1. We
found an alternative representation of the primes in question using
smaller M0 values (divisors of M), leading to a feasible number of
guesses of the value a
0
. e reduction of M is possible since the entropy loss is suciently high to have more than enough known bits
for the application of Coppersmith’s algorithm to lengths including
1024 and 2048 bits.
2.2 Fingerprinting
e public RSA modulus N is a product of two primes p,q. e
RSALib generates primes of the described form (1). e moduli
have the corresponding form:
N =
p
z }| {
(k ∗ M + 65537a mod M) ∗
q
z }| {
(l ∗ M + 65537b mod M), (2)
for a,b, k,l ∈ Z. e previous identity implies
N ≡ 65537a+b ≡ 65537c mod M, (3)
for some integer c. e public modulus N is generated by 65537
in the multiplicative group Z
∗
M
. e existence of the discrete logarithm c = log65537 N mod M is used as the ngerprint of the public
modulus N generated by the RSALib.
2.2.1 Eiciency. Although the discrete logarithm problem is a
hard problem in general, in our case, it can be computed within microseconds using the Pohlig-Hellman algorithm [64]. e algorithm
can be used to eciently compute a discrete logarithm for a group
G, whose size |G| is a smooth number (having only small factors).
is is exactly our case with the group G = [65537] (subgroup of
Z
∗
M
generated by 65537). e size of G is a smooth number (e.g.,
|G| = 2
4
∗ 3
4
∗ 5
2
∗ 7 ∗ 11 ∗ 13 ∗ 17 ∗ 23 ∗ 29 ∗ 37 ∗ 41 ∗ 53 ∗ 83 for
512-bit RSA) regardless of the key size. e smoothness of G is a
direct consequence of the smoothness of M. Since M is smooth
(M is a primorial, M = 2 ∗ 3 ∗ 5 ∗ · · · ∗ Pn), the size of Z
∗
M
is even
“smoother” (|Z
∗
M
| = φ(M)). e size |G| is a divisor of |Z
∗
M
| (from
Lagrange’s theorem), and it is therefore smooth as well.
2.2.2 False positives. e existence of the discrete logarithm
serves as a very strong ngerprint of the keys. e reason is that
while random primes/moduli modulo M cover the entire Z
∗
M
, the
RSALib generates primes/moduli from the group G – a tiny portion
of the whole group. e sizes |G| of the groupG are listed in Table 1
in the Na¨ıve brute force (BF) column. e size of Z
∗
M
is equal to
φ(M). For example, |G| = 2
62.09 while |Z
∗
M
| = φ(M) = 2
215.98 for
512-bit RSA. e probability that a random 512-bit modulus N is
an element of G is 262−216 = 2
−154. is probability is even smaller
for larger keys. Hence, we can make the following conclusion with
high condence: an RSA key was generated by the RSALib if and
only if the Pohlig-Hellman algorithm can nd the discrete logarithm log65537 N mod M. Our theoretical expectation was veried
in practice (see Section 3.1) with no false positives found within a
million of tested keys.
2.3 Factorization – attack principle
Our method is based on Coppersmith’s algorithm, which was originally proposed to nd small roots of univariate modular equations.
In [22], Coppersmith showed how to use the algorithm to factorize
RSA modulus N when high bits of a prime factor p (or q) are known.
We slightly modied the method to perform the factorization with
known p mod M (= 65537a mod M).
2.3.1 Coppersmith’s algorithm. Coppersmith’s algorithm is used
as a parametrized black box in our approach. Parameters aect
the success rate and running time of the algorithm. In order to
optimize the entire factorization process, we optimized the parameters of Coppersmith’s algorithm. We choose parameters so that the
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1633
algorithm will certainly nd unknown bits of the factor and so the
computation time will be minimal. e fraction of known bits of the
factor determines the optimal parameters (100% success rate, best
speed) of the algorithm. Coppersmith’s algorithm is slowest when
using the required minimum of known bits (half of the bits of the
factor). With more bits known, the running time of the algorithm
decreases.
2.3.2 Na¨ıve algorithm. For N of the form (2), we look for factor
p or q. In order to nd a prime factor (say, p), one has to nd the
integers k, a. A na¨ıve algorithm would iterate over dierent options
of 65537a mod M and use Coppersmith’s algorithm to aempt to
nd k. e prime p (q, respectively) is found for the correct guess of
parameter a (b). e cost of the method is given by the number of
guesses (ord) of a and the complexity of Coppersmith’s algorithm.
e term ord represents the multiplicative order of 65537 in the
group Z
∗
M
(ord = ordM (65537)) and can be computed simply using
the technique described in Section 2.6. In practice, ord determines
the running time of the entire factorization. e number of aempts
is too high (see Table 1, Na¨ıve BF # aempts) even for small key
sizes. Decreasing the number of aempts is necessary to make the
method practical.
2.3.3 Main idea. A crucial observation for further optimization
is that the bit size of M is analogous to the number of known bits
in Coppersmith’s algorithm. It is sucient to have just loд2 (N)/4
bits of p for Coppersmith’s algorithm [22]. In our case, the size of
M is much larger than required (loд2 (M) > loд2 (N)/4). e main
idea is to nd a smaller M0 with a smaller corresponding number
of aempts ordM0 (65537) such that the primes are still of the form
(1), with M replaced by M0
and a, k replaced by a
0
, k
0
. e form
of the primes p,q implies that the modulus N is of the form (2)
and (3) also for M0 – of course with new corresponding variables
a
0
,b
0
,c
0
, k
0
,l
0
.
In order to optimize the na¨ıve method, we are looking for M0
such that:
(1) primes (p,q) are still of the form (1) – M0 must be a divisor
of M;
(2) Coppersmith’s algorithm will nd k
0
for correct guess of
a
0 – enough bits must be known (loд2 (M0
) > loд2 (N)/4);
(3) overall time of the factorization will be minimal – number
of aempts (ordM0 (65537)) and time per aempt (running
time of Coppersmith’s algorithm) should result in a minimal time.
For practical factorization, there is a trade-o between the number of aempts and the computational time per aempt as Coppersmith’s algorithm runs faster when more bits are known (see
Figure 2). In fact, we are looking for an optimal combination of
value M0
and parameters (m,t – for more details, see Section 2.7)
of Coppersmith’s algorithm. It should be noted that the search for
value of M0
is needed only once for each key size. e optimal parameters M0
,m,t along with N serve as inputs to our factorization
Algorithm 1.
2.3.4 Results. e optimized values of M0
for dierent key
lengths were found along with parameters m,t using a local brute
force search optimized by the results of a greedy heuristic. e
size of the resulting M0
is more than the bound loд2 (N)/4 but is
Input :N, M0
, m, t
Output :p – factor of N
c
0 ← log65537 N mod M0
. Use Pohlig–Hellman alg;
ord0 ← ordM0 (65537) . See Section 2.6 for method;
forall a
0 ∈
f
c
0
2
,
c
0+or d0
2
g
do
f (x) ← x + (M0−1 mod N) ∗ (65537a
0
mod M0
) (mod N);
(β,X) ← (0.5, 2 ∗ N
β
/M0
) . Seing parameters;
k
0 ← Coppersmith(f (x), N, β,m,t,X);
p ← k
0
∗ M0 + (65537a
0
mod M0
) . Candidate for a factor;
if N mod p = 0 then
return p
end
end
Algorithm 1: e factorization algorithm for RSA public keys N
generated by the RSALib. e input of the algorithm is a modulus N of the form (1) with M0
as a product of small primes and
optimized parameters m,t for Coppersmith’s method.
relatively close to it. e resulting order (Table 1, Optimized BF
# aempts) is small enough for the factorization of 512, 1024 and
2048-bit RSA to be practically feasible. Figure 1 summarizes the
factorization complexity and relevant parameters for all key lengths
between 512 and 4096 bits with 32-bit steps. e search space of
a
0
can be trivially partitioned and parallelized on multiple CPUs.
We veried the actual performance of the proposed factorization
method on multiple randomly selected public keys.
2.4 Coppersmith’s algorithm in detail
ere are various aacks on RSA based on Coppersmith’s algorithm
(for a nice overview, see [57]). e algorithm is typically used in
scenarios where we know partial information about the private key
(or message) and we want to compute the rest. e given problem
is solved in the three steps:
problem → f (x) ≡ 0 mod p → д(x) = 0 → x0
First, we transform the given problem to the modular polynomial
equation f (x) ≡ 0 mod p with an unknown p (divisor of some
known N) and the small root x0 (f (x0) ≡ 0 mod p) we are looking
for. e root x0 should be smaller than some suciently small
constant X (i.e., |x0 | < X). e polynomial f (x) ∈ Z[x] should be
constructed so that the root x0 solves the problem. In the second
step, Coppersmith’s algorithm eliminates the unknown p by transforming the modular equation to the equation д(x) = 0 over the
integers that have the same roots (i.e., x0 is a root of д(x)). In the
third step, all roots x0 of the integer polynomial д(x) are found easily by standard methods (e.g., the Berlekamp-Zassenhaus algorithm
[8, 21]).
e polynomial д(x) is constructed in Coppersmith’s algorithm
as a linear combination д(x) =
P
i ai ∗ fi
(x), ai ∈ Z of some polynomials fi
(x) derived from f (x). e polynomials fi are chosen so
that fi
(x) and f (x) have the same roots modulo p. is implies that
д(x) and f (x) share the same roots (with some additional roots)
modulo p as well. e main idea of Coppersmith’s algorithm is to
nd д(x) ∈ Z[x] such that |д(x0)| < p, which means that the equivalence д(x0) ≡ 0 mod p also holds over the integers, i.e., д(x0) = 0.
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1634
Key size M Size of M Size of M0 Na¨ıve BF # attempts Our BF # attempts Time per Worst case (ordM (65537)/2) (ordM0 (65537)/2) attempt
512 b P39# = 167# 219.19 b 140.77 b 2
61.09 2
19.20 11.6 ms 1.93 CPU hours
1024 b P71# = 353# 474.92 b 285.19 b 2
133.73 2
29.04 15.2 ms 97.1 CPU days
2048 b P126# = 701# 970.96 b 552.50 b 2
254.78 2
34.29 212 ms 140.8 CPU years
3072 b P126# = 701# 970.96 b 783.62 b 2
254.78 2
99.29 1159 sec 2.84 ∗ 1025 years
4096 b P225# = 1427# 1962.19 b 1098.42 b 2
433.69 2
55.05 1086 ms 1.28 ∗ 109 years
Table 1: Overview of the used parameters (original M and optimized M0
) and performance of our factorization algorithms for
commonly used key lengths. Time measurements for multiple attempts were taken on one core of an Intel Xeon E5-2650 v3
CPU clocked at 3.00 GHz, and the worst case time estimates are extrapolated from the orders and the average times required
per attempt. e expected factorization time is half of the worst case time.
512 768 1024 1280 1536 1792 2048 2304 2560 2816 3072 3328 3584 3840 4096
Key size [bits]
0
2
20
2
40
2
60
2
80
2
100
2
120
2
140
2
160
2
180
2
200
2
220
2
240
2
260
2
280
2
300
2
320
2
340
2
360
2
380
2
400
2
420
Order of 65537 (Number of Coppersmith attack attempts)
Full order of 65537: number of attempts with naïve application of Coppersmith's attack
Order of 65537 for optimized M': number of attempts for optimized order of 65537
Worst case factorization time estimate
No practical attack (theoretically possible - but lattice up to 71*71 insufficient)
Attack not possible based on Coppersmith's attack (not enough known bits)
Simulated private keys based on knowledge of real public keys
10
−6
8.75 hours
1 year
10
3
10
6
10
9
10
12
10
15
10
18
10
21
10
24
10
27
10
30
10
33
10
36
10
39
10
42
10
45
10
48
10
51
10
54
10
57
10
60
10
63
10
66
10
69
10
72
Worst case factorization time estimate [years]
Figure 1: e complexity of the factorization of keys produced by the studied RSALib with dierent key lengths starting from
512 to 4096 bits in 32-bit steps (horizontal axis). e blue crosses show the worst case estimate for the time to factorize a
key with the given length, with the vertical axis scale on the right side showing the estimated CPU eort on one core of an
Intel Xeon E5-2650 v3 CPU clocked at 3.00 GHz. e red lines show the full order of the group. e green dots show the
reduced order as achieved by our method. e yellow areas indicate the key lengths for which our method, which is based
on Coppersmith’s attack, is not applicable due to an insucient number of known bits. e orange areas indicate the key
lengths where the attack should be possible in practice; however, we were not successful in nding suitable parameters. e
gray area shows the key lengths where only public keys were available to us; hence, we simulated the private keys for the
computations backing the creation of the graph (since the structure of the keys can be recovered from either private or public
keys, the simulation should be sucient).
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1635
e polynomial д(x) is found by the LLL algorithm [51] using the
fact that the root x0 is small.
e LLL algorithm reduces a laice basis b0, · · · ,bn−1. e algorithm computes an alternative basis b
0
0
, · · · ,b
0
n−1
of the laice such
that the vectors b
0
0
, · · · ,b
0
n−1
are smaller than the vectors in the
original basis. e LLL algorithm is typically used to nd one su-
ciently short vector of the laice. e algorithm is applied to the
matrix B, which consists of row vectors bi
. e result of the reduction is the matrix B
0 of short vectors b
0
j
, which are all constructed as
linear (but with integer coecients) combinations of basis vectors
bi
. Coppersmith’s algorithm utilizes the LLL algorithm in order to
nd the desired polynomial д(x) with a small function value д(x0).
e LLL is used to nd an “equivalent” polynomial д(xX) (x – a
variable, X – a known constant) rather than д(x). e LLL is used
here to nd the polynomial д(xX) as a linear combination of polynomials fi
(xX). e LLL algorithm is applied to the matrix B that
consists of coecient vectors of polynomials fi
(xX) for |x0 | < X.
e polynomial д(x) is dened by the smallest vector b
0
0
of the reduced basis as д(x) =
Pn−1
i=0
b
0
0,i
x
i
for b
0
0
= [b
0
0,0
,b
0
0,1
, · · · ,b
0
0,n−1
].
A small norm |b
0
0
| =
qPn−1
i=0
(b
0
0,i
Xi
)
2 of the vector b
0
0
implies small
function value |д(x0)| = |
Pn−1
i=0
b
0
0,i
x
i
0
| [57, Proof of eorem 2].
2.5 Application of Coppersmith’s algorithm
Our factorization is based on the SageMath implementation [75]
of the Howgrave-Graham method [40] – a revisited version of
Coppersmith’s algorithm.
2.5.1 Howgrave-Graham method. In general, Coppersmith’s algorithm and the Howgrave-Graham method use p
m instead of p,
i.e., x0 is root of polynomials fi
(x) modulo p
m, and we are looking
for д(x) such that |д(x0)| < p
m. e method uses the following set
of polynomials fi
(x) generated as:
fi
(x) =x
jN
i
f
m−i
(x) i = 0, · · · ,m − 1, j = 0, · · · , δ − 1, (4)
fi+m (x) =x
i
f
m (x) i = 0, · · · ,t − 1, (5)
and parametrized by the degree δ of the original polynomial f (x)
(δ = 1 in our case). e Coppersmith-Howgrave-Graham method
is further parametrized by three parameters m,t,X (apart from
f (x), N), dening the matrix B and inuencing the running time.
e parameters m,t dene the number of polynomials n = δ ∗m +t
and the dimension of the square matrix B. e third parameter X
– the upper bound for the solutions we are looking for (x0 < X) –
determines the bit size of the entries of the matrix B. e running
time of Coppersmith’s algorithm is dominated by the time needed
for the LLL reduction. e running time of the LLL reduction is
given by the matrix B (the row dimension and the size of its entries)
and is mostly determined by the matrix size n.
2.5.2 Application to (p mod M0
) known. e Howgrave-Graham
method is able to nd a suciently small solution x0 of the equation f (x) = 0 mod p. In our case, the primes p,q are of the form
p = k
0
∗ M0 + (65537a
0
mod M0
), with the small k
0 being the only
unknown variable of the equation. Hence, the polynomial f (x)
can be constructed as f (x) = x ∗ M0 + (65537a
0
mod M0
), since
f (x0) = 0 mod p has a small root x0 = k
0
. e method requires
f (x) to be monic (the leading coecient is 1), but the form can be
easily obtained [57] as:
f (x) = x + (M
0−1 mod N) ∗ (65537a
0
mod M
0
) (mod N). (6)
2.5.3 Seing the parameters X and β. e parameter β represents the upper bound for the ratio of the bit size of the factor p and
the modulus N, i.e., p < N
β
. Since the bit size of both primes p,q
is half of the bit size of N, the value β is set to 0.5. e parameter
X represents the upper bound for the solution x0 of the modular
polynomial equation. In our case, X represents an upper bound
for the value of k
0
from the equation (1); hence, its value can be
computed as X = 2 ∗ N
0.5
/M0
.
2.6 Computing the order of a generator in Z
∗
M0
e order of the generator 65537 is used in our Algorithm 1 and
also for the optimization of parameters (see the next section). e
multiplicative order ord0 = ordM0 (65537) is the smallest non-zero
integer such that 65537or d0
≡ 1 mod M0
, which is equivalent to
65537or d0
≡ 1 mod Pi for all prime divisors Pi of M0
. Since M0
is
the product of dierent primes, the ord0
can be computed as the
least common multiple of the partial orders ordPi = ordPi
(65537)
for primes divisors Pi of M0
:
ord0 = lcm(ordP1
, ordP2
, · · · ) for Pi
|M
0
. (7)
2.7 Optimization of the parameters M0
,m,t
e optimization of parameters is performed only once for all RSA
keys of a given size. e parameters M0
,m,t aect the success rate
and the running time of our method. We are looking for parameters
M0
,m,t such that the success rate is 100% (k
0
is certainly found for
a correct guess of a
0
) and the overall time is minimal. e running
time (the worst case)
Time = ordM0 (65537) ∗ T (M
0
,m,t)
of our method is determined by the number of guesses (ordM0 (65537)
for the parameter a
0
) and the computation average running time T
for one aempt (computation of k
0 using Coppersmith’s algorithm).
e running time of Coppersmith’s algorithm is dominated by the
LLL reduction so it is aected mostly by the size n = m + t of the
square matrix B and partially by the size of matrix elements given
by the size of M0
. e value M0
aects both the number of aempts
(ordM0 (65537)) and the time for one aempt (T (M0
,m,t)); hence,
we optimize all parameters M0
,m,t together. During the optimization, we focus on decreasing the value ord0 = ordM0 (65537). e
optimization process can be described as follows:
(1) Compute a set of candidates for M0
, each candidate with
suciently small corresponding ord0
;
(2) For each candidate, nd the optimal (100% success rate,
minimal time per aempt) parameters m,t – only reasonably small parameters m,t are brute-forced (t = m + 1 and
m = 1, · · · , 35). For a given m,t, the Howgrave-Graham
method is applied to the polynomial (6) for correct guess of
a
0
(to compute success rate) and also for incorrect guesses
of a
0
(to compute the average time per aempt);
(3) Return the best combination M0
,m,t with the minimal
corresponding Time.
e best combination M0
,m,t was obtained with respect to the
implementation [75] of the Howgrave-Graham method applied to
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1636
2
21
2
25
Number of
attempts ●
Parameter optimization
for 512-bit RSA keys
0.001
0.01
0.1
Time/attempt
[seconds] +
0.26 0.28 0.30 0.32 0.34
Known bits as a fraction of N
10
−3
10
−2
Total time
[years]
2
31
2
38
Number of
attempts ●
Parameter optimization
for 1024-bit RSA keys
0.01
1
Time/attempt
[seconds] +
0.26 0.28 0.30 0.32
Known bits as a fraction of N
10
0
10
1
10
2
Total time
[years]
2
41
2
52
Number of
attempts ●
Parameter optimization
for 2048-bit RSA keys
0.1
10
1000
Time/attempt
[seconds] +
0.26 0.28 0.30 0.32 0.34
Known bits as a fraction of N
10
2
10
3
10
4
10
5
10
6
10
7
10
8
Total time
[years]
2
93
2
135
2
177
2
219
Number of
attempts ●
Parameter optimization
for 3072-bit RSA keys
0.1
10
1000
Time/attempt
[seconds] +
0.26 0.28 0.30
Known bits as a fraction of N
Total time
[years]
2
47
2
65
2
83
Number of
attempts ●
Parameter optimization
for 4096-bit RSA keys
0.1
10
Time/attempt
[seconds] +
0.26 0.28 0.30 0.32
Known bits as a fraction of N
Total time
[years]
2
23
2
28
2
33
Number of
attempts ●
Parameter optimization
for 544-bit RSA keys
0.01
0.1
1
Time/attempt
[seconds] +
0.26 0.28 0.30 0.32 0.34
Known bits as a fraction of N
10
−2
10
−1
Total time
[years]
Figure 2: e trade-o between the number of attempts (green circles) and the time per attempt (orange crosses) as the function
of the number of known bits (size of the optimized M0
). We select the parameters corresponding to the minimal overall time
of the factorization (blue stars). Values with the same lattice size perform an attempt in an approximately same time. e best
number of attempts for each considered lattice size (m + t) is plotted. ere can exist more than one local minimum for the
total time (as seen for 544-bit RSA keys). Please notice the logarithmic scale of the vertical axis.
Input :primorial M, ord0 – divisor of ordM (65537)
Output :M0 of maximal size with ordM0 (65537)|ord0
M0 ← M;
forall primes Pi
|M do
ordPi ← ordPi
(65537);
if ordPi
- ord0
then
M0 ← M0
/Pi
;
end
end
return M0
Algorithm 2: e computation of the maximal divisor M0 of the
primorial M with ordM0 (65537)|ord0
for a given ord0
(divisor of
ordM (65537)).
keys of a given size. We used a dataset of RSA keys of given sizes
(512 to 4096 bits, by 32-bit increments) with known factorizations
and having our special form (2). e approximate size of the optimized M0
for various key lengths can be found in Figure 1. e most
common key lengths used the following m,t values: m = 5,t = 6
for 512, m = 4,t = 5 for 1024, m = 6,t = 7 for 2048, m = 25,t = 26
for 3072, m = 7,t = 8 for 4096.
2.7.1 Optimizing M0
. In order to preserve the format of the
primes, we are looking for a divisor M0 of M (see Section 2.3.3)
that is a primorial M = 2 ∗ 3 ∗ · · · ∗ Pn. Divisor M0 of M is selected
as a candidate for an optimal M0
(with the best m,t) if the value
ordM0 (65537) is suciently small but the size M0
is large enough
(Coppersmith’s algorithm requires loд2 (M0
) > loд2 (N)/4).
Our aim is to perform a brute force search for M0
. In order to
speed up the search we are looking for the value ordM0 (65537)
rather than M0
. Once ord0 = ordM0 (65537) is found, the maximal
corresponding value M0
can be computed easily. Although the
search space for ord0
is smaller than the space for M0
, the brute
force search is still feasible only for smaller key sizes. Hence, we
used a combination of two heuristics – greedy and local brute force
search.
e general strategy is to maximize the size of M0
and simultaneously minimize the corresponding order. e value M0
for given
key size was found in two steps:
• First, we used a greedy heuristic (with a “tail brute force
phase”) to nd an “almost” optimal M0
, denoted by M0
дr eedy
with the corresponding order ord0
дr eedy
.
• Second, the value ord0
дr eedy
was used to reduce the search
space of a “local” brute force search for a beer M0
.
In both strategies, we used the simple Algorithm 2 that givenord0
looks for the maximal M0
(divisor of M) such that given ord0
equals
ordM0 (65537). In some cases, no such M0
exists, then Algorithm 2
nds M0
such that the corresponding order ordM0 (65537) is the
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1637
maximal proper divisor of given ord0
. Algorithm 2 is based on the
formula (7). e algorithm eliminates from M only those prime
divisors Pi
|M whose partial order ordPi
(65537) does not divide
given ord0
.
2.7.2 Greedy heuristic. In the greedy strategy, we try to minimize ordM0 (65537) and simultaneously maximize the size of M0
(to get loд2 (M0
) > loд2 (N)/4). e greedy heuristic is an iterated
strategy with local optimal improvement performed in each iteration. In each iteration, we reduce (divide) ord0 by some prime
power divisor p
ej
j
and compute the corresponding M0 of maximal
size using Algorithm 2. In the greedy choice, we select the most
“valuable” prime power divisor p
ej
j
of ord0
that provides a large
decrease in the order ord0
at a cost of a small decrease in the size
of M0
. e divisor is chosen as the highest reward-at-cost value,
dened as:
∆size of ordM0
∆size of M0
=
log2
(ordM0
old
) − log2
(ordM0
new
)
log2
(M0
old ) − log2
(M0
new )
for M0
new computed by Algorithm 2 with M0
old , ord0 = ordM0
old
/p
ej
j
as an input. e reward-at-cost represents the bit size reduction of
the order at the cost of the bit size reduction of M0
. e following
example illustrates how our greedy heuristic works:
Example 2.1. e initial M0
old for RSA–512 is set to M = P39# =
167# = 2 ∗ 3 ∗ · · · ∗ 167. e factorization of the initial order is:
ord0 = ordM0
old
= 2
4
∗ 3
4
∗ 5
2
∗ 7 ∗ 11 ∗ 13 ∗ 17 ∗ 23 ∗ 29 ∗ 37 ∗ 41 ∗ 83.
ere are 19 candidates 21
, · · · , 2
4
, 3, · · · , 3
4
, 5, 5
2
, 7, · · · , 83 for the
most valuable prime power divisor p
ej
j
of ord0
in the rst iteration. For the candidate p
ej
j
= 831
, Algorithm 2 eliminates 167 from
M0
old since 831
|ord167 = 166 and 831
- ord0
. Algorithm 2 returns
M0
new = M0
old /167 for the input values Mold , ord0 = ordM0
old
/831
.
e reward-at-cost for 831
is computed as log2
83/ log2
167 =
6.37
7.38
for the reduction of the order by 6.37 bits and the reduction of
M0 by 7.38 bits. For the candidate 171
, Algorithm 2 eliminates
103, 137 (i.e., M0
new = M0
old /(103 ∗ 137)), since 17|ord103 = 51 =
17 ∗ 3, 17|ord137 = 136 = 17 ∗ 8 and 171
- ordM0
old
/17. e
reward-at-cost for 171
is computed as log2
17/ log2
(103 ∗ 137) =
4.08/13.78, etc. e most valuable candidate in the rst iteration is
p
ej
j
= 831 with the highest reward-at-cost 0.8633.
In the second iteration, we start with M0
old = M/167 and ord0 =
ordM0
old
= 2
4
∗ 3
4
∗ · · · ∗ 7 ∗ 11 ∗ 13 ∗ 17 ∗ 23 ∗ 29 ∗ 37 ∗ 41 and
compute the new reward-at-cost for all 18 candidates 21
, · · · , 2
4
,
3, · · · , 3
4
,5, 5
2
, 7, · · · , 41. In the second iteration, the best candidate
for divisor p
ej
j
of new ord0 with the highest reward-at-cost is p
ej
j
=
531
, etc.
roughout the iterations, the following best candidates for p
ei
i
are found: 831
, 531
, 411
, 291
, 371
, 231
, 171
, 3
2
, 111
.
In the last iteration, the greedy heuristic computes M0
that is
too small (log2
(M0
) < log2
(N)/4), which nishes the computation.
e resulting M0 = 0x55eb8fbb4ca1e1879d77 from the previous
iteration is computed by Algorithm 2 for M0 = M/83/53/ · · · /11.
e greedy method returns an optimal M0
for 512-bit RSA keys.
e optimality was veried by brute force, testing all possible divisors of M with suciently small corresponding order.
2.7.3 Tail brute force. e greedy strategy can be improved for
larger keys by brute force testing all divisors of ordM0 that is found
by the greedy heuristic. First, we execute the greedy strategy, that
gives us the sequence of the values of M0
0
> M0
1
> · · · > M0
L
from the iterations 0, 1, · · · , L. en, we use brute force (testing
all divisors) for ordM0
i
, starting with M0
L−1
and continuing with
M0
L−2
, · · · , limited by reasonable running time.
2.7.4 Local brute force. ere are two ways to perform the brute
force search for an optimized M0
(divisor of M). We can search
through divisors M0 of M, or we can use an alternative search
through all divisors ord0 of ordM (65537) (M0
|M =⇒ ordM0 |ordM )
and compute the corresponding M0
from ord0 using Algorithm 2.
We use the second approach since the search space for ord0
is
signicantly smaller than that for M0
. For example, for 512-bit RSA
keys, M = P167# is product of 39 primes, i.e., there are 239 dierent
divisors of M, while there are only 52
∗3∗2
9 ≈ 2
15 dierent divisors
of ordM (65537) = 2
4
∗ 3
4
∗ 5
2
∗ 7 ∗ 11 ∗ 13 ∗ 17 ∗ 23 ∗ 29 ∗ 37 ∗ 41 ∗ 83.
For smaller key sizes, it is possible to search through all divisors
of the order, but for large key sizes (e.g., 4096-bit RSA), the brute
force strategy is infeasible and needs to be optimized. We implemented an algorithm that recursively iterates through all divisors
ord0 of ordM (65537). Recursion allows us to optimize the search
and to skip inappropriate candidates (small M0
, big ordM0 (65537))
for an optimal M0
.
We use two approaches that recursively iterate through orders:
• Decreasingly – In this approach we start with the full
order ord0 = ordM (65537), and in each iteration, we divide ord0 = ord0
/pj by a prime divisor of current ord0
.
e branch of the recursion is stopped when M0
is too
small (loд2 (M0
) < loд2 (N)/4). is approach is suitable
for key sizes with bit sizes of M0
close to the lower bound
loд2 (N)/4 because only several primes pj can be eliminated
from ord0
and most inappropriate candidates are skipped
due to a small size of M0
.
• Increasingly – We start with ord0 = 1 and in each step
multiply the order ord0 = ord0
∗pj by some prime divisor pj
of ordM (65537). When ord0
is too large, we stop the given
branch of the recursion and skip the worst candidates. As
an upper bound for ord0
, we use the value ordдr eedy ∗ 2
5
.
is approach is suitable for key sizes for which the bit
size of M0
is signicantly bigger than loд2 (N)/4 since most
candidates are skipped due to the large value of ord0
.
2.8 Guessing strategy
Our method can nd the prime factor p for the correct guess x of
a
0
. A simple incremental search x = 0, 1, · · · for a
0 would iterate
through ordM0 (65537) for dierent values of x in the worst case
since
p = 65537a
0
mod M
0
.
Denoting ord0 = ordM0 (65537), we are looking for x ≡ a
0 mod
ord0
.
Since both p,q are of the same form, our method can also nd
the factor q for x ≡ b
0 mod ord0
. Hence, our method is looking
simultaneously for p and q. is fact can be used to halve the time
needed to nd one of the factors p,q of N. In order to optimize the
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1638
guessing strategy, we are looking for the smallest subset (interval)
of Zor d0 that contains either a
0 or b
0
. We use the value c
0 obtained
during the ngerprinting (a discrete logarithm of N) to describe
the desired interval. e interval is of the following form:
I =
"
c
0
2
,
c
0 + ord0
2
#
.
It is easy to see that either a
0 or b
0
(c
0 ≡ a
0 +b
0 mod ord0
) occur in
the interval I and that the size of the I is the smallest possible.
3 PRACTICAL IMPLEMENTATION
We implemented the full aack in SageMath, based on an implementation [75] of the Howgrave-Graham method [40]. We used
it to verify the applicability of the method on real keys generated
on the vulnerable smartcards. It was also used to perform time
measurements in order to optimize our parameters and evaluate
the worst case running time, as captured by Figure 1 and Table 1.
3.1 Details and empirical evaluation
e ngerprint verication algorithm computes the discrete logarithm of a public modulus. We chose the primorial of 512-bit RSA
as the modulus, since it applies to all key lengths. We recorded no
false negatives in 3 million vulnerable keys generated by RSALib,
since all of the keys have the sought structure. As expected, no false
positives were recorded on 1 million non-aected keys generated
by OpenSSL. We estimated the probability of a false positive on a
single key as 2−154 in Section 2.2.2.
We practically veried the factorization method on multiple
randomly selected 512 and 1024-bit keys. Since the complexity of
factorization of a 2048-bit key could be approximately 100 CPU
years, we did not select keys randomly. Instead, we generated
keys on an aected smartcard and exported the private keys. e
knowledge of the primes allows us to precisely compute the number
of aempts required for the factorization as the distance of the
initial guess c
0
/2 (Section 2.8) to a
0 or b
0
(whichever is closer).
Out of 137,000 freshly generated keys, we selected 24 public keys
with the least eort required (all keys with 221 aempts or fewer)
for factorization and ran the computation, each nishing within
one week. We used the time measurements to verify the linear
relationship of factorization time on the order and we checked that
the worst case time estimate matches the slope of the line.
3.2 Possible improvements and limitations
e aack can be trivially parallelized on multiple computers. Each
individual task is assigned a dierent subrange of the values a
0
that
need to be guessed. e expected wall time of the aack can be
decreased linearly with the number of CPUs (assuming that each
task can execute the same number of aempts per a unit of time).
However, the expected CPU time and the worst case CPU time
remain unaected.
e time of each aempt is dominated by laice reduction. Our
implementation uses the default implementation of LLL in SageMath (backed by the fpyLLL wrapper for fpLLL [27]). A more
ecient implementation might speed up the process. However, we
do not expect signicant improvements.
In our opinion, the best improvement could be achieved by a
beer choice of polynomials in the phase of laice construction.
We follow the general advice for polynomial choice from [57]. More
suitable laice may exist for our specic problem.
Our algorithm for optimizing the running time utilizes a heuristic
for nding an optimized value of the modulus M0
. A beer heuristic
or a bruteforce search might nd a modulus, where the generator
has a lower order or could discover a beer combination of the
laice size and M0 value.
Despite an extensive search for beer values within a signi-
cantly larger space (Section 2.7.4), we obtained only small improvements of the overall factorization time (halving the overall time
at best in comparison to the greedy algorithm). We examined the
trade-o between the number of aempts and the time per aempt,
as captured by Figure 2 to understand the nature of the optimization
process.
We did not explore implementations of laice reduction backed
by dedicated hardware or GPUs. Most key lengths are processed
with a laice of low dimensions, however, some improvements
may be gained for lengths that require a large laice [39]. In our
experience, the memory used by one factorization was up to 300 MB.
SageMath is an interpreted language, so the requirements of a
hardware circuit might be dierent.
Finally, we cannot rule out that a fundamentally improved approach, which would utilize the properties of keys more eciently,
will be devised.
4 ANALYSIS OF IMPACTS
e discussion of impacts is far from straightforward. First, the
prevalence of factorizable keys in a given usage domain is between
very easy to very dicult to obtain. For example, the prevalence
of ngerprinted keys used for TLS is easy to enumerate thanks
to Internet-wide scans like Censys [28]. Obtaining large datasets
of public keys for usage domains for devices expected to be more
vulnerable (e.g., electronic passports) is usually signicantly harder
given the nature of secure hardware use.
Secondly, the actual damage caused by a factorized key varies
signicantly between and also within the usage domains. Finally,
not all key lengths are actually factorizable, and the factorization
time varies signicantly – hence, the security of a particular key
length depends on the target domain.
We discuss the overall impact based on the following aspects:
(1) Accessibility of public keys – how dicult it is for an
aacker to obtain the target public key(s) for subsequent
factorization aempts;
(2) Total number of factorizable keys found or assumed – as
detected by scans of a given usage domain;
(3) Cost to factorize the keys with the lengths actually used
in the target domain (as estimated in Table 2);
(4) Implications of a successful factorization – what damage
the aacker can cause.
Note that due to the varying parameter M used by the RSALib
when generating the keys of dierent lengths, the diculty of key
factorization does not strictly increase with the key length (see
Figure 1). Some shorter keys may be actually more dicult to
factorize using our method than other longer keys. As an example,
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1639
Key size University cluster Rented Amazon c4 instance Energy-only price ($0.2/kWh)
(Intel E5-2650 v3@3GHz Q2/2014) (2x Intel E5-2666 v3@2.90GHz, estimated) (Intel E5-2660 v3@2.60GHz, estimated)
512 b 1.93 CPU hours (veried) 0.63 hours, $0.063 $0.002
1024 b 97.1 CPU days (veried) 31.71 days, $76 $1.78
2048 b 140.8 CPU years 45.98 years, $40,305 $944
3072 b 2.84 ∗ 1025 years 9.28 ∗ 1024 years, $8.13 ∗ 1027 $1.90 ∗ 1026
4096 b 1.28 ∗ 109 years 4.18 ∗ 108 years, $3.66 ∗ 1011 $8.58 ∗ 109
Table 2: An estimation of factorization times and prices for dierent key lengths on dierent types of computational devices.
All results are the worst case estimates with expected resources spent being the half of the values shown. e time values
marked as (veried) were practically veried by factorization of real test keys while others were extrapolated based on a know
number of attempts and a time per attempt. e energy consumption was estimated based on the thermal design power (TDP)
specications of Intel Xeon E5-2660 v3 @ 2.60 GHz [42] (note that peak power can be up to 1.5-3x more), time per attempt as
benchmarked on Amazon c4 instance, energy price of $0.2/kWh and scaled to 2.90 GHz (as Amazon c4 uses publicly unreleased
Intel Xeon E5-2666 v3 clocked at a slightly higher frequency). e university cluster column captures the factorization times
as measured by us on a university computational cluster with Intel Xeon E5-2650 v3 @ 3.00 GHz CPUs scaled to a singlecore of this CPU. e Amazon c4 instance price corresponds to outsourcing of a single key factorization to Amazon AWS (c4
price is $0.1/hour for a 2-core CPU). We performed benchmark on a c4 instance for a single Coppersmith’s computation and
extrapolated to number of attempts in the worst case. e energy-only price corresponds to situation when one operates own
hardware and wants to factorize so many keys that the price of hardware completely amortizes over all factorized keys. A
factorization benchmark on Microso Azure was also performed with results roughly comparable to Amazon AWS (+10%).
a 1280-bit key is more dicult to factorize than a 2048-bit key in
our seing. It is crucial to survey the precise key lengths as used
within the inspected domains. We take advantage of the possibility
to quickly detect the key ngerprint, with quick summary of the
aected domains in Section 4.1 and in Table 3 and Table 4 followed
with additional details for every domain thereaer.
4.1 Summary of results
e electronic identity documents (eIDs) domain is signicantly
aected. Despite the general diculty of obtaining relevant datasets
with public keys from passports or eIDs that limited our analysis to
only four countries, we detected two countries issuing documents
with vulnerable keys. e public lookup service of Estonia allowed
for a random sampling of the public keys of citizens and revealed
that more than half of the eIDs of regular citizens are vulnerable
and that all keys for e-residents are vulnerable.
e use of two-factor authentication tokens and commit signing
is on the rise, yet these approaches are still adopted only by a minority of developers – but usually for the more signicant projects.
e analysis of the authentication keys of all GitHub developers
found several hundreds of vulnerable keys. e developers with
vulnerable keys have access to crucial open-source repositories
with more than 50,000 stars. Increased scrutiny should be applied
to new commits before the aected users replace vulnerable keys.
Trusted Platform Modules (TPMs) provide secure hardware anchor for trusted boot. Although it is dicult to directly extrapolate
the overall prevalence of chips with vulnerable keypair generation
from our limited sample of 41 laptops with dierent TPM chips,
approximately 24% were producing vulnerable keys, indicating that
the domain is signicantly aected. As the replacement of a chip
alone is very impractical or almost impossible, organizations have
to replace the whole laptop, slowing down the recovery from the
problem. Importantly, TPM is used not only to facilitate trusted
boot, but also to store sensitive secrets like ones necessary to access
the Volume Master Key (VMK) for Microso BitLocker full disk encryption soware [58]. e possibility to factorize TPM’s 2048-bit
key for “sealed storage” might lead to a recovery of BitLocker’s disk
decryption key in the conguration using a TPM and a PIN.
e Prey Good Privacy (PGP) keys used for digital signatures
and email encryption are easy to download from PGP keyservers.
We detected almost three thousand ngerprinted keys with slightly
less than one thousand practically factorizable. e Yubikey 4 token
seems to be the origin for the majority of these keys as hundreds
even contain identifying strings in the keyholder information and
the date of generation correlates with the release date of this token.
We found only a negligible fraction of vulnerable keys in the
TLS/HTTPS domain. However, all 15 unique keys found were tied
to dierent pages with SCADA-related topics, which may point to
a single provider of a SCADA remote connection platform.
We did not collect relevant datasets of public keys for authentication tokens implementing PIV or U2F standard but found at
least one instance of a widely used token utilizing chips with the
aected RSALib. Similarly, other devices (e.g., e-health and EMV
payment cards) might be impacted by the described vulnerability,
although we were not able to verify the impact in such domains.
We encourage the use of our tool for detecting vulnerable keys
described in Section 5 and the notication of aected parties if
found.
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1640
4.2 Electronic identity documents
Various citizen identity documents represent a large area for the
application of cryptographic smartcards, such as biometric passports (ePassport, ICAO Doc 9303), eDriver licenses (ISO/IEC 18013)
and additional identity documents. Some national IDs are based on
the same suite of protocols as ePassports, which are standardized
by ICAO 9303 [41]. Other countries have implemented their own
suite of protocols, such as the Estonian EstEID [5], the Belgian eID
[6] or the Taiwanese ID.
Electronic passports and identity cards utilize digital signatures
for: 1) the authentication of stored data (passive authentication);
2) the verication of the genuine origin of the chip inside (active
authentication, AA); and 3) the establishment of a secure channel between the passport and the border inspection terminal with
mutual authentication (Extended Access Control, EAC-PACE). Additionally, in some instances, the issuing country uses the national
IDs for citizen authentication when accessing government services
via the Internet.
e suppliers of ePassport implementations typically provide the
platform in several possible congurations with dierent supported
algorithms (RSA-based, EC-based) and protocols (EAC-PACE, AA),
leaving the choice of the preferred conguration to the issuing
country. e use of the RSALib is referenced in multiple certication
documents of electronic passports of several countries.
We are not aware of any country disclosing publicly the full
database of their citizens public keys. A small fraction of countries
provide lookup services with signicant limitations on the number of queries allowed. We analyzed four dierent types of digital
certicates issued by the country of Estonia: a) regular citizenship
eID keys (denoted as esteid); b) eID keys for electronic use only
(“digital certicate of identity”, denoted as esteid-digi); c) keys for
operations from mobile devices (denoted as esteid-mobiil); and d)
e-resident keys (denoted as esteid-resident). For every type, separate authentication (auth) and signature (sign) 2048-bit RSA keys
are available. e keys are used to support various eGovernment
services, including VAT forms, private companies management (all
types) and voting (esteid). In total, we analyzed the keys of approximately 10% of randomly selected citizens. e results showed a
mix of on-card and out-of-card key generation. More than half of
the analyzed keys were vulnerable for esteid and all keys were vulnerable for esteid-digi and esteid-resident. No vulnerable keys were
detected for esteid-mobiil. Extrapolation to the whole population
results in at least hundreds of thousands of vulnerable keys.
Additionally, we analyzed keys from a limited sample of keys
extracted from the physical electronic documents of three other
countries and detected one (Slovakia) issuing documents with ngerprinted 2048-bit keys.
ese results also demonstrate the general diculty of analyzing
the impacted domains – large-scale analysis was possible only for
the Estonian eID because of the public directory with more than
half of the documents found to be vulnerable. e small samples
collected for other countries (like Slovakia) give only very limited
insight – are all other documents vulnerable or only a limited
production series given the two vulnerable IDs detected? Or were
only documents from non-vulnerable series for other countries
inspected?
e possibility of factorizing on-card keys would lead to cloning
of legitimate passports or identity cards. e Slovak national ID in
question is also deployed in the wider context of an eGovernment
system, where the on-chip generated digital signatures serve as a
replacement for traditional hand-wrien signatures.
4.3 Code signing
e digital signing of applications, modules, OS distributions or
code is now common. In some cases, application signing is mandatory and enforced by the platform (e.g., Android, iOS, OS drivers)
or voluntarily adopted by the developers. GPG signatures can be
also used to authenticate commits or tags submied by developers
to a source control system (e.g., GitHub).
4.3.1 GitHub. To access the Git repositories hosted on GitHub,
developers can use SSH authentication as an alternative to a password for both read and write permissions. Users may also upload
GPG keys for commit signing. e public keys of all users are
accessible via the public GitHub API. We analyzed the proles of
almost 25 million GitHub users and found 4.7 M SSH keys in a scan
performed in February 2017.
Hundreds of ngerprinted keys were found, including keys with
access to very popular repositories with up to 2,000 stars (users
bookmarking the project) for user-owned repositories and more
than 50,000 stars for organization-owned repositories, including
repositories that are very inuential in the Internet community.
e impact is increased by the fact that some relevant repositories
are libraries used in other projects and are essentially trusted by
third-party developers.
In total, we found 447 ngerprinted keys. More than half (237)
have practically factorizable key length of 2048 bits, with the rest
mostly being 4096-bit RSA keys. However, it is not straightforward
to determine whether a particular account has write access to repositories not explicitly owned by the account. Similarly, membership
in an organization does not guarantee write access to particular
repositories. GitHub does not provide this kind of information
directly, and the APIs that can be used to derive this information
are quite limited. e information can be inferred from an analysis
of previously performed commits by the given user. We veried
several instances manually and conrmed access with factorizable
keys.
We view the overall impact as signicant. Luckily, any potential
changes made to a repository can be traced back to a particular
commit due to the nature of source control systems. Many projects
also use commit reviews (e.g., using pull requests), where increased
caution should be used until the aected users move to more secure
keys.
4.3.2 Maven. e Maven public repository has required developers to sign uploaded artifacts since approximately 2009 [54]. Each
developer must be associated with a PGP key that is also publicly
reachable from a PGP keyserver. Each artifact is uniquely identied
by a tuple (group ID, artifact ID, version). We downloaded the most
recent versions of each artifact found in the Maven repository index
in April 2017. In total, we downloaded 180,730 artifacts equipped
with the Maven index le (pom.xml) – 161,841 had a signature on
the pom.xml le. ere were 16,959 unique PGP keys found, of
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1641
which 5 were ngerprinted, all with 4096-bit moduli (not considered
practically factorizable by our method). e potentially aected
artifacts appear as dependencies only in a few other artifacts. We
therefore estimate the impact as small.
4.3.3 Android. We downloaded the 540 most popular Android
applications and the 540 top ranking Android games according to
the Google Play top charts. e content of the Android application package (APK) is signed with the developer key before being
published to the Google Play system. ere is no simple way for
the developers to change the signing keys; hence, the applications
will most likely have used the same keys since the time of the rst
upload. No ngerprinted keys were detected among the top 540
applications and games in a scan performed in January 2017. e
analysis should be also extended to less popular applications. If
any vulnerable keys are found in other already established applications, the aected developers may have complications migrating to
dierent signing keys.
4.4 Trusted Platform Modules
Trusted Platform Module (TPM) is a specication created by the
Trusted Computing Group [34, 35]. TPMs are cryptographic hardware (usually in form of a chip aached to a motherboard) that
provide basic cryptographic functionality. e typical use cases
include: a) secure storage of a user’s private keys or disk decryption
keys; b) maintaining an unspoofable log of applications that were
deployed on a target machine via a hash chain (Platform Conguration Registers – PCRs); and c) aestation of the state of the platform
to a remote entity by an on-TPM signature of the PCRs. e TPM
specication version 1.2 supports only RSA with 2048-bit keys [34].
We analyzed a sample of 41 dierent laptop models equipped
with TPM chips. Six dierent manufacturers were detected, with
chips supplied by Manufacturer (acronym IFX) being the most common and found in 10 devices. TPM chips from devices produced
before 2013 and with rmware versions5 between 1.02 and 3.19 do
not exhibit a ngerprint and are not factorizable by our method.
All chips found in devices introduced in 2013 or later were vulnerable, including both TPM 1.2 and TPM 2.0. In our sample, the
ngerprinted keys from the RSALib appear earliest in the rmware
version 4.32 (however, we had no TPM chip with a version between
3.19 and 4.32 in our sample). All subsequent chip versions, including 5.x and 6.x, were also found to produce vulnerable keys. We
hypothesize that the RSALib was rst used with TPM rmware
version 4.x.
ere are two important RSA private keys stored inside a TPM –
the Endorsement key (EK), which is permanently embedded by the
chip manufacturer during its production and cannot be changed,
and the long-term Storage Root Key (SRK), which is generated onchip when a user claims the TPM ownership. Additionally, dedicated Aestation Identity Keys (AIKs) used for Remote Aestation
may be generated.
e factorization of the EK compromises the root of trust for chip
authentication. An aacker can generate a new keypair outside
the TPM and then sign it with the factorized EK; hence, it will be
trusted by the remote system (e.g., the company network).
5e version of the rmware of the TPM chip does not directly relate to the version of
the RSALib.
e TPM can hold only a very limited number of private keys
directly on the chip. All other private keys are generated inside the
TPM but are then wrapped by the SRK and exported outside the
TPM. If required, the keys are imported back, unwrapped and used.
e factorization of the SRK therefore allows an aacker to decrypt
all previously exported wrapped private keys, including the “sealed
storage” packages with sensitive information otherwise readable
only on the particular machine with the associated AIK keys used
for Remote Aestation. If AIK is directly factorized or its value
is compromised due to the factorization of the SRK, an aacker is
able to forge an aestation report – allowing the aacker to start
additional or modied malicious soware without being noticed.
e “sealed storage” is also utilized by Microso BitLocker full
disk encryption soware [58] to store a sensitive value required
to obtain the Volume Master Key [48, 49]. BitLocker is typically
setup together with TPM and an additional secret – either a PIN, a
recovery key on a USB token, or both. e possibility to factorize
TPM’s 2048-bit SRK directly leads to a decryption of an unwrapping
key necessary to decrypt the Volume Master Key, thus bypassing
the need for TPM to validate the correctness of a PIN value via a
dedicated PCR. As a result, an aacker can decrypt a disk from a
stolen laptop with a vulnerable TPM if encrypted by BitLocker in
TPM+PIN mode (but not in a conguration with an additional USB
token). We did not verify the aack in practice due to BitLocker’s
proprietary storage format and the cost of factorization of a 2048-bit
SRK key.
4.5 PGP with cryptographic tokens
e private key as used in Prey Good Privacy (PGP) [29] is typically a very sensitive long-term secret. If compromised, an aacker
can forge new signatures and decrypt all previously captured messages since PGP does not provide forward secrecy. Many users
choose to use a cryptographic device that stores and performs private key operations inside a secure environment using an OpenPGP
compliant application [62].
A large fraction of public keys used for PGP can be easily downloaded from PGP keyservers [4]. Since the content of PGP key
servers is publicly available, the vulnerable keys can be easily identied together with the associated user contact information. We
analyzed the state of a PGP keyserver from mid-April 2017 that
contained a total of 4.6 M master keys and 4.4 M sub-keys with
1.9 M and 1.7 M, respectively, being RSA keys. We detected 2,892
ngerprinted keys. Of these, two keys are 1024-bit and 954 keys are
2048-bit – both lengths are practically factorizable. Additionally, 86
and 1846 ngerprinted (but not feasibly factorizable by our method)
keys of 3072 and 4096-bit lengths, respectively, were detected. Finally, four keys with uncommon lengths of 3008 and 3104-bit were
present.
e earliest creation date of a ngerprinted key as obtained
from a PGP certicate is 2006, yet only for a single user – we
hypothesize this nding was caused by an incorrect system clock.
e subsequent observed year is 2009, again with a single user only.
2013 is the earliest year with keys from multiple users.
No key is observed originating in the year 2014, with more ngerprinted keys observed from July 2015 onwards. e date coincides
with the ocial launch of a cryptographic token Yubikey 4 (further
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1642
Domain name Used length (bits) Pub. key availability Misuse
TLS/HTTPS 2048 easy MitM/eavesdropping
Message security (PGP) 1024/2048 easy message eavesdropping, forgery
Trusted boot (TPM) 2048 limited unseal data, forged aestation
Electronic IDs (eID, ePassport) 2048 limited clone passport, e-gov document forgery
Payment cards (EMV)* 768/960/1024/1182 limited clone card, fraudulent transaction
Certication authorities (root, intermediate)* 2048 or higher easy forged certicates, MitM
Authentication tokens (U2F) 2048 or higher limited unauthorized access or operation
Soware signing 2048 or bigger easy malicious application update
Programmable smartcard (Java Card) 1024-4096 depends on use depends on use
Table 3: e summary of the impact of key factorization in the dierent usage domains. e ngerprinted keys were found
within all listed domains with exceptions marked with an asterisk (*). No ngerprinted keys were found in the very limited
dataset of 13 EMV cards that we collected or for large datasets of browser-trusted root and intermediate CAs.
Domain name Analyzed datasets # Vuln. keys/devices % Vulnerable
Complete/larger-scale datasets
Certication authorities all browser-trusted roots (173), level 6 3 intermediates (1,869) 0 keys 0
ePass signing certicates ICAO Document Signing Certicates, CSCA Master Lists 0 keys 0
Estonian eID sample of 130,152 randomly selected citizens 71,417 keys 54.87
Estonian mobile eID sample of 30,471 randomly selected citizens 0 keys 0
Estonian e-residents sample of 4,414 e-residents 4,414 keys 100
Message security (PGP) complete PGP key server dump (9 M) 2,892 keys 0.03
Soware signing (GitHub) SSH keys for GitHub developers (4.7 M) 447 keys 0.01
Soware signing (Maven) signing keys for all public Maven artifacts 5 keys 0.003
TLS/HTTPS complete IPv4 scan, Certicate Transparency 15 keys <0.001
Trusted boot (TPM) 41 laptops with dierent chips by 6 TPM manufacturers 10 devices 24.39
Limited, custom-collected datasets
Payment cards (EMV) 13 cards from 4 EU countries, 6 with Manufacturer chip 0 keys 0
Programmable smartcard 25 cards from JCAlgTest.org database, 6 with Manufacturer chip 2 cards 8.67
Soware signing (Android) 1,080 top ranking applications and games 0 keys 0
Table 4: e summary of the number and fraction of vulnerable keys detected in dierent domains. e domains are ordered
lexicographically and separated into two groups based on the representativeness of inspected datasets.
denoted as Token). is hints that Token is the major source of the
ngerprinted keys in the PGP dataset Out of 2,892 ngerprinted
keys, 436 even contain some form of Token-related identication
in the User ID string (154 being master keys with the rest being
sub-keys). Of these, no key with a length shorter than 2048-bit is
present, 96 keys are 2048-bit and 340 keys have a length of 4096 bits.
Given that an older version of Token is not producing ngerprinted
keys, all these keys were likely generated by the newer version of
Token.
e Token vendor recommends generating a keypair outside the
token (for example, using OpenSSL) and importing it to facilitate
private key recovery aer a potential token failure. Interestingly,
such advice seems not to have been followed by a signicant number
of users (the users who followed this advice are not detected by our
ngerprinting method as their keys have no ngerprint).
e evidence for other devices (not produced directly by the
Manufacturer) generating ngerprinted keys also shows that the
RSALib is provided to external parties developing for the Manufacturer hardware.
We would like to stress that not all key lengths generated with
Token are immediately practically factorizable by our method. Token
can generate and use RSA keys up to 4096 bits long, which may be
one of the appeals of the device – given the lack of other available
smartcards supporting key lengths exceeding 2048 bits. Indeed, the
analysis of the ngerprinted PGP keys with respect to the used
length shows a strong user preference for 4096-bit keys. Token
can also generate less common key lengths including 3936-bit RSA
where our aack is not directly applicable, as seen in Figure 1. e
majority of the Token users on this domain therefore should not be
imminently aected by direct factorization using our aack, but
we urge the generation of fresh keys – in light of potential further
improvement of an aack.
4.6 TLS and SCADA-related keys
We used our ngerprinting method on two large datasets of public
key certicates, used (mostly) to secure Internet TLS connections.
One dataset originates from a periodic scan of the whole IPv4 address space between 2012 and 2017 [28] collected from servers
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1643
listening on port 443 and congured to prefer RSA signatures. e
second dataset comes from the Certicate Transparency logs maintained by Google [33] (CT logs maintained by Google included in
Google Chrome, date 2017-04-25). In total, we analyzed more than
100 million certicates.
Despite the relatively large number of keys, we only found 15
distinct ngerprinted keys – four were 1024 bits long and eleven
with 2048 bits – used in tens of dierent certicates. Surprisingly,
almost all these certicates contain the string “SCADA” in the common name eld (probably referring to Supervisory Control and
Data Acquisition systems) or a URL leading to a website related
to an industrial monitoring system, or both. As a result, we hypothesize that there is at least one provider of a remote connection
platform with a focus on SCADA systems. It is not clear to us
whether the interfaces are linked to real industrial systems since
administrators of such systems may want to limit the access from
the Internet. Hence, there might exist more systems with administration interfaces protected by vulnerable keys, but deployed on
local networks.
Interestingly, all 15 keys contain the inspected ngerprint, but
the majority of values of the most signicant byte (MSB) of their
moduli are signicantly outside the range observed in the RSALib
(the MSB of keys produced by the inspected smartcards and TPMs
always falls in the interval 0x90-0xA8). is nding suggests the
existence of a dierent implementation of the prime construction
algorithm with the same structure but a dierent modication of
the most signicant bits.
e factorization of the key of a TLS server trivially leads to
numerous powerful aacks: server impersonation, active manin-the-middle aack or passive decryption of the content of the
communication when the connection establishment lacks forward
secrecy. Overall, the impact on the public portion of the Internet
seems to be only very marginal due to the small number of detected
vulnerable TLS keys. However, the potentially signicant impact for
the entry points of some SCADA services should not be neglected.
4.7 Certication authorities
e presence of vulnerable keys belonging to certication authorities would magnify the impact due to the possibility of key certi-
cate forgery. We therefore examined two signicant usage domains.
Browser-trusted certicates. We examined the certicates of root
certication authorities stored in Mozilla Firefox as browser-trusted
roots (158 certicates) and in Ubuntu 16.04 (173 certicates). e
intermediate authorities of level 1 (1,016 total), level 2 (832 total)
and level 3 (21 total) as extracted from TLS scans were also analyzed.
No ngerprinted keys were detected as of May 2017.
ICAO signing certicates. We analyzed the collection of Document
Signing Certicates (DSCs) of the ICAO ePassport database (version 2044) containing 8,496 certicates, and the collection of CSCA
Master Lists (version 84) with 616 certicates. We also inspected the
publicly available national certicates (e.g., Belgium, Estonia, Germany, Switzerland) [43, 68] available as of May 2017. Fortunately,
no vulnerable keys were found in either dataset, as the occurrence
of such a certicate would lead to the possibility of impersonating
an inspection terminal or forging electronic document data.
4.8 Generic Java Card platform
Smartcards using the Java Card platform [59] have two principal
congurations: 1) an open, fully programmable platform where
the users develop and upload their own applications; and 2) Java
Card-based systems closed from the point of view of cryptography
(e.g., banking EMV or SIM cards). Here, we focus on the former
conguration.
e prevalence of the RSALib in the area of programmable smartcards is notoriously dicult to estimate. Not all smartcards based
on the Manufacturer’s hardware are vulnerable, as the vulnerability
stems from the deployed cryptographic library and not from the
hardware design itself. Many vendors use the bare hardware (e.g.,
SLE78 chip) and choose not to deploy the RSALib in question. In
such a case, the implementation of the higher-level cryptographic
functions (including RSA keypair generation) is done by the company that builds on the hardware produced by the Manufacturer.
Although the vulnerable keys have a strong ngerprint that can
be easily veried, the real problem (for impact assessment) lies in
obtaining sample public keys. No representative public databases
(comparable to those for TLS and PGP) are available.
Our analysis is based on smartcards from 10 dierent platform
providers (Axalto, Feitian, G&D, Gemalto, Inneon, JavaCardOS,
NXP, Oberthur, Solock and Yubico) as recorded by the JCAlgTest
database [60]. e chip manufacturer (ICFabricator property) and
the manufacturing date (ICFabricationDate) can be obtained from
the Card Production Life Cycle (CPLC) information as dened by
the GlobalPlatform specication [32].
Out of the 63 dierent cards included, 25 cards are listed with
the provided CPLC information: 16x NXP (ICFabricator = 4790),
6x Inneon (4090), 1x Samsung (4250) and 2x unknown (2050 and
4070). Out of six cards with a Manufacturer chip, two produce
ngerprinted keys. e ICFabricationDate property indicates the
years of manufacture to be 2012 and 2015. Hence, our estimate
of the prevalence of the vulnerability is conrmed again since it
corresponds to the situation observed in TPM chips.
e full impact of the vulnerability will depend entirely on the
scenario in which the cards are actually used. e large number
of already fabricated and distributed smartcards may hinder the
potential for a recall of the product from the market. e card operating system and the base libraries are stored in read-only memory
and cannot be updated by the user to remove the vulnerability once
a card is deployed. We expect to see the cards for a rather long
time (several years) before all the vulnerable cards are eventually
sold out, especially when dealing with low volume markets. e
buyers should check the cards for the presence of ngerprinted
keys and/or opt for longer key lengths if they are supported by the
card hardware.
4.9 Other domains
e smartcards are also used in many other domains than those
surveyed here in the previous sections, including authentication
tokens (e.g., U2F [70]); e-health cards to authenticate both patients
and medical sta to access medical records or personal identity
verication cards (FIPS 201 PIV [61]); and electronic payment cards
(EMV).
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1644
e chip-based payment cards used world-wide are backed by
a set of protocols specied under the EMV standard [52], which
is currently maintained by the EMV consortium. e RSALib was
approved for use in EMV cards by EMVCo [2, 3], and we found
several references to it in related certication reports. However,
we are not aware of any public dataset of keys originating from
EMV cards. We collected a tiny sample of RSA keys from 13 payment cards issued by dierent banks in four European countries.
Although 6 cards reported chips produced by the Manufacturer,
none of them contained the distinctive ngerprint, meaning that
the RSA key generation method implemented by the RSALib was
not used in either one.
If used, the potential impact of factorizable keys would be particularly damaging to EMV cards due to the generally short RSA
key lengths used. Short keys are oen used for legacy reasons or to
improve the usability of payments by the shorter time required to
authorize the transaction (especially relevant for contactless payments). Out of the 13 cards inspected, we observed the following
bit lengths of ICC keys: 768 (3x), 896 (4x), 960 (1x) and 1024 (5x).
We recommend analyzing the keys used in a particular scenario
with the provided ngerprint detection tool and following the recommendations given in Section 5.
5 MITIGATION AND DISCLOSURE
We propose a mitigation of the aack impacts and report on the
process of responsible disclosure to the Manufacturer.
5.1 Mitigation
Mitigation can be performed on multiple levels. Inarguably, algorithm replacement is the best long-term mitigation method. However, changing the algorithm requires updating rmware – which
is usually not possible in already deployed devices like smartcards
or TPMs with code stored in read-only memory. Other options
are available even within the hardware device with the vulnerable
version of the RSALib with some caveats. New keys can be still
generated on the device if they are congured to use key lengths
not directly aected by our method (yet still with a reduced security margin), or keypairs could be generated by another library
(outside the device) and then imported to the device. If the potentially vulnerable keys remain deployed, their usage scenario can be
supplemented with additional risk management.
5.1.1 Changes to the algorithm. e library could adopt an approach common in open-source libraries – instead of constructing
candidates for the primes, they are generated randomly and their
value is incremented until a prime is found. Other alternative constructions exist, such as provable or safe primes, as described in
the NIST FIPS 186-4 standard [46]. We noticed a certain similarity between the algorithm of the Manufacturer and an algorithm
published by Joye and Paillier [44] focused on key generation on
smartcards. e key dierence seems to be the fact that the RSALib
uses a constant value in the generator (65537), while in the paper,
the value is always chosen randomly using a unit generation algorithm [44, Figure 4]. e approach in the paper [44] is not aected
by the same vulnerability.
Note that due to the nature of deployment of the RSALib, the
devices already in use cannot be updated. e RSALib is oen stored
in a read-only on-chip memory with no possibility to distribute
and apply a x aer deployment.
5.1.2 Importing a secure keypair. A secure RSA keypair can
be generated in another cryptographic library and then imported
to the aected device. We are not aware of any vulnerability in
Manufacturer devices as far as the use of securely generated keys
is concerned. Coincidentally, the import of externally generated
keypair is even recommended by Yubico vendor [77], although for
the purpose of private key backup.
5.1.3 Use of less aected key lengths. As discussed in Section 2,
we consider 512, 1024 and 2048-bit keys to be insecure. Due to
design choices made by the manufacturer, it appears that 3072-bit
keys are seemingly less aected by our method than 4096-bit RSA
though with a signicantly reduced security margin. Our aack
is inecient or directly inapplicable when applied to some quite
uncommon key lengths (such as 1952 bits or 3936 bits). Hence, we
recommend limiting the choice of the key lengths to the seemingly
unaected keys if the usage of the vulnerable chips with on-chip
generated keys is absolutely unavoidable. Note however, that these
keys still suer from signicant entropy loss. If a somewhat “standard” key length is required, we recommend switching to 3072-bit
keys.
We also suggest caution when using the ngerprinted 4096-bit
keys, even though our method is not practical for their factorization
at the moment (requiring 1.28 ∗ 109 CPU-years). e strongest possible key length with respect to the general factorization methods
and our aack is 3936-bit RSA. If a device supports at most 2048-bit
keys, the key length of 1952 bits is the most secure option (see
Figure 1).
5.1.4 Additional risk management. e use of potentially vulnerable keys (especially 2048-bit keys requiring feasible yet still
signicant computational power) can be amended with additional
scrutiny to perform supplementary risk management. e presence
of the ngerprint is an advantage in this scenario since the public keys can be quickly tested to decide when to apply additional
measures by the cooperating system.
5.2 Future prevention and analysis
e impacts of the documented vulnerability may serve as cases
supporting the need for future systematic changes and deeper additional analyses, not limited just to the library in question.
5.2.1 Preventing the single point of failure. e described problem would be mitigated if not a single but two or even more independent implementations were used to generate the RSA keypair. More
generally, a secure multi-party protocol can be utilized to remove
the single point of failure, not only during the keypair generation,
but also during its use. e general goal is to provide tolerance
against up to k out of t misbehaving (either faulty or intentionally
malicious) participants [26]. Multiple protocols based on common
cryptographic primitives like RSA, Die-Hellman or Elliptic curve
cryptography were proposed in literature [15, 31, 37, 72]. Such approaches protect not only against an intentionally malicious party,
but also against unintentional mistakes weakening the resulting key.
e area of collaborative RSA keypair generation is well studied
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1645
with the primary goal to generate parts (shares) of RSA keypairs,
yet not to reveal the factorization of the resulting modulus N, until
all or a specied number (threshold) of parties cooperate.
Gilboa’s threshold RSA signature scheme [31] requires collaboration during every signature operation, introducing protocol
changes. A more ecient generation method by Straub based on 3-
prime RSA [72] is not suitable for use by smartcards that implement
oine signature generation with limited APIs, typically exposing
only standard 2-prime RSA operations. Moreover, protocols securing against active adversaries, like that described in Hazay et al.
[37], are time-consuming even on standard CPUs while having prohibitively long keypair generation phases on performance-limited
hardware. Parsovs proposed a collaborative method that splits key
generation between card manufacturer and cardholder [63]. e
resulting 4-prime 4096-bit RSA key is generated from two 2048-bit
parts during an interactive protocol executed before the card’s rst
use, limiting the necessity to trust a vendor with the generation of
the whole keypair, as well as removing the single point of failure.
Gennaro et al. proposed a distributed key generation algorithm
for discrete-log cryptosystems (not directly applicable to RSA) [30],
with extensions to provably secure distributed Schnorr signatures
[71] and with the implementation shown to be ecient enough to
run on cryptographic smartcards [56] as a mitigation of hardware
Trojans.
Note that all the methods described above require changes to user
interfaces and protocols and are therefore less suitable for legacy
systems. However, a systematic adoption of secure multiparty
protocols, instead of relying on a single vendor and implementation,
can provide a signicant overall increase of security of a system.
5.2.2 Analysis of other limited devices. e need for fast keypair generation on limited hardware naturally leads to a search for
alternative methods for nding completely random primes. e generation method of Joye and Paillier [44] is one example. erefore,
other modications (with respect to [44]) or completely dierent
methods may have been adopted by other hardware vendors. We
did not detect any deviances in cards from 5 other manufacturers
using our ngerprinting method. However, even a minor change
to unit generation used in RSALib will suppress the bias that is
detectable by our method (e.g., generators for p and q other than
65537), yet these changes will not automatically result in keys being
secure against variations of our aack. e search for alternative
detection techniques as well as aack variations represents possible
future work.
5.3 Responsible disclosure
Disclosure of this vulnerability was made to Manufacturer in the
beginning of February 2017 together with the tools demonstrating
ngerprinting capabilities and practical factorization. e vulnerability was subsequently conrmed with further notication of the
aected parties by Manufacturer.
We made public disclosure of the discovered issue in the middle
of October 2017 together with the release a tool for ngerprint
detection for provided public keys to facilitate a quick assessment
of the presence of the vulnerability for end-users. e full details
of the aack are published in this paper.
For the time being, we are not releasing our source code of the
factorization algorithm. We believe that honest parties can make
their own implementation based on our description.
6 RELATED WORK
e generation of RSA keys and aacks on them are the two main
areas related to this work. Besides aacks on the messages (e.g.,
padding oracle [11, 16, 19] or related messages [25, 76]), most attacks aim to deduce the private key from the corresponding public
key. e aacks can be divided into two classes based on the assumptions about the key: 1) No additional information – methods
such as Pollard p-1 [65], Pollard Rho [18, 66], and a class of several
sieving methods (e.g., NFS, GNFS); 2) Partial information – low
private or public exponent [13, 14, 24, 74], implementation and
side-channel aacks, and aacks based on Coppersmith’s method
[23].
e usage of generic aacks is limited to small RSA keys due to
their exponential time complexity (the current record for a general
768-bit RSA [47] was broken using NFS). Only aacks from the
second class are known to be used to break RSA moduli used in
practice. Side-channel aacks (e.g., timing aacks, power analysis)
are out of the scope of this work since they require active access to
the device performing the RSA computation. Except for Wiener’s attack [74] for a small private exponent, other notable aacks belong
to the same class as Coppersmith’s aack.
In 2012, two independent teams [38, 50] analyzed RSA public
keys on the Internet. e teams analyzed several millions of widespread keys in network devices such as keys in SSL certicates,
SSH host keys and PGP keys. ese teams observed that a small
portion (0.5% of TLS, 1% of SSH) of public RSA keys shared prime
factors. Due to insucient entropy (e.g., SSL keys were generated
by low-powered devices with no source of entropy) during the generation process, these keys can be trivially factorized using GCD. In
2013, Bernstein et al. [9] analyzed the “Citizen Digital Certicate”
database of 3.2 million public RSA keys generated by smartcards
used as the national IDs of Taiwanese citizens. In addition to recovering 184 keys that shared primes using a batch GCD computation,
the authors adapted Coppersmith’s algorithm and computed an
additional 81 private keys. To our knowledge, this is the only practical application of Coppersmith’s method to aack real RSA keys
prior to our aack. Coppersmith’s algorithm can be viewed as a
universal tool for aacking RSA keys generated with improperly
chosen parameters or originating from a faulty implementation.
e algorithm was adapted for various scenarios where some bits
of a factor, of the private exponent or of the message are known
[12]. e factorization of moduli with known high [22] or low [24]
bits of a factor were among the rst variants of the method. A nice
overview of these methods can be found in [57].
e generation of RSA keys is described in several standards
(e.g., FIPS 186-4 [46], IEEE 1363-2000 [1] – see [53] for an overview),
many having dierent requirements for the form of the primes. One
feature is common to all these standards – the primes should be
generated randomly using a large amount of entropy. In addition
to specialized construction methods (e.g., provable primes), the
generation of RSA primes is typically performed in several iterations, repeating two fundamental steps: a random candidate is
Session H1: Crypto Attacks CCS’17, October 30-November 3, 2017, Dallas, TX, USA 1646
generated and then tested for primality. Since the primality test is
a time-consuming process, several authors have proposed various
speedups for the candidate generation process ([17, 45, 55], see
[44] for an overview of such methods). e current state of the
art focused on constrained devices is described in [44], where the
authors decreased the number of primality tests with a negligible
loss of entropy (0.5 bits).
7 CONCLUSIONS
We presented a cautionary case of a vulnerable prime selection
algorithm adopted in RSA key generation in a widely used security
library of a cryptographic hardware manufacturer found in NIST
FIPS 140-2 and CC EAL 5+ certied devices. Optimizations that
were motivated by a higher performance in the key generation
process have inadvertently led to signicantly weakened security
of the produced keys. e primes are constructed with a specic
structure that makes the factorization of the resulting RSA keys
of many lengths (including 1024 and 2048 bits) practically feasible
with only the knowledge of the public modulus. Worse still, the
keys carry a strong ngerprint, making them easily identiable in
the wild. e factorization method is based on our extension of the
Howgrave-Graham renement of Coppersmith’s method.
To quantify and mitigate the impacts of this vulnerability, we
investigated multiple domains where the RSA algorithm is deployed.
Based on the specic structure of the primes, we devised a very fast
algorithm to identify all vulnerable keys even in very large datasets,
such as TLS or Certicate Transparency. Where public datasets
were missing (eID, TPM, etc.), we aempted to collect some keys on
our own. e results conrmed the use of the RSALib that produces
vulnerable RSA keys across many domains.
ere is mounting evidence that prime generation is a critical
part of implementations that designers and developers struggle
with. Authoritative design notes for robust approaches should
be produced and disseminated. Developers must follow existing
standards without modications.
Our work highlights the dangers of keeping the design secret
and the implementation closed-source, even if both are thoroughly
analyzed and certied by experts. e lack of public information
causes a delay in the discovery of aws (and hinders the process
of checking for them), thereby increasing the number of already
deployed and aected devices at the time of detection.
e certication process counter-intuitively “rewards” the secrecy of design by additional certication “points” when an implementation is dicult for potential aackers to obtain - thus favoring
security by obscurity. Relevant certication bodies might want to
reconsider such an approach in favor of open implementations and
specications. Secrecy may increase the diculty of spoing a aw
(above the capability of some aackers) but may also increase the
impacts of the aw due to the later discovery thereof.