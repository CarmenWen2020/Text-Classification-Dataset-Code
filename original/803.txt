Cyber threat intelligence (CTI) is being used to search for indicators
of attacks that might have compromised an enterprise network for
a long time without being discovered. To have a more effective
analysis, CTI open standards have incorporated descriptive relationships showing how the indicators or observables are related
to each other. However, these relationships are either completely
overlooked in information gathering or not used for threat hunting.
In this paper, we propose a system, called Poirot, which uses these
correlations to uncover the steps of a successful attack campaign.
We use kernel audits as a reliable source that covers all causal relations and information flows among system entities and model
threat hunting as an inexact graph pattern matching problem. Our
technical approach is based on a novel similarity metric which assesses an alignment between a query graph constructed out of CTI
correlations and a provenance graph constructed out of kernel audit
log records. We evaluate Poirot on publicly released real-world
incident reports as well as reports of an adversarial engagement designed by DARPA, including ten distinct attack campaigns against
different OS platforms such as Linux, FreeBSD, and Windows. Our
evaluation results show that Poirot is capable of searching inside
graphs containing millions of nodes and pinpoint the attacks in a
few minutes, and the results serve to illustrate that CTI correlations
could be used as robust and reliable artifacts for threat hunting.
KEYWORDS
Cyber Threat Hunting, Cyber Threat Intelligence, Indicator of Compromise, Graph Alignment, Graph Pattern Matching

1 INTRODUCTION
When Indicators of Compromise (IOCs) related to an advanced persistent threat (APT) detected inside an organization are released, a
common question that emerges among enterprise security analysts
is if their enterprise has been the target of that APT. This process is
commonly known as Threat Hunting. Answering this question with
a high level of confidence often requires lengthy and complicated
searches and analysis over host and network logs of the enterprise,
recognizing entities that appear in the IOC descriptions among
those logs and finally assessing the likelihood that the specific APT
successfully infiltrated the enterprise.
In general, threat hunting inside an enterprise presents several
challenges:
• Search at scale: To remain under the radar, an attacker often
performs the attack steps over long periods (weeks, or in some
cases, months). Hence, it is necessary to design an approach
that can link related IOCs together even if they are conducted
over a long period of time. To this end, the system should be
capable of searching among millions of log events (99.9% of
which often correspond to benign activities).
• Robust identification and linking of threat-relevant entities: Threat
hunting must be sound in identifying whether an attack campaign has affected a system, even though the attacker might
have mutated the artifacts like file hashes and IP addresses
to evade detection. Therefore, a robust approach should not
merely look for matching IOCs in isolation, but uncover the
entire threat scenario, which is harder for an attacker to mutate.
• Efficient Matching: For a cyber analyst to understand and react
to a threat incident in a timely fashion, the approach must efficiently conduct the search and not produce many false positives
so that appropriate cyber-response operations can be initiated
in a timely fashion.
Commonly, knowledge about the malware employed in APT
campaigns is published in cyber threat intelligence (CTI) reports
and is presented in a variety of forms such as natural language,
structured, and semi-structured form. To facilitate the smooth exchange of CTI in the form of IOCs and enable characterization of
adversarial techniques, tactics, and procedures (TTPs), the security
community has adopted open standards such as OpenIOC [14],
STIX [49], and MISP [48]. To provide a better overview of attacks,
these standards often incorporate descriptive relationships showing
how indicators or observables are related to each other [28].
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1795
However, a vast majority of the current threat hunting approaches
operates only over fragmented views of cyber threats[15, 64], such
as signatures (e.g., hashes of artifacts), suspicious file/process names,
and IP addresses (domain names), or by using heuristics such as
timestamps to correlate suspicious events [54]. These approaches
are useful but have limitations, such as (i) lacking the precision
to reveal the complete picture as to how the threat unfolded especially over long periods (weeks, or in some cases, months), (ii)
being susceptible to false signals when adversaries use legitimatelooking names (like svchost in Windows) to make their attacks
indistinguishable from benign system activities, and (iii) relying on
low-level signatures, which makes them ineffective when attackers
update or re-purpose [63, 68] their tools or change their signatures
(IP addresses or hash values) to evade detection. To overcome these
limitations and build a robust detection system, the correlation
among IOCs must be taken into account. In fact, the relationships
between IOC artifacts contain essential clues on the behavior of
the attacks inside a compromised system, which is tied to attacker
goals and is, therefore, more difficult to change [36, 77].
This paper formalizes the threat hunting problem from CTI reports and IOC descriptions, develops a rigorous approach for deriving the confidence score that indicates the likelihood of success
of an attack campaign, and describes a system called Poirot that
implements this approach. In a nutshell, given a graph-based representation of IOCs and relationships among them that expresses
the overall behavior of an APT, which we call a query graph, our
approach efficiently finds an embedding of this query graph in a
much larger provenance graph, which contains a representation
of kernel audit logs over a long period of time. Kernel audit logs
are free of unauthorized tampering as long as system’s kernel is
not compromised, and reliably contain relationships between system entities (e.g., processes, files, sockets, etc.), in contrast to its
alternatives (e.g., firewall, network monitoring, and file access logs)
which provide partial information. We assume that to maintain the
integrity of kernel audit logs, a real-time kernel audit storage on a
separate and secure log server is used as a precaution against log
tampering.
More precisely, we formulate threat hunting as a graph pattern
matching (GPM) problem searching for causal dependencies or
information flows among system entities that are similar to those
described in the query graph. To be robust against evasive attacks
(e.g., mimicry attacks [52, 70]) which aim to influence the matching,
we prioritize flows based on the cost they have for an attacker
to produce. Given the NP-completeness of the graph matching
problem [10], we propose an approximation function and a novel
similarity metric to assess an alignment between the query and
provenance graph.
We test Poirot’s effectiveness and efficiency using three different datasets, particularly, red-team/blue-team adversarial engagements performed by DARPA Transparent Computing (TC) program
[31], publicly available real-world incident reports, and attack-free
activities generated by ordinary users. In addition, we simulate several attacks from real-world scenarios in a controlled environment
and compare Poirot with other tools that are currently used to do
threat hunting. We show that Poirot outperforms these tools. We
have implemented different kernel log parsers for Linux, FreeBSD,
and Windows, and our evaluation results show that Poirot can
search inside graphs containing millions of nodes and pinpoint the
attacks in a few minutes.
This paper is organized as follows: Related work appears in
section 2. We present an overall architecture of Poirot in section 3.
In section 4, we provide the formal details of the graph alignment
algorithm. Section 5 discusses the evaluation, and we conclude in
section 6.
2 RELATED WORK
Log-based Attack Analytics. Opera et al. [51] leverage DNS or
web proxy logs for detecting early-stage infection in an enterprise.
Disclosure [4] extracts statistical features from NetFlow logs to
detect botnet C&C channels. DNS logs have also been extensively
used [1, 2] for detecting malicious domains. Hercule [54] uses
community detection to reconstruct attack stages by correlating
logs coming from multiple sources. Similar to Poirot, a large body
of work uses system audit logs to perform forensic analysis and
attack reconstruction[20, 21, 42, 56].
Provenance Graph Explorations. The idea to construct a provenance graph from kernel audit logs was introduced by King et al.
[33, 35]. The large size and coarse granularity of these graphs have
limited their practical use. However, recent advancements have
paved the way for more efficient and effective use of provenance
graphs. Several approaches have introduced compression, summarization, and log reduction techniques [26, 40, 74] to differentiate
worthy events from uninformative ones and consequently reduce
the storage size. Dividing processes into smaller units is one of the
approaches to add more granularity into the provenance graphs,
and to this end, researchers have utilized different methods, such
as dynamic binary analysis [39, 46], source code annotation [45],
or modeling-based inference [38, 43, 44]. Additionally, record-andreplay [29, 30] and parallel execution methods [37] are proposed for
more precise tracking. Recent studies have leveraged provenance
graphs for different objectives, such as alert triage [24], zero-day
attack path identification [61], attack detection and reconstruction
[25, 47]. However, the scope of Poirot is different from these recent works, since it is focused on threat hunting and not real-time
detection or forensic analysis.
Query Processing Systems. Prior works have incorporated
novel optimization techniques, graph indexing, and query processing methods [19, 62, 71] to support timely attack investigations.
SAQL [17] is an anomaly query engine that queries specified anomalies to identify abnormal behaviors among system events. AIQL
[18] can be used as a forensic query system that has a domainspecific language for investigating attack campaigns from historical audit logs. Pasquier et al. [53] propose a query framework,
called CamQuery, that supports real-time analysis on provenance
graphs, to address problems such as data loss prevention, intrusion
detection, and regulatory compliance. Shu et al. [57] also propose a
human-assisted query system equipping threat hunters with a suite
of potent new tools. These works are orthogonal to Poirot and can
be used as a foundation to implement our search algorithm.
Behavior Discovery. Extracting malicious behaviors such as information flows and causal dependencies and searching for them as
robust indicators have been investigated in prior works. Christodorescu et al. [9] have proposed an approach for mining malware behavior from dynamic traces of that malware’s samples. Similarly,
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1796
Kolbitsch et al. [36] automatically generate behavior models of malware using symbolic execution. They represent this behavior as a
graph and search for it among the runtime behavior of unknown
programs. On the contrary, Poirot does not rely on symbolic expressions but looks for correlations and information flows on the
whole system. TGMiner [77] is a method to mine discriminative
graph patterns from training audit logs and search for their existence in test data. The focus of this work is query formulation
instead of pattern query processing, and the authors have used
a subsequence matching solution [76] for their search, which is
different from our graph pattern matching approach.
Graph Pattern Matching. Graph Pattern Matching (GPM) has
proved useful in a variety of applications [16]. GPM can be defined
as a search problem inside a large graph for a subgraph containing
similar connections conjunctively specified in a small query graph.
This problem is NP-complete in the general case [10]. Fan et. al.
[12] proposed a polynomial time approach assuming that each
connection in the pattern could only be mapped to a path with
a predefined number of hops. Other works [8, 78] have tackled
the problem by using a sequence of join functions in the vector
space. NeMa [32] is a neighborhood-based subgraph matching
technique based on the proximity of nodes. In contrast, G-Ray
and later Mage[55, 69] take into account the shape of the query
graph and edge attributes and are more similar to our approach,
where similar information flows and causal dependencies play a
crucial role. However, these approaches work based on randomwalk, which is not reliable against attackers (with knowledge of
the threat-hunting method) who generate fake events (as explained
in section 4.1). While our graph alignment notions are similar to
these works, the graph characteristics Poirot analyzes present
new challenges such as being labeled, directed, typed, in the order
of millions of nodes, and constructed in an adversarial setting.
Moreover, many of these related works are looking for a subgraph
that contains exactly one alignment for each node and each edge
of the query graph and cannot operate in a setting where there
might not be an alignment for certain nodes or edges. As a result,
we develop a new best-effort matching technique aimed at tackling
these challenges.
3 APPROACH OVERVIEW
A high-level view of our approach is shown in Fig. 1. We provide
a brief overview of the components of Poirot next, with more
detailed discussions relegated to section 4.
3.1 Provenance Graph Construction
To determine if the actions of the APT appear in the system, we
model the kernel audit logs as a labeled, typed, and directed graph,
which we call provenance graph (Gp ). This is a common representation of kernel audit logs, which allows tracking causality and
information flow efficiently [17, 18, 25, 33, 34]. In this graph, nodes
represent system entities involved in the kernel audit logs, which
have different types such as files and processes, while edges represent information flow and causality among those nodes taking
into account the direction. Poirot currently supports consuming
Graph Alignment
… S < Threshold
System Behavior
(Provenance Graph, Gp
)
Attack Behavior
(Query Graph, Gq
)
Alert !
Alignment
Score (S)
S > Threshold
Forensic
Analysis
MISP STIX
IOC Relationships Kernel Audit Logs
Fig. 1: Poirot Approach Overview.
kernel audit logs1
from Microsoft Windows, Linux, and FreeBSD
and constructs a provenance graph in memory, similar to prior
work in this area [25]. To support efficient searching on this graph,
we leverage additional methods such as fast hashing techniques
and reverse indexing for mapping process/file names to unique
node IDs.
3.2 Query Graph Construction
We extract IOCs together with the relationships among them from
CTI reports related to a known attack. These reports appear in
security blogs, threat intelligence reports by industry, underground
forums on cyber threats, and public and private threat intelligence
feeds. In addition to natural language, the attacks are often described in structured and semi-structured standard formats as well.
These formats include OpenIOC[14], STIX[49], MISP[48], etc. Essentially, these exchange formats are used to describe the salient
points of the attacks, the observed IOCs, and the relationships
among them. For instance, using OpenIOC the behavior of a malware sample can be described as a list of artifacts such as the files
it opens, and the DLLs it loads [13]. These standard descriptions
are usually created by the security operators manually [66, 67].
Additionally, automated tools have also been built to automatically
extract IOCs from natural language and complement the work of
human operators [27, 41, 75]. These tools can be used to perform
an initial extraction of features to generate the query graph and
later refined manually by a security expert. We believe that manual
refinement is an important component of the query graph construction because automated methods may often generate noise and
reduce the quality of the query graphs.
1Kernel logs can be monitored using tools such as ETW, Auditd, and DTrace in Microsoft Windows, Linux, and FreeBSD, respectively.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1797
A
B
C D
E
1. exec
2. write 3. write
4. send
Fig. 2: Query Graph of DeputyDog Malware. A=∗.%exe%, B=∗, C=%APPDATA%\∗,
D=%HKCU%\Software\Microsoft\Windows\CurrentVersion\-
Run\∗, E=%External IP address%.
We model the behavior appearing in CTI reports also as a labeled,
typed, and directed graph, which we call query graph (Gq). If a
description in a standard format is present, the creation of the query
graph can be easily automated and further refined by humans. In
particular, the entities appearing in the reports (e.g., processes, files)
are transformed into nodes while relationships are transformed
into directed edges [60]. Nodes and edges of the query graph may
be further associated with additional information such as labels (or
names), types (e.g., processes, files, sockets, pipes, etc) and other
annotations (e.g., hash values, creation time, etc) depending on the
information that an analyst may deem necessary for matching. In
the current Poirot implementation, we use names and types for
specifying explicit mappings between nodes in the query graph
and nodes in the provenance graph.
As an example of query graph construction, consider the following excerpt from a report [50] about the DeputyDog malware, used
in our evaluation.
Upon execution, 8aba4b5184072f2a50cbc5ecfe326701 writes
“28542CC0.dll” to this location: “C:\Documents and Settings\All
Users\Application Data\28542CC0.dll”. In order to maintain
persistence, the original malware adds this registry key:
“%HKCU%\Software\Microsoft\Windows\CurrentVersion\Run\
28542CC0”. The malware then connects to a host in South Korea
(180.150.228.102).
The excerpt mentions several actions and entities that perform
them and is readily transformed into a graph by a security analyst.
For instance, the first sentence clearly denotes a process writing to
a file (upon execution the malware writes a file to a location). We
point out that the level of detail present in this excerpt is common
across a large majority of CTI reports and can be converted to a
reliable query graph by a qualified cyber analyst. In particular, the
verbs that express actions carried out by subjects can often be easily
mapped to reads/writes from/to disk or network and to interactions
among processes (e.g., a browser downloads a file, a process spawns
another process, a user clicks on a spear-phishing link, etc).
Fig. 2 shows the query graph corresponding to the above excerpt.
Ovals, diamonds, rectangles, and pentagons represent processes,
sockets, files, and registry entries, respectively 2
. In Fig. 2, node B
represents the malware process or group of processes (we use a ∗ to
denote that it can have any name), node A represents the image file
of the malware, while nodes C, D and E represent a dropped file, a
registry and an Internet location, respectively. We highlight at this
point that the query graph that is built contains only information
2We use the same notation for the rest of the figures in the paper.
about information flows among specific entities as they appear in
the report (processes, files, IP addresses, etc) and is not intended
to be a precise subgraph of all the malicious entities that actually
appear during the attack. In a certain sense, the query graph is a
summary of the actual attack graph. In our experiments, the query
graphs we obtained were usually small, containing between 10-40
nodes and up to 150 edges.
3.3 Graph Alignment
Finally, we model threat hunting as determining whether the query
graph Gq for the attack “manifests” itself inside the provenance
graph Gp . We call this problem Graph Alignment Problem.
We note at this point that Gq expresses several high-level flows
between the entities (processes to files, etc.). In contrast, Gp expresses the complete low-level activity of the system. As a result,
an edge in Gq might correspond to a path in Gp consisting of multiple edges. For instance, if Gq represents a compromised browser
writing to a system file, in Gp this may correspond to a path where
a node representing a Firefox process forks new processes, only
one of which ultimately writes to the system file. Often, this kind of
correspondence may be created by attackers adding noise to their
activities to escape detection. Therefore, we need a graph alignment
technique that can match single edges in Gq to paths in Gp . This
requirement is critical in the design of our algorithm.
In graph theory literature, there exist several versions of the
graph matching problem. In exact matching, the subgraph embedded in a larger graph Gp must be isomorphic to Gq [76]. In contrast,
in the graph pattern matching (GPM) problem, some of the restrictions of exact matching are relaxed to extract more useful subgraphs.
However, both problems are NP-complete in the general case [10].
Even though a substantial body of work dedicated to GPM exists
[8, 12, 16, 32, 55, 69, 78], many have limitations that make them
impractical to be deployed in the field of threat hunting. Specifically,
they (i) are not designed for directed graphs with labels and types
assigned to each node, (ii) do not scale to millions of nodes, or (iii)
are designed to align all nodes or edges in the query graph exhaustively. Moreover, these approaches are not intended for the context
of threat hunting, taking into account an evasive adversary which
tries to remain stealthy utilizing the knowledge of the underlying
matching criteria. Due to these considerations, we devise a novel
graph pattern matching technique that addresses these limitations.
In Fig. 1, graph nodes are represented in different shapes to model
different node types, such as a file, process, and socket, however,
the labels are omitted for brevity. In particular, Poirot starts by
finding the set of all possible candidate alignments i : j where i and
j represent nodes in V (Gq) and V (Gp ), respectively. Then, starting
from the alignment with the highest likelihood of finding a match,
called a seed node, we expand the search to find further node alignments. The seed nodes are represented by hexagons in Fig. 1 while
matching nodes in the two graphs are connected by dotted lines.
To find an alignment that corresponds to the attack represented
in CTI relationships, the search is expanded along paths that are
more likely to be under the influence of an attacker. To estimate this
likelihood, we devise a novel metric named influence score. Using
this metric allows us to largely exclude irrelevant paths from the
search and efficiently mitigate the dependency explosion problem.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1798
Prior works have also proposed approaches to prioritize flows based
on a score computed as length [32, 69] or cost [25]. However, they
can be defeated by attacks [52, 70] in which attackers frequently
change their ways to evade the detection techniques. For instance, a
proximity-based graph matching approach [32, 69] might be easily
evaded by attackers, who, being aware of the underlying system
and matching approach, might generate a long chain of fork commands to affect the precision of proximity-based graph matching.
In contrast, our score definition explicitly takes the influence of a
potential attacker into account. In particular, we increase the cost
for the attacker to evade our detection, by prioritizing flows based
on the effort it takes for an attacker to produce them. Our search for
alignment uses such prioritized flows and is described in section 4.
After finding an alignment Gq :: Gp , a score is calculated, representing the similarity between Gq and the aligned subgraph of
Gp . When the score is higher than a threshold value, Poirot raises
an alert which declares the occurrence of an attack and presents
a report of aligned nodes to a system analyst for further forensic
analysis. Otherwise, Poirot starts an alignment from the next seed
node candidate. After finding an attack subgraph in Gp , Poirot
generates a report containing the aligned nodes, information flows
between them, and the corresponding timestamps. In an enterprise
setting, such visually compact and semantic-rich reports provide
actionable intelligence to cyber analysts to plan and execute cyberthreat responses. We discuss the details of our approach in section 4.
4 ALGORITHMS
In this section, we discuss our main approach for alignment between Gq and Gp by (a) defining an alignment metric to measure
how proper a graph alignment is, and (b) designing a best-effort
similarity search based on specific domain characteristics.
4.1 Alignment Metric
We introduce some notations (in table 1), where we define two
kinds of alignments, i.e., a node alignment between two nodes in
two different graphs, and a graph alignment which is a set of node
alignments. Typically, two nodes i and j are in a node alignment
when they represent the same entity, e.g., a node representing a commonly used browser mentioned in the CTI report (node %browser%
in the query graph Gq of Fig. 3) and a node representing a Firefox
process in the provenance graph. We note that, in general, the node
alignment relationship is a many-to-many relationship from V(Gq)
to V(Gp ), where V(Gq) and V(Gp ) are the set of vertices of Gq and
Gp respectively. Therefore, given a query graph Gq, there may be a
large number of graph alignments betweenGq and many subgraphs
Notation Description
i : k Node alignment. Node i is aligned to node k (i and k are in
two distinct graphs).
i 99K j Flow. A path starting at node i and ending at node j.
i
label
−−−→ j An edge from node i to node j with a specific label.
Gq :: Gp Graph alignment. A set of node alignments i : k where i is a
node of Gq and k is a node of Gp .
V (G) Set of all vertices in graph G.
E(G) Set of all edges in graph G.
F (G) Set of all flows i 99K j in graph G such that i , j.
Table 1: Notations.
of Gp . Another thing to point out is that each of these graph alignments can correspond to different subgraphs of Gp . Each of these
subgraphs contains the nodes that are aligned with the nodes of
Gq; however, they may contain different paths among those nodes.
Among these subgraphs, we are interested in finding the subgraph
that best matches the graph Gq.
Based on these definitions, the problem is to find the best possible
graph alignment among a set of candidate graph alignments. To
illustrate this problem, consider the query and provenance graphs
Gq and Gp , and two possible aligned graphs in Fig. 3, where the
node shapes represent entity types (e.g., process, file, socket), and
the edges represent information flow (e.g., read, write, IPC) and
causal dependencies (e.g., fork, clone) between nodes. The numbers
shown on the edges of Gp are not part of the provenance graph but
serve to identify a single path in our discussion. In addition, the
subgraphs of Gp determined by these two graph alignments with
Gq are represented by dotted edges in Gp . Each flow in Gp and
corresponding edge in Gq is labeled with the same number. The
problem is, therefore, to decide which among many alignments is
the best candidate. Intuitively, for this particular figure, alignment
(Gq :: Gp )2 is closer to Gq than (Gq :: Gp )1, mainly because the
number of its aligned nodes is higher than that of (Gq :: Gp )1, and
most importantly, its flows have a better correspondence to the
edges of the query graph Gq.
4.1.1 Influence Score. Before formalizing the intuition expressed
above, we must introduce a path scoring function, which we call
influence score and which assigns a number to a given flow between
two nodes. This score will be instrumental in defining the “goodness”
of a graph alignment. In practice, the influence score represents
the likelihood that an attacker can produce a flow. To illustrate
this notion, consider the two nodes firefox2 and %registry%\firefox
in the graph Gp in Fig. 3. There exist two flows from firefox2 to
%registry%\firefox, one represented by the edges labeled with the
number 2 (and passing through nodes java1 and java2), and another
represented by the edges labeled 3, 3, and 5 (and passing through
nodes tmp.doc and word1). Assuming firefox2 is under the control of
an attacker, it is more likely for the attacker to execute the first flow
rather than the second flow. In fact, in order to exercise the second
flow, an attacker would have to take control over process launcher2
or word1 in addition to firefox2. Since launcher2 or word1 share no
common ancestors in the process tree with firefox2, such takeover
would have to involve an additional exploit for launcher2 or word1,
which is far more unlikely than simply exercising the first flow,
where all processes share a common ancestor launcher1. We point
out that this likelihood does not depend on the length of the flow,
rather on the number of processes in that flow and on the number
of distinct ancestors those processes share in the process tree. One
can, in fact, imagine a long chain of forked processes, which are
however all under the control of the attacker because they all share
a common ancestor in the process tree, i.e., the first process of
the chain. Another possible scenario of attacks present in the wild
involves remote code loading from a single compromised process,
where all the code with malicious functionality is loaded in main
memory and the same process (e.g., firefox) executes all the actions
on behalf of the attacker. While this technique leaves no traces
on the file system and may evade some detection tools, Poirot
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1799
firefox2 240.2.1.1
%registry%
\firefox
launcher1
firefox1
240.1.1.1
240.1.1.2
240.1.1.3
word1
Word.exe
spoolsv1 cmd.exe
tmp.exe
%registry%
\access
spoolsv3
%registry%
\Run
word2
spoolsv2
Gp
:
%browser%
spoolsv
External IP
*
.exe
%registry%
Gq
:
launcher2
1
1 1
2
3
3
4
4
5
5
6
7
7
8
8
9
tmp.doc 3 launcher3
java1
java2
2
2
9
firefox2
240.1.1.1
Word.exe %registry%
\firefox
1
2
3
4
5
(Gq
::Gp
)1
firefox1
tmp.exe
%registry%
\Run
spoolsv3
6
7
8
9
(Gq
::Gp
)2 240.2.1.1
Fig. 3: Simplified Provenance Graph (Gp ), Query Graph (Gq), and two sample graph alignments (Gq :: Gp ). Node types are
shown with different shapes, and possible alignments for each node is shown with the same color. The numbers on the edges
are merely to illustrate possible paths/flows and do not have additional meaning.
would be able to detect this kind of attack. In fact the influence
score remains trivially unchanged.
One additional important point to note is that this notion of
measuring the potential influence of an attacker is very robust
concerning evasion methods from an attacker. Every activity that
an attacker may use to add noise and try to evade detection will
likely have the same common ancestors, namely the initial compromise points of the attack, unless the attacker pays a higher cost
to perform more distinct compromises. Thus, such efforts will be
ineffective in changing the influence score of the paths.
Based on these observations, we define the influence score, Γi,j
,
between a node i and a node j as follows:
Γi,j =



max
i99Kj
1
Cmin(i 99K j)
∃i 99K j | Cmin(i 99K j) ≤ Cthr
0 otherwise
(1)
In Equation (1), Cmin(i 99K j) represents the minimum number
of distinct, independent compromises an attacker has to conduct to
be able to generate the flow i 99K j. This value captures the extent
of the attacker’s control over the flow and is calculated based on the
minimum number of common ancestors of the processes present
in the flow. For instance, if there is a flow from a node i to a node
j, and all the processes involved in that flow have one common
ancestor in the process tree, an attacker needs to compromise only
that common ancestor process to initiate such flow, and therefore
Cmin(i 99K j) is equal to 1. Note that if a node i represents a
process and node j a child process of i, then Cmin(i 99K j) will be
equal to 1 as i is parent of j. If the number of common ancestors
is larger than one (e.g., there are two ancestors in the path firefox2
→ tmp.doc → word1 → %registry%\firefox), an attacker has to
compromise at least as many (unrelated) processes independently;
therefore it is harder for the attacker to construct such flow. For
instance, for the attacker to control the flow firefox2 → tmp.doc →
word_1→ %registry%\firefox), (s)he needs to control both launcher1
and launcher2; therefore Cmin is equal to 2.
We also reasonably assume that it is not practical for an attacker
to compromise more than a small number of processes with distinct
exploits. In a vast majority of documented APTs, there is usually
a single entry point or a very small number of entry points into a
system for an attacker, e.g., a spear phishing email, or a drive-by
download attack on the browser. We have confirmed that this is
true also based on a review of a large number of white papers on
APTs [72]. Once an attacker has an initial compromise, it is highly
unlikely that they will invest additional resources in discovering
and exploiting extra entry points. Therefore, we can place a limit
Cthr on the Cmin(i 99K j) values and reasonably assume that any
flow between two nodes that has a Cmin(i 99K j) greater than
Cthr can not have been initiated by an attacker.
While the value of Cmin(i 99K j) expresses how hard it is for an
attacker to control a specific path, the influence score expresses how
easy it is for an attacker to control that path, and it is defined as
a value that is inversely proportional to Cmin(i 99K j). If there is
more than one flow between two nodes i and j, the influence score
will be the maximum 1
Cmin(i 99K j)
over all those flows. Based on
this equation, the value of Γi,j
is maximal (equal to 1) when there
is a flow whose Cmin(i 99K j) equals 1 and is minimal (equal to 0)
when there is no flow with a Cmin(i 99K j) greater than Cthr .
4.1.2 Alignment Score. We are now ready to define a metric that
specifies the score of a graph alignment Gq :: Gp . Based on the
notion of influence score, we define the scoring function S(Gq :: Gp ),
representing the score for an alignment Gq :: Gp as follows:
S(Gq :: Gp ) =
1
|F (Gq) |
Õ
(i99Kj)∈F (Gq )
Γk,l
| i : k & j : l (2)
In Equation (2), nodes i and j are members of V (Gq), and nodes k
and l are members of V (Gp ). The flow i 99K j is a flow defined
over Gq. In particular, the formula starts by computing the sum
of the influence scores among all the pairs of nodes (k,l) with at
least one path from k to l in the graph Gp such that k is aligned
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1800
with i and l is aligned with j. This sum is next normalized by
dividing it with the maximal value possible for that sum. In fact,
|F (Gq)| is the number of flows in Gq. Since the maximal value of
the influence score between two nodes is equal to 1, then the number
of flows automatically represents the maximal value of the sum of
the influence scores.
From Equation (2), intuitively, the larger the value of S(Gq ::
Gp ), the larger the number of node alignments and the larger the
similarity between flows in Gq and flows in Gp , which are likely
to be under the influence of a potential attacker. In particular, the
value of S(Gq :: Gp ) is between 0 and 1. When S(Gq :: Gp ) = 0,
either no proper alignment is found for nodes in V (Gq), or no
similar flows to those of Gq appear between the aligned nodes in
Gp . On the contrary, when S(Gq :: Gp ) = 1, all the nodes in Gq
are aligned to the nodes in Gp , and all the flows existing in Gq
also appear between the aligned nodes in Gp , and they all have an
influence score equal to 1, i.e., it is highly likely that they are under
the attacker’s control.
Finally, when the alignment score S(Gq :: Gp ) bypasses a predetermined threshold value (τ ), we raise the alarm. To determine the
optimal value of this threshold, recall that Cthr is the maximum
number of distinct entry point processes we are assuming an attacker is willing to exploit independently. Therefore, an attacker is
assumed to be able to influence any information flow with influence score of 1
Cthr
or higher. On the other hand, S(Gq :: Gp ) is the
average of all influence scores. Therefore, we define the threshold τ
as follows:
S(Gq :: Gp ) ≥ τ (3)
τ =
1
Cthr
(4)
If S(Gq :: Gp ) bypasses τ , we declare a match and raise the alarm.
4.2 Best-Effort Similarity Search
After defining the alignment score, we describe our procedure to
search for an alignment that maximizes that score. In particular,
given a query graph Gq, we need to search a very large provenance
graph Gp to find an alignment Gq :: Gp with the highest alignment
score based on Equation (2).
The first challenge in doing this is the size of Gp , which can
reach millions of nodes and edges. Therefore, it is not practical to
store influence scores between all pairs of nodes of Gp . We need
to perform graph traversals on demand to find the influence scores
between nodes or even to find out whether there is a path between
two nodes. Besides, we are assuming that all analytics are being
done on a stationary snapshot of Gp , and no changes happen to its
nodes or edges from the moment when a search is initiated until it
terminates.
Our search algorithm consists of the following four steps, where
steps 2-4 are repeated until finding alignment with a score higher
than the threshold value τ (Equation (4)).
Step 1. Find all Candidate Node Alignments: We start by
searching among nodes of Gp to find candidate alignments for
each node in Gq. These candidate alignments are chosen based
on the name, type, and annotations on the nodes of the query
graph. For instance, nodes of the same type (e.g., two process nodes)
with the same label (e.g., Firefox) appearing in Gq and Gp may
form candidate alignments, nodes whose labels match a regular
expression (e.g., a file system path and file name), and so on. A user
may also manually annotate a node in the provenance graph and
explicitly specify an alignment with a node in the query graph. In
general, a node in Gq may have any number of possible alignments
in Gp , including 0. Note that in this first step, we do not have
enough information about paths and flows and are looking at nodes
in isolation. In Fig. 3, the candidate node alignments are represented
by the pairs of nodes having the same color.
Step 2. Selecting Seed Nodes: To find a good-enough alignment Gq :: Gp , we need to explore connections between candidate
alignments found in Step 1, by performing graph traversals on Gp .
However, due to the structure and large size of Gp , starting a set of
graph traversals from randomly aligned nodes in Gp might lead to
costly and unfruitful searches. To determine a good starting point,
a key observation is that the attack activities usually comprise a
tiny portion of Gp , while benign activities are usually repeated
multiple times. Therefore, it is more likely for artifacts that are specific to an attack to have fewer alignments than artifacts of benign
activities. Based on this observation, we sort the nodes of Gq by an
increasing order in the number of candidate alignments related to
each node. We select the seed nodes with fewest alignments first.
For instance, with respect to the example in Fig. 3, the seed node
will be %browser%, since it has the smallest number of candidate
node alignments. If there are seed nodes with the same number of
candidate alignments, we choose one of them randomly.
Step 3. Expanding the Search: In this step, starting from the
seed node chosen at Step 2, we iterate over all the nodes in Gp
aligned to it and initiate a set of graph traversals, going forward or
backward, to find out whether we can reach other aligned nodes
among those found in Step 1. For instance, after choosing node
%browser% as a seed node, we start a series of forward and backward
graph traversals from the nodes in Gp aligned to %browser%, that is
firefox1 and firefox2. In theory, these graph traversals can be very
costly both because of the size of the graph and also the number
of candidate aligned nodes, which can be located anywhere in the
graph. In practice, however, we can stop expanding the search along
a path once the influence score between the seed node and the last
node in that path reaches 0. For instance, suppose we decide that
Cthr is equal to 2 in Fig. 3. Then, the search along the path (firefox2
→ tmp.doc → word1 → %registry%\firefox→ word2) will not
expand past the node word2, since the Cmin between firefox2 and
any node along that path becomes greater than 2 at word2, and thus
the influence score becomes 0. Note that there is an additional path
from firefox2 to word2 via %registry%\firefox and along this path,
theCmin between firefox2 and word2 is still 2. Therefore, because of
this path, the search will continue past word2. Using the influence
score as an upper bound in the graph traversals dramatically reduces
the search complexity and enables a fast exploration of the graph
Gp .
Based on the shape of the query graphGq, multiple forward/backward tracking cycles might be required to visit all nodes (for instance, if we choose %browser% as a seed node in our example,
then node 240.2.1.1 in Gp is unreachable with only one forward or
backward traversal starting at firefox1 or firefox2). In this case, we
repeat the backward and forward traversals starting from nodes
that are adjacent to the unvisited nodes but that have been visited
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1801
in a previous traversal (for instance, node spoolsv3 in our example).
We iterate this process until we cover all the nodes of the query
graph Gq.
Step 4. Graph Alignment Selection: This step is responsible
for producing the final result or for starting another iteration of
the search from step 2, in case a result is not found. In particular,
after performing backward/forward traversals, we identify a subset
of candidate nodes in Gp for each node in Gq. For instance, with
respect to our example, we find that node%browser% has candidates
firefox1 and firefox2, node External IP has candidate alignments
240.1.1.1, 240.1.1.2, 240.1.1.3, and 240.2.1.1, and so on. However, the
number of possible candidate graph alignments that these candidate nodes can form can be quite large. If each node i in Gq has
ni candidate alignments, then the number of possible graph alignments is equal to Ö
i
ni
. For instance, in our example, we can have
216 possible graph alignments (2 × 3 × 3 × 3 × 4). In this step, we
search for the graph alignment that maximizes the alignment score
(Equation (2)).
A naive method for doing this is a brute-force approach that
calculates the alignment score for all possible graph alignments.
However, this method is very inefficient and does not fully take
advantage of domain knowledge. To perform this search efficiently,
we devise a procedure that iteratively chooses the best candidate for
each node in Gq based on an approximation function that measures
the maximal contribution of each alignment to the final alignment
score.
In particular, starting from a seed node in Gq, we select the node
in Gp that maximizes the contribution to the alignment score and
fix this node alignment (we discuss the selection function in the
next paragraph). For instance, starting from seed node %Browser%
in our example, we fix the alignment with node firefox1. From this
fixed node alignment, we follow the edges inGq to fix the alignment
of additional nodes connected to the seed node. The specific node
alignment selected for each of these nodes is the one that maximizes
the contribution to the alignment score. For instance, from node
%Browser% (aligned to firefox1), we can proceed to node ∗.exe and
fix the alignment of that with one node among cmd.exe, tmp.exe,
and Word.exe, such that the contribution to the alignment score is
maximized.
Selection Function. The key intuition behind the selection function, which selects and fixes one among many node alignments,
is to approximate how much each alignment would contribute to
the final alignment score and to choose the one with the highest contribution. For a given candidate aligned node k in Gp , this
contribution is calculated as the sum of the maximum influence
scores between that node and all the other candidate nodes l in
Gp that: 1) are reachable from k or that have a path to k, and 2)
whose corresponding aligned node j in Gq has a flow from/to the
node in Gq that corresponds to node k. For instance, consider node
%Browser% and the two candidate alignment nodes firefox1 and
firefox2 in our example. To determine the contribution of firefox1,
we measure for every flow (%Browser% 99K ∗.exe, %Browser% 99K
spoolsv, %Browser% 99K %registry%) from/to %Browser% in Gq, the
maximum influence score between firefox1 and the candidate nodes
aligned with ∗.exe, spoolsv, and %registry%, respectively. In other
words, we compute the maximum influence score between firefox1
and each of the node alignment candidates of ∗.exe, the maximum
influence score between firefox1 and each of the node alignment candidates of spoolsv, and the maximum influence score between firefox1
and each of the node alignment candidates of %registry%. Each of
these three maximums provides the maximal contribution to the
alignment score of each of the possible future alignments (which
are not fixed yet) for ∗.exe, spoolsv, and %registry%, respectively.
Next, we sum these three maximum values to obtain the maximal
contribution that firefox1 would provide to the alignment score.
We repeat the same procedure for firefox2 and, finally select the
alignment with the highest contribution value. This contribution is
formally computed by the following equation, which approximates
A(i : k) the contribution of a node alignment i : k.
A(i : k)
=
Õ
j:(i99Kj)∈F (Gq )

1{j:l } × Γk,l + (1 − 1{j:l }
) × max
m∈cand idat es(j)
(Γk,m)

+
Õ
j:(j99Ki)∈F (Gq )

1{j:l } × Γl,k + (1 − 1{j:l }
) × max
m∈cand idat es(j)
(Γm,k )

(5)
where 1A is an indicator function, which is 1 if the alignment
expressed in A is fixed, and is 0 otherwise. In other words, if the
alignment between node j and l, has been fixed, l {j:l } equals to 1,
and otherwise, if node j is not aligned to any node yet, 1{j:l } equals
to 0. Note that 1{j:l } and (1 − 1{j:l }
) are mutually exclusive, and at
any moment, only one of them equals 1, and the other one equals
to 0.
We note that the first summation is performed on outgoing flows
from node i, while the second summation is performed on flows
that are incoming to node i. Inside each summation, the first term
represents a fixed alignment while the second term represents the
maximum among potential alignments that have not been fixed yet,
as discussed above.
Finally, for each node i having a set K of candidate alignments
as produced by Step 3, the selection function, which fixes the alignment of i is as follows:
arg max
k∈K
A(i : k) (6)
The intuition behind equations 5 and 6 is that once a node alignment is fixed, the other possible alignments of that node are ignored
by future steps of the algorithm and the calculation of the maximum influence score related to that alignment is reduced to a table
lookup instead of an iteration over candidate node alignments. In
particular, the search starts as a brute force search, but as more
and more node alignments are fixed, the search becomes faster
by reusing results of previous searches stored in the table. Using
equations 5 and 6 dramatically speeds up the determination of a
proper graph alignment. While in theory, this represents a greedy
approach, which may not always lead to the best results, in practice,
we have found that it works very well.
Finally, after fixing all node alignments, the alignment score is
calculated as in Equation (2). If the score is below the threshold,
the steps 2-4 are executed again. Our evaluation results in section 5
show that the attack graph is usually found within the first few
iterations.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1802
5 EVALUATION
We evaluate Poirot’s efficacy and reliability in three different experiments. In the first experiment, we use a set of DARPA Transparent Computing (TC) program red-team vs. blue-team adversarial
engagement scenarios which are set up in an isolated network
simulating an enterprise network. The setup contains target hosts
(Windows, BSD, and Linux) with kernel-audit reporting enabled.
During the engagement period, benign background activities were
continuously run in parallel to the attacks from the red team.
In the second experiment, we further test Poirot on real-world
incidents whose natural language descriptions are publicly available
on the internet. To reproduce the attacks described in the public
threat reports, we obtained and executed their binary samples in a
controlled environment and collected kernel audit logs from which
we build the provenance graph. In the third experiment, we evaluate
Poirot’s robustness against false signals in an attack-free dataset.
In all the experiments, we set the value of Cthr to 3 (and thus
a threshold of 1
3
). This choice is validated in section 5.3. We note,
however, that one can configure Poirot with higher or lower values
depending on the confidence about the system’s protection mechanisms or the effort cyber-analysts are willing to spend to check
the alarms. In fact, the value of Cthr influences the number of false
positives and potential false negatives. A higher Cthr will increase
the number of false positives while a lower Cthr will reduce it. On
the other hand, a higher value of Cthr may detect sophisticated
attacks, with multiple initial entry points, while a smaller value
may miss them. After finding alignment with a score bypassing the
threshold, we manually analyzed all the matched attack subgraphs
to confirm that they were correctly pinpointing the actual attacks
present in the query graphs.
5.1 Evaluation on the DARPA TC Dataset
This experiment was conducted on a dataset released by the DARPA
TC program, generated during a red-team vs. blue-team adversarial
engagement in April 2018 [31]. In the engagement, different services
were set up, including a web server, an SSH server, an email server,
and an SMB server. An extensive amount of benign activities was
simulated, including system administration tasks, web browsing to
many web sites, downloading, compiling, and installing multiple
tools. The red-team relies on threat descriptions to execute these
attacks. We obtained these threat descriptions and used them to
extract a query graph for each scenario (summary shown in table 2).
In total, we evaluated Poirot on ten attack scenarios including
four on BSD, two on Windows, and four on Linux. Due to space
Scenario subjects ∈
|V (Gq )|
objects ∈
|V (Gq )|
|E(Gq )| |F (Gq )|
BSD-1 4 9 19 81
BSD-2 1 7 10 32
BSD-3 3 18 34 159
BSD-4 2 8 13 43
Win-1 13 8 26 149
Win-2 1 13 19 94
Linux-1 2 9 19 62
Linux-2 5 12 24 112
Linux-3 2 8 22 48
Linux-4 4 11 22 96
Table 2: Characteristics of Query Graphs.
restrictions, we are not able to show all the query graphs; however,
their characteristics are described in table 2, where subjects indicate
processes, and objects indicate files, memory objects, and sockets.
BSD-1-4 pertain to attacks conducted on a FreeBSD 11.0 (64-bit)
web-server which was running a back-doored version of Nginx.
Win-1&2 pertain to attacks conducted on a host machine running
Windows 7 Pro (64-bit). The Win-1 scenario contains a phishing
email with a malicious Excel macro attachment, while the Win-2
scenario contains exploitation of a vulnerable version of the Firefox browser. Linux1&2 and Linux3&4 pertain to attacks conducted
on hosts running Ubuntu 12.04 (64-bit) and Ubuntu 14.04 (64-bit),
respectively. Linux1&3 contain in-memory browser exploits, while
Linux2&4 involve a user who is using a malicious browser extension.
Alignment Score. As discussed in section 4.2, Poirot iteratively
repeats the node alignment procedure starting from the seed nodes
with fewer candidates. Fig. 4 shows the number of candidate aligned
nodes for each node of Gq. Most of the nodes of Gq have less than
ten candidate nodes in Gp , while there are also nodes with thousands of candidate nodes. These nodes, which appear thousands of
times, are usually ubiquitous processes and files routinely accessed
by benign activities, such as Firefox or Thunderbird. We remind
the reader that our seed nodes are chosen first from the nodes with
fewer alignments. In each iteration, an alignment is constructed,
and its alignment score is compared with the threshold value, which
is set to 1
3
.
Table 3 shows Poirot’s matching results for each DARPA TC
scenario after producing an alignment of the query graphs with
the corresponding provenance graphs. We stop the search after the
first alignment that surpasses the threshold value. The second and
third columns of table 3 show the number of iterations of the steps
2-4 presented in section 4.2 and the actual score obtained for the
first alignment that bypasses the threshold value. In 9 out of 10
scenarios, an alignment bypassing the threshold value was found
in the first iteration. In one case, the exact matching of Gq could
be found in Gp (see BSD-4).
The fourth column of table 3 shows the maximum alignment
score among the 20 alignments constructed by iterating steps 2-4
of our search algorithm 20 times while the last column shows the
earliest iteration-number that resulted in the maximum value. As
can be seen, on average, our search converges quickly to a perfect
solution. In 7 out of 10 scenarios, the maximum alignment score is
calculated in the first iteration, while in the other 3, the maximum
Scenario Earliest
iteration
bypassing
threshold
Earliest
score
bypassing
threshold
Max
score in
20
iterations
Earliest
iteration
resulting
Max score
BSD-1 1 0.45 0.64 5
BSD-2 1 0.81 0.81 1
BSD-3 1 0.89 0.89 1
BSD-4 1 1 1 1
Win-1 1 0.63 0.63 1
Win-2 1 0.47 0.63 4
Linux-1 1 0.58 0.58 1
Linux-2 2 0.55 0.71 5
Linux-3 1 0.54 0.54 1
Linux-4 1 0.87 0.87 1
Table 3: Poirot’s Graph Alignment Scores.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1803
 0
 0.2
 0.4
 0.6
 0.8
 1
 1 10 100 1000
Percentage of |V(G
q)| (CDF)
Number of Candidates
BSD-1
BSD-2
BSD-3
BSD-4 0
 0.2
 0.4
 0.6
 0.8
 1
 1 10 100 1000
Percentage of |V(G
q)| (CDF)
Number of Candidates
Win-1
Win-2 0
 0.2
 0.4
 0.6
 0.8
 1
 1 10 100 1000
Percentage of |V(G
q)| (CDF)
Number of Candidates
Linux-1
Linux-2
Linux-3
Linux-4
Fig. 4: Cumulative Distribution Function (CDF) of number of candidates in |Gp | for each node of |Gq |. From left to right: BSD,
Windows, and Linux Scenarios.
61.130.69.232 firefox
/etc/firefox/native-messaging-hosts/gtcache
/bin/sh -c ./gtcache &>/dev/null &
/etc/passwd
/proc/30691/stat
/home/admin/profile
/var/log/wdev
/tmp/memtrace.so
/var/log/mail
/var/log/mail
149.52.198.23
128.55.12.10
%Browser%
23.194.99.39 145.199.103.57
*
/hosts/pass_mgr %External IP
Address%

*
gtcache*
/etc/passwd /etc/group

*
profile*
/var/log/mail /var/log/wdev /tmp/memtrace.so
*mail*
%External IP
Address%
%Intranet IP
Address%
send
recv send recv
.*
send
recv
write fork
execve
read read read
.*
write write
read
write
fork
execve
send
recv
send recv
/proc/*
*
/stat
gtcache*
A B B A
C
C
D
D
E
E
F
F
G
G
H
H I J I J
K
K
L
M
M
L
Fig. 5: Query Graph of Scenario: Linux-2 (on the left) and its Detected Alignment (on the right).
alignment scores are calculated in the fourth or fifth iterations.
The latter is due to slight differences between the attack reports
and the red team’s implementation of the attacks, which result
in information flows and causal dependencies that differ slightly
between the query graph and the provenance graph. As an example,
in Fig. 5, we show the query graph and its aligned subgraph for the
Linux-2 scenario. In this scenario, the attacker exploits Firefox via
a malicious password manager browser extension, to implant an
executable to disk. Then, the attacker runs the dropped executable
to exfiltrate some confidential information and perform a port scan
of known hosts on the target network. We tag the aligned nodes
in each graph with the same letter label. Some nodes on the query
graph are not aligned with any nodes in the provenance graph.
This reduces the score of the graph alignment to a value that is
less than 1. Although Gq largely overlaps with a subgraph in Gp ,
some nodes have no alignment, and some information flows and
causal dependencies do not appear in the provenance graph. The
percentage of these nodes is small, however. As long as the reports
are mainly matching the actual attack activities, our approach will
not suffer from this.
5.2 Evaluation on Public Attacks
In this section, we describe the evaluation of Poirot on attacks
performed by real-world malware families and compare its effectiveness with that of other similar tools. We show the results of this
evaluation in table 4. The names of these malware families, the CTI
reports we used as descriptions of their behavior, and the year in
which the report is published are shown in the first three columns.
Mutation Detection Evaluation. As mentioned earlier, a common practice among attackers is that of mutating malware to evade
detection or to add more features to it. Therefore, a CTI report
may describe the behavior of a different version of the malware
that is actually present in the system, and it is vital for a threat
hunting tool to be able to detect different mutations of a malware
sample. To this end, we execute several real-world malware families,
containing different mutated versions of the same malware, in a
controlled environment. The fourth column of table 4, shows the
number of malware samples with different hash values belonging
to the family mentioned in the corresponding CTI report. We note
that the reports describe the behavior of only a few samples. The
fifth column of table 4 shows our selected sample’s hash value,
while the sixth column shows the relation between our selected
sample and the ones the CTI report is based on. For instance, the
reports of DeputyDog, Uroburos, and OceanLotus cover different
activities performed by a set of different samples, and our selected
sample is one of them. We have aggregated all those activities in
one query graph. For the other test cases, the sample we have executed is different from the ones that the report is based on, which
could be considered as detecting a mutated malware. njRAT and
DustySky explicitly mention their analyzed sample, which are different from the one we have chosen. The Carbanak report mentions
109 samples, from which we have randomly selected one. Finally,
the sample of HawkEye malware is selected from an external source
and is not among the samples mentioned in the report.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1804
Malware Report Year Reported Analyzed Malware MD5 Sample Isolated Detection Results
Name Source Samples Relation IOCs RedLine Loki Splunk Poirot
njRAT Fidelis [58] 2013 30 2013385034e5c8dfbbe47958fd821ca0 different 153 F+H F+H P B (score=0.86)
DeputyDog FireEye [50] 2013 8 8aba4b5184072f2a50cbc5ecfe326701 subset 21 F×2+H+R F×2+H P+R B (score=0.71)
Uroburos Gdata [5] 2014 4 51e7e58a1e654b6e586fe36e10c67a73 subset 26 F+H F+H R B (score=0.76)
Carbanak Kaspersky [22] 2015 109 1e47e12d11580e935878b0ed78d2294f different 230 - PE S B (score=0.68)
DustySky Clearsky [65] 2016 79 0756357497c2cd7f41ed6a6d4403b395 different 250 - - - B (score=1.00)
OceanLotus Eset [6] 2018 9 d592b06f9d112c8650091166c19ea05a subset 117 F+R F+PE P+R B (score=0.65)
HawkEye Fortinet [7] 2019 3 666a200148559e4a83fabb7a1bf655ac different 3 - PE - B (score=0.62)
Table 4: Malware reports. In the Detection Results, B=Behavior, PE=PE-Sieve, F=File Name, H=Hash, P=Process Name,
R=Registry, S=Windows Security Event.
Comparison with Existing Tools. We compare Poirot with the
results of three other tools, namely RedLine[15], Loki[64], and
Splunk[59]. The input to these tools is extracted from the same
report we extract the query graphs and contains IOCs in different
types such as hash values, process names, file names, and registries.
We have transformed these IOCs to the accepted format of each
tool (e.g., RedLine accepts input in OpenIOC format [14]). The number of IOCs submitted to Redline, Loki, and Splunk are shown in
column-7, while the query graphs submitted to Poirot are shown in
Figs. 6 and 7. A detailed explanation of these query graphs demonstrating how they are constructed can be found in appendix A. The
correspondence between node labels in the query graphs and their
actual names is represented in the second and third columns of
tables 5 and 6, while the alignments produced by Poirot are shown
in the last column.
As shown in the extracted query graphs, the design of Poirot ’s
search method, which is based on the information flow and causal
dependencies, makes us capable to include benign nodes (nodes C,
D, E, and F in DustySky) or attack nodes with exact same names of
benign entities (node E in Carbanak) in the query graph. However,
these entity names could not be defined as an IOC in the other
tested tools as will lead to many false positive alarms. As Redline,
Loki, and Splunk look for each IOC in isolation, they expect IOCs
as input that are always malicious regardless of their connection
with other entities. To this end, we do a preliminary search for
each isolated IOC in a clean system and make sure that we have
only extracted IOCs that have no match in a clean system. As a
result, for some test cases, like HawkEye, although the behavior
graph is rich, there are not so many isolated IOCs except a few hash
values that could be defined. This highlights the importance of the
dependencies between IOCs, which is the foundation of Poirot’s
search algorithm, and is not considered by other tools.
Detection Results. The last four columns of table 4 contain the
detection results, which show how each tool could detect the tested
samples. Keywords B, F, H, P, and R represent detection based on
the behavior, file name, hash value, process name, and registry,
respectively. In addition, some of the tested tools feature other
methods to detect anomalies, injection, or other security incidents.
Among these, we encountered some alarms from Windows Security
Mitigation and PE-Sieve [23], which are represented by keywords
S and PE, respectively. While for Poirot, a score is shown which
shows the goodness of the overall alignment of each query graph,
for the other tools, ×N indicates the number of hits when there has
been more than one hit for a specific type of IOC.
As shown in table 4, for all the test cases, Poirot has found an
alignment that bypasses the threshold value of 1
3
. After running
the search algorithm, in most of the cases, Poirot found a node
alignment for only a subset of the entities in the query graph,
except for DustySky, where Poirot found a node alignment for
every entity. The information flows and causal dependencies that
appear among the aligned nodes are often the same as the query
graph with some exceptions. For example, in contrast to how it
appears in the query graph of njRAT, where node A generates most
of the actions, in our experiment, node F generated most of the
actions, such as the write event to nodes C, G, K, L, and the fork
event of node I. However, since there is a path from node A to node
F in the query graph, Poirot was able to find these alignments and
measure a high alignment score.
The samples of njRAT, DeputyDog, Uroburous, and OceanLotus
are also detected by all the other tools, as these samples use unique
names or hash values that are available in the threat intelligence
and could be attributed to those malwares. For the other three
test cases, none of the isolated IOCs could be detected because of
different reasons such as malware mutations, using random names
in each run (nodes J and K in HawkEye query graph), and using
legitimate libraries or their similar names. Nevertheless, Splunk
found an ETW event related to the Carbanak sample, which is
generated when Windows Security Mitigation service has blocked
svchost from generating dynamic code. Loki’s PE-Sieve has also
detected some attempts of code implants which have resulted in
raising some warning signal and not an alert. PE-Sieve detects
all modifications done to a process even though they may not
necessarily be malicious. As such modifications happen regularly
in many benign scenarios, PE-Sieve detections are considered as
warning signals that need further investigations.
Conclusions. Our analysis results show that other tools usually
perform well when the sample is a subset of the ones the report
is written based on. This situation is similar to when there is no
mutations, and therefore, there are unique hash values or names that
could be used as signature of a malware. For example, DeputyDog
sample drops many files with unique names and hash values that
do not appear in a benign system, and finding them is a strong
indication of this malware. However, its query graph (Fig. 2) is not
very rich, and Poirot has not been able to correlate the modified
registry (node D) with the rest of the aligned nodes. Although the
calculated score is still higher than the threshold, but the other
tools might perform better when the malware is using well-known
IOCs that are strong enough to indicate an attack in isolation.
On the contrary, when the chosen sample is different from the
samples analyzed by the report, which is similar to the case that
malware is mutated, other tools usually are not able to find the
attacks. In such situations, Poirot has a better chance to detect the
attack as the behavior often remains constant among the mutations.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1805
Malware Node Label Aligned Node Label
Carbanak
A %Mail Application% Thunderbird
B ∗.%exe% invitation.exe
C ∗ invitation
D %system32%\svchost C:\Windows\SysWOW64\svchost.exe:WofCompressedData
E svchost svchost
F ∗Sys$ None
G %COMMON_APPDATA%\Mozilla\∗.%exe% C:\ProgramData\Mozilla\BwgWXFhfbVpfWgJfBg.bin
H [HKCU]\Software\Microsoft\Windows\CurrentVersion \Internet Settings [HKCU]\Software\Microsoft\Windows\CurrentVersion \Internet Settings
I %AppData%\Mozilla\Firefox\∗\prefs.js C:\Users\test_user\AppData\Roaming\Mozilla\Firefox\Profiles\
ddl1t72n.default\prefs.js
J %External IP address% None
Uroburos
A ∗ contract.exe
B %APPDATA%\Microsoft\credprov.tlb C:\Users\test_user\AppData\Roaming\Microsoft\credprov.tlb
C %APPDATA%\Microsoft\shdocvw.tlb C:\Users\test_user\AppData\Roaming\Microsoft\shdocvw.tlb
D rundll32 rundll32
E [HKCU]\Software\Classes\CLSID\42aedc87-2188-41fd-b9a3-
0c966feabec1\
[HKCU]\Software\Classes\CLSID\42aedc87-2188-41fd-b9a3-
0c966feabec1\
F ∗\winview.ocx None
G ∗\mskfp32.ocx None
H ∗\msvcrtd.tlb None
I %APPDATA%\Microsoft\oleaut32.dll C:\Users\test_user\AppData\Roaming\Microsoft\oleaut32.dll
J %APPDATA%\Microsoft\oleaut32.tlb C:\Users\test_user\AppData\Roaming\Microsoft\oleaut32.tlb
K %APPDATA%\Microsoft\libadcodec.dll C:\Users\test_user\AppData\Roaming\Microsoft\libadcodec.dll
L %APPDATA%\Microsoft\libadcodec.tlb C:\Users\test_user\AppData\Roaming\Microsoft\libadcodec.tlb
DustySky
A ∗.%exe% News.docx.exe
B ∗ News
C %Microsoft Word% C:\Program Files\Microsoft Office\Office12\Winword.exe
D ∗\vboxmrxnp.dll C:\WINDOWS\vboxmrxnp.dlls
E ∗\vmbusres.dll C:\WINDOWS\vmbusres.dlls
F ∗\vmGuestlib.dll C:\WINDOWS\SysWOW64\vmGuestLib.dll
G %TEMP%\∗.%exe% C:\Users\test_user\AppData\Local\Temp
\1371372533114561232114361100131187183149253.exe
H ∗ 1371372533114561232114361100131187183149253
I %TEMP%\temps C:\Users\test_user\AppData\Local\Temp\temps
OceanLotus
A ∗.%exe% Chi tiet don khieu nai gui saigontel.exe
B ∗ Chi tiet don khieu nai gui saigontel
C %temp%\∗ C:\Users\test_user\AppData\Local\Temp\tmp.docx
D %temp%\[0-9].tmp.%exe% None
E %Microsoft Word% C:\Program Files\Microsoft Office\Office12\Winword.exe
F ∗\rastlsc.%exe% C:\Program Files (x86)\Symantec\Officewordtask\rastlsc.exe
G ∗\rastls.dll C:\Program Files (x86)\Symantec\Officewordtask\rastls.dll
H ∗\(Sylog.bin|OUTLFLTR.DAT) C:\Program Files (x86)\Symantec\Officewordtask\OUTLFLTR.DAT
I rastlsc rastlsc
J \SOFTWARE\Classes\AppX∗ None
K ∗\HTTPProv.dll None
L SOFTWARE\Classes\CLSID\{E3517E26-8E93-458D-A6DF-8030BC80528B} SOFTWARE\Classes\CLSID\{E3517E26-8E93-458D-A6DF-8030BC80528B}
M %External IP address% None
Table 5: Node labels of the query graphs in Fig. 6 and their alignments. A B
C D
E
G H
I
F
J
1. write
2. exec
3. write
4. exec
5. unlink
7. write
8. read
6. fork
10. send 9. read
A B
C
D
E
G
H
I
1. exec
3. read 2. fork
4. read
5. read
7. write
8. fork
9. exec
10. write
F
6. read
A
B
1: write
C
2: write
D 3: fork
4: load
5: load
E
6: write
F
7: write
10: unlink
I
12: unlink
J
13: unlink
11: unlink
K
14: unlink
L
15: unlink
G
8: write H
9: write
Uroburos
Carbanak DustySky
A
B
D
C
F
H
G
I
K
J
L
M
1. exec
3. write
2. write
6. write
8. write
7. write
9. fork
10. exec
12. read
11. load 14. load
13. read
15. write
16. write
17. read
E
4. fork
5. exec
OceanLotus
Fig. 6: Query Graphs of Carbanak, Uroburos, DustySky, and OceanLotus malware extracted from their CTI reports.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1806
Malware Node Label Aligned Node Label
njRAT
A ∗ Authorization
B ∗.exe.config C:\Users\test_user\Desktop\Authorization.exe.config
C ∗.tmp C:\Users\test_user\AppData\Roaming\ja33kk.exe.tmp
D C:\WINDOWS\Prefetch\∗.EXE-∗.pf C:\Windows\Prefetch\AUTHORIZATION.EXE-69AD75AA.pf
E %APPDATA%\∗ C:\Users\test_user\AppData\Roaming\ja33kk.exe
F ∗ ja33kk
G C:\WINDOWS\Prefetch\∗.EXE-∗.pf C:\Windows\Prefetch\JA33KK.EXE-7FA5E873.pf
H %USER_PROFILE%\Start Menu\Programs\Startup\∗ C:\Users\test_user\AppData\Roaming\Microsoft\Windows\Start
Menu\Programs\Startup\9758a8dfbe15a00f55a11c8306f80da1.exe
I netsh netsh
J C:\WINDOWS\Prefetch\NETSH.EXE-∗.pf C:\Windows\Prefetch\NETSH.EXE-CD959116.pf
K [HKCU]\Software\Microsoft\Windows\CurrentVersion\Run\ [HKCU]\Software\Microsoft\Windows\CurrentVersion\Run\
L [HKLM]\Software\Microsoft\Windows\CurrentVersion\Run\ [HKLM]\Software\Microsoft\Windows\CurrentVersion\Run\
M [HKLM]\SYSTEM\CurrentControlSet\Services\SharedAccess\-
Parameters\FirewallPolicy\StandardProfile\AuthorizedApplications\List\APPDATA\
None
N %External IP address% None
HawkEye
A ∗.%Compressed% PROFORMA INVOICE _20190423072201 pdf.bin.zip
B %Unachiever% WinRAR.exe
C ∗.%exe% C:\Users\test_user\Desktop\PROFORMA INVOICE _20190423072201 pdf.bin
D ∗ PROFORMA INVOICE _20190423072201 pdf
E RegAsm RegAsm
F vbc vbc (PID1)
G vbc vbc (PID2)
H1 ∗Opera∗ C:\Users\test_user\AppData\Roaming\Opera\Opera7\profile\wand.dat
H2 ∗Chrome∗ C:\Users\test_user\AppData\Local\Google\Chrome\User Data\Default\Login
Data
H3 ∗Chromium∗ C:\Users\test_user\AppData\Local\Chromium\User Data
H4 ∗Chrome SxS∗ C:\Users\test_user\AppData\Local\Google\Chrome SxS\User Data
H5 ∗Thunderbird∗ C:\Users\test_user\AppData\Roaming\Thunderbird\Profiles
H6 ∗SeaMonkey∗ C:\Users\test_user\AppData\Roaming\Mozilla\SeaMonkey\Profiles
H7 ∗SunBird∗ None
H8 ∗IE∗ C:\Users\test_user\AppData\Local\Microsoft\Windows\History\History.IE5
H9 ∗Safari∗ None
H10 ∗Firefox∗ C:\Users\test_user\AppData\Roaming\Mozilla\Firefox\profiles.ini
H11 ∗Yandex∗ C:\Users\test_user\AppData\Local\Yandex\YandexBrowser\User
Data\Default\Login Data
H12 ∗Vivaldi∗ C:\Users\test_user\AppData\Local\Vivaldi\User Data\Default\Login Data
I1 ∗Yahoo∗ [HKLM]\Software\Yahoo\Pager
I2 ∗GroupMail∗ None
I3 ∗Thunderbird∗ C:\Users\test_user\AppData\AppData\Roaming\Thunderbird\Profiles
I4 ∗MSNMessenger∗ [HKLM]\Software\Microsoft\MSNMessenger
I5 ∗Windows Mail∗ C:\Users\test_user\AppData\Local\Microsoft\Windows Mail
I6 ∗IncrediMail∗ [HKLM]\Software\WOW6432Node\IncrediMail\Identities
I7 ∗Outlook∗ [HKLM]\Software\Microsoft\Office\16.0\Outlook\Profiles
I8 ∗Eudora∗ [HKLM]\Software\Qualcomm\Eudora\CommandLine
J %temp%\∗.tmp C:\Users\test_user\AppData\Local\Temp\tmp8FC3.tmp
K %temp%\∗.tmp C:\Users\test_user\AppData\Local\Temp\tmp8BAB.tmp
L http[s]:\\whatismyipaddress.com\∗ None
M %External IP address% None
DeputyDog
A ∗.%exe% C:\Users\test_user\Desktop\img20130823.jpg.exe
(Fig. 2)
B ∗ img20130823
C %APPDATA%\∗ C:\ProgramData\28542CC0.dll
D [HKCU]\Software\Microsoft\Windows\CurrentVersion\ Run\ None
E %External IP address% 180.150.228.102
Table 6: Node labels of the query graphs in Figs. 2 and 7 and their alignments.
I H1
1
I2
I8
H12
H2
H1
A
B
C
D
E
G F
K J
L M
1. read 2. write
3. exec
4. fork 6. fork 5. fork
19. open
26. open
20. open
28. write
30. read
32. unlink
7. open
8. open
18. open
27. write
29. read
31. unlink
33. write
34. read
33. write
HawkEye
B
A
D
C
E
F
G
H
I
J K
L M
N
1. read
3. write 2. write
4. write
5. fork
6. exec
7. write 8. write
9. fork
11. write 10. write
12. write
13. write
14. send
njRAT
Fig. 7: Query Graphs of HawkEye and njRAT malware, extracted from their CTI reports.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1807
Scenario Size on Disk
(Uncompressed)
Consumption
time
Occupied
Memory
Log Duration sub ∈
|V (Gp )|
obj ∈
|V (Gp )|
|E(Gp )| Search Time (s)
BSD-1 3022 MB 0h-34m-59s 867 MB 03d-18h-01m 110.66 K 1.48 M 7.53 M 3.28
BSD-2 4808 MB 0h-58m-05s 1240 MB 05d-01h-15m 213.10 K 2.25 M 12.66 M 0.04
BSD-3&4 1828 MB 0h-21m-31s 638 MB 02d-00h-59m 84.39 K 897.63 K 4.65 M 26.09 (BSD-3), 1.47 (BSD-4)
Win-1&2 54.57 GB 4h-58m-30s 3790 MB 08d-13h-35m 1.04 M 2.38 M 70.82 M 125.26 (Win-1), 46.02 (Win-2)
Linux-1&2 9436 MB 1h-26m-37s 4444 MB 03d-04h-20m 324.68 K 30.33 M 51.98 M 1279.32 (Linux-1), 1170.86 (Linux-2)
Linux-3 131.1 GB 2h-30m-37s 21.2 GB 10d-15h-52m 374.71 K 5.32 M 69.89 M 385.16
Linux-4 4952 MB 0h-04m-00s 1095 MB 00d-07h-13m 35.81 K 859.03 K 13.06 M 20.72
Table 8: Statistics of logs, Consumption and Search Times.
 0
 0.2
 0.4
 0.6
 0.8
 1
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Rate
Threshold
Optimal Value
Precision
Recall
F-score
Fig. 8: Selecting the Optimal Threshold Value.
5.3 Evaluation on Benign Datasets
To stress-test Poirot on false positives, we used the benign dataset
generated as part of the adversarial engagement in the DARPA TC
program and four machines (a client, a SSH server, a mail server
and a web server) we monitored for one month. Collectively, these
datasets contained over seven months worth of benign audit records
and billions of audit records on Windows, Linux, and FreeBSD. During this time, multiple users used these systems and typical attackfree actions were conducted including web browsing, installing
security updates (including kernel updates), virus scanning, taking
backups, and software uninstalls.
After collecting the logs, we run Poirot to construct the provenance graph, and then search for all the query graphs we have
extracted from the TC reports and the public malware reports. We
try up to 20 iterations starting from different seed node selections
per each query graph per each provenance graph and select the
highest score. Note that although these logs are attack-free, they
share many nodes and events with our query graphs, such as confidential files, critical system files, file editing tools, or processes
related to web browsing/hosting, and email clients, all of which
were accessed during the benign data collection period. However,
even in cases where similar flows appear by chance, the influence
score prunes away many of these flows. Consequently, the graph
alignment score Poirot calculates among all the benign datasets is
at most equal to 0.16, well below the threshold.
Validating the Threshold Value. The selection of the threshold
value is critical to avoid false signals. Too low a threshold could
result in premature matching (false positives) while too high a
threshold could lead to missing reasonable matches (false negatives). Thus, there is a trade-off in choosing an optimal threshold
value. To determine the optimal threshold value, we measured the
F-score using varying threshold values, as shown in Fig. 8. This
analysis is done based on the highest alignment score calculated
in 20 iterations of Poirot’s search algorithm for all the attack and
benign scenarios we have evaluated. As it is shown, the highest
F-score value is achieved when the threshold is at the interval [0.17,
0.54], which is the range in which all attack subgraphs are correctly
found, and no alarm is raised for benign datasets. The middle of
this interval, i.e., 0.35, maximizes the margin between attack and
benign scores, and choosing this value as the optimal threshold
minimizes the classification errors,. Therefore, we set the Cthr to 3
which results in 1
Cthr
=
1
3 which is close to the optimal value.
5.4 Efficiency
The overheads and search times for the different tools we used are
shown in table 7. Redline and Loki are offline tools, searching for
artifacts that are left by the attacker on the system, while Splunk and
Poirot are online tools, searching based on system events collected
during runtime. Hence, Redline and Loki have no runtime overhead
due to audit log collection. The runtime overheads of Splunk and
Poirot due to log collection are measured using Apache benchmark
[3], which measures web server responsiveness, JetStream [73],
which measures browser execution times, and HDTune [11], which
measures heavy hard drive transactions. As shown in table 7, both
tools have shown negligible runtime overhead, while the runtime
of Splunk can be further improved by setting it up in a distributed
setting and offloading the data indexing task to another server.
The last column of table 7 shows the time it took searching for
IOCs per each tool. The search time of offline tools highly depends
on the number of running processes and volume of occupied disk
space, which was 500 GB in our case. On the other hand, the search
time of online methods highly depends on the log size, type and
number of activities represented by the logs. As our experiments
with real-world malware samples were running in a controlled environment without many background benign activities and Internet
connection, both Splunk and Poirot spend less than one minute to
search for all the IOCs mentioned in table 4. In the following, we
perform an in-depth analysis of Poirot ’s efficiency on the DARPA
TC scenarios, which overall contain over a month worth of log data
with combined attack and benign activities. The analysis is done
on an 8-core CPU with a 2.5GHz speed each and a 150GB of RAM.
Detection Type Runtime Overhead Search
Method Apache
[3]
JetStream
[73]
HDTune
[11]
Time (min)
Redline offline - - - 124
Loki offline - - - 215
Splunk online 3.70% 2.94% 4.37% < 1
Poirot online 0.82% 1.86% 0.64% < 1
Table 7: Efficiency Comparison with Related Systems.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom 1808
Audit Logs Consumption. In table 8, the second column shows
the initial size of the logs on disk, the third column represents the
time it takes to consume all audits log events from disk for building
the provenance graph in memory. This time is measured as the wallclock time and varies depending on the size of each audit log and the
structure of audits logs generated in each platform (BSD, Windows,
Linux). The fourth column shows the total memory consumption
by each provenance graph. Comparing the size on disk versus
memory, we notice that we have an average compression of 1:4
(25%) via a compact in-memory provenance graph representation
based on[25]. However, if memory is a concern, it is still possible to
achieve better compression using additional techniques proposed
in this area [26, 40, 74]. The fifth column shows the duration during
which the logs were collected while columns 6, 7, and 8 show the
total number of subjects (i.e. processes), objects, and events in the
provenance graph that is built from the logs, respectively. We note
that the query graphs are on average 209K times smaller than the
provenance graph for these scenarios. Nevertheless, Poirot is still
able to find the exact embedding of Gq in Gp very fast, as shown
in the last column. We note that some scenarios are joined (e.g.,
Win-1&2) because they were executed concurrently on the same
machines.
Graph Analytics. In the last column of table 8, we show the runtime of graph analytics for Poirot’s search algorithm. These times
are measured from the moment a search query is submitted until we
find a similar graph in Gp with an alignment score that surpasses
the threshold. Therefore, for Linux-2, the time includes the sum of
the times for two iterations. The main bottleneck is on the graph
search expansion (Step 3), and the time Poirot spends on graph
search depends on several factors. Obviously, the sizes of both query
and provenance graph are proportional to the runtime. However,
we notice that the node names in Gq and the shape of this graph
have a more significant effect. In particular, when there are nodes
with many candidate alignments, there is a higher chance to reverse
the direction multiple times and runtime increases accordingly.
6 CONCLUSION
Poirot formulates cyber threat hunting as a graph pattern matching
problem to reliably detect known cyber attacks. Poirot is based on
an efficient alignment algorithm to find an embedding of a graph
representing the threat behavior in the provenance graph of kernel
audit records. We evaluate Poirot on real-world cyber attacks and
on ten attack scenarios conducted by a professional red-team, over
three OS platforms, with tens of millions of audit records. Poirot
successfully detects all the attacks with high confidence, no false
signals, and in a matter of minutes.