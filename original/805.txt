Robotic vehicles (RVs), such as drones and ground rovers, are a type
of cyber-physical systems that operate in the physical world under
the control of computing components in the cyber world. Despite
RVs’ robustness against natural disturbances, cyber or physical
attacks against RVs may lead to physical malfunction and subsequently disruption or failure of the vehicles’ missions. To avoid or
mitigate such consequences, it is essential to develop attack detection techniques for RVs. In this paper, we present a novel attack
detection framework to identify external, physical attacks against
RVs on the fly by deriving and monitoring Control Invariants (CI).
More specifically, we propose a method to extract such invariants
by jointly modeling a vehicle’s physical properties, its control algorithm and the laws of physics. These invariants are represented in a
state-space form, which can then be implemented and inserted into
the vehicle’s control program binary for runtime invariant check.
We apply our CI framework to eleven RVs, including quadrotor,
hexarotor, and ground rover, and show that the invariant check can
detect three common types of physical attacks – including sensor
attack, actuation signal attack, and parameter attack – with very
low runtime overhead.
CCS CONCEPTS
• Security and privacy → Embedded systems security; • Computer systems organization → Embedded and cyber-physical systems; Evolutionary robotics;
KEYWORDS
CPS Security; Robotic Vehicle; Control Invariant; Attack and Detection

1 INTRODUCTION
Robotic Vehicles (RVs) are a type of cyber-physical systems (CPS)
that consist of both cyber and physical components working jointly
to support the vehicle’s operations in the physical world. RVs are
becoming an integral part of our daily life. Self-driving vehicles [15,
17, 79] are expected to be commonly seen on streets and work sites.
Unmanned Aerial Vehicles [4, 62] such as drones are widely used
in defense scenarios [51] and start to appear in many commercial
and personal applications. Amazon [3] has already demonstrated
the feasibility of employing drones for order delivery. The first
passenger drone, Ehang 184 [74], was introduced in 2016.
With increasing usage of RVs in a wide range of application
domains, the security of RV has become an essential requirement
and imperative challenge. Many recent efforts in RV security have
focused on protecting the cyber components (e.g., control software and firmware) of an RV from cyber attacks [14, 43, 60], by
software security approaches such as control flow integrity (CFI)
[14, 60], memory isolation [43], and software/firmware hardening
[16, 18, 20, 67]. These solutions are effective in defending against
attacks launched via a cyber vector such as program vulnerability
exploitation and with cyber payloads, such as injected or trojaned
code and ROP.
To make attacks against RVs harder to detect, adversaries have
started to target the physical components of a victim vehicle. First,
the vehicle’s sensors can be maliciously misguided through external, non-cyber vectors. For instance, GPS spoofing [35, 75, 78] can
disturb GPS sensor readings. Optical sensor spoofing [21] allows
an attacker to acquire an implicit control channel, by deceiving
the optical flow sensor of a drone with a physically altered ground
plane. Gyroscopic sensor spoofing through acoustic noises [72]
can lead to drone crashes. In [69], it is shown that an automobile’s
anti-lock braking system (ABS) [69] can be attacked by injecting
magnetic fields to tamper with the wheel speed sensor readings.
In [76], it is shown that attackers can manipulate the measurements
from MEMS accelerometers via analog acoustic signal injection.
Second, attackers may disrupt vehicle communications, such as
the wireless channel between a drone and the ground station [34].
Third, attackers may compromise important parameter values (e.g.,
those deciding control gains) stored in memory through physical
interference. In [70], it is demonstrated that values in EEPROM
and Flash memory can be corrupted by heating up a memory cell
inside a memory array without damaging the device. These physical attacks – contrary to cyber attacks – pose new challenges as
they cannot be effectively handled by traditional computer security
techniques.
Meanwhile, invariant checking is a well-established approach to
detecting runtime anomalies caused by program bugs or exploits.
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 801
Traditionally, invariants are properties of the program execution
state that should always hold. Such invariants are manually specified by developers or automatically extracted via program analysis.
For instance, DAIKON [29] infers invariants from execution using
pre-defined templates and then monitors the invariants to detect
runtime exceptions. Runtime verification (e.g., [12, 65]) represents
legitimate program state transitions in an automaton that can be
validated at runtime. Control Flow Integrity (CFI) derives control
flow invariants [1] (e.g., function gee() can only be invoked by
function foo(). Invocations from any other caller are considered
exceptions). There is a large body of work [7, 22, 37, 42, 71, 83]
demonstrating that invariant checking can prevent a wide spectrum of software oriented (i.e., cyber) attacks.
Inspired by program invariant checking, we propose a novel
control invariant (CI) checking framework for detecting external,
physical attacks against RVs. The novelty lies in the fact that we
do not aim to check the traditional program-based invariants, but
rather control invariants that model both control and physical properties/states of the vehicle. The control invariants are determined
jointly by physical attributes of the RV (e.g., weights and shapes), its
underlying control algorithm and the laws of physics (e.g., inertia
and effects of gravity). The control invariants reflect (and set constraints to) an RV’s normal behaviors according to its control inputs
(e.g., make a 30o
turn) and current physical states (e.g., velocity and
position); any deviation from them will be deemed anomalous.
Our control invariant (CI) framework works as follows. First, it
leverages a control system engineering methodology called system
identification (SI), the “physical” counterpart of program reverse
engineering, to extract the control invariants from a subject RV.
The SI method takes a control invariant template (equations with
unknown coefficients) and a large set of vehicle profiling measurement data (such as system inputs, outputs, and states), as input.
It then instantiates the template’s coefficients so that the resulted
equations provide the best fit for the measurement data. These
equations will be used at runtime to predict the behaviors of the
vehicle based on inputs and states and hence serve as the control
invariants of the vehicle. A key observation – well-established in
control system engineering – is that the same control invariant
template can be used to instantiate control invariants for a family
of vehicles with a similar physical organization (e.g., all quadrotors [9]). In other words, their control invariants can be based on the
same equation template, only differing in coefficient values. This
significantly reduces a subject RV’s modeling space in SI, making
our framework generic and practical.
Next, the CI framework involves instrumenting the vehicle’s control program binary to insert a piece of control invariant checking
code into the main control loop. At runtime, the code will periodically observe the current system state and independently compute
the expected state using the control invariant equations. If the discrepancy between the computed and observed states accumulates
and exceeds a threshold within a monitoring window, an alarm
will be raised. The window is defined to filter out transient errors
caused by physical disturbances (e.g., winds).
Contribution. The salient features of our CI framework include
the following: (1) By modeling the physical/control properties and
normal dynamics of a subject vehicle, the control invariants directly
Figure 1: Acoustic noise attack and the affected flight trajectory
while performing a simple flight mission
expose any violation caused by physical, external attacks (which
may not cause any program-level anomaly); (2) Based on the generic
method of SI, our framework is applicable to a wide range of RVs
and does not require per-vehicle controller program reverse engineering to derive control invariants; (3) With monitoring window
and threshold, our framework achieves high detection accuracy
by filtering out false positive invariant violations. To realize these
features we have addressed a number of design and engineering
challenges, such as vehicle mission planning for profile data generation, monitoring window size determination, and binary control
program instrumentation; (4) Our framework enables softwarebased detection of physical attacks without hardware modification
or addition.
We have developed a prototype of the CI framework and applied it to 11 robotic vehicles including quadrotors, hexarotors and
ground rovers. Our evaluation results demonstrate effectiveness of
the framework: The derived control invariants are able to detect
three types of common attacks including sensor spoofing, control
signal spoofing, and parameter corruption; the inserted control invariant checking code incurs low runtime overhead (<2.3%); and the
attack detection logic achieves zero false positives during normal
operation of subject vehicles.
2 MOTIVATION
To further motivate our framework, we describe, as a working example, an external sensor spoofing attack [21, 35, 46, 58, 69, 72, 75–78]
against an IRIS+ quadrotor. A sensor spoofing attack misleads sensor inputs by perturbing the physical environment being sensed.
Given the malicious sensor inputs, the vehicle’s controller will generate erroneous outputs which will disrupt or damage the vehicle.
A typical RV utilizes a number of sensors to measure the current physical states of the vehicle. In the quadrotor, its Inertial
Measurement Unit (IMU) has gyroscopes, accelerometer sensors,
and magnetometers, which measure the angular and linear state
information. Among these sensors, our sample attack aims to spoof
the gyroscope readings, from which erroneous angular state will
be inferred, leading to a crash[72, 77]. In particular, the attacker intentionally injects acoustic noises at the resonant frequency of the
gyroscope, causing the gyroscope to generate abnormal readings.
We note that the attack is an external, physical one without access
to the internals of the victim vehicle, and it cannot be detected by
existing software security techniques.
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 802
1 main_loop () {
2
3 angles = read_AHRS () ;
4
5 targets = navigation_logic () ;
6
7 // invariant monitoring
8 inv_monitor ( targets , angles ) ;
9
10 inputs = attitude_controller (
targets , angles ) ;
11
12 motor . update ( inputs ) ;
13 }
(a) main loop
1 attitude_controller ( targets , angles ) {
2
3 error = targets - angles ;
4
5 // example pid controller
6 P = kp * error ;
7 I = ki * error_sum ;
8 D = kd * ( angles - angles_last ) ;
9
10 inputs = P + I + D ;
11
12 return inputs ;
13
14 }
(b) attitude controller
1 inv_monitor ( targets , angles ) {
2
3 y = Cx + D * targets ;
4 x = Ax + B * targets ;
5
6 i_err = y - angles ;
7 i_err_sum += i_err ;
8 if( i_err_sum > threshold ) {
9 raise_alram () ;
10 }
11
12 if( window == expired )
13 i_err_sum = 0;
14 }
(c) invariant monitor
Figure 2: Simplified example of a control loop and invariant monitor
Figure 1 illustrates the attack and its consequences. In the flight
mission, the quadrotor is supposed to take off from the home position to an altitude of 20 meters and then move to waypoints 1 and 2
and then go back to the base. The white line indicates the expected
trajectory. Between waypoints 1 and 2, the attack is launched. The
red line shows the actual flight trajectory. Observe that after the
attack is launched, the drone deviates from the planned route and
eventually crashes.
To understand how the attack induces the abnormal behavior,
Figures 2(a) and (b) show the related code snippets in the quadrotor’s control program. (They have been substantially simplified for
readability.) Figure 2(a) shows the main control loop. The loop is
invoked by a real-time scheduler at a certain frequency. In each
iteration, the loop starts by reading sensor inputs. At line 3, the
angular information is obtained through the Attitude and Heading
Reference System (AHRS). At line 5, the target states are computed
by the autonomous navigation logic based on the flight plan. At
line 10, the control loop invokes the attitude controller to generate
control signals (e.g., rotational speeds of the four rotors) based on
the difference between the current and target states.
Figure 2(b) shows the attitude controller based on the classic
Proportional-Integral-Derivative (PID) control algorithm. Line 3 in
attitude_controller calculates the error. In lines 6 to 8, the PID
algorithm determines the control signals based on the error and a
weighted sum of the propositional (P), integral (I), and derivative
(D) terms.
During the spoofing attack, the sensor generates wrong angular
position readings such that variable angles at line 3 in (a) has
a faulty state. Subsequently, in the attitude controller, the error
value at line 3 in (b) is corrupted, leading to wrong actuation signal
in inputs at line 10 in (a). In the next control loop iteration, the
real angular position (due to the wrong actuation signal) will not
be reported by the spoofed sensor, further disrupting the vehicle’s
attitude and eventually leading to its crash.
The CI Approach. Under the CI framework, we can detect such an
external attack by checking whether the (perceived) physical state
of the vehicle is consistent with its expected state determined by its
control model. The control model in turn is defined by the RV’s system properties and control algorithm, mathematically represented
by our control invariants. For example, the weight, frame shape,
and parameter values in a PID controller determine how a drone
would respond to external environmental conditions and control
signals. Intuitively, the control invariants will predict the next move
of the vehicle based on its current state and inputs. An external
attack, by definition, will influence the vehicle to deviate from its
normal, expected actions/motions, without accurate knowledge
about the RV’s internals, especially the controller’s current input,
state, and output values. Hence the deviation can be manifested
by violation of the control invariants, as if the vehicle is no longer
following the control and physics laws.
state new state
input
output
Figure 3: State-space representation of a quadrotor’s control
More specifically, our CI framework will work as follows. Given
a subject RV, the system identification (SI) method will first be applied to “reverse engineer” the dynamics and control model of the
vehicle. More specifically, the control model will be represented by
two equations [56]: the output equation that determines the control
output (e.g., new angle of a drone) based on the system’s current
state (e.g., attitude and position) and its input (e.g., target position);
and the state equation that determines the next system state from
the current state and input. Figure 3 shows the two equations for a
quadrotor drone, with x(t), u(t), y(t), and x
′ denoting its control
state at time t, input at t, output at t, and next expected state, respectively. Different systems have different A, B, C, and D matrices. The
SI method will concretize the values of the matrices for a specific
vehicle, based on its measurement and profile data.
In our working example, we conduct SI on the quadrotor to derive the matrices, which allows us to estimate the output y and
future state x at lines 3-4 in Figure 2 (c) with y denoting the predicted value of angles. Then, line 6 calculates the error between
the observed and the expected angle values. To avoid false positives
due to transient errors, we would not raise an alarm every time an
error is observed. Instead, we accumulate the errors in a monitoring window (line 7 in (c)) and compare the aggregated error with
a threshold (line 8). We develop an analysis tool to determine the
monitoring parameters: window size and threshold (to be described
in Section 4.2). In an external attack, the attacker cannot precisely
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 803
obtain and control the (internal) RV controller’s current states; and
the malicious sensor readings inflicted by the attacker cannot accurately reflect the physical properties or planned moves of the
RV. As a result, the spoofed sensor readings would undermine the
validity of the feedback loop, leading to substantial errors.
0 10 20 30 40 50 60
time (sec)
-400
-200
0
200
400
angle (deg)
measured
invariant
takeoff wp1 attack
measured
Invariant
Figure 4: Roll changes during flight
Figure 4 shows the changes of roll angle, one of the attitude
angles of a quadrotor under attack. The red curve indicates the
sensor readings and the blue curve shows the corresponding values
predicted by the control invariants. During normal operation (the
green area), the two have negligible difference. During the attack,
the roll values fluctuated in the red area and substantially deviated
from the predicted values. Note that the red values are what the
vehicle (under attack) perceived. The vehicle’s controller thus tried
to correct the (bogus) errors. Such correction conversely made the
drone oscillate and eventually lose balance. In comparison, the
predicted values (the blue curve in the red region in Figure 4) did
not fluctuate as much because they follow the control model and
physics.
Technical Challenges. Leveraging on SI’s generality, the CI framework should be applicable to a wide range of RVs. To develop the
framework, we need to address the following challenges, especially
under the assumption of no control program source code: (1) We
need to derive the control invariants (i.e., concretizing the matrices
in the state and output equations). The SI method requires a set of
training flights to determine the matrices. In addition, treating an
RV as a black box during SI may lead to a very large search space
(for the model) such that it might not converge with good precision
within a reasonable amount of time. (2) We need to identify – from
the control program binary – the main control loop and program
variables that denote the current system states. The main control
loop needs to be located for the insertion of control invariant checking code in the loop; the state variables need to be recognized as
they are needed in the evaluation of the two control model equations. (3) We need to set an appropriate size of the monitoring
window and the detection threshold (at lines 8 and 12 in Figure 2
(c)). If the threshold is too large, we may not be able to detect an
attack in time. If the threshold is too small, transient errors (e.g.,
overshoot when a drone turns) and environmental disturbances –
both correctable by the controller – may be reported as attacks.
3 FRAMEWORK OVERVIEW
Figure 5 gives an overview of the CI framework, which consists
of three main components: control invariants extraction, control
program reverse engineering, and monitor (i.e., control invariant
check code) generation.
System	
Identification
Monitoring
Monitoring	
Parameter	
Selection
Invariants	
Instrumentation
D Inv
Inv, �th, ƛ
B’
B, LAddr
Vt Binary	Reverse	Engineering	 ,Vm
Invariant	Extraction Monitor	Generation
Data	
Collection
Control	Loop	
RE
State	Variables	
RE
Figure 5: Overview of the CI framework
In the "invariant extraction" step, system identification (SI) is
performed to instantiate the invariant equation matrices. First, a set
of missions (i.e., flights or rides) to be performed by the subject RV
are generated and executed. During the missions, we measure and
record the runtime inputs (target states) and system states. These
data will be used in SI to derive unknown coefficients.
We then set up a control model template for the target RV. Such
a template includes equations of a certain degree/form with uninstantiated parameters (e.g., quadratic functions) and can be determined by the vehicle’s physical properties and the type of control
algorithm used. A family of RVs, for example, drones of the similar physical form (e.g., quadrotors), share the same template but
have different parameters (e.g., weight, control gain, inertia, etc.).
Quadrotors, hexarotors, and rovers belong to different families
hence require different templates. With the model template and
measurement data from the test missions, SI determines the optimal template parameters that best fit the data. The instantiated
equations reflect the vehicle’s control model and hence serve as its
control invariants.
Next, to instrument the (binary) control program with invariantchecking logic, we locate the main control loop and state variables,
which will be accessed by the invariant checking code when evaluating the invariant equations. This is achieved by dynamic program
analysis. Specifically, the control loop is identified by observing the
instruction sequences that are periodically executed. The program
variable corresponding to a model variable is identified by comparing the value sequences of the program variable with those of the
model variable. The latter are generated by running the model with
the same mission.
In the “monitor generation” step, we determine the critical monitoring parameters: error threshold ϵth and monitoring window size
λ. We first determine the window size by calculating the maximum
temporal deviation between the actual state sequences (e.g., the
attitude variations overtime) and the corresponding model-derived
sequences via a sequence alignment algorithm for the training runs.
Once the window is determined, we calculate the accumulated
transient errors in each monitoring window and use the maximum
observed error to set the error threshold.
Finally, we use detour-based binary rewriting [36] to insert the
invariant-checking code into the control program binary.
Adversary Model. In this paper, we focus on attacks that interfere
with RV operations by corrupting or injecting (actuation or sensor)
signals through external means (e.g., distorting actuation signals or
misleading sensors to generate erroneous readings). We assume that
the attacker does not have access to the control program running onboard and hence cannot compromise/bypass the invariant-checking
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 804
code. We note that the more traditional cyber attacks (launched via
software/firmware) are not the focus of this paper as they can be
effectively handled by existing software security techniques (e.g.,
CFI).
We assume that the attacker does not know at least one of the
following three aspects about the vehicle: (1) the physical properties
of the vehicle, such as weight and detailed frame shape specification; (2) the low-level control algorithm parameter setting; and
(3) the maneuver commands from the auto-navigation system or
human operator. The first two determine how the vehicle react to
control signals and environment condition changes, whereas the
third represents mission semantics of the vehicle. Finally, attacks
targeting non-vehicle control logic (e.g., a vehicle’s computer vision
system) are outside the scope of this paper.
4 DESIGN
We continue to use the quadrotor as an example to describe the
CI framework in detail. We point out that CI is generic and can be
applied to a range of RVs, as shown in Section 5.
4.1 Control Invariant Extraction
Given a subject RV, we need to extract its control invariants that
capture how its controller responds to commands and sensor inputs, based on its current state. The control invariants are largely
determined by two aspects: vehicle dynamics and the underlying
control algorithm.
Computing	System	(Controller)
Σ
Physical	System
Control	
Algorithm
Sensors
Noise	
v(t)
+ -
Setpoint
u(t) e(t) c(t) y(t)
Cyber	
Domain
Physical
Domain
Autonomous
Control	
Logics
Commands
(Missions) Actual	
Behavior Actuators
Controller
Disturbance
x(t) w(t)
Figure 6: A typical closed-loop control system
Control Invariant. Figure 6 describes a typical RV control system,
which consists of both cyber and physical components. The cyber
component includes an autonomous control subsystem that takes
commands or mission directives from the user and execute the
controller program to determine the target state u(t) at time t. The
controller implements a control algorithm that compares the target
state with the current state perceived by the sensors and determines
the error e(t). The control algorithm then computes the control
signal c(t) from e(t). The control signal drives the actuators and
produces output y(t), which is affected by the external disturbance
w(t). The resulting state is perceived by the sensors and fed back
to the control loop. The RV’s control invariants are represented by
a state-space model of the system, consisting of the state (1) and
output (2) equations:
x
′ = Ax(t) + Bu(t) (1)
y(t) = Cx(t) + Du(t) (2)
where u(t) (i.e., the target state) is system input and y(t) is system
output. As such, the two equations determine the next state and
output of the system based on the current state and control signal.
The goal of SI is to determine matrices A, B, C and D for the subject
vehicle.
Data Collection. Intuitively, derivation of the matrices is equivalent to determining unknown parameters in a number of mathematical equations. To do so, we need to collect the subject vehicle’s
operation profile data, including the series of state (e.g., velocity),
input (e.g., target attitude), and output (e.g., updated attitude) values.
We develop a test generation tool that can produce random (but
legitimate) missions with environmental effects. Details of the tool
are in Appendix A. Note that the SI method only requires a small
amount of data (i.e., data from a few flight/missions) to accurately
derive the uninstantiated parameters, as shown in our evaluation
(Section 5). The amount of data needed by our framework is much
smaller than learning-based approaches (e.g., [2, 13, 40, 68]). Intuitively, we just need to collect enough data to solve a few equations
with their templates known a priori.
System Identification (SI). The procedure of SI to extract control
invariants works as follows. It takes a model template for the RV.
Intuitively, a template contains some algebraic equations with unknown coefficients, describing the structure of the vehicle (with
unknown metrics) and the nature of its control algorithm (with
unknown parameters). We call the former dynamics template and
the latter control template. It also takes the profile data that contain
the state, input and output values recorded during the vehicle’s
SI missions. We then invoke the MATLAB System Identification
Toolbox [49] to determine the coefficients that best fit the profile
data.
We have two key observations from control engineering practice
and our own experience: (1) All vehicles of similar type/organization share the same dynamics template. For example, all quadrotors
share a dynamics template whereas (ground) rovers share another
template, due to their different physical properties. Intuitively, vehicles with the same architecture operate in a similar fashion. The
dynamics templates for standard vehicle types are readily available in textbooks and literature. (2) The basic PID controller can
approximate complex control algorithms reasonably well for external
attack detection, as shown in our evaluation (Section 5). Ideally, we
would like to precisely model the control algorithm implemented
in each subject vehicle. However, this is impractical as modern
control algorithms are highly customized and complicated. Reverse
engineering their implementations is highly challenging, not to
mention that the source code may be unavailable. Although the PID
controller is not as sophisticated as the control algorithms in real
RVs, it controls the vehicle reasonably well and the errors it induces
are correctable and of a much smaller scale – compared with those
caused by external attacks. For example, a simple PID controller
may lead to over-shoot when making a turn, which would not happen under a more advanced controller. But such (correctable) errors
are much smaller compared to errors inflicted by external attacks.
Conveniently, all PID controllers share the same equation template.
We further note that the basic PID model can sufficiently approximate higher-order dynamics – a common control engineering
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 805
practice. Even for nonlinear control systems, the majority of control effort is from its linear (i.e., PID) portion. Since second-order
response dominates RV dynamics, the lumped vehicle dynamics is
a third-order system with the basic PID control. In summary, the
PID model is sufficient to capture an RV’s closed-loop behaviors.
As such, we can use the dynamics template for the specific vehicle type and the PID control template during SI, avoiding manual,
per-vehicle control model generation.
Detailed Example. In the following, we first briefly explain the
dynamics of the quadrotor and the PID algorithm, which constitute
the model template. We then explain how to instantiate the model.
yB
z
y
x
zB
xB
R
nose
tail
yaw
roll
pitch
1 2
3 4
Figure 7: The inertial and body frames of a quadrotor
(1) Determining Quadrotor Dynamics. A quadrotor operates in two
frames, the body frame and the inertial frame, as shown in Figure 7.
The inertial frame (on the left) is determined by gravity, which
points in the negative z direction. The body frame is defined by the
orientation of the quadrotor, with the rotor axes pointing in the
positive zB direction and the arms pointing in the xB and yB directions. Intuitively, the thrusts of the rotors are computed in the body
frames whereas their effects (e.g., linear and angular accelerations)
can only be determined by projecting to the inertial frame.
The motion of a quadrotor is determined by its linear acceleration
along the x, y, and z dimensions (of the inertial frame), denoted as
xÜ, yÜ, and zÜ, and its angular acceleration along the three dimensions
in the body frame: pitch, yaw, and roll, denoted as vÛy , vÛz , and vÛx ,
respectively. The linear motion can be described by the following
Newton-Euler equation.
m






xÜ
yÜ
zÜ






= Rk






0
0
Σ
4
i=1
ω
2
i






+






0
0
−mд






+






−kdxÛ
−kdyÛ
−kd
zÛ






(3)
Variable m denotes the mass of the quadrotor, wi the speed of
the ith rotor, д the gravity, and R the conversion matrix from the
body frame to the inertial frame. k and kd are constant factors, and
xÛ, yÛ, zÛ are velocities.
The equation shows that the product of the mass and the accelerations (on the left) is equal to the sum of three terms on the
right, denoting the thrust, gravity effect, and the drag force (i.e.,
air resistance), respectively. Observe that the thrust is along the
zB axis of the body frame (with the values along the xB and yB
axises being 0), and proportional to the sum of squares of the rotor
speeds. To reason about its effect in the inertial frame, it has to be
transformed to the inertial frame by the R matrix. In the second
term, the effect of the gravity is along the opposite direction of z
(in the inertial frame) and hence there is a negative sign. The drag
force also has negative signs and is proportional to the speed of
the quadrotor. Intuitively, the larger the speed, the stronger the
resistance. The linear velocities and positions of the vehicle can be
computed from the accelerations and time. The angular motion can
be described as follows:






vÛx
vÛy
vÛz






=






lk(−ω
2
2
+ ω
2
4
)I
−1
x x
lk(−ω
2
1
+ ω
2
3
)I
−1
yy
b(ω
2
1
− ω
2
2
+ ω
2
3
− ω
2
4
)I
−1
zz






(4)
where l is the distance between the rotor and the center of mass,
k is a constant, and b is a constant related to drag force. Ix x/yy/zz
denote the rotational analogue to mass along the xB, yB, zB axes,
respectively. The larger the Ix x values, the more difficult it is to
rotate around the xB axis (and thus the smaller the vÛx value). The
equation essentially specifies that increasing the 4th rotor velocity
and decreasing the 2nd rotor velocity causes rolling; increasing the
3rd and decreasing the 1st causes pitching; and changing all four
rotors causes yawing.
(2) Instantiating PID Controller. A PID controller [56] can be described by the following formula.
u(t) = Kpe(t) + Ki
∫ t
0
e(τ )dτ + Kd
de(t)
dt
(5)
The first term is the proportional term P, which aims to adjust
the control signal (e.g., the rotor currents) proportionally to the
error. The second term is the integral term I, which aims to consider
the history of the error. Intuitively, it compensates for P’s inability
to reduce the error in the previous rounds. The third term is the
derivative term D, which aims to avoid changing the error too
quickly (otherwise, the vehicle may overshoot), analogous to a
brake. Different coefficient values of Kp , Ki
, Kd
result in different
PID controllers.
By combining the aforementioned equations, specifically, computing e(t) from the accelerations and time interval t and feeding
it to the PID equation, we obtain a formula that computes the new
states from the previous states, which is the control model template
described earlier.
(3) Completing System Identification. Next, we apply the System
Identification tool in MATLAB[49] to determine the values of the
unknown coefficients in the invariant template.
1 for i = 1: N
2 data { i } = iddata ( y { i } , u { i } , Ts )
3 end
4 tf = tfest ( data , np , nz )
5 [ num , den ] = tfdata ( tf )
6 [A ,B ,C , D ] = tf2ss ( num , den )
Figure 8: Simplified MATLAB code for system identification.
Figure 8 shows a simplified MATLAB code snippet for the procedure. In the first 3 lines (1-3), the program imports N time-domain
datasets collected in N missions of the vehicle, each containing
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 806
data sampled at a sequence of time instances. The data is combined
into an IDDATA object data in the MATLAB workspace, which
consists of input and output value matrices and a fixed sampling
interval Ts. The input u and output y values collected in mission i
are represented as vectors y{i} and u{i}.
At line 4, the tfest function (provided by the tool) identifies
the optimal coefficients for the model template from the vehicle’s
profile data. Parameters np and nz represent the encoding of the
model template after applying Laplace transformation to the template equations. The transformation turns a time-domain function
into the frequency domain and hence substantially reduces the complexity of fitting the profile data. The details are elided as they are
not centrally related to our problem. Interested readers are referred
to [56]. At line 5, function tfdata accesses the resultant model: num
and den that encode the model (with instantiated coefficients) in
the frequency domain. They are essentially polynomials regarding
the Laplace complex number variable s.
H(s) =
6.395s
2 − 0.1866s + 66.45
s
3 + 6.102s
2 + 10.54s + 63.71
(6)
However, they are not directly usable as we do not want to produce state/output values in the frequency domain. Instead, we aim
to estimate states/outputs in the time domain. At line 6, function
tf2ss converts the model back to the time domain. The resulting A, B, C and D matrices concretize our model (i.e., the control
invariants).
The following shows the example model of roll angle for our
3DR IRIS+ quadrotor with the ArduCopter controller obtained by
SI. The output (roll angle) and the internal state of the system are
denoted as y(t) and x(t), respectively.
x
′ =






0.9884 −0.0493 −0.0242
0.0025 0.9999 0
0 0.0025 1.0






x(t) +






0.0025
0
0






u(t) (7)
y(t) =

1.8651 16.8655 10.0631
x(t) +

0

u(t) (8)
The equations for other outputs and other RVs can be similarly
derived and hence elided.
4.2 Monitoring Parameters Selection
The model constructed in the previous section represents the control invariants that will be monitored at runtime. Our model is an
approximation of the real RV for the following reasons: (1) We use
the same dynamics template for vehicles of the same type. However,
as individual vehicles may have minor structural differences, our
invariant extraction procedure may not be able to capture the small
differences in the corresponding dynamics equations. (2) Our procedure does not model uncertain environmental perturbations, such
as temperature and wind gusts. (3) We use the basic PID controller
to approximate the more advanced controller (e.g., non-linear controller) implemented in the vehicle. All these factors may lead to
errors during monitoring. We call them the transient errors induced
by our approximation. Hence an important challenge is to distinguish transient errors from the errors caused by attacks, which we
call inflicted errors.
With the assumption that attackers cannot keep accurate track
of the vehicle controller’s (internal) execution, our key observation
is that transient errors are much smaller than externally inflicted
errors as the attacker cannot generate malicious signals that closely
follow the invariants for unknown target states (runtime inputs),
without accurate knowledge about the controller program’s execution. This implies that, on one hand we should not treat transient
errors as indication of true attacks (e.g., the model may lead to
overshoot when making a turn due to the simplicity of the PID
controller; whereas the real vehicle will not); on the other hand, we
do not want to miss or delay true attack detection. Our solution is to
accumulate errors (between the model output and the real vehicle
output) for a time window, called the monitor window, and compare
the accumulated errors with a threshold. This section explains how
to systematically determine the window size and the threshold.
Intuitively, our invariant model can be considered a less sophisticated version of the real system. It can (virtually) fulfill a given
mission with a little extra latency. For example, assume the real
vehicle needs x seconds to make a turn. The model may take x +w
seconds to make the same turn. Therefore, our idea of determining
the monitor window is to look for the maximum w in all the primitive operations (e.g., take-offs, turns, and moving-to-waypoint).
Once the window is decided, the error threshold is then computed
from the maximum observed model-induced errors within the window.
time warp
time
(a) not aligned (b) aligned
s1
s2
time
s1
s2
Figure 9: Time alignment of two time sequences. The dashed lines
indicate the alignment
To determine w, we adapt the dynamic time-warping (DTW)
technique [66] that was originally proposed for speech recognition
to recognize words when they are pronounced by different persons
with varying speeds [63]. Given two time series (e.g., sequences of
output sample values over a period of time), time-warping looks for
an order-preserving alignment of the timestamps of the sequences,
so that the sum of the value differences at the aligned timestamps
are minimal. Here, “order-preserving” means that if a timestamp t1
precedest2 in a sequence, its alignment also precedest2’s alignment
in the other sequence. This procedure can be illustrated by Figure 9.
Figure (a) shows two time series before DTW. Observe that the
lower seriess2 is a stretched and skewed version of the upper series
s1. Figure (b) shows that DTW finds an alignment. Observe that
the first peaks in the two series are aligned. We use the maximum
difference between aligned timestamps, called the time warp, as the
window size.
The window size and threshold are both vehicle-specific. However, similar to the SI procedure, the determination of the two
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 807    
parameters is highly automated. To achieve good precision, we use
the data collection missions (Section 4.1) for this procedure. We
note that our data collection missions cover a wide range of normal
vehicle operation sequences and disturbances. With monitoring
parameters set by such missions, unusual RV operations and severe
disturbances would lead to alarms, which is reasonable. For the
IRIS+/ArduCopter sample RV, our technique determines that the
window size is 2.6 seconds and the error threshold is 91 degree for
the roll angle. As shown in Section 5, it takes much shorter than
2.6s to detect attacks.
4.3 Control Program Reverse Engineering and
Instrumentation
Based on the control invariants and monitoring parameters determined, our monitoring function, which will check and detect
violation of the control invariants at runtime, needs to be inserted
into the RV’s control program. Commodity RVs may only provide
binary executables of control programs without source code. Hence
insertion of the monitoring function will have to be via binary
code instrumentation. This raises three challenges: (1) We need to
identify a location in the binary to insert the function so that it can
be periodically executed as part of the control loop. (2) We need to
locate the (program-level) control variables to be accessed by the
control invariant checking function. (3) We need to perform ARM
binary rewriting as most RVs’ microcontrollers are ARM-based.
libc-2.19.so
(below main)
99.97%
(0.00%)
1×
ArduCopter.elf main
99.97%
(0.00%)
1×
99.97%
1×
ArduCopter.elf
HAL_SITL::run(int, char* const*, AP_HAL::HAL::Callbacks*) const
99.97%
(0.01%)
1×
99.97%
1×
ld-2.19.so
0x0000000000001260
100.00%
(0.00%)
0×
ArduCopter.elf
0x000000000040363e
99.97%
(0.00%)
1×
99.97%
1×
99.97%
1×
ArduCopter.elf
AC_AttitudeControl::rate_bf_to_motor_pitch(float)
0.51%
(0.10%)
87657×
ArduCopter.elf
AP_AHRS_NavEKF::get_gyro() const
1.27%
(0.24%)
383334×
0.29%
87657×
ArduCopter.elf
NavEKF::getFilterFaults(unsigned char&) const
3.05%
(1.54%)
1137274×
1.02%
381730×
ArduCopter.elf
AC_AttitudeControl::rate_bf_to_motor_yaw(float)
0.51%
(0.10%)
87657×
0.29%
87657×
ArduCopter.elf
AC_AttitudeControl::rate_controller_run()
1.56%
(0.13%)
87657×
0.51%
87657×
0.29%
87657×
0.51%
87657×
ArduCopter.elf
AP_AHRS::update_trig()
1.70%
(0.55%)
174913×
ArduCopter.elf
AP_AHRS_NavEKF::get_dcm_matrix() const
0.58%
(0.11%)
174913×
0.58%
174913×
libc-2.19.so
isnanf
2.79%
(2.79%)
23392463×
0.12%
1049478×
0.47%
174511×
ArduCopter.elf
AP_AHRS_DCM::drift_correction(float)
0.97%
(0.36%)
87657×
ArduCopter.elf
AP_AHRS_DCM::matrix_update(float)
0.65%
(0.19%)
87657×
ArduCopter.elf Matrix3<float>::rotate(Vector3<float> const&)
0.88%
(0.66%)
359465×
0.21%
87657×
ArduCopter.elf
Vector3<float>::operator+(Vector3<float> const&) const
0.87%
(0.87%)
4382095×
0.21%
1078395×
ArduCopter.elf
AP_AHRS_DCM::update()
4.02%
(0.09%)
87657×
0.85%
87657×
0.97%
87657×
0.65%
87657×
ArduCopter.elf Matrix3<float>::to_euler(float*, float*, float*) const
2.09%
(0.26%)
359466×
0.51%
87657×
libm-2.19.so
atan2f
3.01%
(0.23%)
1460032×
1.44%
718932×
0.54%
4549096×
ArduCopter.elf
Vector3<float>::is_nan() const
1.44%
(0.84%)
1690823×
0.97%
1137274×
ArduCopter.elf
AP_AHRS_NavEKF::get_position(Location&) const
1.68%
(0.11%)
91676×
0.24%
91273×
ArduCopter.elf
NavEKF::getLLH(Location&) const
0.63%
(0.27%)
95699×
0.63%
91273×
ArduCopter.elf
NavEKF::getPosNED(Vector3<float>&) const
1.28%
(0.48%)
176881×
0.63%
87220×
ArduCopter.elf
NavEKF::healthy() const
0.89%
(0.50%)
289473×
0.27%
87222×
ArduCopter.elf
location_diff(Location const&, Location const&)
0.61%
(0.37%)
391234×
0.17%
107351×
0.54%
176881×
ArduCopter.elf
AP_AHRS_NavEKF::get_relative_position_NED(Vector3<float>&) const
0.95%
(0.07%)
89291×
0.24%
88890×
0.64%
88890×
ArduCopter.elf
AP_AHRS_NavEKF::update()
38.07%
(0.09%)
87657×
4.02%
87657×
ArduCopter.elf
AP_AHRS_NavEKF::update_EKF1()
33.88%
(0.36%)
87657×
33.88%
87657×
0.85%
87256×
ArduCopter.elf
NavEKF::UpdateFilter()
31.08%
(0.16%)
87256×
31.08%
87256×
ArduCopter.elf
NavEKF::getEulerAngles(Vector3<float>&) const
0.60%
(0.03%)
88027×
0.60%
87256×
ArduCopter.elf
NavEKF::SelectMagFusion()
24.96%
(0.17%)
87255×
24.96%
87255×
ArduCopter.elf
NavEKF::SelectVelPosFusion()
1.65%
(0.92%)
87255×
1.65%
87255×
ArduCopter.elf
NavEKF::UpdateStrapdownEquationsNED()
2.63%
(0.52%)
87255×
2.63%
87255×
ArduCopter.elf
NavEKF::readIMUData()
1.17%
(0.33%)
87257×
1.17%
87256×
ArduCopter.elf Quaternion::to_euler(float&, float&, float&) const
0.55%
(0.10%)
88034×
0.55%
88027×
ArduCopter.elf
AP_Baro::calibrate()
0.54%
(0.00%)
1×
ArduCopter.elf
HALSITL::SITLScheduler::delay(unsigned short)
1.90%
(0.00%)
350×
0.54%
25×
ArduCopter.elf
HALSITL::SITLScheduler::delay_microseconds(unsigned short)
47.12%
(0.07%)
92024×
1.45%
4367×
ArduCopter.elf
AP_GPS::update()
0.86%
(0.03%)
10957×
ArduCopter.elf
AP_GPS_UBLOX::read()
0.83%
(0.12%)
10951×
0.83%
10951×
ArduCopter.elf
HALSITL::SITLUARTDriver::read()
0.69%
(0.10%)
214126×
0.68%
210900×
ArduCopter.elf
HALSITL::SITLUARTDriver::available()
0.82%
(0.67%)
488501×
0.40%
214126×
ArduCopter.elf
AP_HAL::Scheduler::delay_microseconds_boost(unsigned short)
45.68%
(0.01%)
87657×
45.67%
87657×
ArduCopter.elf
HALSITL::SITL_State::wait_clock(unsigned long)
47.03%
(0.58%)
92023×
47.03%
92023×
ArduCopter.elf
AP_InertialNav_NavEKF::update(float)
3.28%
(0.07%)
87657×
1.61%
87657×
0.93%
87657×
ArduCopter.elf
AP_InertialSensor::_init_gyro()
0.52%
(0.00%)
1×
0.52%
305×
ArduCopter.elf
AP_InertialSensor::calc_vibration_and_clipping(unsigned char, Vector3<float> const&, float)
2.79%
(0.62%)
543618×
ArduCopter.elf
LowPassFilter<Vector3<float> >::apply(Vector3<float>, float)
2.24%
(1.40%)
1174893×
2.07%
1087236×
ArduCopter.elf
Vector3<float>::operator-(Vector3<float> const&) const
0.55%
(0.55%)
2794488×
0.11%
543618×
0.14%
1174893×
0.23%
1174893×
ArduCopter.elf
Vector3<float>::operator*(float) const
1.44%
(1.44%)
8066012×
0.21%
1174893×
ArduCopter.elf
Vector3<float>::operator+=(Vector3<float> const&)
0.94%
(0.94%)
4319709×
0.26%
1174893×
ArduCopter.elf
AP_InertialSensor::init(AP_InertialSensor::Sample_rate)
0.52%
(0.00%)
1×
0.52%
1×
ArduCopter.elf
AP_InertialSensor::wait_for_sample()
45.83%
(0.01%)
87658×
ArduCopter.elf
AP_InertialSensor::wait_for_sample() [clone .part.6]
45.83%
(0.10%)
87963×
45.82%
87658×
45.68%
87657×
ArduCopter.elf
AP_MotorsMatrix::output_armed_stabilizing()
0.94%
(0.40%)
29530×
ArduCopter.elf
AP_MotorsMulticopter::output()
1.33%
(0.12%)
87657×
0.94%
29530×
ArduCopter.elf
AP_Scheduler::run(unsigned short)
5.78%
(1.33%)
87657×
ArduCopter.elf
void Functor<void>::method_wrapper<Copter, &Copter::gcs_check_input>(void*)
0.77%
(0.00%)
87657×
0.77%
87657×
ArduCopter.elf
void Functor<void>::method_wrapper<Copter, &Copter::gcs_data_stream_send>(void*)
1.46%
(0.00%)
10957×
1.46%
10957×
ArduCopter.elf
void Functor<void>::method_wrapper<Copter, &Copter::update_GPS>(void*)
0.87%
(0.01%)
10957×
0.87%
10957×
ArduCopter.elf
Copter::gcs_check_input()
0.77%
(0.10%)
87657×
0.77%
87657×
ArduCopter.elf
Copter::gcs_data_stream_send()
1.46%
(0.07%)
10957×
1.46%
10957×
0.86%
10957×
ArduCopter.elf
AP_Terrain::calculate_grid_info(Location const&, AP_Terrain::grid_info&) const
1.49%
(0.60%)
281743×
0.44%
281743×
ArduCopter.elf
location_offset(Location&, float, float)
0.53%
(0.32%)
381963×
0.44%
281743×
libm-2.19.so
cosf
0.72%
(0.72%)
1529656×
0.20%
391234×
0.17%
321459×
ArduCopter.elf
AP_Terrain::height_amsl(Location const&, float&)
2.42%
(0.56%)
274890×
1.44%
273113×
ArduCopter.elf
Compass::setHIL(unsigned char, float, float, float)
3.09%
(0.62%)
543618×
ArduCopter.elf Matrix3<float>::from_euler(float, float, float)
2.01%
(0.83%)
543628×
2.01%
543619×
libm-2.19.so
sincosf
2.59%
(2.59%)
3077239×
1.18%
1630884×
ArduCopter.elf
Copter::auto_land_run()
0.81%
(0.03%)
56817×
ArduCopter.elf
Copter::auto_run()
1.48%
(0.02%)
77716×
0.81%
56817×
ArduCopter.elf
Copter::auto_wp_run()
0.58%
(0.02%)
18216×
0.58%
18216×
ArduCopter.elf
Copter::delay(unsigned int)
0.81%
(0.00%)
7×
0.81%
7×
ArduCopter.elf GCS_MAVLINK::update(Functor<void, AP_HAL::UARTDriver*>)
1.12%
(0.16%)
263379×
0.67%
262971×
ArduCopter.elf GCS_MAVLINK::send_message(ap_message)
1.37%
(0.02%)
62611×
1.33%
28602×
ArduCopter.elf GCS_MAVLINK::try_send_message(ap_message)
1.35%
(0.02%)
29590×
1.35%
29590×
ArduCopter.elf
Copter::init_ardupilot()
1.45%
(0.00%)
1×
0.52%
1×
0.32%
1×
ArduCopter.elf
Copter::init_barometer(bool)
0.54%
(0.00%)
1×
0.54%
1×
0.54%
1×
ArduCopter.elf
Copter::loop()
98.51%
(0.11%)
87658×
1.56%
87657×
38.07%
87657×
45.83%
87658×
5.78%
87657×
ArduCopter.elf
Copter::motors_output()
1.35%
(0.03%)
87657×
1.35%
87657×
ArduCopter.elf
Copter::read_inertia()
3.28%
(0.01%)
87657×
3.28%
87657×
ArduCopter.elf
Copter::update_flight_mode()
1.60%
(0.02%)
87657×
1.60%
87657×
ArduCopter.elf
Copter::update_land_and_crash_detectors()
0.59%
(0.07%)
87657×
0.59%
87657×
1.33%
87657×
3.28%
87657×
1.48%
77716×
0.17%
87657×
ArduCopter.elf
Copter::setup()
1.45%
(0.00%)
1×
1.45%
1×
ArduCopter.elf
HALSITL::SITL_State::_fdm_input_local()
19.81%
(1.13%)
271809×
19.81%
271809×
ArduCopter.elf
HALSITL::SITL_State::_update_barometer(float)
0.59%
(0.36%)
271809×
0.59%
271808×
ArduCopter.elf
HALSITL::SITL_State::_update_compass(float, float, float)
6.53%
(1.87%)
271809×
6.53%
271808×
ArduCopter.elf
HALSITL::SITL_State::_update_ins(float, float, float, double, double, double, double, double, double, float, float)
17.90%
(2.02%)
271809×
17.90%
271808×
ArduCopter.elf
HALSITL::SITLScheduler::stop_clock(unsigned long)
0.50%
(0.23%)
271809×
ArduCopter.elf
HALSITL::SITL_State::_airspeed_sensor(float)
3.46%
(3.38%)
271809×
0.50%
271808×
ArduCopter.elf
HALSITL::SITL_State::badguy_input()
1.30%
(0.84%)
271808×
1.30%
271808×
ArduCopter.elf
SITL::Aircraft::fill_fdm(SITL::sitl_fdm&, SITL::sitl_fdm_extras&) const
2.72%
(0.52%)
271808×
2.72%
271808×
ArduCopter.elf
SITL::MultiCopter::update(SITL::Aircraft::sitl_input const&)
13.89%
(2.07%)
271808×
13.89%
271808×
1.58%
271808×
0.60%
271808×
0.66%
271808×
0.24%
1359040×
0.30%
1359040×
1.05%
1087232×
ArduCopter.elf Matrix3<float>::normalize()
1.07%
(0.36%)
271808×
1.07%
271808×
ArduCopter.elf Matrix3<float>::operator*(Vector3<float> const&) const
0.69%
(0.69%)
1246860×
0.30%
543616×
ArduCopter.elf
SITL::Aircraft::add_noise(float)
6.07%
(1.28%)
271808×
6.07%
271808×
ArduCopter.elf
SITL::Aircraft::update_position()
1.69%
(0.31%)
271808×
1.69%
271808×
ArduCopter.elf
HALSITL::SITL_State::_ground_sonar()
3.93%
(0.43%)
271809×
ArduCopter.elf
HALSITL::SITL_State::_rand_float()
4.88%
(1.38%)
4096005×
0.65%
543618×
ArduCopter.elf
HALSITL::SITL_State::height_agl()
2.60%
(0.20%)
271809×
2.60%
271809×
0.21%
543618×
libc-2.19.so
random
5.96%
(2.36%)
6986114×
3.49%
4096005×
2.40%
271809×
libc-2.19.so
random_r
3.60%
(3.60%)
6986114×
3.60%
6986114×
ArduCopter.elf
HALSITL::SITL_State::_rand_vec3f()
1.23%
(0.35%)
271809×
0.70%
815427×
ArduCopter.elf
Vector3<float>::length() const
0.64%
(0.64%)
2687359×
0.13%
543618×
3.09%
543618×
1.23%
271809×
0.11%
543618×
2.79%
543618×
3.46%
271809×
3.93%
271809×
4.21%
3533517×
0.22%
1087236×
98.51%
87658×
1.45%
1×
0.11%
543616×
0.19%
815424×
0.24%
1359040×
libm-2.19.so
__atan2f_finite
2.77%
(1.39%)
1460032×
2.77%
1460032×
ArduCopter.elf
NavEKF::ConstrainStates()
1.17%
(0.90%)
87255×
0.27%
2268630×
ArduCopter.elf
NavEKF::ConstrainVariances()
1.04%
(0.79%)
98165×
0.26%
2159630×
ArduCopter.elf
NavEKF::CovariancePrediction()
5.95%
(5.68%)
23997×
0.26%
23997×
ArduCopter.elf
NavEKF::FuseMagnetometer()
18.71%
(17.88%)
71985×
0.77%
71985×
5.41%
21814×
18.71%
71985×
ArduCopter.elf
NavEKF::readMagData()
0.65%
(0.06%)
87259×
0.65%
87255×
0.54%
2183×
0.19%
349020×
1.17%
87255×
0.35%
176068×
0.60%
5072469×
0.14%
1157892×
0.25%
289473×
0.19%
1087232×
0.12%
543616×
libm-2.19.so
log
2.55%
(0.08%)
815424×
2.55%
815424×
libc-2.19.so
rand
1.93%
(0.16%)
2074682×
1.93%
2074682×
libm-2.19.so
__ieee754_log_avx
2.47%
(2.47%)
815424×
2.47%
815424×
1.77%
2074682×
0.57%
271808×
ArduCopter.elf
location_update(Location&, float, float)
0.79%
(0.31%)
271849×
0.79%
271808×
0.14%
269531×
0.31%
271849×
libm-2.19.so
atanf
1.39%
(1.39%)
1462778×
1.39%
1455412×
libc-2.19.so
(below main)
99.97%
(0.00%)
1×
ArduCopter.elf
main
99.97%
(0.00%)
1×
99.97%
1×
ArduCopter.elf
HAL_SITL::run(int, char* const*, AP_HAL::HAL::Callbacks*) const
99.97%
(0.01%)
1×
99.97%
1×
ld-2.19.so
0x0000000000001260
100.00%
(0.00%)
0×
ArduCopter.elf
0x000000000040363e
99.97%
(0.00%)
1×
99.97%
1×
99.97%
1×
ArduCopter.elf
AC_AttitudeControl::rate_bf_to_motor_pitch(float)
0.51%
(0.10%)
87657×
ArduCopter.elf
AP_AHRS_NavEKF::get_gyro() const
1.27%
(0.24%)
383334×
0.29%
87657×
ArduCopter.elf
F::getFilterFaults(unsigned char&) const
3.05%
(1.54%)
1137274×
ArduCopter.elf
AC_AttitudeControl::rate_bf_to_motor_yaw(float)
0.51%
(0.10%)
87657×
0.29%
87657×
ArduCopter.elf
AC_AttitudeControl::rate_controller_run()
1.56%
(0.13%)
87657×
0.51%
87657×
0.29%
87657×
0.51%
87657×
ArduCopter.elf
AP_AHRS::update_trig()
1.70%
(0.55%)
174913×
ArduCopter.elf
AP_AHRS_NavEKF::get_dcm_matrix() const
0.58%
(0.11%)
174913×
0.58%
174913×
libc-2.19.so
isnanf
2.79%
(2.79%)
23392463×
0.12%
1049478×
0.47%
174511×
ArduCopter.elf
AP_AHRS_DCM::drift_correction(float)
0.97%
(0.36%)
87657×
ArduCopter.elf
AP_AHRS_DCM::matrix_update(float)
0.65%
(0.19%)
87657×
ArduCopter.elf
Matrix3<float>::rotate(Vector3<float> const&)
0.88%
(0.66%)
359465×
0.21%
87657×
ArduCopter.elf
Vector3<float>::operator+(Vector3<float> const&) const
0.87%
(0.87%)
4382095×
0.21%
1078395×
ArduCopter.elf
AP_AHRS_DCM::update()
4.02%
(0.09%)
87657×
0.85%
87657×
0.97%
87657×
0.65%
87657×
0.54%
4549096×
ArduCopter.elf
Vector3<float>::is_nan() const
1.44%
(0.84%)
1690823×
0.97%
1137274×
n&) const
ArduCopter.elf
avEKF::getPosNED(Vector3<float>&) const
1.28%
(0.48%)
176881×
0.63%
87220×
ArduCopter.elf
NavEKF::healthy() const
0.89%
(0.50%)
289473×
0.27%
87222×
ArduCopter.elf
location_diff(Location const&, Location const&)
0.61%
(0.37%)
391234×
0.54%
176881×
ArduCopter.elf
AP_AHRS_NavEKF::get_relative_position_NED(Vector3<float>&) const
0.95%
(0.07%)
89291×
0.24%
88890×
0.64%
88890×
ArduCopter.elf
AP_AHRS_NavEKF::update()
38.07%
(0.09%)
87657×
4.02%
87657×
ArduCopter.elf
AP_AHRS_NavEKF::update_EKF1()
33.88%
(0.36%)
87657×
33.88%
87657×
0.85%
87256×
ArduCopter.elf
NavEKF::UpdateFilter()
31.08%
(0.16%)
87256×
31.08%
87256×
ArduCopter.elf
NavEKF::getEulerAngles(Vector3<float>&) const
0.60%
(0.03%)
88027×
0.60%
87256×
ArduCopter.elf
NavEKF::SelectMagFusion()
24.96%
(0.17%)
87255×
24.96%
87255×
ArduCopter.elf
NavEKF::SelectVelPosFusion()
1.65%
(0.92%)
87255×
1.65%
87255×
ArduCopter.elf
NavEKF::UpdateStrapdownEquationsNED()
2.63%
(0.52%)
87255×
2.63%
87255×
ArduCopter.elf
NavEKF::readIMUData()
1.17%
(0.33%)
87257×
1.17%
87256×
0.55%
88027ArduCopter.elf
AP_Baro::calibrate()
0.54%
(0.00%)
1×
ArduCopter.elf
HALSITL::SITLScheduler::delay(unsign1.90%
(0.00%)
350×
0.54%
25×
HALSArduCopter.elf
AP_HAL::Scheduler::delay_microseconds_boost(unsigned short)
45.68%
(0.01%)
87657×
45.67%
87657×
ArduCopter.elf
AP_InertialNav_NavEKF::update(float)
3.28%
(0.07%)
87657×
1.61%
87657×
0.93%
87657×
ArdAP_InertialS03ArduCopter.elf
AP_InertialSensor::calc_vibration_and_clipping(unsigned char, Vector3<float> const&, float)
2.79%
(0.62%)
543618×
ArduCopter.elf
LowPassFilter<Vector3<float> >::apply(Vector3<float>, float)
2.24%
(1.40%)
1174893×
2.07%
1087236×
ArduCopter.elf
Vector3<float>::operator-(Vector3<float> const&) const
0.55%
(0.55%)
2794488×
0.11%
543618×
0.14%
1174893×
0.23%
1174893×
ArduCopter.elf
Vector3<float>::operator*(float) const
1.44%
(1.44%)
8066012×
0.21%
1174893×
Vector3<floaAP_InertialSensor:ArduCopter.elf
AP_InertialSensor::wait_for_sample()
45.83%
(0.01%)
87658×
ArduCopter.elf
AP_InertialSensor::wait_for_sample() [clone .part.6]
45.83%
(0.10%)
87963×
45.82%
87658×
45.68%
87657×
ArduCopter.elf
AP_MotorsMatrix::output_armed_stabilizing()
0.94%
(0.40%)
29530×
ArduCopter.elf
AP_MotorsMulticopter::output()
1.33%
(0.12%)
87657×
0.94%
29530×
ArduCopter.elf
AP_Terrain::calculate_grid_info(Location const&, AP_Terrain::grid_info&) const
1.49%
(0.60%)
281743×
0.44%
281743×
ArduCopter.elf
location_offset(Location&, float, float)
0.53%
(0.32%)
381963×
0.44%
281743×
0.20%
391234×
0.17%
321459×
ArduCopter.elf
AP_Terrain::height_amsl(Location const&, float&)
2.42%
(0.56%)
274890×
1.44%
273113×
ArduCopter.elf
Copter::auto_land_run()
0.81%
(0.03%)
56817×
ArduCopter.elf
Copter::auto_run()
1.48%
(0.02%)
77716×
0.81%
56817×
ArduCopter.elf
Copter::auto_wp_run()
0.58%
(0.02%)
18216×
0.58%
18216×
ArduCopter.elf
Copter::delay(unsigned int)
0.81%
(0.00%)
7×
0.81%
7×
ArduCopter.elf
Copter::init_ardupilot()
1.45%
(0.00%)
1×
0.52%
1×
0.32%
1×
ArduCopter.elf
Copter::init_barometer(bool)
0.54%
(0.00%)
1×
0.54%
1×
0.54%
1×
ArduCopter.elf
Copter::loop()
98.51%
(0.11%)
87658×
1.56%
87657×
38.07%
87657×
45.83%
87658×
5.78%
87657×
ArduCopter.elf
Copter::motors_output()
1.35%
(0.03%)
87657×
1.35%
87657×
ArduCopter.elf
Copter::read_inertia()
3.28%
(0.01%)
87657×
3.28%
87657×
ArduCopter.elf
Copter::update_flight_mode()
1.60%
(0.02%)
87657×
1.60%
87657×
ArduCopter.elf
Copter::update_land_and_crash_detectors()
0.59%
(0.07%)
87657×
0.59%
87657×
1.33%
87657×
3.28%
87657×
1.48%
77716×
0.17%
87657×
ArduCopter.elf
Copter::setup()
1.45%
(0.00%)
1×
1.45%
1×
ArduCopter.elf
HALSITL::SITL_State::_update_compass(float, float, float)
6.53%
(1.87%)
271809×
6.53%
271808×
ArduCopter.elf
HALSITL::SITL_State::_update_ins(float, float, float, double, double, double, double, double, double, float, float)
17.90%
(2.02%)
271809×
ArduCopter.elf
HALSITL::SITL_State::_airspeed_sensor(float)
3.46%
(3.38%)
271809×
SITL::0.66%
271808×
ArduCopter.elf
Matrix3<float>::normalize()
1.07%
(0.36%)
271808×
1.07%
271808×
ArduCopter.elf
Matrix3<float>::operator*(Vector3<float> const&) const
0.69%
(0.69%)
1246860×
0.30%
543616×
ArduCopter.elf
HALSITL::SITL_State::_ground_sonar()
3.93%
(0.43%)
271809×
ArduCopter.elf
HALSITL::SITL_State::_rand_float()
4.88%
(1.38%)
4096005×
0.65%
543618×
ArduCopter.elf
HALSITL::SITL_State::height_agl()
2.60%
(0.20%)
271809×
2.60%
271809×
0.21%
543618×
libc-2.19.so
random
5.96%
(2.36%)
6986114×
3.49%
4096005×
2.40%
271809×
libc-2.19.so
random_r
3.60%
(3.60%)
6986114×
3.60%
6986114×
ArduCopter.elf
HALSITL::SITL_State::_rand_vec3f()
1.23%
(0.35%)
271809×
0.70%
815427×
ArduCopter.elf
Vector3<float>::length() const
0.64%
(0.64%)
2687359×
0.13%
543618×
3.09%
543618×
1.23%
271809×
0.11%
543618×
2.79%
543618×
3.46%
271809×
3.93%
271809×
4.21%
3533517×
0.22%
1087236×
98.51%
87658×
1.45%
1×
0.11%
543616×
0.19%
815424×
0.24%
1359040×
ArduCopter.elf
NavEKF::ConstrainStates()
1.17%
(0.90%)
87255×
0.27%
2268630×
ArduCopter.elf
NavEKF::ConstrainVariances()
1.04%
(0.79%)
98165×
0.26%
2159630×
ArduCopter.elf
NavEKF::CovariancePrediction()
5.95%
(5.68%)
23997×
0.26%
23997×
ArduCopter.elf
NavEKF::FuseMagnetometer()
18.71%
(17.88%)
71985×
0.77%
71985×
5.41%
21814×
18.71%
71985×
ArduCopter.elf
NavEKF::readMagData()
0.65%
(0.06%)
87259×
0.65%
87255×
0.54%
2183×
0.19%
349020×
1.17%
87255×
0.60%
5072469×
0.14%
1157892×
0.25%
289473×
0.19%108723Figure 10: Call graph of ArduCopter with invocation counts
Control Loop Identification. Most RV control programs have a
control loop that is regularly invoked to update system states and
compute new control outputs. The loop dominates the execution
of the program, with access to all critical state variables.
To identify the control loop, we leverage the following observation: A control loop does not manifest itself as a “looping” control
flow structure such as for- or while-loop. Rather, it is a function
regularly triggered by a timer. As such, the function will exhibit
high execution frequency whereas its parent (in the call graph) will
not. We note that, in some control programs, there may be some
functions such as message callbacks which are triggered frequently.
If they are not part of the control loop, their triggering frequency
would be much lower than the control (hence invariant-checking)
frequency and not as periodic. If those functions indeed perform
control tasks with control frequency, our technique will identify
them as part of the control loop body for invariant-checking function insertion. Based on this observation, we leverage the Callgrind
tool [55] to construct the dynamic call graph annotated with function execution frequencies. Then we traverse the call graph in a
top-down fashion to find the first function that has the aforementioned properties. Figure 10 shows an example call graph of ArduCopter (i.e., the control software for IRIS+ quadrotor) annotated
with call counts and costs. Note that the enlarged area includes the
control loop function Copter::loop() (the green box). The parent
function calls the loop function 87658 times while the parent itself
is executed only once.
Identifying Memory Locations for Critical State Variables.
According to the control invariant equations (1) and (2), the current
state x(t) and input u(t) (e.g., the target attitude) are needed to
compute the new state x
′
and the output y(t) (e.g., next attitude).
Therefore, our control invariant check function needs to access the
input value, compute the new state and compare it with the corresponding current state variables in the original control program.
To identify the memory locations of these variables, we collect the
value traces for all variables defined in the control loop and compare them with the value traces of the model variables generated
by the invariant model under the same mission.
Specifically, we use Valgrind to instrument and trace all the memory writes that occur in the control loop function. Given a mission,
a value trace is generated for all variable updates that happen inside
the control loop function. We then partition the trace into multiple
time series of values, each series containing all the updates for a
unique memory location. On the other hand, MATLAB allows us to
execute the control invariant model we have derived. Intuitively, it
simulates the vehicle operations by computing all the state values
according to the model equations. We instrument the MATLAB
program to collect traces for the model variables and then execute
it with the same input as for the real vehicle. For each model variable trace, we identify the program variable trace with the smallest
Euclidean distance, which establishes the mapping between the
model variable and the corresponding program variable (and its
memory location).
0 200 400 600
time (sec)
-20
-10
0
10
20
angle (deg)
(a) A model variable
0 200 400 600
time (sec)
-20
-10
0
10
20
0x800E86E
0x800E886
0x800E8A0
(b) Multiple program variables
Figure 11: State variable value traces at model and program levels
For example, Fig 11(a) shows a model variable value trace for the
roll angle state and (b) three program variables’ value traces. We
can easily observe that the trace for memory location 0x800E86E
(blue line) in (b) matches (a).
ARM Binary Rewriting. We apply trampoline-based binary rewriting [10, 36, 47] to insert the monitoring function and its invocation
to the ARM binary of the control program. Specifically, the monitoring function (source) code is first compiled and made positionindependent. The resulting code snippet is added to the end of
the control program binary. Given a code location inside the main
control loop, we add a jump – usually at the end of the control
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 808
loop – to a small code snippet called a trampoline to invoke the
monitoring function.
0x08004B2A PUSH {R4, LR}
⋯
0x08004B50 ADD R4, R0, R1
0x08004B54 MOV R0, R2
0x08004B56 BL _ZN6Copter12..
0x08004B5A ADD R0, R4, R0
0x08004B5E POP {R4, PC}
...
0x080E1604 LDR R0, [R4, #0x5F00]
0x080E1606 LDR R1, [R4, #0x5510]
0x080E1608 BL loc_800E17A2
0x080E160C POP {R4, PC}
...
Trampoline
Monitoring
Function
Original Control Code
pc
pce
B loc_80E1604 ...
Figure 12: Example of trampoline-based rewriting
Figure 12 shows an example. Suppose a long jump takes n bytes
and we want to add an invocation to the monitoring function at
position pc. We compose a trampoline code snippet that contains
the monitoring function’s invocation, followed by the n bytes of
instructions starting at pc of the original binary and then a jump
to location (pc + n). The trampoline is attached at the end of the
control program binary, say at location pce . Then the original n
bytes at pc are replaced by a longjump to pce . At runtime, when
the execution reaches pc, it jumps to pce to execute the trampoline,
which will first invoke the monitoring function and then execute
the original n bytes of instructions, before jumping back to location
(pc + n).
4.4 Runtime Control Invariant Monitoring
Algorithm 1 Runtime Control Invariant Monitoring
1: x control states of the real vehicle
2: u control input of the real vehicle
3: y control output of the real vehicle
4:
5: procedure InvMonitor(x, u, y)
6: xp ← A · xp + B · u
7: yp ← C · xp + D · u ▷ calculates expected output
8: s_er r ← |y − yp |
2
9: er r _sum ← er r _sum + s_er r
10: er ror ← er r _sum/t
11: t + +
12: if er ror > thr eshold then ▷ runtime attack detected
13: aler t()
14: end if
15: if t > monitor _w indow then ▷ window expires
16: t ← 0
17: er r _sum ← 0
18: xp ← x
19: end if
20: end procedure
Algorithm 1 describes the logic of the runtime control invariant
monitoring code. It takes the current states, the control input and
output of the real vehicle (identified by control program reverse engineering) as arguments. It then computes the predicted new state
xp and the predicted new output yp , using the control invariant
equations (lines 6 and 7). The squared error s_err is computed and
aggregated. Note that squared error is sensitive to outliers (caused
by attacks). At line 12, the algorithm compares the error with the
pre-determined threshold. If the (accumulated) error exceeds the
threshold, function alert() will be invoked. Invocation of alert()
will further lead to attack response, which may be vehicle/missionspecific. For example, in response to an alert, a quadrotor may
Table 1: Subject Vehicles in Evaluation
Type HW Vendor Model Controller Software
Quadrotor 3D Robotics IRIS+ ArduCopter 3.4
Quadrotor 3D Robotics IRIS+ PX4 Pro 1.6
Rover Erle Robotics Erle-Rover APMrover2 3.2
Hexacopter Ardupilot APM SITL ArduCopter 3.6
Quadrotor Parrot Bebop2 (JSBSim) Paparazzi 5.12
Quadrotor Erle Robotics Erle-Copter (Gazebo) ArduCopter 3.4
Quadrotor 3D Robotics 3DR Solo (Gazebo) PX4 Pro 1.6
Quadrotor Parrot ARDrone2 (JSBSim) Paparazzi 5.12
Rover Ardupilot APM SITL APMrover2 2.5
Quadrotor 3D Robotics 3DR Solo Ardupilot-solo 1.3.1
Quadrotor Pixhawk-based Self-built ArduCopter 3.4
switch the flight mode to a fail-safe mode which involves aborting
the mission and landing. Attack response/recovery is beyond the
scope of this paper but we will briefly discuss it in Section 6. At
line 15, the algorithm checks if the monitoring duration has exceeded the pre-determined monitor window size. If so, it resets the
window counter t and accumulated error err_sum to zero; and the
model (invariant) states to the real vehicle’s states. Note that the
monitoring algorithm/code does not use the real vehicle state for its
own state prediction (lines 6 and 7), which means that the control
invariant model basically executes independently of the real vehicle
controller within a window. When the window expires and no alert
is raised, the accumulated error is reset to zero to prevent further
accumulation of transient errors (Section 4.2) and a new monitoring
window starts with the real vehicle states x as the initial states (line
16-18).
5 EVALUATION
5.1 Implementation
The implementation of the CI framework consists of the following:
(1) a Valgrind-based dynamic analysis component for identifying
control loop and important state variables; (2) a mission generator
(for SI) in Python that takes state machine specification and parameter ranges as input, and generates random but realistic missions;
(3) a profiler implemented based on MAVlink to collect measurement data for SI; (4) a control invariant extraction and parameter
selection component implemented on MATLAB; (5) a monitoring
function template implemented in C++ that takes the derived control invariant equation matrices and performs matrix computation;
and (6) an ARM binary rewriter written in Python.
5.2 Subject Vehicles and Attacks
We use 11 different RVs of three types: quadrotors, hexarotors, and
(ground) rovers.
Figure 13: Real RVs in evaluation: 3DR IRIS+, Erle-Rover, 3DR Solo,
Self-built (left to right)
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 809
In particular, we have ten different vehicles among which four
are real vehicles (shown in Figure 13). The others are virtual vehicles
provided by various simulator packages. For example, Gazebo has
a full-fledged simulator of the 3DR Solo quadrotor by 3D Robotics.
Details of the vehicles are shown in columns 1-3 of Table 1. We use
5 different control programs (column 4). For vehicle simulation, we
use Gazebo, JSBSim [39], and APM SITL [5] (column 3). We run the
simulators on Ubuntu 64-bit with Intel(R) Xeon(R) CPU E5620 @
2.40GHz x8 processor and 3.8 GB RAM.
Attacks. Most reported attacks against RVs that exploit physical
channels/components can be classified into (1) sensor spoofing
attacks [21, 35, 46, 58, 69, 72, 75–78], (2) control signal spoofing
attacks [11, 45], and (3) parameter corruption attacks [19]. While it
is difficult to implement all these attacks in real world due to lack of
special attack devices (e.g., the equipment to emit acoustic noises),
we are able to simulate these attacks without losing realism.
To simulate sensor spoofing, we choose to compromise inertial
sensors and GPS sensors. These sensors are necessary for all the
vehicles in our experiments. Specifically, we insert the attack simulation code at the interface between the (real) control program and
sensor modules and manipulate sensor measurements by injecting
malicious signals. To simulate control signal spoofing, we target
the motor pulse width modulation (PWM) signals that are used to
adjust the rotation of motors/rotors. Such signals are generated by
the control program and emitted to the physical vehicle peripherals
through a communication channel (e.g., bus). We insert a piece of
signal-manipulation code into the PWM signal emission module of
the control program. To simulate parameter corruption attacks, we
add a piece of attack code to the control program that modifies the
control parameters (e.g., the PID control coefficients) at runtime.
While we modify the real-world control programs to simulate
the external physical attacks for experimentation convenience, we
do assume that the attackers do not have access to the vehicle’s internals including the control program and they do not have accurate
knowledge about the vehicle’s missions.
5.3 Experiments and Results
Our evaluation focuses on two aspects: efficiency and effectiveness.
To evaluate efficiency, we measure the execution time of key steps
of the CI framework, including the dynamic analysis that identifies
the control loop and state variables, the SI procedure, and monitoring parameter determination. More importantly, we measure the
overhead of control invariant checking at runtime.
To evaluate effectiveness, we conduct a variety of experiments:
(1) We validate that the extracted control invariants can properly
predict normal vehicle behaviors and do not raise false alarms during normal operation. (2) We measure the false negative rate of
attack detection. (3) We show that control invariants are vehiclespecific hence the invariants extracted for vehicle A cannot be used
for vehicle B. (4) We evaluate the effectiveness of our monitoring parameter setting techniques (Section 4.2) by showing that improperly
set parameter values may lead to false positives and false negatives.
(5) We measure error changes under various environmental conditions (i.e. wind) to show that our framework is effective even
in unfavorable environments. We also vary the scale of attacks to
show that our framework remains effective under different scale.
Efficiency. Table 2 summarizes the results of efficiency evaluation.
We let each vehicle execute 20 missions and apply the SI method to
extract its control invariants (Section 4.1). In particular, column RO
shows the runtime overhead of the instrumented control program.
Since the control invariant monitoring function mainly involves
a small number of matrix multiplication and error calculation operations, it incurs very low runtime overhead (below 2.3%). The
profiling overhead (PO) is large but it is offline. The system identification time (ST) is less than 1 minute.
0 5 10 15 20
The number of missions
90
95
100
105
110
115
Error
Figure 14: Convergence of system identification
Figure 14 shows the convergence of the SI procedure for IRIS+
/ArduCopter relative to the number of missions (flights) conducted.
The y-axis shows the average distance between the measured output
and expected output from our model. Observe that the SI-generated
model reaches a fix-point at about 5 missions, indicating that it only
takes a few missions to achieve reasonable accuracy. The results
for other vehicles are similar and hence elided.
Figure 15: Match between real behavior and model prediction
Effectiveness. In the first experiment, we use our mission generator (details in Appendix) to generate a new set of 20 normal
missions (not the ones used in SI) for each vehicle. We then let the
instrumented vehicles execute these missions, during which the
control invariant monitor does not raise any attack alarm. Figure 15
shows how closely the control invariants’ prediction matches the
real (normal) behavior of the IRIS+/ArduCopter vehicle – in a real
flight. In the figure, the red curve denotes the measured roll angle
and the blue curve denotes the predicted values. Only small errors
exist between the two curves (i.e., the orange area at the bottom).
The larger errors at the peaks/dips are due to the approximation
nature of our framework.
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 810
Table 2: Summary of Efficiency/Overhead Results
System CS (KB) PS (KB) PO (%) ST (sec) Target ID WS (s) TH SO (%) RO (%)
IRIS+/ArduCopter 772 1,212 285 29.7 Roll angle 3 x 3 2.6 91.0 0.04 1.87
IRIS+/PX4 Pro 857 719 1,096 28.2 Roll rate 3 x 3 4.4 6.0 0.04 1.01
Erle-Rover/APM:Rover2 1,164 552 115 13.0 Steering rate 3 x 3 4.2 2.5 0.08 0.53
APM SITL/ArduCopter 14,125 1,174 280 33.6 Roll angle 3 x 3 2.0 43 0.08 0.66
Bebop2/Paparazzi 2,337 2,848 603 18.3 Roll rate 3 x 3 1.8 5.6 0.48 1.23
Erle-Copter/ArduCopter 14,640 606 1,400 16.1 Roll angle 3 x 3 2.5 45.6 0.09 0.55
Solo/PX4 Pro 14,599 750 1,480 39.3 Roll rate 3 x 3 3.6 8.2 0.08 2.23
ARDrone2/Paparazzi 2,539 2,449 598 18.1 Roll rate 3 x 3 2.0 6.3 0.45 1.12
APM SITL/Rover 11,128 1,155 124 12.8 Steering rate 3 x 3 1.7 1.54 0.11 0.94
3DR Solo/ArduCopter 660 1,097 1909 21.5 Roll angle 3 x 3 0.5 13.5 0.06 1.31
Custom/ArduCopter 738 1,146 1399 14.8 Roll angle 3 x 3 4.7 20.7 0.06 1.40
* CS: Code Size, PS: Profile Size, PO: Profiling Overhead, ST: SI Time, ID: Invariant Dimension (A matrix), WS: Window Size, TH: Threshold, SO: Code Size
Overhead, RO: Runtime Performance Overhead
In the second experiment, we launch attacks during 20 missions
(of each vehicle) and record the number of attacks that are detected.
Our framework detects all the attacks within an average of 0.2
second after they are launched (i.e., zero false negative rate with
detection timeliness).
0 10 20 30 40 50 60 70
time(s)
-20
-15
-10
-5
0
5
10
15
20
roll angle (deg)
measured
invariant
(a) IRIS+/ArduCopter using IRIS+/PX4 Model
0 5 10 15 20 25
time(s)
-20
-15
-10
-5
0
5
10
15
20
roll angle (deg)
measured
invariant
(b) SITL/HexaCopter using IRIS+/ArduCopter Model
Figure 16: Applying different models on different vehicles
In the third experiment, we use the model extracted from IRIS+
/PX4 to predict behaviors of IRIS+/ArduCopter and use the model
extracted from IRIS+/ArduCopter (a quadrotor) to predict the behaviors of SITL/ArduCopter (a hexarotor). The first pair involves
the same vehicle with two different control programs and the second pair involves two different vehicles using the same control
program. The results are shown in Figures 16a and 16b, respectively. Observe that the errors are non-trivial. This observation
confirms that control invariant models are vehicle (including control algorithm)-specific.
In the fourth experiment, we measure the FP and FN detection
rates under different monitoring parameter (window and threshold)
values. To measure FPs, we run 20 normal missions. To measure
FNs, we launch attacks during 20 missions and observe how many
attacks are missed, under different parameter values. Figures 17a
and 17b show the results. We observe that: (1) under the same
threshold, a larger window generally leads to fewer FPs and more
0 50 100 150 200
Threshold
0
10
20
30
40
50
60
70
80
False Positive (%)
W = 10
W = 20
W = 30
W = 40
W = 50
W = 60
W = 70
W = 80
W = 90
W = 100 Selected Value
(a) False positive rates
0 5,000 10,000 15,000 20,000
Threshold
0
5
10
15
20
25
30
False Negative (%)
W = 10
W = 20
W = 30
W = 40
W = 50
W = 60
W = 70
W = 80
W = 90
W = 100
Selected Value
(b) False negative rates
Figure 17: FP and FN under different parameters
FNs and (2) for the same window size, a larger threshold leads to
fewer FPs and more FNs. (1) is because the accumulated error is
normalized (i.e., divided by the time lapse within the window) before comparison with the threshold such that a larger window leads
to smaller normalized errors. We also observe that FNs only occur
when the threshold is set to a very large value. This experiment
highlights the importance of our monitoring parameter determination technique (Section 4.2), which achieves zero FP and zero
FN.
Figure 18: Error under different wind speed and attack scale
In the fifth experiment, we measure the error (i.e., the result
of control invariant check) under different wind speed and attack
scale. We set up a mission in which a quadrotor makes a sharp turn,
which is highly sensitive to environmental conditions and injected
noises. Figure 18 shows the results. First, in the left sub-figure, the
error significantly increases at 30m/s wind speed, while the other
cases (i.e., below 25m/s) result in small errors. The quadrotor is not
able to take off when the wind speed is higher than 35m/s. Note
that the 25m/s wind speed corresponds to the “storm force” (i.e.,
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 811
Beaufort Scale 10 [73]) and manufacturers would not recommend
flying a drone under such an extreme condition.
We also measure the error under various attack scale on the roll
angle. Specifically, 0% attack means that we set the roll angle to
0, 10% attack means that we set it to a random value in [-10%×
360, 10%×360] and 100% attack means that we set it to [-360,360].
The quadrotor performs the same mission. The right sub-figure in
Figure 18 shows the maximum error during three different attacks
under different scales. Note that the errors are substantially larger
compared with the error threshold (=91) for this vehicle and our
control invariant check detects all the attacks. The errors under
the parameter corruption attacks are relatively smaller because
the vehicle has its own internal protection that caps control gains,
making a larger noise impossible.
5.4 Case Studies
In this section, we present case study with two real RVs under
six attacks. The subject vehicles include the IRIS+ quadrotor and
Erle (ground) rover running ArduCopter and APMrover2 control
programs, respectively. We launch three attacks on the IRIS+ and
three attacks on the Erle-rover.
In the first case, we let the IRIS+ fly a mission in which it first
takes off from the home position to an altitude of 2 meters and then
turns left and right. We launch the sensor spoofing attack during
the flight. The attack is launched at time instance 5.7s (Figure 19a),
when the inertial sensor reading is disrupted and then the roll
measurement is compromised, leading to the quadrotor’s crash.
Our framework detects the attack only 100ms after it is launched.
Figure 19g shows the invariant check error between the measured
and predicted roll values under the attack. A video of the attack
and its detection can be viewed at [23].
In the second case, the IRIS+ performs the same mission as the
first case. During the flight, we launch a control signal spoofing
attack. The IRIS+ is equipped with four MN2213 950kV DC motors,
actuated by motor pulse width modulation (PWM) signals to adjust
the motors’ rotation and hence control the speed and attitude of
the vehicle. We launch the attack at time instance 2.4s (Fig 19b),
when one of the signals is maliciously replaced by a constant value.
The quadrotor loses the roll control and then crashes. Figure 19h
shows the error between the invariant-predicted and measured roll
values. Our framework detects the attack 100ms after it is launched.
A demo video is at [24].
In the third case, we corrupt a control parameter in the same
mission. This leads to a control gain change (by a factor of 6).
We launch the attack at 10.5s (Figure 19c). Upon the attack, the
quadrotor flies in a circle and gradually loses balance. Figure 19i
shows the invariant check error. Our framework detects the attack
1.1s after it is launched. A demo video is at [25]. Note that this
attack does not substantially violate the invariants at once as it
takes some time for the effect of the compromised parameter to
manifest itself physically. Therefore, it takes longer time to detect
the attack. However, the detection time is still short enough for
possible recovery as the impact of this attack is milder than the
earlier ones.
In the fourth case, the Erle-rover performs a mission in which it
departs from the home position, follows a rectangular track, and
then comes back to the home location. We launch the motor input
spoofing attack during the mission. The attack module modifies the
value of a steering servo which is generated by the controller and
controls the steering rate. We launch the attack at 7.7s (Figure 19d).
The rover then fails to follow the track and gets stuck in a circle
pattern. Figure 19j shows the error between the invariant-predicted
and measured steering rates. Our framework detects this attack
100ms after it is launched. A video is at [26].
In the fifth case, the Erle-rover performs the same mission under
GPS spoofing. We launch the attack at 14.1s (Figure 19e). The rover
then deviates from the track and moves to a non-home location at
the end of the mission. Our framework detects the attack 600ms
after it is launched. Figure 19k shows the error and a video is at [27].
In the sixth case, we aim to reproduce an attack similar to that
in [76], in which the attacker can manipulate the sensor signal in a
non-random fashion. The Erle-rover performs a mission where it
follows the straight line. During the mission, an attacker controls
the yaw sensor in a sophisticated fashion and manages to change
the measurements to +30, 0 and -30 deg at the 4th, 17th and 28th
second, respectively (Figure 19f). The rover then deviates from the
original straight line. As shown in Figure 19l, the errors during
the attack are significant. This case demonstrates that, even if the
attacker can manipulate signals in a delicate way, without knowing
the accurate motion plan of the vehicle, the invariant check errors
are still sufficient for detection. A demo video can be found at [28].
6 DISCUSSION
Mimicry Attacks. The CI framework can effectively detect external attacks against RVs that exploit physical channels/vulnerabilities. In theory, we cannot rule out the possibility that an attacker
closely mimics the behaviors of the target vehicle (e.g., by following the model of a similar vehicle). For example, a sophisticated
attack can be launched such that the compromised sensor readings largely respect the vehicle’s dynamics and laws of physics
while generating small errors. We expect that such attacks are difficult to implement, when the attacker cannot directly manipulate
the target states/values and instead has to rely on indirect physical channels (e.g., affecting gyroscope sensors by acoustic noises).
Moreover, as shown in our experiments (Section 5), control invariants are vehicle-specific hence setting a high bar for high accuracy
approximation. More importantly, the behaviors of a vehicle are
determined by three factors: physics, control algorithm and parameters, and mission plan and user commands (runtime inputs).
Even if the attacker manages to grasp the first two, missing the
third factor would still expose the attack as shown in the last attack
case in Section 5.4. Note that we can even equip the vehicle with
a proactive self-validation procedure that is executed regularly to
detect attacks. Specifically, the control software can switch to a
different set of pre-defined control parameters and then make a
few maneuvers. Since these new parameters are unknown to the
attacker, substantial errors between the perceived motions (under
attacker’s control) and predicted motions (from control invariants)
are expected.
More Adaptive Detection. We rely on proper monitoring parameters (monitoring window and accumulated error threshold) to
distinguish attacks from transient errors. However, under highly
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 812
roll angle (deg)
time(s)
measured
Invariant
(a) Attack1
roll angle (deg)
time(s)
measured
Invariant
(b) Attack2
roll angle (deg)
time(s)
measured
Invariant
(c) Attack3
lateral accel (m/s
2
)
time(s)
measured
Invariant
(d) Attack4
lateral accel (m/s
2
)
time(s)
measured
Invariant
(e) Attack5
lateral accel (m/s
2
)
time(s)
measured
Invariant
(f) Attack6
error
time(s)
error
(g) Attack1 error
error
time(s)
error
(h) Attack2 error
error
time(s)
error
(i) Attack3 error
error
time(s)
error
(j) Attack4 error
error
time(s)
error
(k) Attack5 error
error
time(s)
error
(l) Attack6 error
Figure 19: Case study: attacks on IRIS+/ArduCopter and Erle-rover
unfavorable environmental conditions not experienced during training, false positive detection may happen. One possible solution is to
make those parameters adaptive to the environment during a real
mission. The physical properties of a vehicle (i.e., its mass under
different payloads) may also change, so should its model. A possible
solution is to pre-define a number of vehicle configurations and
construct a model for each of them.
Attack Response. After an attack is detected, a proper response
to it is essential. While attack response is outside the scope of this
paper, we note that many response/recovery mechanisms exist,
such as deploying a parachute (for aerial vehicles) and stopping
the vehicle (for ground vehicles). More advanced attack recovery
techniques also exist that maintain the vehicle’s non-stop operation
via controller redundancy [30, 81] or checkpointing [44].
7 RELATED WORK
System Identification. System Identification (SI) [61] is a mature
and widely practiced method in control engineering to infer the
control model of a subject system. The model describes the relation
between the system’s input and output. Besides typical model construction [8, 48], SI is also applied to disturbance handling [50, 80],
worst case analysis [33], and so on. Different from those application
scenarios, we in this paper customize SI for RV attack detection.
Attacks against RVs. Many external attacks against RVs have
been reported. In [11, 45], the authors demonstrate the feasibility
of infiltrating internal vehicle networks. In [38], the authors exploit
a car tire pressure sensing system, which utilizes Radio Frequency
(RF)-based wireless motes. GPS spoofing [35, 75, 78] by sending
interfering signals is a typical active physical sensor attack. Optical
sensor input spoofing [21] involves obtaining an implicit control
channel by tricking optical flow sensors with a physically altered
ground plane. In [72], the authors propose a gyroscopic sensor
attack with intentional acoustic noise to crash drones. Later the
authors of [76] compromise accelerometers by injecting acoustic
noise in a controlled manner, as a more advanced form of the attack. Anti-lock Braking System (ABS) attack [69] involves injecting
magnetic fields to spoof wheel speed sensor. In [34], it is shown
that an attacker with an antenna and a malicious ground station
can compromise a benign UAV by sending malicious packets. In
[59], the authors propose attacks on a camera-based ground vehicle
by relaying and spoofing signals. In [54], the authors analyze the
effects of false data injection attacks on control systems.
Attack Detection. Attack detection for RVs [2, 6, 31, 32, 40, 41,
52, 53, 68, 81, 82, 84] can be based on the following methodologies:
signature, learning, system redundancy and specification. Signaturebased detection [32, 41] monitors the target system and compares it
with pre-determined attack patterns known as attack signatures. It
generally achieves low false positive rate, but it needs to maintain
an up-to-date attack dictionary and cannot handle zero-day attacks
effectively. Redundancy-based techniques [30, 31, 82] duplicate important system components (e.g., controller) and cross-check their
states/outputs at runtime [81] to detect attacks/anomalies. The
redundancy can be in the form of software and/or hardware. However, this approach, by definition, incurs additional cost and system
complexity (e.g., for implementing multiple versions of the same
controller). The learning-based approach [2, 13, 40, 68] monitors
abnormal behaviors using a machine learning-based model. The
normality can be defined by unsupervised and supervised training.
However, in the physical domain, it is hard to obtain large sets
of normal and attack training data. Although unsupervised learning eliminates the need for attack data, it may be susceptible to
a high false positive rate. Our CI framework is not dependent on
learning from a large amount of data. We only need to instantiate control invariant parameters with standard model templates,
based on profiling data from just a few test missions. Behavioral
rule-based techniques [6, 52, 53, 84] use a specification to describe
normal system operations. These techniques model program state
transitions or execution time constraints, whereas our CI framework models control invariants based on a standard controller (e.g.,
PID) and physics, without having to reverse engineer the specific
control algorithm of a vehicle. Moreover, external physical attacks
may not cause any program-level anomaly.
Session 5A: Cyberphysical CCS’18, October 15-19, 2018, Toronto, ON, Canada 813
8 CONCLUSION
We have presented a new comprehensive framework CI for detecting external physical attacks against RVs, based on the definition,
derivation, and monitoring of control invariants for the vehicles.
The control invariants are derived from the physical dynamics and
control model of a subject vehicle. The corresponding invariantchecking logic is implanted in the vehicle’s binary control program.
Our framework does not require control program source code or
per-vehicle control algorithm reverse engineering. Our evaluation
of the CI framework with 11 physical or simulated RVs – all running
real-world control programs – demonstrates high attack detection
accuracy and low runtime overhead