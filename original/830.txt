Homomorphic Encryption (HE) is a cryptosystem which supports
computation on encrypted data. López-Alt et al. (STOC 2012) proposed a generalized notion of HE, called Multi-Key Homomorphic
Encryption (MKHE), which is capable of performing arithmetic
operations on ciphertexts encrypted under different keys.
In this paper, we present multi-key variants of two HE schemes
with packed ciphertexts. We present new relinearization algorithms
which are simpler and faster than previous method by Chen et al.
(TCC 2017). We then generalize the bootstrapping techniques for
HE to obtain multi-key fully homomorphic encryption schemes. We
provide a proof-of-concept implementation of both MKHE schemes
using Microsoft SEAL. For example, when the dimension of base
ring is 8192, homomorphic multiplication between multi-key BFV
(resp. CKKS) ciphertexts associated with four parties followed by a
relinearization takes about 116 (resp. 67) milliseconds.
Our MKHE schemes have a wide range of applications in secure
computation between multiple data providers. As a benchmark,
we homomorphically classify an image using a pre-trained neural
network model, where input data and model are encrypted under
different keys. Our implementation takes about 1.8 seconds to evaluate one convolutional layer followed by two fully connected layers
on an encrypted image from the MNIST dataset.
CCS CONCEPTS
• Security and privacy → Cryptography.
KEYWORDS
multi-key homomorphic encryption; packed ciphertext; ring learning with errors; neural networks

1 INTRODUCTION
As large amount of data are being generated and used for driving
novel scientific discoveries, the effective and responsible utilization
of large data remains to be a big challenge. This issue might be
alleviated by outsourcing to public cloud service providers with
intensive computing resources. However, there still remains a problem in privacy and security of outsourcing data and analysis. In the
past few years, significant progresses have been made on cryptographic techniques for secure computation. Among the techniques
for secure computation, Multi-Party Computation (MPC) and Homomorphic Encryption (HE) have received increasing attention
due to technical breakthroughs.
The history of MPC dates back three decades ago [5, 50], and
since then it has been intensively studied in the theory community.
In this approach, two or more parties participate in an interactive
protocol to compute a function on their private inputs, where only
the output of the function is revealed to the parties. Recent years
witnessed a large body of works on improving the practical efficiency of MPC, and state-of-the-art protocols have achieved orders
of magnitude improvements on performance (see e.g. [20, 36, 49]).
However, these protocols are still inherently inefficient in terms
of communication complexity: the number of bits that the parties
need to exchange during the protocol is proportional to the product
between the complexity of the function and the number of parties.
Therefore, the high communication complexity remains the main
bottleneck of MPC protocols.
Moreover, the aforementioned MPC protocols may not be desirable for cloud-based applications, as all the parties involved need
to perform local computation proportional to the complexity of the
function. However, in practical use-cases, we cannot expect the data
providers to either perform large amount of work or stay online
during the entire protocol execution. Another model was proposed
where the data owners secret-share their data with a small number
of independent servers, who perform an MPC to generate the computation result [23, 44]. These protocols have good performance
and they moved the burden from the data providers to the servers,
but their privacy guarantees rely on the assumption that the servers
do not collude.
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 395
HE refers to a cryptosystem that allows computing on encrypted
data without decrypting them, thus enabling securely outsourcing
computation in an untrusted cloud. There have been significant
technical advances on HE after Gentry’s first construction [24].
For example, one can encrypt multiple plaintext values into a single packed ciphertext, and use the single instruction multiple data
(SIMD) techniques to perform operations on these values in parallel [26, 48]. Hence, HE schemes with packing techniques [6, 7, 16, 22]
have good amortized complexity per plaintext value, and they have
been applied to privacy-preserving big data analysis [11, 37, 39].
However, traditional HE schemes only allow computation on ciphertexts decryptable under the same secret key. Therefore, HE does
not naturally support secure computation applications involving
multiple data providers, each providing its own secret key.
López-Alt et al. [43] proposed a Multi-Key Homomorphic Encryption (MKHE) scheme, which is a cryptographic primitive supporting arithmetic operations on ciphertexts which are not necessarily
decryptable to the same secret key. In addition to solving the aforementioned issues of HE, MKHE can be also used to design roundefficient MPC protocols with minimal communication cost [45].
In addition, an MPC protocol from MKHE satisfies the on-the-fly
MPC [43] property, where the circuit to be evaluated can be dynamically decided after the data providers upload their encrypted
data.
Despite its versatility, MKHE has been seldom used in practice.
Early studies [19, 45, 46] used a multi-key variant of the GSW
scheme [28]. These constructions have large ciphertexts and their
performance does not scale well with the number of parties. Previous works [8, 10] proposed MKHE schemes with short ciphertexts,
with the caveat that one ciphertext encrypts only a single bit. The
only existing MKHE scheme with packed ciphertexts [13, 41] is a
multi-key variant of the BGV scheme [7]. Note that all the above
studies were purely abstract with no implementation given, and it
remains an open problem whether an MKHE scheme with support
for SIMD operations can be practical.
1.1 Our Contributions
We design multi-key variants of the BFV [6, 22] and CKKS [16]
schemes. We propose a new method for generating a relinearization
key which is simpler and faster compared to previous technique
in [13]. Furthermore, we adapt the state-of-the-art bootstrapping
algorithms for these schemes [9, 12, 14] to the multi-key scenario
to build Multi-Key Fully Homomorphic Encryptions with packed
ciphertexts. Finally, we give a proof-of-concept implementation
of our multi-key schemes using Microsoft SEAL [47] and present
experimental results. To the best of our knowledge, this is the first
practical implementation of MKHE schemes that support packed
ciphertexts.
We also present the first viable application of MKHE that securely
evaluates a pre-trained convolutional neural network (CNN) model.
We build an efficient protocol where a cloud server provides on-line
prediction service to a data owner using a classifier from a model
provider, while protecting the privacy of both data and model using
MKHE. Our scheme with support for the multi-key operations
makes it possible to achieve this at a low end-to-end latency, and
near-optimal cost for the data and model providers, as shown in
Fig. 1. The server can store numerous ciphertexts encrypted under
different keys, but the computational cost of a certain task depends
only on the number of parties related to the circuit. We note that
our solution has the advantage over single-key HE since the ML
model providers do not need to send the unencrypted model to the
server.
1.2 Overview of Our Construction
Let R = Z[X]/(X
n + 1) be the cyclotomic ring with a power-oftwo dimension n, and si ∈ R be the secret of the i-th party. The
starting point of the construction of a ring-based MKHE scheme is
the requirement that the resulting scheme should be able to handle
homomorphic computations on ciphertexts under independently
generated secret keys. A ciphertext of our MKHE scheme associated
to k different parties is of the form ct = (c0,c1, . . . ,ck
) ∈ R
k+1
q
for a modulus q, which is decryptable by the concatenated secret
sk = (1,s1, . . . ,sk
). In other words, its phase µ = ⟨ct,sk⟩ (mod q)
is a randomized encoding of a plaintext message m corresponding
to the base scheme.
Homomorphic multiplication of BFV or CKKS consists of two
steps: tensor product and relinearization. The tensor product of two
input ciphertexts satisfies ⟨ct1⊗ct2,sk⊗sk⟩ = ⟨ct1,sk⟩· ⟨ct2,sk⟩, so
it is a valid encryption under the tensor squared secretsk⊗sk. In the
relinearization step, we aim to transform the extended ciphertext
ct = ct1 ⊗ ct2 ∈ R
(k+1)
2
q
into a canonical ciphertext encrypting
the same message under sk. This step can be understood as a keyswitching process which requires a special encryption of sk ⊗ sk.
We note that sk ⊗ sk contains entries sisj which depend on secrets
of two distinct parties. Hence a relinearization key corresponding
to non-linear entries cannot be generated by a single party, different
from the traditional HE schemes.
We propose an RLWE-based cryptosystem to achieve this functionality. It looks similar to the ring variant of GSW [21, 28] but
our scheme supports some operations between ciphertexts under
different keys. Let g ∈ Z
d be an integral vector, called the gadget
vector. This scheme assumes the Common Reference String (CRS)
model so all parties share a random polynomial vector a ∈ R
d
q
. Each
party i generates a special encryption of secret si by itself, which is
a matrix Di = [di,0 |di,1 |di,2] ∈ R
d×3
q
satisfying di,0+si
·di,1 ≈ ri
·g
(mod q) and di,2 ≈ ri
· a + si
· g (mod q) where ri
is a small polynomial sampled from the key distribution. It is published as the
evaluation key of the i-th party.
We present two relinearization methods with different advantages. For each pair 1 ≤ i, j ≤ k, the first method combines the i-th
evaluation key Di with the j-th public key bj ≈ −sj
· a (mod q) to
generate Ki,j ∈ R
d×3
q
such that Ki,j
· (1,si
,sj) ≈ sisj
· g (mod q).
That is, Ki,j can be used to relinearize one entry ci,j of an extended
ciphertext into a triple (c
′
0
,c
′
i
,c
′
j
) such thatc
′
0
+c
′
i
s
′
i
+c
′
j
sj ≈ ci,jsisj
(mod q). This method can be viewed as a variant of the previous
GSW ciphertext extension proposed in [45]. In particular, each
row of Ki,j consists of three polynomials in Rq (compared to O(k)
dimension of previous works [13, 41]), so that the bit size of a
shared relinearization key {Ki,j }1≤i,j ≤k
is O(dk2
· n logq) and the
complexity of key generation is O(d
2k
2
) polynomial operations
modulo q (see Section 3 for details). The relinearization algorithm
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 396
Figure 1: High-level Overview of the oblivious neural network inference.
repeats O(k
2
) key-switching operations from sisj to (1,si
,sj), so
its complexity is O(dk2
) operations in Rq. We note that Ki,j can
be pre-computed before multi-key operations, and a generated key
can be reused for any computation related to the parties i and j.
Our second approach directly linearizes each of the entries of
an extended ciphertext by multiplying the j-th public key bj and
i-th evaluation key Di
in a recursive way. The first solution should
generate and store a shared relinearization key {Ki,j }1≤i ≤k
, so its
space and time complexity grow quadratically on k. However, the
second algorithm allows us to keep only the individual evaluation
keys which is linear on k. Furthermore, it significantly reduces
the variance of additional noise from relinearization, so that we
can use a smaller parameter while keeping the same functionality.
Finally, we adapt the modulus raising technique [27, 38] to the
second approach to reduce the noise growth even more.
As an orthogonal issue, the bootstrapping of packed MKHE
schemes has not been studied in the literature. We generalize the
existing bootstrapping methods for HE schemes [9, 12, 14, 25, 32]
to the multi-key setting. The main issue of generalization is that the
pipeline of bootstrapping includes some advanced functionalities
such as slot permutation. We resolve this issue and provide all necessary operations by applying the multi-key-switching technique
in [10] to Galois automorphism.
Finally, we apply the state-of-art optimization techniques for
implementing HE schemes [4, 15, 30] to our MKHE schemes for
performance improvement. For example, we implement full Residue
Number System (RNS) variants of MKHE schemes and use an
RNS-friendly decomposition method [4, 15, 30] for relinearization,
thereby avoiding expensive high-precision arithmetic.
1.3 Related Works
López-Alt et al. [43] firstly proposed an MKHE scheme based on
NTRU. After that, Clear and McGoldrick [19] suggested a multikey variant of GSW together with ciphertext extension technique
to design an MKHE scheme and it was simplified by Mukherjee
and Wichs [45]. Peikert and Shiehian [46] developed two multihop MKHE schemes based on the same multi-key GSW scheme.
However, these schemes could encrypt only a single bit in a huge
extended GSW ciphertext.
Brakerski and Perlman [8] suggested an MKHE scheme with
short (LWE-based) ciphertexts, however, its asymptotic/concrete efficiency has not been presented clearly. Chen, Chillotti and Song [10]
Scheme Space Time
Type Complexity Type Complexity
LZY+19 [41] EvalKey O˜(k
3n) EvalKey Gen O˜(k
3n)
Ciphertext O˜(kn) Mult O˜(k
3n)
CCS19 [10] EvalKey O˜(k
2n
2
) EvalKey Gen O˜(k
2n
2
)
Ciphertext O˜(kn) NAND O˜(k
2n
2
)
This work EvalKey O˜(kn) EvalKey Gen −
Ciphertext O˜(kn) Mult O˜(k
2n)
Table 1: Memory (bit-size) and computational costs (number of scalar operations) of MKHE schemes. k denotes the
number of parties and n is the dimension of the (R)LWE
assumption. EvalKey denotes the evaluation (or bootstrapping) keys.
proposed an improved scheme by applying the framework of TFHE
[17] with the first implementation of MKHE primitive. However,
this scheme does not support the packing technique, thereby resulting in a large expansion rate similar to TFHE.
The most relevant studies are by Chen et al. [13] and Li et al. [41].
They designed multi-key variants of BGV [7] by generating a relinearization key based on the multi-key GSW scheme. However,
it consists of O(k
2
) key-switching keys from sisj to the ordinary
key each of which has O(k) components. In addition, they did not
provide any implementation result or analysis about concrete performance. Our work is an extension of these researches in the sense
that our relinearization method and other optimization techniques
can be applied to BGV as well. We also stress that the performance
of previous batch MKHE schemes can be improved by observing the
sparsity of evaluation keys, but this point was not pointed out in the
manuscripts. In Table 1, we provide the performance of the recent
MKHE schemes; in the context of our work, the second method is
taken into account for comparison.
2 BACKGROUND
2.1 Notation
All logarithms are in base two unless otherwise indicated. We denote vectors in bold, e.g. a, and matrices in upper-case bold, e.g. A.
We denote by ⟨u, v⟩ the usual dot product of two vectors u, v. For
a real number r, ⌊r⌉ denotes the nearest integer to r, rounding
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 397
upwards in case of a tie. We use x ← D to denote the sampling
x according to distribution D. For a finite set S, U (S) denotes the
uniform distribution on S. We let λ denote the security parameter
throughout the paper: all known valid attacks against the cryptographic scheme under scope should take Ω(2
λ
) bit operations.
2.2 Multi-Key Homomorphic Encryption
A multi-key homomorphic encryption is a cryptosystem which
allows us to evaluate an arithmetic circuit on ciphertexts, possibly
encrypted under different keys.
Let M be the message space with arithmetic structure. An MKHE
scheme MKHE consists of five PPT algorithms (Setup, KeyGen, Enc,
Dec, Eval). We assume that each participating party has a reference (index) to its public and secret keys. A multi-key ciphertext
implicitly contains an ordered set T = {id1, . . . ,idk
} of associated
references. For example, a fresh ciphertext ct ← MKHE.Enc(µ; pkid )
corresponds to a single-element set T = {id} but the size of reference set gets larger as the computation between ciphertexts from
different parties progresses.
• Setup: pp ← MKHE.Setup(1
λ
). Takes the security parameter as
an input and returns the public parameterization. We assume that
all the other algorithms implicitly take pp as an input .
• Key Generation: (sk, pk) ← MKHE.KeyGen(pp). Outputs a pair
of secret and public keys.
• Encryption: ct ← MKHE.Enc(µ; pk). Encrypts a plaintext µ ∈ M
and outputs a ciphertext ct ∈ {0, 1}
∗
.
• Decryption: µ ← MKHE.Dec(ct; {skid }id ∈T ). Given a ciphertext
ct with the corresponding sequence of secret keys, outputs a plaintext µ.
• Homomorphic evaluation:
ct ← MKHE.Eval(C, (ct1, . . . , ctℓ
), {pkid }id ∈T ).
Given a circuit C, a tuple of multi-key ciphertexts (ct1, . . . , ctℓ
)
and the corresponding set of public keys {pkid }id ∈T , outputs a
ciphertext ct. Its reference set is the union T = T1 ∪ · · · ∪ Tℓ of
reference sets Tj of the input ciphertexts ctj for 1 ≤ j ≤ ℓ.
Semantic Security. For any two messages µ0, µ1 ∈ M, the distributions {MKHE.Enc(µi
; pk)} for i = 0, 1 should be computationally
indistinguishable where pp ← MKHE.Setup(1
λ
) and (sk, pk) ←
MKHE.KeyGen(pp).
Correctness and Compactness. An MKHE scheme is compact if
the size of a ciphertext relevant to k parties is bounded by poly(λ, k)
for a fixed polynomial poly(·, ·).
For 1 ≤ j ≤ ℓ, let ctj be a ciphertext (with reference set Tj
)
such that MKHE.Dec(ctj
, {skid }id ∈Tj
) = µj
. Let C : Mℓ → M
be a circuit and ct ← MKHE.Eval(C, (ct1, . . . , ctℓ
), {pkid }id ∈T ) for
T = T1 ∪ · · · ∪Tℓ
. Then,
MKHE.Dec(ct, {skid }id ∈T ) = C(µ1, . . . , µℓ
) (1)
with an overwhelming probability. The equality of (1) can be substituted by approximate equality similar to the CKKS scheme for
approximate arithmetic [16].
2.3 Ring Learning with Errors
Throughout the paper, we assume that n is a power-of-two integer
and R = Z[X]/(X
n +1). We write Rq = R/(q ·R) for the residue ring
of R modulo an integer q. The Ring Learning with Errors (RLWE)
assumption with parameter (n,q, χ,ψ) is that given any polynomial
number of samples of the form (ai
,bi = s · ai + ei) ∈ R
2
q
, where ai
is uniformly random in Rq, s is chosen from the key distribution χ
over Rq, and ei
is drawn from the error distribution ψ over R, the
bi
’s are computationally indistinguishable from uniformly random
elements of Rq.
2.4 Gadget Decomposition
Let g = (дi) ∈ Z
d be a gadget vector and q an integer. The gadget
decomposition, denoted by g
−1
, is a function from Rq to R
d which
transforms an element a ∈ Rq into a vector u = (u0, . . . ,ud−1
) ∈ R
d
of small polynomials such that a =
Íd−1
i=0
дi
· ui (mod q).
The gadget decomposition technique is widely used in the construction of HE schemes. For example, homomorphic evaluation of a
nonlinear circuit is based on the key-switching technique and most
of HE schemes exploit various gadget decomposition method to control the noise growth. There have been suggested in the literature
various decomposition methods such as bit decomposition [6, 7],
base decomposition [17, 21] and RNS-based decomposition [4, 30].
Our implementation exploits an RNS-friendly decomposition for
the efficiency.
3 RELINEARIZING MULTI-KEY
CIPHERTEXTS
This section provides a high-level description of our MKHE schemes
and explain how to perform the relinearization procedures which
are core operations in homomorphic arithmetic.
3.1 Overview of HEs with Packed Ciphertexts
In recent years, there have been remarkable advances in the performance of HE schemes. For example, the ciphertext packing technique allows us to encrypt multiple data in a single ciphertext and
perform parallel homomorphic operations in a SIMD manner. Currently the batch HE schemes such as BGV [7], BFV [6, 22] and
CKKS [16] are the best-performing schemes in terms of amortized
size and timing per plaintext slot. They adapt some DFT-like algorithms to transform a vector of plaintext values into an element of
a cyclotomic ring.
Let sk = (1,s) for the secret s ∈ R. A canonical RLWE-based ciphertext is of the form ct = (c0,c1) ∈ R
2
q
such that the inner product
µ = ⟨ct,sk⟩ (mod q), called the phase, is a randomized encoding
of a plaintext m. For example, the phase of a BFV ciphertext has
the form of µ = (q/t) · m + e for the plaintext modulus t while the
phase µ = m + e of CKKS is an approximate value of the plaintext.
For homomorphic computation, we basically perform arithmetic
operations between the phases of given ciphertexts. In particular,
homomorphic multiplication of RLWE ciphertexts consists of two
steps: tensor product and relinearization. For input ciphertexts
ct1 and ct2, we first compute their tensor product and return the
extended ciphertext ct = ct1 ⊗ ct2 that satisfies ⟨ct,sk ⊗ sk⟩ =
⟨ct1,sk⟩ · ⟨ct2,sk⟩. Since sk ⊗ sk contains the nonlinear entry s
2
, it
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 398
requires to perform the relinearization procedure which transforms
the extended ciphertext to a canonical ciphertext encrypting the
same message. Roughly speaking, we publish a relinerization key
which is some kind of ciphertext encrypting s
2 under sk and run
the key-switching algorithm for this conversion.
In the multi-key case, a ciphertext related to k different parties is
of the form ct = (c0,c1, . . . ,ck
) ∈ R
k+1
q which is decryptable by the
concatenated secret sk = (1,s1, . . . ,sk
), i.e., its phase is computed
by µ = ⟨ct,sk⟩ = c0 +
Ík
i=1
ci
· si
. If we follow the same pipeline
for homomorphic operation as in the single-key setting, the tensor
product step returns an extended ciphertext corresponding sk ⊗ sk.
Hence, we need to generate a relinearization key which consists
of multiple ciphertexts encrypting the entries si
· sj of sk ⊗ sk.
Different from the classical HE schemes, it requires some additional
computations since the termsi
·sj depends on two secret keys which
are independently generated by different parties. In the following,
we will explain how to efficiently generate a relinearization key for
multi-key homomorphic multiplication.
3.2 Basic Scheme
In this section, we present a ring-based scheme which will be used
to generate some public material for relinearization.
• Setup(1
λ
): For a given security parameter λ, set the RLWE dimension n, ciphertext modulus q, key distribution χ and error distribution ψ over R. Generate a random vector a ← U (R
d
q
). Return
the public parameter pp = (n,q, χ,ψ, a).
• KeyGen(pp): Sample the secret key s ← χ. Sample an error vector
e ← ψ
d
and set the public key as b = −s · a + e (mod q) in R
d
q
.
• UniEnc(µ;s): For an input plaintext µ ∈ R, generate a ciphertext
D = [d0 |d1 |d2] ∈ R
d×3
q
as follows:
(1) Sample r ← χ.
(2) Sample d1 ← U (R
d
q
) and e1 ← ψ
d
, and set d0 = −s · d1 +
e1 + r · g (mod q).
(3) Sample e2 ← ψ
d
and set d2 = r · a + e2 + µ · g (mod q).
The public parameter pp contains a randomly generated vector
a ∈ R
d
q
, so we are assuming the common reference string model.
All parties should take the same public parameter as an input of
the key-generation algorithm to support multi-key homomorphic
arithmetic. We note that the same assumption was made in all the
previous work on MKHE.
The uni-encryption algorithm is a symmetric encryption which
can encrypt a single ring element. An uni-encrypted ciphertext
D = [d0 |d1 |d2] ← UniEnc(µ;s) consists of three vectors in R
d
q
so is
(3/4) times as large as an ordinary RGSW ciphertext in R
2d×2
q
. For
an uni-encrypted ciphertext D, the first two columns [d0 |d1] can
be viewed as an encryption of r under the secret s while [d2 | − a]
forms an encryption of µ under secret r.
Security. The uni-encryption scheme is IND-CPA secure under the
RLWE assumption of parameter (n,q, χ,ψ). We prove it by showing
that the distribution
{(a, b, D) : pp = (n, χ,ψ, a) ← Setup(1
λ
),
(s, b) ← KeyGen(pp), D ← UniEnc(µ;s)}
is computationally indistinguishable from the uniform distribution
over R
d
q × R
d
q × R
d×3
q
for an arbitrary µ ∈ R. We refer the reader to
Appendix B for the proof of this result.
3.3 Relinearization
We revisit the relinearization procedure on extended ciphertexts
and present two solutions with different advantages. We recall that
the tensor product ct = ct1 ⊗ ct2 of two multi-key ciphertexts cti ∈
R
k+1
q
encrypted under the concatenated secret sk = (1,s1, . . . ,sk
)
can be viewed as a ciphertext corresponding to the tensor squared
secret sk ⊗ sk. Note that sk ⊗ sk contains some nonlinear entries
si
· sj related to two different parties. Therefore, the computing
server should be able to transform the extended ciphertext ct ∈
R
(k+1)×(k+1)
q
into a canonical ciphertext by linearization of the nonlinear entries si
· sj
.
Our relinearization methods require the same public material
(evaluation key) that is generated by individual parties as follows:
• EvkGen(s): Given the secret s ∈ R, return D ← UniEnc(s;s).
To be precise, each party i generates its own secret, public, and
evaluation keys by running the algorithms (si
, bi) ← KeyGen(pp)
and Di ← EvkGen(si), then publishes the pair (bi
, Di). For the
rest of this section, we present two relinearization algorithms and
explain their pros and cons.
We make an additional circular security assumption since the
evaluation key is an uni-encryption of secret s encrypted by itself.
However, we stress that our assumption is no stronger than the
same assumption in HE schemes [16, 17, 22, 27] requiring either
bootstrapping or relinearization of ciphertexts.
3.3.1 First Method. This solution includes a pre-processing step
which generates a shared relinearization key corresponding to the
set of involved parties. A shared relinearization key consists of
encryptions of si
· sj for all pairs 1 ≤ i, j ≤ k. Then, we can linearize an extended ciphertext by applying a standard key-switching
technique.
This approach is similar to a method proposed in previous work [13,
41] which also generates a shared evaluation key. However, each
element of our shared relinearization key is computed from the
public information of at most two parties so consists of three vectors, while previous method based on the multi-key GSW scheme
has O(k) dimensional entries.
• Convert(Di
, bj): It takes as the input a pair of an uni-encryption
Di = [di,0 |di,1 |di,2] ∈ R
d×3
q
and a public key bj ∈ R
d
q generated by (possibly different) parties i and j. Let ki,j,0 and ki,j,1
be the vectors in R
d
q
such that ki,j,0[ℓ] = ⟨g
−1
(bj[ℓ]), di,0⟩ and
ki,j,1[ℓ] = ⟨g
−1
(bj[ℓ]), di,1⟩ for 1 ≤ ℓ ≤ d, i.e., [ki,j,0 |ki,j,1] =
Mj
· [di,0 |di,1] where Mj ∈ R
d×d
is the matrix whose ℓ-th row
is g
−1
(bj[ℓ]) ∈ R
d
. Let ki,j,2 = di,2 and return the ciphertext
Ki,j = [ki,j,0 |ki,j,1 |ki,j,2] ∈ R
d×3
q
.








ki,j,0 ki,j,1








=









g
−1
(bj[1])
.
.
.
g
−1
(bj[d])









·








di,0 di,1








,








ki,j,2








=








di,2








.
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 399
Algorithm 1 Relinearization method 1
Input: ct = (ci,j)0≤i,j ≤k
, rlk = {Ki,j }1≤i,j ≤k
.
Output: ct′
= (c
′
i
)0≤i ≤k ∈ R
k+1
q
.
1: c
′
0 ← c0,0
2: for 1 ≤ i ≤ k do
3: c
′
i ← c0,i + ci,0 (mod q)
4: end for
5: for 1 ≤ i, j ≤ k do
6: (c
′
0
,c
′
i
,c
′
j
) ← (c
′
0
,c
′
i
,c
′
j
) + g
−1
(ci,j) · Ki,j (mod q)
7: end for
• Relin(ct; {(Di
, bi)}1≤i ≤k
): Given an extended ciphertext ct =
(ci,j)0≤i,j ≤k and k pairs of evaluation/public keys {(Di
, bi)}1≤i ≤k
,
generate a ciphertext ct′
∈ R
k+1
q
as follows:
(1) Compute Ki,j ← Convert(Di
, bj) for all 1 ≤ i, j ≤ k and set
the relinearization key as rlk = {Ki,j }1≤i,j ≤k
.
(2) Run Alg. 1 to relinearize ct.
We note that the first step (generation ofrlk) can be pre-computed
on public information {(Di
, bi)}1≤i ≤k without taking a ciphertext
as the input.
Correctness. We first claim that, if Di
is an uni-encryption of
µi ∈ R encrypted by the i-th party and bj
is the public key of the
j-th party, then the output Ki,j ← Convert(Di
, bj) of the conversion algorithm is an encryption of µisj with respect to the secret
(1,si
,sj), i.e., ki,j,0 + si
· ki,j,1 + sj
· ki,j,2 ≈ µisj
· g (mod q). It is
derived from the following formulas:
ki,j,0 + si
· ki,j,1 = Mj
· (d0 + si
· d1) ≈ Mj
· ri g = ri bj (mod q),
sj
· ki,j,2 = sj
· d2 ≈ risj
· a + µsj
· g ≈ −r · bj + µisj
· g (mod q).
Note that Mj
, sj and ri should be small to hold the approximate
equalities. We estimate the size of noise in Appendix C.
We now show the correctness of our algorithm. Since the evaluation key Di of the i-th party is an uni-encryption of µi = si
, we
obtain that Ki,j
· (1,si
,sj) ≈ sisj
· g (mod q). From the definition
of ct′
, we get
⟨ct′
,sk⟩ = c
′
0 +
Õ
k
i=1
c
′
i
· si
= c0,0 +
Õ
k
i=1
(c0,i + ci,0)si +
Õ
k
i,j=1
g
−1
(ci,j) · Ki,j
· (1,si
,sj) (mod q)
≈ c0,0 +
Õ
k
i=1
(c0,i + ci,0)si +
Õ
k
i,j=1
ci,j
· sisj = ⟨ct,sk ⊗ sk⟩ (mod q).
3.3.2 Second Method. Our second solution does not generate a
shared relinearization key different from the previous one. Instead,
it directly linearizes each entry ci,j of an extended ciphertext ct =
(ci,j)0≤i,j ≤k by multiplying it to bj and Di
in a recursive way.
• Relin(ct; {(Di
, bi)}1≤i ≤k
): For given extended ciphertext ct =
(ci,j)0≤i,j ≤k and k pairs of evaluation/public keys {(Di
, bi)}1≤i ≤k
,
generate a ciphertext ct′
∈ R
k+1
q
as described in Alg. 2.
Algorithm 2 Relinearization method 2
Input: ct = (ci,j)0≤i,j ≤k
,

(Di = [di,0 |di,1 |di,2], bi)
	
1≤i ≤k
.
Output: ct′
= (c
′
i
)0≤i ≤k ∈ R
k+1
q
.
1: c
′
0 ← c0,0
2: for 1 ≤ i ≤ k do
3: c
′
i ← c0,i + ci,0 (mod q)
4: end for
5: for 1 ≤ i, j ≤ k do
6: c
′
i,j ← ⟨g
−1
(ci,j), bj⟩ (mod q)
7: (c
′
0
,c
′
i
) ← (c
′
0
,c
′
i
) + g
−1
(c
′
i,j
) · [di,0 |di,1] (mod q)
8: c
′
j ← c
′
j
+ ⟨g
−1
(ci,j), di,2⟩ (mod q)
9: end for
We will analyze and compare two relinearization methods in the
following section. In short, the second method has advantages in
storage and noise growth while the first method could be faster if
a shared evaluation key is used repeatedly to relinearize multiple
ciphertexts corresponding to the same set of parties. We first show
the correctness of the second method.
Correctness. At each iteration of the second for-loop in Alg. 2, we
compute c
′
i,j
= ⟨g
−1
(ci,j), bj⟩, then add g
−1
(c
′
i,j
) · [di,0 |di,1] and
⟨g
−1
(ci,j), di,2⟩ to (c
′
0
,c
′
i
) and c
′
j
, respectively. We note that
g
−1
(c
′
i,j
) · [di,0 |di,1] · (1,si) ≈ ri
·c
′
i,j
(mod q), and
⟨g
−1
(ci,j), di,2⟩ · sj ≈ ⟨g
−1
(ci,j), −ri
· bj + sisj
· g⟩ (mod q)
= −ri
·c
′
i,j + ci,j
· sisj (mod q).
From the definition of ct′
, we get
⟨ct′
,sk⟩ = c
′
0 +
Õ
k
i=1
c
′
i
· si
= c0,0 +
Õ
k
i=1
(c0,i + ci,0)si +
Õ
k
i,j=1
g
−1
(c
′
i,j
) · [di,0 |di,1] · (1,si)
+
Õ
k
i,j=1
⟨g
−1
(ci,j), di,2⟩ · sj (mod q)
≈ c0,0 +
Õ
k
i=1
(c0,i + ci,0)si +
Õ
k
i,j=1
ci,j
· sisj = ⟨ct,sk ⊗ sk⟩ (mod q).
3.3.3 Performance of Relinearization Algorithms. Suppose that there
are k different parties involved in a multi-key computation. For
relinearizing an extended ciphertext ct = (ci,j)0≤i,j ≤k ∈ R
(k+1)
2
q
,
both of our relinearization methods repeat some computations on
each ci,j to switch its corresponding secret si
· sj
into (1,si
,sj). So
we will focus on a single step (i, j) of each solution to compare their
performance.
In our first method, a computing party generates a shared relinearization key Ki,j and uses it to linearize an input extended
ciphertext. The generation of Ki,j
includes a multiplication between
d × d and d × 2 matrices so its complexity is 2d
2 polynomial multiplications. However, the computation of g
−1
(ci,j) · Ki,j
in Step 6
of Alg. 1 requires only 3d polynomial multiplications. Meanwhile,
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 400
the second method does not have any pre-processing but a single
iteration of Alg. 2 requires 4d polynomial multiplications. As a
result, the first method can be up to (4/3) times faster when one
performs multiple homomorphic arithmetic on the same set (or its
subset) of parties using a pre-computed shared relinearization key,
however, the required storage grows quadratically on k compared
to the linear memory of the second method.
The second method also has an advantage in noise management,
which we will discuss below together with modulus raising technique.
3.3.4 Special Modulus Technique. Noise growth is the main factor
determining the parameter size and thereby overall performance
of a cryptosystem. In general, we can use a large decomposition
degree d to reduce the size of a decomposed vector g
−1
(·) as well
as key-switching error, but this naive method causes performance
degradation. In addition, the benefit of this trade-off between noise
growth and computational complexity gets smaller and smaller as
d increases. Therefore, this method is not the best option when we
should have a small noise.
The special modulus (a.k.a. modulus raising) technique proposed
in [27, 38] is one attractive solution to address this noise problem
with a smaller overhead. Roughly speaking, it raises the ciphertext
modulus from q to pq for an integer p called special modulus, and
then computes the key-switching procedure over Rpq followed by
modulus reduction back to q. The main advantage of this method
is that a key-switching error is decreased by a factor of about
p due to the modulus reduction. We apply this technique to our
relinearization and encryption algorithms. In particular, a special
modulus variant of relinearization requires two sequential modulus
switching operations (see Appendix A for details).
We recall that for an extended ciphertext ct ∈ R
(k+1)
2
q
, the goal
of relinearization is to generate a ciphertext ct′
∈ R
k+1
q
such that
⟨ct′
,sk⟩ = ⟨ct,sk ⊗ sk⟩ + el in for some error el in, which should
be minimized for efficiency. We refer the reader to Appendix C
which provides a noise analysis based on the variance of polynomial
coefficients, but we present a concise summary in this section.
Let u be a uniform random variable over Rq. We consider its
decomposition g
−1
(u) and denote by Vд the average of variances
of its coefficients. We respectively estimate the variance of a relinearization error from our first and second methods:
V1 ≈ k
2
n
2
σ
2
· d
2V
2
д
, V2 ≈ k
2
n
2
σ
2
· dVд .
In addition, the special modulus variant of the second method
achieves a smaller noise whose variance is
V
′
2 = p
−2
· V2 +
1
24
(k
2 + k)n.
Compared to the first method, our second solution has significant
advantages in practice because we may use an efficient decomposition method with a small d while obtaining the same level of noise
growth. Furthermore, its modulus raising variant obtains an even
smaller error variance which is not nearly affected by the size of
decomposition since V
′
2
is dominated by the second term (rounding
error) when we introduce a special modulus p which can cancel
out the term V2.
4 TWO MKHE SCHEMES WITH PACKED
CIPHERTEXTS
In this section, we present multi-key variants of the BFV [6, 22] and
CKKS [16] schemes. They share the following setup and key generation phases but have different algorithms for message encoding
and homomorphic operations.
• MKHE.Setup(1
λ
): Run Setup(1
λ
) and return the parameter pp.
• MKHE.KeyGen(pp): Each party i generates secret, public and evaluation keys by (si
, bi) ← KeyGen(pp) and Di ← EvkGen(si), respectively.
Encryption, decryption and homomorphic arithmetic of our
MKHE schemes are described in the next subsections. We have
a common pre-processing when performing a homomorphic operation between ciphertexts. For given ciphertexts cti ∈ R
ki+1
q
, we
denote k ≥ max{k1, k2} the number of parties involved in either ct1
or ct2. We rearrange the entries of cti and pad zeros in the empty entries to generate some ciphertexts ct∗
i
sharing the same secret sk =
(1,s1, . . . ,sk
). To be precise, a ciphertext cti = (c0,c1, . . . ,cki
) corresponding to the tuple of parties (id1, . . . ,idki
) ∈ {1, 2, . . . , k}
ki
is converted into the ciphertext ct∗
i = (c
∗
0
,c
∗
1
, . . . ,c
∗
k
) ∈ R
k+1
q which
is defined as c
∗
0
= c0 and c
∗
i
=
(
cj
if i = idj for some 1 ≤ j ≤ ki
;
0 otherwise,
for 1 ≤ i ≤ k. We remark that
⟨cti
, (1,sid1
, . . . ,sidki
)⟩ = ⟨ct∗
, (1,s1, . . . ,sk
)⟩.
For simplicity, we will assume that this pre-processing is always
done before homomorphic arithmetic so that two input ciphertexts
are related to the same set of k parties.
Security and Correctness. We recall that BFV and CKKS are INDCPA secure under the RLWE assumption of parameter (n,q, χ,ψ).
Our MKHE schemes have exactly the same single-key encryption
algorithms so that their security relies on the hardness of the same
RLWE problem (see Appendix B for details). We will briefly show
the correctness of our schemes in this section but the rigorous
proofs with noise analysis will be provided in Appendix C.
4.1 Multi-Key BFV
The BFV scheme [6, 22] is a scale-invariant HE which supports
exact computation on a discrete space with a finite characteristic.
We denote by t the plaintext modulus and ∆ = ⌊q/t⌉ be the scaling
factor of the BFV scheme. The native plaintext space is the set of
cyclotomic polynomials Rt
, but a plaintext is decoded to a tuple of
finite field elements via a ring isomorphism from Rt depending on
the relation of t and n [48].
• MK-BFV.Enc(m; b, a): This is the standard BFV encryption which
takes a polynomial m ∈ Rt as the input. Let a = a[0] and b = b[0].
Sample v ← χ and e0, e1 ← ψ. Return the ciphertext ct = (c0,c1) ∈
R
2
q where c0 = v ·b +∆·m+e0 (mod q) and c1 = v ·a+e1 (mod q).
• MK-BFV.Dec(ct;s1, . . . ,sk
): Let ct = (c0,c1, . . . ,ck
) ∈ R
k+1
q
be a
ciphertext associated to k parties and s1, . . . ,sk be their secret keys.
Set sk = (1,s1, . . . ,sk
) and compute j
(t/q) · ⟨ct,sk⟩
m
(mod t).
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 401
• MK-BFV.Add(ct1, ct2): Given two ciphertexts cti ∈ R
k+1
q
, return
the ciphertext ct′
= ct1 + ct2 (mod q).
• MK-BFV.Mult(ct1, ct2; {(Di
, bi)}1≤i ≤k
): Given two ciphertexts cti ∈
R
k+1
q
, compute ct =

(t/q) · (ct1 ⊗ ct2)

(mod q) ∈ R
(k+1)
2
q and return the ciphertext ct′ ← Relin(ct; {(Di
, bi)}1≤i ≤k
).
The correctness of our scheme is obtained from the properties of
the basic BFV and relinearization algorithm. A multi-key BFV encryption ofm ∈ Rt
is a vector ct = (c0,c1, . . . ,ck
) ∈ R
k+1
q
such that
⟨ct,sk⟩ ≈ ∆·m (mod q) for the secretsk = (1,s1, . . . ,sk
). So the decryption algorithm can recoverm correctly. If ct1 and ct2 are encryptions of m1 and m2 with respect to the secret sk = (1,s1, . . . ,sk
),
then their (scaled) tensor product ct =

(t/q) · (ct1 ⊗ ct2)

(mod q)
satisfies ⟨ct,sk ⊗ sk⟩ ≈ ∆ · m1m2 (mod q) similar to the ordinary
BFV scheme. The output ct′ ← Relin(ct;rlk) holds ⟨ct′
,sk⟩ ≈
⟨ct,sk ⊗ sk⟩ ≈ ∆ · m1m2 (mod q).
4.2 Multi-Key CKKS
The CKKS scheme [16] is a leveled HE scheme with support for approximate fixed-point arithmetic. We assume q =
ÎL
i=0
pi for some
integers pi to have a chain of ciphertext moduli q0 < q1 < · · · < qL
for qℓ =
Îℓ
i=0
pi
. The native plaintext is a small polynomial m ∈ R,
but one can pack at most (n/2) complex numbers in a single polynomial via DFT. In addition to the basic arithmetic operations, it
supports the rescaling algorithm to control the magnitude of encrypted message. For homomorphic operations between ciphertexts
at different levels, it requires to transform a high-level ciphertext
to have the same level as the other.
• MK-CKKS.Enc(m; b, a): Let m ∈ R be an input plaintext and let
a = a[0] and b = b[0]. Sample v ← χ and e0, e1 ← ψ. Return the
ciphertext ct = (c0,c1) ∈ R
2
q where c0 = v · b +m +e0 (mod q) and
c1 = v · a + e1 (mod q).
• MK-CKKS.Dec(ct;s1, . . . ,sk
): Let ct = (c0,c1, . . . ,ck
) ∈ R
k+1
qℓ
be a
ciphertext at level ℓ associated to k parties and s1, . . . ,sk be their
secret keys. Set sk = (1,s1, . . . ,sk
) and return ⟨ct,sk⟩ (mod qℓ
).
• MK-CKKS.Add(ct1, ct2): Given two ciphertexts cti ∈ R
k+1
qℓ
at level
ℓ, return the ciphertext ct′
= ct1 + ct2 (mod qℓ
).
• MK-CKKS.Mult(ct1, ct2; {(Di
, bi)}1≤i ≤k
): Given two ciphertexts
cti ∈ R
k+1
qℓ
at level ℓ, compute ct = ct1 ⊗ ct2 (mod qℓ
) ∈ R
(k+1)
2
qℓ
and return the ciphertext ct′ ← Relin(ct; {(Di
, bi)}1≤i ≤k
) ∈ R
k+1
qℓ
.
The relinearization algorithm is defined over modulus q = qL, but
we compute the same algorithm modulo qℓ
for level-ℓ ciphertexts.
• MK-CKKS.Rescale(ct): Given a ciphertext ct = (c0,c1, . . . ,ck
) ∈
R
k+1
qℓ
at level ℓ, compute c
′
i
=
j
p
−1
ℓ
·ci
m
for 0 ≤ i ≤ k and return
the ciphertext ct′
= (c
′
0
,c
′
1
, . . . ,c
′
k
) ∈ R
k+1
qℓ−1
.
A level-ℓ multi-key encryption of a plaintext m with respect
to the secret sk = (1,s1, . . . ,sk
) is a vector ct = (c0,c1, . . . ,ck
) ∈
R
k+1
qℓ
satisfying ⟨ct,sk⟩ ≈ m (mod qℓ
). For basic homomorphic
operation, we take as input level-ℓ encryptions of m1 and m2. Then,
homomorphic addition (resp. multiplication) returns a ciphertext
ct′
such that [⟨ct′
,sk⟩]qℓ
is approximately equal to m1 + m2 (resp.
m1m2). Finally, we show that for a level-ℓ encryption ct of m, the
rescaling algorithm returns a ciphertext ct′
at level (ℓ−1) encrypting
p
−1
ℓ
· m from the equation [⟨ct′
,sk⟩]qℓ−1 ≈ p
−1
ℓ
· [⟨ct,sk⟩]qℓ
.
4.3 Distributed Decryption
In the classical definition of MKHE primitive, all the secrets of the
parties involved are required to decrypt a multi-key ciphertext. In
practice, however, it is not reasonable to assume that there is a
party holding multiple secret keys. Instead, we can think about a
protocol between several key owners to jointly decrypt a ciphertext.
The decryption algorithms of our schemes are (approximate) linear
combinations of secrets with known coefficients, and there have
been proposed some secure methods for this task. We introduce
one simple solution based on the noise flooding technique, but any
secure solution achieving the same functionality can be used.
The distributed decryption consists of two algorithms: partial
decryption and merge. In the first phase, each party i receives the ith entry of a ciphertext and decrypts it with a noise. We set the noise
distribution ϕ which has a larger variance than the standard error
distribution ψ of basic scheme. Then, we merge partially decrypted
results with c0 to recover the message.
• MKHE.PartDec(ci
,si): Given a polynomial ci and a secret si
, sample an error ei ← ϕ and return µi = ci
· si + ei (mod q).
• MK-BFV.Merge(c0, {µi }1≤i ≤k
): Compute µ = c0+
Ík
i=1
µi (mod q)
and return m = ⌊(t/q) · µ⌉.
• MK-CKKS.Merge(c0, {µi }1≤i ≤k
): Compute and return µ = c0 +
Ík
i=1
µi (mod q).
For a multi-key ciphertext ct = (c0, . . . ,ck
), both multi-key BFV
and CKKS schemes compute µ = c0+
Ík
i=1
µi = ⟨ct,sk⟩+
Ík
i=1
ei ≈
⟨ct,sk⟩ (mod q) in the merge phase. Then, BFV extracts the plaintext by cancelling the scaling factor (q/t).
5 BOOTSTRAPPING FOR TWO MKHE
SCHEMES
There have been several studies on the bootstrapping procedures of
the standard (single-key) ring-based HE schemes [9, 12, 14, 25, 32].
Previous work had different goals and solutions depending on the
underlying schemes but they are basically following the Gentry’s
technique [24] – homomorphic evaluation of the decryption circuit. In particular, the BFV and CKKS schemes have a very similar
pipeline for bootstrapping which consists of four steps: (1) Modulus
Raise, (2) Coeff to Slot, (3) Extraction and (4) Slot to Coeff. The
second and last steps are specific linear transformations, which
require rotation operations on encrypted vectors.
For the rest of this section, we first explain how to perform the
rotation operation on multi-key ciphertexts based on the evaluation of Galois automorphisms. Then, we revisit the bootstrapping
procedures for BFV and CKKS to generalize the existing solutions
to our MKHE schemes.
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 402
5.1 Homomorphic Evaluation of Galois
Automorphisms
The Galois group Gal(Q[X]/(X
n +1)) of a cyclotomic field consists
of the transformation X 7→ X
j
for j ∈ Z
∗
2n
. We recall that BFV (resp.
CKKS) uses the DFT on Rt
(resp. R) to pack multiple plaintext values
into a single polynomial. As noted in [26], these automorphisms
provide special functionalities on packed ciphertext such as rotation
of plaintext slots.
The evaluation of an automorphism can be done based on the keyswitching technique. In some more details, let τj
: a(X) 7→ a(X
j
)
be an element of the Galois group. Given an encryption ct =
(c0,c1, . . . ,ck
) ∈ R
k+1
q ofm, we denote byτj(ct) = (τj(c0), . . . , τj(ck
))
the ciphertext obtained by taking τj to the entries of ct. Then τj(ct)
is a valid encryption of τj(m) corresponding the secret key τj(sk).
We then perform the key-switching procedure from τj(sk) back to
sk, so as to generate a new ciphertext encrypting the same message
under the original secret key sk.
In the following, we present two algorithms for the evaluation of
the Galois element. The first algorithm generates an evaluation key
for the Galois automorphism τj
. The second algorithm gathers the
evaluation keys of multiple parties and evaluates τj on a multi-key
ciphertext using the multi-key-switching technique proposed in
[10].
• MKHE.GkGen(j;s): Generate a random vector h1 ← U (R
d
q
) and
an error vector e
′ ← ψ
d
. For an RLWE secret s ∈ R, compute
h0 = −s · h1 + e
′ + τj(s) · g (mod q). Return the Galois evaluation
key as gk = [h0 |h1] ∈ R
d×2
q
.
• MKHE.EvalGal(ct; {gki
}1≤i ≤k
): Let gki = [hi,0 |hi,1] be the Galois
evaluation key of the i-th party for 1 ≤ i ≤ k. Given a ciphertext
ct = (c0, . . . ,ck
) ∈ R
k+1
q
, compute and return the ciphertext ct′
=
(c
′
0
, . . . ,c
′
k
) by
c
′
0 = τj(c0) +
Õ
k
i=1
⟨g
−1
(τj(ci)), hi,0⟩ (mod q), and
c
′
i = ⟨g
−1
(τj(ci)), hi,1⟩ (mod q) for 1 ≤ i ≤ k.
In the context of CKKS, all the computations are carried out over
modulus q = qℓ
for level-ℓ ciphertext. We now show the correctness
of our algorithms.
Correctness. From the definition, the output ciphertext ct′
=
(c
′
0
, . . . ,c
′
k
) ← MKHE.EvalGal(ct; {gki
}1≤i ≤k
) holds
⟨ct′
,sk⟩ = c
′
0 +
Õ
k
i=1
c
′
i
· si
= τj(c0) +
Õ
k
i=1
⟨g
−1
(τj(ci)), hi,0⟩ + ⟨g
−1
(τj(ci)), hi,1⟩ · si (mod q)
≈ τj(c0) +
Õ
k
i=1
⟨g
−1
(τj(ci)), τj(si) · g⟩ (mod q)
=
D
τj(ct), τj(sk)
E
= τj

⟨ct,sk⟩

(mod q),
as desired. In other words, if the input ciphertext has the phase
µ(X) = ⟨ct,sk⟩ (mod q), then the phase of the output ciphertext is
approximately equal to τj(µ(X)) = µ(X
j
).
Besides the rotation of plaintext slots, we can evaluate the Frobenius endomorphism X 7→ X
t on BFV ciphertexts using the same
technique. In the case of CKKS, the map X 7→ X
−1
corresponds to
the complex conjugation over plaintext slots.
Any linear transformation can be represented as a linear combination of shifted plaintext vectors. We note that previous HE
optimization techniques [9, 25, 32] for linear transformations can
be directly applied to our MKHE schemes.
5.2 Bootstrapping for Multi-Key BFV
Chen and Han [12] described a bootstrapping procedure for the
single-key BFV scheme, which follows the paradigm of [32], done
for BGV scheme. The bootstrapping procedure in [12] takes as input
a ciphertext with an arbitrary noise and outputs another ciphertext
with a low noise encrypting the same plaintext. Below we present
a multi-key variant of [12].
(1) The previous work [12] published an encryption of the secret
key by itself to raise the modulus. However, we observe that
this step can be done by multiplying a constant without extra
information. Suppose that the input ciphertext ct encrypts a
message m with a plaintext modulus t, i.e., ⟨ct,sk⟩ =
q
t m +
e (mod q) for some error e. Then we perform a modulusswitching down to a divisor q
′ of q, resulting in ⟨ct′
,sk⟩ =
q
′
t m + e
′
(mod q
′
), then multiply the ciphertext with q/q
′
and get a ciphertext ct′′ whose phase is ⟨ct′′
,sk⟩ =
q
q
′ ·

q
′
t m + e
′

(mod q). This is a trivial (noise free) encryption
of µ =
q
′
t m + e
′ with plaintext modulus q
′
and ciphertext
modulus q.
(2) It computes a homomorphic linear transform which produces multiple ciphertexts holding the coefficients µi ∈ Zt
of µ in their plaintext slots. We note that this step can be
done using the additions, scalar multiplications and multikey rotations.
(3) We homomorphically evaluate a polynomial, called lower
digits removal [12], on the multi-key ciphertexts obtained
in previous step. It removes the noise e
′
and leaves the coefficients of m in plaintext slots.
(4) The final step is another linear transformation which inverts
the second step and outputs an encryption of m.
As a consequence, the output ciphertext has the phase q
t m + e
′′
(mod q) for an error which is smaller than the initial noise e.
5.3 Bootstrapping for Multi-Key CKKS
Cheon et al. [14] presented a bootstrapping procedure for the singlekey CKKS scheme and its performance was improved in the followup research [9]. The bootstrapping procedure of CKKS aims to
refresh a low-level ciphertext and return an encryption of the (almost) same messages in a larger ciphertext modulus. We describe
its multi-key version as follows.
(1) The first step takes a lowest-level ciphertext ct as an input.
Let µ = ⟨ct,sk⟩ (mod q0). Then ⟨ct,sk⟩ = q0 · I + µ for a
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 403
small I ∈ R, so ct can be considered as an encryption of
t = q0 · I + µ in the largest ciphertext modulus qL.
(2) We apply a homomorphic linear transformation to compute
one or two ciphertexts encrypting the coefficients of t(X) in
their plaintext slots. This step requires multi-key rotation
and conjugation described in Section 5.1.
(3) We evaluate a polynomial which approximates the reduction
modular q0 function. It removes the I part of t and leaves
coefficients of µ in the slots.
(4) Finally, we apply the inverse linear transformation of the
second step to pack all the coefficients of µ back into a ciphertext.
The output ciphertext ct′
encrypts the same plaintext µ in a
higher level than the input ciphertext ct, i.e., ⟨ct′
,sk⟩ ≈ µ (mod qℓ
)
for some 0 < ℓ < L.
6 IMPLEMENTATION
We provide a proof-of-concept implementation to show the performance of our MKHE schemes. Our source code is developed in
C++ with Microsoft SEAL version 3.2.0 [47] which includes BFV
and CKKS implementations. We summarize our optimization techniques, recommended parameter sets, and some experimental results in this section. Finally, we apply the multi-key CKKS scheme to
evaluate an encrypted neural network model on encrypted data and
report the experimental result to classify handwritten images on the
MNIST dataset [40]. All experiments are performed on a ThinkPad
P1 laptop: Intel Xeon E-2176M @ 4.00 GHz single-threaded with 32
GB memory, compiled with GNU C++ 7.3.0 (-O2). In our implementation, we set the secret distribution χ as the uniform distribution
over the set of polynomials in R whose coefficients are in {0, ±1}.
Each coefficient of an error e ← ψ is drawn according to the discrete Gaussian distribution centered at zero with standard deviation
σ = 3.2.
6.1 Optimization Techniques
6.1.1 Basic Optimizations. In the relinearization process, we first
compute the tensor product of two ciphertexts which corresponds
to the tensor squared secret sk ⊗ sk. It has duplicated entries at (i, j)
and (j,i), so we can reduce its dimension from (k + 1)
2 down to
1
2
k(k +1). Both the size of the relinearization key and complexity of
the algorithm are almost halved. Furthermore, each of the diagonal
entries s
2
i
of sk ⊗ sk depends on a single party, so we can include
a key-switching key for s
2
i
in the generation of an evaluation key.
It increases the size of evaluation keys but reduces the complexity
and noise of relinearization.
6.1.2 RNS and NTT. Our schemes are designed on the ring structure Rq, so we need to optimize the basic polynomial arithmetic.
There is a well-known technique to use an RNS by taking a ciphertext modulus q =
ÎL
i=0
pi which is a product of coprime integers. Based on the ring isomorphism Rq →
ÎL
i=0
Rpi
, a 7→ (a
(mod pi))0≤i ≤L, we achieve asymptotic/practical improvements in
polynomial arithmetic over Rq. In particular, it has been studied
how to design full-RNS variants of BFV and CKKS [4, 15, 30], which
do not require any RNS conversions. In addition, each of base prime
can be chosen properly so that there exists a (2n)-th root of unity
Parameter Public Key Evaluation Key
ID n ⌈logq⌉ ⌈logpi⌉ # p
′
i
s Size Gen. Size Gen.
I 2
13 218 49–60 4 0.75 MB 3 ms 2.25 MB 8 ms
II 2
14 438 53–60 8 7 MB 24 ms 21 MB 59 ms
III 2
15 881 54–60 16 60 MB 195 ms 180 MB 470 ms
Table 2: Proposed parameter sets. logq and logpi denote the
bit lengths of the largest RLWE modulus and individual
RNS primes, respectively. # p
′
i
s denotes the number of RNS
primes. Public keys’ and evaluations keys’ generation times
and sizes are those of each party. ms = 10−3
sec.
modulo pi
. It allows us to exploit an efficient Number Theoretic
Transformation (NTT) modulo pi
. Our implementation adapts these
techniques to improve the speed of polynomial arithmetic.
6.1.3 Gadget Decomposition. As mentioned before, the gadget
decomposition has a major effect on the performance of homomorphic arithmetic. Bajard et al. [4] observed that the formula
a =
Í
i дi
· [a]pi
(mod q) where дi =

Î
j,i pj
−1

pi
·
Î
j,i pj

can be used to build an RNS-friendly decomposition a 7→ ([a]pi
)i
with the gadget vector g = (дi)i
. We adapt this decomposition
method and take an advantage of an RNS-based implementation
by storing ciphertexts in the RNS form.
In [4, 30], the authors further combined this method with the
classical digit decomposition method to provide a more fine-grained
control of the trade-off between complexity and noise growth. However, we realize that this hybrid method increases the decomposition
degree (and thereby space and computational complexity) several
times, and the special modulus technique described in Section 3.3.4
provides a much better trade-off. Therefore, the digit decomposition
is not used in our implementation.
6.2 Micro-benchmarks for MKHE Schemes
Table 2 illustrates the selected parameter sets used in experiments.
They are default parameter sets in Microsoft SEAL which provide
at least 128-bit of security level according to LWE-estimator [3]
and HE security standard [2]. Generation time and size of secret
keys, and execution time of encryption are the same as those in
single-key BFV and CKKS. Decryption and ciphertext addition
take 1
2
(k + 1) times longer than the ordinary HE schemes. We
remark that generation time and size of public and evaluation keys
{(bi
, Di)}1≤i ≤k do not depend on the number of parties or the
scheme because the generation can be executed in a synchronous
way.
In our experiments, a homomorphic multiplication is always
followed by a relinearization procedure. BFV requires more NTTs
than CKKS overall to perform these operations, and is therefore
slower, which is confirmed by the timing results.
The execution times of multiplications in both MKHE schemes
are asymptotically quadratic in the number of parties as discussed
in Section 3.3. In practice, they are better than quadratic, as reported
in Table 3. This is because both multiplication and relinearization
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 404
ID #Parties Mult + Relin EvalGal
BFV CKKS BFV CKKS
I
1 20 ms 8 ms 3 ms 4 ms
2 44 ms 22 ms 7 ms 8 ms
4 116 ms 67 ms 14 ms 16 ms
8 365 ms 229 ms 28 ms 31 ms
II
1 110 ms 59 ms 22 ms 24 ms
2 257 ms 165 ms 47 ms 49 ms
4 717 ms 521 ms 88 ms 95 ms
8 2, 350 ms 1, 845 ms 176 ms 193 ms
III
1 675 ms 465 ms 170 ms 172 ms
2 1, 715 ms 1, 364 ms 333 ms 359 ms
4 5, 025 ms 4, 287 ms 646 ms 711 ms
8 17, 450 ms 15, 159 ms 1, 332 ms 1, 413 ms
Table 3: Execution time that depends on the number of parties. Multiplication is always followed by a relinearization
in MKHE. ms = 10−3
sec.
include a notable portion of computation that is linear in the number of parties. The execution times of homomorphic evaluation
of Galois automorphisms are almost linear on the number of the
parties as described in Section 5.1.
For the single-party scenario in Table 3, we measured performance of our modified Microsoft SEAL [47] with a special modulus.
It is infeasible to fairly compare the ordinary BFV and CKKS with
their multi-key variants because the performance of a scheme can
be analyzed from various perspectives: space/time complexity, noise
growth, functionality, etc. It is provided merely as a reference point,
for a more portable estimation of MKHE on different processors.
6.3 Application to Oblivious Neural Network
Inference
Jiang et al. [34] proposed a novel framework to test encrypted
neural networks on encrypted data in the single-key scenario. We
consider the same service paradigm but in a multi-key setting: the
data and trained model are encrypted under different keys.
6.3.1 Homomorphic Evaluation of CNN.. We present an efficient
strategy to evaluate CNN prediction model on the MNIST dataset.
Each image is a 28 × 28 pixel array and will be labeled with 10 possible digits after an arbitrary number of hidden layers. We assume
that a neural network is trained with the plaintext dataset in the
clear. Table 4 describes our neural network topology which uses
one convolution layer and two fully-connected (FC) layers with
square activation function. The final step is to apply the softmax
activation function for a purpose of probabilistic classification, so
it is enough to obtain an index of maximum values of outputs in a
prediction phase. Our objective is to predict a single image in an
efficient way, thereby achieving a low latency. In Appendix D, we
describe the detailed algorithms for encryption and evaluation.
The Convolutional Layer. As noted in [35], strided convolution
can be decomposed into a sum of simple convolutions (i.e., the
stride parameter = 1). From our choice of the parameters, each of
such simple convolutions takes as inputs 14 × 14 images and 2 × 2
Layer Description
Convolution Input image 28 × 28, window size 4 × 4,
stride (2, 2), number of output channels 5
1
st square Squaring each of the 845 inputs
FC-1 Fully connecting with 845 inputs and 64 outputs
2
nd square Squaring each of the 64 inputs
FC-2 Fully connecting with 64 inputs and 10 outputs
Table 4: Description of our CNN to the MNIST dataset.
filters. This representation allows more SIMD parallelism, since
we can pack all the inputs into a single ciphertext and perform
four simple convolutions in parallel. Once this is done, we can
accumulate the results across plaintext slots using rotate-and-sum
operations in [31]. Moreover, we can pack multiple channels in a
single ciphertext as in [35, Section VI.D], yielding in a fully-packed
ciphertext of the convolution result.
The First Square Layer. This step applies the square activation
function to all the encrypted output of the convolutional layer in
an SIMD manner.
The FC-1 Layer. In general, an FC layer with ni
inputs and no outputs can be computed as a matrix-vector multiplication. Let W and
v be the no × ni weight matrix and ni-length vector, respectively.
We assume that ni and no are smaller than the number of plaintext
slots, and no is much lower than ni
in the context of FC layers.
Halevi and Shoup [31] presented the diagonal encoding method
which puts a square matrix in diagonal order, multiplies each of
them with a rotation of the input vector, and then accumulates all
the output vectors to obtain the result. Juvekar et al. [35] extended
the method to multiply a vector by a rectangular matrix. If the
input vector is encrypted in a single ciphertext, the total complexity is no homomorphic multiplications, (no − 1) rotations of the
input ciphertext of v, and log(ni /no ) rotations for rotate-and-sum
algorithm.
We extend their ideas to split the original matrix W into smaller
sized blocks and perform computation on the sub-matrices as shown
in Fig. 2. Suppose that the vector v is split into ℓ many sub-strings
with the same length. For simplicity, we consider the first ℓ rows
of W. We first apply the diagonal method to arrange the 1 × (ni /ℓ)
sized sub-matrices of W in a way that intermediate numbers are
aligned in the same position across multiple slots after homomorphic multiplications. To be precise, the encryptions of diagonal
components are multiplied with ℓ rotations of the encrypted vector
and all these encryptions are added together similar to the diagonal method. Then, the output ciphertext represents (ni /ℓ)-sized
ℓ chunks, each containing partial sums of ℓ entries of ni
inputs.
Finally, we can accumulate these using a rotate-and-sum algorithm
with log(ni /ℓ) rotations. As a consequence, the output ciphertext
encrypts the first ℓ many entries of Wv. We repeat this procedure
for each ℓ many rows of W, resulting in (no /ℓ) ciphertexts.
When ni
is significantly smaller than the number of plaintext
slots ns , the performance can be improved by packing multiple
copies of the input vector into a single ciphertext and performing
(ns /ni) aforementioned operations in parallel. The computational
cost is (no ·ni)/ns homomorphic multiplications, (ℓ−1) rotations of
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 405
Figure 2: Our matrix-vector multiplication algorithm (ℓ = 2).
the input ciphertext of v, and (no · ni)/(ns · ℓ) · log(ni /ℓ) rotations.
We provide additional details in Appendix D.2. As a result, our
method provides a trade-off between rotations on the same input
ciphertext (which can benefit from the hoisting optimization of
[33]) and rotations on distinct ciphertexts (which cannot benefit
from hoisting).
As described in Fig. 2, all slots except the ones corresponding to
the result components may reveal information about partial sums.
We therefore multiply the output ciphertexts by a constant zero-one
plaintext vector to remove the information.
The Second Square Layer. This step applies the square activation
function to all the output nodes of the first FC layer.
The FC-2 Layer. This step performs a multiplication with small
sized weight matrix U and vector v. As discussed in [31], it can be
considered as the linear combination of U’s columns using coefficients from v. Suppose that the column vectors are encrypted in
a single ciphertext in such a way that they are aligned with the
encrypted vector. We first repeatedly rotate the encryption of the
vector to generate a single ciphertext with no copies of each entry.
Then, we apply pure SIMD multiplication to multiply each column
vector by the corresponding scalar of the vector in parallel. Finally,
we aggregate all the resulting columns over the slots to generate
the final output.
6.3.2 Performance Evaluation. We evaluated our framework to
classify encrypted handwritten images of the MNIST dataset. We
used the library keras [18] with Tensorflow [1] to train the CNN
model from 60,000 images of the dataset. We employ the special
modulus variant of the multi-key CKKS scheme to achieve efficiency of approximate computation. Each layer of the network has
a depth of one homomorphic multiplication (except the first FC
layer requiring one more depth for multiplicative masking), so it
requires 6 levels for the evaluation of CNN. We chose the parameter
Set-II from Table 2 so as to cope with such levels of computations.
The data owner chooses one among 10,000 test images from
MNIST dataset, normalizes it by dividing by the maximum value 255,
and encrypts it into a single ciphertext using the public key, which
takes 1.75 MB of space. Meanwhile, the model provider generates a
relatively large number of ciphertexts for the trained model: four
for the multiple channels, eight for the weight matrix of the FC-1
layer, and one of each for the other weight or bias. Therefore, the
total size of the output ciphertexts is 18.5 MB and it takes roughly
Stage Runtime
Data owner Image encryption 31 ms
Model provider Model encryption 236 ms
Cloud
server
Convolutional layer 705 ms
1
st square layer 143 ms
FC-1 layer 739 ms
2
nd square layer 75 ms
FC-2 layer 135 ms
Total evaluation 1, 797 ms
Table 5: Performance breakdown for evaluating an encrypted neural network on encrypted MNIST data, where
the two encryptions are under different secret keys.
Framework Methodology Runtime
Latency Amortized
CryptoNets HE 570 s 0.07 s
MiniONN HE, MPC 1.28 s -
Gazelle HE, MPC 0.03 s -
E2DM HE 28.59 s 0.45 s
Ours MKHE 1.80 s -
Table 6: MNIST benchmarks of privacy-preserving neural
network frameworks.
7 times longer to encrypt the trained model than an image, but it is
an one-time process before data outsourcing and so it is a negligible
overhead. After the evaluation, the cloud server outputs a single
multi-key ciphertext encrypting the prediction result with respect
to the extended secret key of the data and model owner. Table 5
presents running time of the CNN evaluation. It takes about 1.8
seconds to classify an image using a pre-trained model.
Our parameter guarantees at least 32-bit precision after the decimal point. That is, the infinity norm distance between encrypted
evaluation and plain computation is bounded by 2
−32. Therefore,
we had enough space to use the noise flooding technique for decryption. In terms of the accuracy, it achieves about 98.4% on the
test set which is the same as the one obtained from the evaluation
in the clear.
6.3.3 Comparison with Previous Works. In Table 6, we compare our
benchmark result with the state-of-the-art frameworks for oblivious neural network inference: CryptoNets [29], MiniONN [42],
Gazelle [35], and E2DM [34]. The first column indicates the framework and the second column denotes the cryptographic primitives
used for preserving privacy. The last columns give running time
for image classification as well as amortized time per instance.
Among the aforementioned solutions for private neural network
prediction, E2DM relies on a third-party authority holding a secret
key of HE, since the data and model are under the same secret key.
CryptoNets has good amortized complexity, but it has a high latency
for a single prediction. MiniONN and Gazelle have good latency, but
they require both parties to be online during the protocol execution,
and at least one party performs local work proportional to the
complexity of the function being evaluated. Also, the number of
round scales with the number of layers for MiniONN and Gazelle in
Session 2D: Encryption (Searchable, Updatable, Homomorphic, etc.) CCS ’19, November 11–15, 2019, London, United Kingdom 406
the neural network. On the other hand, our solution has a constant
number of rounds.
Moreover, our solution allows the parties to outsource homomorphic evaluation to an untrusted server (e.g. a VM in the cloud with
large computing power), so both parties only need to pay encryption/decryption cost, and the communication cost only scales with
the input/model sizes, but not the complexity of the network itself.
This feature is made possible since our scheme supports multi-key
operations. Note that the server is only assumed to be semi-honest:
we do not require non-collusion assumptions since even if the server
colludes with one party, they cannot learn the other party’s private inputs due to the IND-CPA security of MKHE. Therefore, we
believe that our work presents an interesting point in the design
space of oblivious machine learning inference. Last but not least,
MiniONN and Gazelle have communication cost scaling linearly
with the number of activation nodes in the neural network due to
the use of garbled circuits. In our case, the size of the ciphertexts
and public/evaluation keys only depends on the number of layers
and the number of input nodes of the neural network. Hence our
solution is asymptocially more communication size-efficient.
7 CONCLUSION
In this paper, we presented practical multi-key variants of the BFV
and CKKS schemes and their bootstrapping methods. We provided
the first experimental results of MKHE with packed ciphertexts
by implementing our schemes. The main technical contribution is
to propose new relinearization algorithms achieving better performance compared to prior works [13, 41]. Finally, we showed that
our scheme can be applied to secure on-line prediction services by
evaluating an encrypted classifier on an encrypted data under two
different keys. We implemented our protocol on CNNs trained on
the MNIST dataset and showed that it can achieve a low end-to-end
latency by leveraging the optimized homomorphic convolutions
and homomorphic matrix-vector multiplications.