Symmetric Searchable Encryption (SSE) has received wide attention
due to its practical application in searching on encrypted data.
Beyond search, data addition and deletion are also supported in
dynamic SSE schemes. Unfortunately, these update operations leak
some information of updated data. To address this issue, forwardsecure SSE is actively explored to protect the relations of newly
updated data and previously searched keywords. On the contrary,
little work has been done in backward security, which enforces that
search should not reveal information of deleted data.
In this paper, we propose the first practical and non-interactive
backward-secure SSE scheme. In particular, we introduce a new
form of symmetric encryption, named symmetric puncturable encryption (SPE), and construct a generic primitive from simple cryptographic tools. Based on this primitive, we then present a backwardsecure SSE scheme that can revoke a server’s searching ability
on deleted data. We instantiate our scheme with a practical puncturable pseudorandom function and implement it on a large dataset.
The experimental results demonstrate its efficiency and scalability.
Compared to the state-of-the-art, our scheme achieves a speedup of
almost 50× in search latency, and a saving of 62% in server storage
consumption.
CCS CONCEPTS
• Security and privacy→Privacy-preserving protocols; Management and querying of encrypted data;
KEYWORDS
Symmetric Searchable Encryption; Puncturable Encryption; Backward Security
1 INTRODUCTION
Symmetric searchable encryption (SSE) [12, 31] allows a server to
search directly over encrypted data. A long line of research has
been made to realize various SSE schemes [8, 9, 11, 12, 24, 27] with
tradeoffs between efficiency, expressiveness, and security. Some
schemes are called dynamic SSE if data addition and/or deletion
is also supported. In general, the security of SSE guarantees the
protection of data contents or even that of processed queries and
search results. It is captured by well-defined leakage functions
which express the types of information leaked in search or update
queries.
In practice, dynamic SSE is more desirable because of its enriched
functionality. However, data addition and deletion in most existing dynamic SSE schemes leak more information than search [27].
Specifically, data addition reveals relations between newly added
data and keywords searched before. Practical attacks in [7, 36]
showed that the above information learned in data addition could
be exploited to compromise the privacy of query keywords. Accordingly, a number of forward-secure SSE schemes [3, 15, 28, 32] have
been designed just recently to break the linkability of the newly
added data and queried keywords. Regarding data deletion, most
of the existing schemes require server to use a revocation list to
filter deleted data indices (identifiers) from search results [8, 27].
Thus, after data deletion server can still match the deleted data.
To hide the relations between the deleted data and subsequently
queried keywords, backward security was initially considered in
[33]. However, little work has studied backward-secure SSE, where
server should no longer be able to match and retrieve the deleted
data.
An informal notion of backward security for SSE was first given
by Stefanov et al. [33]. Very recently, Bost et al. [5] formalized the
notion and designed several backward- (also forward-) secure SSE
schemes. Their proposed schemes introduced either high communication complexity or high computation complexity. Nevertheless,
they presented the first (and the only existing) non-interactive
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 763
backward-secure SSE scheme, named Janus. In that scheme, data
indices are encrypted through puncturable encryption [19]. Later,
server with punctured secret key can only decrypt and retrieve the
matched indices except the deleted (punctured) ones, even they are
not physically removed. Due to the adopted expensive public puncturable encryption [19], however, Janus can be hardly deployed in
practice. As shown in our experiment in Section 5, it takes over
30 minutes to fetch 10 thousand indices for a given query keyword with 50 deletions on it. Hence, the construction of practical
backward-secure SSE schemes or efficient puncturable encryption
schemes is left as an open problem.
To tackle this problem, we observe that the public-key setting
does not appear to be necessary for SSE. Therefore, a natural question is that:
Does there exist any practical symmetric alternative of puncturable
encryption that satisfies the requirements of SSE applications with
backward secuirty?
In this work, we answer this question affirmatively by presenting
a novel symmetric puncturable encryption (SPE) and constructing a
practical backward-secure SSE scheme based on the proposed SPE.
The main contributions of this paper are summarized as below:
• We first formalize the syntax and security definitions of
symmetric puncturable encryption (SPE). To make it suitable
for dynamic SSE applications such that client can efficiently
enforce data deletions, we refine SPE and propose a new
variant with an additional property, named Incremental SPE.
With this property, each time client conducts a deletion, s/he
can outsource partial punctured secret key to server, and
hence data can be deleted gradually with a low and constant
local storage.
• We propose a generic Incremental SPE based on simple cryptographic tools, which may be of independent interests. After
that, we present a single-keyword backward- and forwardsecure SSE scheme by leveraging the above refined SPE,
where an update operation does not leak any information
about either the updated keyword or the updated data index.
Furthermore, we elaborate how to extend our SSE scheme
to process batch deletions.
• We prove that our SPE and SSE schemes are secure in the random oracle model under static assumptions. We instantiate
our constructions with the well-known puncturable pseudorandom function (GGM PRF [18]) in a non-trivial manner,
and obtain the first practical and scalable backward-secure
SSE scheme named Janus++.
• We implement Janus++ with Python and evaluate it over
a real-world database on Azure Cloud. To demonstrate its
efficiency, we perform a set of comprehensive comparison
with the state-of-the-art backward-secure SSE scheme, Janus
[5]. Among others, our encryption function reaches a comparable time cost and our puncture function achieves a
speedup of 1.35 ×. Moreover, Janus++ brings a saving of
62% in server storage cost on the encrypted database and
achieves a speedup of 47∼49 × in search latency.
1.1 Related Work
Symmetric Searchable Encryption. Song et al. [31] invented
the notion of symmetric searchable encryption (SSE). After that, a
line of work has been done for SSE security [5, 12, 17, 33], query
functionality [9, 11, 16, 25, 29, 34], and performance optimization
[8, 10, 30]. All SSE schemes allow leakage called search pattern and
access pattern. Recently, researchers started exploiting the above
leakage to break the security of SSE, e.g., leakage-abuse attacks [7].
It is shown that padding [4, 7] and secure multi-party computation [23] can be leveraged for defense. SSE schemes [8, 21, 26, 27, 35]
that support data addition and deletion are known as dynamic
SSE. In [33], Stefanov et al. first introduced the notions of forward
and backward security for dynamic SSE to reduce the leakage due
to addition and deletion, respectively. Driven by attacks [7, 36]
that exploited leakage in dynamic operations, many efforts have
been made recently to achieve forward security. Schemes proposed
in [3, 15, 28, 32] support forward-secure addition, i.e., hiding relations between newly added data and previous queries.
Just recently, Bost et al. [5] formally defined the notion of backward security for dynamic SSE, and designed two backward-secure
schemes. The first resorts to constrained pseudorandom functions
to limit a server’s search capability. It requires to maintain the states
of the inserted and deleted entries (aka counter linking to document/keyword pairs). As a result, search tokens are generated from
the states of the entries that are not deleted. However, this approach
introduces an extra round of interaction for each search query, if
the above states are stored at server in an encrypted form. Besides,
the cost of the states scales with the total number of entries in the
database. The second resorts to public-key puncturable encryption.
Although it is non-interactive, the costly puncturable encryption
does not appear to make search operations practically deployable.
In this work, we solve the open problem raised in [5] and propose a
novel symmetric puncturable encryption. We employ it to dynamic
SSE to realize the backward security in an efficient and scalable
manner.
Puncturable encryption. Puncturable encryption was initially
introduced by Green and Miers [19] to realize forward-security
in secure messaging. It was designed by “puncturing" the secret
key after each decryption. Following this way, previous ciphertexts
cannot be decrypted, even after the exposure of current (punctured)
secret key. In recent years, puncturable encryption was found very
useful in many applications, e.g., devising chosen-ciphertext secure fully homomorphic encryption [6] and forward-secure key
exchange protocols [13, 20]. In particular, it was adapted to construct backward-secure SSE as shown in [5]. To the best of our
knowledge, however, all existing puncturable encryptions are proposed in public settings, which are not suitable or impractical for
scenarios that only require symmetric settings. In this work, we initialize the study of practical symmetric alternative of puncturable
encryption, and leverage it to design the first practically deployable
backword-secure SSE scheme.
2 PRELIMINARIES
In this section, we briefly introduce the basic cryptographic primitives used throughout the work, including the syntax and security
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 764
definitions of puncturable pseudorandom function and dynamic
symmetric searchable encryption.
2.1 Symmetric Encryption
A symmetric encryption scheme with key space K and message
space {0, 1}
∗ usually consists of two algorithms SE = (SE.Enc,
SE.Dec) with the following syntax:
SE.Enc(K,m): takes as input a secret key K ∈ K and a message
m, and generates a ciphertext ct.
SE.Dec(K,ct): takes as input a ciphertext ct and the secret key
K, and recovers m from ct or returns a failure symbol ⊥.
For correctness, it is required that the message m encrypted in
ct can always be recovered with secret key K.
Next, we briefly recall the IND-CPA security definition of SE,
which is defined via an experiment shown in Figure 1.
ExptIND-CPA
A,SE (λ) : O
Enc
K
(m) :
b
$←− {0, 1};K
$←− K ct ← SE.Enc(K,m)
(m0,m1,st) ← AO
Enc
K
(·)
1
(1
λ
) Return ct.
s.t. |m0 | = |m1 |
ct∗ ← SE.Enc(K,mb
)
b
′ ← AO
Enc
K
(·)
2
(st,ct∗
)
Return (b
′ = b).
Figure 1: IND-CPA Security of SE
Definition 2.1 (Semantic Security of SE). Let SE = (SE.Enc,
SE.Dec) be a symmetric encryption scheme. It is called IND-CPA
secure if for all sufficiently large security parameter λ ∈ N and
probabilistic polynomial time (PPT) adversary A, its advantage
defined as
Adv
IND-CPA
A,SE (λ) =




Pr[ExptIND-CPA
A,SE (λ) = 1] − 1
2




,
is negligible in λ.
2.2 Pseudorandom Function
Let F : K × X → Y be a function defined from X to Y. It is
called a pseudorandom function (PRF) if for all PPT adversary A,
its advantage defined as
Adv
PRF
A,F
(λ) =



Pr[AF (k, ·)(1
λ
) = 1] − Pr[Af (·)(1
λ
) = 1]


 ,
is negligible in λ, where k
$← K and f is a random function from
X to Y.
2.3 Puncturable Pseudorandom Function
Next we recall the syntax and security of puncturable pseudorandom functions (Pun-PRFs) [22]. A PRF F : K × X → Y with key
space K is a puncturable PRF if there is an additional key space Kp
and a pair of algorithms (F.Punc, F.Eval) satisfying the following
properties:
• F.Punc(k, x): takes as input a PRF key k ∈ K and an element
x ∈ X, and outputs a punctured secret key kx ∈ Kp .
• F.Eval(kx , x
′
): takes as input a punctured key kx ∈ Kp and
an element x
′ ∈ X, and outputs an element y ∈ Y.
Correctness: For all k ∈ K, x, x
′ ∈ X and kx ← F.Punc(k, x),
it holds that
F.Eval(kx , x
′
) =

F (k, x
′
), x
′ , x,
⊥, others.
Security: Similarly, the security of a Pun-PRF F is defined
through an experiment, as described in Figure 2.
ExptPun-PRF
A,F
(λ) : O
Eval
k
(x) :
b
$←− {0, 1}; k
$←− K; E ← ∅ y ← F (k, x)
(x
∗
,st) ← AO
Eval
k
(·)
1
(1
λ
) E ← E ∪ {x}
y0
$←− Y; y1 ← F (k, x
∗
) Return y.
kx
∗ ← F.Punc(k, x
∗
)
b
′ ← A2(st, (kx
∗ ,yb
))
Return (b
′ = b ∧ x
∗ < E).
Figure 2: Security of Pun-PRF
Definition 2.2 (Security of Pun-PRFs). A PRF F : K × X ← Y is a
secure Pun-PRF if for all large enough λ and PPT adversary A, the
advantage, Adv
Pun-PRF
A,F
(λ), of A is negligible in λ, where
Adv
Pun-PRF
A,F
(λ) =




Pr[ExptPun-PRF
A,F
(λ) = 1] − 1
2




.
2.4 Symmetric Searchable Encryption
A dynamic SSE scheme Σ = (Setup, Search,Update) is comprised
of one algorithm and two protocols:
Setup(1
λ
, DB): takes a security parameter λ and a database DB,
and outputs (K, σ, EDB), where K is a secret key, σ is the client’s
state, and EDB is the encrypted database.
Search(K, q, σ; EDB): this is a protocol between client with input
(K, q, σ) and server with input EDB. After the protocol, matching
results R are returned from server to client. In a single-keyword
scheme, query q is restricted to a single keyword w.
Update(K, σ, op, in; EDB): this is a protocol between a server
with input EDB and a client with input (K, σ, op, in), where op is
the update operation of adding or deleting a document/keyword
pair and in an input parsed as the document index ind and a set W of
keywords. After the protocol, the input in is added to or (logically)
deleted from EDB.
Correctness: A dynamic SSE scheme Σ = (Setup, Search,
Update) is correct if for each query, the search protocol always
returns correct results with an overwhelming probability. For the
formal definition, please refer to [8, 27].
Security: The security of SSE is captured by using the real-world
versus ideal-world formalization [5, 8, 27]. In brief, it expresses an
intuition that an adversary should not learn any information about
the content of the database and the queries beyond some explicit
leakage.
The security model is parameterized by the (stateful) leakage
function L = (LStp
, LSrch
, LUpdt), which is used to capture the
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 765
information learned by the adversary and its components express
the information leaked by Setup, Search and Update operation,
respectively. The task of the adversary is to distinguish between the
experiments Real and Ideal. Following the notion given in [8, 27],
we present the security definition of SSE in Definition 2.3. Loosely
speaking, the definition ensures that whenever the client triggers
any of these operations adaptively, the adversary obtains no more
information except what can be inferred from the corresponding
leakage function.
Definition 2.3 (Adaptive Security of Dynamic SSE). Let Σ =
(Setup, Search,Update) be a dynamic SSE scheme and L a leakage
function. Σ is said to be L-adaptively secure, if for all PPT adversary
A that makes a polynomial q(λ) of queries, there exists an efficient
simulator S such that:



Pr[RealΣ
A(λ) = 1] − Pr[IdealΣ
A,S, L
(λ) = 1]


 ≤ negl(λ),
where RealΣ
A
(λ) and IdealΣ
A,S, L
(λ) are defined as:
• RealΣ
A
(λ): A initially chooses a database DB, and gets back
EDB generated by calling Setup(1
λ
, DB). Then, A adaptively
performs search (resp. update) queries with input q (resp. (op,
in)), and receives transcript generated by running Search(q)
(resp. Update(op, in)). Eventually, A observes real transcripts
of all operations and outputs a bit b.
• IdealΣ
A,S, L
(λ): A chooses a database DB, and receives EDB
generated by the simulator S(LStp(DB)). Then A adaptively
performs search (resp. update) queries with input q (resp. (op,
in)), and gets a transcript generated by running S(LSrch(q))
(resp. S(LUpdt(op, in))). Finally, A observes all simulated
transcripts (rather than the real ones) and outputs a bit b.
2.5 Forward and Backward Security of SSE
Forward and backward security of dynamic SSE was firstly defined
in [33], and then formalized by Bost et al. [3, 5]. Briefly speaking,
forward security ensures that update queries leak no information
about the involved keywords in the keyword/document pairs to be
updated, while backward security ensures that subsequent search
queries on keyword w do not reveal the document indices ind’s
(matching w) that are added previously but deleted later. It is worth
noting that the ind will be revealed with no doubt, if a search query
on w is issued after the insertion of the pair (w,ind) and before its
deletion. Therefore, backward security only considers documents
that are added and then deleted between two successive search
operations on the same w. In the following, we borrow the formal
definitions from [5] verbatim.
Before going ahead, we first recall some leakage functions used
later. The leakage function L keeps a list Q of all queries issued
so far. Each entry of Q is either a search query (u,w) on keyword
w or an update query (u, op, in) with operation op and input in,
where u is a timestamp initially set to 0 and gradually increased
with queries.
The first leakage function we consider is search pattern sp, which
is a common leakage in most of the existing SSE schemes [5, 12].
It captures the fact that which search queries are performed on
the same keyword. More formally, the search pattern sp(w) over
keyword w is defined as
sp(w) = {u : (u,w) ∈ Q},
where sp(w) consists of the timestamps of matched search queries in
Q and thus leaks all the search queries related to the same keyword
so far.
In order to capture backward security, we recall new leakage
functions TimeDB and DelHist introduced in [5]. For a keyword w,
TimeDB(w) is a list of all non-deleted documents matchingw along
with the timestamps of inserting them in database. More formally,
TimeDB(w) is defined as
TimeDB(w) =

(u,ind) :

u, add, (w,ind)

∈ Q
and ∀u
′
,

u
′
, del, (w,ind)

< Q
	
.
Note that TimeDB(w) can be constructed simply from the query
list Q, and it is completely oblivious to any previously added document that was deleted later, but keeps all remaining information.
Specifically, it holds DB(w) = {ind : ∃u s.t. (u,ind) ∈ TimeDB(w)}.
As for DelHist(w), it is the deletion history of w and consists
of the timestamps for all deletion operations, together with the
timestamps of inserted entries removed by these operations. More
formally, DelHist(w) is defined as
DelHist(w) =

(u
add
,u
del) : ∃ ind s.t.
u
del
, del,
(w,ind)

∈ Q and
u
add
, add, (w,ind)

∈ Q
	
.
With the leakage functions described above, forward and backward security of SSE is formally defined as below.
Definition 2.4 (Forward Security of Dynamic SSE [5]).
An L-adaptively secure dynamic SSE scheme Σ =
(Setup, Search,Update) is said to be forward-secure iff the
update leakage function LUpdt can be written as
L
Updt(op, (w,ind)) = L
′
(op,ind),
where L′
is a stateless function.
Definition 2.5 (Backward Security of Dynamic SSE
[5]). An L-adaptively secure dynamic SSE scheme
Σ = (Setup, Search,Update) is said to be backward-secure
iff the search and update leakage functions LSrch and LUpdt can
be written as
LUpdt(op, (w,ind)) = L′
(op,w),
LSrch(w) = L′′(TimeDB(w), DelHist(w)),
where L′
and L′′ are stateless.
We remark that backward security given above is called weak
backward security in [5]. It is currently the highest level security
that the state-of-art dynamic SSE schemes can achieve with a single
roundtrip1
. In addition, if an SSE scheme achieves both forward
and (weak) backward security, then the leakage of update queries
is independent of both the updated keyword (cf. Def. 2.4) and the
document (cf. Def. 2.5), and hence only limited to the nature of
operations. Similar to Janus proposed in [5], our scheme in this
work also achieves the above security strength.
1Note that, a concurrent study [37] may achieve a higher-level backward security, but
it introduces an additional roundtrip.
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada    
ExptIND-PUN-CPA
A,SPE (λ) : O
Enc
msk(m,t) : OPun(t
′
i
) : OCorr() :
msk ← KeyGen(1
λ
,d); P, T ← ∅;i ← 1 ct ← Enc(msk,m,t) If t
′
i
< P, \\single query
((m0,m1,t
∗
),st) ← AO
Enc
msk(·, ·), OPun(·)
1
(1
λ
) T ← T ∪ {t } SKi ← Pun(SKi−1,t
′
i
) If t
∗ ∈ P,
s.t. m0,m1 ∈ M, |m0 | = |m1 | and t
∗ ∈ T Return ct. \\SK0 = msk return SKi
b
$←− {0, 1};ct∗ ← Enc(msk,mb
,t
∗
) P ← P ∪ {t
′
i
} Else return ⊥.
b
′ ← A
O
Enc
msk(·, ·), OPun(·), OCorr()
2
(st,ct∗
) i ← i + 1
Return (b
′ = b). Else return ⊥.
Figure 3: Semantic Security of SPE
3 SYMMETRIC PUNCTURABLE ENCRYPTION
In this section, we introduce a new cryptographic primitive, called
Symmetric Puncturable Encryption (SPE), which is a symmetric
version of puncturable encryption [19].
3.1 Syntax and Security of SPE
A symmetric d-puncturable encryption scheme SPE with message
space M and tag space T consists of a tuple of PPT algorithms
(KeyGen, Enc, Pun, Dec):
KeyGen(1
λ
,d): on input a security parameter λ and a maximum
number d of tags to be punctured, the algorithm outputs an initial
master secret key msk.
Enc(msk,m,t): on input msk, a message m ∈ M and an associated tag t ∈ T, the algorithm outputs a ciphertext ct.
Pun(SKi−1,t
′
i
): on input SKi−1 and a new tag t
′
i
, the algorithm
outputs a new punctured secret key SKi that can decrypt what
SKi−1 can decrypt except for those encrypted with t
′
i
. We note that
SK0 is the master secret key msk.
Dec(SKi
,ct,t): on input a secret key SKi and a ciphertextct w.r.t.
tag t, it outputs m or ⊥ if the decryption fails.
Correctness: For large enough security parameter λ, integer
d ∈ N
∗
, 0 ≤ i ≤ d, msk ← KeyGen(1
λ
,d), SKi ← Pun(SKi−1,t
′
i
),
message m ∈ M and t ∈ T \Ti
, where Ti  {t
′
1
, t
′
2
, . . . ,t
′
i
} ⊂ T is
an arbitrary set of distinct tags punctured in SKi
, it holds that
Pr[Dec(SKi
, Enc(msk,m,t),t) = m] = 1.
Security: The security of symmetric d-puncturable encryption
is defined by an IND-PUN-CPA experiment presented below. The
security definition is similar to the standard indistinguishability
definition for symmetric encryption, except for introducing two
new oracles: Puncture oracle and Corrupt oracle. In more details,
the Puncture oracle takes any tag t
′ ∈ T as input and updates
the current secret key to revoke t
′
. The adversary can query this
oracle adaptively but for at most d times, each time producing a new
punctured secret key. As to the Corrupt oracle, it sends back to the
adversary the most recent punctured secret key as long as it has
been punctured on the challenge tag t
∗
. The concrete description
of the experiment is shown in Figure 3.
Definition 3.1 (Semantic Security of SPE). A symmetric puncturable encryption scheme SPE is called IND-PUN-CPA secure
if for all PPT adversary A and large enough security parameter λ,
its advantage Adv
IND-PUN-CPA
A,SPE (λ) is negligible in λ, where
Adv
IND-PUN-CPA
A,SPE (λ) =




Pr[ExptIND-PUN-CPA
A,SPE (λ) = 1] − 1
2




.
Selective Security: We also consider a weaker security for SPE
schemes, which is defined by a variant of IND-PUN-CPA experiment. In contrast, the new experiment is subject to the following
conditions:
(1) Adversary is required to submit at the beginning the challenge tag t
∗
she wants to puncture later.
(2) Without loss of generality, the adversary is assumed to issue
a set of distinct puncture queries and one of them is t
∗
, say
t
′
k
= t
∗
, where k is the index of puncture query on t
∗
. A
further restriction is that t
′
j
< T for all 1 ≤ j ≤ k − 1.
Specifically, the restricted experiment is depicted in Figure 4, and
the above conditions are captured by the colored parts.
Definition 3.2 (Selective Security of SPE). A symmetric puncturable encryption scheme SPE is said to be IND-sPUN-CPA2
secure if for all PPT adversary A and large enough λ, the advantage,
Adv
IND-sPUN-CPA
A,SPE (λ), of A is negligible in λ, where
Adv
IND-sPUN-CPA
A,SPE (λ) =




Pr[ExptIND-sPUN-CPA
A,SPE (λ) = 1] − 1
2




.
To apply our SPE to design backward-secure dynamic SSE with
low local storage, it is desirable that there exist SPE schemes that
support a kind of property, named “Incremental Puncture". With this
property, the client needs only a constant-size fraction of current
secret key to delete next keyword/document pair. In the following,
we call this kind of SPE Incremental SPE or SPE with Incremental
Puncture. Intuitively, such property requires that each time a tag t
′
is revoked or punctured, a new part of secret key associated with
t
′
is produced and this partial secret key can be evaluated by only
using a constant-sized fraction of the previous secret key. Thus, the
total size of punctured secret key increases linearly in the number
of punctures, and consists of at least i + 1 parts for i-punctures.
More formally, this property is defined as below.
Incremental Puncture: Assuming the punctured secret key for
(i − 1)-punctures is in the form of SKi−1 = (msk,psk1, . . . ,pski−1)
and a subsequent punctured secret key for a new tag t
′
is SKi =
(msk′
,psk′
1
, . . . ,psk′
i−1
, psk′
i
) ← Pun(SKi−1,t
′
), we say that the
2We remark that our selective security is a bit weaker than that usually named in the
literature, since an additional condition is imposed to the puncture oracle here.
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 767
ExptIND-sPUN-CPA
A,SPE (λ) : O
Enc
msk(m,t) : OPun(t
′
i
) : OCorr() :
(t
∗
,st1) ← A1(1
λ
) s.t. t
∗ ∈ T ct ← Enc(msk,m,t) If t
′
i
< P ∧ (t
∗ ∈ P ∨ t
′
i
< T
′
), \\single query
msk ← KeyGen(1
λ
,d); P, T ← ∅;i ← 1 T ← T ∪ {t } \\T
′  T \ {t
∗
} If t
∗ ∈ P,
((m0,m1),st2) ← AO
Enc
msk(·, ·), OPun(·)
2
(st1) Return ct. SKi ← Pun(SKi−1,t
′
i
) return SKi
s.t. m0,m1 ∈ M and |m0 | = |m1 | \\SK0 = msk Else return ⊥.
b
$←− {0, 1};ct∗ ← Enc(msk,mb
,t
∗
) P ← P ∪ {t
′
i
}
b
′ ← A
O
Enc
msk(·, ·), OPun(·), OCorr()
3
(st2,ct∗
) i ← i + 1
Return (b
′ = b). Else return ⊥.
Figure 4: Selective Security of SPE
SPE scheme is incremental if for all 1 ≤ i ≤ d, there exists an
efficient algorithm IncPun such that
(1) (msk′
,psk′
i
) ← IncPun(msk,t
′
),
(2) psk′
j
= pskj for all 1 ≤ j ≤ i − 1,
which means the new punctured secret key can be evaluated via
IncPun that takes only msk and t
′
as input.
3.2 IND-PUN-CPA Secure SPE
In this part, we present a generic SPE from any public puncturable
encryption (PPE) with a specific key generation procedure.
Let PPE = (KeyGen, Enc, Pun, Dec) be an IND-PUN-CPA secure public puncturable encryption, as defined in [19]: on input a
security parameter λ, KeyGen(1
λ
) generates a master public and
secret key pair, say (mpk,msk) ← KeyGen(1
λ
); on input mpk and
(m,t), Enc(mpk,m,t) produces a ciphertextct. For other algorithms,
they are the same as those in SPE. To the end, we further require
that the master public key of the PPE be efficiently computed as a
function of msk, say mpk = f (msk). Then, it is straightforward to
get an SPE scheme SPE = (KeyGen′
, Enc′
, Pun′
, Dec′
), such that
Enc′
(msk,m,t)  Enc(f (msk),m,t) and other algorithms are identical to those of PPE.
Assuming PPE = (KeyGen, Enc, Pun, Dec) is such an IND-PUNCPA secure scheme, then it is easy to see that the SPE scheme
derived from the PPE is IND-PUN-CPA secure as well. In more
details, the reduction algorithm, given a master public key mpk
of the PPE, can easily simulate the encryption oracle of the SPE
with mpk. For other queries, e.g., puncture queries, they can be
simulated by directly leveraging its own oracle. In this case, the
reduction can perfectly answer all queries issued by the adversary,
and hence the security of the SPE follows readily from that of the
PPE.
Following the above framework, we can get a concrete INDPUN-CPA secure SPE from an existing PPE scheme (e.g., [13, 19]).
However, the scheme derived in this way either suffers from a
heavy computation cost or cannot support incremental puncture,
which is more of a feasibility result than a practical solution. In
the following section, we present a novel Incremental SPE scheme,
which is only IND-sPUN-CPA secure yet well suited for our SSE
application.
3.3 Incremental SPE from Pun-PRF
In this section, we present a novel SPE based on a Pun-PRF F : K ×
X → Y with algorithms (F.Punc, F.Eval), a symmetric encryption
scheme SE = (SE.Enc, SE.Dec) and a cryptographic hash function
H : K × N
∗ → K. In more details, our generic SPE scheme SPE =
(KeyGen, Enc, Pun, Dec) is constructed as follows:
KeyGen(1
λ
,d): on input a security parameter λ and a positive
integer d, it chooses a random key sk0 uniformly at random from
K, and sets msk = (sk0,d).
Enc(msk,m,t): on input msk = (sk0,d) and a message m ∈ M
along with tag t ∈ T, it computes the ciphertext for m under t in
the following way:
(1) Compute ski = H(ski−1,i) for all 1 ≤ i ≤ d.
(2) Calculate k =
É
d
i=0
F (ski
,t), and compute ct = SE.Enc(k,m).
(3) Output the ciphertext ct together with the corresponding
tag t.
Pun(SKi−1,t
′
i
): on input a new tag t
′
i
and SKi−1 =

mski−1,
psk1,psk2, . . . ,pski−1

for tags {t
′
1
,t
′
2
, . . . , t
′
i−1
}, where mski−1 =
(ski−1,d) and SK0 = msk, it generates the new punctured secret
key SKi as follows:
(1) Compute pski = F.Punc(ski−1,t
′
i
) and ski = H(ski−1,i),
(2) Set mski = (ski
,d) and output the new secret key SKi =
mski
,psk1,psk2, . . . ,pski

.
Dec(SKi
,ct,t): on input a secret key SKi =

mski
,psk1,
psk2, . . . ,pski

and a ciphertextct associated with tag t, it decrypts
ct as follows:
(1) If i < d, first compute skℓ = H(skℓ−1
, ℓ) for all i + 1 ≤ ℓ ≤ d;
otherwise (i.e., i = d), directly proceed to the following step.
(2) Evaluate k
′ =
É
i
s=1
F.Eval(psks ,t) ⊕ É
d
ℓ=i
F (skℓ
,t) and recover
message m′ = SE.Dec(k
′
,ct).
Correctness: The correctness of our SPE follows readily from
that of the Pun-PRF F and the symmetric encryption SE. For
SKi =

mski
,psk1,psk2, . . . ,pski

associated with tags Ti =
{t
′
1
,t
′
2
, . . . ,t
′
i
} and ct attached with t, we have that
Ê
i
s=1
F.Eval(psks ,t) =
Ê
i
s=1
F (sks−1,t)
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada    
if t < Ti
, which derives from the fact that for all s ∈ [1,i]
F.Eval(psks ,t) = F (sks−1,t) if t , t
′
s
. Then, we get that
Ê
i
s=1
F.Eval(psks ,t) ⊕Ê
d
ℓ=i
F (skℓ
,t) =
Ê
d
j=0
F (skj
,t)
and thus k
′ = k. Finally, the message can be correctly recovered by
computing m = SE.Dec(k
′
,ct).
3.4 Security Analysis
In this part, we show that the proposed SPE scheme can be proven
IND-sPUN-CPA secure in the random oracle model, under the
security of Pun-PRF F and SE.
Theorem 3.3 (Selective Security). Assuming that F : K×X →
Y is a secure Pun-PRF, H is modeled as a random oracle and SE is
an IND-CPA secure symmetric encryption, then the proposed SPE is
IND-sPUN-CPA secure in the random oracle model.
Proof. We prove the security of our SPE scheme through a
series of games. In the following, we denote by Gamei the i-th game,
and PrGi
[E] the probability that an event E happens in Gamei
.
Game0: it is exactly the same as the real experiment for selective
security (cf. Def. 3.2). More specifically, when receiving challenge
tag t
∗
, challenger C generates msk = (sk0,d) by running msk ←
KeyGen(1
λ
,d), and then responds to adversary’s encryption queries
(m,t) with msk. For the j-th puncture query t
′
j
, C uses the most
recent secret key SKj−1 =

mskj−1,psk1,psk2, . . . ,pskj−1

to compute pskj = F.Punc(skj−1,t
′
j
) and skj = H(skj−1, j). Then C sets
SKj =

mskj = (skj
,d),psk1,psk2, . . . ,pskj

and adds t
′
j
to P. For
corrupt query, C returns the most recent secret key SKi
if t
∗ ∈ P,
otherwise returns ⊥. When receiving challenge messages (m0,m1),
C randomly picks b ∈ {0, 1}, generatesct∗ ← Enc(msk,mb
,t
∗
) and
sends back ct∗
. At last, the adversary A outputs its guess b
′
.
Without loss of generality, we assume that A issues in total
i distinct puncture queries {t
′
1
,t
′
2
, . . . ,t
′
i
} and the k-th puncture
query is t
∗
(i.e., t
′
k
= t
∗
), where k ∈ [1,i] and i ≤ d. Recall that the
hash function H is modeled as a random oracle. By the Definition
3.2, it is easy to get that
Adv
IND-sPUN-CPA
A,SPE (λ) =




Pr G0
[b
′ = b] − 1
2




.
Game1: in this game, all {ski }i ∈[d]
s.t. ski = H(ski−1,i) are
computed at the setup of the game, and then used directly to answer
the following queries. Obviously, it is essentially identical to the
previous one. Thus, we have that
Pr G1
[b
′ = b] = Pr G0
[b
′ = b].
Game2: the only difference of this game from Game1 is that
{ski }i ∈[k] are chosen uniformly at random, rather than produced
by calling the random oracle H. More concretely, all {ski }i ∈[d]
in
this game are generated in the following way:
(1) sk0,sk1, . . . ,skk
$←− K,
(2) ski = H(ski−1,i) for i ∈ [k + 1,d].
Regarding the remaining queries, they are answered directly
with these keys.
Lemma 3.4. Assuming that F is a secure Pun-PRF and H is a random oracle, then Game2 and Game1 are computationally indistinguishable. That is,

Pr G2
[b
′ = b] − Pr G1
[b
′ = b]


≤ (2d + 1)Adv
Pun-PRF
B,F
(λ) + d · QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y | 
,
where d and QH are the maximum number of puncture queries and
random oracle queries made by A, respectively.
Game3: this game differs from the previous one only in the
generation of ciphertexts under t
∗
. The challenger in this game
chooses k
∗ ∈ K uniformly at random, instead of computing it as
k
∗ =
É
d
i=0
F (ski
,t
∗
), and then uses it to encrypt all messages with
tag t
∗
. More precisely, C answers the encryption queries and the
challenge query as follows:
• For an encryption query (m,t), it directly computes ct =
SE.Enc(k
∗
,m) if t = t
∗
, otherwise (i.e., t , t
∗
) calculates
k =
É
d
i=0
F (ski
,t) first and then computes ct = SE.Enc(k,m).
• For the challenge query (m0,m1), it randomly chooses b
$←−
{0, 1}, and then computes ct∗ = SE.Enc(k
∗
,mb
).
Lemma 3.5. Assuming that F is a secure Pun-PRF, then Game3
and Game2 are computationally indistinguishable. That is,

Pr G3
[b
′ = b] − Pr G2
[b
′ = b]

 ≤ 2Adv
Pun-PRF
B,F
(λ).
Moreover, we will show that the advantage of A winning in
Game3 is negligible under the IND-CPA security of the underlying
symmetric encryption scheme SE, which is formally stated as below.
Lemma 3.6. Assuming that SE is an IND-CPA secure symmetric
encryption scheme, then it holds that




Pr G3
[b
′ = b] − 1
2




= Adv
IND-CPA
D,SE (λ).
Suppose all above lemmata hold, then it is easy to get:
Adv
IND-sPUN-CPA
A,SPE (λ)
=

Pr G0
[b
′ = b] − 1
2


≤

Pr G1
[b
′ = b] − Pr G2
[b
′ = b]

 +

Pr G2
[b
′ = b] − Pr G3
[b
′ = b] + | Pr G3
[b
′ = b] − 1
2


≤ (2d + 3)Adv
Pun-PRF
B,F
(λ) + d · QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y | 
+Adv
IND-CPA
D,SE (λ).
Now what remains to do is to show the above lemmata hold. First
of all, we will prove Lemma 3.4, showing Game2 and Game1 are
computationally indistinguishable. Note that, the only difference of
these two games is the replacement of {ski }i ∈[k] by random strings,
which is not a problem unless the event that one of {ski }i ∈[k]
is
equal to one of the adversary’s H-queries happens. At first glance,
it seems that the probability of the event happening can be easily
bounded with the “random" distribution of ski
. In fact, it is not an
easy task since the responses to either puncture queries or encryption queries will reduce the entropy of ski
. Instead, we prove the
lemma step-by-step, which is achieved through the following two
claims.
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 7  
Proof of lemma 3.4. Before going ahead, we first define a sequence of games Game1.ℓ for ℓ ∈ [0, k]. In fact, Game1, ℓ is the
same as Game1, except that sk0,sk1, . . . ,skℓ are chosen uniformly
at random from K. Specifically, Game1.0 and Game1.k are exactly
Game1 and Game2, respectively.
Next we intend to show any two successive games Game1.ℓ and
Game1.ℓ+1 are computationally indistinguishable, then we can get
the indistinguishability between Game1 and Game2 by combining
them altogether. To this end, we argue the following two claims
hold.
Claim 1. Assuming that F is a secure Pun-PRF and H is a random
oracle, then Game1.ℓ and Game1.ℓ+1 are computationally indistinguishable for all ℓ ∈ [0, k − 2]. That is,

Pr G1.ℓ+1
[b
′ = b] − Pr G1.ℓ [b
′ = b]


≤ 2Adv
Pun-PRF
B,F
(λ) + QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y | 
,
where QH is the number of A’s random oracle queries.
Proof of Claim 1. We note that the only difference of
Game1.ℓ+1
from Game1.ℓ is that skℓ+1
is produced by randomly
choosing from K, rather than by computing skℓ+1 = H(skℓ
, ℓ + 1).
Thus, if the adversary A does not make any H-query on (skℓ
, ℓ +1)
in Game1.ℓ (recall that H is a random oracle), then these two games
are identically distributed from the point of A’s view. Therefore,
we have that

Pr G1.ℓ+1
[b
′ = b] − Pr G1.ℓ [b
′ = b]

 ≤ Pr G1.ℓ [Eℓ
],
where Eℓ denotes the event A makes some H-query on (skℓ
, ℓ + 1).
Next, we are going to bound the probability of Eℓ happening in
Game1.ℓ. Suppose that Eℓ occurs in Game1.ℓ with a non-negligible
probability, then there exists an efficient algorithm B that can
successfully break the security of the Pun-PRF F . More precisely,
the algorithm B that simulates Game1.ℓ is described as follows.
When receiving challenge tag t
∗
from A, the simulator B(1
λ
)
with evaluation oracle O
Eval
skℓ
(·) picks sk0, . . . ,skℓ−1
, skℓ+1
randomly from K, where skℓ
is a randomly chosen PRF key and skℓ+1
is implicitly set as H(skℓ
, ℓ+1). Then, B computesski = H(ski−1,i)
for all i ∈ [ℓ + 2,d] and adds the tuple
(ski−1,i),ski

to an initially
empty H-query list LH , which is used to keep track of all H queries
made by A. After that, B uses {ski }i ∈[0,d]\{ℓ } and his own oracle
O
Eval
skℓ
(·) to simulate all queries in the following way:
• For an H-query (sk′
,i
′
), first checks if this query is contained in LH . If so, directly returns the corresponding sk s.t.

(sk′
,i
′
),sk
∈ LH . Otherwise, outputs sk $←− K and records

(sk′
,i
′
),sk
to LH .
• For an encryption query (m,t), directly forwardst to his own
evaluation oracle O
Eval
skℓ
(·) and gets back the value F (skℓ
,t)
of PRF F (skℓ
, ·) on t. Then computes k =
É
d
i=0
F (ski
,t) and
ct = SE.Enc(k,m), sends ct back to A and adds the tag t to
T.
• For the j-th puncture query t
′
j
, directly returns ⊥ if j < k
(i.e., t
∗ < P) and t
′
j
∈ T
3
. Otherwise, responds to this query
as follows:
– j , ℓ + 1: directly uses skj−1 to compute pskj =
F.Punc(skj−1,t
′
j
).
– j = ℓ + 1: forwards t
′
j
to his own challenger, and gets back
(psk,y) s.t. psk = F.Punc(skℓ
,t
′
j
) and
y =

F (skℓ
,t
′
j
), δ = 1
u, δ = 0
where u
$←− Y, then sets pskj = psk and adds t
′
j
to P.
At last, B sets SKi = (mski
,psk1,psk2, . . . ,pski) after A
made all puncture queries {t
′
1
,t
′
2
, . . . ,t
′
i
}, where mski =
(ski
,d), and then returns SKi when the corrupt query is
issued.
• For the challenge query (m0,m1), first uses psk to evaluate F (skℓ
,t
∗
) = F.Eval(psk,t
∗
), where t
∗ , t
′
ℓ+1
, and then
computes k
∗ =
É
d
i=0
F (ski
,t
∗
) and ct∗ = SE.Enc(k
∗
,mb
).
Finally, A outputs its guess on b, and then B returns his guess
on δ as below:
• For all
(sk′
, ℓ + 1),sk
∈ LH , chooses a test x ∈ X s.t. x ,
t
′
ℓ+1
and checks if there exists some sk′
satisfying F (sk′
, x) =
F.Eval(psk, x)(= F (skℓ
, x)). If not, directly outputs a random
guess δ
′
$←− {0, 1}.
• Otherwise, further checks if y = F (sk′
,t
′
ℓ+1
). If so, outputs
δ
′ = 1, else returns δ
′ = 0.
At this point, we complete the entire description of B. Hereafter,
we denote the simulated game above by Games im
1.ℓ . It is easy to
see from the above that B perfectly simulates Game1.ℓ before the
event Eℓ happens, so we get that
Pr G1.ℓ [Eℓ
] = Pr G
s im
1.ℓ
[Eℓ
].
Currently, we only need to analyze the probability of Eℓ happening in Games im
1.ℓ . For clarity, we denote by E
′
ℓ
the event that
there exists some (sk′
, ℓ + 1) ∈ LH s.t. F (sk′
, x) = F.Eval(psk, x)
for any x , t
′
ℓ+1
, and let Col be the event that there exists some
(sk′
, ℓ + 1) ∈ LH s.t. sk′ , skℓ but F (sk′
, x) = F.Eval(psk, x). From
the simulation, we know
Pr G
s im
1.ℓ
[BO
Eval
skℓ
(·)(1
λ
, (psk,y)) = δ]
= Pr G
s im
1.ℓ
[δ
′ = δ |E
′
ℓ
] Pr G
s im
1.ℓ
[E
′
ℓ
]+
Pr G
s im
1.ℓ
[δ
′ = δ |E¯′
ℓ
] Pr G
s im
1.ℓ
[E¯′
ℓ
]
≥ Pr G
s im
1.ℓ
[δ
′ = δ ∧ Eℓ
|E
′
ℓ
] Pr G
s im
1.ℓ
[E
′
ℓ
] +
1
2
Pr G
s im
1.ℓ
[E¯′
ℓ
]
= Pr G
s im
1.ℓ
[δ
′ = δ |Eℓ
] Pr G
s im
1.ℓ
[Eℓ
|E
′
ℓ
] Pr G
s im
1.ℓ
[E
′
ℓ
]+
1
2
(1 − Pr G
s im
1.ℓ
[E
′
ℓ
])
= Pr G
s im
1.ℓ
[Eℓ
] +
1
2
(1 − Pr G
s im
1.ℓ
[E
′
ℓ
])
≥
1
2
+ Pr G
s im
1.ℓ
[Eℓ
] − 1
2
(Pr G
s im
1.ℓ
[Eℓ
] + Pr G
s im
1.ℓ
[Col])
=
1
2
+
1
2
Pr G
s im
1.ℓ
[Eℓ
] − 1
2
Pr G
s im
1.ℓ
[Col].
3Recall that, t
′
j
for all j ∈ [1, k − 1] should not belong to the most recent set T of
encryption tags according to the second restriction (cf. Def. 3.2).
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada    
where the third equality follows from the fact that B can always
guess correctly (i.e., δ
′ = δ) conditioned on Eℓ
. Hence, we get that
Pr G
s im
1.ℓ
[Eℓ
] ≤ 2Adv
Pun-PRF
B,F
(λ) + Pr G
s im
1.ℓ
[Col].
Next, we continue to show that
Pr G
s im
1.ℓ
[Col] ≤ QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y| 
,
where QH is the number of H queries made by A in Games im
1.ℓ . To
this goal, we only need to prove that, for any x ∈ X and sk′ ∈ K
s.t. sk′ , skℓ
, it holds that
Pr[F (sk′
, x) = F (skℓ
, x)|sk′ , skℓ
] ≤ Adv
PRF
B′
,F
(λ) +
1
|Y| ,
where skℓ
is a randomly chosen PRF key. The analysis is carried
out as below.
On input a security parameter λ, the adversary B
′
chooses a
secret key sk′ ∈ K and a test x ∈ X, then sends x to the challenger
of PRF F and gets back y, such that
y =

F (skℓ
, x), b = 1
f (x), b = 0
where f is a truly random function with the same domain and
range as F . After that, B
′
checks if F (sk′
, x) = y. If so, outputs its
guess b
′ = 1, otherwise b
′ = 0.
Now it is easy to derive from the above that
Pr[b
′ = 1|b = 1]
= Pr[F (sk′
, x) = F (skℓ
, x)]
= Pr[F (sk′
, x) = F (skℓ
, x)|sk′ = skℓ
] Pr[sk′ = skℓ
]+
Pr[F (sk′
, x) = F (skℓ
, x)|sk′ , skℓ
] Pr[sk′ , skℓ
]
≥ Pr[F (sk′
, x) = F (skℓ
, x)|sk′ , skℓ
]
and
Pr[b
′ = 1|b = 0] = Pr[F (sk′
, x) = f (x)] =
1
|Y| ,
from which we can further deduce that
Pr[F (sk′
, x) = F (skℓ
, x)|sk′ , skℓ
] ≤ Adv
PRF
B′
,F
(λ) +
1
|Y| .
Combining all (in)equalities above, we have that

Pr G1.ℓ+1
[b
′ = b] − Pr G1.ℓ [b
′ = b]


≤ 2Adv
Pun-PRF
B,F
(λ) + QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y | 
.

Claim 2. Assuming that F is a secure Pun-PRF and H is a random
oracle, then Game1.k−1 and Game1.k are computationally indistinguishable. That is,

Pr G1.k
[b
′ = b] − Pr G1.k−1
[b
′ = b]


≤ 3Adv
Pun-PRF
B,F
(λ) + QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y | 
.
Proof of Claim 2. The main idea of this proof is similar to that
of Claim 1, except for involving a more complicated reduction. Since
the only difference of Game1.k
from Game1.k−1
is that skk
is randomly chosen from K rather than generated as skk = H(skk−1
, k),
the views of A in these two games are identically distributed if A
does not make any H-query on (skk−1
, k) in Game1.k−1
. Thus, we
have that

Pr G1.k
[b
′ = b] − Pr G1.k−1
[b
′ = b]

 ≤ Pr G1.k−1
[Ek−1
],
where Ek−1 denotes the event that A makes some H-query on
(skk−1
, k).
Next we analyze the probability that Ek−1 occurs in Game1.k−1
through a simulated game Games im
1.k−1
, which is detailed as follows.
Whenever receiving a challenge tag t
∗
, the simulator B(1
λ
) with
evaluation oracle O
Eval
skk−1
(·) forwards t
∗
to his own challenger and
gets back (psk,y) s.t. psk = F.Punc(skk−1
,t
∗
) and
y =

F (skk−1
,t
∗
), δ = 1
u, δ = 0
where skk−1
is a randomly chosen PRF key and u is a random element of Y. Then, B randomly chooses sk0, . . . , skk−2
,skk
from
K, where skk
is implicitly set as H(skk−1
, k), computes ski =
H(ski−1,i) for all i ∈ [k + 1,d] and adds
(ski−1,i),ski

to an
initially empty H-query list LH . After that, B uses (psk,y) and
{ski }i ∈[0,d]\{k−1}
to simulate all queries in the following way:
• For an H-query (sk′
,i
′
), first checks if this query is contained in LH . If so, directly outputs the corresponding sk s.t.

(sk′
,i
′
),sk
∈ LH . Otherwise, returns sk $←− K and records

(sk′
,i
′
),sk
to LH .
• For an encryption query (m,t), first checks if t = t
∗
. If
so, evaluates k = y ⊕
É
d
i=0,,k−1
F (ski
,t
∗
), otherwise k =
F.Eval(psk,t)
É
d
i=0,,k−1
F (ski
,t), then computes and sends
back ct = SE.Enc(k,m), and adds t to T.
• For the j-th puncture query t
′
j
, directly returns ⊥ if j < k
and t
′
j
∈ T. Otherwise, responds to this query as follows:
– j , k: uses skj−1 straightforwardly to compute pskj =
F.Punc(skj−1,t
′
j
).
– j = k: directly sets pskj = psk. Recall that in this case
t
′
k
= t
∗
and psk = F.Punc(skk−1
,t
∗
).
At last, B sets SKi = (mski
,psk1,psk2, . . . ,pski) after A
made all puncture queries {t
′
1
,t
′
2
, . . . ,t
′
i
}, where mski =
(ski
,d). Then, B returns SKi when the corrupt query is issued.
• For the challenge query (m0,m1), first computes
k
∗ = y ⊕
Ê
d
i=0,,k−1
F (ski
,t
∗
)
and then returns ct∗ = SE.Enc(k
∗
,mb
).
Finally, A outputs its guess b
′
. Then B returns his guess δ
′
as
below:
• For all
(sk′
, k),sk) ∈ LH , chooses a test x ∈ X s.t. x , t
∗
and checks if there exists some sk′
satisfying F (sk′
, x) =
F.Eval(psk, x)(= F (skk−1
, x)). If not, directly outputs a random guess δ
′
$←− {0, 1}.
• Otherwise, further checks if y = F (sk′
,t
∗
). If so, outputs
δ
′ = 1, else returns δ
′ = 0.
Now we complete the description of Games im
1.k−1
. First of all,
we intend to give an upper-bound on the probability of Ek−1 happening in Games im
1.k−1
. Essentially, the analysis of Pr G
s im
1.k−1
[Ek−1
] is
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada     
identical to that of Pr G
s im
1.ℓ
[Eℓ
]. By a similar analysis, we get that
Pr G
s im
1.k−1
[Ek−1
] ≤ 2Adv
Pun-PRF
B,F
(λ) + QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y| 
.
Next, we proceed to bound the probability of Ek−1 happening
in Game1.k−1
. We remark that the challenge ciphertext and encryption queries on t
∗
in Games im
1.k−1
are not perfectly simulated
as in Games im
1.ℓ , so we cannot directly argue that Pr G1.k−1
[Ek−1
] =
Pr G
s im
1.k−1
[Ek−1
]. Instead, we will show that they are negligibly close
to each other. In the following, we denote by Real and Rand the
events “y = F (skk−1
,t
∗
)” (i.e., δ = 1) and “y = u” (i.e., δ = 0),
respectively. Then, we have that
| Pr G1.k−1
[Ek−1
] − Pr G
s im
1.k−1
[Ek−1
]|
= | Pr G1.k−1
[Ek−1
] − 1
2
Pr G
s im
1.k−1
[Ek−1
|Real]−
1
2
Pr G
s im
1.k−1
[Ek−1
|Rand]|
=
1
2
| Pr G
s im
1.k−1
[Ek−1
|Real] − Pr G
s im
1.k−1
[Ek−1
|Rand]|

1
2
| Pr G
s im
1.k−1
(Real)
[Ek−1
] − Pr G
s im
1.k−1
(Rand)
[Ek−1
]|,
where the second equality follows from the fact that B perfectly
simulates Game1.k−1 before Ek−1 happens, in the case of y =
F (skk−1
,t
∗
).
Thus, we only need to argue that Pr G
s im
1.k−1
(Real)
[Ek−1
] and
Pr G
s im
1.k−1
(Rand)
[Ek−1
] are negligibly close to each other, which is
demonstrated by a reduction to the security of the Pun-PRF. Essentially, the reduction is the same as the simulation of Game1.k−1
,
except that the simulator adopts a different strategy to output his
guess on δ. In particular, the reduction is conducted as follows.
Whenever receiving a challenge tag t
∗
, the simulator B(1
λ
) with
evaluation oracle O
Eval
skk−1
(·) forwards t
∗
to his own challenger and
gets back (psk,y) s.t. psk = F.Punc(skk−1
,t
∗
) and
y =

F (skk−1
,t
∗
), δ = 1
u, δ = 0
where u
$←− Y and skk−1
is a randomly chosen PRF key. Then,
B picks sk0, . . . , skk−2
,skk uniformly at random from K, where
skk
is implicitly set as H(skk−1
, k), computes ski = H(ski−1,i) for
all i ∈ [k + 1,d] and adds
(ski−1,i),ski

to an initially empty Hquery list LH . After that, B uses (psk,y) and {ski }i ∈[0,d]\{k−1}
to
simulate all the following queries:
• For an H-query (sk′
,i
′
), checks if this query is contained in
LH . If so, directly returns the associated sk s.t.
(sk′
,i
′
),sk
∈
LH . Otherwise, outputs sk $←− K and records
(sk′
,i
′
),sk
to LH .
• For an encryption query (m,t), first checks if t = t
∗
.
If so, evaluates k = y ⊕
É
d
i=0,,k−1
F (ski
,t
∗
), otherwise
k = F.Eval(psk,t)
É
d
i=0,,k−1
F (ski
,t). Then, computes ct =
SE.Enc(k,m), returns it and adds t to T.
• For the j-th puncture query t
′
j
, directly returns ⊥ if j < k
and t
′
j
∈ T. Otherwise, responds this query as follows:
– j , k: directly uses skj−1 to compute pskj =
F.Punc(skj−1,t
′
j
).
– j = k: directly sets pskj = psk. Recall that in this case
t
′
k
= t
∗
.
At last, B sets SKi = (mski
,psk1,psk2, . . . ,pski) after A
made the last puncture query t
′
i
, wheremski = (ski
,d). Then,
SKi
is returned when the adversary issues the corrupt query.
• For the challenge query (m0,m1), first computes
k
∗ = y ⊕
Ê
d
i=0,,k−1
F (ski
,t
∗
)
and then returns ct∗ = SE.Enc(k
∗
,mb
).
Finally, A outputs its guess b
′
. Then B chooses a test x ∈ X s.t.
x , t
∗
, and checks if there exists some sk′
satisfying F (sk′
, x) =
F.Eval(psk, x) for all
(sk′
, k),sk) ∈ LH . If so, outputs 1, otherwise
returns 0.
In the following, we denote by E
′
k−1
the event that there exists
some (sk′
, k) ∈ LH s.t. F (sk′
, x) = F.Eval(psk, x) for any x , t
∗
, and
Col the event that there exists some (sk′
, k) ∈ LH s.t. sk′ , skk−1
but F (sk′
, x) = F.Eval(psk, x). Then, we have that
Pr[BO
Eval
skk−1
(·)(Real) = 1]
= Pr G
s im
1.k−1
(Real)
[E
′
k−1
]
= Pr G
s im
1.k−1
(Real)
[Ek−1
] + Pr G
s im
1.k−1
(Real)
[Col]
and
Pr[BO
Eval
skk−1
(·)(Rand) = 1]
= Pr G
s im
1.k−1
(Rand)
[E
′
k−1
]
= Pr G
s im
1.k−1
(Rand)
[Ek−1
] + Pr G
s im
1.k−1
(Rand)
[Col].
Moreover, since Pr G
s im
1.k−1
(Real)
[Col] = Pr G
s im
1.k−1
(Rand)
[Col] =
Pr G
s im
1.k−1
[Col], it holds that
Pr G
s im
1.k−1
(Real)
[Ek−1
] − Pr G
s im
1.k−1
(Rand)
[Ek−1
]
= Pr[BO
Eval
skk−1
(·)(Real) = 1] − Pr[BO
Eval
skk−1
(·)(Rand) = 1]
≤ 2Adv
Pun-PRF
B,F
(λ).
Thus, we get that
| Pr G1.k−1
[Ek−1
] − Pr G
s im
1.k−1
[Ek−1
]|
=
1
2
| Pr G
s im
1.k−1
(Real)
[Ek−1
] − Pr G
s im
1.k−1
(Rand)
[Ek−1
]|
≤ Adv
Pun-PRF
B,F
(λ).
Combining all (in)equalities above, we have that

Pr G1.k
[b
′ = b] − Pr G1.k−1
[b
′ = b]


≤ 3Adv
Pun-PRF
B,F
(λ) + QH ·

Adv
PRF
B′
,F
(λ) +
1
|Y | 
.

Eventually, with Claim 1 and Claim 2 we finish the proof of
Lemma 3.4.
Proof of lemma 3.5. Suppose that there is an efficient adversary A capable of distinguishing Game2 and Game3 with a nonnegligible probability, then we can design an efficient algorithm B
to successfully break the security of the Pun-PRF F , the details of
which are shown as below.
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada      
On input a security parameter λ, the algorithm B(1
λ
) with evaluation oracle O
Eval
skk−1
(·), where skk−1
is a randomly chosen master
key of PRF F , simulates a hybrid game in the following way.
When receiving a challenge tag t
∗
from A, the simulator B
directly forwards it (implicitly set as his own challenge) to the
challenger CF of the Pun-PRF F and gets back (psk,y), such that
psk = F.Punc(skk−1
,t
∗
) and
y =

F (skk−1
,t
∗
), δ = 1
u, δ = 0
where u is chosen uniformly at random from Y. After that, B randomly picks sk0, . . . ,skk−2
,skk ∈ K, computes ski = H(ski−1,i)
for i ∈ [k + 1,d], and then uses (psk,y) and {ski }i ∈[0,d]\{k−1}
to
simulate all the following queries:
• For an encryption query (m,t), B checks if t = t
∗
and responds to the query as:
– t = t
∗
: first uses y to compute
k = y ⊕
Ê
d
i=0,,k−1
F (ski
,t),
and then generates ct = SE.Enc(k,m).
– t , t
∗
: first uses psk to evaluate
k = F.Eval(psk,t) ⊕ Ê
d
i=0,,k−1
F (ski
,t),
and then computes ct = SE.Enc(k,m).
• For the j-th puncture query t
′
j
, B sets pskj = psk if j = k
(i.e., t
′
j
= t
∗
), otherwise computes pskj = F.Punc(skj−1,t
′
j
).
After A made the last puncture query t
′
i
, B sets SKi =
(mski
,psk1,psk2, . . . ,pski) where mski = (ski
,d), and returns SKi when A issues the corrupt query.
• For the challenge query (m0,m1), B first calculates
k
∗ = y ⊕
Ê
d
i=0,,k−1
F (ski
,t
∗
),
and then generates the challenge ciphertext as ct∗ =
SE.Enc(k
∗
,mb
), where b
$←− {0, 1}.
Finally, B outputs δ
′ = 1 if A’s guess b
′ = b, otherwise 0.
From the above, it is easy to observe that B perfectly simulates
Game2 if y = F (skk−1
,t
∗
), otherwise conducts a perfect simulation
of Game3. Hence, we have that Pr[δ
′ = 1|δ = 1] = Pr G2
[b
′ =
b] and Pr[δ
′ = 1|δ = 0] = Pr G3
[b
′ = b]. Thus, it holds that

Pr G3
[b
′ = b] − Pr G2
[b
′ = b]

 ≤ 2Adv
Pun-PRF
B,F
(λ).

Proof of lemma 3.6. The proof of this lemma can be easily reduced to the IND-CPA security of SE. Suppose that there exists an
efficient adversary A that can guess b correctly in Game3 with a
non-negligible advantage. Then we can leverage A to construct an
algorithm D that can efficiently break the IND-CPA security of SE
with a non-negligible probability as below.
On input a security parameter λ, the algorithm D(1
λ
) with
encryption oracle O
Enc
k
∗ (·), where k
∗ ∈ K is chosen uniformly
at random, simulates Game3 as follows. Whenever receiving t
∗
from A, D randomly picks sk0,sk1, . . . ,skk ∈ K, computes
ski = H(ski−1,i) for all i ∈ [k + 1,d], and then uses {ski }i ∈[0,d]
to
answer all queries in the following way:
• For an encryption query (m,t), D checks if t = t
∗
and answers this query as:
– t = t
∗
: directly forwards the message m to its own
encryption oracle O
Enc
k
∗ (·) and sends back the response
ct = SE.Enc(k
∗
,m).
– t , t
∗
: first evaluates k =
É
d
i=0
F (ski
,t), and then computes
and returns ct = SE.Enc(k,m).
• For the j-th puncture query t
′
j
, D generates a new secret
key SKj by computing pskj = F.Punc(skj−1,t
′
j
) and setting
SKj = (mskj
,psk1, psk2, . . . ,pskj). After A made the last
puncture query t
′
i
, D sets SKi = (mski
,psk1,psk2, . . . ,pski)
where mski = (ski
,d), and returns SKi when the corrupt
query is issued.
• For the challenge query (m0,m1), D forwards the messages
(m0,m1) to its own challenger and then sends the response
ct∗ = SE.Enc(k
∗
,mb
) back to A.
At last, the algorithm D returns what A outputs. From the above,
it is easy to see that D perfectly simulates Game3. Therefore, we
get that




Pr G3
[b
′ = b] − 1
2




= Adv
IND-CPA
D,SE (λ).

By combining all above proofs, we get the IND-sPUN-CPA security of our SPE scheme in the random oracle model (cf. Theorem
3.3). In fact, our initial attempt is to generate ski with a PRF rather
than a cryptographic hash H, thus we could get rid of the random
oracle. Unfortunately, we find that the puncture queries cannot
be simulated in this case. In addition, our scheme is only proven
selectively secure. It might be improved to the adaptive security by
leveraging the existing techniques for transforming selective security to full security [1, 2, 14]. We leave the construction of practical
adaptively-secure incremental SPE scheme without random oracles
as the future work.
4 DYNAMIC SSE FROM INCREMENTAL SPE
In this section, we present a generic construction of dynamic SSE
based on Incremental SPE. After that, we propose an instantiation
on the basis of the well-known GGM PRF [18].
4.1 Generic Construction
Our dynamic SSE scheme follows the adaption of puncturable encryption as in [5]. The major difference is that our scheme replaces
the adopted public puncturable encryption [19] with Incremental
SPE for deletion, while the protocol between client and server is
similar to their scheme Janus except for a few modifications remarked later. The main idea here is to use two forward-secure
SSE instances to achieve backward security, one instance Σadd for
storing inserted indices encrypted by our SPE scheme and the other
Σdel for storing punctured key shares w.r.t. deleted indices. When
conducting a search query on w, server runs the search protocol
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 773   
Algorithm 1 Dynamic SSE Σ from Incremental SPE
Setup(1
λ
)
1: (EDBadd, Kadd, σadd)← Σadd.Setup(1
λ
)
2: (EDBdel, Kdel, σdel)← Σdel.Setup(1
λ
)
3: Ks ,Kt
$←− {0, 1}
λ
, MSK, PSK, DEL, SC, EDBcache ← ∅
4: return ((EDBadd, EDBdel, EDBcache ), (Kadd,Kdel,Ks , Kt
),
(σadd, σdel, MSK, PSK, DEL, SC))
Search(KΣ,w, σ; EDB)
Client:
1: i ← SC[w], msk′ ← PSK[w]
2: if i =⊥ then
3: return ∅
4: end if
5: Send msk′
and tkn = F (Ks ,w) to the server
6: d ← dw , DEL[w] ← d ◃ Reset the number of deletions for w
7: msk ← SPE.KeyGen(1
λ
,d) ◃ Update msk for w after search
8: MSK[w] ← msk, PSK[w] ← msk, SC[w] ← i + 1
Client & Server:
9: Run Σadd.Search(Kadd,w||i, σadd; EDBadd), and the server gets
a list ((ct1,t1), (ct2,t2), . . . ,(ctn,tn)) of ciphertexts and tags
10: Run Σdel.Search(Kdel,w||i, σdel; EDBdel), and the server gets
a list (psk1,t
′
1
), (psk2,t
′
2
), . . . ,(pskm,t
′
m)) of punctured key
shares and tags
Server:
11: Server uses SK = (msk′
,psk1, . . . ,pskm) to decrypt each entry
of the ciphertext list as below
12: for i ∈ [1,n] do
13: indi = SPE.Dec(SK,cti
,ti)
14: NewR← NewR ∪ {(indi
,ti)}
15: end for
16: OldR← EDBcache [tkn]
17: OldR← OldR\{(ind,t) : ∃i ∈ [1,m],t = t
′
i
}
18: Res← NewR ∪ OldR, EDBcache [tkn] ← Res
19: return Res
Update(KΣ, op, (w,ind), σ; EDB)
Client:
1: t ← FKt
(w,ind)
2: msk ← MSK[w], msk′ ← PSK[w], i ← SC[w], d ← DEL[w]
3: if msk =⊥ then
4: d ← dw , DEL[w] ← d ◃ Set the number of deletions for w
5: msk ← SPE.KeyGen(1
λ
,d)
6: MSK[w] ← msk, PSK[w] ← msk
7: i ← 0, SC[w] ← i
8: end if
9: if op = add then
10: ct = SPE.Enc(msk,ind,t) ◃ Fixed msk before next search
11: Run Σadd.Update(Kadd, add,w||i, (ct,t), σadd; EDBadd)
12: else
13: (msk′
,pskt ) ← SPE.IncPun(msk′
,t)
14: Run Σdel.Update(Kdel, add,w||i, (pskt
,t), σdel; EDBdel)
15: PSK[w] ← msk′
16: end if
over Σadd and Σdel to retrieve all the encrypted indices matching w
and all the punctured key shares corresponding to deleted indices
(containing w), respectively. Then, server uses all these punctured
key shares together with the associated local key share (sent along
with the search token) to decrypt all matched indices except for the
deleted (punctured) ones.
In this framework, there is a different encryption key (i.e., master
secret key msk of SPE) for each keyword w, and it is punctured
gradually as the number of deletions on w increases. We note that
the deletion times between two successive search queries on w
in our scheme are upper-bounded by a pre-defined integer d, in
contrast to Janus. As pointed out in [5], once the secret key for
w has been sent to server for search, it can never be used by the
client to encrypt indices matching w in future insertions, since
the revealed secret key can be used to decrypt all indices that are
not deleted. Therefore, it is required to update the encryption key
after each search. Nevertheless, it does not require to re-encrypt
the result indices with a new key, as server can learn them from
access pattern, i.e., keeping track of the results over repeated search
queries. Hence, we adopt the same strategy as [5] to cache search
results at server.
Following the above idea, our generic scheme Σ = (Setup,
Search,Update) built on an incremental SPE scheme SPE =
(SPE.KeyGen, SPE.Enc, SPE.IncPun, SPE.Dec), forward - secure dynamic SSE schemes Σop = (Σop.Setup, Σop.Search, Σop.Update) for
op ∈ {add, del} and a PRF F is described as follows. The details are
presented in Algorithm 1.
Setup(1
λ
): on input a security parameter λ, client chooses
Ks ,Kt
$←− {0, 1}
λ
, generates (EDBadd, Kadd, σadd) and (EDBdel,
Kdel, σdel) by running the Setup algorithm of Σadd and Σdel, and
initializes empty sets MSK, PSK, DEL, SC and EDBcache , where
MSK keeps the encryption keys for all keywords, PSK keeps the
local key shares for future punctures at client, DEL keeps the number of deletions allowed for each keyword, SC keeps the times of
search queries over each keyword, and EDBcache keeps the previous result indices. At last, client outputs KΣ = (Kadd,Kdel,Ks ,Kt ),
EDB = (EDBadd, EDBdel, EDBcache ) and σ = (σadd, σdel, MSK,
PSK, DEL, SC).
Search(KΣ,w, σ; EDB): to perform a search query on w, client
with input (KΣ,w, σ) looks up the local key share msk′ ∈ PSK[w]
and the current search times i ∈ SC[w], and then sends back to
server msk′
, along with a token tkn = F (Ks ,w) used to fetch the
previous search results from the cache. After that, client runs search
on w||i for both Σadd and Σdel. Through search protocol, server
obtains encrypted indices and punctured key shares updated after
the last search on w. Then combining the punctured key shares
with msk′
, it is able to recover those indices that have not yet been
punctured. At the end, server returns the search result consisting
of newly recovered indices and those kept in cache (excluding the
newly deleted ones). It is noted that the encryption key for w must
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 774
be refreshed after each search, and the fresh key will be used to
encrypt new entries matching w before next search.
Update(KΣ, op, (w,ind), σ; EDB): to insert a new entry (w,ind)
(i.e., op = add), client retrieves the associated master encryption
key msk of SPE from table MSK[w], and encrypts ind under the
tag FKt
(w,ind). Then, the client inserts this pair of ciphertext and
tag (as a new entry matching w (exactly w||i)) to EDBadd. When
proceeding to delete an entry (w,ind) (i.e., op = del), client retrieves
the associated local key share msk′
from PSK[w], punctures the
current msk′ on tag t = FKt
(w,ind), and gets the punctured key
share pskt and a new associated key msk′
. Then it updates the
associated (local) key share to PSK[w] and inserts (pskt
,t) as a
new entry to EDBdel.
Remark. Another difference of our design from Janus is that the
number of allowed deletions d is bounded between two consecutive
search queries. But it is adjustable for different keywords or the
same keyword during runtime according to the workload. The
reason is that both the newly added index entries and punctured
keys on a given keyword are derived from a fresh master secret
key after each search. Previous results are cached at server, while
updated entries are queried by tokens generated via a new master
key, so no entries need to be re-encrypted. We argue that it is not
critical in practice as deletions are less frequent than searches. In
addition, as shown in Section 4.4 later, our instantiation naturally
supports batch deletion; it enables multiple deletions in each of the
total d punctures. Thus, the number of actual allowed deletions can
be increased.
4.2 Security Analysis
Like Janus, our scheme only realizes weak backward security defined in [5]; that is, server can know which inserted entries are
deleted later as well as the timestamps of these deletions. Note
that our scheme can also achieve forward-security, which follows
readily from that of Σadd and Σdel. Here, we only focus on backward
security, which is formally stated in Theorem 4.1.
Theorem 4.1. Assuming that Σadd and Σdel are LF S -adaptively
secure SSE schemes, SPE is IND-sPUN-CPA secure and F is a secure PRF, then the proposed SSE Σ is LBS -adaptively secure, where
LBS = (LSr ch
BS , L
U pd t
BS ) is defined as LSr ch
BS = (sp(w), TimeDB(w),
DelHist(w)) and L
U pd t
BS (op,w,ind) = op, and LF S denotes the leakage of the underlying forward-secure SSE schemes as defined in [5].
Proof. The proof is similar to that of Theorem 3 in [5]. The
main difference is that the security of our construction Σ is reduced
to the IND-sPUN-CPA security of the proposed SPE. A more detailed explanation will be given later. The other parts of the proof
including the construction of the simulator are almost the same.
For completeness, the entire proof is given as below.
Game0: this is exactly the real SSE security game (cf. Def. 2.5).
So, we have that
Pr[RealΣ
A(λ) = 1] = Pr[Game0 = 1].
Game1: the only difference of this game from the previous is
that the computation of the PRF F is replaced by picking random elements from its range. Particularly, each time F (Ks , ·) (resp.
F (Kt
, ·)) is evaluated on a previously unseen keyword w (resp. document/keyword pair (w,ind)), a random string is chosen from Y
and stored in the table Tokens (resp. Tags), from which the corresponding value can be directly retrieved whenever F is reused on
the same input. Obviously, the change to either F (Ks , ·) or F (Kt
, ·)
induces a distinguishing advantage equal to that of the PRF. Hence,
we get that
| Pr[Game1 = 1] − Pr[Game0 = 1]| ≤ 2Adv
PRF
B1,F
(λ),
where B1 makes at most N queries on F in the reduction.
Game2: this game is identical to Game1, except that all real
calls to the underlying SSE instances Σadd and Σdel are replaced by
invoking the simulators Sadd and Sdel, respectively. To do so, the
game makes some bookkeeping during the updates to keep track of
all the Update queries, and postpones all encryption and puncture
operations to the subsequent Search query. This can be done only
because the updates do not leak any information of their contents,
due to the forward secuirty of both Σadd and Σdel. In addition, two
new lists Ladd and Ldel are created and used in this game, where
Ladd consists of the encryption of result indices for the search query,
their associated tags and the corresponding insertion timestamps,
and Ldel consists of the punctured key shares, their associated tags
and the relevant timestamps. Actually, Ladd and Ldel correspond to
the update histories on the subsequently queried keyword for the
schemes Σadd and Σdel, and hence will be used as the inputs of the
simulators Sadd and Sdel, respectively. The precise description of
this game is given in the full version.
From the above, we can get that the distinguishing advantage
between these two games is
| Pr[Game2 = 1] − Pr[Game1 = 1]|
≤ Adv
SSE, LF S
Σadd, Badd,Sadd
(λ) + Adv
SSE, LF S
Σdel, Bdel,Sdel
(λ),
where Badd and Bdel making at most N insertions are two efficient adversaries against Σadd and Σdel, and Sadd and Sdel are two
associated simulators.
Game3: in this game, the encryption of deleted documents is
changed to that of 0. More specifically, if the inserted indices during
the updates are deleted later prior to the subsequent search, then
they are replaced by constant 0 when encrypted with SPE. The
concrete description of this game is given in the full version. We
note that this modification is only made for the ciphertexts associated with punctured tags, so the distinguishing advantage between
Game3 and Game2 can be reduced to that of our incremental SPE.
Briefly speaking, the simulator in the reduction can get the deleted
tag from Updates[w], then he can submit it as the challenge tag,
and continues to simulate the encryption of non-deleted documents
and the punctured key shares4 by leveraging his own encryption
oracle and puncture oracle, respectively. Thus, we get that
| Pr[Game3 = 1] − Pr[Game2 = 1]| ≤ d · Adv
IND-sPUN-CPA
B2,SPE (λ),
where B2 makes at most N encryption queries and d puncture
queries in the reduction.
Game4: this game differs from the previous one only in the way
of constructing the lists Ladd and Ldel. In this game, we first use
the Updates table to explicitly compute the leakage information
4To get the punctured keys on tags associated with previous encryption queries, the
simulator only needs to submit the challenge tag as the first puncture query.
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 775
TimeDB and DelHist, and then leverage this information to construct Ladd and Ldel. The details are precisely described in the full
version. Clearly, it is essentially identical to Game3, so it holds that
Pr[Game4 = 1] = Pr[Game3 = 1].
Game5: this game is in fact the same as Game4, except that tags
are generated in a different but equivalent way. Precisely, the tags
in this game are generated on the fly, instead of being generated
from document/keyword pairs and stored in table Updates. It can
be done like this because each document index is supposed to be
added and deleted at most once during the updates. In this case,
we only need to guarantee that the previously inserted and later
deleted document/keyword pairs (w,ind) are associated with the
unique tags, and do not have to store them in a table to ensure
consistence. The detailed description of this game is shown in the
full version. From the above, it is easy to get that
Pr[Game5 = 1] = Pr[Game4 = 1].
Game6: prior to presenting a simulator for Σ, what remains to
do is to replace the way of explicitly using keyword w to generate Tokens[w]. In particular, Tokens[w] in this game is generated by using the search pattern sp(w), exactly replacing w with
wˆ = min sp(w). The concrete description of this game is shown in
the full version. Clearly, we have that
Pr[Game6 = 1] = Pr[Game5 = 1].
Simulator. It is easy to observe that the final game can be efficiently simulated by relying on the leakage function LBS . In more
details, the simulator can directly use the leakage TimeDB(w) and
DelHist(w) as the input of Search to produce the lists Ladd and Ldel,
and thus avoids the need of keeping track of the updates as before.
Hence, we get that
Pr[Game6 = 1] = Pr[IdealΣ
A,S, LBS
(λ) = 1].
By combining all the distinguishing advantages above, we get
that the advantage of a PPT adversary against our SSE scheme Σ is
| Pr[RealΣ
A
(λ) = 1] − Pr[IdealΣ
A,S, LBS
(λ) = 1]|
≤ Adv
SSE, LF S
Σadd, Badd,Sadd
(λ) + Adv
SSE, LF S
Σdel, Bdel,Sdel
(λ)+
2Adv
PRF
B1,F
(λ) + d · Adv
IND-sPUN-CPA
B2,SPE (λ).

4.3 Instantiation
We instantiate our generic SSE scheme based on simple cryptographic primitives and name it as Janus++. Recall that our scheme
is mainly constructed from a forward-secure SSE and our SPE. For
the former, it can be instantiated with the same SSE scheme Diana as in [5]. As to our SPE, we instantiate it on the basis of the
well-known tree-based GGM PRF [18].
For ease of presentation, we first introduce how the Pun-PRF
built from GGM PRF works. We let G : {0, 1}
λ ← {0, 1}
2λ be a
length-doubling pseudorandom generator, and divide the output
of G(k) into two halves G0(k) and G1(k), then the GGM PRF F on
n-bit strings is defined as Fk
(x) = Gxn−1
(· · ·Gx1
(Gx0
(k))), where
the binary representation of x is xn−1 · · · x1x0. It is observed that
the PRF F for n-bit input is a binary tree with height n, and the
leaves of the tree correspond to the output of the PRF. Before going
ahead, we denote by Px and Nx the path from root to leaf x, where
we intend to puncture, and the set of siblings to the nodes in Px ,
respectively. Now the punctured key pskx on x is set as pskx =
{Fk
(y) : y ∈ Nx }, where k is the PRF key. In other words, pskx =
{G1−xi
(Gxi−1
(· · · (Gx0
(k)))}i ∈[0,n−1]
. Note that the punctured key
pskx contains all the values of F on the siblings to the path to x,
which allows server to evaluate F for every value other than x.
As mentioned, we employ tree-based GGM PRF [18] to implement the Pun-PRF. For each keyword/document pair (w,ind) to be
added, d +1 GGM PRFs will be leveraged to encrypt ind under a tag
t, which is derived from the to-be-updated (w,ind) and corresponds
to a leaf node of the GGM tree. As presented in Section 3.3, only
the master secret key for the first GGM tree is initialized (for each
keyword), and the other master secret keys for the remaining d
GGM trees are generated from a hash chain orderly. Namely, client
can generate all d + 1 values of d + 1 Pun-PRFs from the master
key of the first GGM tree to encrypt a document index. Note that
the client does not have to store all these trees, as the Pun-PRF
value associated with each leaf node can be computed on the fly.
Recall that, d in our SSE scheme is the maximum number of allowed
deletions (punctures), which can be varied for different keywords,
or even between any two consecutive search queries on the same
keyword.
Regarding deletion, punctures should be performed orderly over
d GGM trees, starting from the first one. Once a deletion (w,ind)
is issued, if it is the first deleted document on w, the puncture
operation is performed on the first GGM tree, i.e., traversing the
tree and recording all siblings Nx (with paths) to the nodes in path
Px , where x is the leaf node corresponding to the tag derived from
(w,ind). Then the siblings Nx (with paths) are used to generate the
punctured key share pskx , which will be inserted along with the tag
to the deletion instance Σdel. After that, client stores the number
of deletions and computes the master secret key for the second
GGM tree, which is updated to the local key share state and used
for the subsequent deletion and search. On the other hand, if the
deletion (w,ind) is not the first deleted document over w, client
will check the above local state to puncture the most recent master
secret key for next GGM tree through the same procedure above.
During search, client sends the current local key share to server, so
that server can evaluate any value of the GGM PRFs that are not
punctured. In the meanwhile, server obtains punctured key shares
from Σdel to evaluate the values of punctured GGM PRFs on tags
that are not deleted (punctured). After that, server recovers the
document indices that have not been deleted.
In our protocol, the input of F is the tag associated with each
document/keyword pair. Therefore, the height of the binary tree is
equal to the length of the tag. In our experiment later, we choose 16-
bit tag for evaluation, which can support at most 65536 documents
matching a keyword.
4.4 Batch Deletion
In practice, client may want to delete at one time a set of documents
containing one same keyword (aka document/keyword pairs). A
straightforward solution is to delete these pairs one by one, as
shown by our scheme and Janus. However, the communication
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 776 
Table 1: Complexity of Janus++
Computation Storage
Enc/Decryption Puncture Local state Ciphertext Server key share per deletion
O(d · |taд|) O(|taд|) O(W · (|d| + |msk|)) O(N · (|ct| + |taд|)) O(|psk|)
|d|: the bit length of the maximum number d of allowed deletions between two consecutive search queries; |taд|: the bit length of the taд
derived from keyword/document pair (w,ind); W : the total number of keywords in DB; |ct|: the length of an SPE ciphertext; N: the total
number of the document/keyword pairs; |msk|: the length of the local master key share for SPE; |psk|: the length of the punctured key
share for SPE.
cost (including bandwidth and roundtrip) will increase linearly
with the number of deleted documents. By instantiating our SPE
with a t-multi-puncturable PRF instead of the standard (i.e., t=1)
puncturable PRF, our proposed SSE scheme can efficiently deal with
batch deletions. In particular, each (master secret key of) GGM tree
can be used to puncture (delete) t tags (w.r.t. tree nodes), and each
time a compact punctured key is generated and uploaded to server.
As a result, such batch deletion will lead a reduction of interaction,
bandwidth, and storage overhead. The only tradeoff is that client
needs to cache t deleted document indices for batch deletion. On
the other hand, the total number of the actual allowed deletions can
reach t ×d for two consecutive search queries on the same keyword.
As long as t × d is greater than the size of the keyword matching
list, the parameter d will not limit the deletion operations, and it
only limits the number of deletion batches. We plan to implement
it in the future.
5 EXPERIMENTAL EVALUATION
5.1 Setup
We develop our scheme in Python and use pycrypto (2.6.1) to implement cryptographic primitives, i.e., AES cipher and SHA256.
Pseudorandom generator in GGM PRF is implemented via AES.
We select Enron Email Dataset 5
and extract total 4,762,706 document/keyword pairs from it, where the maximum size of posting list
that matches a given keyword is 63, 893. Regarding experiments, we
deploy our scheme to Azure Cloud and create an isolated DV15_V2
instance (Intel Xeon E5-2673 2.4GHz CPU with 20 cores and 140G
RAM), where Ubuntu Server 17.1 is installed. Our code is published
at GitHub6
. For comparison, we use the opensource code of Janus7
and only adjust its configurations of parameters in our experiments.
5.2 Evaluation
To understand the performance of our proposed scheme, we conduct a set of comprehensive evaluations from costs of storage, addition (encryption), deletion (puncture), and search. Specifically, two
schemes will be evaluated, i.e., our scheme Janus++ and Bost et al.’s
scheme Janus [5] . Unless otherwise indicated, we use a 16-bit taд
by default for each document; it is generated via truncated SHA256.
The computation and storage complexity of Janus++ is given in
Table 1 for the reference of the following empirical evaluations.
Storage evaluation. With regard to the server-side storage cost,
two dictionaries are maintained, i.e., one for addition and the other
5Enron Email Dataset: online at https://www.cs.cmu.edu/~enron/.
6
Janus++: online at https://github.com/MonashCybersecurityLab/JanusPP.
7OpenSSE Schemes: online at https://github.com/OpenSSE/opensse-schemes.
Table 2: Storage cost evaluation
Scheme client per w 4.7 × 106 pairs 108 pairs
Baseline - 150MB 3.2GB
Janus++ 17B 160MB 3.4GB
Janus 200B 423MB 9GB
(a) Client (local key share) and server storage (search dictionary) cost for
SSE, Janus++, and Janus, respectively
Scheme 8-bit tag 16-bit tag 32-bit tag
Janus++ 134B 275B 582B
Janus 201B 202B 204B
(b) Storage cost of punctured key elements (server key share) per deletion
in deletion dictionary.
Table 3: Puncture time cost
Scheme Janus++ (8-bit) Janus++ (16-bit) Janus
Puncture (ms) 0.4 0.93 1.26
for deletion. Here, we use Cash et al.’s scheme [8] as the baseline to
measure the storage overhead of achieving backward security. The
reasons is that Janus++ and Janus are both built from this encrypted
dictionary, which is comprised of encrypted document/keyword
pairs as index entries.
Table 2-(a) reports the size of encrypted dictionary in three
schemes respectively to explain the overhead for backward security. We evaluate the cost before any deletions. Assume that token
size for all three schemes is same in each entry, aka 16 bytes, and
the difference of storage cost mainly results from the ciphertext.
In Janus++, only a taд is stored along with the ciphertext for decryption during search, and the ciphertext size (16 bytes) is the
same as it in the baseline due to symmetric encryption. It is shown
that Janus++ only introduces small overhead. As reported in [5],
the ciphertext of Janus costs 74 bytes, so the total size is 90 bytes,
almost triple to the baseline. Table 2-(a) shows that Janus++ consumes 3.4GB for 108
index entries while Janus consumes 9GB. On
the other hand, client in Janus++ and Janus needs to maintain the
local key share for puntruable encryption. For Janus, it costs 200
bytes per keyword as given in [5]. For Janus++, the master key
msk of the current GGM tree (not being punctured) is stored which
is 16 bytes, and the number of allowed deletions between current
and next queries d is also cached at the client which is 1 byte (the
maximum d in our experiment is set as 100). In both schemes, the
local state scales in the number of keywords.
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 777
10 20 30 40 50
d
0
1
2
3
4
5
6
time cost per index entry (ms)
Janus++ (8b-tag)
Janus++ (16b-tag)
Janus
Figure 5: Encryption cost comparison
10-2
100
100
80 10000
search time (s) 102
60 8000
# dels
6000
# matched ids
40
104
4000 20 2000 0 0
Janus++
Janus
Figure 6: Search time comparison
After each deletion, a set of punctured key shares for the deleted
document will be generated by client and stored in an encrypted
form at server. We measure the above cost for Janus++ and Janus
respectively in Table 2-(b). As we instantiate Janus++ via GGM PRF,
punctured key shares for each deletion include the punctured tag,
siblings to the nodes on the path from the root to the punctured
leaf in a GGM tree, and paths of the siblings. Note that the last two
elements scale in the length of tag, aka the height of the GGM tree.
In Janus, punctured key shares for each deletion have a constant
size, and the punctured tag is also attached. Note that the above
cost will not be the bottleneck, because the punctured key shares
and tags in the deletion dictionary can be removed after a search
operation. The reason is that the results for previous queries are
cached at server, and only the new punctured key shares and tags
after a search operation are required to be stored.
Addition evaluation. To evaluate the performance of addition,
we insert 105 key-value pairs to the database without invoking
any deletion and compare the average encryption cost per pair
with Janus in Figure 5. As seen, Janus++ scales in two factors, tag
length |taд| and d. The reason is two-fold: |taд| (GGM tree height)
determines the number of AES calls, while d determines the number
of GGM trees used for encryption. Note that in Janus, the cost is
constant. In our experiment, Janus++ and Janus reach a breakeven when d is 25. Although Janus++ does not outperform Janus
under larger d, the decryption cost is comparable to the encryption
0 2000 4000 6000 800010000
number of matched ids
0
4
8
12
search time (s)
#dels = 2
#dels = 6
#dels = 10
(a) d = 10
0 2000 4000 6000 800010000
# matched ids
0
10
20
30
search time (s)
#dels = 10
#dels = 20
#dels = 30
(b) d = 30
0 2000 4000 6000 800010000
# matched ids
0
20
40
60
search time (s)
#dels = 10
#dels = 30
#dels = 50
(c) d = 50
0 2000 4000 6000 800010000
# matched ids
0
40
80
120
search time (s)
#dels = 10
#dels = 50
#dels = 100
(d) d = 100
Figure 7: Search time of Janus++.
cost due to its symmetric-based construction. This makes Janus++
practically deployable for search as demonstrated later. Besides,
encryption in all existing SSE schemes is assumed to be a one-time
setup, unless re-encryption is invoked periodically to reset leakage
functions.
Deletion evaluation. As mentioned above, a set of punctured
key share for a deleted document is computed at client and then
uploaded to server. Thus, the bandwidth consumption (server key
shares) can also be reflected from Table 2-(b), increasing in the
length of tag. The time cost of client is reported in Table 3. It is
not affected by d, because only one GGM tree is punctured at one
deletion. But it is still in linear with the tag length, because we
need to generate all siblings on the path to the punctured leaf in the
punctured GGM tree for each deletion. Compared to Janus, Janus++
with 16-bit tag achieves a speedup of 1.35 × in puncture time cost.
Search evaluation. To demonstrate the practicality of Janus++,
we compare its search latency with Janus. For fairness, we set the
same number of deletions in each comparison, i.e., 10, 30, 50, and
100. Regarding Janus++, we set the number of deletions #dels to be
equal to d. As depicted in Figure 6, Janus++ can achieve a speedup
of dozens of times in search latency compared to Janus. Although
per decryption cost for both Janus and Janus++ scales in the number
of deletions, the base cost (decryption cost without puncture) of
Janus++ is much smaller than Janus, i.e., 0.06 ∼ 0.08ms v.s. 3 ∼
4ms. For #dels = 10, Janus takes 413s to fetch 10, 000 indices and
decrypt 990 of them, while Janus++ takes 8.7s, a speedup of 47×.
For #dels = 50, Janus takes over 1880s to fetch 10, 000 indices and
decrypt 950 of them, while Janus++ takes 39s, a speedup of 49×.
To further explore the performance of Janus++, we evaluate
search latency in various parameter settings. We expect to understand the impacts of #dels and d on decryption time. In Figure 6
and Figure 7, the time for fetching the same number of matched
indices increases as d increases. The reason is straightforward; the
number of GGM trees is equal to d and the decryption cost scales
in d. Another observation is that, when more deletions happen,
Session 4D: Encrypted Search & Computation 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada 778
1 2 4 8
# cores
0
1000
2000
3000
4000
decrypted indices /s
#dels = 10
#dels = 30
#dels = 50
Figure 8: Search throughput of Janus++
search latency will reduce. The reason is two-fold. First, the total
number of indices which need to be decrypted is reduced. Second,
within each decryption, more deletions indicate that more values
of Pun-PRF will be computed from the punctured key shares rather
than the master key (with fewer AES calls compared to the values
computed from tree root).
At last, we confirm the scalability of Janus++. Specifically, we
create a cluster of DS1 standard instances (1 core on each) and
evaluate the index decryption throughput of Janus++ as depicted
in Figure 8. Each measurement is derived from an average of 20
trials of searching 10K indices. As seen, the throughput of Janus++
scales linearly with the number of cores.
6 CONCLUSIONS
In this work, we investigate new approaches of achieving practical
dynamic symmetric searchable encryption schemes with strong security guarantees. To the end, we for the first time introduce a new
cryptographic primitive, named symmetric puncturable encryption,
and propose a generic construction based on standard puncturable
pseudorandom functions. Although it can only be proven selectively secure in the random oracle model, it is sufficient for our
applications. Still, it is a challenging problem to construct practical
adaptively-secure incremental symmetric puncturable encryption
scheme without random oracles.
Based on the new primitive, we then present a practical
backward-secure symmetric searchable encryption scheme that
can be instantiated efficiently with basic symmetric cryptographic
tools. Moreover, we implement our scheme on a large dataset. The
experimental results demonstrate that our design is scalable in practice. Recall that our protocol only achieves weak backward security,
which may leak which deletion update canceled which addition
update, so how to design higher-level backward-secure dynamic
symmetric searchable encryption with a single roundtrip is still an
open problem.