Network middleboxes perform deep packet inspection (DPI) to
detect anomalies and suspicious activities in network traffic. However, increasingly these traffic are encrypted and middleboxes can
no longer make sense of them. A recent proposal by Sherry et al.
(SIGCOMM 2015), named BlindBox, enables the middlebox to perform inspection in a privacy-preserving manner. BlindBox deploys
garbled circuit to generate encrypted rules for the purpose of inspecting the encrypted traffic directly. However, the setup latency
(which could be 97s on a ruleset of 3,000 as reported) and overhead
size incurred by garbled circuit are high. Since communication can
only be commenced after the encrypted rules being generated, such
delay is intolerable in many real-time applications. In this work, we
present PrivDPI, which reduces the setup delay while retaining similar privacy guarantee. Compared to BlindBox, for a ruleset of 3,000,
our encrypted rule generation is 288x faster and requires 290,227x
smaller overhead for the first session, and is even 1,036x faster and
requires 3424,505x smaller overhead over 20 consecutive sessions.
The performance gain is based on a new technique for generating
encrypted rules as well as the idea of reusing intermediate results
generated in previous sessions across subsequent sessions. This is
in contrast to Blindbox which performs encrypted rule generation
from scratch for every session. Nevertheless, PrivDPI is 6x slower in
generating the encrypted traffic tokens, yet in our implementation,
the token encryption rate of PrivDPI is more than 17,271 per second which is sufficient for many real-time applications. Moreover,
the intermediate values generated in each session can be reused
across subsequent sessions for repeated tokens, which could further speedup token encryption. Overall, our experiment shows that
PrivDPI is practical and especially suitable for connections with
short flows.
CCS CONCEPTS
• Security and privacy → Security protocols; Web protocol
security; Cryptography.
KEYWORDS
Network privacy; Encrypted traffic inspection; Middlebox privacy
1 INTRODUCTION
Deep packet inspection (DPI) has been deployed for many functionalities such as intrusion detection, network monitoring, and
preventing data leakage. At the same time, it is expected that 80% of
all network traffic on the web is encrypted (i.e. SSL/TLS) [11]. This
means existing DPI techniques that inspect plain packets would be
of limited usage. In order to inspect encrypted traffic, a technique
widely used by enterprises is split-TLS using man-in-the-middle
(MitM) attack. A middlebox serves as a MitM by establishing a
session with the client and the destination server on behalf of the
client. By doing so the middlebox is able to decrypt, inspect and
re-encrypt the encrypted traffic originated from the client. This
provides a practical solution since modification is not required on
the underlying security protocol (i.e. TLS).
A system based on the above technique is secure as long as the
root certificate required in the MitM approach is securely stored
and the TLS protocol implemented is up-to-date. Unfortunately,
deployments have been shown to be insecure due to weaknesses in
their implementation, such as allowing deprecated cipher suites, as
discussed by Jarmoc [18], Carnavalet and Mannan [12], Durumeric
et al. [14] and Waked et al. [28]. Also, as was discussed by Sherry
et al. [23], a large network with heterogeneous network devices
would require many experienced administrators to administer them.
This poses another privacy concern when MitM approach is used,
since many of these devices may have access to the decrypted data.
In addition, MitM violates end-to-end encryption and data privacy
guarantee of the supposedly secure two-party communications.
The various security issues prompted the US-Cert to issue an alert
(TA17-075A) on interception of encrypted traffic [27].
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1657
New approaches have been proposed in order to address the
issues stated. A recent approach is BlindBox proposed by Sherry
et al. [24]. BlindBox performs deep packet inspection directly on
the encrypted traffic, without the client being able to learn the
rules used by the middlebox, and the middlebox not being able to
gain any information of the underlying content of the encrypted
payloads (except for the content that matches the rules). It introduced a technique called obfuscated rule encryption to achieve this,
which is based on garbled circuit. Specifically, the client and the
server generate a garbled circuit for a function F and perform oblivious transfer (OT) with the middlebox respectively to prepare the
encrypted rules. After that, the client tokenizes its payloads and
encrypts the payloads to obtain the corresponding encrypted tokens using the same key as was used in preparing the encrypted
rules. The middlebox then compares the encrypted rules with the
encrypted tokens in the traffic.
However, such garbled circuit approach incurs significant computation and communication overhead, where roughly 97 seconds
are required to prepare 3,000 encrypted rules as reported in [24].
Furthermore, for every new session, this operation must be performed again. As noted in [24], BlindBox is not yet practical for
short, independent flows with many rules.
1.1 Our Contributions
To address the limitations of BlindBox, we present PrivDPI, which
provides a secure, practical solution whereby (a) the encrypted rule
generation is relatively more efficient than BlindBox yet retains the
same security and privacy guarantee, and (b) introducing a reusable
technique so that a client and the middlebox only need to perform
rule preparation (i.e., generation of obfuscated rules) once, which
is during the first session. The obfuscated rules can then be reused
to generate encrypted rules for every new session, thus effectively
reducing the computation and communication overhead in rule
preparation compared to BlindBox.
To realize our objective, we developed the following techniques:
• We present a new obfuscated rule generation technique that does
not use garbled circuit, which achieves a better performance for
encrypted rule generation.
• We introduce a reusable obfuscated rule generation technique, in
which for every Q sessions, the obfuscated rules generated in
the first session can be reused in subsequent sessions, which
minimizes the computation and communication overhead during
encrypted traffic inspection. The capability to reuse the rules
further improves the performance of our proposal.
We demonstrate through extensive experiments the improved
performance due to our proposed techniques as compared to BlindBox. For the first session on a ruleset of 3,000, the encrypted rule
generation of PrivDPI is 288x faster, and requires 290,227x less
bandwidth than that of BlindBox. For 20 consecutive sessions on
a ruleset of 3,000, the encrypted rule generation is 1,036x faster
compared to BlindBox, and requires 3424,505x less bandwidth. The
token encryption phase of PrivDPI, however, is roughly 6x slower
than that of BlindBox (with AES-NI hardware support). In order to
reduce the computation overhead, we record the encrypted tokens
generated so far and reuse them in subsequent sessions when the
same tokens appear. It is shown in our experiments that the performance of our token encryption phase using this reuse mechanism
is only 3.5x slower when all the tokens of the current session have
already appeared in previous sessions. For a complete TLS connection on a ruleset of 3,000, our running time is less than BlindBox
providing that the number of tokens in both client and server is
less than around 3.78 million. This demonstrates that PrivDPI is
practical and especially suitable for settings using connections with
short flows.
1.2 Use Cases
The main objective of PrivDPI is to enable a middlebox in an enterprise or Internet Service Provider (ISP) to be able to inspect
encrypted traffic, while at the same time preserve privacy of the
underlying payloads. In this setting, a user can deploy PrivDPI
so that he/she is assured that the middlebox has no access to the
encrypted information transmitted except if the session has been
compromised (i.e. encrypted malware traffic). For example, a subscriber to an ISP service may install PrivDPI so that he/she can be
assured that his/her email or Facebook can never be viewed by the
personnel that administers the middlebox.
An enterpise may also provide a guarantee to its employees in
the scenario where personal data privacy becomes increasingly
prevalent (i.e. General Data Protection Regulation (GDPR)). The
inspection on encrypted payloads is performed in such a way that
not even the administrators have the ability to exploit the existing
middlebox setting. We note that an enterprise usually installs or
subscribes to security services in order to secure its enterprise networks. Furthermore, the enterprise can deploy PrivDPI to detect
potential data exfiltration through keyword matching yet maintaining privacy of the users.
2 OVERVIEW
PrivDPI has a similar architecture as in BlindBox [24] (Fig. 1). It
consists of four entities: Rule Generator (RG), MiddleBox (MB),
Client (C) and Server (S) described as follows.
• RG: It issues rule tuples that contain network rules. These rule
tuples are used by MB to detect malicious network traffic. In
particular, each rule contains one or more keywords describing
malicious behaviours in the network communication. RG can be
an organization that provides network security services.
• MB: It is a network appliance that monitors the encrypted traffic
and try to find malicious data payload(s) in the traffic that match
the rule issued by RG.
• C: It is the user (e.g. the web browser) that sends and receives
network traffic. In this work, we focus on encrypted network
traffic. In particular, TLS connections.
• S: It is the service provider that provides content to the client.
2.1 Threat Model
There are two types of adversaries in the system. The first type of
adversaries involves either C or S. In this case, we assume either
C or S is malicious but not both. Here, the main objective of an
adversary is to escape detection of malicious behaviour, e.g., by
generating encrypted token that does not correspond to the real
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1658
traffic. This is a similar threat setting of a standard intrusion detection system (IDS). We do not consider the case when both C and S
are malicious, since they can just agree on a secret key and encrypt
their traffic throughout the entire session. The assumption that
either C or S is malicious is a standard setting for data exfiltration
and parental filtering applications [24].
The second type of the adversaries involves MB. An adversary
of the second type exploits the system in order to learn the content
of the encrypted traffic between C and S. We assume the adversary
to be semi-honest (i.e., honest-but-curious), in that it follows the
protocol as it is, and only tries to learn the content of the encrypted
payload(s). The goal of PrivDPI is to enable MB to perform deep
packet inspection without exposing the content of the traffic to it.
2.2 System Flow
PrivDPI consists of the following phases.
• Setup. In this phase, MB receives a set of rule tuples from RG.
Meanwhile, C and S establish a session key through the TLS
handshake protocol. This session key can be used as a common
randomness source for C and S.
• Preprocessing. In this phase, MB interacts with C and S to
establish a set of reusable obfuscated rules in such a way that
C and S do not learn the rules while MB does not learn the key
used by C and S.
• Session Rule Preparation. In this phase, the reusable obfuscated rules generated in the preprocessing phase are used as
“seeds” to establish the session rules for the TLS session. The
session rules can then be used as a key to generate the encrypted
rules for traffic detection (in the following token detection phase).
• Token Encryption. C first tokenizes the data to be transmitted
through the TLS session. Each token is then encrypted, which
will be used for matching during the token detection phase.
• Token Detection. MB first generates encrypted rules using the
session rules generated in the session rule preparation phase. It
then performs token detection based on the encrypted tokens
received from C and the encrypted rules it generated. The main
characteristic here is that MB is able to reuse the obfuscated
rules, which is prepared in the first session, in the subsequent
sessions.
• Token Validation. This phase is required only when either C
or S is malicious in that the data sent through the TLS session
and the tokenization session is different. Since S (resp. C) has the
session key, S (resp. C) may perform the same tokenization and
encryption algorithms on the data that it receives and compares
the generated tokens to the tokens received from C (resp. S).
3 PRIVDPI
In this section, we present a basic version of our PrivDPI. This
version uses bilinear map to ensure C and S use the same key to
generate tokens, in order to guard against a malicious C (or S)
generating tokens that are different from the TLS payloads to evade
detection by MB. It is designed with minimal involvement of S.
This reduces computation and communication requirements on S
during preparation of obfuscated rules. However, use of bilinear
map incurs high computation costs. In Section 4, we will present
a variant of PrivDPI that does not need pairing with much better
efficiency but require more interactions with S. In the following,
we provide preliminaries before we describe PrivDPI.
3.1 Preliminaries
3.1.1 Notation. Let PPT be probabilistic polynomial-time. Let N
be the natural numbers. We denote N ∈ N as the number of rules,
and define [N] to represent the set {1,. . . ,N}, [i,j] to represent the
set {i,i + 1,. . . ,j}. Table 1 lists the notation we used in the system.
3.1.2 Bilinear Maps. Let G and GT be two multiplicative cyclic
groups of prime order p, and д be a generator ∈ G. Let e : G ×
G → GT be a bilinear map, which has the following properties:
(1) Bilinearity: for all д ∈ G and a,b ∈ Zp , we have e (д
a
,д
b
) =
e (д,д)
ab ; (2) Non-degeneracy: e (д,д) , 1. The group operation in
G and the bilinear map e : G × G → GT are efficiently computable.
3.1.3 Computational Diffie-Hellman (CDH) Assumption. Given (д,
д
a
,д
b
) ∈ G for any (a,b) ∈ Z
∗
p
, it is hard to compute д
ab ∈ G.
3.1.4 Decisional Diffie-Hellman (DDH) Assumption. Given (д,д
a
,
д
b
,Z) ∈ G for any (a,b) ∈ Z
∗
p
, it is hard to decide Z = д
ab or Z is
a random value.
3.2 Setup
During the setup phase, for a rule set {ri ∈ R }i ∈[N ]
(where R is the
rule domain), RG chooses a random secret α ∈ Zp , random si ∈ Zp
for each ri
, and sets A = д
α
, Ri = д
αri+si
for i ∈ [N]. RG then
signs {Ri}i ∈[N ] with its private key to obtain a set of signatures
{sig(Ri
)}i ∈[N ]
. Finally, RG sends ({si
,Ri
,sig(Ri
)}i ∈[N ]
) to MB.
These rule tuples, which contain keywords known to be used to
formulate attacks, will enable MB to perform privacy-preserving
deep packet inspection at the later stage. Note that this is the only
time RG is involved in the protocol (except when there are updates
on the rules). RG can be offline once the above steps are performed.
Independently, C and S install a PrivDPI HTTPS configuration
which includes A, the public key of the signature scheme used by
RG, a hash function H and a value RS. Similar to BlindBox, H is
implemented using AES, and RS is a parameter used to reduce the
ciphertext size to reduce bandwidth overhead.
Let sk be the session key established from the TLS handshake
protocol. As in BlindBox, C and S then derive the following three
keys using sk (via a pseudorandom number generator):
• kr and : will be used as a seed for generating randomness. Note
that since C and S share the same seed, the randomnesses they
later generate are the same;
• k: will be used for generating reusable obfuscated rules and session rules1
. Without loss of generality, we assume k ∈ Zp ;
• kT LS : is the regular TLS key, and is used to encrypt the traffic.
3.3 Preprocessing
In this phase, a preprocessing protocol will be executed in the first
TLS session right after the completion of the handshake protocol.
The protocol is described in Fig. 2. The aim of this protocol is
to establish a set of intermediary, reusable obfuscated rules for
MB, which will be reused to generate session rules in subsequent
1The security requirement of k is that: given k, it is computationally infeasible to
recover sk.
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1659
Client	C Middlebox	MB Server	S
Reusable	obfuscated	
rules	preparation
Rule	Generator	RG
Tuples	of	
rules	and	signatures
Encrypted	
rules
TLS
Detect
Tokenize Encrypt
Encrypted	traffic
Encrypted	tokens
Validate	
tokens
TLS
Figure 1 PrivDPI System Architecture: There are two data flows, one the TLS session and another the tokenized data. RG prepares rule tuples
and generates signatures for the rule tuples. MB interacts with C and S to prepare the reusable obfuscated rules. MB inspects the tokenized
data and forwards the TLS session to the server. The server is able to verify the two data flows are identical since it has the session key used
to encrypt the TLS traffic and the tokenized data.
Table 1 Notation
Notation Meaning Description
(si
,Ri
,sig(Ri
)) Rule tuple Generated by RG for rule ri as the input to MB to generate reusable obfuscated rule
Ii Reusable obfuscated rule Generated by MB for rule ri
in the preprocessing phase in the first session, used as a
source to generate session rule for any new session
Si Session rule Generated by MB for rule ri
in the session rule preparation phase, used as the “seed”
to generate encrypted rule
Ti Session token Generated by C (or S) for token ti
in the token encryption phase, used as the “seed” to
generate encrypted token
Cri Encrypted rule Generated by MB for rule ri
in the token detection phase, used for matching
Cti Encrypted token Generated by C (or S) for token ti
in the token encryption phase, used for matching
sessions. The reusable obfuscated rule of a rule ri
is Ii = д
kαri+k
2
,
where k,α,ri are as defined in Section 3.2.
We now explain the rationale behind this protocol. In order to
enable MB to detect the encrypted traffic, MB needs to obtain
a function Fk
(ri
) which is jointly generated from both k and ri
.
However, MB should not obtain k and C should not know ri
. This
is because if MB knows k, MB will be able to arbitrarily generate
encrypted rules to learn the content of the encrypted payloads. Due
to the rules ri being proprietary knowledge that should only be
known to MB and RG, C is not supposed to know ri
. To address the
above issue, we introduce a new technique called oblivious reusable
obfuscated rule generation, which is inspired by a recent protocol
for oblivious transfer [10]. Our main intuition is for C to obfuscate
the key k and for the RG and MB to obfuscate the rules such that
an obfuscated rule can be derived without revealing the k or ri
. We
did it in a way that enables the obfuscated rules to be reusuable.
In more details, given a group G and its generator д, C calculates
Kc = д
k using her k and sends Kc to MB. Symmetrically, MB
sends a set {Ri = д
αri+si }i ∈[N ]
to C. The key observation is that
C can derive a value Ki = (Ri
· Kc )
k = д
kαri+ksi+k
2
for a rule
ri
, and that MB is not able to calculate this value assuming CDH
assumption holds. This ensures that MB can only obtain the set
{Ki}i ∈[N ] corresponding to {Ri}i ∈[N ]
. The set {Ki}i ∈[N ] will be
used to generate the reusable obfuscated rules {Ii}i ∈[N ]
, which are
the key components for inspecting the encrypted traffic. However,
MB cannot inject additional rules RDnot provided by RG and forge
KDi = (RDi
· Kc )
k
for RDi < {Ri}i ∈[N ]
. As a result, MB does not have
the ability to learn more information from the encrypted traffic
except for {Ri}i ∈[N ]
. There are further, subtle issues that need to
be addressed. We explain them in the followings:
1. In order to prevent MB from gaining more information on the
encrypted traffic by creating RDi < {Ri}i ∈[N ]
to obtain KDi =
(RDi
· Kc )
k
, MB needs to send the signatures of {Ri}i ∈[N ] along
with {Ri}i ∈[N ]
. C will verify the received {Ri}i ∈[N ] using the
signatures received. Since MB cannot forge the signature for RDi
,
any additional RDi will be detected by C.
2. In order to ensure k in Kc (sent by C) and k in Ki
(generated by
C) for rule ri
is identical, S needs to calculate Ks = д
k using her
k and sends Ks to MB. Since C and S share the same k and one of
them is honest, for the case where C uses a different k
′
, MB can
notice this by checking whether Kc equals Ks . For the case where
Ki
is computed by C using a different k
′
, MB can notice this by
checking whether the equation e (Ki
,д) = e (Ri
· Kc ,Kc ) holds.
We present a more efficient mechanism to check the correctness
of Kc sent by C without using bilinear map in section 4, which
requires more interactions with S.
3. In order to prevent C from learning the rules, the rule is blinded
by α and si chosen by RG. In particular, for a rule ri
, C receives
Ri = д
αri+si
, where α,si ∈ Zp . For the case where the rule
domain is small, since ri
is blinded by α and si
, C cannot obtain
the value of ri even by launching brute-force attack, even if C is
computational unbounded.
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1660
Preprocessing Protocol
Input: MB has inputs ({si
,Ri
,sig(Ri
)}i ∈[N ]
) (from RG), where
Ri = д
αri+si
; C and S have common inputs k.
Protocol:
1. C computes Kc = д
k
(using her k), and sends Kc to MB.
Similarly, S computes Ks = д
k
(using her k) and sends Ks to
MB.
2. MB checks whether Kc equals Ks . If not, it halts and outputs
⊥. Otherwise, it sends ({Ri
,Sig(Ri
)}i ∈[N ]
) to C.
3. C does as follows:
(a) For i ∈ [N], check if Sig(Ri
) is a valid signature on Ri
using the public key of the signature scheme used by RG.
If not, halt and output ⊥.
(b) Compute Ki = (Ri
· Kc )
k = д
kαri+ksi+k
2
for i ∈ [N].
Finally, send {Ki}i ∈[N ]
to MB.
4. For i ∈ [N], MB verifies whether the equation e (Ki
,д) =
e (Ri
· Kc ,Kc ) holds. If not, it halts and outputs ⊥. Otherwise,
for i ∈ [N], it calculates the reusable obfuscated rule Ii =
Ki /(Kc )
si = д
kαri+k
2
for future use.
Figure 2 Preprocessing Protocol
3.4 Session Rule Preparation
In this phase, a session rule preparation protocol is executed to
generate session rule. The session rule is derived from the reusable
obfuscated rule generated in the preprocessing protocol. The protocol is described in Fig. 3. The main objective is so that for subsequent
sessions, the protocol does not need to re-compute the obfuscated
rule. This improves the computation and communication costs as
compared to BlindBox, which we demonstrate in our experiment.
In the preprocessing protocol discussed in the previous section,
C and S establish a session key sk and derive (kr and ,k,kT LS ) in
the first TLS session. For a new session, we denote the session key
that C and S established as sknew . Let (Dkr and ,Dk,DkT LS ) be the new
keys derived from sknew .
For the first session, the reusable obfuscated rules {Ii}i ∈[N ] generated in the preprocessing protocol can be used directly as the
session rules. For any subsequent sessions, C will send KDc = д
kD
specific to the current session to MB. MB generates the session rules
specific to the current session by calculating Si = Ii
· KDc using the
reusable obfuscated rules {Ii}i ∈[N ] generated in the preprocessing
protocol. In order to prevent C from sending a different KDc , S needs
to send KDs = д
kD
to MB as well. If a different KD′
c
is sent by C, MB
will be able to notice this fact by checking whether the messages
received from C and S are the same.
Remark: We note that as the number of session increases, more
and more group elements will be consumed. In order to prevent
brute-force attack, the preprocessing protocol (Fig. 2) will be run
every Q sessions (the value of Q depends on the group we chosen).
The session when the preprocessing is performed is treated as the
new first session.
Session Rule Preparation Protocol
Input: MB has inputs {Ii}i ∈[N ]
(from the preprocessing protocol). C and S have common inputs k (for the first session) or Dk
(for a subsequent session).
Protocol:
Case 1: For the first session, MB sets {Si = Ii}i ∈[N ] as the
session rules.
Case 2: For a subsequent session, the protocol operates as follows:
1. C sends KDc = д
kD
to MB. Similarly, S sends KDs = д
kD
to MB.
2. MB checks whether KDc equals KDs . If not, it halts and outputs
⊥. Otherwise, for i ∈ [N], it calculates Si = Ii
· KDc as the
session rule.
Figure 3 Session Rule Preparation Protocol
3.5 Token Encryption
Sliding window-based tokenization was used by Blindbox and we
follow the same approach in our protocol, in which each token
consists of 8 bytes. As an example, given a keyword “confidential”
which consists of 12 bytes of character, we can generate five tokens
in 8 bytes, such that “confiden”, “onfident”, “nfidenti”, “fidentia”, and
“idential”. In order to reduce storage size (as there exists overlay tokens), given a keyword that is more than 8 bytes, MB needs only to
generate two tokens, a prefix “confiden” and a suffix “idential”. This
would be sufficient to detect the keyword. We note that an optimization was also proposed in Blindbox, namely delimiter-based tokenization, which is applicable to the HTTP realm by observing how
the keywords from rules for these protocols are structured. For example, suppose that given a payload “submit.php?keyword=secret",
the possible keywords in rules are “submit", “submit.php", “?keyword=", “keyword=secret", but not “subm" or “submit.p". In practice,
we can generate tokens that match keywords that start and end on
delimiter-based offsets.
After tokenization, for every token t, token encryption is performed based on the algorithm described in Fig. 4. The intuition
is that, since MB holds the session rules ({Si = Ii}i ∈[N ]
for the
first session or {Si = Ii
· KDc }i ∈[N ]
for other session), to perform
an equality check, the encrypted token should be derived from
д
kαt+k
2
for the first session or д
kαt+k
2+kDc
for the other session.
Hence, we require C to compute Tt = A
k t
· д
k
2
= д
kαt+k
2
for the
first session or Tt = A
k t
· д
k
2
· KDc = д
kαt+k
2+kD
for a subsequent
session with key Dk. We call Tt the session token for token t.
The security requirement here is that MB should be able to match
a token t if t equals a rule r hold by MB, otherwise, no information
is revealed except for the fact that there is no match. To achieve
this with high efficiency, a simple approach is to encrypt Tt using
a deterministic encryption scheme. However, simply encrypting
Tt using a deterministic encryption scheme leaks information that
may lead to frequency analysis attack. This is because identical
tokens in the encrypted packet stream will have the same session
tokens, which will result in identical ciphertexts. Here, we adopt the
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1661
approach in BlindBox. We add a random salt to prevent frequency
analysis attack. However, naively adding a random salt to each
token requires one salt per encrypted token. The salt needs to be
sent to MB in order to perform equality check. In order to avoid
sending an independent salt for each encrypted token, C initializes
a counter table CTc that will record a tuple (t,Tt
,ctt
) for every
token t, where Tt
is the session token corresponding to t and ctt
is
the times t appeared in the stream per session so far. In addition,
C derives a value salt as the initial salt using kr and and sends it
to MB, which MB will record. For every token t, we consider the
following two cases:
1. For the first session, if there does not exist a tuple corresponding
to t, calculate Tt = A
k t
·д
k
2
, setctt ← 0, add the tuple (t,Tt
,ctt
)
into CTc , and compute the encrypted token as H(salt + ctt
,Tt
).
Otherwise, i.e., there exists a tuple (t
′
,Tt
′,ctt
′ ) in CTc such that
t
′ = t, set ctt
′ ← ctt
′ + 1, and compute the encrypted token as
H(salt + ctt
′,Tt
′ ).
2. For other session, first compute Tt = A
k t
· д
k
2
· KDc . If there
does not exist a tuple corresponding to t in CTc , set ctt ← 0
and add tuple (t,Tt
,ctt
) into CTc , compute the encrypted token
as H(salt + ctt
,Tt
). If there exists a tuple (t
′
,Tt
′,ctt
′ ) in CTc
such that t
′ = t and Tt
′ , Tt
, set Tt
′ ← Tt
, ctt
′ ← 0, compute
the encrypted token as H(salt + ctt
′,Tt
′ ). If there exists a tuple
(t
′
,Tt
′,ctt
′ ) in CTc such thatt
′ = t andTt
′ = Tt
, setctt
′ ← ctt
′+1,
the encrypted token as H(salt + ctt
′,Tt
′ ).
Token Encryption Algorithm
Input: A counter table CTc , a token t, and k (for the first session)
and KDc (for a subsequent session), A = д
α
.
Algorithm:
Case 1: For the first session, the algorithm operates as follows:
1. For every token t, there are two cases:
– If there does not exist a tuple corresponding to t in CTc :
compute Tt = A
k t
· д
k
2
= д
kαt+k
2
, set ctt ← 0, ct ← ctt
,
and insert tuple (t,Tt
,ctt
) into CTc .
– If there exists a tuple (t
′
,Tt
′,ctt
′ ) in CTc satisfying t
′ = t:
set Tt ← Tt
′, ctt
′ ← ctt
′ + 1 and ct ← ctt
′.
2. Compute the encryption of t as Ct = H(salt + ct,Tt
).
Case 2: For a new session (different from the first session), the
algorithm operates as follows:
1. Compute Tt = A
k t
· д
k
2
· KDc = д
kαt+k
2+kD
.
2. For every token t, we have the following cases:
– If there does not exists a tuple corresponding to t in CTc :
set ctt ← 0, ct ← ctt and insert tuple (t,Tt
,ctt
) into CTc .
– If there exists a tuple (t
′
,Tt
′,ctt
′ ) in CTc satisfying t
′ = t
and Tt
′ , Tt
: set Tt
′ ← Tt
, ctt
′ ← 0 and ct ← ctt
′.
– If there exists a tuple (t
′
,Tt
′,ctt
′ ) in CTc satisfying t
′ = t
and Tt
′ = Tt
: set ctt
′ ← ctt
′ + 1 and ct ← ctt
′.
3. Compute the encryption of t as Ct = H(salt + ct,Tt
).
Figure 4 Token Encryption algorithm
Similar to BlindBox, in order to prevent CTc from growing too
large, C can reset CTc and sends a new salt salt′
to MB, where
salt′ = salt + maxtctt + 1.
3.6 Token Detection
To perform equality check, MB only needs to compute the encrypted rule Cri = H(salt + ctri
,Si
) and check whether Ct equals
Cri
. This is possible because as shown in Step 2 of Fig. 4, the encrypted token for token t generated by C is Ct = H(salt +ctt
,Tt
),
where Tt = д
kαt+k
2
for the first session and Tt = д
kαt+k
2+kD
for
other session with Dk. MB, as shown in Fig. 3, holds the session rule
set {Si = Ii}i ∈[N ]
for the first session and {Si = Ii
·KDc }i ∈[N ]
for the
other session. To reduce the bandwidth and detection overhead, we
use a counter table and search tree as used in BlindBox. Specifically,
for each session, MB initializes a count table CTmb that contains a
tuple (ctri
,Cri
) for every rule ri
, where ctri
is the count of ri and is
set to be 0, and Cri = H(salt + ctri
,Si
). MB also initializes a fast
search tree that contains {Cri
}i ∈[N ]
. The token detection algorithm
is described in Fig. 5.
Token Detection Algorithm
Input: A counter table CTmb and a fast search tree.
Scheme: For each encrypted token Ct
in the traffic stream, if
there exists a Cri
equals Ct for some i ∈ [N], do
1. Take the corresponding action dictated by the security policy.
2. Delete the node in tree corresponding to ri and insert Cri =
H(salt + ctri + 1,Si
).
3. Set ctri ← ctri + 1.
Figure 5 Token Detection Algorithm
3.7 Token Validation
S runs the same tokenization and token encryption algorithm on
the decrypted traffic from TLS as C does. S then checks the resulting
encrypted tokens are the same as the encrypted tokens received
from MB. If not, it concludes that C is malicious.
4 VARIANT OF PRIVDPI
In order to improve the efficiency of PrivDPI, we introduce the
following methods by modifying the token encryption algorithm
and the preprocessing protocol, respectively.
4.1 Enhanced Token Encryption Algorithm
We introduce two approaches to reduce the computational overhead
of the token encryption algorithm in Section 3.5, which are based
on the following observations:
1. For a token t, the main task in this algorithm is to compute
Tt = A
k t
· д
k
2
for the first session or Tt = A
k t
· д
k
2
· KDc for other
subsequent session. Our first observation is described as follows.
For the first session, Tt = A
k t
·д
k
2
can be written as Tt = A
k t
·V ,
where V = д
k
2
. For any subsequent token t
′
in the stream within
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1662
the same session (i.e., in the first session), the detection token
Tt
′ can be computed as A
k t′
· V
′
, where V
′ = V . That is, we can
reuse V for any subsequent tokens, the main computation cost
is reduced to one exponentiation in G per token. Similarly, for
any new token t
′ within the same session or in any subsequent
session, we can reuse V to compute Tt
, which only takes one
exponentiation in G per token.
2. Our second observation is that in addition to the fact where one
token may appear for many times within one session, the same
token may appear in subsequent sessions. Hence, we can reuse
the session token generated in previous session(s) to reduce the
computation overhead of token encryption algorithm.
Based on the first observation, we modify the token encryption
algorithm in Section 3.5 as follows. We add one more step prior to
any operation, where V = д
k
2
(for the first session) is computed.
The value V is then reused for generating all tokens within the
same session or any subsequent session.
Based on the second observation, we modify the token encryption algorithm in Section 3.5 as follows. Before encryption of a token, C initializes a counter table CT′
c
that records a tuple (t,Tt
,Tt,0,
ctt
,cts ) for each token t, where Tt
is the session token corresponding to t, Tt,0 is the session token generated using key k (where k is
the key in the first session),ctt
is the number of timest appeared in
the stream so far per session and cts is the index of the latest session
where t appears. In addition, C derives a value salt as the initial
salt using kr and and sends it to MB, which MB will record. For
each token t, the modified token encryption algorithm is described
in Fig. 6.
Remark: Note that as the table CT′
c grows, the search time will
increase accordingly. Hence, CT′
c will be reset for every Q sessions.
The value of Q will depend on the number of tokens.
4.2 Enhanced Preprocessing protocol
Note that the fourth step of the preprocessing protocol in Section
3.3 requires the pairing operation. In general, the elliptic curve
supporting pairing is less efficient than other normal elliptic curves.
Hence, if we can remove the need of pairing, we can use a more efficient elliptic curve to reduce the computation overhead. In addition,
for i ∈ [N], Ki = (Ri
·Kc )
k
can be written as Ki = (Ri
)
k
·K, where
K = (Kc )
k
. Hence, we can (pre-)compute K for once, and reuse K to
compute Ki = (Ri
)
k
·K for i ∈ [2,N]. Thus, the computational cost
is reduced to one exponentiation inG per token fori ∈ [2,N]. Based
on the above observations, the modified preprocessing protocol is
shown in Fig. 7.
5 SECURITY
We first introduce the syntax for our protocol, and then provide the
security definition. Finally we prove our protocol is secure based
on the defined security definition.
5.1 Syntax
We first introduce the syntax for the class of encryption schemes
called middlebox searchable encryption scheme (MBSE for short),
as introduced in BlindBox. We then define the syntax for the preprocessing protocol.
Enhanced Token Encryption Algorithm
Input: A counter table CT′
c
, a token t, and k (for the first session)
or Dk (for a new session), A = д
α
.
Algorithm:
Case 1: For the first session, the algorithm operates as follows:
1. First compute V = д
k
2
and store it.
2. For every token t, there are two cases:
– If there does not exist a tuple corresponding to t in CT′
c
:
compute Tt = A
k t
· V = д
kαt+k
2
, set Tt,0 ← Tt
, ctt ← 0,
ct ← ctt
, cts ← 1, and insert tuple (t,Tt
,Tt,0,ctt
,cts ) into
CT′
c
.
– If there exists a tuple (t
′
,Tt
′,Tt
′
,0,ctt
′,cts ) in CT′
c
: set Tt ←
Tt
′, ctt
′ ← ctt
′ + 1 and ct ← ctt
′.
3. Compute the encryption of t as Ct = H(salt + ct,Tt
).
Case 2: For the i-th session where i > 1, the algorithm operates
as follows:
1. For every token t, there are three cases:
– If there does not exists a tuple corresponding to t in CT′
c
:
compute Tt,0 = A
k t
· V = д
kαt+k
2
, Tt = Tt,0 · KDc =
д
kαt+k
2+kD
, set ctt ← 0, ct ← ctt
, cts ← i, and insert tuple
(t,Tt
,Tt,0,ctt
,cts ) into CT′
c
.
– If there exists a tuple (t
′
,Tt
′,Tt
′
,0,ctt
′,cts ) in CT′
c
such that
t
′ = t and cts < i: compute Tt = Tt
′
,0 · KDc , set Tt
′ ← Tt
,
ctt
′ ← 0, ct ← ctt
′, cts ← i.
– If there exists a tuple (t
′
,Tt
′,Tt
′
,0,ctt
′,cts ) in CT′
c
such that
t
′ = t and cts = i: setTt ← Tt
′,ctt
′ = ctt
′ +1 and ct ← ctt
′.
2. Compute the encryption of t as Ct = H(salt + ct,Tt
).
Figure 6 Enhanced Token Encryption algorithm
5.1.1 Definition of MBSE. The syntax of MBSE is defined as follows.
Definition 5.1. An MBSE scheme with message space M consists
of four PPT algorithms (Setup,TEnc,REnc,Match) as follows:
• Setup(1
λ
): The setup algorithm takes as input the security parameter 1λ
, outputs a key k and the public parameter pk.
• TEnc((t1,...,tn ),k,pk): The token encryption algorithm takes
as input a set of n tokens (t1,..., tn ) ∈ Mn
, a key k and the
public parameter pk, outputs a salt salt and a set of ciphertexts
(ct1,...,ctn ).
• REnc(r,k,pk): The rule encryption algorithm takes as input a
rule r ∈ M, a key k and the public parameter pk, and outputs an
encrypted rule ctr .
• Match(salt, (ct1,...,ctn ),ctr ): The match algorithm takes as input a salt salt, a set of ciphertexts (ct1,...,ctn ) and an encrypted
rule ctr corresponding to a rule r, and outputs a set of indexes
I = {id1,...,idm }, where idi ∈ [n] for i ∈ [m].
Correctness. An MBSE scheme ensures that: (1) for every token
that matches a given rule, the probability of a match is 1; (2) for every
token that does not match a given rule, a match is detected with
only negligibly small probability. Specifically, for any sufficiently
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1663
Enhanced Preprocessing Protocol
Input: MB has inputs ({si
,Ri
,sig(Ri
)}i ∈[N ]
) (from RG); C and
S have common inputs k.
Protocol:
1. C computes Kc = д
k
(using her k), and sends Kc to MB.
Similarly, S computes Ks = д
k
(using her k) and sends Ks to
MB.
2. MB checks whether Kc equals Ks . If not, it halts and outputs
⊥. Otherwise, it sends ({Ri
,Sig(Ri
)}i ∈[N ]
) to C and S.
3. C and S do as follows respectively:
(a) For i ∈ [N], check if Sig(Ri
) is a valid signature on Ri
using the public key of the signature scheme used by RG.
If not, halt and output ⊥.
(b) Compute K = (Kc )
k
(resp. K = (Ks )
k
for S), which will be
reused in the next step.
(c) ComputeKi = (Ri
)
k
·K = д
kαri+ksi+k
2
fori ∈ [N]. Finally,
send {Ki}i ∈[N ]
to MB.
4. For i ∈ [N], MB verifies whether the Ki from C and S are
the same. If not, it halts and outputs ⊥. Otherwise, for i ∈
[N], it calculates reusable obfuscated rule Ii = Ki /(Kc )
si =
д
kαri+k
2
for future use.
Figure 7 Enhanced Preprocessing Protocol
large security parameter λ, for any polynomial n(·), if n = n(λ), for
all (t1,...,tn ) ∈ Mn
, for every rule r ∈ M, for every index id1 such
that r = tid1
and for every id2 such that r , tid2
, we have:
Pr












k,pk ← Setup(1
λ
);
salt, (ct1,...,ctn ) ← TEnc((t1,...,tn ),k,pk);
ctr ← REnc(r,k,pk);
I ← Match(salt, (ct1,...,ctn ),ctr ) :
id1 ∈ I












= 1.
and
Pr












k,pk ← Setup(1
λ
);
salt, (ct1,...,ctn ) ← TEnc((t1,...,tn ),k,pk);
ctr ← REnc(r,k,pk);
I ← Match(salt, (ct1,...,ctn ),ctr ) :
id2 ∈ I












= negl(λ).
5.1.2 Definition of the preprocessing protocol. The preprocessing
protocol is a two-party computation that maps pairs of inputs to
pairs of outputs. We refer to the process of the computation as a
functionality f : {0,1}
∗ × {0,1}
∗ → {0,1}
∗ × {0,1}
∗
, where for every
pair inputs x1,x2, the output pair is (f1 (x1,x2), f2 (x1,x2)). For our
preprocessing protocol, the two parties are C with input k (the first
party) and MB with input r (the second party) (the actual protocol
is a form of r), and the output is only given to MB.
5.2 Security Definition
5.2.1 MBSE Security. The security definition follows that of BlindBox, which is also similar to the security definition of Song et al. [25].
As with BlindBox, our security definition is indistinguishabilitybased. Specifically, given two sets of tokens, no PPT adversary can
distinguish an encryption of one of these two sets of tokens with
chance better than half. In addition, for an MBSE scheme, given an
encrypted rule, the middlebox is able to tell which encrypted token
this rule matches. Hence, in the security definition, we allow the
adversary to choose any number of rules and any two sets of tokens
of the same length, with the restriction that the two sets of tokens
match the set of rules at the same tokens. For an MBSE scheme
defined in Section 5.1, its security is defined by the following games
between a challenger C and an adversary A:
• Setup: C calls the Setup(1
λ
) algorithm and sends the public
parameter pk to A.
• Challenge: In this phase, A chooses two set of tokens T0 =
(t
0
1
,...,t
0
n
), T1 = (t
1
1
,...,t
1
n
) and forwards them to C. C flips a
random coin b ∈ {0,1} and calls the TEnc algorithm with Tb
as input to obtain a salt salt and a set of ciphertexts (c1,...,cn ).
Finally, C sends salt and (c1,...,cn ) to A.
• Query Phase: A randomly chooses a set of rules (r1,...,rl
) and
sends them to C. Fori ∈ [l], C calls the REnc algorithm to obtain
the encrypted rule ctri
. Finally, C sends (ctr1
,...,ctrl
) to A.
• Guess: A outputs his guess b
′ ∈ {0,1} for b.
Let I0,I1 be the sets of indexes that match any rule ri ∈ (r1,...,rl
),
respectively. We say that the adversary wins the above game if
I0 = I1 and b
′ = b for all i ∈ [l].
Definition 5.2. The MBSE scheme is secure if all PPT adversaries
have at most a negligible advantage in λ in the above security game,
where the advantage of an adversary A is defined as AdvA =
Pr[(b
′ = b)] −
1
2
.
5.2.2 Preprocessing Security. PrivDPI employs a preprocessing protocol, where MB obtains a set of reusable obfuscated rules that will
be used in subsequent sessions. There are two security requirements
for the preprocessing protocol: (1) MB should not be able to compute the reusable obfuscated rule of any new rule that is different
from the rules being processed in the preprocessing protocol; (2) C
cannot obtain what the rules are. Intuitively, after the execution of
the protocol, if MB cannot obtain any information about k, we can
conclude that the first security requirement is satisfied. Similarly, if
C cannot obtain any information about r, then the second security
requirement is satisfied. In the threat model described in Section
2.1, MB is semi-honest in the sense that it will follows the protocol.
In the preprocessing protocol described in Section 3.3, all malicious
behaviors of C will be detected by MB using the messages received
from S. Hence, we can treat C as semi-honest in the two-party
computation with MB. We here use the definition of security in
present of static semi-honest adversaries in [9, 16]. Let π be a twoparty protocol for computing the functionality f defined in Section
5.1. Let viewπ
i
be the view of the ith party (i ∈ {1,2}) during an
execution of a protocol π on input (x1,x2) and security parameter
λ, which consists of its input xi
, its internal random coins ci and
the messages that it received. Let Outputπ be the joint output of
the two parties from an execution of π.
Definition 5.3. Let f : {0,1}
∗ × {0,1}
∗ → {0,1}
∗ × {0,1}
∗ be a
functionality. We say that π securely computes f in the presence
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1664
of static semi-honest adversaries if there exist PPT algorithms S1
and S2 such that
{S1 (x1, f1 (x1,x2)), f (x1,x2)}
c
≡ {viewπ
1
(x1,x2),outputπ
(x1,x2)},
{S2 (x2, f2 (x1,x2)), f (x1,x2)}
c
≡ {viewπ
2
(x1,x2),outputπ
(x1,x2)}.
where x1,x2 ∈ {0,1}
∗
such that |x1 | = |x2 |.
Note that the above definition considers the joint distribution of
the output of S1, S2 and the parties, it works for the general case
of probabilities functionalities. For the deterministic functionalities,
we separate the correctness and privacy requirements. The security
definition for deterministic functionalities is shown below.
Definition 5.4. Let f : {0,1}
∗ × {0,1}
∗ → {0,1}
∗ × {0,1}
∗ be a deterministic functionality. We say that π securely computes f in the
presence of static semi-honest adversaries if (1) Outputπ
(x1,x2) =
f (x1,x2); (2) there exist PPT algorithms S1 and S2 such that
{S1 (x1, f1 (x1,x2))}
c
≡ {viewπ
1
(x1,x2)},
{S2 (x2, f2 (x1,x2))}
c
≡ {viewπ
2
(x1,x2)}.
where x1,x2 ∈ {0,1}
∗
such that |x1 | = |x2 |.
5.3 Construction
5.3.1 Construction of MBSE scheme. We provide a construction
that outlines the main structure below from the security context, in
a similar way as BlindBox. In this treatment, we do not include the
underlying data structure since it does not affect security. We also
do not include the preprocessing protocol that generates the set of
reusable obfuscated rules and the session rule preparation phase.
The security of preprocessing protocol will be provided independently. In addition, since session reuse does not affect security, we
only consider the scenario of the first session.
• Setup(1
λ
): Generate k,α ∈ Zp , compute A = д
α
, and set k as
the key and A as pk.
• TEnc((t1,...,tn ),k,pk):
1. Let salt be a random salt and set ct = 0.
2. For each i ∈ [n], do:
(1) Set ct be the number of times ti appeared in the sequence
t1,...,ti−1.
(2) Compute Tti = A
k t
· д
k
2
, Cti = H(salt + ct,Tti
).
3. Output salt,{Cti
}i ∈[n]
.
• REnc(r,k,pk): Output Tr = д
kαr+k
2
.
5.3.2 The preprocessing protocol. Any malicious behaviors of C
can be verified by the messages sent from S, hence, in this simplified
version of preprocessing protocol, we remove the messages sent for
the aim of verification and assume C is semi-honest. As introduced
in Section 2.1, MB is semi-honest, the only malicious act within the
semi-honest model is to send additional R
∗
i
< {Ri}i ∈[N ]
, however,
this can be detected and verified using the signatures sent from
MB trivially. Hence, we do not include the signatures here. The
simplified preprocessing protocol is two-party computation in the
presence of static semi-honest adversaries. The protocol is described
in Fig. 8.
5.4 Security Proof
5.4.1 Security of MBSE Scheme.
Simplified preprocessing protocol
Inputs: C has k ∈ Zp , MB has {si
,Ri
,}i ∈[N ]
, where Ri =
д
αri+si
, si ∈ Zp , {ri ∈ R }i ∈[N ]
, R is the domain of rules.
Protocol:
1. C computes Kc = д
k
and sends Kc to MB.
2. MB sends {Ri}i ∈[N ]
to C.
3. C computes Ki = (Ri
· Kc )
k = д
kαri+ksi+k
2
for i ∈ [N], and
sends {Ki}i ∈[N ]
to MB.
4. For i ∈ [N], MB calculates the reusable obfuscated rule Ii =
Ki /(Kc )
si = д
kαri+k
2
for future use.
Figure 8 Simplified preprocessing protocol
Theorem 5.5. Assuming that H is a programmable random oracle,
the construction of MBSE scheme in Section 5.3 is a secure MBSE
scheme.
The proof of this theorem is given in Appendix A.1.
5.4.2 Security of Preprocessing Protocol.
Lemma 5.6. No computationally unbounded algorithm A, engaging in the role of C in the execution of the simplified preprocessing
protocol, can guess ri with probability greater than 1/|R | with input
Ri
.
The proof of this lemma is given in Appendix A.2.
Theorem 5.7. Assume that DDH problem is hard. Then, the preprocessing protocol securely computes the functionality f in the presence
of static semi-honest adversaries.
The proof of this theorem is given in Appendix A.3.
6 EXTENSIONS OF PRIVDPI
The protocol proposed in Section 3 supports single keyword inspection, which is the simplest case. In this section, we discuss briefly
how our protocol can be extended, just as in BlindBox, to support (1)
a limited form of IDS, (2) a full IDS based on retrieval of the session
key from a matched suspicious keyword (known as probable cause
privacy in BlindBox). This reflects the flexibility of our protocol, in
that PrivDPI does not sacrifice the practical and useful features in
order to achieve marked improvement in efficiency and reusability.
We refer readers who are interested in the details to BlindBox [24,
Section 4].
6.1 Supporting limited form of IDS
PrivDPI can be extended to support matching of multiple keywords
as well as absolute and relative offset information within the encrypted packet. For example, consider a rule with three keywords,
then it is a match if all three keywords appeared in the flow. Industrial rules also contain offset information (e.g. between 10 and
13) and, for example, a rule can be triggered if the content contains certain keywords at the offset of 10-13. The window-based
tokenization approach that we deployed generates token at each
offset and hence can be used to support the above feature.
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1665
6.2 Supporting full IDS
This extension enables full IDS functionality by allowing MB to
decrypt the TLS traffic when a token matches a keyword in the
rule. This allows inspection such as regular expression, that cannot
be achieved based solely on token matching. The basic idea is as
follow.
Insight. For token t, replace the encrypted token Ct = H(salt +
ct,Tt
) in PrivDPI withCt = H(salt+ct,Tt
) ⊕kT LS . In this manner,
it is possible to retrieve the session simply by XORing the matched
encrypted token with the encrypted rule. However, in this case, one
cannot use the rule tree to do the simple tree lookup. In contrast,
it will need a linear scan of the rules in order to perform the XOR
operation.
Construction. To maintain efficiency during detection, we use
a similar method as BlindBox. In particular, for a token whose
encrypted token isCt = H(salt+ct,Tt
), we generate an additional
parameter as C
′
t = H(salt + ct + 1,Tt
) ⊕ kT LS . Now one can use
the rule tree to do the tree lookup for matching. If a match is found,
one can compute C
′′
t = H(salt + ct + 1,Tt
) and compute C
′′
t ⊕ C
′
t
to obtain kT LS .
7 PERFORMANCE EVALUATION
Our experiments were performed by implementing the variant of
PrivDPI (Section 4) on a Intel(R) Core(TM) i7-8750H CPU with 6
cores running at 2.20GHz under 64-bit Linux OS. The CPU supports
AES-NI instructions. PrivDPI is built on Charm-crypto, a python
library that was used to prototype cryptosystems. We also utilize
pyOpenSSL library for establishing TLS connection between C
and S. Our system was constructed based on prime256v1 curve
(known as NIST Curve P-256), which is widely adopted in most of
real-world applications nowadays. We use the rule sets from Snort
Emerging Threats with around 3,000 rules. Each rule is tokenized
to a size of 8 bytes in our evaluation. We measure the time taken
by repeating each instance 10,000 times and eventually take the
average of the results. In order to compare the performance of
PrivDPI and BlindBox, we reconstruct BlindBox with JustGable [6]
and OTExtention [1] to simulate C (and S) and MB in performing
the preprocessing protocol for the preparation of encrypted rules.
7.1 Middlebox
The main computation and communication overhead for the middlebox is in the execution of the pre-processing protocol and token
detection, which we discuss in the followings.
7.1.1 Performance (first session). Here we consider the time and
bandwidth costs for the first session established between the client,
the middlebox and the server.
Time. Table 2 shows the total time in the pre-processing phase
for the preparation of encrypted rules. PrivDPI is more efficient
computation-wise than BlindBox. In particular, PrivDPI takes 0.64
seconds with 3,000 rules compared to BlindBox 183.83 seconds. In
other words, for 3,000 rules, PrivDPI is 288x more efficient. The
reason behind this is that BlindBox requires one garbled circuit per
rule while PrivDPI only requires one exponentiation in G per rule.
Bandwidth. As shown in Table 2, BlindBox requires 50.16GB for
generating 3,000 encrypted rules. PrivDPI achieves better result
Table 2 MB: Time and bandwidth (first session)
No. of Rules
(8 bytes)
Time Bandwidth
BlindBox PrivDPI BlindBox PrivDPI
1 0.595 s 0.1392 s 16.72 MB 57.61 B
3000 183.832 s 0.6371 s 50.16 GB 172.83 KB
Table 3 MB: Time required in token detection
Detection over No. of Rules BlindBox PrivDPI
1 rule, 1 token 7.9 µs
3000 rules, 1 token 30.2 µs
Table 4 MB: Time and bandwidth (subsequent session)
No. of
Sessions
Time Bandwidth
BlindBox PrivDPI BlindBox PrivDPI
1 183.832 s 0.1586 s 50.16 GB 49 B
5 918.14 s 1.271 s 250.845 GB 0.291 MB
10 1838.33 s 2.074 s 501.69 GB 0.292 MB
20 3674.39 s 3.547 s 1003.38 GB 0.293 MB
with 172.83KB. This is because Blindbox sends the messages of
garbled circuit per rule, while PrivDPI only need to send a few
group elements per rule, which only incurs very low bandwidth.
Token detection. The time for token detection is shown in Table
3. The mechanisms deployed are identical between BlindBox and
PrivDPI, hence, the running time are the same.
7.1.2 Performance (subsequent session). We now consider the time
and bandwidth for the subsequent session.
Time. Table 4 shows the running time for 5, 10, 20 consecutive
sessions with the generation of 3,000 rules for comparison. For
20 consecutive sessions, PrivDPI takes only 3.547 seconds, while
BlindBox requires 3674.39 seconds. Hence, PrivDPI is 1,035x faster
than BlindBox. This is due to the fact that BlindBox needs to evaluate a garbled circuit for each rule in each session. In contrast,
PrivDPI can reuse the reusable obfuscated rules generated during
the preprocessing protocol in the first session, eliminating the need
to re-generate the session rules from scratch.
Bandwidth. Table 4 shows the bandwidth for 5, 10, 20 consecutive
sessions in the similar settings as before. For 20 consecutive sessions,
the bandwidth of PrivDPI is 0.293 MB, while the bandwidth of
BlindBox is 1003.38 GB, meaning PrivDPI requires 3424,500x less
bandwidth than BlindBox. As in the previous case, this is because
BlindBox sends the garbled tables for each garbled circuit for each
rule in each session. In contrast, PrivDPI can reuse the reusable
obfuscated rules stored after the preprocessing protocol in the first
session. For each subsequent session, PrivDPI only has to send one
group element per session.
Token detection. As before, the time taken for token detection is
comparable with BlindBox due to the use of similar mechanism.
7.2 Client (or Server)
The main computation and communication overhead is in the execution of the token encryption protocol.
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1666
Table 5 C (or S): Time and Bandwidth
No. of Rules
(8 bytes)
Time
BlindBox PrivDPI
1 0.05110 s 0.00110 s
3000 143.547 s 0.19909 s
7.2.1 Performance (first session). Here we consider time and bandwidth for token encryption in the first session.
Time. The client and server in Blindbox performs garbling of the
AES circuit as in the case of the middlebox described above. However, the time required to perform this operation is lesser than the
time required to perform the operation in middlebox (cf. Table 2)
as the sender do not have to wait for the middlebox to evaluate the
garbled circuit. For PrivDPI, although it seems that the workload is
the same, the fact that without the need to perform circuit garbling
significantly improves the performance for C (or S). Table 5 shows
a comparison between Blindbox and PrivDPI. We observe that more
load is on the middlebox as compared to C (or S) on PrivDPI as
the performance is faster by 721x compared to the previous score
of 288x during the full setup. As network operators are more incentivized to invest in middleboxes with powerful hardware than
client computers, shifting the load from C to the middleboxes is
highly desirable.
Bandwidth. There is no discernible difference between the bandwidth usage of the middlebox (cf. Table 2) and C (or S) between
both protocols, they have equal bandwith requirements as whatever
sent by C (or S) needs to be received by the middlebox.
Token Encryption. Table 6 shows the running time we measured
for 1,000 token in the first session. The running time on the C
(or S) side of PrivDPI is around 6x slower than BlindBox. This is
mainly due to the mechanism in BlindBox requiring two AES encryptions, while PrivDPI requires one exponentiation in G, one
multiplication in G, and one AES encryption. But we note that in
actual client-server communication, repeating tokens are likely to
occur, especially for S
2
(e.g., S having similar content each time it
is accessed by the C). The repeating tokens are key to increase the
encryption performance of PrivDPI, by storing some parts of the
computation in a lookup table. The exponentiation in G and multiplication in G can be eliminated by storing them for future lookup.
This means that for every repeating token, only one AES encryption
is required. Fig 9 shows the improved performances as the number
of tokens repeating increases. Likewise, for any token that repeats
itself a number of times, PrivDPI also shows an improvement by
storing the result of the corresponding exponentiation and multiplication computation. As shown in Fig 10, as the number of times a
token repeating itself increases, the time taken to encrypt the token
drops proportionally. This is also a likely real world scenario given
that keywords in articles or documents tend to have a high number
of ocurrences or the high frequency of common english words like
’something’, ’between’, ’different’, ’together’ and ’important’.
7.2.2 Performance (subsequent session). Building on the same philosophy in the previous section, subsequent session(s) between C
and S must also consist some degree of similarity, and we ask the
2This is the case when the traffic is sent from S to C.
Number of repeated token (for two times)
0 100 200 300 400 500
 Time (Seconds)
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.1
BlindBox
PrivDPI
Figure 9 Token encryption time
Percentage of one token repeating
0 5 10 15 20 25 30
 Time (Seconds)
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.1
BlindBox
PrivDPI Figure 10 Token encryption time
Table 6 Running time in token encryption
No. of Tokens BlindBox PrivBox
1 0.0096 ms 0.0579 ms
500 4.9026 ms 29.0646 ms
1000 10.1182 ms 58.5263 ms
question whether if the same technique will work. We evaluated the
token encryption time against the percentage of repeating token.
We argue that the scenario is also applicable in the real world as C
may use S as a source of information, while the content of S remain
the same over multiple sessions (i.e looking up recipes, tutorial or
specifications online). The results of our evaluation are shown in
Fig 11. One can observe that for a high percentage of tokens being
repeated from the previous session, the performance is comparable
to that of blindbox despite being relatively slow initially. The speed
up is due to the fact that the tokens found in the re-used table only
require one multiplication in G and one AES encryption.
7.3 Performance of a complete TLS session
We also perform a full experiment to evaluate the trade off between
pre-processing and token encryption. For this setup, we consider
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1667
Percentage of repeated token
0 20 40 60 80 100
 Time (Seconds)
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.1
BlindBox
PrivDPI
Figure 11 Token encryption time
that no tokens will repeat and only one session (no reuse) occurs
between a client C and a server S. We recorded the time it takes to
perform the pre-processing protocol and send a 8 bytes (or 1 token)
from C to S and have S reply with a message of the same length.
The whole process includes the pre-processing, token encryption
and detection from a rule set of 3000 rules. In other words, a round
trip of sending 80 bytes (or 10 token) requires 1 setup, 20 token
encryptions and 20 token detections to realize. Bearing in mind
that usually the client-server request to response bandwidth ratio is
generally heavier for the server for general use cases, we chose this
setup to reflect on the most extreme of a client-server architecture,
namely an echo server to show in what scenario will PrivDPI be
advantageous compared to Blindbox.
7.3.1 Analysis. From our experiment, we found that Blindbox will
surpass PrivDPI after transmission of 1.89 million tokens from both
C and S that is graphed on Fig 12. That’s a total of roughly 3.78
million tokens. To put that into perspective, the required transfer
bandwidth for a google search is roughly 0.6-0.8 KB based on different browser tools. Visiting a heavy weight page like youtube.com
requires roughly 2 MB per session of transfer bandwidth. This is
to say that visiting or performing short-lived queries and lookups
to these pages that requires loading only once or twice can be
better with PrivDPI. We note that even with a large number of
inbound/outbound rules, PrivDPI does not jeopardize the performance of the network traffic and is able to allow a client to quickly
establish a session with the middlebox and a server.
8 RELATED WORK
As was stated in our discussion in the introduction, Sherry et al. [24]
introduced BlindBox, one of the early privacy-preserving deep
packet inspection scheme that inspects encrypted traffic directly.
The client establishes an encrypted session with the server. A separate session is also established for token matching. Both the sessions route through MB. The idea is for MB to host encrypted
rulesets derived from the session key of the TLS session. For the
second session, the client tokenizes and encrypts its payloads using
identical key. The tokenized traffic is route through this second
session to MB. MB then tries to match the tokenized traffic with
Number of token ×106
0 0.5 1 1.5 2
0
50
100
150
200
250
300
350
 Time (Seconds)
BlindBox
PrivDPI
Figure 12 Round Trip Total Time
the encrypted rulesets. If matched, the traffic is considered malicious. BlindBox preserves privacy of rules (from C) and the secret
key derived from session key (from MB) through garbled circuit
and oblivious transfer for every session, which is computationally
expensive.
The tokenization mechanism in BlindBox is extended by Lan et
al. [19]. The scheme is termed Embark, which is focused on the setting of outsourced MB. It proposes new token matching technique
that include prefix matching, and caters for different middlebox
services such as IP firewall, NAT, HTTP Proxy, data exfiltration and
intrusion detection. In order to address the performance bottleneck
of BlindBox, Canard et al. [8] proposed BlindIDS. It proposes a
token-matching protocol based on pairing-based public key operation, and is not compatible with existing TLS protocol.
Another scheme that uses public key operation is SPABox by
Fan et al. [15]. The scheme uses oblivious pseudo-random function
for encrypted rule preparation. For regular expression matching,
the scheme deploys a variant of garbled circuit. Yuan et al. [29]
proposed a scheme that is more efficient than BlindBox but requires
the server to first register with the administration service of the enterprise hosting the client. Another scheme, with the cloud setting
is SplitBox proposed by Asghar et al. [5]. It is based on a two cloud
system, in which every rule is XOR with a random string and then
split into many blocks to the various MBs resided in one of the
cloud systems. Both cloud systems then collaboratively compute
the blocks to perform traffic inspection.
There are also proposals based on client-server accountable
model, where both client and server are aware of and can authenticate all the MBs deployed between the two of them. Naylor et
al. [21] introduced a scheme of this type, termed mcTLS. It modifies
existing TLS protocol to allow the client, the MBs and the server
to establish authenticated and secure channel, and exchange read
and write secret keys in addition to the session key. The main issue
with mcTLS is that it is a new protocol. For adoptions, existing
TLS protocol that is widely used must all be replaced with mcTLS.
Acknowledging this issue, Naylor et al. [20] further proposed another scheme, termed mbTLS. It does not change the underlying
TLS protocol, except in introducing extensions that can be readily
adopted using existing protocol. More recently, Bhargavan et al. [7]
Session 7E: Privacy-Preserving Techniques CCS ’19, November 11–15, 2019, London, United Kingdom 1668
demonstrated attacks on mcTLS, and proposed a formal model on
analyzing the protocol.
Other related work include proposal to analyse encrypted traffic
based on machine learning, without inspecting the encrypted payloads. Anderson et al. [2–4] proposed techniques for malware detection that uses various header information or metadata. Trusted hardware has also been deployed for privacy-preserving deep packet
inspection. Most of the proposal utilizes the secure enclave of Intel SGX. The main idea is to give the trusted hardware, resided
in the MB, the session key. The decryption, inspection and reencryption is performed in the enclave. Han et al. [17] proposed a
scheme, SGX-Box, using this technique. There are also proposals
for secure Network Function Virtualization (NFV) systems that use
trusted hardware to provide deep packet inspection. These includes
SafeBricks by Poddar et al. [22], ShieldBox by Trach et al. [26] and
LightBox by Duan et al. [13].
9 CONCLUSION
In this work we proposed a privacy-preserving deep packet inspection system, PrivDPI, which directly inspects encrypted traffic using
a similar detection mechanism as in BlindBox. BlindBox incurs high
performance overhead for the preparation of encrypted rules due
to the use of garbled circuit. Our first key contribution is in minimizing such computation and communication overhead while at
the same time preserves the security and privacy requirements as
in BlindBox. We demonstrated that our encrypted rule generation
on a ruleset of 3,000 is 288x times faster. We further introduce the
notion of reusable obfuscated rules, which enables a client and the
middlebox to reuse them in subsequent sessions. Such reusable obfuscated rules only need to be generated in the first session, which
greatly reduce the performance overhead. We demonstrated that
our encrypted rule generation over 20 consecutive sessions on a
ruleset of 3,000 is 1036x faster. We note that, the limitation of our
system is that the token encryption of payloads is 6x slower than
BlindBox. By reusing of encrypted token generated previously, the
token encryption is only 3.5x slower in the ideal case that all the
tokens of the current session have appeared before. Overall, the
computation time for a full session is faster than BlindBox on a ruleset of 3,000 providing that there are less than roughly 3.78 million
tokens.