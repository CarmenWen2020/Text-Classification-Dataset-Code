Many real-world social networks are decentralized in nature, and
the only way to analyze such a network is to collect local views of
the social graph from individual participants. Since local views may
contain sensitive information, it is often desirable to apply differential privacy in the data collection process, which provides strong
and rigorous privacy guarantees. In many practical situations, the
local view of a participant contains not only her own connections,
but also those of her neighbors, which are private and sensitive for
the neighbors, but not directly so for the participant herself. We call
such information beyond direct connections an extended local view
(ELV), and study two fundamental problems related to ELVs: first,
how do we correctly enforce differential privacy for all participants
in the presence of ELVs? Second, how can the data collector utilize
ELVs to obtain accurate estimates of global graph properties?
This paper points out that when collecting ELVs, it is insufficient
to apply a straightforward adaptation of local differential privacy
(LDP), a commonly used scheme in practice, to protect the privacy
of all network participants. The main problem is that an adversarial
data collector can accumulate private information on a specific
victim from multiple neighbors of the victim; even though the
data collected from each neighbor is perturbed under LDP, their
aggregate can still violate the victim’s privacy. To prevent this
attack, we formulate a novel decentralized differential privacy (DDP)
scheme, which requires that each participant consider not only her
own privacy, but also that of her neighbors involved in her ELV.
The stringent privacy requirement of DDP, however, makes it
challenging to design an effective mechanism for data collection.
Towards this goal, we design a novel multi-phase framework under DDP that enables an analyst to accurately estimate subgraph
counts, an important property of social graphs. The main idea is
that instead of collecting subgraph counts directly, which would
require excessively noise, the analyst first asks individuals about
their respective minimum noise scale, which is private information
since it depends on the local graph structure, and, thus, must be
performed under DDP. For some types of subgraphs, this process is
applied recursively, i.e., the analyst asks about the necessary noise
to be injected into the private information on the minimum local
noise scale required to protect subgraph counts under DDP. As
case studies, we instantiate the proposed framework for three common subgraph patterns: triangles, three-hop paths, and k-cliques.
Extensive experiments using real data demonstrate that the proposed scheme leads to accurate estimates of global subgraph counts,
whereas baseline solutions fail to obtain meaningful result utility.
CCS CONCEPTS
• Security and privacy → Data anonymization and sanitization.
KEYWORDS
decentralized differential privacy; subgraph statistics; social networks
1 INTRODUCTION
In this paper, we consider the problem of analyzing a decentralized
social network, in which the analyst cannot directly obtain information on the global structure of the network. Instead, the analyst
needs to communicate with individual participants of the network,
each of which has a limited local view of the whole social graph.
Then, the analyst combines information from different participants
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 703
to estimate the global network properties. The setting of decentralized social networks could arise due to a variety of reasons.
First, many social networks are inherently decentralized as there is
no central organizer. For instance, the contact lists in everybody’s
mobile phones could be pieced together to form a giant contacts
social network, though no single entity is aware of the whole network structure. Second, even when there is a centralized entity that
possesses the knowledge of the entire network, that entity may
choose not to share it with the analyst, out of business, legal or
other considerations. For example, an organization operating an
anonymous messaging app could see who messages whom (though
not necessarily message contents). However, it would be difficult
to share such a communication network with outsider analysts.
Collecting information of users’ local views has a clear privacy
implication, as they often reflect sensitive social interactions among
individuals. Any analysis of decentralized social networks thus has
to ensure rigorous protection of privacy. In this paper we consider
private data collection under the differential privacy scheme [11],
in which each individual injects random noise into her private
information, and only releases the perturbed version to the data
collector; the exact private information is never revealed. The scale
of random noise is calibrated according to a pre-defined privacy
budget [11]. A lower privacy budget leads to stronger perturbation
and lower accuracy of the analysis, and vice versa.
In many social networks, a participant is aware of not only
her own connections, but also a broader subgraph in her local
neighborhood. We call such a subgraph an extended local view (ELV).
For instance, with the default setting of Facebook (facebook.com),
a user allows each of her friends to see all her connections. In the
offline world, we also commonly accumulate knowledge on the
relationships between our friends, e.g., when we attend a social
event together. Hence, the ELV of a social network participant often
contains multi-hop neighbors and their connections. Accordingly, the
participant could reveal private information about her neighbors’
connections to the data collector. To our knowledge, this is the first
study that considers this problem: that an individual must protect
not only her own privacy, but also the privacy of her neighbors.
The presence of ELVs poses new challenges for privacy protection. As pointed out in Section 2, a straightforward application of
local differential privacy (LDP) [13], a popular scheme used in several major software systems such as Google Chrome [13] and Apple
iOS / macOS [38], fails to provide sufficient privacy protection in
this case. The deficiency comes from the fact that in LDP, each
individual has her privacy budget locally, which covers her entire
ELV regardless of what specific information from the ELV is collected. Therefore, an adversarial data collector with a target victim
in mind can gather multiple reports of the same private information
(e.g., whether the victim has a politically sensitive connection) from
multiple individuals in the victim’s neighborhood, and combine
them to infer the sensitive connection with high confidence.
We address the above problem with a new privacy preservation
scheme called decentralized differential privacy (DDP). As explained
in Section 2, all participants of the social network share the same
privacy budget, which covers the entire social graph; each individual, when reporting information about her ELV to the data collector,
must ensure that the released information is sufficiently perturbed
to protect all graph participants, i.e., the data collector cannot infer
the presence or absence of any edge in the graph from all collected
reports. Under DDP, however, it is rather challenging to design
an effective mechanism to obtain high result utility of an analysis,
since the privacy definition is over the global graph, whereas data
come from individual local views.
Towards the goal of accurate social graph analysis under DDP,
we propose a multi-phase framework for subgraph counting, a
fundamental type of graph analyses, under (ϵ, δ)-decentralized
differential privacy (defined in Section 2), where ϵ represents the
total privacy budget for all nodes in the social graph, and δ controls
the probability that every node’s privacy is preserved. The main
idea is that instead of collecting information (i.e., local subgraph
counts) directly, which would require excessive noise to cover worstcase scenarios, the analyst first asks each node in the network
(corresponding to an individual) about the minimum amount of
noise necessary to protect the node’s local subgraph count under
DDP. In a subsequent phase, the analyst determines the minimum
noise scale for the whole network, and collects subgraph counts
accordingly. Since the noise scale now reflects the true social graph
structure rather than pathological, worst-case scenarios, the end
result is often significantly more accurate than directly collecting
subgraph counts from nodes.
Note that in the first phase, i.e., minimum noise scale computation, the noise scale reported by a node depends on the structure
of its ELV, which is private information. Therefore, the noise scale
itself must be perturbed to satisfy DDP. In the process of DDPcompliant collection of noise scale, we can recursively apply the
above framework. In particular, the analyst first asks each node to
report the (second-level) minimum noise scale necessary to perturb
the (first-level) noise scale for subgraph counts. Then, the analyst
aggregates the second-level noise scale information to obtain a tight
bound on the noise for subgraph counts. The second-level noise
scale, in turn, depends on the nodes’ ELV structures, and needs to
be collected under DDP.
We instantiate this framework with several different types of subgraph patterns, including triangles, three-hop paths, and k-cliques,
each with its own specific optimizations. Extensive experiments,
using multiple real datasets, confirm that the proposed methods
obtain significantly higher result utility compared to baseline solutions as well as existing ones.
In summary, we make the following contributions in the paper:
• We propose decentralized differential privacy, a new privacy
protection scheme for graph analysis that correctly enforces
differential privacy for all social network participants, in the
presence of extended local views.
• We design a novel multi-phase, recursive framework that
utilizes local graph structures to accurately estimate global
subgraph counts in a decentralized graph, under the (ϵ, δ)-
DDP requirement.
• We instantiate the proposed multi-phase framework on common subgraph patterns such as triangles, three-hop paths
and k-cliques, and develop pattern-specific optimization for
each case.
• We conduct comprehensive experiments over several real
social graphs. The results show that the proposed technique
consistently outperforms baseline and existing solutions in
terms of result accuracy, by large margins.
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 704
2 BACKGROUND AND DECENTRALIZED
DIFFERENTIAL PRIVACY
2.1 Differential Privacy
Since first proposed by Dwork et al. [11], differential privacy quickly
becomes a de facto standard privacy definition in sensitive data analysis and publishing. Differential privacy was originally designed
for the centralized setting, where a database of private user information is managed by a trust party, who answers queries about the
database while preserving each user’s privacy. Formally, we have
the following definition:
Definition 2.1 (Differential privacy). A randomized mechanism
M satisfies (ϵ, δ)-differential privacy, if for any pair of neighboring
datasets D and D
′
that differ by one record, and any set of possible
outputs S ⊆ ranдe(M), we have
Pr(M(D) ∈ S) ≤ Pr(M(D
′
) ∈ S) · e
ϵ + δ .
When δ = 0, M satisfies ϵ-differential privacy.
Essentially, differential privacy ensures that from the output of
M, one cannot distinguish whether the input is D or D
′ with high
confidence. ϵ is often called the privacy budget, as it controls the
strength of privacy protection offered by differential privacy.
One common technique to achieve differential privacy is the
Laplace mechanism [11], which adds noise following the Laplace
distribution to obfuscate the true outcome of a query. Specifically,
let f : D → R
d be a function, where D is a set of datasets and
d is a positive integer. The sensitivity of f , denoted ∆f , is given
by ∆f = max ∥ f (D) − f (D
′
) ∥1, over all pairs of neighboring
datasets D and D
′
. It has been shown that M(D) = f (D) + Y,
where Y ∼ Lap(
∆f
ϵ
), satisfies ϵ-differential privacy [11]. We also
call λ =
∆f
ϵ
the scale of the Laplace noise.
Differential privacy is composable: given t randomized mechanisms M1, . . . ,Mt that satisfy (ϵ1, δ1), . . . ,(ϵt
, δt )-differential privacy respectively, the sequential composition of Mi(D) satisfies
(
Ít
i=1
ϵi
,
Ít
i=1
δi)-differential privacy.
2.2 Decentralized Differential Privacy
Let G = (V, E) be a social graph, where V is the set of participants
and E is the set of edges. For simplicity, we assume G is undirected.
A data analyst, who have no access to the whole graph G, aims
to estimate global statistical properties of G, e.g., the number of
occurrences of a given subgraph such as triangles or cliques. To
do so, the analyst collects information from each participant, i.e.,
nodes in V . Each node v ∈ V has an extended local view (ELV) of G,
denoted Gv , which corresponds to a subgraph of G surrounding v.
Since each node v clearly knows all its direct connections, its
ELVGv always contains (i) all edges involving v and (ii) all one-hop
neighbors of v, each of which (say, node u) satisfies that there exists
an edge (u, v) ∈ E. In this paper, we focus on a common type of ELV
that also includes two-hop neighbors1
, as defined in the following.
Definition 2.2 (Two-Hop Extended Local View). Given a node v ∈
V , its two-hop extended local view (ELV) Gv consists of:
• v’s one-hop neighbors: {u | u ∈ V ∧ (u,v) ∈ E}.
1We leave ELVs beyond two-hop neighborhoods for future work as they are less
common in practice.
v1
v2
v3
v4
v5
v1’s local view
v1
v2
v3
v4
v5 v6
v7
v8
v9
The global graph G
v3
v5 v6
v7
v8
v9
v4
v8’s local view
Figure 1: Example of two-hop ELVs
• Edges involving v: {e = (v,u) | e ∈ E}.
• v’s two-hop neighbors: {w | ∃u ∈ V, (u,v) ∈ E ∧ (u,w) ∈ E}.
• Edges involving v’s one-hop neighbors: {e = (u,w) | e ∈
E ∧ (u,v) ∈ E}
Figure 1 shows an example with 9 nodes v1, . . . ,v9. The ELV of
v1 contains its one-hop neighbors v2 and v3, two-hop neighbors
v4 and v5, as well as the edges between these nodes. Similarly, the
ELV ofv8 consists of nodesv5,v7,v9 (one-hop neighbors),v3,v4,v6
(two-hop neighbors), 3 edges betweenv8 and its one-hop neighbors,
2 edges between its one-hop neighbors, e.g., (v9,v7)), and 4 edges
connecting its one-hop and two-hop neighbors, e.g., (v5,v4).
In our setting, since the analyst needs to collect information
from all social network participants, we assume that the analyst
already knows their identities (i.e., membership in V ), and the
private information is on the connections between them (i.e., E). In
other words, we focus on the edge privacy model [20]. This leads
to the following definition of neighboring graphs:
Definition 2.3 (Neighboring graphs). Two graphs G and G
′
are
neighboring graphs if G and G
′ only differ in one edge, i.e., G
′
can
be obtained by adding or removing one edge from G.
Why local differential privacy is insufficient. Before presenting our privacy model, we first explain why a straightforward
application of local differential privacy (LDP) [13] fails to provide
adequate privacy protection in the presence of ELVs. Specifically,
in LDP, each individual has her privacy budget locally, and submits
a report based on her local data to the analyst, which is perturbed
to satisfy differential privacy. In our setting, the local data of an
individual v is her ELV Gv ; thus, LDP ensures that the data collector cannot distinguish v’s exact data Gv from a neighbor dataset,
which in our setting would be a neighbor graph (Definition 2.3) of
Gv . Formally, we define (ϵ, δ)-LDP as follows:
Definition 2.4 (Local differential privacy). Given a node v ∈ V
and its ELV Gv , a randomized mechanism M satisfies (ϵ, δ)-LDP,
iff. for any neighboring graph G
′
v of Gv and any set S of possible
outputs of M, we have Pr(M(Gv ) ∈ S) ≤ Pr(M(G
′
v
) ∈ S) · e
ϵ +δ.
To see why the above privacy definition is insufficient, consider
the case where an adversarial data collector with a specific target
victim u aims to find whether u is connected to another node v.
To do so, the data collector asks u, as well as all of its one-hop
neighbors, to report a binary value on whether edge (u, v) exists.
After that, the data collector computes the mean value of these
binary reports. Although each report satisfies LDP, the mean value
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 705
over multiple reports yields an increasingly accurate estimate of
the true value as the number of reports grows. With a sufficiently
large number of reports, the adversary obtains high confidence on
whether edge (u, v) exists. This clearly violates the privacy of u.
Decentralized differential privacy. The key reason that the
above definition of LDP fails to provide adequately protection on
the social network participants’ privacy, is that each participant
only considers her own privacy when releasing information to the
data collector, and the released information compromises her neighbors’ privacy. To remedy this, we propose a decentralized differential
privacy (DDP) scheme, which ensures that the data collector cannot
infer the presence of absence of any edge in the graph from the set
of all reports collected from all network participants. In particular,
we first define the notion of neighboring ELV, as follows.
Definition 2.5 (Neighboring extended local views). Given a graph
G = (V, E), a node v ∈ V , its ELV Gv ⊆ G, and a neighboring graph
G
′ of G. The neighboring ELV G
′
v of Gv with respect to G
′
is then
the ELV of v in G
′
.
Note that in the above definition, a neighboring ELV G
′
v of Gv
is not the same as a neighbor graph of Gv as Definition 2.3. In
particular, two neighboring ELVs may not contain the same set of
nodes, and can differ in multiple edges. For instance, in Figure 1, if
we remove edge (v1, v2) from G, then node v4 is no longer in the
ELV of v1, since it is now a three-hop neighbor of v1. Similarly, if
we add a new edge (v1, v8) to G, then nodes v7-v9 enter the ELV of
v1, along with all the edges connecting them. Based on the notion of
neighboring ELVs, we define the proposed decentralized differential
privacy (DDP) scheme, as follows.
Definition 2.6 (Decentralized differential privacy). Given a set of
nodes V = v1,v2, . . .vn, a set of randomized mechanisms {Mi
, 1 ≤
i ≤ n} collectively satisfy (ϵ, δ)-DDP, iff. for any two neighboring
graphs G = (V, E) and G
′ = (V, E
′
), and any subsets of possible
outputs {Si ⊆ ranдe(M), 1 ≤ i ≤ n}, we have:
Pr(M1(G1) ∈ S1, . . . ,Mn(Gn) ∈ Sn)
≤ Pr(M1(G
′
1
) ∈ S1, . . . ,Mn(G
′
n
) ∈ Sn) · e
ϵ + δ,
where Gi and G
′
i
(1 ≤ i ≤ n) are the neighboring ELVs of vi with
respect to G and G
′
, respectively. In addition, since our DDP is
under the (ϵ, δ)-DP framework, the composition rule still applies.
Discussion. Similar to the case of LDP (Definition 2.4), in DDP
each node vi applies its own randomized mechanism Mi(Gi) on
its local data, i.e., its ELV Gi
. In other words, no knowledge of the
global graph G is required when node vi computes its report Mi to
be submitted to the data collector. On the other hand, unlike LDP
where each node independently preserves its own privacy without
any consideration for its neighbors, DDP covers the set of all mechanisms applied to all nodes as a whole, and protects all edges in
the entire social graph G. Hence, the attack on LDP in which the
data collector obtains multiple reports on the same information no
longer works under DDP, since the latter by definition guarantees
that the data collector cannot infer the presence of absence of an
edge from all collected reports.
Our problem is different from existing LDP applications where
users have independent data, e.g., collecting browser usage [13].
Instead, DDP can be viewed as a generalization of LDP when users’
data are dependent, following the general principle of differential
privacy in the local setting [10].
Designing effective mechanisms under DDP, however, is also
significantly more challenging compared to the case of LDP. The
main difficulty is that when generating a perturbed report Mi
, each
node vi must consider all possible neighbor graphs of the global
graph G; yet, vi does not know G, except for its own ELV Gi
. We
address this problem in the next section.
3 A GENERAL FRAMEWORK FOR
SUBGRAPH COUNTING UNDER DDP
In this paper, we focus on a fundamental problem in graph analysis:
subgraph counting, under the decentralized differential privacy
requirement in Definition 2.6. Specifically, let д be a given subgraph
pattern, e.g., a triangle, a k-clique, etc., the data analyst aims to
estimate the number of occurrences of д in the global graph G, by
collecting data from each node in G under (ϵ, δ)-DDP.
Given a node vi ∈ V and its two-hop ELV Gi
, we define γд(vi)
as the exact number of occurrences of д in Gi that involve vi
itself.
In other words, occurrences of д in Gi that does not contain vi are
not counted in γд(vi). In the non-private setting, the data analyst
simply collects the exact γд(vi) from each vi
, and aggregates them
to obtain the total number of occurrences of д in the whole graph
G. For example, when д is a triangle, the analyst simply adds up the
local triangle counts from every node, and then divides the result
by 3, since every triangle is reported 3 times by each of its nodes.
Under the DDP requirement, each node vi cannot reveal the
exact γд(vi), as it depends on vi
’s private information Gi
. Instead,
each vi submits a perturbed report Mi(Gi) generated through a
DDP-compliant mechanism Mi
. For instance, one straightforward
approach, explained below in Section 3.1, is to let each vi submit
a noisy version γ
∗
д
(vi) of γд(vi), perturbed under DDP. In general,
the mechanism Mi applied at each node vi can be different, as long
as the set of all Mi
’s for 1 ≤ i ≤ n satisfy DDP as in Definition 2.6.
In our setting, we assume that the data analyst as well as all
participants of the social network strictly follow the proposed protocols. In other words, the adversary is honest but curious. The case
where the analyst actively breaks the protocol to gain private information, possibly in collusion with some of the network nodes,
is out of the scope of this paper, and left as future work.
3.1 A Baseline Approach
We first present a baseline approach, referred to as Pessimistic
Laplace mechanism, in which the analyst directly collects perturbed
subgraph counts from the participants under DDP. As shown soon,
this method incurs a prohibitively high amount of noise, due to the
fact that in order to satisfy DDP, the method has to consider pathological worst-case scenarios that necessitate heavy perturbations.
This highlights the challenge of mechanism design under DDP.
Pessimistic Laplace mechanism follows the standard Laplace
mechanism [11]. Specifically, we first extend the notion of sensitivity
(explained in Section 2.1) to the DDP setting, as follows.
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 706
Definition 3.1 (Sensitivity under DDP). Given a set of nodes V =
{vi
| 1 ≤ i ≤ n}, and a function f , the sensitivity of f is defined as:
∆(f ) = maxG,G′
Õn
i=1
| f (Gi) − f (G
′
i
)|,
where G and G
′
are two arbitrary neighboring social graphs with
the set of nodes V , and {Gi } and {G
′
i
} (1 ≤ i ≤ n) are the sets of
neighboring ELVs with respect to G and G
′
, respectively.
In Pessimistic Laplace mechanism, given a subgraph pattern д,
each participant directly reports a noisy version of its subgraph
count γд(vi). Formally, f = Γд, where Γд(Gi) = γд(vi). The sensitivity ∆(Γд) of Γд, however, is prohibitively high, leading to poor
result utility.
To explain, consider a simple case where д is a triangle. (Other
cases of д are discussed later in Section 4.) We have ∆(Γ△) = 3(n−2)
since (i) in the worst case, an edge (u, v) in an n-node graph can
appear in n − 2 triangles, when both u and v are connected to
all other nodes in the entire social graph, and (ii) each triangle
is reported three times by its three vertices, respectively. Note
that to satisfy DDP, in which privacy is defined over the entire
graph G, we must consider all possible cases of G, including the
above worst case. According to the following lemmata, adding
Laplace noise Lap 
3(n−2)
ϵ

intoγ△(vi) ensures ϵ-DDP, but leads to a
prohibitively high noise variance in the resulting estimated triangle
count: O

n
3
ϵ
2

. Note that the noise variance only depends on the
number of n, regardless of the structure of the actual social graph
G, since the sensitivity is derived from the worst-case scenario.
Lemma 3.2. Adding i.i.d. Laplace noise Lap 
3(n−2)
ϵ

to γ△(vi) of
each vi satisfies ϵ-DDP 2
.
Lemma 3.3. Pessimistic Laplace mechanism leads to O

n
3
ϵ
2

variance in the estimated total triangle count.
Discussion. The above description of Pessimistic Laplace ensures
ϵ-DPP, which can be viewed as (ϵ, δ)-DDP for the strict case that
δ = 0. When δ > 0, we can improve its accuracy as follows. Each
node vi reports its exact subgraph count γд(vi) with probability
δ, and the perturbed subgraph count (according to the above approach) otherwise. Alternatively, we could follow the Gaussian
mechanism [1] instead of the Laplace mechanism, which we call
the Pessimistic Gaussian mechanism. Neither of these approaches,
however, addresses the core issue that we inject noise according
to some pathological worst-case scenario, regardless of the actual
structure of the social graph G. As our experiments in Section 5
shows, none of these baseline approaches obtain competitive result
accuracy.
3.2 Proposed Multi-Phase Framework
Local sensitivity. Observe that the main reason that Pessimistic
Laplace mechanism incurs a high noise variance is that it injects
noise based on the global sensitivity of the graph count function
Γд, which is determined by a worst-case scenario. In real social networks, however, such pathological scenarios are rare. The proposed
2Proofs can be found in the Appendix.
framework avoids the excessive noise due to the worst case, by
employing the concept of local sensitivity [30], defined as follows.
Definition 3.4 (Local sensitivity under DDP). Given a global graph
G = (V, E) containing nodes V = {vi
|1 ≤ i ≤ n}, and a function f .
The local sensitivity of f is defined as:
LS(f ) = maxG,G′
Õn
i=1
|f (Gi) − f (G
′
i
)|,
where G
′
is an arbitrary neighboring graph of G, and {Gi } and
{G
′
i
} (1 ≤ i ≤ n) are the sets of ELVs with respect to G and G
′
,
respectively.
For instance, in the case of triangle counting, we have LSG (Γ△) =
maxG′
Ín
i=1
|γ△(vi) −γ
′
△
(vi)|, where G
′
is any neighboring graph
of G, and γ
′
△
(vi) denotes the triangle count to be reported by
vi
in G
′
. In other words, LSG (Γ△) measures the maximum number of triangles affected by adding or removing one edge in G. If
LSG (Γ△) ≪ n − 2, is it sufficient to ask each user to inject Laplace
noise Lap 
3LSG (Γ△)
ϵ

into her triangle count? Unfortunately, the
answer is no: it has been shown in the literature [30] that injecting
noise according to local sensitivity fails to satisfy differential privacy. Figure 2 shows an example in the same setting as in Figure
1. Consider the task of triangle counting. The local sensitivity at
node v1 is 1, since adding / removing any edge in the global graph
G (shown in Figure 1) can only change the number of triangles
in G1 by at most 1. Observe that the local sensitivity value at v1
in fact only depends on its ELV G1, regardless of the structure of
G outside G1. Now, consider a neighbor graph G
′ of G, which is
identical to G except for one addition edge (v1, v8). On G
′
, the local
sensitivity of triangle counting at v1 becomes 2, e.g., adding an edge
(v1, v5) leads to two additional triangles. Therefore, the value of
the local sensitivity reveals whether the global is G or G
′
, meaning
that using its exact value in the randomized mechanism Mi would
violate differential privacy.
In the traditional, centralized setting of differential privacy, there
exist solutions (e.g., [22, 24, 30, 42]) that correctly inject noise based
on an adjusted version of local sensitivity. However, as reviewed in
Section 6, none of them applies to our setting, since they all rely
on knowledge about the global graph G. Our proposed framework
directly tackles the root problem that local sensitivity fails to satisfy
differential privacy: that the noise scale itself is private information.
The idea is simple: we still injects Laplace noise into each node’s
subgraph count γд(vi), but the scale of the noise is not deterministic. Instead, the noise scale is a random variable sampled from
a carefully chosen distribution, such that with 1 − δ probability,
the injected Laplace noise can conceal the existence or absence of
any particular edge in G. This idea is explored in previous work
[21, 24] under the centralized differential privacy model (CDP). But
its adoption in the DDP setting is highly non-trivial due to the
fundamental differences between CDP and DDP.
Two-phase framework. Let д be a subgraph pattern and Γд =
{γд(v1), . . . ,γд(vn)} be the set of subgraph counts that each user
is asked to report. Our solution consists of two phases. Phase 1
applies an (ϵ1, δ1)-DDP algorithm to collect information about each
user, and decides an appropriate noise scale λ. After that, Phase 2
asks each user to report her subgraph count injected with Laplace
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 707
v1
v2
v3
v4
v5
v1’s local view G1
v1
v2
v3
v4
v5
The local sensitivity of G1 is 1
v1
v2
v3
v4
v5
A neighboring local view G’1 of G1
v1
v2
v3
v4
v5
v8
v1
v2
v3
v4
v5
v8
v1
v2
v3
v4
v5
v8
The local sensitivity of G’1 is 2
Figure 2: Local view sensitivity
noise Lap(λ), and we show that this satisfies ϵ2-DDP with at least
1 − δ2 probability, for some ϵ2 and δ2. According to the sequential
composition property of differential privacy (explained in Section
2.1), the two-phases as a whole satisfies (ϵ, δ)-DDP where ϵ = ϵ1+ϵ2
and δ = δ1 + δ2. It turns out that Phase 1 of our solution needs
to be custom-designed for different types of subgraph patterns д,
which we detail in Section 4. In what follows, we present the main
requirements for Phase 1 necessary for the proposed framework to
satisfy (ϵ, δ)-DDP.
Let λ be the noise scale returned by Phase 1 given a graph G. We
require that λ satisfy the following two conditions:
(1) λ is generated using an (ϵ1, δ1)-DDP algorithm.
(2) With at least 1 − δ2 probability, we have
ϵ2 · λ ≥ LSG

Γд

. (1)
Intuitively, in the above two-phase framework, Phase 1 essentially aims to establish an upper bound on the local sensitivity
LSG (Γд) to be used in Phase 2. This upper bound is estimated by
λ
ϵ2
. There is a chance (i.e., with probability δ2) that Phase 1 can fail,
in which case λ
ϵ2
< LSG (Γд). Such failures are tolerated by the (ϵ,
δ)-differential privacy definition as long as the failure probability
satisfies δ2 < δ. Meanwhile, in the framework Phase 1 is left as a
black box, as long as it satisfies the above conditions.
From two-phase to multi-phase. In the above framework, Phase
1 is a black box that involves an (ϵ1, δ1)-DDP mechanism to compute λ. This mechanism can be realized by recursively applying
the two-phase framework itself, leading to a multi-phase solution.
Specifically, we split Phase 1 into two sub-phases: Phase 1.1 and
Phase 1.2. Meanwhile, we partition the privacy parameters (ϵ1, δ1)
allocated to Phase 1 into (ϵ1,1, δ1,1) and (ϵ1,2, δ1,2), and assign them
to Sub-Phases 1.1 and 1.2, respectively.
As before, in Sub-Phase 1.1, we estimate an appropriate noise
scale λ1 using a black box (ϵ1,1, δ1,1)-DDP mechanism. Then, SubPhase 1.2 applies the Laplace mechanism, which, when used with a
correct noise scale, satisfies ϵ1,2-differential privacy. Sub-Phase 1.1
has a probability δ1,2 to fail, i.e., its output noise scale is not sufficiently large for Sub-Phase 1.2 to satisfy ϵ1,2-differential privacy.
Essentially, Sub-Phase 1.1 estimates the local sensitivity
LSG (LSG (Γд)) of local sensitivity LSG (Γд) of graph counts. Its output is an upper bound of the true LSG (LSG (Γд)) with probability
1 − δ1,2. Then, Sub-Phase 1.2 uses the estimated LSG (LSG (Γд)) to
output an estimated LSG (Γд), which is an upper bound of its true
value with probability 1 − δ2. Finally, Phase 2 applies the estimated
LSG (Γд) to obtain randomized subgraph counts. A concrete instantiation is presented later in Section 4.2.
Correctness of the framework. To formally establish the correctness of the proposed multi-phase framework, it suffices to prove
the two-phase case; the multi-phase case can then be proved by
induction. For the two-phase framework, we prove that the two
requirements for Phase 1 (i.e., it satisfies (ϵ1, δ1)-DDP and its output
λ satisfies Inequality (1) with probability 1 − δ2) ensure that our
solution achieves (ϵ, δ)-DDP for ϵ = ϵ1 + ϵ2 and δ = δ1 + δ2.
Let (λ,Y) denote the output of Phase 1, and Γ
∗
д denote the set
of noisy subgraph counts returned by Phase 2. Here, Y represents
all additional private information besides λ that is revealed to the
data collector during Phase 1. Let Sλ
(resp. SΓ) be an arbitrary set
of possible outputs from Phase 1 (resp. Phase 2). We will establish
the privacy guarantee of our solution by showing that, for any
neighboring graphs G and G
′
and for any Γ
∗
д
, λ, and Y,
Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ Sλ



G
i
≤ e
ϵ
· Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ Sλ



G
′
i
+ δ . (2)
Let S
′
λ
be the subset of Sλ
such that
S
′
λ
=

(λ,Y)


(λ,Y) ∈ Sλ ∧ ϵ2 · λ ≥ LSG

Γд
	
.
We have
Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ Sλ



G
i
= Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ S′
λ



G
i
+ Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ Sλ \ S′
λ



G
i
≤ Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ S′
λ



G
i
+ δ2, (3)
since Phase 1 ensures Eq. (1) with at least 1 − δ2 probability. Then,
to prove Eq. (2), it suffices to show that
Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ S′
λ



G
i
≤ e
ϵ
· Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ S′
λ



G
′
i
+ δ1. (4)
Since (λ,Y) is generated using an (ϵ1, δ1)-DDP algorithm, we have
Pr
(λ,Y) ∈ S′
λ

 G

≤ e
ϵ1
· Pr
(λ,Y) ∈ S′
λ

 G
′

+ δ1.
Therefore,
Pr h
Γ
∗
д ∈ SΓ, (λ,Y) ∈ S′
λ



G
i
= Pr h
Γ
∗
д ∈ SΓ


 (λ,Y) ∈ S′
λ
,G
i
· Pr
(λ,Y) ∈ S′
λ

 G

≤ Pr h
Γ
∗
д ∈ SΓ


 (λ,Y) ∈ S′
λ
,G
i
·

e
ϵ1
· Pr
(λ,Y) ∈ S′
λ

 G
′

+ δ1

≤ e
ϵ1
· Pr h
Γ
∗
д ∈ SΓ


 (λ,Y) ∈ S′
λ
,G
i
· Pr
(λ,Y) ∈ S′
λ

 G
′

+ δ1
(5)
We will show that for any x ≥ LSG (Γд)/ϵ2, any y, and any set ϒ
of noisy subgraph counts,
Pr h
Γ
∗
д = ϒ



λ = x,Y = y,G
i
≤ e
ϵ2
· Pr h
Γ
∗
д = ϒ



λ = x,Y = y,G
′
i
,
(6)
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 7            
which would lead to
Pr h
Γ
∗
д ∈ SΓ


 (λ,Y) ∈ S′
λ
,G
i
≤ e
ϵ2
·Pr h
Γ
∗
д ∈ SΓ


 (λ,Y) ∈ S′
λ
,G
′
i
.
This, when combined with Eq.(3), (4), and (5), shows that our twophase approach ensures (ϵ, δ)-DDP.
Let Γд = {γд(vi)} and Γ
′
д = {γ
′
д
(vi)} be the subgraph counts
on G and G
′
respectively. Since Phase 2 generates Γ
∗
д
by injecting
Laplace noise Lap(λ) into each subgraph count, we have
Pr h
Γ
∗
д = ϒ



λ = x,Y = y,G
i
Pr h
Γ
∗
д = ϒ



λ = x,Y = y,G′
i
=
1
2x
exp 
−
1
x
Ín
i=1


γ
∗
д
(vi) −γд(vi)




1
2x
exp 
−
1
x
Ín
i=1


γ
∗
д
(vi) −γ
′
д
(vi)




≤ exp
1
x
Õn
i=1


γд(vi) −γ
′
д
(vi)



!
≤ exp 
1
x
LSG (Γд)

≤ e
ϵ2
,
where the last inequality is due to x ≥ LSG (Γд). Therefore, Eq. (6)
is proved. Thus, we arrive at the following theorem:
Theorem 3.5. The proposed two-phase framework ensures (ϵ, δ)-
DDP whenever ϵ1 + ϵ2 ≤ ϵ and δ1 + δ2 ≤ δ.
4 COUNTING DIFFERENT TYPES OF
SUBGRAPHS UNDER DDP
In this section, we instantiate the proposed multi-phase framework for subgraph counting under DDP on three types of common
subgraphs: triangles, three-hop paths and k-cliques. These instantiations are themselves non-trivial, and involve subgraph-specific
optimizations necessary to achieve high result accuracy.
4.1 Triangles
First-cut solution. According to Section 3.2, to achieve (ϵ, δ)-DDP
in triangle counting, we need to design an (ϵ1, δ1)-DDP algorithm
that returns a noise scale λ which satisfies ϵ2 · λ ≥ LSG (Γ△) with at
least 1−δ2 probability. Equivalently, we can compute a differentially
private upper bound τ of LSG (Γ△), and then set λ = ϵ2 · τ . In the
case of triangle counting, our solution sets δ1 = 0 and δ2 = δ.
First of all, we introduce a method for computing a probabilistic
upper bound of any value α, when given a noisy version of α
injected with Laplace noise:
Lemma 4.1. Let x be any real value, and x
∗ = x +Lap(α) for some
α > 0. Then, with 1 − δ probability,
x
∗ + α · log 
1
2δ

≥ x.
By Lemma 4.1, if we are to derive τ , we may first inject Laplace
noise Lap(λc ) into LSG (Γ△), and then sets τ to the noisy value
plus λc · log 
1
2δ

. This approach, however, only works if (i)
LSG (Γ△) + Lap(λc ) can be computed in the decentralized setting,
and (ii) Lap(λc ) is sufficient to ensure (ϵ1, δ1)-DDP for LSG (Γ△). In
relation to this, we first note that LSG (Γ△) equals the maximum
number of common neighbors shared by two users in G, i.e.,
LSG (Γ△) = max
vi
,vj ∈G,i,j
3 · |N(vi) ∩ N(vj)|, (7)
where N(v) denotes the set of neighbors of user v. This is because
(i) adding or removing one edge ⟨vi
,vj⟩ only affects those triangles
that contain both vi and vj as vertices, (ii) the number of such
triangles equals |N(vi) ∩ N(vj)|, and (iii) each of these triangles is
reported by three users.
Based on Eq. (7), we may compute a probabilistic upper bound of
LSG (Γ△) in the decentralized setting as follows. First, for each user
vi
, we ask her to compute the maximum number c(vi) of common
neighbors that she shares with any other user in her local view, i.e.,
c(vi) = max
vj ∈Gi∧j,i
|N(vi) ∩ N(vj)|. (8)
Note that for any node vk < Gi
, we have |N(vi)∩N(vk
)| = 0. Then,
we ask vi to report a noisy version c
∗
(vi) of c(vi) injected with
Laplace noise Lap(λc ). After that, we take
c
⊤(vi) = c
∗
(vi) + λc · log 
1
2δ

as a probabilistic upper bound of c(vi), and we set
τ = max
vi ∈G
c
⊤(vi)
as a probabilistic upper bound of LSG (Γ△).
Unfortunately, the above approach requires λc = n/ϵ1 to ensure that τ satisfies ϵ1-DDP. To explain, observe that adding or
removing one edge in G could change each c(vi) by 1 in the worst
case. Therefore, the sensitivity of {c(v1), . . . ,c(vn)} equals n, due to
which we need λc ≥ n/ϵ1 to guarantee that {c
∗
(v1), . . . ,c
∗
(vn)} is
ϵ1-differentially private. As such, we have τ >
n
ϵ1
· log 
1
2δ

, which
leads to a prohibitive of noise in Phase 2 of our solution.
Optimized solution. To address the deficiency of the aforementioned method, we propose to avoid directly collecting
{c(v1), . . . ,c(vn)} (as it has a high sensitivity), but let each user
vi report a probabilistic upper bound d
⊤(vi) of her degree d(vi),
i.e., the number of 1-hop neighbors of vi
. The rationale is that
d(vi) ≥ c(vi) holds for any vi
, and hence, we can use a probabilistic
upper bound of d(vi) in place of c(vi).
In particular, for some λd
, δd
that we clarify shortly, we ask each
user vi to inject Laplace noise Lap(λd
) into her degree d(vi), and
then report the noisy degree d
∗
(vi); after that, we take
d
⊤(vi) = d
∗
(vi) + λd
· log 
1
2δd

(9)
as a probabilistic upper bound of d(vi). We can then set τ =
maxvi ∈G d
⊤(vi) as a probabilistic upper bound of LSG (Γ△).
The advantage of this approach is that only a small amount of
noise is needed in {d
∗
(v1), . . . ,d
∗
(vi)}. In particular, since adding
or removing an edge in G only changes the degrees of two nodes,
each by 1, the sensitivity of D = {d(v1), . . . ,d(vi)} equals 2. Hence,
injecting Laplace noise Lap(2/ϵ) into Dд achieves ϵ-DDP. The disadvantage, however, is that d(vi) could be a rather loose upper
bound of c(vi), due to which setting τ = maxvi ∈G d
⊤(vi) could
still lead to excessive noise in Phase 2. This motivates us to develop
a hybrid approach that combines both c
⊤(vi) and d
⊤(vi).
In the proposed hybrid approach, different nodes report different
information to the analyst, i.e., Mi varies depending onvi
. The main
idea is as follows. First, we obtain a probabilistic degree upper bound
d
⊤(vi) for every user vi
, and we identify the set S of nodes whose
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 709
Algorithm 1: Optimized Two-Phase Approach
Input :Privacy budget for phase 1 ϵ1, privacy budget for phase 2 ϵ2,
invalidation probability δ , a large number h
′
;
Output : Scale λ;
1 λd =
2
0.5ϵ1
; // Server
2 δ
′ =
δ
2h′+2
; // Server
3 for each vi do
4 d
⊤(vi ) = d(vi ) + Lap(λd ) + λd · log 
1
2δ
′

; // Client
5 Report d
⊤(vi ) to server; // Client
6 Sort {vi } into {v[1]
, v[2]
, . . . , v[n] } by d
⊤(vi ) in descending order;
// Server
7 for i = 1 to h
′ do // Server
8 if i
0.5ϵ1
· log 
1
2δ
′

≥ d
⊤(v[i+2]
) then // Server
9 break; // Server
10 h = ⌈i/2⌉; // Server
11 S = {v[i]
|2 ≤ i ≤ h + 1}; // Server
12 λc =
h
0.5ϵ1
; // Server
13 for each vi ∈ S do
14 c
⊤(vi ) = c(vi ) + Lap(λc ) + λc · log 
1
2δ
′

// Client
15 c
†
(vi ) = min{c
⊤(vi ), d
⊤(vi )} // Client
16 Report c
†
(vi ) to server; // Client
17 λ = 3 max{
1
ϵ2
d
⊤(v[h′+2]
),
1
ϵ2
maxvi ∈S c
†
(vi )}; // Server
18 return λ // Server
degree upper bounds are the largest. Intuitively, for any v ∈ S,
using d
⊤(v) as an upper bound of c(v) is likely to be ineffective,
since c(v) could be much smaller than d
⊤(v). Therefore, for each
v ∈ S, we derive c
⊤(v) as an alternative upper bound ofc(v), instead
of relying solely on d
⊤(v). Note that in this case, the amount of
Laplace noise injected into c
⊤(v) is O(|S |) instead of O(n), since
we do not only request c
⊤(v) for any v < S. Finally, we combine
d
⊤(v1), . . . ,d
⊤(vn) and c
⊤(v) (v ∈ S) to compute an improved
upper bound of LSG (Γ△). We will explain later how to select the
set of nodes S used in this step later
Algorithm 1 shows the pseudo-code of the proposed solution for
Phase 1 of the framework. The algorithm involves two rounds of
reporting; all nodes participate in the first round, and only a selected
few participate in the second round. Specifically, the algorithm
starts by splitting budget λd and δ
′
in Lines 1-2. This is done by
the server. Here we divide the budget ϵ1 into two halves for the
two-round reporting. We also divide the probability δ into 2h
′ + 2
parts, where h
′
is a user-specified number indicating the maximum
number of clients to do the second round of reporting. The specific
value of h
′
slightly affects the accuracy of the estimation result, but
not the correctness of the algorithm. In our experiments, we found
that h
′ = 100 usually leads to good results.
After that, the server sends these parameters to all the clients, i.e.,
nodes in the social network. Lines 4-5 are executed by each client,
which calculate the probabilistic upper bound of the actual degree
d(vi) and report it to the server, i.e., the data collector. Then, in
Lines 6-11, the server uses a heuristic to decide h ≤ h
′
, the number
of clients who do the second-round reporting, and obtains the set S
of h nodes. The intuition of the heuristic will be explained shortly.
In Line 12, the server spends another half of ϵ in the secondround reporting. After getting λc , as shown in Lines 14-16, all the
clients in S calculate c
⊤(vi) as their probabilistic upper bound of
common neighbor counts, then get their final upper bound c
†
(vi)
in Line 15 and report it to the server.
Finally, in Lines 17-18, the server computes the final upper bound
of each client, and selects the maximum one. However, it is possible that the client vi with maximum c(vi) is not in S, and hence,
maxvi ∈S c
†
(vi) is unable to cover the sensitivity. In such case, the
client is hiding in {v[h
′+2]
, . . . ,v[n]
}, and it has to be covered by
d
⊤(v[h
′+2]
). That is reason that we derive the final λ by getting the
maximum value in Line 17. Finally, since every addition/removal
of a triangle is always observed by 3 clients, we multiply the result
by 3.
Lemma 4.2. Algorithm 1 satisfies ϵ1-DDP and, with at least 1 − δ
probability, returns λ ≥
1
ϵ2
LSG (Γ△).
As mentioned above, Lines 6-10 in Algorithm 1 are a heuristic
to choose h, the size of the set of nodes S who report further their
c
⊤ to deduce a final upper bound λ. Clearly, if h is too small, the
final upper bound would be close to the second largest d
⊤, which
is likely to be much larger than the maximum c(v) among all nodes.
If h is too large, each node v in S would end up adding too much
noise to c(v), again resulting in a much larger final upper bound.
To find an appropriate h, we have the following intuition. Suppose
that h = i. Observe that for each node v in S, besides the Laplace
noise, it also needs to add an additional noise i
0.5ϵ1
· loд

1
2δ
′

to
c(v). If this noise is already bigger than d
⊤(v[h+2]
), then any bigger
i would not result in smaller final upper bounds. Meanwhile, since
c
⊤(v) also includesc(v), the i we have now is likely to be more than
enough to ensure c
⊤(v) > d
⊤. Therefore, we set h =
i
2
to derive
the final upper bound. In Section 5, we experimentally evaluate the
quality of this heuristic in choosing h.
4.2 Three-Hop Paths
Baseline: Pessimistic Laplace mechanism. A three-hop path
refers to a set of three edges that form a simple path. Suppose that
we let each user vi report the number γ⊔(vi) of three-hop paths
in which she is one of the two nodes in the middle (referred to
as the internal nodes). In that case, the Pessimistic Laplace mechanism (explained in Section 3.1) lets each vi
inject Laplace noise
Lap (6(n − 2)(n − 3)/ϵ) into γ⊔(vi) before reporting it. To explain,
observe that for any two nodes u and v, there can be at most
6(n − 2)(n − 3) three-hop paths in which ⟨u,v⟩ is one of the edges.
Accordingly, the sensitivity of Γ⊔ = {γ⊔(v1), . . . ,γ⊔(vn)} equals
6(n − 2)(n − 3), since (i) adding or removing an edge ⟨u,v⟩ in G affects at most 3(n −2)(n −3) three-hop paths, and (ii) each three-hop
path is reported by two users.
Two-phase solution. Next we apply the proposed two-phase
framework, for which the key is to develop an (ϵ1, δ)-differentially
private algorithm for computing a probabilistic upper bound of
LSG (Γ⊔). Observe that
LSG (Γ⊔) ≤ max
vi
,vj ∈G,i,j
2

d (vi) · d

vj

+
Õ
vℓ ∈N (vi )
(d (vℓ
) − 1)
+
Õ
vℓ ∈N (vj)
(d (vℓ
) − 1)

, (10)
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 71 



Phase 1: Derive d
⊤(vi) with Lap 
2
ϵ1a

and ψ
⊤(vi) with Lap 
8(n−2)
ϵ1b

Phase 2: Derive Γ⊔ based on d
⊤(vi) and ψ
⊤(vi)



Phase 1:



Sub-Phase 1: Derive d
⊤(vi) with Lap 
2
ϵ1a

Sub-Phase 2: Derive ψ
⊤(vi) based on Lap
4

d
⊤
(1)
+d
⊤
(2)

ϵ1b
!
Phase 2: Derive Γ⊔ based on d
⊤(vi) and ψ
⊤(vi)
(a) Two-phase solution. (b) Proposed three-phase solution.
Figure 3: Comparison of two-phase and three-phase solutions for counting three-hop paths under DDP.
where d(v) denotes the degree of v and N(v) denotes the set of
neighbors of v. This is because there can be (i) at most d(vi) · d(vj)
three-hop paths in which vi and vj are the two internal nodes, (ii)
at most Í
vℓ ∈N (vi )
(d (vℓ
) − 1) +
Í
vℓ ∈N (vj)
(d (vℓ
) − 1) three-hop
paths in which ⟨vi
,vj⟩ is an edge and either vi or vj
is an end point.
Let ψ(vi) =
Í
vℓ ∈N (vi ) 2 (d (vℓ
) − 1) and Ψ = {ψ(v1), . . . ,ψ(vn)}.
By Eq. (10), if we can derive probabilistic upper bounds d
⊤(vi)
and ψ
⊤(vi) for d(vi) and ψ(vi), respectively, then we can use
maxvi
,vj ∈G,i,j

2d
⊤(vi) · d
⊤(vj) +ψ
⊤(vi) +ψ
⊤(vj)

as an upper
bound of LSG (Γ⊔).
Note that d
⊤(vi) can be computed based on Eq. (9). To derive
ψ
⊤(vi), we may utilize Lemma 4.1 as follows. First, we let each user
vi
inject Laplace noise Lap 
λψ

into ψ(vi), to obtain a noisy value
ψ
∗
(vi), and then setting
ψ
⊤(vi) = ψ
∗
(vi) + λψ · log
1
2δψ
!
, (11)
for some δψ . This approach, however, offers inferior accuracy, as it
requires λψ ≥ 8(n − 2)/ϵ to achieve ϵ-DDP, because the sensitivity
of Ψ equals 8(n−2). To understand this, observe that when all nodes
in G are connected to each other, we have ψ(vi) = 2(n − 1)(n − 2)
for every user vi
. If we remove the edge ⟨v1,v2⟩, then we have
ψ(v1) = ψ(v2) = 2(n − 2)
2
, and ψ(vj) = 2(n − 1)(n − 2) − 4 for j ≥ 3.
This worst-case scenario leads to a total change of 8(n − 2) in Ψ,
which explains the sensitivity of Ψ.
Proposed three-phase solution. Next we present the proposed
solution, which recursively applies the two-phase framework to
the estimation of Ψ. Observe that although Ψ has a large sensitivity,
its local sensitivity LSG (Ψ) can be much smaller:
LSG (Ψ) ≤ max
vi
,vj ∈G∧i,j
4

d(vi) + d(vj)

. (12)
In particular, when one edge ⟨vi
,vj⟩ is added or removed in G,
(i) ψ(vi) changes by at most 2d(vj), (ii) ψ(vj) changes by at most
2d(vi), and (iii) {ψℓ
| ℓ , i, j} changes by at most 2d(vi) + 2d(vj).
The fact that LSG (Ψ) is relatively small motivates the recurisve
application of the two-phase framework on the estimation of Ψ, i.e.,
we first compute a probabilistic upper bound of LSG (Ψ), and then
inject noise into Ψ accordingly. After that, we derive a probabilistic
upper bound ψ
⊤(vi) for each user vi
, and ask them to report their
square counts injected with Laplace noise Lap 
maxvi ∈Gψ
⊤(vi )
ϵ2

.
Figure 3 illustrates the differences between the proposed threephase solution and the aforementioned two-phase solution, which
suffers from the large sensitivity of Ψ.
We now explain how we derive a probabilistic upper bound
ψ
⊤(vi) of eachψ(vi). First, we compute a probabilistic degree upper
bound d
⊤(vi) for each vi
, based on Eq. (9). Let d
⊤
(1)
and d
⊤
(2)
be
Algorithm 2: Optimized Three-Phase Approach
Input :Privacy budget for phase 1 ϵ1, privacy budget for phase 2 ϵ2,
invalidation probability δ , a large number h
′
1 λd =
2
0.5ϵ1
; // Server
2 δ1 = δ ; // Server
3 for each vi do
4 d
⊤(vi ) = d(vi ) + Lap(λd ) + λd · log 
1
2δ1

; // Client
5 Report d
⊤(vi ) to server; // Client
6 Sort {vi } into {v[1]
, v[2]
, . . . , v[n] } by d
⊤(vi ) in descending order;
// Server
7 λψ =
4

d
⊤(v[1]
)+d
⊤(v[2]
)

0.5ϵ1
; // Server
8 δ2 = δ ; // Server
9 for each vi do
10 ψ
⊤(vi ) = ψ (vi ) + Lap(λψ ) + λψ · log 
1
2δ2

; // Client
11 Report ψ
⊤(vi ) to server; // Client
12 λ =
1
ϵ2
maxvi ∈G ψ
⊤(vi ); // Server
13 return λ // Server
the largest two degree upper bounds. By Eq. (12), we can take
4

d
⊤
(1)
+ d
⊤
(2)

as a probabilistic upper bound of LSG (Ψ). After that,
we let each user vi
inject Lapalce noise Lap(λψ ) into ψ(vi), with
λψ = 4

d
⊤
(1)
+ d
⊤
(2)

/ϵ1, and then report the noisy value ψ
∗
(vi).
Then, we derive an upper bound ψ
⊤(vi) of each ψ(vi) based on
Eq. (11). Finally, we compute maxvi ∈G ψ
⊤(vi) as a probabilistic
upper bound of LSG (Γ⊔).
Algorithm 2 shows the pseudo-code of the above method for
computing λ. The following lemma establishes the privacy guarantee of the algorithm.
Lemma 4.3. Algorithm 2 satisfies (ϵ1, δ1)-DDP and, with 1 − δ2
probability, returns λ ≥
1
ϵ2
LSG (Γ⊔).
4.3 k-Cliques
Pessimistic Laplace mechanism. A k-clique refers to a set of
k nodes that are fully connected to each other. Let γkC(vi) be
the number of k-cliques that user vi appears in, and ΓkC =
{γkC(v1), . . . ,γkC(vn)}. To obtain ΓkC with ϵ-DDP, our based solution, namely Pessimistic Laplace mechanism, lets each uservi
inject
Laplace noise Lap 
k
n−2
k−2

/ϵ

into γkC(vi), since the sensitivity of
ΓkC equals k
n−2
k−2

. This is because (i) adding or removing one edge
e in G affects only those k-cliques where e is an edge, (ii) there are
at most n−2
k−2

such k-cliques, and (iii) each k-clique is reported by
k users.
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdo     
Dataset Num. of nodes Num. of edges Avg. deg. Num. of triangles Num. of three-hop paths Num. of 4-cliques
Facebook 4,039 88,234 43.69 1,612,010 1,055,326,189 30,004,668
HepPh 12,008 118,489 19.73 3,358,499 3,146,167,903 150,281,372
AstroPh 18,771 198,050 21.10 1,351,441 986,743,120 9,580,415
Table 1: Dataset Properties
Proposed solution. Next we apply the proposed two-phase framework to obtain a more accurate estimate of the k-clique count. For
this purpose, we present an ϵ1-differentially private algorithm for
computing a probabilistic upper bound of LSG (ΓkC). First, we have
LSG (ΓkC) = max
vi
,vj ∈G,i,j
k · C

Gi∩j
, k − 2

, (13)
where Gi∩j denotes the subgraph of G induced the common neighbors of vi and vj
, and C

Gi∩j
, k − 2

denotes the number of (k −2)-
cliques in Gi∩j
. To explain, observe that if an k-clique is affected
by the presence or absence of an edge ⟨vi
,vj⟩, then (i) the k-clique
must contain both vi and vj
, and (ii) apart from vi and vj
, the
remaining k − 2 nodes in the clique must form a (k − 2)-clique.
There exist only C

Gi∩j
, k − 2

such k-cliques, and each of them
is reported by k users. Therefore, Eq. (13) holds.
Let z(vi) = maxvj ∈G,i,j kC

Gi∩j
, k − 2

. By Eq. (13), if we can
derive a probabilistic upper bound z
⊤(vi) of each z(vi), then we may
use maxvi ∈G z
⊤(vi) as an upper bound of LSG (ΓkC). By Lemma 4.1,
we can compute z
⊤(vi) as
z
⊤(vi) = z
∗
(vi) + λz · log 
1
2δz

,
where λz and δz are constants and z
∗
(vi) is obtained by injecting
Laplace noise Lap(λz ) into z(vi). To ensure ϵ-DDP, however, we
need λz ≥ kn 
n−2
k−2

−
n−3
k−2


/ϵ, since adding or removing one
edge in G may change each z(vi) by up to k

n−2
k−2

−
n−3
k−2


. This
leads to an enormous amount of noise in z
⊤(vi).
To address the above issue, we recursively apply our two-phase
framework to derive an alternative upper bound of LSG (ΓkC), in
a manner similar to the method illustrated in Figure 3b. First, let
c(vi) be as defined in Eq. (8). Then, we have
LSG (ΓkC) = max
vi
,vj ∈G,i,j
k · C

Gi∩j
, k − 2

≤ max
vi ∈G
k

c(vi)
k − 2

.
Therefore, if we are able to derive an upper bound maxvi ∈G c
⊤(vi)
of maxvi ∈G c(vi), then we can use maxvi ∈G c
⊤(vi )
k−2

as an upper bound of LSG (ΓkC). We compute such an upper bound
maxvi ∈G c
⊤(vi) using the same method described in Section 4.1.
That is, we compute c
⊤(v) for a selected set S of users v, as well
as a probability degree upper bound d
⊤(vj) for each user vj
. After
that, we combine d
⊤(v1), . . . ,d
⊤(vn) and c
⊤(v) (v ∈ S) to derive
an upper bound of maxvi ∈G c(vi).
For brevity, we omit the pseudo-code as it can be easily constructed from the λ△ returned by Algorithm 1. That is, after getting
λ△ from Algorithm 1, let
λkC = k
 ϵ2
3
λ△
k − 2

/ϵ2. (14)
Since we have
ϵ2
3
λ△ = max{d
⊤(v[h
′+2]
), max
vi ∈S
c
†
(vi) ≥ max
vi ∈G
c(vi),
with probability 1 − δ, and λ△ satisfies ϵ1-DDP. So λkC satisfies
ϵ1-DDP and we have LSG (ΓkC) ≤ k

ϵ2
3
λ△
k−2

with probability 1 − δ.
5 EXPERIMENTS
Datasets. We conduct experiments on three real world datasets
from Stanford Large Network Dataset Collection [26]. The Facebook
dataset contains “friends list” from Facebook, a large social network.
It was collected from surveying participants using the Facebook
app. The HepPh dataset and AstroPh dataset are the co-authorship
networks from arXiv, which contains the collaborations between
authors who submit their papers to High Energy Physics and Astro
Physics, respectively. Table 1 shows the properties of the datasets
and their true subgraph pattern counts.
Parameter selection. Since our solutions follow the proposed
multi-phase framework, we need to split (ϵ, δ) budget among different phases. Recall from Section 3 that in the two-phase framework,
Phase 1 estimates an upper bound of the required noise scale, and
Phase 2 reports noisy counts. In order to get more accurate counting
results, we assign more privacy budget to Phase 2. Specifically, we
set ϵ1 = 0.1ϵ and ϵ2 = 0.9ϵ for Phase 1 and Phase 2, respectively.
Regarding the other privacy parameter δ, following the popular
guideline in [12], we set δ to 1
n
, where n is the number of nodes
in the social network. Inside the proposed solutions described in
Section 3, δ is sub-divided, e.g., by the number of entities to be
protected for triangle counting.
Baselines. We compare the fully optimized versions of proposed
solutions for private subgraph counting, denoted by Mo in the
following, against the following baselines: (i) the (ϵ, δ)-DDP version of the baseline method, i.e., Pessimistic Laplace mechanism,
described in Section 3, (ii) first-cut versions of the proposed solutions, denoted as Mc in the following, and (ii) LDPGen [32], which
generates synthetic graphs under LDP. The counts of differential
private subgraph patterns are computed directly from the synthetic
graph. Note that in LDPGen, the data collector only gathers information from the nodes on their direct connections; that is, no
ELV is involved in this method, in which case DDP (Definition
2.6) reduces to LDP (Definition 2.4). Besides, we have also run experiments using the Pessimistic Gaussian mechanism, described
towards the end of Section 3.1, which injects Gaussian noise into
the true counts [1] instead of Laplace noise. From our experiments,
we found that Pessimistic Gaussian consistently outputs much noisier results compared to the Pessimistic Laplace mechanism under
(ϵ, δ)-DDP. We thus omit the results for Pessimistic Gaussian for
brevity. Similarly, we omit Pessimistic Laplace under the stricter
ϵ-DDP requirement, which is always worse than the more relaxed
(ϵ, δ)-DDP version.
Noise scale selection. Before presenting our main evaluation results, we first demonstrate the effectiveness of the heuristic in
Section 4.1 for determining the value of h in Phase 1, which is the
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United            
ϵ1 = 0.1 ϵ1 = 0.3 ϵ1 = 0.5
0 5 10 15 20 25 30
1,000
2,000
3,000
4,000
h
Upper bound of LSG(Γ△)
0 5 10 15 20 25 30 1,000
1,500
2,000
2,500
3,000
h
Upper bound of LSG(Γ△)
0 5 10 15 20 25 30 1,000
1,500
2,000
2,500
3,000
h
Upper bound of LSG(Γ△)
(a) Facebook dataset (b) HepPh dataset (c) AstroPh dataset
Figure 4: Selection of h for triangle counting
First-cut two-phase Optimized two-phase Pessimistic Laplace LDPGen
1 2 3 4 5 6 7 8 9 10
10−2
10−1
Privacy budget ϵ
MRE
1 2 3 4 5 6 7 8 9 10
10−2
10−1
Privacy budget ϵ
MRE
1 2 3 4 5 6 7 8 9 10
10−2
10−1
100
Privacy budget ϵ
MRE
(a) Facebook dataset (b) HepPh dataset (c) AstroPh dataset
Figure 5: Triangle Counting
number of nodes participating in the second data collection step in
the proposed improved solution. Figure 4 depicts the upper bound
of LSG (Γ△), i.e., ϵ1λ from Phase 1 as a function of h. For each of
the datasets, for better presentation, the figure only shows three
curves for three values of ϵ1 = {0.1, 0.3, 0.5}, corresponding to the
total budget ϵ = {1, 3, 5}. The valleys represent the optimal value
of h, i.e., with the lowest ϵ1λ, while the vertical lines represent
the heuristic value of h as computed in Lines 7-10 in Algorithm 1.
The figure confirms that the heuristic values of h are close to the
optimal ones. For example, on the Facebook dataset, the optimal
and heuristic values are exactly the same for ϵ1 = 0.1 and ϵ1 = 0.3,
while in the case of ϵ1 = 0.5, the heuristic deviates by 1 from the
optimal value, which results in only 6% increase of the upper bound
compared to its optimal value. The figure also shows that the noise
scale varies across the datasets, with Facebook being the lowest
(e.g., ϵ1λ = 1443 for ϵ1 = 0.3) and HepPh being the highest (e.g.,
ϵ1λ = 1749 for ϵ1 = 0.3). This is simply because the local sensitivity depends on the dataset properties, i.e., number of nodes, node
degrees, node degree distribution.
Evaluation metric. We evaluate the accuracy of our approach
in counting subgraph patterns (triangle, 3-hop path, and k-clique)
on all the aforementioned datasets and compare it with that of
the baselines. The accuracy of each method (M) on graph (G) is
measured by the mean relative error (MRE), that is, MRE(M,G) =
|M(G) − f (G)|/f (G), where M(G) is the differential private subgraph pattern count in input graphG, and f (G) is the true subgraph
count in G. Each result reported is averaged over 300 repeated runs.
Triangle counts. The MRE of triangle counts of all the methods
on all the datasets are depicted on Figure 5 while the privacy budget (ϵ) varies from 1 to 10. The results show that our optimized
approach achieves good accuracy over all datasets. The proposed solution Mo (△) clearly outperforms all the other differential private
methods in terms of result accuracy. Note that the difference is significant since MRE is plotted in log-scale. In the Facebook dataset,
for example, when privacy budget is relatively large, e.g., ϵ = 5, its
MRE always stays below or close to 0.49%. When ϵ decreases, the
accuracy drops but it is still smaller than 3.8% even when ϵ = 1.
The result of the first-cut solution Mc (△) is close to Mo (△) in the
case of HepPh and AstroPh datasets, with Mo (△) strictly better.
However, Mo (△) significantly enhances the accuracy compared to
Mc (△) for the Facebook dataset.
3-hop counts. Figure 6 shows the results for the 3-hop counts.
Again, the figure shows that our improved approach achieves good
accuracy over all datasets. Mo (⊔) clearly outperforms all the other
differential private methods including Mc (⊔), simply because it
injects less noise into the true results. The general trend in the
results of 3-hop counts is the same as that of triangle counts across
datasets and differential private approaches. However, we first note
that, even though the number of 3-hop counts is larger than that
of triangles, triangle counts are more accurate than those of 3-hop
counts. This is because the local sensitivity of triangle counts is
much smaller than that of 3-hop counts. Second, we note that the
difference between Mo (⊔) and Mc (⊔) is bigger than the difference
between Mo (△) and Mc (△). This is because Mo (⊔) uses a much
tighter bound for the noise scale compared to Mc (⊔), while the
noise scale in Mo (△) is not as much tight compared to Mc (△).
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 713
First cut two-Phase Optimized three-phase Pessimistic Laplace LDPGen
1 2 3 4 5 6 7 8 9 10
10−3
10−2
10−1
100
Privacy budget ϵ
MRE
1 2 3 4 5 6 7 8 9 10
10−3
10−2
10−1
100
101
Privacy budget ϵ
MRE
1 2 3 4 5 6 7 8 9 10
10−2
10−1
100
101
102
Privacy budget ϵ
MRE
(a) Facebook dataset (b) HepPh dataset (c) AstroPh dataset
Figure 6: 3-hop-path Counting
First cut two-Phase Optimized two-phase Pessimistic Laplace LDPGen
1 2 3 4 5 6 7 8 9 10
10−1
100
101
Privacy budget ϵ
MRE
1 2 3 4 5 6 7 8 9 10
10−2
10−1
100
101
102
Privacy budget ϵ
MRE
1 2 3 4 5 6 7 8 9 10
10−1
100
101
102
103
Privacy budget ϵ
MRE
(a) Facebook dataset (b) HepPh dataset (c) AstroPh dataset
Figure 7: 4-Clique Counting
Finally, we note that the drop in MRE as ϵ increases is faster in
the case of 3-hop counts compared to triangle counts for both Mo
and Mc . For example, in the Facebook dataset, the MRE of Mo (⊔)
drops from 14.7% when ϵ = 1 to 0.44% when ϵ = 5.
4-clique counts. Figure 7 shows the results for the 4-clique counts.
k-clique counting for a larger k > 4 would be expensive to evaluate due to the high time complexity of counting such cliques. Our
proposed approach Mo (4C) once again achieves good accuracy
over all datasets, and consistently outperforms its competitors. The
general trend in the results of 4-clique counts is the same as that of
triangle counts across datasets and differential private approaches.
However, triangle counts are much more accurate than 4-clique
counts due to the larger scale of 4-cliques in Eq. (14) compared to triangles. We also note that LDPGen is strictly better than Pessimistic
Laplace for all privacy budgets on all the datasets.
6 RELATED WORK
Differential privacy [11] has attracted widespread attention from
both academia and industry in the last decade. There are two existing models of differential privacy: centralized differential privacy
(CDP) and local differential privacy (LDP). In CDP, data from individuals are collected and maintained by a trusted centralized data
curator. The trusted curator executes a DP mechanism on the sensitive data and releases outputs, e.g., to untrusted data analysts.
In LDP, there is no trusted centralized data curator. Rather, each
individual perturbs its own data using a (local) differentially private
algorithm. The data analyst collects these perturbed data, and uses
it to infer aggregate statistics of the datasets. In a broader sense,
this work falls into the category of differential privacy in the local setting [10], and our privacy definition (i.e., DDP) generalizes
existing LDP definitions by considering extended local views.
Graph analysis with CDP. Graph analysis under the CDP setting
has been studied intensively in the literature. Two different CDP
models were defined for graph analysis: edge differential privacy
and node differential privacy. Edge differential privacy considers
two graphs as neighbors if they differ in one edge, while node
differential privacy considers two graphs as neighbors if one can be
obtained from the other by deleting a node and its adjacent edges.
Edge differentially private algorithms have focused on releasing
various types of graph statistics, including degree distributions
[19, 22, 28], cuts [3, 17, 18], degree sequences [19, 22], k-stars and ktriangles [29], and subgraph counts [4, 21, 34, 42]. Triangle counting
queries can be answered with edge differential privacy by efficiently
computing the smooth sensitivity [30], empirical sensitivity [6],
and ladder functions [42].
Earlier works on graph analysis under node differential privacy
include [4, 6, 24]. Gehrke et al. [16] defined a generalization of
differential privacy, called zero-knowledge privacy, that enforces
node differentially privacy for bounded-degree graphs. [5, 33] focus on high-dimension graph data release with node differential
privacy. Day et al. [8] investigated graph data publishing under
node-differential privacy. Continuous release of graph statistics
(e.g., degree distributions and subgraph counts) with node differential privacy has been initiated in [36]. All these CDP solution
(for both edge and node differential privacy) require that the data
Session 3E: Privacy II CCS ’19, November 11–15, 2019, London, United Kingdom 714
publisher has the full knowledge of the whole input graph. Therefore, they are not applicable to our setting, where the social graph
is decentralized and no party knows the full graph.
Graph analysis with LDP. The LDP notion [23] assumes there is
no trusted centralized data curator. Randomized response [41] is
one of the simplest LDP techniques. However, directly applying
the randomized response method on the local graph information
(e.g., neighbor lists) collected from individual users may ruin the
property (e.g., sparsity) of the original graph [32]. Gao et al. [15]
transform the local graphs into neighbor lists and apply the hierarchical random graph (HRG) approach to add noise on the neighbor
lists. Qin et al. [32] design LDPGen, a multi-phase technique that
generates representative synthetic decentralized social graphs with
local differential privacy. The synthetic graphs can be used for various graph analysis, such as graph modularity, clustering coefficient
and assortativity coefficient. To our best knowledge, ours is the
first work that considers subgraph counts in decentralized social
networks with differential privacy guarantees, and the first to consider the case where each node possesses an extended local view
with information beyond direct connections.
LDP for other types of data analysis. Finally, beyond social
graph analysis, LDP algorithms for a variety of tasks have been
widely investigated recently. Examples include frequency estimation [13, 39], heavy hitters [2, 14, 31], frequent itemsets [40], and
marginal tables [7, 43]. The LDP model has been applied to the collection of various data types, including location [9] and positioning
data [25], responses from crowdsourcing workers [27, 35, 37], and
user data on mobile devices [38].
7 CONCLUSION
Given that more and more data are generated in the context of social networks and the well-spread concern of privacy, the problem
of decentralized social network analysis would become increasingly
important and relevant in practice. Our work is the one of first efforts toward develop privacy-preserving techniques to address the
problem. With the proposed concept of decentralized differential
privacy, our framework could be extended in multiple directions.
For one, diverse local view models could be further considered. For
example, in some social networks, though one cannot see all his two
hop neighbors, the connections between her one-hop neighbors
would be visible. How to accurately estimate relevant graph properties with such local views under DDP would be interesting future
work. Another important direction is to integrate our framework
with specific social network applications and carry out more sophisticated graph analysis tasks (e.g., community discovery, social
graph recommendation).