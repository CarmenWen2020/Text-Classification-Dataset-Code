A threshold signature scheme enables distributed signing among n
players such that any subgroup of size t + 1 can sign, whereas any
group with t or fewer players cannot. While there exist previous
threshold schemes for the ECDSA signature scheme, we are the
first protocol that supports multiparty signatures for any t ≤ n with
an efficient dealerless key generation. Our protocol is faster than
previous solutions and significantly reduces the communication
complexity as well. We prove our scheme secure against malicious
adversaries with a dishonest majority. We implemented our protocol, demonstrating its efficiency and suitability to be deployed in
practice.
1 INTRODUCTION
A threshold signature scheme enables n parties to share the power
to issue digital signatures under a single public key. A threshold t
is specified such that any subset of t + 1 players can jointly sign,
but any smaller subset cannot. Generally, the goal is to produce
signatures that are compatible with an existing centralized. In a
threshold scheme the key generation and signature algorithm are
replaced by a communication protocol between the parties, but the
signatures produces are compatible with the centralized scheme
and the verification algorithm is therefore unchanged.
In recent years there has been renewed attention to this topic, in
particular to the threshold generation of ECDSA signatures, mostly
due to the use of ECDSA in Bitcoin and other digital currencies.
Cryptocurrency transactions are authorized by digital signatures,
and thus proper key storage is critical for security. With a (t,n)
threshold signature scheme, control of a cryptocurrency wallet can
be distributed among n servers (or players) such that t + 1 of them
are required to produce a signature. Crucially, the funds will remain
secure even if up to t of these servers are compromised.
The study of DSA/ECDSA threshold signature schemes predates
Bitcoin. Gennaro et al. [18, 19] present a threshold scheme for DSA,
but their scheme assumes an honest majority and thus requires
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5693-0/18/10. . . $15.00
https://doi.org/10.1145/3243734.3243859
that t < n/2. Moreover, their scheme requires 2t + 1 players to
participate to generate a signature. This is not ideal for several
reasons. Firstly, it rules out the possibility of an n-of-n threshold
signing scheme. Secondly, it provides an attacker with additional
targets: while an attacker only needs to compromise t + 1 servers,
the scheme requires 2t + 1 servers to generate a signature.
As Gennaro et al.’s scheme did not suport then-of-n case, Mackenzie and Reiter built a scheme specifically for the 2-of-2 case (i.e.
t = 1 and n = 2) [27]. Recently much improved 2-out-of-2 schemes
have been presented [12, 26]. However 2-out-of-2 sharing is very
limited and can’t express more flexible sharing policies that might
be required in certain applications.
Gennaro and others in [17] (improved in [4]) address the more
general (t,n) case in the threshold optimal case, meaning n ≥ t + 1
and that only t+1 players are needed to sign. However, their scheme
too has a setback in that the distributed key generation protocol is
very costly and impractical.
Our Result: We present a new threshold-optimal protocol for
ECDSA that improves in many significant ways over [4, 17]. Our
protocol supports a highly efficient distributed key generation; it
also supports faster signing than [4, 17], and requires far less data
to be transmitted between the parties (details of the comparison
appear below).
1.1 Overview of our solution
Consider a "generic" DSA signature algorithm that works over any
cyclic group G of prime order q generated by an element д. It uses a
hash function H defined from arbitrary strings into Zq, and another
hash function H
′ defined from G to Zq. The secret key is x chosen
uniformly at random in Zq, with a matching public key y = д
x
. To
sign a message M, the signer computes m = H(M) ∈ Zq, chooses
k uniformly at random in Zq and computes R = д
k
−1
in G and
r = H
′
(R) ∈ Zq. Then she computes s = k(m + xr) mod q. The
signature on M is the pair (r,s) which is verified by computing
R
′ = д
ms−1 mod q
y
r s−1 mod q
in G
and accepting if H
′
(R
′
) = r.
The technical complication with sharing DSA signatures comes
from having to jointly compute R (which requires raising д to
the inverse of a secret value k) and to compute s which requires
multiplying two secret values k, x. As shown in [18] it is sufficient
to show how to compute two multiplication over secret values that
are shared among the players. In [18] the values are shared via
Shamir’s secret sharing, i.e. as points on a polynomial of degree t
with free term the secret. The effect of multiplication is that the
degree of the polynomial is doubled, which explains why the [18]
solution requires at least 2t + 1 players to participate. To address
this problem [27] use a multiplicative sharing of the secret key x as
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1179
x = x1 · x2 (an approach taken also in [12, 26]) which is however
hard to generalize to t > 2.
A different approach was taken in [17]: the secret key x is encrypted under a public key encryption scheme E, and it is the secret
key of E that is shared among the players, effectively providing a
secret sharing of x. If E is an additively homomorphic encryption
scheme (e.g. Paillier’s [29]) they show that it is possible to construct
a reasonably efficient protocol, with a few troubling bottlenecks.
The major one is that the protocol requires a joint generation of
the public key/secret key pair for the additively homomorphic encryption E by the parties. When E is instantiated using Paillier, this
requires the distributed generation of an RSA modulus. Although
solutions are known for this problem (e.g. [22]), they are far from
scalable and efficient. To our knowledge the protocol from [22] has
never been implemented for the malicious multiparty case. The
only benchmark we are aware of for this protocol is that for the
two-party semi-honest case it takes 15 minutes [26], and we can
extrapolate that it would take significantly longer in the multiparty
malicious setting. Moreover the signature generation protocols in
[4, 17] require long messages and complicated ZK proofs.
In this paper we take a different path inspired by the SPDZ
approach to multiparty computation [9]. Given two secrets a,b
shared additively among the players, i.e. a = a1 + . . . + an and b =
b1 + . . . +bn where Pi holds ai
,bi
, we want to generate an additive
sharing of c = ab. We note that ab =
Í
i,j aibj and therefore to
get an additive sharing of ab, it is sufficient to obtain an additive
sharing of each individual term aibj
. To that extent we use a 2-party
protocol that allows two parties to transform multiplicative shares
of a secret to additive shares of the same secret. The players engage
in this protocol in a pairwise fashion to obtain an additive sharing
of the product ab.
Using this approach, we build a simple and elegant threshold
ECDSA protocol for the general multiparty setting. The players
start with a (t,n) Shamir sharing of the secret key x. When t + 1
players want to sign, they generate an additive sharing of two
random values k =
Í
i ki and γ =
Í
i γi and they use the above
idea to compute additive sharings of the products δ = kγ (which
is reconstructed in the clear) and σ = kx =
Í
i wi
(which is kept
shared). By multiplying the local shares of γ by the public value δ
−1
the players end up with an additive sharing1 of k
−1
. The value R
is then easily computed in the exponent R =
Î
i д
γi δ
−1
. The value
s is shared additively among the players since each player holds
si = kim + wir and s =
Í
i
si
.
1.2 Avoid expensive ZK Proofs in case of a
Malicious Adversary
Following [26] we make minimal use of ZK proofs to detect malicious behavior by the players.
Instead we take an "optimistic" approach and run the protocol
assuming everybody is honest. We then check the validity of the
resulting signature to detect if there were players who deviated
from the protocol (if the signature does not verify then obviously
at least one player did not follow the instructions).
At that point, because we possibly have a dishonest majority
among the players, there is no guarantee that we can generate a
1 This is the famous Bar-Ilan and Beaver inversion trick [1].
correct signature so the protocol stops and aborts. This creates a
technical complication in the proof as we have to make sure that
the values revealed by the good players do not leak any valuable
information, not only in the case of good executions, but also in
the case of aborting executions. As we will see, this will require
us to "distributively" check that the shares si reconstruct a valid
signature before revealing them. This check is somewhat reminiscent of the way Canetti and Goldwasser solve a similar problem
in [7] to construct threshold CCA secure encryption based on the
Cramer-Shoup scheme.
Range Proofs. Even when using the signature verification step to
detect cheating, we have to run two relatively expensive ZK proofs
during the share conversion protocol:
• a "range proof" that a value a encrypted under Paillier’s
encryption scheme is "small";
• a proof that a party knows x such that c = E(x) and y = д
x
where E is Paillier’s encryption scheme.
As we discuss later, removing these ZK proofs creates an attack
that leaks some information about the DSA secret key (and the
randomizer k used in each signature) shared among the servers.
We conjecture that this information is so limited that the protocol
remains secure even without them (see Section 6 for details).
1.3 Experimental Results
We implemented our scheme and found both the key generation
and signing protocols to be very efficient.
The key generation protocol is easy to implement and is quite
fast (under a second for any reasonable choice of parameters). This
is in stark contrast to [4, 17] for which the key generation protocol
has never been implemented, and it is hard to estimate what the
actual running time would be.
Our signing protocol is also extremely efficient, and is a significant improvement over previous works both in terms of data
transferred and running time.
With the combination of an efficient key generation and signing
protocol, our scheme is suitable to be deployed in practice. We
present full benchmarks and evaluations in Section 7.
2 PRELIMINARIES
Communication Model. We assume the existence of a broadcast
channel as well as point-to-point channels connecting every pair
of players.
The Adversary. We assume a probabilistic polynomial time malicious adversary, who may deviate from the protocol description
arbitrarily. The adversary can corrupt up to t players, and it learns
the private state of all corrupted players. As in previous threshold
ECDSA schemes [4, 17, 18, 26], we limit ourselves to static corruptions, meaning the adversary must choose which players to corrupt
at the beginning of the protocol. There are standard techniques
for converting a protocol secure against static corruptions to secure against adaptive corruptions [6, 23], but these will incur an
overhead.
We assume a rushing adversary, meaning that the adversary gets
to speak last in a given round and, in particular, can choose his
message after seeing the honest parties’ messages.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1180
Following [4, 17] (but unlike [18]), we assume a dishonest majority, meaning t, the number of players the adversary corrupts,
can be up to n−1. In this case, there is no guarantee that the protocol
will complete, and we therefore do not attempt to achieve robustness, or the ability to complete the protocol even in the presence of
some misbehaving participants.
2.1 Signature Schemes
A digital signature scheme S consists of three efficient algorithms:
• (sk, pk)←Key-Gen(1
λ
), the randomized key generation algorithm which takes as input the security parameter and
returns the private signing key sk and public verification
key pk.
• σ←Sig(sk,m), the possibly randomized signing algorithm
which takes as input the private key sk and the message to
be signedm and outputs a signature, σ. As the signature may
be randomized, there may be multiple valid signatures. We
denote the set of valid signatures as {Sig(sk,m)} and require
that σ ∈ {Sig(sk,m)}.
• b ←Ver (pk,m, σ), the deterministic verification algorithm,
which takes as input a public key pk, a message m and a
signature σ and outputs a bit b which equals 1 if and only if
σ is a valid signature on m under pk.
To prove a signature scheme secure, we recall the standard notion
of existential unforgeability against chosen message attacks (EUCMA) as introduced in [21].
Definition 2.1 (Existential unforgeability). Consider a PPT adversary A who is given public key pk output by Key-Gen and oracle
access to the signing algorithm Sig(sk, ·) with which it can receive
signatures on adaptively chosen messages of its choosing. Let M
be the set of messages queried by A. A digital signature scheme
S =(Key-Gen,Sig,Ver) is said to be existentially unforgeable if there is
no such PPT adversary A that can produce a signature on a message
m < M, except with negligible probability in λ.
2.2 Threshold Signatures
Threshold secret sharing. A (t,n)−threshold secret sharing of
a secret x consists of n shares x1, . . . , xn such that an efficient
algorithm exists that takes as input t +1 of these shares and outputs
the secret, but t or fewer shares do not reveal any information about
the secret.
Threshold signature schemes. Consider a signature scheme, S=(KeyGen, Sig, Ver). A (t,n)-threshold signature scheme TS for S enables
distributing the signing among a group of n players, P1, . . . , Pn
such that any group of at least t + 1 of these players can jointly
generate a signature, whereas groups of size t or fewer cannot.
More formally, TS consists of two protocols:
• Thresh-Key-Gen, the distributed key generation protocol,
which takes as input the security parameter 1
λ
. Each player
Pi receives as output the public key pk as well as a private
output ski
, which is Pi
’s share of the private key. The values
sk1, . . . ,skn constitute a (t,n) threshold secret sharing of the
private key sk.
• Thresh-Sig, the distributed signing protocol which takes
as public input a message m to be signed as well as a private input ski from each player. It outputs a signature σ ∈
{Sig(sk,m)}.
Notice that the signature output by Thresh-Sig is a valid signature
under Sig, the centralized signing protocol. Thus we do not specify
a threshold variant of the verification algorithm as we will use the
centralized verification algorithm, Ver.
In some applications, it may be acceptable to have a trusted
dealer generate the private key shares for each party. In this case,
Thresh-Key-Gen would not be run.
Following [18, 19], we present a game-based definition of security
analogous to EU-CMA.
Definition 2.2 (Unforgeable threshold signature scheme [18]). We
say that a (t,n)-threshold signature scheme TS =(Thresh-KeyGen,Thresh-Sig) is unforgeable, if no malicious adversary who corrupts at most t players can produce, with non-negligible (in λ)
probability, the signature on any new (i.e., previously unsigned)
message m, given the view of the protocol Thresh-Key-Gen and of
the protocol Thresh-Sig on input messages m1, . . . ,mk which the
adversary adaptively chose as well as signatures on those messages.
This is a game-based definition of security which is analogous
to the notion of existential unforgeability under chosen message
attack as defined by Goldwasser, Micali, and Rivest [21]. Unlike in
the centralized EU-CMA definition, the adversary is additionally
given the corrupted players’ views of the key generation protocol
as well as their views in the signing protocol for the messages it
chooses. A stronger simulation-based definition is also possible (see
e.g. [17, 18, 26]).
2.3 Additively Homomorphic Encryption
Our protocol relies on an encryption scheme E that is additively
homomorphic modulo a large integer N. Let Epk (·) denote the
encryption algorithm for E using public key pk. Given ciphertexts
c1 = Epk (a) and c2 = Epk (b), there is an efficiently computable
function +E such that
c1 +E c2 = Epk (a + b mod N)
The existence of a ciphertext addition operation also implies a
scalar multiplication operation, which we denote by ×E . Given an
integer s ∈ N and a ciphertext c = Epk (a), then we have
c ×E s − Epk (as mod N)
Informally, we say that E is semantically secure if for the probability distributions of the encryptions of any two messages are
computationally indistinguishable.
We instantiate our protocol using the additively homomorphic
encryption scheme of Paillier [29], and we recall the details here:
• Key-Gen: generate two large primes P,Q of equal length, and
set N = PQ. Let λ(N) = lcm(P − 1,Q − 1) be the Carmichael
function of N. Finally choose Γ ∈ Z
∗
N 2
such that its order is
a multiple of N. The public key is (N, Γ) and the secret key
is λ(N).
• Encryption: to encrypt a message m ∈ ZN , select x ∈R Z
∗
N
and return c = Γ
mx
N mod N
2
.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1181
• Decryption: to decrypt a ciphertext c ∈ ZN 2 , let L be a
function defined over the set {u ∈ ZN 2 : u = 1 mod N}
computed as L(u) = (u − 1)/N. Then the decryption of c is
computed as L(c
λ(N )
)/L(Γ
λ(N )
) mod N.
• Homomorphic Properties: Given two ciphertexts c1,c2 ∈
ZN 2 define c1 +E c2 = c1c2 mod N
2
. If ci = E(mi) then
c1 +E c2 = E(m1 + m2 mod N). Similarly, given a ciphertext
c = E(m) ∈ ZN 2 and a number a ∈ Zn we have that a ×E c =
c
a mod N
2 = E(am mod N).
The security of Paillier’s cryptosystem relies on the N-residuosity
decisional assumption [29], which informally says that it is infeasible to distinguish random N-residues from random group elements
in Z
∗
N 2
.
2.4 Non-Malleable Equivocable Commitments
A trapdoor commitment scheme allows a sender to commit to a
message with information-theoretic privacy. i.e., given the transcript of the commitment phase the receiver, even with infinite
computing power, cannot guess the committed message better than
at random. On the other hand when it comes to opening the message, the sender is only computationally bound to the committed
message. Indeed the scheme admits a trapdoor whose knowledge
allows to open a commitment in any possible way (we will refer to
this also as equivocate the commitment). This trapdoor should be
hard to compute efficiently.
Formally a (non-interactive) trapdoor commitment scheme consists of four algorithms KG, Com, Ver, Equiv with the following
properties:
• KG is the key generation algorithm, on input the security
parameter it outputs a pair pk, tk where pk is the public key
associated with the commitment scheme, and tk is called the
trapdoor.
• Com is the commitment algorithm. On input pk and a message M it outputs [C(M),D(M)] = Com(pk, M, R) where r
are the coin tosses. C(M) is the commitment string, while
D(M) is the decommitment string which is kept secret until
opening time.
• Ver is the verification algorithm. On input C,D and pk it
either outputs a message M or ⊥.
• Equiv is the algorithm that opens a commitment in any possible way given the trapdoor information. It takes as input pk,
strings M, R with [C(M),D(M)] = Com(pk, M, R), a message
M′ , M and a string T . If T = tk then Equiv outputs D
′
such
that Ver(pk,C(M),D
′
) = M′
.
We note that if the sender refuses to open a commitment we can set
D = ⊥ and Ver(pk,C, ⊥) = ⊥. Trapdoor commitments must satisfy
the following properties
Correctness If [C(M),D(M)] = Com(pk, M, R) then
Ver(pk,C(M),D(M)) = M.
Information Theoretic Security For every message pair M, M′
the distributions C(M) and C(M′
) are statistically close.
Secure Binding We say that an adversary A wins if it outputs
C,D,D
′
such that Ver(pk,C,D) = M, Ver(pk,C,D
′
) = M′
and M , M′
. We require that for all efficient algorithms
A, the probability that A wins is negligible in the security
parameter.
Such a commitment is non-malleable [13] if no adversary A,
given a commitment C to a messages m, is able to produce another
commitment C
′
such that after seeing the opening of C to m, A can
successfully decommit to a related message m′
(this is actually the
notion of non-malleability with respect to opening introduced in
[10]).
The non-malleable commitment schemes in [10, 11] are not suitable for our purpose because they are not “concurrently" secure, in
the sense that the security definition holds only for t = 1 (i.e. the
adversary sees only 1 commitment).
The stronger concurrent security notion of non-malleability for
t > 1 is achieved by the schemes presented in [8, 16, 28]), and any
of them can be used in our threshold DSA scheme.
However in practice one can use any secure hash function H and
define the commitment to x as h = H(x,r), for a uniformly chosen
r of length λ and assume that H behaves as a random oracle. We
use this efficient random oracle version in our implementation.
2.5 The Digital Signature Standard
The Digital Signature Algorithm (DSA) was proposed by Karivtz in
1991, and adopted by NIST in 1994 as the Digital Signature Standard
(DSS)[3, 25] . ECDSA, the elliptic curve variant of DSA, has become
quite popular in recent years, especially in cryptocurruencies.
All of our results in this paper apply to both the traditional
DSA and ECDSA. We present our results using the generic G-DSA
notaiion from [17], which we recall here.
The Public Parameters consist of a cyclic group G of prime order
q, a generator д for G, a hash function H : {0, 1}
∗ → Zq, and
another hash function H
′
: G → Zq.
.
Key-Gen On input the security parameter, outputs a private key x
chosen uniformly at random in Zq, and a public key y = д
x
computed in G.
Sig On input an arbitrary message M,
– compute m = H(M) ∈ Zq
– choose k ∈R Zq
– compute R = д
k
−1
in G and r = H
′
(R) ∈ Zq
– compute s = k(m + xr) mod q
– output σ = (r,s)
Ver On input M, σ and y,
– check that r,s ∈ Zq
– compute R
′ = д
ms−1 mod qy
r s−1 mod q
in G
– Accept (output 1) iff H
′
(R
′
) = r.
The traditional DSA algorithm is obtained by choosing large
primes p,q such that q|(p − 1) and setting G to be the order q
subgroup of Z
∗
p
. In this case the multiplication operation in G is
multiplication modulo p. The function H
′
is defined as H
′
(R) =
R mod q.
The ECDSA scheme is obtained by choosing G as a group of
points on an elliptic curve of cardinality q. In this case the multiplication operation in G is the group operation over the curve.
The function H
′
is defined as H
′
(R) = Rx mod q where Rx is the
x-coordinate of the point R.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1182
2.6 Feldman’s VSS Protocol
Recall that in Shamir’s scheme [33], the secret shares are evaluations
of a polynomial
p(x) = σ + a1x + a2x
2 + · · · + at x
t mod q
In a verifiable secret sharing scheme, auxiliary information is
published that allows players to check that their shares consistently
define a unique secret.
Feldman’s VSS [14] is an extension of Shamir’s secret sharing in
which the dealer also publishes vi = д
ai
in G for all i ∈ [1,t].
Using this auxiliary information, each player can check its share
σi for consistency by verifying:
д
σi
?
=
Öt
0
v
zi
i
in G
If the check does not hold for any player, it raises a complaint
and the protocol terminates. Note that this is different than the
way Feldman VSS was originally presented as it assumed an honest
majority and could recover if a dishonest player raised a complaint.
However, since we assume dishonest majority in this paper, the
protocol will abort if a complaint is raised.
While Feldman’s scheme does leak д
σ
, it can be shown via a
simulation argument that nothing else is leaked, but we omit the
details here.
2.7 Assumptions
DDH. Let G be a cyclic group of prime order q, generated by д. The
DDH Assumption states that the following two distributions over
G
3
are computationally indistinguishable:DH = {(д
a
,д
b
,д
ab ) for a,b ∈R
Zq } and R = {(д
a
,д
b
,д
c
) for a,b,c ∈R Zq }.
Strong-RSA. Let N be the product of two safe primes, N = pq,
with p = 2p
′ + 1 and q = 2q
′ + 1 with p
′
,q
′ primes. With ϕ(N) we
denote the Euler function of N, i.e. ϕ(N) = (p − 1)(q − 1) = p
′q
′
.
With Z
∗
N
we denote the set of integers between 0 and N − 1 and
relatively prime to N.
Let e be an integer relatively prime to ϕ(N). The RSA Assumption
[31] states that it is infeasible to compute e-roots in Z
∗
N
. That is,
given a random element s ∈R Z
∗
N
it is hard to find x such that
x
e = s mod N.
The Strong RSA Assumption (introduced in [2]) states that given
a random element s in Z
∗
N
it is hard to find x, e , 1 such that
x
e = s mod N. The assumption differs from the traditional RSA
assumption in that we allow the adversary to freely choose the
exponent e for which she will be able to compute e-roots.
We now give formal definitions. Let SRSA(n) be the set of integers
N, such that N is the product of two n/2-bit safe primes.
Assumption 1. We say that the Strong RSA Assumption holds,
if for all probabilistic polynomial time adversaries A the following
probability
Prob[ N ← SRSA(n) ; s ← Z
∗
N
: A(N,s) = (x, e) s.t. x
e = s mod N ]
is negligible in n.
3 A SHARE CONVERSION PROTOCOL
Assume that we have two parties Alice and Bob holding two secrets a,b ∈ Zq respectively which we can think of as multiplicative
shares of a secret x = ab mod q. Alice and Bob would like to compute secret additive shares α, β of x, that is random values such
that α + β = x = ab mod q with Alice holding a and Bob holding b.
Here we show a protocol based on an additively homomorphic
scheme which has appeared many times before in the literature (e.g.
[9, 24, 26, 27] but that we adapt to our needs. We assume that Alice
is associated with a public key EA for an additively homomorphic
scheme E over an integer N. Let K > q also be a bound which will
be specified later.
In the following we will refer to this protocol as an MtA (for Multiplicative to Additive) share conversion protocol. In our protocol
we also assume that B = д
b might be public. In this case an extra
check for Bob is used to force him to use the correct value b. We
refer to this enhanced protocol as MtAwc (as MtA "with check").
(1) Alice initiates the protocol by
• sending cA = EA(a) to Bob
• proving in ZK that a < K via a range proof
(2) Bob computes the ciphertext cB = b ×E cA +E EA(β
′
) =
EA(ab + β
′
) where β
′
is chosen uniformly at random in ZN .
Bob sets his share to β = −β
′ mod q. He responds to Alice
by
• sending cB
• proving in ZK that b < K
• only if B = д
b
is public proving in ZK that he knows b, β
′
such that B = д
b
and cB = b ×E cA +E EA(β
′
)
(3) Alice decrypts cB to obtain α
′
and sets α = α
′ mod q
Correctness. Assume both players are honest and N > K
2q. Then
note that Alice decrypts the value α
′ = ab + β
′ mod N. Note that
if β
′ < N − ab the reduction modN is not executed. Conditioned
to this event, then the protocol correctly computes α, β such that
α + β = x mod q.
Since ab ≤ K
2
and N > K
2q we have that β
′ ≥ N − ab with
probability at most 1/q (i.e. negligible).
Simulation. We first point out that as a stand-alone protocol, we
can prove security even without the range proofs. Indeed, if the
adversary corrupts Alice, then Bob’s message can be simulated without knowledge of its input b. Indeed a simulator can just choose
a random b
′ ∈ Zq and act as Bob. The distribution of the message
decrypted by Alice in this simulation is identically to the message
decrypted when Bob uses the real b, because the “noise" β
′
is uniformly distributed in ZN .
If the adversary corrupts Bob, then Alice’s message can be simulated without knowledge of its input a. Indeed a simulator can just
choose a random a
′ ∈ Zq and act as Alice. In this case the view of
Bob is computationally indistinguishable from the real one due to
the semantic security of the encryption scheme E.
However if the range proofs are not used, a malicious Alice
or Bob can cause the protocol to "fail" by choosing large inputs.
As a stand-alone protocol this is not an issue since the parties
are not even aware that the reduction modN took place and no
information is leaked about the other party’s input. However, when
used inside our threshold DSA protocol, this attack will cause the
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1183
signature verification to fail, and this information is linked to the
size of the other party’s input.
Consider for example the case of Alice running the protocol with
input a
′ = q
2+a. If Bob’s input is "small" then the reduction mod N
wil not take place and the protocol will succeed, and eventually
the signature produced by our threshold DSA protocol will verify
(since a
′ = a mod q). But if Bob’s input is large the protocol will
fail.
So we need security in the presence of an oracle that tells the
parties if the reduction mod N happens or not, but due to the ZK
"range proofs" such reduction will only happen with negligible
probability and security holds.
Remark. An alternative approach. The above protocol is overwhelmingly correct, and hides b perfectly. We could modify it so that β
′
is
always chosen uniformly at random in [0...N − K
2
]. This distribution is statistically close to the uniform one over ZN (since K > q),
therefore the value b is now hidden in a statistical sense. On the
other hand the protocol is always correct.
Remark. On the ZK proofs and the size of the modulus N. For the
ZK proofs required in the protocol we use simplified versions of
similar ZK proofs presented in [27] and already used in [17]).
These are ZK arguments with security holding under the Strong
RSA Assumption. Moreover they require K q3 which in turns require N > q
7
. We point out that for typical choices of parameter N
is approximately q
8
(since q is typically 256-bit long while N is a
2048-bit RSA modulus), so this requirement is not problematic2
.
4 OUR SCHEME
We now describe our protocol. The players run on input G,д the
cyclic group used by the DSA signature scheme. We assume that
each player Pi
is associated with a public key Ei for an additively
homomorphic encryption scheme E.
4.1 Key generation protocol
• Phase 1. Each Player Pi selectsui ∈R Zq; computes[KGCi
,KGDi] =
Com(д
ui ) and broadcast KGCi
. Each Player Pi broadcasts
Ei the public key for Paillier’s cryptosystem.
• Phase 2. Each Player Pi broadcasts KGDi
. Let yi be the value
decommitted by Pi
. The player Pi performs a (t,n) FeldmanVSS of the value ui
, with yi as the “free term in the exponent"
The public key is set to y =
Î
i yi
. Each player adds the
private shares received during the n Feldman VSS protocols.
The resulting values xi are a (t,n) Shamir’s secret sharing of
the secret key x =
Í
i ui
. Note that the values Xi = д
xi are
public.
• Phase 3 Let Ni = piqi be the RSA modulus associated with
Ei
. Each player Pi proves in ZK that he knows xi using
Schnorr’s protocol [32] and that he knows pi
,qi using any
proof of knowledge of integer factorization (e.g. [30])
2
For the simple range proof that a, b < K one could alternatively use a variation of
Boudot’s proof [5] which establish K q which sets N q3
. This proof is less efficient
that the ones from [17, 27] which are anyway required for Bob in the MtAwc protocol.
Moreover as we said earlier, N > q
8
in practice anyway so the improvement in the
size of N is irrelevean for ECDSA.
4.2 Signature Generation
We now describe the signature generation protocol, which is run on
input m (the hash of the message M being signed) and the output
of the key generation protocol described above. We note that the
latter protocol is a t-out-of-n protocol (and thus the secret key x is
shared using (t,n) Shamir secret-sharing).
Let S ⊆ [1..n] be the set of players participating in the signature
protocol. We assume that |S | = t
′ where t < t
′ ≤ n. For the signing
protocol we can share any ephemeral secrets using a (t
′
,t
′
) secret
sharing scheme, and do not need to use the general (t,n) structure.
We note that using the appropriate Lagrangian coefficients λi,S each
player in S can locally map its own (t,n) share xi of x into a (t
′
,t
′
)
share wi = λi,S xi of x, i.e. x =
Í
i ∈S wi
. Since Xi = д
xi and λi,S
are public values all the players can compute Wi = д
wi = X
λi,S
i
.
• Phase 1. Each Player Pi selects ki
,γi ∈R Zq; computes
[Ci
,Di] = Com(д
γi ) and broadcast Ci
.
Define k =
Í
i ∈S ki
, γ =
Í
i ∈S γi
. Note that
kγ =
Õ
i,j ∈S
kiγj mod q
kx =
Õ
i,j ∈S
kiwj mod q
• Phase 2. Every pair of players Pi
, Pj engages in two multiplicativeto-additive share conversion subprotocols
– Pi
, Pj run MtA with shares ki
,γj respectively. Let αij [resp.
βij] be the share received by player Pi [resp. Pj] at the
end of this protocol, i.e.
kiγj = αij + βij
Player Pi sets δi = kiγi +
Í
j,i αij +
Í
j,i βji . Note that
the δi are a (t
′
,t
′
) additive sharing of kγ =
Í
i ∈S
δi
– Pi
, Pj run MtAwc with shares ki
,wj respectively. Let µij
[resp. νij] be the share received by player Pi [resp. Pj] at
the end of this protocol, i.e.
kiwj = µij + νij
Player Pi sets σi = kiwi +
Í
j,i
µij +
Í
j,i
νji . Note that
the σi are a (t
′
,t
′
) additive sharing of kx =
Í
i ∈S σi
• Phase 3. Every player Pi broadcasts δi and the players reconstruct δ =
Í
i ∈S
δi = kγ . The players compute δ
−1 mod q.
• Phase 4. Each Player Pi broadcasts Di
. Let Γi be the values
decommitted by Pi who proves in ZK that he knows γi s.t.
Γi = д
γi using Schnorr’s protocol [32].
The players compute
R = [
Ö
i ∈S
Γi]
δ
−1
= д
(
Í
i∈S γi )k
−1γ
−1
= д
γ k
−1γ
−1
= д
k
−1
and r = H(R).
• Phase 5. Each player Pi sets si = mki + rσi
. Note that
Õ
i ∈S
si = m
Õ
i ∈S
ki + r
Õ
i ∈S
σi = mk + rkx = k(m + xr) = s
i.e. the si are a (t
′
,t
′
) sharing of s.
– (5A) Player Pi chooses ℓi
, ρi ∈R Zq computes Vi = R
siд
ℓi
,
Ai = д
ρi
, Bi = д
ℓi ρi and and [Cˆ
i
,Dˆ
i] = Com(Vi
,Ai
, Bi)
and broadcasts Cˆ
i
.
Let ℓ =
Í
i
ℓi and ρ =
Í
i ρi
.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1184
– (5B) Player Pi broadcasts Dˆ
i and proves in ZK that he
knows si
, ℓi such that Vi = R
siд
ℓi and Bi = A
ℓi
i
. If a ZK
proof fails, the protocol aborts. Let V = д
−my
−r Î
i ∈S Vi
(this should be V = д
ℓ
)
– (5C) Player Pi computesUi = V
ρi andTi = [
Î
j,i Aj]
ℓi =
д
ℓi (ρ−ρi )
. It commits [C˜
i
,D˜
i] = Com(Ui
,Ti) and broadcasts C˜
i
.
– (5D) Player Pi broadcastsD˜
i to decommit toUi
,Ti
If Î
i ∈S
[TiBi] ,
Î
i ∈S Ui the protocol aborts.
– (5E) Otherwise player Pi broadcasts si
. The players compute s =
Í
i ∈S
si
. If (r,s) is not a valid signature the players
abort, otherwise they accept and end the protocol.
Let us explain the intuition behind Phase 5. To avoid expensive
ZK proofs, we are potentially reconstructing an incorrect signature,
which is then checked and possibly rejected. A naive approach to the
last phase is for the players to reveal si and reconstruct s =
Í
i
si
.
But, for reasons that will become clear in the proof, this is not
provably secure – the intuitive reason being that if the adversary
makes the protocol fail by outputting an invalid signature the values
si held by the good players may give him valuable information.3
Naively this could be done by first broadcasting Si = R
si and
check that Î
i Si = R
s = д
my
r
according to the DSA verification
algorithm. But for similar reasons, this step makes the proof fail.
So in our protocol the players mask R
si with a random value д
ℓi
.
Let Vi = R
siд
ℓi
. Then Î
i Vi = R
sд
ℓ
and therefore V = д
ℓ
. The
players cannot reveal д
ℓi
to check the correctness ofV as this would
"de-mask" R
si so we "randomize" the "aggregate" value to U = д
ℓρ
.
Alongside the players compute д
ℓρ via pairwise "Diffie-Hellman"
exchanges. If this distributed randomized signature verification
carries out, then it is safe to release the sharessi
, but if the signature
does not verify then the protocol aborts here and the values si held
by the good players are never revealed in the clear.
4.3 The Zero-Knowledge Proofs
In step (5B) a player P outputs V = R
sд
ℓ
and A, B = A
ℓ
and must
prove that he knows s, ℓ satisfying the above relationship. A classic
(honest-verifier) ZK proof for this task is as follows:
• The Prover chooses a,b ∈R Zq and sends α = R
aд
b
and
β = A
b
• The Verifier sends a random challenge c ∈R Zq
• The Prover answers with t = a + cs mod q and u = b +
cℓ mod q.
• The Verifier checks that R
tд
u = αV
c
and A
u = βB
c
4.4 Security Proof
In this section we prove the following
Theorem 4.1. Assuming that
• The DSA signature scheme is unforgeable;
• The Strong RSA Assumption holds;
• KG, Com, Ver, Equiv is a non-malleable equivocable commitment scheme;
• the DDH Assumption holds
then our threshold DSA scheme in the previous section is unforgeable.
3 We do not have an attack but we do not see a way to make a proof work either.
The proof of this theorem will proceed by a traditional simulation
argument, in which we show that if there is an adversary A that
forges in the threshold scheme with a significant probability, then
we can build a forger F that forges in the centralized DSA scheme
also with a significant probability.
So let’s assume that there is an adversary A that forges in the
threshold scheme with probability larger than ϵ ≥ λ
−c
.
We assume that the adversary controls players P2, . . . , Pt+1 and
that P1 is the honest player. We point out that because we use
concurrently non-malleable commitments (where the adversary
can see many commitments from the honest players) the proof also
holds if the adversary controls less than t players and we have more
than 1 honest player. So the above assumption is without loss of
generality.
Because we are assuming a rushing adversary, P1 always speaks
first at each round. Our simulator will act on behalf of P1 and interact with the adversary controlling P2, . . . , Pn. Recall how A works:
it first participates in the key generation protocol to generate a
public key y for the threshold scheme. Then it requests the group
of players to sign several messages m1, . . . ,mℓ
, and the group engages in the signing protocol on those messages. At the end with
probability at least ϵ the adversary outputs a message m , mi and
a valid signature (r,s) for it under the DSA key y. This probability
is taken over the random tape τA of A and the random tape τ1 of
P1. If we denote with A(τA)P1(τ1)
the output of A at the end of the
experiment described above, we can write
Probτ1,τA
[ A(τA)P1(τ1)
is a forgery ] ≥ ϵ
We say that an adversary random tape τA is good if
Probτ1
[ A(τA)P1(τ1)
is a forgery ] ≥ ϵ
2
By a standard application of Markov’s inequality we know that if
τA is chosen uniformly at random, the probability of choosing a
good one is at least ϵ
2
.
We now turn to building the adversary F that forges in the
centralized scheme. This forger will use A as a subroutine in a
“simulated" version of the threshold scheme: F will play the role of
P1 while A will control the other players. F will choose a random
tape τA for A: we know that with probability at least ϵ
2
it will be a
good tape. From now on we assume that A runs on a good random
tape.
F runs on input a public key y for the centralized DSA scheme,
which is chosen according to the uniform distribution in G. The
first task for F is to set up an indistinguishable simulation of the
key generation protocol to result in the same public key y.
Similarly every time A requests the signature of a message mi
,
the forger F will receive the real signature (ri
,si) from its signature
oracle. It will then simulate, in an indistinguishable fashion, an
execution of the threshold signature protocol that on input mi
results in the signature (ri
,si).
Because these simulations are indistinguishable from the real
protocol for A, the adversary will output a forgery with the same
probability as in real life. Such a forgery m,r,s is a signature on a
message that was never queried by F to its signature oracle and
therefore a valid forgery for F as well. We now turn to the details
of the simulations.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1185
4.5 Simulating the key generation protocol
The simulation Sim-Key-Gen is described below. On input a public
key y = д
x
for DSA the forger F plays the role of P1 as follows.
The forger F also runs on input a public key E for which he does
not know the matching secret key (this is necessary for when we
have to make a reduction to the semantic security of the Paillier
encryption scheme).
Simulation: Repeat the following steps (by rewinding A) until A
sends valid messages (i.e. a correct decommitment) for P2, . . . , Pn
on both iterations.
• F (as P1) selects a random valueu1 ∈ Zq, computes[KGC1,KGD1]=
Com(д
u1 ) and broadcasts KGC1. A broadcast commitments
KCGi for i > 1;
• Each player Pi broadcasts KGDi
; let yi be the decommitted
value and the accompanying Feldman-VSS (F will follow the
protocol instructions). Each player broadcasts Ei
. F broacasts
E1 = E.
• Let yi the revealed commitment values of each party. F
rewinds the adversary to the decommitment step and
– changes the opening of P1 to KGDˆ
1 so that the committed
value revealed is now yˆ1 = y ·
În
i=2
y
−1
i
.
– simulates the Feldman-VSS with free term yˆ1
• The adversary A will broadcasts KGDˆ
i
. Let yˆi be the committed value revealed by A at this point (this could be ⊥ if
the adversary refused to decommit).
• The players compute yˆ =
Ît+1
i=1
yˆi
(set to ⊥ if any of the yˆi
are set to ⊥ in the previous step).
We now prove a few lemmas about this simulation.
Lemma 4.2. The simulation terminates in expected polynomial
time and is indistinguishable from the real protocol.
Proof of Lemma 4.2. SinceA is running on a good random tape,
we know that the probability over the random choices of F , that
A will correctly decommit is at least ϵ
2
>
1
2λ
c
. Therefore we will
need to repeat the loop only a polynomial number of times in
expectation.
The only differences between the real and the simulated views
is that P1 runs a simulated Feldman-VSS with free term in the
exponentyˆ1 for which it does not know the discrete log. But we have
shown in Section 2.6 that this simulation is identically distributed
from the real Feldman-VSS. So the simulation of the protocol is
perfect. □
Lemma 4.3. For a polynomially large fraction of inputs y, the
simulation terminates with output y except with negligible probability.
Proof of Lemma 4.3. First we prove that if the simulation terminates on an output which is not ⊥, then it terminates with output
y except with negligible probability. This is a consequence of the
non-malleability property of the commitment scheme. Indeed, if
A correctly decommits KGCi twice it must do so with the same
string, no matter what P1 decommits too (except with negligible
probability)4
. Therefore yˆi = yi for i > 1 and therefore yˆ = y.
4 This property is actually referred to as independence. This is introduced in [20] as a
stronger version of non-malleability and then proven equivalent to non-malleability
in [4]).
Then we prove that this happens for a polynomially large fractions of input y. Let yA =
Ît+1
i=2
yi
, i.e.the contribution of the adversary to the output of the protocol. Note that because of nonmalleability this value is determined and known to F by the time
it rewinds the adversary. At that point F rewinds the adversary
and chooses yˆ1 = yy−1
A
. Since y is uniformly distributed, we have
that yˆ1 is also uniformly distributed. Because A is running on a
good random tape we know that at this point there is an ϵ
2
>
1
2λ
c
fraction of yˆ1 for which A will correctly decommit. Since there is
a 1-to-1 correspondence between y and yˆ1 we can conclude that
for a ϵ
2
>
1
2λ
c
fraction of the input y the protocol will successfully
terminate. □
4.6 Signature generation simulation
After the key generation is over, F must handle the signature queries
issued by the adversary A. When A requests to sign a message m,
our forger F will engage in a simulation of the threshold signature
protocol. During this simulation F will have access to a signing
oracle that produces DSA signatures under the public key y issued
earlier to F .
Semi-Correct Executions. Let k be such that R = д
k
−1
and let ˜k be
the value defined by the inputs of the players in the MtA and MtAwc
protocols. More specifically ifci
is the encryption sent by player Pi
in the first round of those protocols, then define ˜ki = Deci(ci) and
˜k =
Í
i
˜ki
.
We say that a protocol execution is semi-correct if in step (4) it
holds that k = ˜k. Note that this condition is well defined since the
values k,
˜k are uniquely determined by step (4). It is however not
feasible to decide if an execution is semi-correct or not.
Note that an execution is not semi-correct if the adversary "messes"
up the computation of R by revealing wrong shares in the computation of δ.
Bird-Eye View of Simulation. First we note that for semi-correct
executions the adversary, after Step 4 can already detect if the value
R
s1 which will be broadcast in Step (5) by the good player is correct
or not. In fact by this point the adversary has si for i > 1 and for a
"candidate" R
s1 can check if
Ö
i
R
si = R
s = д
my
r
Moreover in such executions when we arrive to step (5A) the simulator will be able to "extract" the value s1 for the good player, which
will allow the simulation to terminate successfully.
Second, we show that a simulation that is not semi-correct will
fail at step (5D) with high probability since the valueU1 contributed
by the good player is indistinguishable from random. This allows
us to simulate Phase (5) by simply using a random s˜1 for P1.
The final question is how do we detect if an execution is semicorrect or not. Here we use an idea from [26]: the forging simulator
will guess which one (if any) of the Q signature queries result in an
execution which is not semi-correct. Since this execution will be an
aborting execution, the simulation will stop there. With probability
1/(Q + 1) the guess will be correct and the simulation will succeed,
and the forger will be able to produce a forgery.
We now proceed with the details.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1186
4.7 Semi-correct executions
We now present a simulation that works for a semi-correct execution. We point out that F does not know the secret values associated
with P1: its correct share w1 of the secret key, and the secret key
of its public key E1. The latter is necessary in order to reduce unforgeability to the semantic security of the encryption scheme.
However F knows the secret keys of all the other players, and
their shares wj
. It also knows the "public key" of P1,W1 = д
w1
from
the simulation of the key generation protocol.
In the following simulation F aborts whenever the protocol is
supposed to abort, i.e. if the adversary (i) refuses to decommit in
steps 4, 5B or 5D or (ii) fails the ZK proof in Step 2 or 5 or (iii) the
signature (r,s) does not verify.
• Phase 1 All the players execute the protocol by broadcasting
Ci
(F runs the protocol correctly for P1).
• Phase 2
– All the players execute the MtA protocol for k and γ . F
runs the protocol correctly for P1 but it cannot decrypt
the share α1j during the execution of the protocol with Pj
on input k1,γj
, so F sets αij to a random value in Zq
– All the players execute the MtAwc protocol for k and x.
Here F simulates P1 according to the simulation described
in Section 3. Moreover it extracts Pj resulting share ν1j
from his ZK proof.
In the protocol with Pj on input kj
,w1, F does not know
w1 so it just sends a random µj1 to Pj
Note that at this point F knows σi for the bad players. Indeed
σi = kiwi +
Õ
j
µij +
Õ
j
νji
and F knows all the values on the right end side of the
equation.
• Phase 3 All the players execute the protocol by revealing δi
.
Let δ =
Í
i
δi
(F runs the protocol correctly for P1 with the
random shares it chose in step 2 – therefore F is effectively
broadcasting a random δ1).
• Phase 4
(1) Each player reveals Di to decommit to Γi
(2) F queries its signature oracle and receives a signature
(r,s) on m. It computes R = д
ms−1
y
r s−1
∈ G (note that
H
′
(R) = r ∈ Zq).
(3) F rewinds A to the decommitment step, and for P1 changes
the decommitment to Γˆ
1 = R
δ Î
i>1 Γ
−1
i
. Note that [Γˆ
1
Î
i>1 Γi]
δ
−1
=
R
Note that at this point F knows the value si held by the bad
players since si = kim + σir. So F can compute the correct
s1 held by P1 as s −
Í
i>1
si
.
• Phase 5 All players execute all the steps in this phase. F uses
s1 as the share for P1
We prove the following Lemma about the simulation.
Lemma 4.4. Assuming that
• The Strong RSA Assumption holds
• KG, Com, Ver, Equiv is a non-malleable equivocable commitment;
then the simulation has the following properties
• on input m it outputs a valid signature (r,s) or aborts.
• it is computationally indistinguishable from a semi-correct
real execution
Proof of Lemma 4.4. The only differences between the real and
the simulated views is the following: In the MtA protocol the values
ci = Ei(ki) are published and in the real protocol R = д
k
−1
where
k =
Í
i ki
, while in the simulated execution R = д
ˆk
−1
for the ˆk
chosen by the signature oracle. This is easily seen to be computationally indistinguishable under the semantic security of Paillier’s
encryption.
Indeed, when F rewinds the adversary to "fix" the value of R, it
implicitly changes the value k1 that F contributes for P1 to R. If
R = д
ˆk
−1
, let (implicitly) ˆk1 = ˆk −
Í
i>1 ki
. Note that R
ˆk1
is known
since R
ˆk1+
Í
i >1 ki = д, therefore R
ˆk1 = дR
−k2
. So to distinguish
between the real execution and the simulated one the adversary
should detect if the ciphertext sent by F for P1 in the first round
of the MtAwc protocol contains a random k1 or the random ˆk1
determined as logR
(дR
−k2 ) which is infeasible under the semantic
security of Paillier’s encryption (given that all values are proven to
be "small" and no wraparound modN happens).
Note that we are simulating a semi-correct execution with an
execution which is not semi-correct, but that’s OK because the two
are indistinguishable.
However, because the real execution is a semi-correct one, we
know that the correct shares of k for the adversary are the ki that the
simulator knows. Therefore the value s1 computed by the simulator
is consistent with a correct share for P1 for a valid signature (r,s),
which makes Phase 5 indistinguishable from the real execution to
the adversary.
Let (r,s) be the signature that F receives by its signature oracle
in Step 2 of Phase 4. This is a valid signature for m. We prove that
if the protocol terminates, it does so with output (r,s). This is a
consequence of the non-malleability property of the commitment
scheme. Indeed, if the adversary correctly decommits, its openings
must be the same except with negligible probability. □
4.8 Simulation of a non semi-correct execution
We now show how to simulate the last execution for a non semicorrect execution when ˜k , k. Details follow.
• Phases 1 to 3 The simulator runs the semi-correct simulation through Phase 3 (including aborting at Phase 4 if the
adversary fails to decommit).
• Phase 4 F does not rewind the adversary to "fix" the value
of R, but runs the protocol normally for P1.
• sf Phase (5) F chooses s˜1 ∈R Zq and runs Phase 5 with this
value instead of s1.
Before we prove that this simulation is indistinguishable for nonsemi-correct executions let us give an intuition. Note that the only
difference with the previous simulation is that here F uses a random
share s˜1 instead of the s1 that it computed in the other simulation.
The reason is that the value s1 computed in the previous simulation
is only guaranteed to be the "correct" share of s if the execution
is semi-correct. If the adversary shares ki don’t match anymore
the value R then s1 is incorrect, and therefore F chooses a random
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1187
value instead. In turns this causes U1 to be uniformly distributed
and the check in step (5D) to fail.
The main point of the proof is that if the execution is not semicorrect then the valueU1 is (given the view of the adversary) computationally indistinguishable from uniform even in the real execution
(under the DDH assumption).
Our proof reflects the above intuition. First we prove that a
real non-semi-correct execution is indistinguishable from one in
which P1 outputs a random S1. And then we prove that this is
indistinguishable from the simulation above.
Lemma 4.5. Assuming that
• KG, Com, Ver, Equiv is a non-malleable equivocable commitment;
• the DDH Assumptions holds
then the simulation is computationally indistinguishable from a nonsemi-correct real execution
Proof of Lemma 4.5. We construct three games between the
simulator (running P1) and the adversary (running all the other
players). In G0 the simulator will just run the real protocol. In G1
the simulator will follow the real protocol but will choose S1 as
a random group element. In G2 the simulator will run the above
simulation.
Indistinguishability of G0 and G1 Let us assume that there is an
adversary A0 that can distinguish between G0 and G1. We show
how this contradicts the DDH Assumption.
Let A = д
a
, B = д
b
,C = д
c be the DDH challenge where c = ab
or random in Zq.
The distinguisher F0 runs A0, simulating the key generation
phase so that y = B = д
b
. It does that by rewinding the adversary
at the end of Phase 2 of the key generation protocol and changing
the decommitment of P1 to y1 = b
Î
i>1 y
−1
i
.
F0 also extracts the values xi from the adversary. Note that at
this point y = B and F0 knows xi
, but not b and therefore not x1.
Moreover F0 extracts the secret key for the encryption keys Ei for
i > 1. In this simulation F0 also knows the secret key matching
E1 (since we are not making any reduction to the security of the
encryption scheme).
Then F0 runs the signature generation protocol for a not-semicorrect execution. Remember here we assume that we have a (t
′
,t
′
)
sharing of the secret key. So b =
Í
i ∈S wi with F0 knowing wi for
i > 1 but not knowing w1. Denote with wA =
Í
i>1 wi
(which is
known to F0) and therefore w1 = b − wA.
F0 runs the protocol normally for Phases 1,2,3,4. It extracts the
value γi for i > 1 from the adversary (and he knows γ1 since he
ran P1 normally). Therefore F0 knows k such that R = д
k
−1
since
k = (
Í
i γi)δ
−1
. It also knows k1 since it was chosen normally
according to the protocol. Before moving to the simulation of Phase
5, let’s look at the MtAwc protocol for the computation of the shares
σi
.
We note that since F0 knows the decryption key for E1 he also
knows all the shares µ1j from the invocation of the MtAwc protocol
between P1 and Pj on input k1 and wj respectively5
.
5
In this case we do not need to extract anything from Pj
’s ZK proof, but we still need
to check that the value sent by Pj
is correct.
For the MtAwc protocol between P1 and Pj on inputw1 and kj respectively, F0 knows the value kj
input by Pj since he has extracted
the secret key of Ej
. However F0 does not know w1 therefore he
sends a random µj1 to Pj and sets (implicitly) νj1 = kjw1 − αj1.
At the end we have that the share σ1 held by P1 is
σ1 = k1w1 +
Õ
j>1
µ1j +
Õ
j>1
νj1
by rearranging the terms and substituting the above we get
σ1 = ˜kw1 +
Õ
j>1
µ1j −
Õ
j>1
µj1
where ˜k =
Í
i ki
. Remember that since this is not a semi-correct
execution then ˜k , k where R = д
k
−1
.
Since w1 = b − wA we have
σ1 = ˜kb + µ1
where
µ1 =
Õ
j>1
µ1j −
Õ
j>1
µj1 − ˜kwA
with µ1,
˜k known to F0.
Note that this allows F0 to compute the correct value
д
σ1 = B
˜k
д
µ1
and therefore the correct value of R
s1 as
R
s1 = R
k1m+rσ1 = д
k
−1
(k1m+rσ1) = д
k
−1
(k1m+r µ1)B
k
−1 ˜kr
or
R
s1 = д
µˆ1B
ˆβ1
where µˆ1 = k
−1
(k1m + r µ1) and ˆβ1 = k
−1 ˜kr and µˆ1 and ˆβ1 are
known to F0.
We now continue the simulation
• 5A/5B F0 selects a random ℓ1 and sets V1 = R
s1д
ℓ1 A1 =
д
ρ1 = A = д
a
and B1 = д
ρ1 ℓ1 = A
ℓ1
. It simulates the ZK
proof (since it does not know ρ1 or s1). It extracts si
, ℓi from
the adversary such that Vi = R
siд
ℓi = д
k
−1
siд
ℓi
. Let sA = Í
i>1 k
−1
si
Note that
V = д
−my
−r Ö
i
Vi = д
−my
−rV1
Ö
i>1
Vi
and therefore substituting the above relations (and setting
ℓ =
Í
i
ℓi
)
V = д
ℓR
s1д
sA−my
−r
Note that y = B so y
−r = B
−r
. Therefore
V = д
ℓ
д
µˆ1B
ˆβ1д
sA−mB
−r
or
V = д
ℓ
д
θ B
κ
where θ = µˆ1 + sA − m and κ = ˆβ1 − r known to F0.
Note that for executions that are not semi-correct , 0
• 5C/5D F0 computes T1 correctly (which he can do since he
knows ℓ1) but for U1 outputs U1 = A
θC
κ
and it aborts.
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1188
Note what happens when C = д
ab . By our choice of a = ρ1 and
b = x we have that U1 = V
ρ1 as in Game G0. However when C is a
random group element, U1 is uniformly distributed as in G1.
Therefore under the DDH assumption G0 and G1 are indistinguishable.
Indistinguishability of G1 and G2 We note that in G2 the simulator really computes U1 as V
ρ1
(rather than outputting a random
group element). However since s˜1 is chosen at random we have
that U1 follows a uniform distribution in both games.
In Phase (5B) F broadcasts a random V˜
1 = R
s˜1д
ℓ1 which is indistinguishable from the correct V1 = R
s1д
ℓ1 because of the "mask"
д
ℓ1 which (under the DDH) is computationally indistinguishable
from a random value, given that the adversary only has A1, B1.
Therefore under the DDH assumption the games G1 and G2 are
indistinguishable.
□
4.9 Finishing up the proof
Before we conclude the proof we note that our protocol detects the
presence of a malicious adversary by noticing that the signature
does not verify. As pointed out by Lindell in [26] this strategy is
not immediately simulatable against a malicious adversary for the
following reason. Consider what happens in Phase 5: In the semicorrect simulation F rewinds the adversary to “hit" the correct s.
But if the adversary had decided to be malicious and terminate the
protocol with an invalid signature, then the protocol would not be
simulatable. If F hits an invalid signature “on purpose" (e.g. by not
rewinding), then the simulation is distinguishable by a semi-honest
adversary who does hit the correct signature.
Luckily for a “game-based" definition of security, this is not an
issue as discussed in [26]. Let Q < λ
c be the maximum number of
signature queries that the adversary makes. In the real protocol,
the adversary will output a forgery after ℓ < Q queries, either
because it stops submitting queries, or because the protocol aborts.
Therefore in our simulation, following Lindell [26], we choose a
random index ι ∈ [0...Q]:
• if ι = 0 we assume that all executions are semi-correct. In
this case we can always simulates as in the previous section
• otherwise we assume that the first ι − 1 executions are semicorrect, but at the ι
th execution the value V is not equal to
д
ℓ
.
With probability 1/(Q + 1) ≥ λ
−c
this is a correct guess.
We can now complete the proof.
Proof of Theorem 4.1. Unforgeability. The forger F described
above produces an indistinguishable view for the adversary A, and
therefore, A will produce a forgery with the same probability as in
real life. The success probability of F is at least ϵ
3
8Q where Q is the
maximum number of queries. That’s because F has to succeed in
• choosing a good random tape for A (this happens with probability larger than ϵ
2
)
• hitting a good public key y (this also happens with probability larger than ϵ
2
)
• guessing the correct index query ℓ (this happens with probability larger than 1/Q
Under those conditions, the adversary A will output a forgery with
probability at least ϵ
2
.
Under the security of the DSA signature scheme, the probability
of success of F must be negligible, which implies that ϵ must also be
negligible, contradicting the assumption that A has a non-negligible
probability of forging.
Correctness. If all players are honest, the protocol fails only if
one of the MtA protocols fails. Since we have a total of 4n
2
such
sub-protocols executed during a run of our signature protocol, we
have that our protocol fails with probability at most 4n
2
q which is
negligible.
□
5 EXTENSIONS
In the final version of the paper we will present the following
natural extensions to our result.
Other additively homomorphic schemes. Our optimistic scheme
works with any additively homomorphic scheme with no modification. It requires an assumption analogous to the Paillier-EC (or an
efficient ZK Proof for the statement in the MtAwc protocol).
Other multiplicative to share conversions. Again, our optimistic protocol works with any protocol that allows two parties to
convert their multiplicative shares of a secret into additive shares.
In particular protocols based on oblivious transfer can be used (see
the literature on SPDZ or the recent work on threshold DSA in
[12]).
Deterministic Key Generation A very popular feature of Bitcoin wallets is deterministic key generation. Introduced in BitcoinImprovement-Proposal 32 (BIP32), the idea of this scheme is to allow
one to deterministicly generate many keys from a single ECDSA
key. Our key sharing is compatible with BIP32 public derivations,
and we leave it as future work to prove security in this setting.
6 REMOVING THE ZK PROOFS FROM THE
MTA PROTOCOL
As we mentioned in the Introduction, the ZK proofs in the MtA
protocol are the most expensive step of our protocol due not only to
the fact that these are ZK proofs over the Paillier cryptosystem, but
also that every player has to run n of them (since they are specific
to each execution of the MtA protocol).
We consider what happens if the range proofs are eliminated.
As we discussed in Section 3 the MtA protocol needs to be secure
in the presence of an oracle that tells the parties if a reduction
mod N happens during the execution. Note that in reality the oracle
represents the failure of the verification of the signature generated
by the protocol, and if that happens the system is reset. So the
oracle is a very weak oracle, which stops the working the moment
it tells you that a reduction modN happened.
We conjecture that our protocol remains secure even if the ZK
proofs are eliminated for Alice and simplified for Bob in the MtA
protocol and simplified in the MtAwc protocol. More precisely both
the MtA and MtAwc protocol work as follow:
• Neither party proves that their values a,b are "small"
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1189
• Bob broadcasts B = д
b
, B
′ = д
β
′
together with a ZK proof
of knowledge for b, β
′ mod q using Schnorr’s prooof [32].
Alice also checks that д
α = B
aB
′
.
We point out that B = д
b
is public in our threshold DSA
protocol. Indeed in one case b = wi
, the share of the secret
key x held by player Pi and B = д
b
is public at the end of the
key generation phase together with a ZK proof of knowledge.
In the other case b = γi
, and B = д
b will be public at the end
of following round which is when Alice performs the above
check.
To support our conjecture we propose some "ad-hoc" computational assumptions which if true, they would guarantee the security
of the protocol. The assumptions are new and non-standard, yet
they look reasonable. We discuss them informally below – a full
proof of security will appear in the final version.
Information Leaked to Alice by removing the Range Proof.
If we remove the proofs that the input a used by Alice is small, we
leak information about the input used by Bob via the knowledge
that a reduction modN happened or not. Notice that Bob’s inputs
to the MtA and MtAwc protocols are the share of ρ (the mask for
the inversion of k) and the share of x (the secret key).
Note that these values are all "high entropy" secrets and that a
reduction modN can only happen once, since if that happens the
protocol ends.
Therefore the following stronger assumption on the unforgeability of DSA would suffice. We define a game between a Challenger
and an Attacker:
• The Challenger gives to the Attacker a DSA public key y =
д
x
and a random number xˆ ∈R Zq. Let x
′ = x − xˆ mod q.
The Attacker chooses an RSA modulus N > q
3
.
• The Attacker submits a message m and three arbitrary numbers λ1, λ2, ρˆ1.
• The Challenger chooses ρ
′ ∈R Zq and β1, β2 ∈R ZN . If
λ1x
′+β1 and λ2ρ
′+β2 are less than N, the Attacker receives
(r,s) a valid DSA signature on m and also α = ρk mod q
where k ∈R Zq and r = д
k
−1
.
Otherwise the game stops.
The Attacker wins if he forges a signature on a message for which
the Challenger did not output a signature. The assumption is that
winning this game is infeasible.
We believe this assumption to be reasonable because it appears
that the Attacker receives only limited information about the values
x, k.
Note that we can’t simulate Alice’s view in this case, but we are
arguing that the information leaked is minimal and does not affect
security in a game-based definition of unforgeability.
Information Leaked to Bob by removing the ZK Consistency
Proof. Here instead we are able to simulate Bob’s view under a
stronger assumption on the Paillier cryptosystem.
If Bob is corrupted, then the simulated Alice sends the encryption
of a random value cA = E(aˆ). But then it must decide if to accept
or reject at the end of step (2) (where the real Alice checks that
д
α = B
aB
′
) without knowing aˆ. Here we assume that the simulator
is provided with an oracle ΩcA
(cB,b, β) which answers 1 if and
only if Dec(cB) = b · Dec(cA) + β mod q. Then the simulator will
extract b, β from the malicious Bob’s proof of knowledge, and query
ΩcA
(cB,b, β) and accepts if the oracle answers 1.
Security cannot be based on the semantic security of the Paillier’s
encryption scheme anymore since the presence of the oracle immediately implies that Paillier is not semantically secure anymore.
However consider the following experiment:
• Generate a Paillier key (E,D)
• Generate two random values a0, a1 ∈R Zq and publish A =
д
a0
• Choose a random bit b and publish c = E(ab
)
• Let b
′ be the output of the adversary who is allowed restricted
access to the oracle Ωc – by restricted we mean that the
oracle will stop working after it outputs 0.
We say that the Paillier-ECR assumption holds if for every PPT adversary, the probability that b = b
′
is negligible. Under the PaillierECR assumption we can prove that no adversary given д
a0 can
distinguish if the MtA protocol was run with a0 or a1 (with both
values being "high entropy" in particularly randomly chosen). This
is sufficient to simulate MtA with high entropy inputs, which is
what is needed to prove security of our threshold DSA protocol.
We note that our Paillier-ECR assumption is a weaker version
of the Paillier-EC assumption in [26]. In the latter the oracle access
is not restricted, which makes the assumption much stronger. In
our case it is sufficient to consider the restricted oracle since the
real protocol stops if Alice detects cheating.
7 IMPLEMENTATION, BENCHMARKS, AND
EVALUATION
We implemented both the key generation and signature generation
of our protocol, and we confirm that they are highly efficient and
fast enough to be used in practice. We benchmarked the version
of our protocol from Section 6 that does not contain the range
proofs, but relies on the Paillier-ECR assumption. We compare the
performance of our protocol to the runtimes of Gennaro et al. [17]
and Boneh et al. [4]. All benchmarks were single-threaded and run
on an an Intel quad-core i7-6700 CPU @ 3.40GHz and 64GB of RAM.
We ran the code [17] and [4] on our benchmark machine to get
an accurate comparison. It should be noted that we implemented
our scheme in C while theirs is a Java implementation which calls
native C libraries for the heaviest arithmetic computations. All
benchmarks were taken over the secp256k1 curve, which is is the
curve used in Bitcoin and more recently a NIST standard.
For the curve operations, we used libsecp256k1.6 We implemented the MtA protocol with Paillier using the implementation
from libhcs.7
.
7.1 Benchmarking the data complexity
When compared to [4, 17], we reduce the amount of data transmitted. All figures in this section were measured empirically from the
respective implementations, and thus it is possible that they may be
further optimized in practice.8 For a threshold of t (i.e. when there
6https://github.com/bitcoin-core/secp256k1
7https://github.com/tiehuis/libhcs
8We note that in [12] they give size benchmarks for [17] and [4] that are far worse than
the numbers we gave– nearly 2 Megabytes for the two party case alone. However,
when we ran the benchmarks ourselves, we found that their numbers were incorrect
Session 6C: Crypto 3 CCS’18, October 15-19, 2018, Toronto, ON, Canada 1190
are t + 1 participants in the signing protocol), the total data d in
bytes sent and received by a given player to/from all other players
during the signing protocol is given by:
dour s (t) = 2, 328 + t × 5, 024 Bytes
In contrast, the data sent to/from a given player in [17] is given
by:
dGennaro (t) = (t + 1) × 34, 578 Bytes
And the data transmitted per player in [4] is given by:
dBoneh(t) = (t + 1) × 38, 189 Bytes
Lastly, we mention that for the 2-of-n case, we have dour s (t =
1) = 3, 976 B. In contrast, the recent protocol of [12] requires far
more than that with 86.7 KiB for 2-of-2 signing and 106.7 KiB
for 2-of-n signing. Lindell’s scheme [26] only requires 769 B to be
communicated in the 2-of-2 case (but does not support 2-of-n).
7.2 Benchmarking signature generation time
Following the methodology of [4, 17], we benchmark the raw computation time of a single player without counting network costs.
Since each player runs their computation in parallel, this represents
the running time of the entire protocol other than network latency.
We find that our protocol significantly outperforms both of [4, 17]
when using this metric.
As in [4, 17], the protocol running time has a fixed cost that is
independent of the number of players plus a linear marginal cost
as the threshold increases. We stress that the signing time only
depends on the number of active participants (t + 1), but does not
depend on n, the total number of players. All times are given on a
single core, and were averaged over 1000 iterations.
Our protocols running time is given by:
rour s (t) = 29 + (t) × 24 milliseconds
The running time of [17] is given by:
rGennaro (t) = 142 + (t) × 52 milliseconds
The running time of [4] is given by:
rBoneh(t) = 397 + (t) × 91 milliseconds
We can see that our protocol significantly outperforms both
previous schemes. See Figure 1 for a comparison of the concrete
raw computation times for thresholds up to 20.
8 CONCLUSION
We have presented a threshold ECDSA protocol that is an improvement over the existing schemes by every metric. Although [17]
has been available for some time, there are still to our knowledge
no Bitcoin services or user wallets that offer threshold-signature
security. We believe that this is due to the impracticality of their
distributed key generation protocol. Having to rely on a trusted
dealer to distribute key shares exposes a single point of failure for
the system and in doing so runs contrary to the entire premise of
using threshold signatures in the first place.
and far too high. Even with our own more favorable benchmarks of [4, 17], our scheme
is still a significant improvement.
Figure 1: Comparison of the raw computation time as
the threshold increases between this work and previous
schemes.
We solve this problem by presenting and implementing a new
scheme with a highly efficient distributed key generation protocol.
Together with our reduction in running time and data transferred,
we believe that ECDSA threshold signatures are finally mature
enough for adoption.