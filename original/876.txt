ABSTRACT
Secure aggregation is a cryptographic primitive that enables a
server to learn the sum of the vector inputs of many clients. Bonawitz
et al. (CCS 2017) presented a construction that incurs computation
and communication for each client linear in the number of parties.
While this functionality enables a broad range of privacy preserving
computational tasks, scaling concerns limit its scope of use.
We present the first constructions for secure aggregation that
achieve polylogarithmic communication and computation per client.
Our constructions provide security in the semi-honest and the semimalicious settings where the adversary controls the server and a
γ -fraction of the clients, and correctness with up to δ-fraction
dropouts among the clients. Our constructions show how to replace the complete communication graph of Bonawitz et al., which
entails the linear overheads, with a k-regular graph of logarithmic
degree while maintaining the security guarantees.
Beyond improving the known asymptotics for secure aggregation, our constructions also achieve very efficient concrete parameters. The semi-honest secure aggregation can handle a billion
clients at the per-client cost of the protocol of Bonawitz et al. for
a thousand clients. In the semi-malicious setting with 104
clients,
each client needs to communicate only with 3% of the clients to
have a guarantee that its input has been added together with the
inputs of at least 5000 other clients, while withstanding up to 5%
corrupt clients and 5% dropouts.
We also show an application of secure aggregation to the task of
secure shuffling which enables the first cryptographically secure
instantiation of the shuffle model of differential privacy.
CCS CONCEPTS
• Security and privacy → Cryptography; Distributed systems
security; Privacy-preserving protocols.
KEYWORDS
multi-party computation; secure aggregation; secure shuffling;
1 INTRODUCTION
Once considered a purely theoretical tool, cryptographic secure
multiparty computation has become a tool that underlies several
technological solutions [1, 7, 8, 12, 23, 27, 29]. In this context, constructions for two parties (or a small number of parties) still have
dominant presence. One reason for this is the increased complexity
that many party solutions bring, which could be a challenge for
adoption among a large number of participants. Another reason
is the fact that many multiparty solutions require communication
channels between all participants, which is not always viable. Further, real scenarios with many parties need to account for the fact
that a fraction of the parties may drop out during the execution.
All of these concerns apply to the setting where a service provider
collects aggregate statistics from a large population in a privacy preserving way. This includes basic statistical tasks such as computing
mean, variance, and histograms, as well as large scale distributed
training of machine learning models as in federated learning [7, 25].
In such settings there is a powerful central server and a large number of clients with constrained resources, a single communication
channel only to the server, and intermittent network connectivity
that results in a significant probability of dropping out during the
protocol execution, a common problem in production systems [7].
While there have been both theoretical and applied works proposing secure computation solutions for settings with restricted communication [10, 14, 22, 26, 30, 33], Bonawitz et al. [8] introduced
the first practical secure computation construction whose implementation scaled to a thousand clients, a larger number of parties
than any existing system. That work presents a secure aggregation
protocol that enables a central server to learn the summation of
the input vectors of many clients securely, i.e. without obtaining
any information beyond the sum. The protocol is also robust in
the presence of a fraction of clients dropping out. That paper and
subsequent work [7] showed that secure vector summation enables powerful privacy-preserving functionalities such as federated
learning [25].
In this work we focus on two aspects of secure vector aggregation. First, we construct two new protocols with semi-honest and
malicious security, which provide better efficiency both in terms of
asymptotics as well as concrete costs. Second, we present a new application of secure aggregation for construction of secure shuffling
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1253
protocols. This enables anonymous data collection in the singleserver setting, and in particular provides the first cryptographically
secure instantiation of the shuffle model of differential privacy [6].
Efficiency of Secure Aggregation. While the existing secure aggregation construction of Bonawitz et al. [8] is sufficiently efficient
to run in production systems [7], scaling concerns limit its scope of
use. Its limitations stem from the computation and communication
complexity of the protocol. For adding n length l vectors (one provided by each client) their protocol requires O(n
2 +ln) computation
and O(n + l) communication per device, and O(ln2
) computation
and O(n
2 +ln) communication for the server. This introduces linear
overhead over the computation in the clear where every client sends
a vector and the server adds up all n vectors. Although recently a
variant with polylog overhead has been proposed [34], it requires
n/logn rounds (as opposed to four for Bonawitz et al.) and, contrary
to Bonawitz et al.’s approach, relies on revealing a partial sum of
logn input values to a coalition of the server and a client.
Reducing client compute time is significant: the more compute
time is required at each device, the more likely that device is to drop
out. This not only results in wasted computation, but also induces
bias as powerful devices with fast connection will be overrepresented in the collected statistics. In practice, these costs limit the
use of secure aggregation to settings of no more than approximately
a thousand devices for large values of l, e.g., larger than 106
. This
prevents computing large histograms or training neural networks
that require large client batches to achieve good quality [31].
Looking beyond concrete efficiency, current theoretical constructions do not provide constant round solutions with sublinear communication (in the number of clients) per client. This is the case
even in the semi-honest setting when we need to account for the
key distribution phase as well as support dropouts [33]. Note that
there exist relevant solutions based on homomorphic encryption
(HE) [17, 18, 32], where the server computes the sum of encrypted
inputs under a key shared among the clients. However, the generation of shared HE parameters among all parties with sublinear
communication and in a way that is robust to dropouts remains a
challenge. Boyle et al. [9] present efficient large-scale secure computation but do use a broadcast channel per party.
Amplification by Shuffling. Differential privacy (DP) [13] has
become the de facto notion of individual privacy in data analysis.
Until recently there have been two main threat models for DP: the
central model, where a curator is trusted with all private inputs
and the task of outputting privatized aggregates, and the local DP
setting where individuals release DP versions of their data. While
the second model has minimal trust assumptions it also comes with
significant limitations in terms of accuracy.
The recently introduced shuffle model of DP [6, 11] assumes
only a trusted shuffler (a party that applies a random permutation
to input data before publishing it) rather than a trusted curator
computing arbitrary functionalities. The shuffle model matches
exactly the setting of a single powerful server and a large number
of devices in a star network. Several recent works [2, 3, 15, 16, 19]
have shown that this model offers a fruitful middle ground (in the
terms of tradeoffs between trust distribution and accuracy) between
the local and curator models. Implementing efficient shufflers in
practice has either required reliance on trusted computing hardware
or onion-routing/mixnet constructions, which require strong noncollusion assumptions and significantly increased communication.
While we can implement the shuffling step with general multiparty
computation to achieve local DP privacy, any practical deployment
would require an efficient shuffling construction.
1.1 Our contributions
Our paper has three main contributions: two new constructions for
secure aggregation which provide security in the semi-honest and
semi-malicious setting, and a new construction for secure shuffling
based on secure aggregation.
For our constructions we consider an aggregation server and n
clients with input vectors of length l. The goal of the protocol is
to provide the server with a summation of the inputs of all clients
that complete the protocol execution. We require that correctness
holds with all but 2
−η probability, where η > 0 is the correctness
parameter. The protocols are secure in the presence of an adversary controlling the server and up to an arbitrary γ -fraction of the
clients that are corrupted independently of the protocol execution.
In other words, client corruptions happen before the protocol execution starts. Note that the only assumption is that the adversary
does not have the ability to compromise new devices adaptively as
the protocol progresses. Our protocols are robust to an arbitrary
δ-fraction of clients dropping out during the protocol execution.
Moreover, a number of dropouts that exceeds that threshold can
only lead to an aborted execution, and does not affect the security
of the protocol. Let us remark that the set of clients that dropout
during the protocol execution are considered public knowledge,
i.e. we do not aim to provide full anonymity to the set of dropout
users. Our constructions achieve information theoretic security
with a security parameter σ, except for the use of a key agreement
protocol for randomness generation, and encryption and signature
for secure communication.
Semi-honest Construction. The construction of Bonawitz et al. [8]
uses the server as a relay that forwards encrypted and authenticated messages between clients. Their solution requires that every
pair of clients are able to communicate. Intuitively, the complete
communication graph serves both security and dropout robustness.
Roughly speaking, every client (a) negotiates shared randomness
with every other client to mask their submitted value, and (b) shares
(with threshold t) their random seeds with every other client. While
(a) ensures security, (b) guarantees that the protocol can recover
from dropouts without compromising security as long as t is set
appropriately.
The main insight to our efficiency improvement is that a complete graph is not necessary: it is enough to consider a k-regular
communication graph, i.e., each client speaks to k < n − 1 other
clients, where k = O(logn). We obtain this result by using a randomized communication graph construction, and then leveraging
its properties with respect to the distributions of corrupt clients
and dropouts.
Our semi-honest construction requiresO(log2 n+l logn) computation and O(logn + l) communication per client, and O(n log2 n +
nl logn) computation and O(n logn + nl) communication for the
server. It requires three rounds of interactions between the server
and clients. We characterize the properties of the communication
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1254
graph that suffice for the security and correctness of the resulting
protocol, and present a graph generation construction with concrete parameters. For example, with σ = 40 and η = 30, we need
only k = 150 neighbors per client in order to run the protocol with
n = 108
clients and provide security for up to γ = 1/5 corrupt nodes
and δ = 1/20 dropouts. In fact, we can run our protocol with a
billion clients, while incurring roughly the same costs per client as
the protocol of Bonawitz et al. [8] when run on a thousand clients
(see Section 5 for more details).
Semi-malicious Construction. Our semi-malicious setting assumes
that the server behaves honestly in the first step of the protocol
when it commits to the public keys of all clients. After this point, it
can deviate arbitrarily from the protocol (as in the usual malicious
security notion) and our construction provides security. This is
analogous to the assumption in [8], and weaker than assuming a
public key infrastructure for key distribution.
The security definition for the malicious case is a bit more involved, and is discussed in detail in Section 4. Roughly speaking,
this is due to the fact that a malicious server can disrupt communication between parties at any round, and thus can simulate dropouts
inconsistently across clients. As it is impossible for clients to distinguish real from simulated dropouts, a malicious server cannot
be prevented from excluding (γ + δ) clients from the final sum by
definition of the summation functionality itself. Instead of requiring
that a malicious server cannot learn the sum of the inputs of less
than (1 −γ − δ)n clients, as in the semi-honest case, we formalize
and prove that our protocol ensures that the server can only learn
sums including at least a constant fraction α of the clients’ inputs.
In other words, every honest client is guaranteed that their input
will be added with at least α(1−γ )n other inputs from honest clients
even when the malicious server is controlling γn other clients.
Bonawitz et al. [8] also propose a semi-malicious version of
their protocol. The main idea there is to add their semi-honest
variant a round in which clients verify that the server reported
consistent views of dropouts to all of them. This extension incurs
additional linear communication and computation. Extending our
semi-honest protocol while maintaining sublinear overhead is more
challenging. First, the server cannot be trusted to generate the communication graph honestly, and thus we propose a protocol where
clients choose their k = O(logn) neighbors in a distributed verifiable way. Second, we find an alternative approach to ensuring
global consistency of reported dropouts by having each client perform only a local verification on their neighborhood. We then prove
that this corresponds to a global property of the communication
graph thanks to the connectivity properties of random graphs.
Our semi-malicious construction requiresO(log2 n+l logn) computation andO(log2 n+l) communication per client, andO(l log2 n)
computation and O(log2 n + ln) communication for the server. It
runs in five and a half rounds of interactions. Our protocol also
achieves very efficient concrete costs. For example, with σ = 40
and η = 30, if we run the protocol with 104
clients and corrupt
and dropout rates γ = δ = 0.05 we need only 300 neighbors to
guarantee that every client’s input is aggregated with the inputs of
at least 5000 clients (see Section 5 for more details).
Secure Shuffle Construction. We provide an instantiation of the
shuffle model of differential privacy by showing a reduction of
shuffling to vector summation. Our solution leverages a randomized
data structure called an invertible Bloom lookup table (IBLT) [21].
To shuffle m messages distributed among n clients, it suffices to
run a single execution of secure vector summation with vectors of
length ∼ 2m. This covers the case where each user has multiple
messages to send, as in the multi-message shuffle model [4, 11, 19],
as well as the case where most users do not have any input, which
models submissions of error reports.
2 PRELIMINARIES AND NOTATION
Hypergeometric distribution. We recall that the Hypergeometric
distribution HyperGeom(n,m, k) is a discrete probability distribution
that describes the probability of s successes in k draws, without
replacement, from a finite population of size n that contains exactly
m objects with that feature. We use the following two tail bounds for
X ∼ HyperGeom(n,m, k): (i) ∀d > 0 : Pr[X ≤ (m/n −d)k] ≤ e
−2d
2k
,
and (ii) ∀d > 0 : Pr[X ≥ (m/n + d)k] ≤ e
−2d
2k
. Moreover, by
choosing d = 1 − m/n, we get that Pr[X ≥ k] = Pr[X ≤ k] ≤
e
−2(1−m/n)
2k
Graphs. We denote a graph with a vertex set V and edge set E as
G(V, E), where (i, j) ∈ E if there is an edge between vertices i and
j. The set of all nodes connected to the i-th node is its neighbors
NG(i) = {j ∈ V : (i, j) ∈ E}. A graph G
′
(V
′
, E
′
) is a subgraph
of G(V, E) if V
′ ⊆ V and E
′ ⊆ E. The subgraph of G induced by
a subset of the vertices V
′ ⊂ V and the edges between E
′ where
(i, j) ∈ E
′
if and only if (i, j) ∈ E) and i, j ∈ V
′
is denoted G[V
′
].
Parameters. We provide in Table 1, Appendix A, the parameters we will use throughout the paper. In particular, σ will denote
an information-theoretic security parameter bounding the probability of bad events happening and η will denote the correctness
parameter. We denote by λ a security parameter associated with
standard cryptographic primitives (such as Shamir secret sharing,
pseudorandom generator, and authenticated encryption).
We says that two distributions D, D′
are computationally indistinguishable with respect to σ and λ, denoted D ≈σ,λ D′
, if the
statistical distance between D and D′
is bounded by the sum of a
negligible function in λ and of a negligible function in σ.
Throughout the paper, we denote X = Z/RZ the domain on
which the summation protocol is performed, and we assume the
representation of elements of X (resp. computational cost of operations in X) is O˜(1) in n (resp. log(n)) so as to enable additions of n
elements in X without overflow.
Cryptographic primitives. In our protocols, we will use the following cryptographic primitives for randomness generation and secure
communication. A signature scheme scheme that is existentially unforgeable under chosen message attacks (EUF-CMA); for example,
it can be instantiated with ECDSA in practice. A cryptographically
secure pseudorandom generator F : {0, 1}
λ → X
l
; for example, it
can be instantiated with AES-CTR in practice [7, 8]. An authenticated encryption scheme with associated data (AEAD), which is
semantically secure under a chosen plaintext attack (IND-CPA) and
provides integrity of ciphertext (INT-CTXT), which means that it is
computationally infeasible to produce a ciphertext not previously
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1255
produced by the sender regardless of whether or not the underlying plaintext is “new”; for example, it can be instantiated with
ChaCha20+Poly1305 [24] in practice. A λ-secure key-agreement
protocol, i.e., a key-agreement protocol such that there exists a
simulator SimK A, which takes as input an output key sampled
uniformly at random and the public key of the other party, and
simulates the messages of the key agreement execution so that the
statistical distance is negligible in λ; for example, it can be instantiated with a Diffie–Hellman key agreement protocol followed by a
key derivation function in practice.
3 THE SEMI-HONEST PROTOCOL
In this section, we present our semi-honest summation protocol.
Our construction is parametrized by a (possibly random) undirected
regular graph G with n nodes and degree k. Intuitively the graph G
will determine the direct communication channels that will be used
in the protocol in the following sense: clients that are connected
in G will exchange private messages in the protocol via the server
which, however, will not be able to see the message content. We will
prove the correctness and the security of our protocol assuming a
set of properties of the graph G. Next we will describe a randomized algorithm called GenerateGraph, which generates graphs
for which these properties hold with high probability. Since we
are in the semi-honest setting this algorithm can be generated by
the server (in the malicious setting protocol of Section 4, we will
describe a distributed graph generation protocol).
3.1 An abstract summation protocol
We present our protocol in Algorithm 2 which can be found in
the appendix. It runs among n clients with identifiers 1, . . . ,n and
the server. All parties have access to the following primitives: a
pseudorandom generator (PRG) F , which is used to expand short
random keys, a secure key agreement protocol KA to create shared
random keys, and an authenticated encryption scheme for private
communication Eauth.
Construction Overview. The main idea of our construction is a
generalization of the secure aggregation protocol of Bonawitz et
al. [8], which only works with complete graphs (i.e., all the vertices
are connected between each other), that works with any graph sampled from a larger set of sparser graphs. Our construction enables
significant efficiency improvements.
As we discussed above, the first step of the protocol will be to
generate a k-regular graph G and a threshold 1 ≤ t ≤ k, where
the n vertices are the clients participating to the protocol. To do
this the server runs a randomized graph generation algoritmhm
GenerateGraph that takes the number n of clients/nodes and samples output (G,t) from a distribution D. Below, we will define which
properties of this distribution suffice for the proofs of correctness
and security.
The edges of the graph determine pairs of clients each of which
run a key agreement protocol to share a random key, which later will
be used by each party to derive a mask for her input. More precisely,
each client i generates key pairs (sk1
i
,pk1
i
), (sk2
i
,pk2
i
) and sends
(pk1
i
,pk2
i
) to all of her neighbors. Then, each pair (i, j) of connected
parties G runs a key agreement protocolsi,j = KA.Aдree(sk1
i
,pk1
j
),
which uses the keys exchange in the previous step to derive a shared
random key si,j
.
Each client i derives pairwise masks for her input mi,j = F (si,j)
derived from shared keys with each of her neighbors j ∈ NG(i),
which she adds to her input as follows
x®i −
Õ
j ∈NG(i),j<i
m®i,j +
Õ
j ∈NG(i),j>i
m®i,j
.
In the setting where all parties submit their masked inputs, all
pairwise masks cancel in the final sum. However, to support execution when dropouts occur, the protocol needs to enable removal of
the pairwise masks of dropout clients (who never submitted their
masked inputs). For this purpose, each client i shares her key sk1
i
to her neighbors j’s by sending a ciphertext containing the share
produced using the public keys pk2
j
’s. Later, if client i drops out,
her neighbors can send the decrypted shares to the server. Armed
with those shares, the server can reconstruct the secret key sk1
i
and
use it together with the public keys of i’s neighbors to compute si,j
.
Finally, the server can recover the corresponding pairwise masks
m®i,j and remove them from the final output sum.
The above approach has a shortcoming that if the server announces dropouts and later some masked inputs of the claimed
dropouts arrive, the server will be able to recover those inputs in
the clear. To prevent this possibility the protocol introduced another level of masks, called self masks, that each client generates
locally r®i = F (bi) from a randomly sampled seed bi
. This mask is
also added to the input
x®i + r®i −
Õ
j ∈NG(i),j<i
m®i,j +
Õ
j ∈NG(i),j>i
m®i,j
.
Now, client i also shares bi to her neighbors. Later, if i submitted
her masked input, the server will instead request shares of bi from
the client’s neighbors in order to reconstruct and remove r®i from
the sum. In other words, either client i has submitted her masked
input and the server will obtain shares from the mask bi
, or client i
has dropped out and the server will obtain shares of sk1
i
. Crucially,
we require each client to provide to the server only one share for
each if her neighbors. This guarantees that the masked inputs of
clients that are not included in the final sum cannot be revealed in
the clear to the server.
Dropouts may happen throughout the steps of the protocol. We
denote by A1 the set of parties that send their secret shares to their
neighbors, A2 ⊆ A1 is the set of parties that send their masked
inputs with their self mask and the pairwise masks generated from
the shared keys with her neighbors in A1, A3 ⊆ A2 is the set of
clients that send shares to the server to be used in the reconstruction
of the output. At each of these steps the server will only wait a
set time for these messages, A
′
i
denotes the subset of Ai whose
messages arrive on time. If the complements of these prime sets
becomes larger than the threshold δn for dropouts, the server aborts.
Also if a client has less than t neighbors in A
′
3
, the server aborts
since it cannot reconstruct at least one mask needed to obtain the
output.
The construction of Bonawitz et al. [8] uses a complete graph
where each client shares a mask with every other client in the
system. While a single random mask hides perfectly a private value,
the intuition of why we need more masks is the presence of corrupt
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1256
clients, who will share their masks with the server, and of dropouts
whose masks will be removed. However, we will show that n − 1
masks per input may be more than what is needed for security. In
particular, the insight in our construction is that the number of such
masks can be significantly reduced toO(logn), in a setting where we
can assume that the pairs of parties sharing common randomness
used to derive masks are chosen at random and independent of
the set of corrupted parties and the set of dropouts. In particular
we model this by using a random k-regular graph that determines
the node neighbors with whom masks are shared. In our security
proofs, we will argue that, when k = O(logn), for each honest
client there is a sufficient number of honest non-dropout neighbors
to protect the client’s input.
Graph Properties. Let G = (V, E) be a k-regular undirected graph
with n nodes, and let 0 < t < k be an integer. Recall that NG(i) =
{j ∈ V : (i, j) ∈ E} is the set of neighbors of i.
The first property that we require from any graph output by
GenerateGraph is that, for every set of corrupt clients C, with all
but negligible probability, no honest client i has t neighbors in C.
Note that this happening would immediately break security, as the
adversary would be able to recover the secrets of i by combining
shares from i’s corrupted neighbors. Formally, we define the event
E1 as a predicate on a set C and a pair (G,t) that is 1 iff the “good”
property holds.1
Definition 3.1 (Not too many corrupt neighbors). Let C ⊂ [n] be
such that |C| ≤ γn. We define event E1 as
E1(C, G,t) = 1 iff ∀i ∈ [n] \ C : |NG(i) ∩ C| < t
Event E1 is not the only event related to the communication
graph G that could break security: consider the situation where
a set of D clients, with |D| ≤ δn, drop out right before sending
their masked input in such a way that removing clients/nodes in D
disconnects the communication graph G, i.e. G[[n] \ D] is not connected. Now, as discussed above, edges in the graph correspond to
shared masksm®i,j that are crucial to ensure security, as these masks
are used to mask values y®i that involve private inputs. However, if
the graph gets disconnected by D, and |D| ≤ δn, then by definition
of the functionality (δ-robustness) the server would be able to recover the masks mi,j
involving clients in D, i.e. the edges in the cut
induced by D. This implies that the server would receive at least
two disjoint sets S1, S2 of masked inputs (one for each connected
component in G[[n] \ D]) whose masks cancel independently of
the other set, resulting in the server learning (at least) two partial
sums, which breaks security. We state our “good” event E2 where
the graph remains connected. Note that although we excluded corrupted nodes in the above description for simplicity, they need to
be taken into account. As before, we define E2 as a predicate on
sets C,D of appropriate size, and a graph G.
Definition 3.2 (Connectivity after dropouts). Let C ⊂ [n] and
D ⊂ [n] be such that |C| ≤ γn and |D| ≤ δn. We define event E2 as
E2(C,D, G) = 1 iff G[[n] \ (C ∪ D)] is connected
1Note that for a complete graph, the event E1 is 1 for every set C trivially, as long as
t > |C |, where |C | ≤ γ n. However this implies that k ≥ t = O(n), and results in
linear overhead.
Note that the above event trivially holds for a complete graph G
(and reasonable parameters γ and δ) and any sets C,D, as in that
case k = n − 1 > (γ + δ)n.
Perhaps surprisingly, we will prove that events E1 and E2 capture all possible ways in which security could be broken (assuming
perfect cryptographic primitives) due to the choice of communication network. More concretely, we will show the following: Consider a graph generation algorithm GenerateGraph such that for
any sets C,D of appropriate sizes, a pair (G,t) generated using
GenerateGraph will satisfy E1(C, G,t) ∧ E2(C,D, G) = 1 except
for negligible probability. Then, GenerateGraph can be used in
Algorithm 2, and the result will be a secure protocol.
Finally, we still need one more property that GenerateGraph
must satisfy to ensure correctness. Note that if after removing
dropouts some client does not have at least t neighbors then the
server can’t recover the final sum.
Definition 3.3 (Enough surviving neighbors for reconstruction). Let
D ⊂ [n] such that |D| ≤ δn. We define event E3 as
E3(D, G,t) = 1 iff ∀i ∈ [n] : |NG(i) ∩ ([n] \ D)| ≥ t
3.2 Generating “Good” Graphs
This section characterizes “good” graph generation algorithms as
those that generate graphs for which events E1, E2, E3 hold with
probability parameterized by a statistical security parameter σ (for
E1 and E2) and a correctness parameter η (for E3).
Definition 3.4. Let D be a distribution over pairs (G,t). We say
that D is (σ, η)-good if, for all sets C ⊂ [n] and D ⊂ [n] such that
|C| ≤ γn and |D| ≤ δn, we have that
(1) Pr[E1(C, G
′
,t
′
) ∧ E2(C,D, G
′
,t
′
) = 1 | (G
′
,t
′
) ← D] >
1 − 2
−σ
(2) Pr[E3(D, G
′
,t
′
) = 1 | (G
′
,t
′
) ← D] > 1 − 2
−η
Analogously, we say that a graph generation algorithm is (σ, η)-
good if it implements a (σ, η)-good distribution.
In Section 3.5, we describe a concrete (randomized) (σ, η)-good
graph generation algorithm.
3.3 Correctness and Security
In this section, we state our correctness and security theorems,
whose proofs are provided in Appendix B of our full paper [5]. We
note that the proof of security uses a standard simulation-based
approach [20, 28] similar to the one by Bonawitz et al. [8]. It is
important to remark that this formulation does not in general imply
security, in the formal sense of [20, 28], in the weaker threat model
where the adversary only corrupts a set of clients and the server is
honest. This is however easy to see for our protocol: note that the
messages sent to the clients are all functions of the other clients’
randomness alone, and in particular do not depend at all on any
inputs. We discuss further the honest server case in the context of
the semi-malicious threat model in Section 4.6.
Theorem 3.5 (Correctness). Let Π be Algorithm 2 instantiated
with a (σ, η)-good graph generation algorithm GenerateGraph. Consider an execution of Π with inputs X = ( ®xi)i ∈[n]
. If |A
′
3
| ≥ (1 − δ)n,
i.e., less than a fraction δ of the clients dropout, then the server does
not abort and obtains z® =
Í
A
′
2
x®i with probability 1 − 2
−η
.
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1257
Theorem 3.6 (Security). Let σ, η, λ be integer parameters. Let
Π be an instantiation of Algorithm 2 with a (σ, η)-good graph generation algorithm GenerateGraph, a IND-CPA secure authenticated
encryption scheme, and a λ-secure key agreement protocol. There exists a PPT simulator Sim such that for all k, all sets of surviving clients
A1,A2,A
′
2
,A3 as defined in Algorithm 2, all inputs X = ( ®xi)i ∈[n]
,
and all sets of corrupted clients C with |C| ≤ γn, denote z® =
Í
i ∈A
′
2
x®i
,
the output of Sim is perfectly indistinguishable from the joint view
of the server and the corrupted clients RealC(A1,A2,A
′
2
,A3) in that
execution, i.e., RealC(A1,A2,A
′
2
,A3) ≈σ,λ Sim(®z, C,A1,A2,A
′
2
,A3).
3.4 Performance Analysis
We report the communication and computation costs for the client
and server when k = O(logn). We recall that we assume that basic
operations and representation of elements in X are O(1).
Client computation: O(log2 n + l logn). Each client computation
can be broken up as 2k key agreements and k encryptions (O(k)
complexity), creating twice t-out-of-k Shamir secret shares (O(k
2
)
complexity), generating m®i,j for all neighbors j (O(kl) complexity).
Client communication: O(logn + l). Each client performs 2k key
agreements (O(k) messages), sends 2k encrypted shares (O(k) messages), sends a masked input (O(l) complexity), reveals up to 2k
shares (O(k) messages).
Server computation: O(n(log2 n + l logn)). The server computation can be broken up as reconstructing t-out-of-k Shamir secrets
for each client (O(n · k
2
) complexity), generating values m®i,j for all
(dropped out) neighbors j of each client i (O(nkl) complexity).
Server communication: O(n(logn + l)). The server receives or
sends O(logn + l) to each client.
3.5 Our Random Graph Constructions
Since Bonawitz et al. [8] uses a complete graph, all of the events
E1(C, G,t), E2(C,D, G) and E3(D, G,t) are deterministically equal
to 1. That is to say that the complete graph is (σ, η)-good for any
σ and η. In this section we will describe how to construct a much
sparser random graph, which is still (σ, η)-good for reasonable σ
and η.
Our randomized construction is shown is Algorithm 1, and consists of uniformly renaming the nodes of a graph known as a Harary
graph with n nodes and degree k. This graph, which we denote
Harary(n, k), has vertices V = [n] and an edge between two distinct vertices i and j if and only if j − i modulo n is ≤ (k + 1)/2
or ≥ n − k/2. Roughly speaking, you can think of this as writing
the nodes of the graph in a circle and putting edges between those
within distance k/2 of each other.
Our whole problem now reduces to defining exactly the function
ComputeDegreeAndThreshold such that the values of k and
t it returns result in GenerateGraph being (σ, η)-good. This in
turn leads to a secure protocol, as we saw in the previous section.
More concretely, we will see in this section that choosing k ≥
O(logn + σ + η) is enough to achieve the (σ, η)-goodness property.
Consider any graph generation algorithm G constructed by sampling k neighbors uniformly and without replacement from the set
Algorithm 1: GenerateGraph
Public Parameters: Max. fraction of corrupt nodes γ , max.
fraction of dropout nodes δ .
Input: Number of nodes n, statistical security parameter σ ,
correctness parameter η.
Output: A triple (G, t, k)
(k, t) = ComputeDegreeAndThreshold(n, γ, δ, σ, η)
Let H = Harary(n, k)
Sample a random permutation π : [n] 7→ [n]
Let G be the set of edges {(π (i), π (j)) | (i, j) ∈ H }
return (G, t, k)
of remaining n − 1 clients (as done in Algorithm 1). This general
property is all we need to argue about events E1, E3 in the definitions of (σ, η)-good, so we don’t need to get into the specifics of
Harary graphs yet.
E1: Not too many corrupt neighbors. Let us first focus on the
event E1(C, G,t), which holds if every client i has fewer than t
corrupt neighbors in NG(i) (Definition 3.1). Let Xi be the random
variable counting the number of malicious neighbors of a useri, and
note that Xi ∼ HyperGeom(n −1,γn, k), i.e. Xi
is hypergeometrically
distributed. Thus by a union bound across all clients we have that
Pr[E1(C, G,t) = 0] ≤ nPr[Xi ≥ t] = n(1 − cdfXi
(t − 1)).
E3: Not too many neighbors drop out. Let us now turn our attention towards correctness: if we set t too large then the server will
fail to recover enough shares of a required mask and abort, and that
would result in a wasted computation. The intuition behind this
event for G is analogous to the case of E1, as if Yi
is the number
of surviving (not dropped out) neighbors of the ith user we have
that Yi ∼ HyperGeom(n − 1, (1 − δ)n, k), thanks again to the fact
that G is such that the k neighbors of i are randomly sampled from
[n] \ {i}. Hence, again by a union bound across clients, we have
that Pr[E3(C, G,t) = 0] ≤ nPr[Yi ≤ t] = n(cdfYi
(t)).
Hypergeometrics (like Binomials) are concentrated around their
mean and have sub-gaussian tails. This means that Pr[Xi ≥ t]
decreases exponentially fast ast gets away from E[Xi
] = γn/(n −1);
thus it is possible to make both of the above probabilities very small.
The Security/Correctness tradeoff. To gain additional intuition,
let us now discuss the interaction between E1 and E3, as they correspond to the tension between correctness and security in out
protocol: For a fixed k, one should be setting t ∈ (0, k) according to Xi
for security, while simultaneously satisfying correctness
with respect to Yi
. Large t achieves results in better security (because the probability of E1 not holding decreases, while smaller
t helps correctness by reducing the failure probability associated
to E3). Figure 1 visually illustrates the situation by showing the
probability mass function of both Xi and Yi
for n = 104
, k = 200,
γ = 1/5, δ = 1/10, and a choice of threshold t = 100 that gives
Pr[Xi ≥ t] < 2
−40 and Pr[Yi < t] < 2
−30. Note that as the probability mass function of hypergeometric distributions has a closed form
we can numerically compute these values accurately. We exploit
this fact to get tighter bounds than the analytical ones in Section 5.
E2: Connectivity after dropouts. Up to this point, we only used the
fact that the neighbors of i in G are random subsamples of [n] \ {i}.
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1258
Figure 1: Probability mass functions of Xi ∼ HyperGeom(n −
1,γn, k) and Yi ∼ HyperGeom(n − 1, (1 − δ)n, k).
To argue about E2 we will leverage the connectivity properties of
Harary graphs. Consider a graph H = Harary(n, k) and assume that
k is even w.l.o.g. Recall that these graphs can be easily constructed
by putting nodes 1, . . . ,n in a circle and connecting each node to
the k/2 nodes to its left and the k/2 nodes to its right (around the
circle). The property that we will use in our argument is that to
disconnect H one needs to remove at least k/2 successive nodes.
To see this consider any way of removing nodes, assume without
loss of generality that node 1 is not removed and assume that some
node is not connected to 1 (and has not been removed). Let m be
such a node of smallest index. Consider nodes m − k/2, . . . ,m − 1.
None of these can be 1 otherwise m would be directly connected
to 1. Furthermore none of them can be connected to 1 and present
as otherwise m would be connected to 1 via them, but as m was
minimal none of them can be disconnected from 1 and present.
Therefore they must all be missing, as required.
This property implies that, as G from Algorithm 1, is simply H
but with nodes randomly renamed, we have that Pr[E2(C,D, G
′
) =
0] ≤ n(γ + δ)
k/2
, by a union bound across clients and the fact that
(γ +δ)
k/2
is an upper bound on the probability that k/2 “successive”
nodes following a particular node in G are in C ∪ D (recall that
|C| ≤ γn and D ≤ δn).
The following lemma captures the three points we have made
so far. Let us remark that it does not tell us immediately how large
k should be. Instead, it states sufficient (efficiently checkable) conditions that would imply that a given k was secure given the rest
of the parameters, and thus it will become central in Section 5.
Lemma 3.7. Let n > 0 be a set of clients, let σ, η be security and
correctness let γ , δ ∈ [0, 1] be the maximum fraction of corrupt and
dropout clients, respectively, and let k,t be natural numbers such that
t ∈ (0, k). Let
Xi ∼ HyperGeom(n − 1,γn, k), Yi ∼ HyperGeom(n − 1, (1 − δ)n, k)
be random variables. If the following two constraints hold then the
distribution D over pairs (G,t) implemented by Algorithm 1 is (σ, η)-
good:
(1) 1 − cdfXi
(t − 1) + (δ +γ )
k/2 < 2
−σ
/n
(2) cdfYi
(t) < 2
−η
/n
Equipped with the above observation, in the rest of this section
we show that in fact k ≥ O(logn+σ +η) suffices, while giving some
evidence that the hidden constant is in fact small (that point will be
addressed fully in Section 5). The following lemmas and theorem
follow from the tail bounds on the hypergeometric distribution
stated in the preliminaries section. Their detailed proofs can be
found in Appendix A of our full paper [5].
Lemma 3.8. Let G be such that, for all i ∈ [n], G(i) is a uniform
sample of size k from [n] \ {i}. Let C ⊂ [n] be such that |C| ≤ γn,
and t = βk. If k ≥ c(σ1 log 2 + logn) and c >
1
2(β−
nγ
n−1
)
2
then
Pr[E1(C, G,t) = 0] ≤ 2
−σ1
.
Let us now turn our attention towards correctness. Maybe not
surprisingly at this point, it turns out that k > O(η + logn), with a
small constant depending on the dropout rate δ is enough to ensure
a failure probability bounded by 2
−η
, as we show in the next lemma.
Lemma 3.9. Let G be such that, for all i ∈ [n], G(i) is a uniform
sample of size k from [n] \ {i}. Let D ⊂ [n] such that |D| ≤ δn
and let t = βk. If k ≥ c(η log 2 + logn) and c >
1
2

n(1−δ )
n−1
−β
2
then
Pr[E3(D, G,t) = 0] ≤ 2
−η
.
It is important to remark that our previous two lemmas did not
rely entirely on our Harary graph construction. In fact any algorithm that results in Xi and Yi being concentrated would work.
These include Erdős-Rényi graphs, as well as a distributed construction where every client samples k neighbors at random (as
done in the malicious version of our protocol presented in the next
section). However, as discussed above to address our remaining
property E2(C,D, G) we will heavily leverage the Harary graph
based construction, as it results in an efficient and simple solution.
This is done in the proof of the following theorem that ties this
section together.
Theorem 3.10. Let γ , δ ∈ [0, 1] be such that γ n
n−1
+ δ < 1.
The distribution D over pairs (G,t) implemented by Algorithm 1 is
(σ, η)-good, as long as β = t/k satisfies γ n
n−1
< β < (1 − δ), and
k ≥ max
©
­
­
«
((σ + 1) log 2 + logn)
c
+ 1,
η log 2 + logn
2

n(1−δ )
n−1
− β
2
ª
®
®
¬
with c = min
2(β − 2γ )
2
, − log(γ + δ)

.
As an example consider the situation in which γ = δ = 1/5 and
take β = 1/2 then we get security and correctness with n = 106
,
σ = 40 and η = 30, so long as k ≥ 385. Whilst this already saves a
factor of 2500 over the complete graph, even lower requirements
are shown to suffice in Section 5.
4 THE MALICIOUS PROTOCOL
In this section we show how to extend the ideas behind our semihonest protocol to withstand an adversary that controls the server
and a fraction γ of the n clients, as before, but where the adversary
can deviate from the protocol execution. This includes, for example,
sending incorrect messages, dropping out, or ignoring certain messages. Crucially, our protocol retains the computational benefits
of the semi-honest variant: sublinear (polylog) client computation
and communication in n.
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 125 
Powerful adversary. To illustrate the power of such an adversary,
let us describe a simple attack on the protocol of the previous section
that can be run by a malicious server, by simply giving inconsistent
views of which users dropped out to different clients. The goal of
the server in this attack is to recover the private vector x®u from a
target client u. Let N = NG(u) be the set of neighbors chosen by
u in an execution without drop-outs. After collecting all masked
inputs, the server tells all clients in N = [n] \ N that the immediate
neighbors of u, i.e., every client in N, have dropped out. In other
words, the server requests shares that are sufficient to recompute
the pairwise masks of everyone in N. Note that these masks include
values that cancel with all of u’s pairwise masks. Hence, to obtain
u’s private vector, the server can announce to clients in N that u
did not drop out to also recover u’s self mask. Note that the server’s
malicious behavior here is only in notifying everyone in N that
clients in N have dropped out, while simultaneously requesting
shares of u’s self mask from all clients in N. For this reason, this
attack succeeds against any variant of the abstract protocol from
the previous section, regardless of the choice of graph G.
What can the server legitimely learn in a robust protocol? While
clearly the above attack is a problem as the server can learn a single
client’s data, formalizing what constitutes an attack against a protocol that aims at being robust against dropouts has some subtleties.
Note that a malicious server can always wait for an execution where
there are no dropouts, and simulate them by ignoring certain messages. Concretely, if a protocol is robust against a fraction δ of the
clients dropping out, and the adversary controls a fraction γ of the
clients, we cannot hope to prevent the server from learning the
sum of any subset H of honest clients of their choice, as long as
|H| ≥ (1 − δ −γ )n.
Bonawitz et al. [8] show how to modify their protocol so that it
is secure in the presence of such a server by adding a “consistency
check” round at the end of the protocol. This additional round
prevents the server from learning the sum of any subset H of size
|H| ≤ α · n, by ensuring that at least α · n clients, with α = Ω(1),
are given a consistent view of who dropped out. Unfortunately, this
consistency check requires to transmit such a set of size α ·n to each
client, yielding a communication overhead linear in n. Achieving
the analogous goal (ensuring that α is a constant fraction of the
secret sharing degree) in our O(logn)-degree regular graphs from
Section 3 would give α = O(logn/n), which is unsatisfactory from
a security standpoint: the number of values among which an honest
client’s value is hidden is too small, e.g., about 9 for n = 104
. Thus,
we require completely new ideas to make α independent of n.
We show that α can in fact be made a constant fraction independent of n while retaining polylog communication in n. More
concretely, we show that the server cannot learn the sum of any
subset H of honest clients such that |H| < αn for α = Ω(1).
4.1 Security Definition
Intuitively, we want to define a summation protocol as being αsecure, for α ∈ [0, 1], if honest clients are guaranteed that their
private value will be aggregated at most once with at least αn other
values from honest clients. Formalizing this requires care. We will
use a simulation-based proof, where we show that any attacker’s
view of the execution can be simulated in a setting where the attacker (which controls the server and a fraction of the clients) does
not interact with the honest clients but a simulator that does not
have the honest parties’ inputs. Instead, we assume that the simulator can query once an oracle computing an “ideal” functionality
that captures the leakage that we are willing to tolerate. We denote
the functionality by FX,α as it is parameterized by the set X of
the honest parties’ inputs and α ∈ [0, 1]. It takes as input a partition of the honest clients (a collection of pairwise disjoint subsets
{N1, ..., Nk+1
}) and, for each subset Ni
it either returns Í
i ∈Ni
x®i
if
the subset is “large enough”, namely |Ni
| ≥ α · |X|, or answers ⊥.
Definition 4.1 (α-Summation Ideal Functionality). Let n, R, ℓ be
integers, and α ∈ [0, 1]. Let H ⊆ [n] and XH = { ®xi }i ∈H where
x®i ∈ Z
ℓ
R
. Let PH be the set of partitions of H.
The α-summation ideal functionality over XH , denoted by FXH ,α ,
is defined for all partition {H1, . . . ,Hκ } ∈ PH as
Fx®,α
({H1, . . . ,Hκ }) = {S1, . . . , Sκ } ,
where
∀k ∈ [1,κ], Sk =
 Í
i ∈Hk
x®i
if |Hk
| ≥ α · |H|,
⊥ otherwise.
Note that the above definition’s only goal is to characterize an
“upper bound” on what an adversary controlling the server could
learn from the protocol, and is unrelated to correctness guarantees.
Let us remark that the prescribed output for the server, as in the
semi-honest case, is the sum of the inputs x®i of surviving clients.
Along with our security theorem, we provide a correctness result
that states a guarantee for semi-honest executions in Theorem 4.8,
and discuss the security of our protocol in the (weaker) threat model
where the server is honest in Section 4.6.
4.2 The Malicious Protocol
Our precise protocol is Algorithm 3 in the appendix. Here we discuss
the intuition behind it.
Similarly to Bonawitz et al. [8], we need the assumption that,
roughly speaking, the clients participating in the execution are
“real” clients, and not simulated by the server as part of a Sybil
attack. This could be achieved assuming a Public Key Infrastructure
(PKI) external to the clients and server. It also suffices to assume
that the server behaves semi-honestly during the key collection
phase. Thus below we assume: the server behaves semi-honestly
during Part I of the protocol and commits the public keys of all “real”
clients in a Merkle tree. This limits the power of a malicious server
to interrupting the communication between parties in subsequent
rounds, which is equivalent to making it appear to certain parties
that certain other parties have dropped out.
A first hurdle in extending our efficient semi-honest protocol
from Section 3 to the malicious setting, which does not apply to the
protocol of Bonawitz et al., is that we cannot rely on the server to
generate the communication graph G anymore, as it may deviate
from the prescribed way and assign many malicious neighbors to
an honest client. Hence, the first difference will be that in the protocol from this section the graph will be generated in a distributed
way (Part II of Algorithm 3). G = (V, E) with V = [n], will now
be a directed graph, and (i, j) ∈ E will mean that client i chose
to trust client j with shares of its secrets; this relationship will
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1260
not be symmetric. We denote by N•→(i) = {j ∈ V : (i, j) ∈ E}
the outgoing neighbors of i. This graph generation algorithm will
enable to prove that no honest client has too many corrupt neighbors with overwhelming probability. In particular, we define the
following event, and will show in Lemma 4.7 that the event holds
with overwhelming probability for the (random) graph generated
in Part II.
Definition 4.2 (Not too many corrupt neighbors (malicious case)).
Let k,t be integers such that k < n and t ∈ (k/2, k), and let C ⊂ [n]
be such that |C| ≤ γn. We define event E4 as
E4(C, G, k,t) = 1 iff ∀i ∈ [n] \ C : |N•→(i) ∩ C| < 2t − k .
Another hurdle, emphasized by the simple attack described at
the beginning of the section, comes as the adversary can give inconsistent views to each honest client about which clients dropout. The
first issue is that the adversary must never learn both the shares
of the self-mask and the secret key of a user i that submitted its
masked value. However, even if what precedes holds, this does not
mean that we are satisfying our security definition. As discussed
above, we also want to provide a K-anonymity-style guarantee
that a client input revealed to the server has been combined with
K = α · n clients where α = Ω(1). We show that it suffices to have
a logarithmic number of neighbors and a local consistency check.
Our first issue is solved by the bound 2t − k (instead of t) in
Definition 4.2, and by the fact that a neighbor of i reveals at most
one share from i. Indeed, ifmi
is the number of malicious neighbors
of i, the adversary needs to learn 2t − 2mi shares from the k − mi
honest neighbors of i to recover both bi and sk1
i
; when the event
in Definition 4.2 holds, i.e. mi < 2t − k, we know the adversary
cannot learn both secret values of i.
As for the second issue, let us describe a way to fix the simple
attack we described, which as we will see leads to a general solution.
Recall that in the attacks, all clients believe that neighborsc1, . . . ,ck
of u (the target client) have dropped out, while the ci
’s are in fact
alive and report shares from u. Instead, we will make sure each ci
refuses to release any secrets (about u or anybody else) unless the
server can convince them that “enough” of their neighbors know
that they are alive. In particular, the server will have to provide the
ci
’s with p = k −t +1 signed messages (assuming that all clients are
honest) from ci
’s neighbors stating that they have been informed
thatci
is alive, and thus will not release shares ofci
’s secret key. To
extend this idea to the setting with corrupted clients it is enough
to note that if we knew that every honest client has no more than
m corrupted neighbors then setting p = k − (t − m) + 1 would
suffice, as we could conservatively assume that the server already
possessesm shares from each client via the corrupted clients. Finally,
to find a value for m that works with overwhelming probability we
will rely on the fact that the number X of corrupted neighbors is
distributed as HyperGeom(n − 1,γn, k) (as in Section 3), and thus an
m ≈ kγ +
p
k + logn suffices.
Lemma 4.3 (Informal). No honest client i reveals a share and has
more than t shares of their secret key sk1
i
revealed.
The previous modification prevents the secrets of the ci from
being revealed, but does not yet prevent the attack from going
through. Indeed, if the server told u that all its neighbors have
dropped out, u will mask its input vector only with its self-mask,
which can be recovered from the ci
’s by telling them u dropped out.
Henceforth, we will additionally have ci not reveal a secret about u
unless she received a signed message from u that the pairwise mask
between u and ci was included in u’s masked input.
The final challenge therefore consists in proving that the two
countermeasures above prevent the adversary from learning the
sum of the inputs of a “small clique” of clients. Instead, we want
to show that the server needs to aggregate at least α · n clients to
hope to learn anything about their inputs with α = Ω(1). Denote
by S a set of honest clients and assume that every honest client
has no more than m corrupted neighbors; in order to learn the
self-masks of the clients in S, the server needs all of them to have
at least t − m honest clients revealing shares of their self-masks.
However, these honest clients reveal such a share only if they know
the pairwise mask has been included in the sum. Therefore, the
server will also need to include those neighbors in the set S. Now
the server needs that each client in S chooses a fraction ≈ t/k −γ
of their neighbors from S, where γ is the fraction of compromised
clients, and hence we obtain that the server will not learn anything
about a set S unless |S |/n is at least ≈ t/k −γ , which is independent
of n when t is a fraction of k. We define the following event, and
show in Lemma 4.7 that it holds with overwhelming probability for
the random graph generated in Part II.
Definition 4.4 (No small near cliques). Let C ⊂ [n]. We define the
event E5 as E5(C, G,t, α) = 1 iff
∀S ⊂ [n] \ C, |S | < αn, ∃i ∈ S, |N•→(i) ∩ (C ∪ S)| < t .
Finally, for the protocol to be correct in the presence of up to δ ·n
dropouts, we define the following event and will show in Lemma 4.7
that the event holds with overwhelming probability for the graph
generated in Part II.
Definition 4.5 (Enough shares are available). Let D ⊂ [n]. We
define the event E6 as
E6(D, G,t) = 1 iff ∀i ∈ [n] : |N•→(i) ∩ ([n] \ D)| ≥ t .
(In)consistent shares. Note that malicious clients may deliver
inconsistent shares to their neighbors, e.g., in a way that results in
different secrets being reconstructed if different sets of shares are
used for reconstruction. This means that we allow malicious parties
to tailor their inputs to which of their neighbors survive until the
end of the protocol. This is a consequence of the fact that we do
not model the fact that a client dropped out as private information.
One could limit that above ability with a simple modification in
the protocol: when sharing (encrypted) secret shares, the clients
also send hashes of their secrets (in the clear) to the server (note that
the secrets have high entropy, hence this does not leak information
to the server). At the end of the protocol, when reconstructing
either the self-mask seed bi or the pairwise masks keys sk1
i
, the
server checks that the reconstructed secret matches the earlier
hashes, and otherwise aborts. This accomplishes that dishonest
clients cannot change their input based on which of their neighbors
dropout after they send their masked input. This, however, does not
prevent clients from changing their input based on which clients
dropout before that happens. In particular, a client i chosen as a
neighbor by a malicious client j could dropout immediately after
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1261
the protocol begins, and nothing prevents j from changing their
input in that event.
The above observation is also relevant to Bonawitz et al. [8], and
the protocol extension would also apply there.
4.3 Generating “Nice” Graphs
As explained above, we would like to show that Part II of Algorithm 3 generates “nice” graphs, i.e., that the events E4, E5, and
E6 happen with overwhelming probability on graphs generated
according to Part II of Algorithm 3. Below, we define formally what
a nice graph generation algorithm is, and state in Lemma 4.7 that
Part II of Algorithm 3 satisfies the definition. A detailed proof of
Lemma 4.7 can be found in Appendix C of our full paper [5].
Definition 4.6. Let k, σ, η be integers and let α, δ ∈ [0, 1]. Let
C ⊆ [n]. Let D be a distribution over pairs (G,t). We say that D is
(σ, η, C, α)-nice if, for all sets D ⊂ [n] such that |D| ≤ δn, we have
that
(1) Pr[E4(C, G
′
,t
′
) ∧ E5(C, G
′
,t
′
, α) = 1 | (G
′
,t
′
) ← D] >
1 − 2
−σ
(2) Pr[E6(D, G
′
,t
′
) = 1 | (G
′
,t
′
) ← D] > 1 − 2
−η−1
Analogously, we say that a graph generation algorithm is(σ, η, C, α)-
nice if it implements a (σ, η, C, α)-nice distribution.
Lemma 4.7. Let γ ≥ 0 and δ ≥ 0 such that γ + 2δ < 1. Then
there exists a constant c making the following statement true for all
sufficiently large n. Let k be such that
c(1 + logn + η + σ) ≤ k < (n − 1)/4
t = ⌈(3 + γ − 2δ)k/4⌉ and α = (1 − γ − 2δ)/12. Let C ⊂ [n], such
that |C| ≤ γn, be the set of corrupted clients. Then for sufficiently
large n, the distribution D over pairs (G,t) implemented by Part II of
Algorithm 3 is (σ, η, C, α)-nice.
4.4 Correctness and Security
In this section, we state our correctness and security theorems; we
formally prove them in Appendix C of our full paper [5].
Theorem 4.8 (Correctness). Let Π be the protocol of Algorithm 3
with the parameters of Lemma 4.7. Consider an execution of Π with
inputs X = ( ®xi)i ∈[n]
, in which all parties follow the protocol. If
A
′
4
≥ (1 − δ)n, i.e. less than a fraction δ of the clients dropout, then
the server does not abort and obtains z® =
Í
A
′
2
x®i with probability
1 − 2
−η
.
Theorem 4.9 (Security). Let σ, η, λ be integer parameters. Let Π
be the protocol of Algorithm 3 with the parameters of Lemma 4.7,
p = k − (t −
kγn
n − 1
+
r
k
2
((σ + 1) log(2) + logn)) + 1,
and instantiated with a IND-CPA and INT-CTXT authenticated encryption scheme, a EUF-CMA signature scheme, and a λ-secure key
agreement protocol. There exists a PPT simulator Sim such that, for
all C ⊂ [n] such that |C| ≤ γn, inputs X = ( ®xi)i ∈[n]\C, and for all
malicious adversary A controlling the server and the set of corrupted
clients C behaving semi-honestly in Part I, the output of Sim is computationally indistinguishable from the joint view of the server and
the corrupted clients RealC, i.e., RealC ≈σ,λ SimFX′
,α (C), where the
simulator can query once the ideal functionality FX,α .
4.5 Performance Analysis
We report the communication and computation costs for the client
and server when k = O(logn). We recall that we assumed that basic
operations and representation of elements in X are O(1).
Client computation: O(log2 n + l logn). Each client computation
can be broken up as receiving ≤ 4k logn hashes (O(k logn) complexity), ≤ 5k key agreements and k encryptions (O(k) complexity),
≤ 5k signatures signing and verifications (O(k) complexity), creating twice t-out-of-k Shamir secret shares (O(k
2
) complexity),
generating values m®i,j for all neighbors j (O(kl) complexity).
Client communication: O(log2 n + l). Each client performs ≤ 5k
key agreements (O(k) messages), send 2k encrypted shares (O(k)
messages), send a masked input (O(l) complexity), send ≤ 5k signatures, and reveal up to 2k shares (O(k) messages).
Server computation: O(n(log2 n + l logn)). The server computation can be broken up as reconstructing t-out-of-k Shamir secrets
for each client (O(n · k
2
) complexity), generating values m®i,j for all
(dropped out) neighbors j of each client i (O(nkl) complexity).
Server communication: O(n(log2 n + l)). The server receives or
sends O(log2 n + l) to each client.
4.6 Guarantees with an honest server
We now discuss the setting where an adversary controls a subset
of γn actively corrupted clients, but the rest of the clients and the
server are honest. It is easy to see that the view of the adversary
in this case does not include any information whatsoever about
honest inputs, because clients only receive shares of a PRG seed
(for self masks) and shares of a public key (for pairwise masks). The
only message that contains the input is the masked input y®i
, which
is sent to the server. Note that malicious clients could lie about their
randomness r®i and pairwise masks when sharing seeds for it, but
this boils down to sending an arbitrary y®i maliciously, which is in
turn equivalent to lying about their input x®i
. Let us remark that we
do not prevent malicious clients to choose their input adaptively
depending on which of their neighbors dropped out (analogously
to [8]). As mentioned in Section 4.2 one could limit this flexibility
to choosing input based on which neighbors dropped out before the
masked input y®i
is sent with a cheap modification in the protocol.
To make the above security claim formal in the standard ideal
vs. real simulation paradigm, one needs to show that there is a simulator in the ideal world that can produce the view of the malicious
clients, along with the output of the honest server. Moreover, this
should be done for any setting D of honest dropped out clients (recall that the adversary controls if/when malicious clients dropout).
The simulator has one-time access to an ideal functionality returning the sum of the values of the clients that did not dropout (the
prescribed output for the server), and can evaluate an attacker A
that controls γn malicious clients. The simulator just needs to run
A with an arbitrary fake input for honest clients, say all zeroes, and
dropping out honest clients according to D . This allows to extract
the sum zmal of the inputs of malicious clients provided by the
adversary. Note that zmal is all that is needed to query the ideal
functionality and obtain the server’s prescribed output (including
the true sum of the honest clients in this case).
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1262
5 NUMERICAL BOUNDS AND CONCRETE
EFFICIENCY RESULTS
In Theorems 3.6 and 4.9, we established that a number of neighbors
k = O(logn + η + σ) suffices to obtain secure and correct protocols
in the semi-honest and malicious variants. These theorems are
derived from tail bounds on the hypergeometric distribution. While
the same tail bounds could be used in practice to set the operating
parameters k,t (i.e. by direct evaluation of the expression for k in
Theorem 3.10), more efficient choices are found below by directly
evaluating the hypergeometric CDF.
5.1 Semi-honest Variant
The results in this Section follow from Lemma 3.7, and the fact
that the CDF of the hypergeometric distribution can be evaluated
directly. More concretely, note that Lemma 3.7 gives sufficient efficiently checkable conditions that k,t can satisfy (given the rest of
the parameters) implying that our protocol is secure and correct
(Lemmas 3.6 and 3.5). This gives a numerical approach to obtain secure parameters k,t given n, σ, η,γ , δ. The naive algorithm iterates
over all possible values of k,t in lexicographic order and stops as
soon as it finds one that satisfies both conditions in Lemma 3.7 (assuming our intent is to minimize computation and communication
for the required security σ). We implemented a more efficient and
stable variant of this approach, using binary search and checks in
the log domain, avoiding numerical under(over)flows. Our implementation consists of less than 100 lines of Python code leveraging
the Scipy scientific computing library [35].
Fig. 2 (a) shows secure values of k for several settings of parameters corresponding to all combinations of γ , δ taking values in
{1/3, 1/20}, σ = 40, and η = 30, as n grows from 103
to 108
. Fig. 2
(b) shows how k scales with γ , everything else being the same. Note
that less than 150 neighbors are enough to provide security up to
n = 108
clients where at most 1 in 5 clients are corrupted by and
1 in 20 clients dropout (or vice versa). Moreover, k = 100 suffices
for n = 104
, which immediately translates into a 100x concrete improvement in client computation and communication with respect
to the protocol by Bonawitz et al [8], with roughly the same server
computation cost. These gains increase linearly with n, as our protocol retains roughly the same client runtime and communication
costs for values of n for which the protocol by Bonawitz et al [8]
becomes highly impractical.
Benchmarking. In the semi-honest protocol, each client performs
(a) 2k key agreements, (b) secret sharing 2 secrets into k shares
(which takes O(k
2
) time), and (c) generating and stretching k + 1
seeds using the PRG F (which we implement using AES) to the
length of the input vector l (which is O(kl)). Thus our runtime and
communication improvements with respect to the semi-honest version of [8] are roughly a factor n/k = O(n/logn). We benchmarked
Shamir share generation and PRG expansion using AES to confirm
that the PRG expansion is the bottleneck (which is consistent with
the running times reported in [8]). We report running times for a
particular setting in Table 2 in the appendix. The setting was chosen for ease of comparison with the running times reported to the
semi-honest version of the protocol of Bonawitz et al. (see Figure 8
in [8]). One can observe that our approach is roughly an order of
magnitude faster for n = 1000 (which is the the only value of n for
which Bonawitz et al. report runtimes). Crucially, our costs remain
almost the same as n increase, which the complete-graph construction of in [8] quickly becomes impractical. This is consistent with
the factor of n/k improvement mentioned above, as k = O(logn)
stays within (80, 120) as n grows within (103
, . . . , 105
).
5.2 Malicious Variant
Our approach to compute numerical bounds for the malicious variant is analogous to the one from the semi-honest variant: Definition 4.6 states sufficient conditions that a triple (k,t, α) must satisfy
to get security and correctness. As in the semi-honest case these
checks involve only simple calculations and querying the CDF of
a hypergeometric random variable. Our implementation consists
of roughly 100 lines of Python code leveraging the Scipy scientific
computing library [35].
Fig. 2 (c) shows secure values of k and α for several settings corresponding to all combinations of γ , δ taking values in {1/5, 1/20},
σ = 40, and η = 30, as n grows from 103
to 108
. For example, with
104
clients and γ = δ = 1/5, less than 600 neighbors per client are
enough for security, and every honest client is guaranteed that if
the (possibly malicious) server gets a sum z in the clear involving
their value, then z is the result of aggregating at least 0.39n = 3900
honest clients. The value of k in this plot is the minimum value
that guarantees security σ, thus minimizing client computation and
communication. Hence, the resulting α, which grows with k, is not
as large as it could be for each setting. This explains the counterintuitive fact that settings with smaller γ also have smaller α (as
they allow a smaller k). To clarify this point Fig. 2 (d) shows how α
scales with k: α converges towards (1 −γ − δ)n, which is the best
one can hope for (as in a round without dropouts a malicious server
can drop any set of (δ)n honest parties from the sum). Hence, by
increasing k, our analysis covers the full spectrum of possible α, and
allows one to fine tune parameters to trade-off between security
(captured by α, σ) and the main computational costs (captured by
k,t). Finally, to illustrate this kind of fine-tuning, Figure 3 shows
how α grows for small numbers of neighbors in some parameters.
For example, the plot shows that, for n = 104
,γ = δ = 1/20, 300
neighbors are enough so that every honest client is certain that
their value will be aggregated with at least 5000 other clients values!
6 SHUFFLING FROM SUMMATION
In this section we consider the following shuffling primitive between many clients with inputs and a server who should obtain
the shuffled clients’ inputs. Each client i has a message xi ∈ M
with |M| = m, and the goal is for the server to receive the multiset of messages with no information on which message came
from whom. This is equivalent to the messages being sent to a
trusted third party and shuffled (or sorted) before being handed
to the server. This primitive is the basis of the shuffle model of
differential privacy [3, 4, 11, 19] and could be used for anonymized
submissions [6].
We show a reduction from secure shuffling to secure summation.
Our reduction makes a single call to secure summation, and thus
the security and drop-out robustness properties of our protocol
directly translate to the shuffling functionality. In particular, in the
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA 1263
Figure 2: (From left to right, a) Secure values of k for several settings (Semi-honest). b) Secure values of k for several settings,
as γ grows (Semi-honest). c) Required number of neighbors for several settings, and the value of α guaranteed in each case
(Malicious). d) Values of α as the number of neighbors increases, for n = 105
(Malicious).
semi-honest variant, honest clients are guaranteed to have their
value shuffled with at least (1 −γ − δ)n other values from honest
clients. In the malicious setting, one gets the analogous guarantee
with αn, as explained in Section 4.
We first discuss a simple baseline solution that only works for
small m. A histogram of how many times each message appears
can be considered as a vector of length m. Thus, each client can
locally build a histogram of their input (which would be a one-hot
vector) and then a vector summation protocol can be used to add
these local histograms together. The server then learns only the
aggregate histogram, as desired. The problem with this solution is
that it is impractical for large m, e.g., m = 2
32. More generally, this
solution is wasteful for scenarios where we know that the result
histogram is going to be sparse.
We address the issues in the above protocol, i.e. for settings
where the size of the message domain m is much larger than the
number of client n by leveraging a probabilistic data structure called
an invertible Bloom lookup table (IBLT) [21]. An IBLT is a linear
sketch of a key-value store, such that if the vector representations
for two IBLTs are added together, the result is a new IBLT that
encodes the union of the key-value stores for the original IBLTs.
IBLTs support the following operations (among others):
• Insert(p, x): insert the key-value pair (p, x).
• ListEntries(): list every key-value pair in the data structure.
Though the ListEntries operation may fail, we can choose parameters so that this failure happens with very small probability.
Using this data structure, the shuffle primitive can be achieved as
follows. Every client first creates an empty local IBLT of length ℓ, all
with the same parameters. Then each client i chooses a pseudonym
πi uniformly at random from a set P that is sufficiently large to
avoid collisions (e.g. 64 bit strings would work well). They then
insert the pair (πi
, xi) into their IBLT. A vector summation protocol
is then used to combine the IBLTs, and the server recovers the
messages using the ListEntries IBLT functionality.
We provide the details of the above construction and the exact
implementations of the local vector preparation algorithm run by
each client and the message recovery algorithm run by the server
in Appendix D of the full version [5]. There we also discuss the
exact parameters, which tell us that for n > 100, the bit length
of the vectors used for the IBLTs can be be taken to be less than
2n⌈log2
(|P |) + log2
(m) + log2
(n)⌉. For example if n = 10,000 and
the clients’ inputs are 32 bits long, the construction requires 2 ·
10,000 · (64 + 32 + 14) = 2,200,000 bit, i.e. 269kB, vectors. As a final
remark, note that this protocol is very easily adapted to the case
where clients have different numbers of messages to send. This
covers the case where each user has multiple messages to send, as
in the multi-message shuffle model [4, 11, 19], and the case where
most users don’t have any message to send, which might be useful
for submitting error reports.
7 CONCLUSION
We presented new constructions for secure aggregation that achieve
both better asymptotic computation and communication costs than
previous solutions as well as very efficient concrete parameters,
which enable much better scalability with the number of clients.
The efficiency cost of the construction of Bonawitz et al. [8] limited
its use to a thousand clients. Our semi-honest construction supports
billions of clients and our semi-malicious construction supports
tens of thousands of clients for the same per client cost. Last but
not least we presented a construction for secure shuffling using
secure vector aggregation, which is the first cryptographically secure instantiation of the shuffle model of differential privacy. This
construction requires each client to have an input vector of size
linear in the total number of submitted messages.
We leave as future work a system implementation of our protocols, and leave as an intriguing open question how to achieve secure
shuffling with sublinear complexity in the single-server setting.