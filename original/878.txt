Fuzzing and symbolic execution are two complementary techniques
for discovering software vulnerabilities. Fuzzing is fast and scalable,
but can be ineffective when it fails to randomly select the right
inputs. Symbolic execution is thorough but slow and often does not
scale to deep program paths with complex path conditions.
In this work, we propose to learn an effective and fast fuzzer from
symbolic execution, by phrasing the learning task in the framework
of imitation learning. During learning, a symbolic execution expert
generates a large number of quality inputs improving coverage on
thousands of programs. Then, a fuzzing policy, represented with a
suitable architecture of neural networks, is trained on the generated
dataset. The learned policy can then be used to fuzz new programs.
We instantiate our approach to the problem of fuzzing smart
contracts, a domain where contracts often implement similar functionality (facilitating learning) and security is of utmost importance.
We present an end-to-end system, ILF (for Imitation Learning based
Fuzzer), and an extensive evaluation over >18K contracts. Our results show that ILF is effective: (i) it is fast, generating 148 transactions per second, (ii) it outperforms existing fuzzers (e.g., achieving
33% more coverage), and (iii) it detects more vulnerabilities than
existing fuzzing and symbolic execution tools for Ethereum.
CCS CONCEPTS
• Security and privacy → Software security engineering.
KEYWORDS
Fuzzing; Imitation learning; Symbolic execution; Smart contracts
1 INTRODUCTION
Fuzzing is a technique for automatically and quickly generating
test inputs, and running them against a target program to uncover
security vulnerabilities. Because of its simplicity and practical effectiveness, fuzzing has become one of the main approaches for
software testing [21, 30, 38, 68].
A key challenge in effective fuzzing of real-world programs is to
generate inputs that thoroughly exercise the code of the programs.
Random fuzzers often get stuck with ineffective inputs that fail
to exercise deep program paths and may thus miss bugs [22, 45,
48, 53]. Symbolic execution has been used to generate effective
inputs as it can leverage off-the-shelf constraint solvers to solve
path constraints which steer program execution along specific paths
that improve coverage or expose new vulnerabilities [13, 14, 52, 67].
Unfortunately, symbolic execution may fail to explore deep paths
and suffers from poor scalability when path constraints are complex
and hard to solve [15, 48, 59].
This Work: Learning to Fuzz from a Symbolic Expert. Our
core insight is that high-quality inputs generated by symbolic execution form a valuable knowledge base which can be used to
learn an effective fuzzer. We propose to learn a fuzzer from inputs
generated by a symbolic execution expert using the framework of
imitation learning [49]. This approach has been successfully applied
in various fields such as autonomous driving [47], robotics [4], and
game playing (e.g., where learned models achieved super-human
performance in playing Go [57]). In this framework, an apprentice
(a fuzzer in our setting) learns to imitate the behavior of a powerful,
but expensive-to-execute expert (a symbolic execution engine). The
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 531
learned fuzzer combines strengths of both fuzzing and symbolic
execution - it generates effective inputs quickly. We can afford to
exhaustively run the symbolic execution expert for learning and
then use the learned fuzzer to test unseen programs.
We illustrate this high-level idea in Figure 1. During the learning
phase, we run a coverage-guided symbolic execution expert on
tens of thousands of programs to produce a dataset of training
input sequences, where every input improves coverage for the
given programs (top part in Figure 1). To learn the behavior of
the symbolic execution expert, we train a suitable architecture of
neural networks that captures a probabilistic fuzzing policy for
generating program inputs. Our neural networks are trained to
achieve high accuracy on the obtained dataset (thus successfully
imitating the symbolic execution expert). After learning, we use
the learned policy to generate input sequences for fuzzing unseen
programs (bottom part in Figure 1). At each step, the fuzzer samples
an input from the fuzzing policy, executes it against the program,
and updates its state to continue the fuzzing process. To the best
of our knowledge, this is the first work to apply the framework of
imitation learning in the context of program testing.
Application Domain: Fuzzing Smart Contracts. We instantiate our fuzzing approach to the domain of (blockchain) smart contracts, which are programs that run on top of distributed ledgers
such as Ethereum [65]. We find this domain particularly suitable
for our learning approach because smart contracts often implement similar functionality, such as tokens and decentralized crowdsales [43]. Indeed, recent work demonstrates that there is substantial code similarity among real-world contracts [34]. This makes
it possible to learn from a symbolic execution expert how to fuzz
new, unseen smart contracts.
Moreover, smart contracts have been proved to be challenging to
fuzz effectively. Conceptually, they are stateful programs, processing sequences of transactions that modify the ledger’s persistent
state. A key obstacle in achieving high coverage for smart contracts
is that some functions can only execute at deeper states (e.g., after
a crowdsale has finished). Indeed, existing fuzzers for contracts
such as Echidna [17] and ContractFuzzer [32] randomly generate sequences of transactions that can fail to cover deeper paths
and expose vulnerabilities. Further, existing symbolic execution
engines [37, 42] can only symbolically reason limited number of
transactions (e.g., 3), failing to reach deeper states. Therefore, highcoverage fuzzing of smart contracts remains an important open
problem, especially since contract vulnerabilities have already led
to significant financial losses [44, 60].
ILF System and Evaluation. Based on our approach, we present
ILF1
(for Imitation Learning based Fuzzer), a new fuzzer for Ethereum
that generates sequences of transactions achieving high coverage
on real-world contracts (deployed on Ethereum). We present an
extensive evaluation of ILF over 18, 000 smart contracts. Our results
show that the learned fuzzer is practically effective. First, ILF is fast,
generating and executing on average 148 transactions per second.
Second, it outperforms existing fuzzing approaches for contracts,
achieving 33% more coverage than Echidna on large contracts
(with ≥3K instructions). Third, it identifies more vulnerabilities
1
ILF is publicly available at https://github.com/eth-sri/ilf.
than existing fuzzing and symbolic execution tools for Ethereum,
e.g., it discovers roughly 2× more Leaking vulnerabilities than Maian [42], a tool based on symbolic execution.
Main Contributions. To summarize, our main contributions are:
• A new fuzzing approach based on learning to imitate a symbolic
execution expert.
• A new neural network architecture that models a fuzzing policy
for generating input sequences for smart contracts (Section 4).
• An end-to-end implementation, called ILF, that supports semantic
feature representation tailored to fuzzing of smart contracts, a
practical symbolic execution expert for smart contracts, and a
set of critical vulnerability detectors (Section 5).
• An extensive evaluation over >18K real-world smart contracts,
demonstrating that ILF is fast, achieves high coverage (92% on
average), and detects significantly more vulnerabilities than existing security tools for smart contracts (Section 6).
2 OVERVIEW
We present a simple contract which highlights the key challenges in
generating transactions achieving high coverage. We then discuss
the limitations of existing fuzzing and symbolic execution tools
and show that they fail to cover relevant functions of the contract.
Finally, we present ILF and illustrate how it works on an example.
2.1 Motivating Example
As a motivating example, we present a crowdsale, one of the most
common paradigms of smart contracts on Ethereum [65]. The goal
of the crowdsale is to collect 100K ether within 60 days. The crowdsale is successful if this goal is reached within 60 days, in which
case the crowdsale’s owner can withdraw the funds. Otherwise, the
crowdsale is considered failed, and the users who have participated
can refund their investments.
In Figure 2, we present the contract’s Solidity code [3] adapted
from the widely-used OpenZeppelin library [43]. The crowdsale’s
constructor initializes the crowdsale’s end to 60 days from the time
of deployment (returned by now) and assigns the crowdsale’s creator
(returned by msg.sender) as its owner.
Users can invest in the crowdsale using the function invest. This
function executes only if the crowdsale is active (phase = 0) and the
goal has not been reached (raised < goal). The crowdsale’s phase
(stored at variable phase) can be changed by calling function setPhase.
This function ensures that the phase is changed to 1 (indicating a
successful crowdsale) only if the amount of raised ether equals or
exceeds the goal, and to 2 (indicating a failed crowdsale) only if the
current time (now) exceeds the crowdsale’s end and the amount of
raised funds is less than the goal. If the crowdsale is in phase 1, then
the invested ether can be transferred to its owner with function
withdraw. Alternatively, if the crowdsale transitions to phase 2, then
it allows users to refund their investments (via calls to refund).
Vulnerability. This crowdsale contract contains a vulnerability
called Leaking, defined in [42]. This vulnerability occurs when
the contract sends ether to an untrusted user who has never sent
ether to the contract. Here, the set of trusted users consists of the
contract’s creator and all users whose addresses have appeared as
arguments in transactions sent by trusted users; all remaining users
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 532
1 contract Crowdsale {
2 uint256 goal = 100000 * (10**18);
3 uint256 phase = 0;
4 // 0: Active , 1: Success , 2: Refund
5 uint256 raised , end ;
6 address owner ;
7 mapping ( address = > uint256 ) investments ;
8
9 constructor () public {
10 end = now + 60 days ;
11 owner = msg . sender ;
12 }
13
14 function invest () public payable {
15 require ( phase == 0 && raised < goal );
16 investments [ msg. sender ] += msg . value ;
17 raised += msg . value ;
18 }
19
20 function setPhase ( uint256 newPhase ) public {
21 require (
22 ( newPhase == 1 && raised >= goal ) ||
23 ( newPhase == 2 && raised < goal && now > end )
24 );
25 phase = newPhase ;
26 }
27
28 function setOwner ( address newOwner ) public {
29 // Fix : require ( msg . sender == owner );
30 owner = newOwner ;
31 }
32
33 function withdraw () public {
34 require ( phase == 1);
35 owner . transfer ( raised );
36 }
37
38 function refund () public {
39 require ( phase == 2);
40 msg . sender . transfer ( investments [msg. sender ]);
41 investments [ msg. sender ] = 0;
42 }
43 }
Figure 2: Crowdsale contract containing a vulnerability that
allows an arbitrary user to steal the funds invested by users.
are considered as untrusted. This definition ensures that the contract’s ownership or administrative permission is not transferred
to untrusted users. The vulnerability in our crowdsale example is
triggered by the following sequence of transactions:
t1: A user calls invest() with msg.value ≥ goal;
t2: A user calls setPhase(newPhase) with newPhase = 1;
t3: An attacker with address A calls setOwner(A);
t4: The attacker calls withdraw().
This sequence exposes the vulnerability because (i) the attacker
does not send ether to the contract (the attacker’s transactions t3
and t4 have msg.value set to 0 by default), (ii) the attacker is untrusted
as her address A is not used as arguments to transactions sent by
possibly trusted users (in t1 and t2), yet (iii) the attacker receives
ether (in t4). The vulnerability indicates a missing pre-condition of
function setOwner, which must restrict calls to owner (Line 29).
2.2 Challenges of Fuzzing Smart Contracts
Smart contracts are stateful programs. Each contract has a persistent
storage, where it keeps relevant state across transactions, such
as the amount of raised funds raised in our crowdsale example
(Figure 2). Each transaction processed by the contract may change
the contract’s state. For example, if a user invokes function invest
of our crowdsale contract with a positive amount of ether (i.e.,
with msg.value > 0), then the amount of raised funds increases. More
formally, each transaction is identified by (i) a contract function to
execute, together with any arguments required by the function, (ii)
the address of the user who initiates the transaction, and (iii) the
amount of ether transferred to the contract.
The stateful nature of smart contracts makes them difficult to
test automatically. Smart contracts often have deep states which can
only be reached after executing a specific sequence of transactions.
For example, our crowdsale can reach a state where phase = 1 holds
only after users have invested a sufficient amount of ether into
the contract (via calls to function invest). This challenge directly
affects the code coverage one can achieve when testing the contract.
The contract’s functions often have pre-conditions defined over the
state that must be satisfied for the functions to execute. For example,
function withdraw in the crowdsale example can be executed only if
phase = 1 holds. Therefore, to achieve high coverage when testing
a smart contract, one needs to generate sequences of transactions
that thoroughly explore the contract’s state space.
Next, we illustrate that existing fuzzers and symbolic execution
tools indeed struggle to achieve high code coverage and, in turn, to
trigger vulnerabilities hiding deeper in the state space.
Limited Coverage of Existing Fuzzers. Existing fuzzers for
smart contracts, such as Echidna [17], generate transactions to test
contracts. Our experiments in Section 6 indicate that these fuzzers
fail to exercise functions that can only execute at deeper states.
For our crowdsale contract, Echidna achieves 57% code coverage.
Inspecting closely the achieved coverage reveals that Echidna fails
to cover functions setPhase, withdraw, and refund, all of which have
pre-conditions that require reaching a specific state. In addition,
function setPhase requires generating an argument newPhase ∈ {1, 2}.
Limited Scalability of Existing Symbolic Execution Tools.
While smart contracts are often small, analyzing them thoroughly
using symbolic execution is challenging. This is because to uncover
bugs that are revealed only at deeper states, one needs to reason
about sequences of transaction symbolically, resulting in block state
explosion and complex constraints. Concretely, the number of symbolic block states grows exponentially in the depth k of analyzed
symbolic transactions. Further, the time complexity of solving the
generated constraints is exponential in k (the number of symbolic
variables grows linearly with k), burdening the constraint solver.
In Section 5.2, we present experimental results that demonstrate
the limited scalability of existing symbolic execution tools.
To cope with this scalability issue, existing symbolic execution
tools [37, 42] bound the depth (e.g., typically to 2-3 transactions)
and analyze a subset of the feasible paths (using heuristics). Indeed,
Maian [42], a symbolic tool that supports the Leaking vulnerability,
fails to reveal the vulnerability in our crowdsale example, even
when increasing the analysis depth to 4 (its default depth is 3).
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 533
2.3 The ILF Fuzzer
To address the above limitations, we developed ILF, a new fuzzer
that uses a probabilistic fuzzing policy for generating sequences
of transactions. The fuzzer is learned from tens of thousands of
sequences of quality transactions generated by running a scalable
symbolic execution expert on real-world contracts. Our expert operates on concrete block states and employs symbolic execution to
generate concrete sequences of transactions. It can generate sufficiently long transaction sequences (of length 30 on average) that
reach reasonably deep states. We present more details on our expert
in Section 5.2. Below, we describe how the learned fuzzing policy
generates transactions.
Fuzzing Policy. We show the learned fuzzing policy in Figure 3.
As an input, the policy receives semantic information derived from
the contract under test and the history of executed transactions
so far. It outputs a probability distribution over a set of candidate
transactions which can be used to extend the sequence of transactions. The transactions generated before selecting ti are shown
in the top-left table in Figure 3. For example, transaction ti−1 is a
call to function setPhase(1), sent by the user with address 0x10 and 0
ether. Based on this sequence, ILF derives a feature vector for each
function f of the contract (invest, setPhase, etc.). These features (described in Section 5.1) capture domain-specific knowledge relevant
for generating a new transaction ti that aims to improve coverage.
Examples of features include current coverage of each function,
opcodes found in the function body and function names. Using
this feature matrix and the hidden state hi−1, the fuzzing policy
outputs several distributions, depicted in the top-right in Figure 3.
ILF samples (i) a function, together with a list of arguments, (ii) an
address for the transaction sender, and (iii) an amount of ether to be
sent with the transaction. These components collectively identify
the next transaction ti to be executed. In our example, ILF selects
invest(), sent by user 0x20, sending a large amount of ether (represented by 99..99). To deal with large domain types, we use a set of
values (e.g., integers and ether amount) observed during training.
Finally, after selecting ti
, ILF updates its hidden state hi and uses it
later to select a transaction in the next fuzzing step.
We remark that the fuzzing policy is non-trivial to represent
(and learn) due to the enormous set of transactions ILF can generate. To address this, we present a carefully crafted neural network
architecture, which addresses relevant challenges, including handling variable number of arguments and large domain types (e.g.,
integers). The architecture is described in detail in Section 4.2.
Coverage and Vulnerability Detection. A key benefit of ILF is
that its fuzzing policy is fast to compute (ILF fuzzes at rate 148 transactions per second), yet it can effectively achieve high-coverage
(92% on average for our dataset). To discover vulnerabilities, ILF
supports six relevant detectors, including one for the Leaking vulnerability. For our crowdsale example, ILF achieves 99% coverage
and correctly identifies the Leaking vulnerability within 2 seconds.
In Section 6, we present an extensive evaluation of ILF and demonstrate its benefits over existing fuzzing and symbolic execution
tools in terms of both code coverage and vulnerability detection.
Fuzzing step i
Fuzzing step i+1
f (x) sender amount
...
setPhase(1) 0x10 0
Function f Feature vector
invest [2, 1, 3, . . .]
setPhase [1, 0, 1, . . .]
setOwner [0, 1, 0, . . .]
withdraw [3, 2, 2, . . .]
refund [1, 1, 2, . . .]
NN-based
fuzzing
policy
withdraw()
setPhase(2)
invest()
0x30
0x20
0x10
99..99
0x40
0
f (x) sender amount
...
setPhase(1) 0x10 0
invest() 0x20 99..99
Function f Feature vector
invest [1, 0, 0, . . .]
setPhase [1, 3, 2, . . .]
setOwner [0, 2, 0, . . .]
withdraw [3, 1, 2, . . .]
refund [2, 2, 1, . . .]
NN-based
fuzzing
policy
. . .
Hidden
state hi−1
Hidden
state hi
Hidden
state hi+1
Extract features
Extract features
Figure 3: Fuzzing process: At each step i, the fuzzer derives features based on the transactions executed so far, and
outputs distributions over the contract’s functions, arguments (shown together with functions), sender addresses,
and ether amounts. It samples a transaction, executes it on
the contract, and updates fuzzing hidden state.
3 BACKGROUND
In this section, we provide background on Ethereum smart contracts, imitation learning, and relevant neural network models.
3.1 Ethereum Smart Contracts
Ethereum [65] is a distributed ledger that supports execution of
arbitrary programs, called smartcontracts. Itsupports user accounts,
which are associated with private keys and provide the interface
through which users submit transactions. It also supports contract
accounts, which are autonomous agents, whose code implementation and state are stored on the ledger. We denote by B the set of
possible ledger states and call a particular state b ∈ B a block state.
A contract’s execution is triggered via transactions (sent by users)
or messages (calls received from other contracts). Smart contracts
are compiled into Ethereum Virtual Machine (EVM) bytecode. The
EVM instruction set supports standard instructions, such as opcodes for reading from and writing to the contract’s state (sstore
and sload), reading the timestamp of the current block timestamp,
reading the transaction sender’s address (caller), and others.
Transactions and Blocks. We model a transaction t as a tuple
t = (f (x),sender, amount),
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 534
where f (x) identifies a public or external function f of the contract
and its arguments x, sender is the transaction sender’s address, and
amount is the ether amount transferred to the contract. A function
can be payable, which means it can receive ether. Non-payable
functions revert if amount is greater than zero. We write T for
the set of all possible transactions. A transaction can modify the
storage of the called contract and other invoked contracts. Formally,
the effect of executing a transaction t at block state b is captured
by b
t→ b
′
. Given an initial block state binit ∈ B and a sequence
of transactions t = (t1, . . . ,tn) ∈ T∗
, we refer to the sequence of
block states binit
t1 → · · ·
tn→ bn induced by t as a block state trace.
For more details on Ethereum, please see [65].
3.2 Imitation Learning
We now describe the relevant background on Markov Decision
Process and imitation learning.
Markov Decision Process. A Markov Decision Process (MDP) is
a mathematical framework for modeling a sequential decision making problem. It involves an agent making a decision in an environment and earning a reward. Formally, an MDP is a tuple (S, A, E, R),
where S is a set of states, A is a set of actions, E : S ×A → S is the
state transition function and R : S × A → R is the reward function.
At each step i, an agent observes the current state si and performs
an action ai
. It then receives a reward ri = R(si
, ai) and the state
is advanced according to the transition function: si+1 = E(si
, ai).
The goal of solving an MDP is to learn a probabilistic policy
πopt : S × A → [0, 1] which maximizes the expected cumulative
reward during n steps. Whenever the agent observes a new state it
can then sample an action from the learned policy. Formally, we
need to solve the following optimization problem:
πopt = arg max
π
E
ai∼π (si )
[
Õn
i=0
R(si
, ai)].
Learning From an Expert by Example. The key challenge is
to design an algorithm to solve the above optimization problem.
To address this challenge, we employ the framework of imitation
learning [49]. This approach leverages an existing expert policy π
∗
which can achieve high reward at the given task. However, π
∗ often
has high time complexity or requires manual effort (in our case,
π
∗
is a symbolic execution engine). Imitation learning uses π
∗
to
provide demonstrations which can be used to learn an apprentice
policy πˆ, which is cheaper to compute with and can ideally achieve
the same reward as π
∗
.
For learning, we first run π
∗ on a training set so to construct
a dataset D =

[(si
, ai)]d
	 |D |
d=1
, where each sample [(si
, ai)]d ∈
(S × A)∗
is a sequence of state-action pairs meaning that π
∗
takes
action ai when encountering state si
. Then, we learn a classifier C
on D, which given a state, outputs a probability vector over the
possible actions and which aims to assign the highest probability
to actions taken by π
∗
. The learned classifier C represents our
apprentice policy πˆ. IfC has high prediction accuracy on the dataset
D, then πˆ will closely mimic π
∗
. Note that learning classifier C is
a standard supervised learning problem as training input-output
pairs are given in D.
Table 1: Mapping from MDP concepts to fuzzing concepts
MDP Concept Fuzzing Concept
State s ∈ S Transaction history t ∈ T∗
Action a ∈ A Transaction t ∈ T
Transition E Concatenation t · t
Reward R Code coverage improvement
Policy π Policy for generating t
Agent Fuzzer with policy π
3.3 Neural Network Models
We now overview the neural network models used to represent our
fuzzing policy described in Section 4.2.
Fully Connected Network. A Fully Connected Network (FCN)
contains multiple fully connected layers which connect each input
neuron to each output neuron. In order to provide non-linearity,
neurons are passed through an activation function (e.g., ReLU and
Sigmoid). A softmax function at the end ensures the outputs of the
network form a probability distribution (i.e., sum up to one).
Gated Recurrent Unit. Gated Recurrent Unit (GRU) [16], a variant of Recurrent Neural Networks (RNN), is a model that deals with
variable length sequential inputs. It is capable of tracking sequence
history by maintaining internal state and memory. At every step i,
GRU receives an input xi ∈ R
m, and based on the last state embedding hi−1 ∈ R
n
computes a new state embedding hi ∈ R
n
. This
operation can be characterized as: hi = GRU (xi
,hi−1). Internally,
GRU also computes an update gate zi ∈ R
n
and a reset gate ri ∈ R
n
,
which decide whether to keep or erase past information. For more
details on GRUs, we refer the reader to [16].
4 FUZZING POLICY
In this section, we instantiate the concept of imitation learning
to the problem of coverage-based fuzzing of smart contracts. We
then show how we represent the learned policy for generating
transactions using a tailored neural network architecture.
4.1 Formulating Fuzzing as MDP
Table 1 shows how the key components of MDPs connect to concepts in coverage-based fuzzing of smart contracts. The tested contract c and its initial block state binit are fixed when fuzzing the
contract. We therefore omit them from the formal definitions to
avoid clutter. We represent the state as a sequence of transactions
to allow the fuzzing policy to base its decision on the entire history
of transactions. At step i, based on the sequence of transactions
ti = (t1, . . . ,ti−1), and the block state trace binit
t1 → · · ·
ti−1 → bi−1
induced when running ti on the contract c under test, the agent
selects a new transaction ti to be executed based on a policy π.
The selected transaction is executed, extending the sequence of
transactions and the block state trace, and the agent receives a
reward (i.e., coverage increase). The goal is to obtain as much coverage as possible at the end of fuzzing (transaction limit or time
limit reached). We now formally define the fuzzing policy and then
instantiate different policies later in this section.
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 535
Fuzzing Policy. The fuzzing policy is captured by the function
π : T
∗ × T → [0, 1]. That is, given a current state and a candidate transaction, the policy outputs the probability of selecting
that transaction. Since smart contract transactions have complex
structure, we decompose the fuzzing policy into four components:
(1) πfunc : T
∗ × F → [0, 1], used to select a function f from F =
{ f
1
, . . . , f
n
}, the set of (public or external) functions of the
tested contract.
(2) πargs : T
∗ × F × X∗ → [0, 1], used to select function arguments
x for the selected function f , where X is the set of possible
function argument values.
(3) πsender : T
∗ × SND → [0, 1], used to select a sender from a
pre-defined set of possible senders SND.
(4) πamount : T
∗ × F × AMT → [0, 1], used to select payment
amount for selected function f , where AMT is the set of possible
ether amounts that can be sent with f .
We note the selections made by πargs and πamount depend on the
selected function f , because the number of arguments selected
using πargs depends on f ’s arity, and the amount of ether selected
using πamount is 0 if f is a non-payable function.
Constructing a Transaction. The fuzzing policy π used to generate new transactions is defined as a sampling process based on
the history of transactions t:
(f (x),sender, amount) ∼ π(t)
where f ∼ πfunc(t) is the sampled function, x ∼ πargs(t, f ) is the
sampled list of arguments for f , sender ∼ πsender(t) is the sampled
sender, and amount ∼ πamount(t, f ) is the sampled ether amount.
Example: a Uniformly Random Policy. We provide the example policy π
unif , which selects transactions uniformly at random:
π
unif
func (t) = Unif (F ),
π
unif
args (t, f ) = Unif (Sig(f )), π
unif
sender(t) = Unif (SND),
π
unif
amount(t, f ) =
(
Unif ([0, MA]) f is payable
{0 → 1} otherwise
where Unif (X)returns a uniform distribution over domainX, Sig(f )
returns the set of arguments that comply with f ’s signature, and
MA is the maximum amount of ether for a transaction. We use this
policy as one of the baselines in Section 6.
4.2 Neural Network-based Policy
We represent the neural network based fuzzing policy π
nn with a
tailored architecture of neural network models, shown in Figure 4.
Fuzzing State. To memorize the information from the history of
transactions during fuzzing, we use a GRU to encode the fuzzing
state. As shown in box [0] of Figure 4, the hidden fuzzing state
hi ∈ R
n
is computed as:
hi = GRUfuzz(α
fi−1
(F,ti),hi−1)
where hi−1 ∈ R
n
is encoding of the last fuzzing state, α
fi−1 (F,ti) ∈
R
m is a feature representation of both the last selected function fi−1
and the history of transactions ti
. We instantiate α in Section 5.1.
GRUfuzz
at step i − 1
GRUfuzz
at step i
GRUfuzz
at step i + 1
α
fi−1
hi GRUint GRUint
FCNint FCNint
int0 int1
FCNfunc
(5 layers)
fi
α(F, ti )
FCNsender
(3 layers) senderi
FCNamount
(3 layers)
amounti
[0] Fuzzing state.
[1] Sampling function fi
.
[2] Sampling integer arguments.
[3] Sampling senderi
.
[4] Sampling amounti
.
hi−1
hi
h
int
0
OH
Figure 4:ILF’s architecture of neural networks (NNs)for generating transactions using five steps (dashed boxes). Boxes
represent NNs. Circles denote vectors and matrices provided as input to NNs. Ellipses are sampled components
of the generated transaction. Solid lines ( ) represent NN
flows and dotted lines ( ) denote sampling.
Generating a Transaction. To sample a new transaction atstep i,
we perform the following substeps:
(1) Sampling function fi
. We transform all functions in F (also taking into account the current trace ti
), into the feature representation matrix α(F,ti) ∈ R
|F |×m. Then, hi and α(F,ti) are fed into
a 5-layer FCN with softmax FCNfunc : R
n ×R
|F |×m → [0, 1]
|F |
.
This is shown in box [1] of Figure 4. Intuitively, FCNfunc computes for each function a score representing its importance
given the current state hi
. The scores are normalized using
softmax and fi
is sampled from the resulting probability distribution. We summarize this process as:
fi ∼ π
nn
func(ti) = FCNfunc(hi
, α(F,ti)).
(2) Sampling function arguments xi
. π
nn can generate the most important types of arguments: integer (both signed and unsigned,
any width), address, and array of them (both static and dynamic,
any dimension). Other types (e.g., string and bytes) appear less
often in our dataset and are generated uniformly at random.
Now we describe how to generate integer arguments.
There are two challenges to generating integer arguments.
First, it can be prohibitive to model all possible values (Solidity
has 2
256 integers). To address this, we learn a set SI of effective seed integers from the symbolic expert and select over SI.
Second, functions can have a variable number of integer arguments. To this end, we use a GRU to model their generation
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 536
process, where the number of arguments generated is based on
the function fi
’s arity. As shown in box [2] of Figure 4 (where
we have two integer arguments), to generate the jth integer
intj
, we feed a one-hot encoding of the last generated integer
OH(intj−1) and the last integer generation state h
int
j−1
∈ R
n
into
GRUint to obtain the current state h
int
j
∈ R
n
:
h
int
j = GRUint(OH(intj−1),h
int
j−1
).
Then, FCNint : R
n → [0, 1]
|S I |
, a 2-layer FCN with softmax,
operates on h
int
j
to produce a distribution where intj
is sampled:
intj ∼ FCNint(h
int
j
).
The initial state h
int
init is initialized as the fuzzing state hi and
the initial input is a zero vector.
Address arguments can also be variable-length and are generated using a GRU analogously, where the set of possible addresses ranges over the set of senders and deployed contracts.
(3) Sampling senderi
. As shown in box [3] of Figure 4, senderi
is
sampled from FCNsender : R
n → [0, 1]
|SND|
, a 3-layer FCN with
softmax:
senderi ∼ π
nn
sender(ti) = FCNsender(hi).
(4) Sampling amounti
. Finally, if the selected function fi
is a nonpayable function, amounti = 0. Otherwise, we need to compute
a probability distribution over the set of possible ether amounts.
Similar to integers, we learn a set of seed amount values SA from
the expert. As shown in box [4] of Figure 4, The 3-layer FCN
with softmax FCNamount : R
n → [0, 1]
|SA| outputs a probability
distribution over SA from which amounti
is sampled. That is:
amounti ∼ π
nn
amount(ti
, fi) =
(
FCNamount(hi) fi
is payable
{0 → 1} otherwise.
After the above steps, we generate a new transaction, run it against
the contract and update the hidden state.
Learning from Expert. To train π
nn, we assume a dataset D
containing sequences [(α(F,ti),ti)] where α(F,ti) is the extracted
feature representation and ti
is a transaction produced by the symbolic execution expert at step i. We describe our expert and the
generation of such a dataset in Section 5.2. Our goal is to train
π
nn to produce the same sequences of transactions as in D. To
train on a single sequence in D, we re-execute its transactions. At
every step i, we feed feature α(F,ti) and hidden state hi−1 to π
nn
.
We compute the cross-entropy loss based on the probabilities of
choosing the same function, arguments, sender and amount as in
ti
. Then, we execute ti and update the hidden state of the GRU
based on ti
. After re-executing all transactions in the sequence, we
perform back-propagation on the loss and jointly update weights
of all networks. As standard, we train on batches of sequences and
stop when all networks reach high classification accuracy.
5 THE ILF SYSTEM
We now present the ILF system which instantiates the neuralnetwork fuzzing policy described earlier. We first introduce our
feature representation for functions. Then, we present the symbolic
execution expert used to generate a training dataset. Finally, we
Table 2: Features that capture semantic information about a
function f for a given history of transactions t. Transaction
tlast denotes the last call to f in t.
Feature Description
Revert (1) Boolean, true if tlast ends with revert.
(2) Fraction of transactions in t that end with revert.
Assert (1) Boolean, true if tlast ends with assert.
(2) Fraction of transactions in t that end with assert.
Return (1) Boolean, true if tlast ends with return.
(2) Fraction of transactions in t that end with return.
Transaction Fraction of transactions in t that calls f .
Coverage (1) Instruction and basic block coverage of the contract.
(2) Instruction and basic block coverage of f .
Arguments (1) Number of arguments of f .
(2) Number of arguments of type address.
Opcodes 50 most representative opcodes in f .
Name Word embedding of f ’s name.
discuss the detection of critical vulnerabilities in smart contracts
during fuzzing.
5.1 Feature Representation of Functions
In Table 2 we present semantic features for functions which we use
as an input to neural networks. Each feature is derived for a given
function f and history of transactions t.
The top three features capture important information about the
success of the last call to f and over all calls to f in a history of
transactions t. For example, if the last call to f has reverted or
many calls to f in t have reverted, this indicates that f ’s arguments
are more likely to violate the pre-conditions of function f . In both
cases, f should be given more importance to improve coverage.
Feature Transaction measures the fraction of transactions that call f .
Feature Coverage captures the current contract coverage and the
coverage gain by calling f .
The last three features characterize properties of f . In order to
select effective function arguments x, we define feature Arguments.
Feature Opcodes returns a vector with counts of 50 distinctive opcodes in f , measuring the functionality and complexity of f . To
select the 50 distinctive opcodes, we excluded commonly used opcodes, such as those used for arithmetic and stack operations. The
50 opcodes are listed in Appendix A. Feature Name encodes the
function’s name. To derive this feature, we tokenize f ’s name into
separate sub-tokens, according to camelCase and pascal_case; cf. [5],
and then map each sub-token into word2vec word embedding [41].
We average the embeddings of sub-tokens to obtain the final embedding, resulting in a 300-dimensional vector. Feature Name can
capture the semantic meaning of functions (e.g., getters and setters).
Based on these features, we define αs , which extracts the semantic feature matrix αs (F,t) from (public and external) functions of
the tested contract F and history of transactions t.
Embedding via a Graph Convolutional Network. To capture
dependencies between functions, we employ a Graph Convolutional
Network (GCN) [35]. We construct a graph д where each function
in F is represented by a node, and an edge (f , f
′
) captures that
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 537
Algorithm 1: Algorithm for running expert policy π
expert
.
1 Procedure RunExpert(c)
Input :Contract c
2 Q ← {binit }
3 while Q.size() > 0 do
4 b ← Q.pop()
5 DfsFuzz(b, Q, c)
6 Procedure DfsFuzz(b, Q, c)
Input :Block state b
Priority queue Q of block states
Contract c
7 t ← Txs(b)
8 t ← π
expert(t)
9 if t , ⊥ then
10 b
′ ← Execute(t, b, c)
11 DfsFuzz(b
′
, Q, c)
12 Q.push(b)
the sets of reads and writes in f and f
′ may overlap (indicating
a dependency). We use this graph to further embed the functions’
semantic information αs (F,t) as follows:
α(F,t) = GCN(αs (F,t),д)
whereGCN : R
|F |×l ×G → R
|F |×m transforms the semantic feature
matrix into an embedding matrix. The embedding matrix α(F,t) is
then used as input to π
nn as described in Section 4.2. We note that
the GCN is treated as an intermediate layer between the extracted
input features αs (F,t) and π
nn, and is trained jointly with π
nn. For
more details on how the GCN is used, see Appendix B.
5.2 Symbolic Execution Expert
Now we discuss the challenge of scaling symbolic execution on
smart contracts and design of our practical symbolic expert.
Challenges of Scaling Symbolic Execution. An ideal expert
would analyze multiple transactions fully symbolically and choose
sequences of concrete transactions that achieve high coverage. Concretely, to fully analyze all behaviors reached by one transaction
from the initial block state binit, one can execute the contract symbolically (assuming symbolic transaction) to compute the symbolic
states at the end of the transaction. This results in symbolic block
states φ
1
1
(T1), . . . ,φ
1
n
(T1), where T1 is the symbolic transaction and
n is determined by the number of paths in the contract. Then, to
analyze all behaviors that can be reached within two transactions,
we symbolically execute the contract from each symbolic state
φ
1
i
(T1), resulting in symbolic block states φ
2
1
(T1,T2), . . . ,φ
2
m(T1,T2),
whereT1 andT2 are the first and second symbolic transactions. Such
scheme can continue to depth k of analyzed symbolic transactions.
Unfortunately, the above approach does not scale due to its
exponential time complexity (as stated in Section 2.2). To measure
its scalability in practice, we randomly selected 100 small contracts
(with <3K instructions) and 100 large ones (with ≥3K instructions)
from our dataset. We then measured how many of the selected
contracts can be analyzed using symbolic execution (as described
Depth 1 Depth 2 Depth 3 Depth 4
0
20
40
60
80
100
100 98
63
49
96
81
41
20
Number of Contracts Small Contracts (<3K instructions)
Large Contracts (≥3K instructions)
Figure 5: Number of contracts that can be fully analyzed
symbolically at different transaction depths within 3 days.
above) for different depths k within 3 days. We plot the results in
Figure 5. The data shows that symbolic reasoning about all states
reachable within 1 transaction is feasible: all small contracts and
96 of the large ones can be analyzed at depth 1. However, only 20
of the big contracts can be fully analyzed symbolically at depth 4.
Aware of the above scalability issue, we design a practical symbolic execution expert π
expert that iteratively constructs a sequence
of transactions by running the contract symbolically for a single
transaction and selecting a concrete one to optimize coverage. We
next describe our symbolic expert.
Expert Policy. Given a sequence of concrete transactions t, our
expert policy π
expert(t) symbolically executes the contract from
the current concrete block state (i.e., the block state reached when
running t at binit), selects a feasible path that improves coverage
the most (if any), runs a constraint solver to generate a concrete
transaction t following that path, and returns t. If no transaction
can improve coverage at the current block state, then π
expert(t) = ⊥.
We use the symbolic execution engine of VerX [46] to symbolically
execute the contract and construct the transaction t.
Running the Expert Policy. In Algorithm 1, we define the procedure for running our expert policy π
expert on a target contract c.
The entry procedure, RunExpert, maintains a priority queue Q of
observed block states, ranked by the coverage improvement that
the expert policy π
expert can achieve by generating a new transaction for a given block state. Initially, Q contains the initial block
state binit. At every loop iteration (Line 3), RunExpert pops a block
state b from Q (Line 4) and runs DfsFuzz (Line 5), until no observed
block states can further improve coverage (i.e. until Q is empty).
The procedure DfsFuzz constructs a sequence of transactions
in a depth-first manner, where each transaction strictly improves
coverage. First, the procedure obtains the sequence of concrete
transactions t = Txs(b) that results in reaching the current block
state b and runs the expert policy π
expert(t), which either returns
a transaction t that improves coverage or ⊥ (indicating that no
transaction improves coverage). If coverage can be improved, the
new transaction t is executed at the current block state b (Line 10),
resulting in a new block state b
′
. DfsFuzz is recursively invoked
with b
′
, to generate another transaction that may further improve
coverage. Every block state b encountered by DfsFuzz is pushed to
Q so that it can be considered again by RunExpert for generating
different sequences of transactions.
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 538
binit t1
π
expert
b1
t2
π
expert
b2 Execute Execute
. . .
Figure 6: Example run of RunExpert in Algorithm 1.
Squares represent block states. Circles and circles represent generated and unselected transactions, respectively.
Solid lines represent covered paths, dashed lines uncovered
paths, and arrows represent block state transitions.
In Figure 6, we show an example run of RunExpert. First, DfsFuzz is executed with the initial block state binit as argument. Policy π
expert considers 3 paths and returns the transaction t1 along
the feasible path improving coverage the most. t1 is executed and
transitions the contract to block state b1. At block state b1, π
expert
considers 4 paths that improve coverage and generates t2, which
transitions the contract to b2. Note that t1,t2, . . . correspond to
the sequence of transactions generated by π
expert. Further, DfsFuzz appends all observed block states binit,b1,b2, . . ., which are
all considered by RunExpert for generating different sequences.
Generating Transaction Sequences for Learning. For each
contract cd
in the training set, we use RunExpert (Algorithm 1) to
generate transactions while keeping track of features αs . We select
the longest sequence [(αs (F,ti),ti)]d where αs (F,ti) is a feature
matrix and ti
is produced by running π
expert on bi−1 (the block
state induced by ti
). This is usually the first sequence produced by
DfsFuzz. Then a generated dataset D =

[(αs (F,ti),ti)]d
	 |D |
d=1
can
be used for learning π
nn as described in Section 4.2.
Learning Seed Integers and Amounts. As mentioned in Section 4.2, we sample integer arguments from a set of seeds SI. We
construct this set by selecting top-K most frequently used integers
in D produced by π
expert solving SMT constraints. The set of seed
amounts SA is constructed similarly. We provide examples of SI
and SA and their appearance counts in Appendix D.
5.3 Vulnerability Detection
We have adapted from [32, 42] six detectors that identify critical
vulnerabilities of smart contracts. They are presented in Table 3
with a brief description and elaborated further in Appendix C. We
note that more detectors can be easily added. We have implemented
a fast dataflow analysis based on backward slicing over concrete
execution traces, which was required by some detectors.
6 EXPERIMENTAL EVALUATION
In this section we present an extensive experimental evaluation of
ILF, addressing the following questions:
• Coverage: Does ILF achieve higher coverage than other fuzzers?
• Vulnerability Detection: Does ILF discover more vulnerabilities than other security tools for Ethereum?
• Components: Are ILF’s components relevant for its performance in terms of coverage and vulnerability detection?
Apart from answering these questions, we report three case studies.
Table 3: ILF’s vulnerability detectors. An attacker for Leaking and Suicidal is an untrusted user who exploits the vulnerability but never sends ether to the contract. See Appendix C for detailed definitions of the detectors.
Vulnerability Description
Locking [42] The contract cannot send out but can receive ether.
Leaking [42] An attacker can steal ether from the contract.
Suicidal [42] An attacker can deconstruct the contract.
Block [32]
Dependency
The contract’s ether transfer depends on block state
variables (e.g., timestamp).
Unhandled
Exception [32]
Root call of the contract does not catch exceptions from child calls.
Controlled
Delegatecall [32]
Transaction parameters explicitly flow into arguments of a delegatecall instruction.
6.1 Implementation
Our transaction execution backend is implemented on top of Go
Ethereum [20]. Instead of performing RPC calls, ILF sends transactions natively to achieve fast execution. Neural Networks (NNs) in
π
nn are implemented using Pytorch [2]. Sizes of all hidden layers in
NNs of π
nn are set to 100 and all FCNs use ReLU as activation functions. After obtaining a training dataset from our expert, we train
ILF as described in Section 4.2 for 20 epochs, which takes around
2h on a single GPU. ILF uses 5 senders for fuzzing (3 trusted users,
and 2 attackers) which proved to be sufficient in our experiments
(more senders do not improve fuzzing). We set the sizes of the seed
integer set SI and seed amount set SA both to 50 (examples are
shown in Appendix D). A heuristic reverting the blockchain to the
initial block state binit after every 50 transactions is added when
running π
nn and π
unif so to avoid getting stuck in a locked state.
6.2 Evaluation Setup
We first describe our experimental setup.
Baselines. In our experiments, we compare ILF to the baselines
and existing tools listed in Table 4. For existing tools, we select
those that report coverage or support more than one of ILF’s detectors. Unif and Expert use fuzzing policies π
unif and π
expert
,
respectively. Echidna [17] reports coverage but does not implement any detectors. ContractFuzzer [32] and Maian [42] each
support three of ILF’s detectors but do not report coverage.
Dataset. We obtain our dataset by crawling Etherscan verified
contracts [19], real-world contracts deployed on Ethereum mainnet.
We removed 7, 799 duplicates by computing the hash of the contracts’ source and bytecode. We filtered contracts which failed to
deploy or contain hardcoded addresses to contracts not present in
our dataset. Our final dataset contains 18, 496 contracts. To examine
the coverage of contracts with different sizes, we split the dataset
into 5, 013 large contracts (≥3K instructions) and 13, 483 small ones
(<3K instructions). Table 5 presents statistics of our dataset. Note
that we add the contracts (if any) that can interact with the target
contract to the local test blockchain. Those contracts are identified
by constructor arguments of the target contract.
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 539
Table 4: Baselines and detectors in common with ILF.
Baseline Type Coverage Detectors
Unif (π
unif ) Fuzzer ✓ All
Expert (π
expert) Symbolic ✓ None
Echidna1
[17] Fuzzer ✓ None
Maian [42] Symbolic ✗ LO, LE, SU
ContractFuzzer2
[32] Fuzzer ✗ BD, UE, CD
1 Latest commit that reports coverage: d93c226b2ad4ff884f33faa850d7d36556c12211.
2 We ignore the LO detector of ContractFuzzer as we found a major bug there.
Table 5: Statistics on our dataset, showing the average numbers of: lines of source code, bytecode instructions, control
flow blocks, functions, and payable functions.
Dataset Source Instr. Block Func. Payable
Overall 227 2719 181 17 0.6
Small 165 2026 131 13 0.4
Large 392 4585 317 27 1.0
Experiments. In our experiments, we perform a standard 5-fold
cross validation: we randomly split the entire dataset into five equal
folds and each time we pick one fold as the testing set and use
the remaining four as the training set. We repeat this training and
testing procedure five times on the five different splits and report
testing results on the entire dataset.
We ran Expert (with 3h limit for each contract) and ContractFuzzer on a server with 512 GB memory and two 2.2 GHz AMD
EPYC 7601 CPUs (64 cores and 128 threads in total). Expert spent
76h and ContractFuzzer spent 62h to run on the entire dataset
(with massive parallelization). All other experiments were done on
a desktop with 64 GB memory, one 4.2 GHz Intel Core i7-7700K
CPU (8 cores and 8 threads) and two Geforce GTX 1080 GPUs.
6.3 Code Coverage
We now present evaluation results on code coverage. We measure
instruction and basic block coverage. In this section, we report
instruction coverage. The results on basic block coverage are similar
and can be found in Appendix E. In the following, we first compare
ILF with fuzzers (Unif and Echidna), and then Expert.
Comparing ILF to Fuzzers. We present coverage of ILF, Unif,
and Echidna on small contracts in Figure 7 and on big contracts in
Figure 8. We plot it in the number of transactions (up to 1K). ILF
consistently outperforms Unif and Echidna. On small contracts,
ILF achieves 94% coverage, 16% higher than Unif and 24% higher
than Echidna. On large contracts, ILF achieves 87%, 16% and 33%
higher than Unif and Echidna, respectively. Echidna did not
perform well because it models EVM incompletely (e.g., we found it
uses one sender and does not model msg.value) and exited with error
on 811 contracts (reporting 0% coverage). Note that the coverage on
the 4.3% contracts cannot significantly impact the results. Overall,
ILF, Unif and Echidna are fast - to fuzz 1K transactions, they spent
7s, 4s, and 6s, respectively, on average per contract.
Comparing ILF to the Symbolic Expert. In Figure 9, we compare ILF with Expert (which ILF learns to imitate). On average,
Expert spent 30 transactions to achieve 90% coverage on small
0 200 400 600 800 1000
0%
20%
40%
60%
80%
100%
Number of Transactions
Instr. Coverage
ILF
Unif
Echidna
Figure 7: Instruction coverage on small contracts.
0 200 400 600 800 1000
0%
20%
40%
60%
80%
100%
Number of Transactions
Instr. Coverage
ILF
Unif
Echidna
Figure 8: Instruction coverage on large contracts.
Small
Contracts
Large
Contracts
50%
60%
70%
80%
90%
100%
90%
68%
82%
57%
94%
87%
Instr. Coverage
Expert
ILF (#txs=Expert)
ILF (2000 txs)
Figure 9: Instruction coverage of Expert and ILF.
contracts. On large contracts, it spent 49 transactions to get 68%.
Compared to Expert, when ILF ran the same number of transactions, it achieves 8% lower coverage on small contracts and 11%
lower coverage on large contracts. This is expected, as Expert is
powerful (i.e., it improves coverage at every transaction).
However, Expert is slow — it took on average 547s (on small
contracts) and 2, 580s (on big contracts) for Expert to achieve the
coverage levels in Figure 9. We also ran ILF for 2K transactions
(only spending 13s on small contracts and 17s on big contracts). In
this case, ILF outperforms Expert by 4% on small contracts and 19%
on large contracts. We found Expert times out more often on large
contracts and thus achieves lower coverage. This indicates that ILF
has the advantage of generating transactions orders of magnitude
faster than Expert and thus covers more code than Expert within
a reasonable amount of time.
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 540
Leaking
(|GT| = 302)
Suicidal
(|GT| = 28)
Locking
(|GT| = 64)
Block
Dependency
(|GT| = 799)
Unhandled
Exception
(|GT| = 90)
Controlled
Delegatecall
(|GT| = 18)
0%
20%
40%
60%
80%
100% 91%
86%
98%
93%
86%
100%
44%
71%
77%
50% 47%
94%
20% 21%
0%
48%
29%
80%
Percentage of True Vulnerabilities
ILF
Unif
Maian
ContractFuzzer
Figure 10: Fraction of true vulnerabilities found by each individual system. The number of ground truth vulnerabilities, which
are computed as the union of all true vulnerabilities detected by each system, are shown under the x-tick labels.
6.4 Vulnerability Detection
We ran ILF, Unif, Maian and ContractFuzzer for detecting vulnerabilities in our dataset. We first describe the setup for running
these tools and report their speed. Then, we describe how we obtain
the ground truth of vulnerabilities. Finally, we compare ILF with
each individual tool on vulnerability detection.
Setup and Speed. ILF and Unif ran for 2K transactions on each
contract, spending on average 14s and, respectively, 8s. ContractFuzzer fuzzes a set of contracts together. We ran it on our whole
dataset with 40 threads until it exited automatically, which spent
62h. Maian detects each vulnerability in separate runs. It spent
(with default depth 3) on average 61s, 15s and 13s to detect Leaking,
Suicidal and Locking, respectively, on each contract.
Obtaining Ground Truth of Vulnerabilities. The detectors in
ILF and Unif report only true positives. For Leaking and Suicidal,
Maian concretely validates exploits produced by symbolic execution to filter false positives and then reports only true positives.
For Locking, it may report false positives. ContractFuzzer produces only true positives on Unhandled Exception and Controlled
Delegatecall but can have false positives on Block Dependency.
By manual inspection, we found that Maian reports 13 false positives for Locking and ContractFuzzer produces 6 false positives
for Block Dependency. We take the union of all true vulnerabilities
found by each system as ground truth and report the fraction of
each system (over the ground truth). Figure 10 shows our results,
indicating that ILF outperforms all other systems on all types of
vulnerabilities. We next compare ILF to each individual system.
Comparing ILF to Uniformly Random Baseline. ILF finds on
average 43% more Leaking, Block Dependency, and Unhandled
Exception vulnerabilities than Unif. ILF also improves over Unif
on the other vulnerabilities: 15% on Suicidal, 22% on Locking, and
6% on Controlled Delegatecall. By inspection, we found that ILF
triggers more ether transfers, which results in detecting 47% more
Leaking and 43% more Block Dependency vulnerabilities than Unif.
Comparing ILF to a Symbolic Execution Detector. We now
compare ILF to Maian. ILF detects 43% more Leaking vulnerabilities than Maian. Inspection indicates that Maian’s false negatives
are mostly because (i) it fails to send ether to those contracts or (ii)
it stops before the required depth to trigger the vulnerabilities. For
Suicidal, ILF detects 86%, while Maian detects 29%. Maian does
Coverage Leaking
(|ILF|= 276)
50%
60%
70%
80%
90%
100% 92%
100%
91%
84%
80%
64%
92% 92% 93%
86%
ILF ILFunif
func ILFunif
args ILFunif
sender ILFunif
amount
Figure 11: Comparison between ILF and the four baselines
with components replaced by their counterparts in Unif.
not report some vulnerabilities that can be revealed within 3 transactions (i.e., it fails to explore some paths at depth 3). ILF detects
18% more Locking vulnerabilities than Maian. Maian reports 29
false positives out of the total 80 Locking reports.
Comparing ILF to an Existing Fuzzer. We now compare ILF to
ContractFuzzer. Overall, ILF finds substantially more vulnerabilities than ContractFuzzer. This is likely because the randomly
generated transactions by ContractFuzzer fail to cover vulnerable code, unlike ILF which uses its learned strategies to explore
the code. ContractFuzzer generates 6 false positives for Block
Dependency because its detection rule syntactically checks for the
existence of ether transfer and block state variables in the trace,
while ILF uses a semantic dataflow check.
6.5 Importance of Policy Components
We now evaluate the relevance of components π
nn
func, π
nn
args, π
nn
sender
and π
nn
amount used in ILF’s fuzzing policy. We show four additional
baselines in Figure 11, where each baseline replaces one component
in ILF with its counterpart in Unif. For example, ILFunif
func replaces
π
nn
func with π
unif
func while keeping the other three intact. We compare
ILF with the additional baselines in terms of coverage and the number of Leaking vulnerabilities detected after 2K transactions (ILF
detects 276). We decide on this vulnerability as it usually involves
multiple transactions. Our results show that π
nn
args is required for
achieving high coverage and critical for detecting the Leaking vulnerability. The remaining three baselines are all sub-optimal in
detecting the Leaking vulnerability.
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 541
1 contract Grid {
2 struct Pixel { address owner ; uint256 price ; }
3 address admin ;
4 mapping ( address = > uint256 ) pending ;
5 Pixel [1000][1000] pixels
6 uint256 public defaultPrice ;
7
8 function Grid () public {
9 admin = msg . sender ;
10 defaultPrice = 2 * 10 ** 15;
11 }
12 function setDefaultPrice ( uint256 price ) public {
13 require ( admin == msg . sender );
14 defaultPrice = price ;
15 }
16 function buyPixel ( uint16 row , uint16 col )
17 public payable {
18 var ( owner , price ) = getPixelInfo ( id );
19 require ( msg . value >= price );
20 pending [ owner ] += msg. value ;
21 pixels [ row ][ col ]. owner = msg . sender ;
22 }
23 function withdraw () public {
24 uint256 amount = pending [ msg . sender ];
25 pending [ msg . sender ] = 0;
26 msg . sender . transfer ( amount );
27 }
28 function getPixelInfo ( uint16 row , uint16 col )
29 public returns ( address , uint256 ) {
30 Pixel pixel = pixels [ row ][ col ];
31 if ( pixel . owner == 0) return ( admin , defaultPrice );
32 return ( pixel . owner , pixel . price );
33 }
34 }
Figure 12: A contract (simplified2
) where ILF achieves high
coverage and detects a new Leaking vulnerability.
6.6 Case Studies
We now present three case studies. The first one gives insights on
how ILF achieves high coverage and detects a Leaking vulnerability.
The second one illustrates a false negative of ILF in detecting a
Leaking vulnerability. Finally, in the third case study, we show a
contract where ILF achieves lower coverage than Expert.
Illustrating Fuzzing Strategy of ILF. Figure 12 shows a contract
where ILF achieves 98% coverage (Unif and Echidna achieve 57%
and 59%, respectively). Function getPixelInfo has an if condition
pixel.owner == 0 at Line 31. If the condition holds, the pixel does not
exist and default values are returned. Otherwise, the pixel’s owner
and price are returned (Line 32). To cover Line 32, one must call
buyPixel beforehand to create a pixel and reuse values of arguments
row and col to call getPixelInfo. Unif and Echidna fail to cover
Line 32 because they generate arguments of type uint16 uniformly
at random which makes it almost unlikely to reuse values for row
and col. ILF, however, samples integer arguments from a probability
distributions over a set of seed integers, and this distribution assigns
more weights to certain values (e.g., 0 and 1). We also inspected ILF’s
probability distributions over functions. We found that it initially
assigns almost equal probabilities to all functions. Later during the
fuzzing process, ILF gradually assigns lower probability (e.g., less
than 0.001) to simpler functions, such as defaultPrice, and higher
2https://etherscan.io/address/0x9d6cde970c30e45311cff3d1f3f9a8dd24ff70f1#code
1 contract TransferableMultsigImpl {
2 function () payable public {}
3 function execute ( uint8 [] sigV , bytes32 [] sigR ,
4 bytes32 [] sigS , address destination ,
5 uint val , bytes data ) external {
6 bytes32 txHash = keccak256 (...);
7 verifySignatures ( sigV , sigR , sigS , txHash );
8 require ( destination . call . value ( val )( data ));
9 }
10 function verifySignatures (
11 uint8 [] sigV , bytes32 [] sigR ,
12 bytes32 [] sigS , bytes32 txHash ) internal {
13 ... // complex operations and requires
14 }
15 }
Figure 13: A false negative (simplified version3
) in detecting
a Leaking vulnerability.
1 contract ProjectKudos {
2 uint256 voteStart ;
3 uint256 voteEnd ;
4 function ProjectKudos () {
5 voteStart = 1479996000; // GMT : 24 - Nov -2016 14:00
6 voteEnd = 1482415200; // GMT : 22 - Dec -2016 14:00
7 }
8 function giveKudos ( bytes32 projectCode , uint kudos ) {
9 if ( now < voteStart ) throw ;
10 if ( now >= voteEnd ) throw ;
11 ... // other operations
12 }
13 }
Figure 14: An example contract (simplified version4
) where
ILF achieves lower coverage than Expert.
probability (e.g., more than 0.1) to more complex functions such as
getPixelInfo and buyPixel.
In addition to achieving high coverage on this example, ILF also
exposes a Leaking vulnerability not found by Maian and Unif. A
sequence of transactions exposing the vulnerability is:
t1: admin calls setDefaultPrice(0) making the contract vulnerable.
t2: An attacker calls buyPixel(1, 2) with msg.value = 0.
t3: A user (not the attacker) calls buyPixel(1, 2) with msg.value > 0.
t4: The attacker calls withdraw to steal earned ether from the user.
A False Negative on Detecting Leaking Vulnerability. In Figure 13, we present a contract with Leaking vulnerability which is
detected by Maian but not by ILF. An attacker can call function
execute with argument destination set to the attacker’s address to
steal ether. To ensure success of the call, its arguments must satisfy
the complex constraints imposed by the call to verifySignatures. ILF
failed to generate such arguments.
A Contract Where ILF Achieves Lower Coverage Than Expert. In Figure 14 we show a contract where Expert achieves
95% instruction coverage while ILF achieves only 74%. Function
giveKudos requires the block’s timestamp (returned by now) to be set
to a value in [voteStart, voteEnd). However, voteStart and voteEnd are
contract-specific values defined by the constructor of the contract,
which ILF can hardly learn.
3https://etherscan.io/address/0x38c1908487de0b82e9ed6d416bc50d5ab08eac75#code
4https://etherscan.io/address/0x5e569e1ecd56fe30dd97ee233ec1675b60fb6680#code
Session 3A: Fuzzing: Methods and Applications CCS ’19, November 11–15, 2019, London, United Kingdom 542
7 DISCUSSION
Now we discuss ILF’s limitations and potential future improvement.
Handling Contracts with Unique Functionality. ILF is effective under the assumption that most contracts have similar functionality [34]. However, some contracts implement unique functionality
not appearing in other contracts (e.g., the contracts in Figure 13
and Figure 14 have contract-specific arguments and variables).
While the learned fuzzer has limited effectiveness in dealing with
unseen functionality, symbolic execution can effectively handle custom constraints. To this end, we propose a new policy π
mix , that
combines π
nn and π
expert as a preliminary solution for handling unseen functionality. The goal of π
mix is to combine the strengths of
the learned and the expert policies: π
nn is fast at handling functionality similar to that in the dataset, while π
expert is slow but effective
at handling unseen functionality. To generate a transaction, π
mix
runs π
expert with probability p and π
nn with probability 1 − p. The
algorithm for running π
mix is defined in Appendix F.
We evaluate π
mix on 59 contracts in our dataset where Expert
achieves >20% higher coverage than ILF. We inspected those contracts and confirmed that they all have unseen functionality. We
ran π
mix on the 59 contracts with a timeout of 20m per contract
and p set to 0.1. On average, π
mix achieves 73% coverage using
230s (π
nn used by ILF achieves 57% using 14s). Moreover, π
mix
discovers 9 more Block Dependency vulnerabilities than π
nn
.
Handling Contract Interaction. Ethereum smart contracts often have interaction by calling each other. ILF supports fuzzing
multiple interacting contracts that are deployed on the local test
blockchain. We note, however, that dependencies between the interacting contracts are not considered when generating transactions.
At each step, ILF samples a contract uniformly at random and
generates a transaction for the sampled contract with π
nn, which
considers only the state of the sampled contract and ignores the
other contracts. For fuzzing a set of interacting contracts, the probability distribution for generating transactions needs to be defined
over multiple contracts. Using the framework of imitation learning, one can extend ILF with a neural policy for selecting a target
contract before generating a transaction. To support such a policy,
a revised neural network architecture handling contract selection
and new features abstracting contract interaction are needed.
8 RELATED WORK
We now discuss the works that are most closely related to ours.
Fuzz Testing. Numerous techniques for fuzz testing have been
proposed in prior work. White-box fuzzing techniques leverage
symbolic/concolic execution [13, 14, 52, 67] to solve path constraints and generate effective inputs. NEUEX [54] leverages neural
constraints to capture dependencies between program variables
and approximate exact symbolic constraints. Generation-based
fuzzers create inputs based on input specifications which can be
defined with a grammar [21, 30, 38, 66], or learned from a given corpus [10, 23, 31, 64]. Mutation-based fuzzers [15, 39, 45, 48, 59, 63, 68]
mutate initial seeds to craft new inputs that may expose vulnerabilities. Static analysis [39, 48], taint analysis [15, 48], and symbolic/-
concolic execution [45, 59] are used to guide mutation processes.
Recent years have witnessed an interest in improving fuzzing
with machine learning. Several works [18, 23, 64] learn generative
models from existing input corpus. AFLFast [12] and NEUZZ [53]
model program branching behavior using Markov Chains and NNs,
respectively, learned from inputs generated during fuzzing. Unfortunately, their models may not be ideal as the datasets used for
training are sub-optimal. In contrast, our training dataset generated
using symbolic execution is high-quality.
Security Analysis of Smart Contracts. A number of systems
have been proposed for detecting vulnerabilities in smart contracts.
Static analysis systems based on Datalog [24, 62] or the LLVM analysis engine [33] provide soundness guarantee but can have false
positives and do not generate exploits. Erays [69] is a reverse engineering tool producing high-level pseudocode from EVM bytecode
to help security inspection. Grossman et al. [25] specifically detect
reentrancy through dynamic linearization checker.
Symbolic execution has been widely applied to smart contract
security. Oyente [40] is the first symbolic engine to detect vulnerabilities. Osiris [61] detects integer bugs. However, they cannot
deal with multiple transactions. teEther [37] (only detects Leaking)
and Maian [42] can generate exploits over multiple transactions.
However, they are limited to a small depth (e.g., 3).Our learned
fuzzer explores deep states rapidly to locate vulnerabilities.
Several works have studied formal verification of smart contracts.
KEVM [28] is an executable formal specification of EVM bytecode
in the K Framework [50]. The authors of [11] and [6, 29] formulate smart contracts in F* and the Isabelle/HOL proof assistant,
respectively. VerX [46] is the first automated verifier for proving
functional properties of contracts.
Machine Learning for Security. Machine learning methods have
been applied in various aspects of computer security. Bao et al. [9]
and Shin et al. [55] learn to recognize functions in stripped binaries. Debin [26] leverages ensemble tree models and probabilistic
graphical models to predict debug information for stripped binaries.
Naive Bayes, GRU and convolutional networks have been used in
malware classification [7, 36, 51].
Reinforcement learning has been applied on various programming language tasks, such as speeding up numerical program analysis [58] and SMT solvers [8], inferring loop invariants for program
verification [56], and program reduction [27]. While those works
treat their problems as MDP, they do not learn from an expert. Our
work instead formulates fuzzing as an MDP and learns a policy by
imitating a symbolic execution expert.
9 CONCLUSION
We presented a new approach for learning a fuzzer from symbolic
execution and instantiated it to the domain of smart contracts. The
key idea was to learn a fuzzing policy, represented using neural
networks, which is trained over a high-quality dataset of inputs
generated using a symbolic execution expert. The learned policy is
then used to generate inputs for fuzzing unseen smart contracts. We
implemented our method in a system called ILF and showed that
it is fast and achieves high code coverage on real-world contracts.
The high coverage facilitates and improves the detection of critical
vulnerabilities, outperforming existing tools.