As network security monitoring grows more sophisticated, there
is an increasing need for outsourcing such tasks to third-party
analysts. However, organizations are usually reluctant to share their
network traces due to privacy concerns over sensitive information,
e.g., network and system configuration, which may potentially be
exploited for attacks. In cases where data owners are convinced
to share their network traces, the data are typically subjected to
certain anonymization techniques, e.g., CryptoPAn, which replaces
real IP addresses with prefix-preserving pseudonyms. However,
most such techniques either are vulnerable to adversaries with
prior knowledge about some network flows in the traces, or require
heavy data sanitization or perturbation, both of which may result
in a significant loss of data utility. In this paper, we aim to preserve
both privacy and utility through shifting the trade-off from between
privacy and utility to between privacy and computational cost.
The key idea is for the analysts to generate and analyze multiple
anonymized views of the original network traces; those views are
designed to be sufficiently indistinguishable even to adversaries
armed with prior knowledge, which preserves the privacy, whereas
one of the views will yield true analysis results privately retrieved
by the data owner, which preserves the utility. We formally analyze
the privacy of our solution and experimentally evaluate it using real
network traces provided by a major ISP. The results show that our
approach can significantly reduce the level of information leakage
(e.g., less than 1% of the information leaked by CryptoPAn) with
comparable utility.
CCS CONCEPTS
â€¢ Security and privacy â†’ Privacy-preserving protocols;
KEYWORDS
Network Trace Anonymization, CryptoPAn, Semantic Attacks
1 INTRODUCTION
As the owners of large-scale network data, todayâ€™s ISPs and enterprises usually face a dilemma. As security monitoring and analytics
grow more sophisticated, there is an increasing need for those
organizations to outsource such tasks together with necessary network data to third-party analysts, e.g., Managed Security Service
Providers (MSSPs) [1]. On the other hand, those organizations are
typically reluctant to share their network trace data with third parties, and even less willing to publish them, mainly due to privacy
concerns over sensitive information contained in such data. For
example, important network configuration information, such as
potential bottlenecks of the network, may be inferred from network
traces and subsequently exploited by adversaries to increase the
impact of a denial of service attack [2].
In cases where data owners are convinced to share their network
traces, the traces are typically subjected to some anonymization
techniques. The anonymization of network traces has attracted
significant attention (a more detailed review of related works will
be given in section 6). For instance, CryptoPAn replaces real IP
addresses inside network flows with prefix preserving pseudonyms,
such that the hierarchical relationships among those addresses
will be preserved to facilitate analyses [3]. Specifically, any two IP
addresses sharing a prefix in the original trace will also do so in the
anonymized trace. However, CryptoPAn is known to be vulnerable
to the so-called fingerprinting attack and injection attack [4â€“6].
In those attacks, adversaries either already know some network
flows in the original traces (by observing the network or from
other relevant sources, e.g., DNS and WHOIS databases) [7], or
have deliberately injected some forged flows into such traces. By
recognizing those known flows in the anonymized traces based on
unchanged fields of the flows, namely, fingerprints (e.g., timestamps
and protocols), the adversaries can extrapolate their knowledge to
recognize other flows based on the shared prefixes [4]. We now
demonstrate such an attack in details.
Example 1.1. In Figure 1, the upper table shows the original trace,
and the lower shows the trace anonymized using CryptoPAn. In this
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 459
example, without loss of generality, we only focus on source IPs. Inside
each table, similar prefixes are highlighted through similar shading.
Original Trace
Start Time Src
Port
Dst
Port
P Pkts ScrIPaddr
10:23:42:50 902 600 UDP 6 10.1.1.0
10:23:42:53 901 2000 UDP 8 150.10.10.1
10:23:43:54 900 63 UDP 10 128.10.10.1
10:53:42:54 800 1900 TCP 2 10.1.1.0
10:53:42:55 750 2330 TCP 1 150.10.1.0
10:53:42:56 220 591 TCP 1 150.10.20.0
10:53:42:57 22 2600 TCP 1 10.1.1.0
CryptoPAn Output
Start Time Src
Port
Dst
Port
P Pkts ScrIPaddr
10:23:42:50 902 600 UDP 6 117.14.242.125
10:23:42:53 901 2000 UDP 8 159.61.5.252
10:23:43:54 900 63 UDP 10 135.243.4.124
10:53:42:54 800 1900 TCP 2 117.14.242.125
10:53:42:55 750 2330 TCP 1 159.61.13.126
10:53:42:56 220 591 TCP 1 159.61.20.124
10:53:42:57 22 2600 TCP 1 117.14.242.125
Step1:
Injecting flows
Step4:
De-anonymizing
IPs or prefixes
Step3:
Identifying more
flows via shared
prefixes
Step2:
Recognizing injected
flows via Start Time
and Src Port
Figure 1: An example of injection attack
(1) Step 1: An adversary has injected three network flows, shown
as the first three records in the original trace (upper table).
(2) Step 2: The adversary recognizes the three injected flows in the
anonymized trace (lower table) through unique combinations
of the unchanged attributes (Start Time and Src Port).
(3) Step 3: He/she can then extrapolate his/her knowledge from the
injected flows to real flows as follows, e.g., since prefix 159.61
is shared by the second (injected), fifth (real) and sixth (real)
flows, he/she knows all three must also share the same prefix in
the original trace. Such identified relationships between flows
in the two traces will be called matches from now on.
(4) Step 4: Finally, he/she can infer the prefixes or entire IPs of
those anonymized flows in the original traces, as he/she knows
the original IPs of his/her injected flows, e.g., the fifth and sixth
flows must have prefix 150.10, and the IPs of the fourth and
last flows must be 10.1.1.0.
More generally, a powerful adversary who can probe all the subnets
of a network using injection or fingerprinting can potentially deanonymize the entire CryptoPAn output via a more sophisticated
frequency analysis attack [4].
Most subsequent solutions either require heavy data sanitization
or can only support limited types of analysis (see section 6).
In this paper, we aim to preserve both privacy and utility by shifting the trade-off from between privacy and utility, as seen in most
existing works, to between privacy and computational cost (which
has seen a significant decrease lately, especially with the increasing
popularity of cloud technology). The key idea is for the data owner
to send enough information to the third party analysts such that
they can generate and analyze many different anonymized views of
the original network trace; those anonymized views are designed
to be sufficiently indistinguishable (which will be formally defined
in subsection 2.4) even to adversaries armed with prior knowledge
and performing the aforementioned attacks, which preserves the
privacy; at the same time, one of the anonymized views will yield
true analysis results, which will be privately retrieved by the data
owner or other authorized parties, which preserves the utility. More
specifically, our contributions are as follows.
(1) We propose a multi-view approach to the prefix-preserving
anonymization of network traces. To the best of our knowledge, this is the first known solution that can achieve similar
data utility as CryptoPAn does, while being robust against
the so-called semantic attacks (e.g., fingerprinting and injection). In addition, we believe the idea of shifting the trade-off
from between privacy and utility to between privacy and
computational cost may potentially be adapted to improve
other privacy solutions.
(2) In addition to the general multi-view approach, we detail a
concrete solution based on iteratively applying CryptoPAn
to each partition inside a network trace such that different
partitions are anonymized differently in all the views except
one (which yields valid analysis results that can be privately
retrieved by the data owner). In addition to privacy and
utility, we design the solution in such a way that only one
seed view needs to be sent to the analysts, which avoids
additional communication cost.
(3) We formally analyze the level of privacy guarantee achieved
using our method, discuss potential attacks and solutions,
and finally experimentally evaluate our solution using real
network traces from a major ISP. The experimental results
confirm that our solution is robust against semantic attacks
with a reasonable computational cost.
The rest of the paper is organized as follows: Section 2 defines our
models. Sections 3 introduces building blocks for our schemes. Section 4 details two concrete multi-view schemes based on CryptoPAn.
Sections 5 presents the experimental results. Section Appendix 4.3
provides more discussions, and section 6 reviews the related work.
Finally, section 7 concludes the paper.
2 MODELS
In this section, we describe models for the system and adversaries,
briefly review CryptoPAn, provide a high level overview of our
multi-view approach, and finally define our privacy property.
2.1 The System and Adversary Model
Denote by L a network trace comprised of a set of flows (or records)
ri
. Each flow includes a confidential multi-value attribute A
IP =
{IPsr c , IPdst }, and the set of other attributes A = {Ai } is called
the Fingerprint Quasi Identifier (fp-QI) [2]. Suppose the data owner
would like the analyst to perform an analysis on L to produce a
report Î“. To ensure privacy, instead of sending L, an anonymization
function T is applied to obtain an anonymized version Lâˆ—
. Thus, our
main objective is to find the anonymization function T to preserve
both the privacy, which means the analyst cannot obtain T or L
from Lâˆ—
, and utility, which means T must be prefix-preserving.
In this context, we make following assumptions (similar to those
found in most existing works [3â€“6]).
i) The adversary is a honest-but-curious analyst (in the sense
that he/she will exactly follow the approach) who can observe
Lâˆ—
. ii) The anonymization function T is publicly known, but the
corresponding anonymization key is not known by the adversary.
iii) The goal of the adversary is to find all possible matches (as
demonstrated in Example 1.1, an IP address may be matched to its
anonymized version either through the fp-QI or shared prefixes)
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 460
between L and Lâˆ—
. iv) Suppose L consists of d groups each of
which contains IP addresses with similar prefixes (e.g., those in the
same subset), and among these the adversary can successfully inject
or fingerprint Î± (â‰¤ d) groups (e.g., the demilitarized zone (DMZ) or
other subnets to which the adversary has access). Accordingly, we
say that the adversary has SÎ± knowledge. v) Finally, we assume
the communication between the data owner and the analyst is over
a secure channel, and we do not consider integrity or availability
issues (e.g., a malicious adversary may potentially alter or delete
the analysis report).
2.2 The CryptoPAn Model
To facilitate further discussions, we briefly review the CryptoPAn [3]
model, which gives a baseline for prefix-preserving anonymization.
Definition 2.1. Prefix-preserving Anonymization [3]: Given
two IP addresses a = a1a2....a32 and b = b1b2....b32, and a one-to-one
function F (.) : {0, 1}
32 â†’ {0, 1}
32, we say that
- a and b share a k-bit prefix (0 â‰¤ k â‰¤ 32), if and only if
a1a2....ak = b1b2....bk
, and ak+1 , bk+1
.
- F is prefix-preserving, if, for any a and b that share a k-bit
prefix, F (a) and F (b) also do so.
Given a = a1a2 Â· Â· Â· a32 and F (a) = a
â€²
1
a
â€²
2
. . . a
â€²
32, the prefixpreserving anonymization function F must necessarily satisfy the
canonical form [3], as follows.
a
â€²
i = ai âŠ• fiâˆ’1(a1a2 Â· Â· Â· aiâˆ’1), i = 1, 2, . . . , 32 (1)
where fi
is a cryptographic function which, based on a 256/128-
bit key K, takes as input a bit-string of length i âˆ’1 and returns a single bit. Intuitively, the i
th bit is anonymized based on K and the preceding iâˆ’1 bits to satisfy the prefix-preserving property. The cryptographic function fi can be constructed as L

R

P(a1a2 . . . aiâˆ’1),K


where L returns the least significant bit, R can be a block cipher
such as Rijndael [30], and P is a padding function that expands
a1, a2, . . . , aiâˆ’1 to match the block size of R [3]. In the following,
PP will stand for this CryptoPAn function and its output will be
denoted by a
â€² = PP(a,K).
The advantage of CryptoPAn is that it is deterministic and allows consistent prefix-preserving anonymization under the same
K. However, as mentioned earlier, CryptoPAn is vulnerable to semantic attacks, which will be addressed in next section.
2.3 The Multi-View Approach
We propose a novel multi-view approach to the prefix-preserving
anonymization of network traces. The objective is to preserve both
the privacy and the data utility, while being robust against semantic
attacks. The key idea is to hide a prefix-preserving anonymized
view, namely, the real view, among N âˆ’ 1 other fake views, such
that an adversary cannot distinguish between those N views, either
using his/her prior knowledge or through semantic attacks. Our
approach is depicted in Figure 2 and detailed below.
2.3.1 Privacy Preservation at the Data Owner Side.
Step 1: The data owner generates two CryptoPAn keys K0 and K1,
and then obtains an anonymized trace using the anonymization function PP (which will be represented by the gear icon
inside this figure) and K0. This initial anonymization step is
designed to prevent the analyst from simulating the process
as K0 will never be given out. Note that this anonymized
trace is still vulnerable to semantic attack and must undergo
the remaining steps. Besides, generating this anonymized
trace will actually be slightly more complicated due to migration as discussed later in Section 3.3.
Step 2: The anonymized trace is then partitioned (the partitioning
algorithms will be detailed in Sections 3.2 and 4).
Step 3: Each partition is anonymized using PP and key K1, but
the anonymization will be repeated, for a different number
of times, on different partitions. For example, as the figure
shows, the first partition is anonymized only once, whereas
the second for three times, etc. The result of this step is called
the seed trace. The idea is that, as illustrated by the different
graphic patterns inside the seed trace, different partitions
have been anonymized differently, and hence the seed trace
in its entirety is no longer prefix-preserving, even though
each partition is still prefix-preserving (note that this is only
a simplified demonstration of the seed trace generator scheme
which will be detailed in Section 4).
Step 4: The seed trace together with some supplementary parameters, including K1, are outsourced to the analyst.
2.3.2 Utility Realization at the Data Analyst Side.
Step 5: The analyst generates totally N views based on the received
seed view and supplementary parameters. Our design will
ensure one of those generated views, namely, the real view,
will have all its partitions anonymized in the same way, and
thus be prefix-preserving (detailed in Section 4), though the
analyst (adversary) cannot tell which exactly is the real view.
Step 6: The analyst performs the analysis on all the N views and
generates corresponding reports.
Step 7: The data owner retrieves the analysis report corresponding to the real view following an oblivious random access
memory (ORAM) protocol [23], such that the analyst cannot
learn which view has been retrieved.
Next, we define the privacy property for the multi-view solution.
2.4 Privacy Property against Adversaries
Under our multi-view approach, an analyst (adversary) will receive
N different traces with identical fp-QI attribute values and different
A
I P attribute values. Therefore, his/her goal now is to identify the
real view among all the views, e.g., he/she may attempt to observe
his/her injected or fingerprinted flows, or he/she can launch the
aforementioned semantic attacks on those views, hoping that the
real view might respond differently to those attacks. Therefore, the
main objective in designing an effective multi-view solution is to
satisfy the indistinguishability property which means the real view
must be sufficiently indistinguishable from the fake views under semantic attacks. Motivated by the concept of Differential Privacy [37],
we propose the Ïµ-indisinguishablity property as follows.
Definition 2.2. Ïµ-Indisinguishable Views: A multi-view solution satisfies Ïµ-Indistinguishability against an SÎ± adversary if and
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 46 
ORAM
Data
Owner
Anonymized
trace
Original
trace
Partitioned
trace
Seed
trace

Step3: Generating
seed trace

Step4:Outsourcing the
seed trace and parameters
Seed
trace
Data
Analyst
ïƒ¼
ïƒ¼
Step1: Initial
Anonymization
Step2: Trace
partitioning
Step5: Generating
multi-views
Step6: Analyzing
generated traces
Step7: Real
report retrieval
Privacy Preservation
Utility Realization
K0
K1
K1
Figure 2: An overview of the multi-view approach
only if (probabilities below are from the adversaryâ€™s point of view)
âˆƒ Ïµ â‰¥ 0, s.t. âˆ€i âˆˆ {1, 2, Â· Â· Â· , N} â‡’
e
âˆ’Ïµ â‰¤
Pr(view i may be the real view )
Pr(view r may be the real view)
â‰¤ e
Ïµ
(2)
In Defintion 2.2, a smaller Ïµ value is more desirable as it means
the views are more indistinguishable from the real view to the
adversary. For example, an extreme case of Ïµ = 0 would mean all
the views are equally likely to be the real view to the adversary
(from now on, we call these views the real view candidates). In
practice, the value of Ïµ would depend on the specific design of a
multi-view solution and also on the adversaryâ€™s prior knowledge,
as will be detailed in following sections.
Finally, since the multi-view approach requires outsourcing some
supplementary parameters, we will also need to analyze the security/privacy of the communication protocol (privacy leakage in
the protocol, which complements the privacy analysis in output
of the protocol) in semi-honest model under the theory of secure
multiparty computation (SMC) [43], [44] (see section 4.2.4).
3 THE BUILDING BLOCKS
In this section, we introduce the building blocks for our multi-view
mechanisms, namely, the iterative and reverse CryptoPAn, partitionbased prefix preserving, and CryptoPAn with IP-collision (migration).
3.1 Iterative and Reverse CryptoPAn
As mentioned in section 2.3, the multi-view approach relies on
iteratively applying a prefix preserving function PP for generating
the seed view. Also, the analyst will invert such an application of PP
in order to obtain the real view (among fake views). Therefore, we
first need to show how PP can be iteratively and reversely applied.
First, it is straightforward that PP can be iteratively applied, and
the result also yields a valid prefix-preserving function. Specifically,
denote by PPj
(a,K) (j > 1) the iterative application of PP on IP
address a using key K, where j is the number of iterations, called
the index. For example, for an index of two, we have PP2
(a,K) =
PP(PP(a,K),K). It can be easily verified that given any two IP
addresses a and b sharing a k-bit prefix, PPi
(a,K) and PPi
(b,K)
will always result in two IP addresses that also share a k-bit prefix
(i.e., PPi
is prefix-preserving). More generally, the same also holds
for applying PP under a sequence of indices and keys (for both IPs),
e.g., PPi
(PPj
(a,K0),K1) and PPi
(PPj
(b,K0),K1) will also share kbit prefix. Finally, for a set of IP addresses S, iterative PP using a
single key K satisfies the following associative property:
âˆ€S,K, and i, j âˆˆ Z (inteĞ´ers) : PPi

PPj
(S,K),K

= PPj

PPi
(S,K),K

= PP(i+j)

S,K

(3)
On the other hand, when a negative number is used as the index,
we have a reverse iterative CryptPAn function (RPP for short), as
formally characterized in Theorem 3.1 (proof in Appendix B.1).
Theorem 3.1. Given IP addresses a = a1a2 Â· Â· Â· a32 and b =
PP(a,K) = b1b2 Â· Â· Â· b32, the function RPP(Â·) : {0, 1}
32 â†’ {0, 1}
32
defined as
RPP(b,K) = c = c1c2 Â· Â· Â·c32
where ci = bi âŠ• fiâˆ’1(c1 Â· Â· Â·ciâˆ’1)
(4)
is the inverse of the PP function given in Equation 1, i.e., c = a.
3.2 Partition-based Prefix Preserving
As mentioned in section 2.3, the central idea of the multi-view
approach is to divide the trace into partitions (Step 2), and then
anonymize those partitions iteratively, but for different number of
iterations (Step 3). In this subsection, we discuss this concept.
Given S as a set of n IP addresses, we may divide S into partitions
in various ways, e.g., forming equal-sized partitions after sorting S
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada    
based on either the IP addresses or corresponding timestamps. The
partitioning scheme will have a major impact on the privacy, and
we will discuss two such schemes in next section.
Once the trace is divided into partitions, we can then apply PP on
each partition separately, denoted by PP(Pi
,K) for the i
th partition.
Specifically, given S divided as a set ofm partitions {P1, P2, Â· Â· Â· , Pm},
we define a key vector V =

v1 v2 Â· Â· Â· vm

where each vi
is a positive integer indicating the number of times PP should be
applied to Pi
, namely, the key index of Pi
. Given a cryptographic
key K, we can then define the partition-based prefix preserving
anonymization of S as PP(S,V,K) =

PPv1 (P1,K), PPv2 (P2,K),
. . . , PPvm (Pm,K)

.
We can easily extend the associative property in Equation 3 to
this case as the following (which will play an important role in
designing our multi-view mechanisms in next section).
PP[PP(S,V1,K),V2,K] = PP(S, (V1 +V2),K) (5)
3.3 IP Migration: IP-Collision into CryptoPAn
As mentioned in section 2.3, once the analyst (adversary) receives
the seed view, he/she would generate many indistinguishable views
among which only one, the real view, will be prefix preserving
across all the partitions, while the other (fake) views do not preserve prefixes across the partitions (Step 5). However, the design
would have a potential flaw under a direct application of CryptoPAn. Specifically, since the original CryptoPAn design is collision
resistant [3], the fact that similar prefixes are only preserved in
the real view across partitions would allow an adversary to easily
distinguish the real view from others.
ğ‘ƒğ‘ƒ
4
(ğ‘ƒ1)
CryptoPAn (Collision Resistant)
144.5.116.249 50.19.13.26 159.61.5.252
39.250.139.225 83.180.10.3 135.243.4.124
17.8.78.28 159.61.20.124 159.61.20.124
150.10.10.1
128.10.10.1
150.10.20.0
ğ‘ƒğ‘ƒ
2 ğ‘ƒ1 (ğ‘ƒ1) ğ‘ƒğ‘ƒ (ğ‘ƒ1)
ğ‘ƒ2 ğ‘ƒğ‘ƒ
5 ğ‘ƒğ‘ƒ (ğ‘ƒ2)
3
(ğ‘ƒ2) ğ‘ƒğ‘ƒ(ğ‘ƒ2)
3-View Defense
Original
Trace
Fake View 1 Fake View 2 Real View
Figure 3: An example showing only the real view contains
shared prefixes (can be identified by adversaries)
Example 3.1. Figure 3 illustrates this flaw. The original trace includes three different addresses and has been divided into two partitions P1 and P2. As illustrated in the figure, the real view is easily
distinguishable from the two fake views as the shared prefixes (159.61)
between addresses in P1 and P2 only appear in the real view. This
is because, since the partitions in fake views have different rounds
of PP applied, and since the original CryptoPan design is collision
resistant [3], the shared prefixes will no longer appear. Hence, the
adversary can easily distinguish the real view from others.
To address this issue, our idea is to create collisions between
different prefixes in fake views, such that adversaries cannot tell
whether the shared prefixes are due to prefix preserving in the
real view, or due to collisions in the fake views. However, due to
the collision resistance property of CryptoPAn [3], there is only a
negligible probability that different prefixes may become identical
even after applying different iterations of PP, as shown in the above
example. Therefore, our key idea of IP migration is to first replace
the prefixes of all the IPs with common values (e.g., zeros), and then
fabricate new prefixes for them by applying different iterations of
PP. This IP migration process is designed to be prefix-preserving
(i.e,. any IPs sharing prefixes in the original trace will still share
the new prefixes), and to create collisions in fake views since the
addition of key indices during view generation can easily collide.
Next, we demonstrate this IP migration technique in an example.
ğ‘ƒğ‘ƒ
ğŸ
(0.0.20.0)=
11.215.10.28
2-View Defense
Original
Trace
Removing
Prefixes
Migration Fake View
(Collision)
Real View
(Prefix Preserving)
150.10.10.1
150.10.20.0
128.10.10.1
0.0.10.1
0.0.20.0
0.0.10.1
ğ‘ƒğ‘ƒ
1
ğ‘ƒğ‘ƒ
1
ğ‘ƒğ‘ƒ
2
ğ‘ƒ1
Group 1
Group 2
Group 1
ğ‘ƒğ‘ƒ
ğŸ
(0.0.20.0)=
11.215.31.108
ğ‘ƒğ‘ƒ
2
(0.0.10.1)=
95.24.141.20
ğ‘ƒ2
ğ‘ƒğ‘ƒ
ğŸ=
95.24.25.30
ğ‘ƒ1
ğ‘ƒğ‘ƒ
1 =
11.215.31.108
ğ‘ƒğ‘ƒ
ğŸ=
95.24.141.20
ğ‘ƒ2
ğ‘ƒğ‘ƒ
1
ğ‘ƒğ‘ƒ
0
ğ‘ƒğ‘ƒ
ğŸ=
95.24.25.30
ğ‘ƒ1
ğ‘ƒğ‘ƒ
ğŸ=
95.24.45.35
ğ‘ƒğ‘ƒ
3=
70.11.01.43
ğ‘ƒ2
ğ‘ƒğ‘ƒ
0
ğ‘ƒğ‘ƒ
1
Group 1
Group 1
Group 2
Figure 4: An example showing, by removing shared
prefixes and fabricating them with the same rounds of PP,
both fake view and real view may now contain fake or real
shared prefixes (which makes them indistinguishable)
Example 3.2. In Figure 4, the first stage shows the same original
trace as in Example 3.1. In the second stage, we â€œremoveâ€ the prefixes
of all IPs and replace them with all zeros (by xoring them with their
own prefixes). Next, in the third stage, we fabricate new prefixes by
applying different iterations of PP in a prefix preserving manner, e.g.,
the first two IPs still sharing a common prefix (11.215) different from
that of the last IP. However, note that whether two IPs share the new
prefixes only depends on their key indices now, e.g., 1 for first two IPs
and 2 for the last IP. This is how we can create collisions in the next
stage (the fake view) where the first and last IPs coincidentally share
the same prefix 95.24 due to their common key indices 2 (however,
note these are the addition results of different key indices from the
migration stage and the view generation stage, respectively). Now, the
adversary will not be able to tell which of those views is real based on
the existence of shared prefixes.
We now formally define the migration function in the following.
Definition 3.1. Migration Function: Let S be a set of IP addresses consisting of d groups of IPs S1, S2, Â· Â· Â· , Sd with distinct prefixes s1,s2, Â· Â· Â· ,sd
respectively, and K be a random CryptoPAn key.
Migration function M : S Ã— C(set of positive integers) â†’ Sâˆ—
is defined as
S
âˆ— = M(S) = {S
âˆ—
i
|âˆ€i âˆˆ {1, 2, Â· Â· Â· ,d}}
where S
âˆ—
i = {PPci
(si âŠ• aj
,K), âˆ€aj âˆˆ Si } (6)
where C = PRNG(d,d) = {c1,c2, Â· Â· Â· ,cd
} is the set of d nonrepeating random key indices generated between [1,d] using a cryptographically secure pseudo random number generator.
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 463    
4 Ïµ-INDISTINGUISHABLE MULTI-VIEW
MECHANISMS
We first present a multi-view mechanism based on IP partitioning
in Section 4.1. We then propose a more refined scheme based on
distinct IP partitioning with key vector generator in Section 4.2.
4.1 Scheme I: IP-based Partitioning Approach
To realize the main ideas of multi-view anonymization, as introduced in Section 2.3, we need to design concrete schemes for each
step in Figure 2. In our first scheme, we divide the original trace in
such a way that all the IPs sharing prefixes will always be placed
in the same partition. This will prevent the attack described in
Section 3.3, i.e., identifying the real view by observing shared prefixes across different partitions. As we will detail in Section 4.1.4,
this scheme can achieve perfect indistinguishability without the
need for IP migration (introduced in Section 3.3), although it has
its limitations which will be addressed in our second scheme. Both
schemes are depicted in Figure 5 and detailed below.
Specifically, our first scheme includes three main steps: privacy
preservation (Section 4.1.1), utility realization (Section 4.1.2), and
analysis report extraction (Section 4.1.3).
4.1.1 Privacy Preservation (Data Owner). The data owner performs a set of actions to generate the seed trace Lâˆ—
0
together with
some parameters sent to the analyst for generating different views.
These actions are summarized in Algorithm 1, and detailed as below.
(1) Applying CryptoPAn using K0: First, the data owner generates two independent keys, namelyK0 (key used for initial anonymization, which never leaves the data owner) and K (key used for later
anonymization steps). The data owner then generates the initially
anonymized trace L0=PP(L,K0). This step is designed to prevent
the adversary from simulating the scheme, e.g., using a brute-force
attack to revert the seed trace back to the original trace in which
he/she can recognize some original IPs. The leftmost block in Figure 5 shows an example of the initially anonymized trace.
(2) Trace partitioning based on IP-value: The initially anonymized
trace is partitioned based on IP values. Specifically, let S be the set
of IP addresses in L0 consisting of d groups of IPs S1, S2, Â· Â· Â· , Sd
with distinct prefixes s1,s2, Â· Â· Â· ,sd
, respectively; we divide L0 to d
partitions, each of which is the collection of all records containing
one of these groups. For example, the upper part of Figure 5 depicts
how our first scheme works. The set of three IPs are divided into
two partitions where P1 includes both IPs sharing the same prefix,
45.20.15.89 and 45.20.141.20, whereas the last IP 121.25.01.08 goes
to P2 since it does not share a prefix with others.
(3) Seed trace creation: The data owner in this step generates the
seed trace using a d-size (recall that d is the number of partitions)
random key vector.
â€¢ Generating a random key vector: The data owner generates a
random vector V of size d using a cryptographically secure
pseudo random number generator PRNG(d ,d) (which generates a set of d non-repeating random numbers between
[1,d]). This vector V and the key K will later be used by the
analyst to generate different views from the seed trace. For
example, in Figure 5, for the two partitions, V =

1 2
is
generated. Finally, the data owner chooses the total number of views N to be generated later by the analyst, based
on his/her requirement about privacy and computational
overhead, since a larger N will mean more computation by
both the data owner and analyst but also more privacy (more
real view candidates will be generated which we will further
study this through experiments later).
â€¢ Generating a seed trace key vector and a seed trace: The data
owner picks a random numberr âˆˆ [1, N] and then computes
V0 = âˆ’r Â· V as the key vector of seed trace. Next, the data
owner generates the seed trace as Lâˆ—
0
= PP(L0,V0,K). This
ensures, after the analysts applies exactly r iterations of V
on the seed trace, he/she would get L0 back (while not being
aware of this fact since he/she does not know r). For example,
in Figure 5, r = 3 and V0 =

âˆ’3 âˆ’6

. We can easily verify
that, if the analyst applies the indices in V on the seed trace
three times, the outcome will be exactly L0 (the real view).
This can be more formally stated as follows (the r
th view
Lâˆ—
r
is actually the real view).
L
âˆ—
r = PP(Lâˆ—
0
,r Â· V,K), using (5)
= PP(L0,V0 + r Â· V,K), using (5)
= PP(L0, âˆ’r Â· V + r Â· V,K) = L0
(4) Outsourcing: Finally, the data owner outsources Lâˆ—
0
, V , N and
K to the analyst.
4.1.2 Network Trace Analysis (Analyst). The analyst generates
the N views requested by the data owner, which is summarized in
Algorithm 2 in Appendix E and formalized below.
L
âˆ—
0
, is the seed view
L
âˆ—
i = PP(Lâˆ—
iâˆ’1
,V,K), i âˆˆ {1, . . . , N}
(7)
Since boundaries of partitions must be recognizable by the analyst
to allow him/her to generate the views, we modify the time-stamp
of the records that are on the boundaries of each partition by changing the most significant digit of the time stamps which is easy to
verify and does not affect the analysis as it can be reverted back to
its original format by the analyst. Next, the analyst performs the
requested analysis on all N views and generates N analysis reports
Î“1, Î“2, Â· Â· Â· , Î“N .
4.1.3 Analysis Report Extraction (Data Owner). The data owner
is only interested in the analysis report that is related to the real
view, which we denote by Î“r . To minimize communication overhead,
instead of requesting all the analysis reports Î“i of the generated
views, the data owner can fetch only the one that is related to
the real view Î“r . He/she can employ the oblivious random accesses
memory (ORAM) [23] to do so without revealing the information
to the analyst (we will discuss alternatives in Section 6).
4.1.4 Security Analysis. We now analyze the level of indistinguishability provided by the scheme. Recall the indistinguishability property defined in Section 2; a multi-view mechanism is
Ïµ-indistinguishable if and only if
âˆƒ Ïµ â‰¥ 0, s.t. âˆ€i âˆˆ {1, 2, Â· Â· Â· , N} â‡’
e
âˆ’Ïµ â‰¤
Pr(view i may be the real view)
Pr(view r may be the real view)
â‰¤ e
Ïµ
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 464    
Seed
Trace
=
121.25.01.108
1
P2
=
P3
=
1
PP
PP
PP
P

Outsourced parameters:
 K ,N (number of views), V
Data Analyst
Outsourced parameters:
K, N,V1,V2,...,VN
L0
*
Data
Owner
L0
* L0
Step3: Generating Seed Trace
Using Constant Vector
Step2:IP
Partitioned
Step2: Distinct
IP Partitioned
Step3: Generating Seed
Trace Using N Key Vectors
Initially Anonymized
Trace
=
45.20.15.89
=
=
PP
PP
PP
2
2
IP Partitioned
Trace
PP =
=
121.25.01.08
PP
P
1
P2
2
Seed
Trace
70.11.23.255
=
70.11.01.43
PP
=
59.101.3.5
PP
P
1
P
2
-4
-2
PP =
-2
1
PP =
1
1
Distinct IP
Partitioned
=
1
P2
=
P3
=
1
PP
PP
PP
P
1
2
2
2
K
Schemeâ… 
Scheme â…¡
45.20.141.20
121.25.01.08
45.20.15.89
45.20.141.20
Initial vector: V0 =-r.V
Real view index:
 r=3
Random Vector:
: Reverse
 CryptoPAn
PRNG(2,3,0)=
V0 =PRNG(2,3,0)-C*
Migration key:
1 2
T
: PP K
V=
T
2 2 1
1 2 1
T
C*=
45.20.15.89
121.25.01.08
45.20.141.20 45.20.141.20
121.25.01.08
L0
Figure 5: An example of a trace which undergoes multi-view schemes I, II
The statement inside the probability is the adversaryâ€™s decision on
a view, declaring it as fake or a real view candidate, using his/her
SÎ± knowledge. Moreover, we note that generated views differ only
in their IP values (fp-QI attributes are similar for all the views).
Hence, the adversaryâ€™s decision can only be based on the published
set of IPs in each view through comparing shared prefixes among
those IP addresses which he/she already know (SÎ± ). Accordingly,
in the following, we define a function to represent all the prefix
relations for a set of IPs.
Lemma 4.1. Function Q : {0, 1}
32 Ã— {0, 1}
32 â†’ N returns the
number of bits in the prefix shared between two IP addresses a and b
Q(a,b) = 31 âˆ’ âŒŠloĞ´
aâŠ•b
2
âŒ‹
Definition 4.1. For a multiset of n IP addresses S, the Prefixes
Indicator Set (PIS) R(S) is defined as follows.
R(S) = {Q(ai
, aj)| âˆ€ai
, aj âˆˆ S,i, j âˆˆ {1, 2, Â· Â· Â· ,n}} (8)
Note that PIS remains unchanged when CryptoPAn is applied
on S, i.e., R(PP(S,K)) = R(S). In addition, since the multi-view
solution keeps all the other attributes intact, the adversary can
identify his/her pre-knowledge in each view and construct prefixes
indicator sets out of them. Accordingly, we denote by RÎ±,i the PIS
constructed by the adversary in view i.
Definition 4.2. Let RÎ± be the PIS for the adversaryâ€™s knowledge,
and RÎ±,i
, i âˆˆ {1, Â· Â· Â· , N} be the PIS constructed by the adversary
in view i. A multi-view solution then generates Ïµ-indistinguishable
views against an SÎ± adversary if and only if
âˆ€i âˆˆ {1, 2, Â· Â· Â· , N}, e
âˆ’Ïµ â‰¤
Pr(RÎ±,i = RÎ± )
Pr(RÎ±,r = RÎ± )
â‰¤ e
Ïµ
(9)
Lemma 4.2. The indistinguishability property, defined in equation 9 can be simplified to
âˆ€i âˆˆ {1, 2, Â· Â· Â· , N}, Pr(RÎ±,i = RÎ± ) â‰¥ e
âˆ’Ïµ
(10)
Proof. Pr(RÎ±,r = RÎ± ) = 1 as view r is the prefix preserving
output. Moreover, âˆ€Ïµ â‰¥ 0 we have e
Ïµ â‰¥ 1. â–¡
From the above, we only need to show RÎ±,i = RÎ± (each generated view i is a real view candidate).
Theorem 4.3. Scheme I satisfies equation 10 with Ïµ = 0.
Proof. Scheme I divides the trace into d (number of prefix
groups) partitions containing all the records that have similar prefixes. Hence, for any partition Pi
(1 â‰¤ i â‰¤ d), any two IP addresses a
and b inside Pi
, and for any m,n â‰¤ N, we have Rm(a,b) = Rn(a,b)
because a and b are always assigned with equal key indices. Moreover, for any two IP addresses a and b in any two different partitions
and any m,n â‰¤ N, we have Rm(a,b) = Rn(a,b) = 0 since they do
not share any prefixes. â–¡
The above discussions show that scheme I produces perfectly indistinguishable views (Ïµ = 0). In fact, it is robust against the attack
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 465
explained in Section 3.3 and thus does not required IP migration,
because the partitioning algorithm already prevents addresses with
similar prefixes from going into different partitions (the case in
Figure 3). However, although adversaries cannot identify the real
view, they may choose to live with this fact, and attack each partition inside any (fake or real) view instead, using the same semantic
attack as shown in Figure 1. Note that our multi-view approach
is only designed to prevent attacks across different partitions, and
each partition itself is essentially still the output of CryptoPAn and
thus still inherits its weakness.
Fortunately, the multi-view approach gives us more flexibility in
designing specific schemes to further mitigate such a weakness of
CryptoPAn. We next present scheme II which sacrifices some indistinguishability (in the sense of slightly less real view candidates) to
achieve better protected partitions.
4.2 Scheme II: Multi-view Using N Key Vectors
To address the limitation of our first scheme, we propose the next
scheme, which is different in terms of the initial anonymization, IP
partitioning, and key vectors for view generation. The data ownerâ€™s
and the analystâ€™s actions are summarized in Algorithms 3, 4.
4.2.1 Initial Anonymization with Migration. First, to mitigate
the attack on each partition, we must relax the requirement that
all shared prefixes go into the same partition. However, as soon as
we do so, the attack of identifying the real view through prefixes
shared across partitions, as demonstrated in Section 3.3, might
become possible. Therefore, we modify the first step of the multiview approach (initial anonymization) to enforce the IP migration.
Figure 6 demonstrates this. The original trace is first anonymized
with K0, and then the anonymized trace goes through the migration
process, which replaces the two different prefixes (97.17 and 75.91)
with different iterations of PP, as discussed in Section 3.3.
L00= PP(L,K0)
Applying Migration
CryptoPAn
Using K0
L0= PP(L00 ,C*,K)
L L00 L0 C*=
2
1
Step1:Initial Anonymization
Anonymized
Trace
97.17.32.50
97.17.67.23
75.91.139.225
Migrated
Trace
= 45.20.15.89
= 45.20.141.20
= 121.25.01.08
PP
PP
PP2
1
IP 1
150.10.10.1
150.10.20.0
128.10.10.1
Start Time
10:23:42:50
10:53:42:54
10:53:42:57
Original Trace
Figure 6: The updated initial anonymization (Step 1 in
Figure 2) for enforcing migration
4.2.2 Distinct IP Partitioning and N Key Vectors Generation. For
the scheme, we employ a special case of IP partitioning where each
partition includes exactly one distinct IP (i.e., the collection of all
records containing the same IP). For example, the trace shown in
Figure 5 includes three distinct IP addresses 150.10.10.1,128.10.10.1,
and 150.10.20.0. Therefore, the trace is divided into three partitions. Next, the data owner will generate the seed view as in the
ğ‘ƒğ‘ƒ
ğŸ
(0.0.20.0)=
95.24.25.30
2-View Defense
Original Trace Migration Seed View
(Collision)
Fake View
(Collision)
Real View
(Prefix Preserving)
150.10.10.1
150.10.20.0
128.10.10.1
ğ‘ƒğ‘ƒ
1
ğ‘ƒğ‘ƒ
1
ğ‘ƒğ‘ƒ
2
ğ‘ƒ1
Group 1
Group 2
Group 1
ğ‘ƒğ‘ƒ
1
(0.0.10.1)=
95.24.141.20
ğ‘ƒ2
ğ‘ƒğ‘ƒ
1âˆ’1
ğ‘ƒğ‘ƒ
2âˆ’1
ğ‘ƒğ‘ƒ
ğŸ
(0.0.20.0)=
11.15.31.108
ğ‘ƒ3
ğ‘ƒğ‘ƒ
ğŸ=
95.24.25.30
ğ‘ƒ1
ğ‘ƒğ‘ƒ
2 =
11.215.10.28
ğ‘ƒ2
ğ‘ƒğ‘ƒ
ğŸ=
11.215.31.108
ğ‘ƒğ‘ƒ ğ‘ƒ3
2âˆ’2
ğ‘ƒğ‘ƒ
ğŸ=
11.215.31.108
ğ‘ƒğ‘ƒ
ğŸ=
11.215.10.28
ğ‘ƒ2
ğ‘ƒğ‘ƒ
1=
95.24.25.30
ğ‘ƒ3
ğ‘ƒ1
ğ‘ƒğ‘ƒ
ğŸ=
95.24.25.30
ğ‘ƒğ‘ƒ
ğŸ=
11.215.10.28
ğ‘ƒ2
ğ‘ƒğ‘ƒ
1=
95.24.25.30
ğ‘ƒ3
ğ‘ƒğ‘ƒ
1âˆ’1
ğ‘ƒğ‘ƒ
2âˆ’2
ğ‘ƒğ‘ƒ
1âˆ’2
ğ‘ƒğ‘ƒ
2âˆ’1
ğ‘ƒğ‘ƒ
2âˆ’2
ğ‘ƒğ‘ƒ
1âˆ’1
Figure 7: An 3 views generation example under scheme II
first scheme, although the key V0 will be generated completely
differently, as detailed below.
Let S
âˆ— = {S
âˆ—
1
, S
âˆ—
2
, Â· Â· Â· , S
âˆ—
d
}, be the set of IP addresses after the
migration step. Suppose S
âˆ—
consists of D distinct IP addresses. We
denote by C
âˆ—
the multiset of totally D migration keys for those
distinct IPs (in contrast, the number of migration keys in C is
equal to the number of distinct prefixes, as discussed in Section 3.3).
Also, let PRNG(d,D,i) be the set of D random number generated
between [1,d] using a cryptographically secure pseudo random
number generator at iteration i
th. The data owner will generate
N + 1 key vector Vi as follows.
Vi = PRNG(d,D,i) âˆ’ PRNG(d,D,i âˆ’ 1), (11)
âˆ€i , r âˆˆ [1, 2 Â· Â· Â· , N]
and
V0 = PRNG(d,D, 0) âˆ’ Câˆ—
(12)
Vr = C
âˆ— âˆ’ PRNG(d,D,r âˆ’ 1)
Example 4.1. In Figure 7, the migration and random vectors are
C
âˆ— = [1 1 2], PRNG(2, 3, 0) = [1 2 2], PRNG(2, 3, 1) = [1 2 1], and
PRNG(2, 3, 2) = [2 2 1], respectively. The corresponding key vectors
will be V0 = [0 1 0], V1 = [0 0 âˆ’ 1] and V2 = [1 0 0] where only V1
and V2 are outsourced.
In this scheme, the analyst at each iteration i generates a new
set of IP addresses S
âˆ—
i
= {S
i
1
, S
i
2
, Â· Â· Â· , S
i
d
} by randomly grouping
all the distinct IP addresses into a set of d prefix groups. In doing
so, each new vector Vi essentially cancels out the effect of the
previous vector Viâˆ’1, and thus introduces a new set of IP addresses
S
âˆ—
i
consisting of d prefix groups. Thus, it is straightforward to verify
that the r
th generated view will prefix preserving (the addresses
are migrated back to their groups using C
âˆ—
).
Example 4.2. Figure 7 shows that, in each iteration, a different
set (but with an equal number of elements) of prefix groups will be
generated. For example, in the seed view, IP addresses 150.10.20.0 and
128.10.10.1 are mapped to prefix group 11.215.
4.2.3 Indistinguishability Analysis. By placing each distinct IP
in a partition, our second scheme is not vulnerable to semantic
attacks on each partition, since such a partition contains no information about the prefix relationship among different addresses.
However, compared with scheme I, as we show in the following,
this scheme achieves a weaker level of indistinguishability (higher
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 466
Ïµ). Specifically, to verify the indistinguishability of the scheme, we
calculate Pr(RÎ± = RÎ±,i) for scheme II in the following. First, the
number of all possible outcomes of grouping D IP addresses into d
groups with predefined cardinalities is:
Ntot al =
D!
|S1 |!|S2 |! Â· Â· Â· |Sd
|!
(13)
where |Si
| denotes the cardinality of group i. Also the number of all
possible outcomes of grouping D IP addresses into d groups while
still having RÎ±,i = RÎ± is:
Nreal view candidates =
Î±! (D âˆ’ Î±)!
Ã(
d
Î±
)
i=1

Î 
Î±
i=1
|Sai
|

|S1 |!|S2 |! Â· Â· Â· |Sd
|!
(14)
for some ai âˆˆ {1, 2, Â· Â· Â· ,d}. This equation gives the number of
outcomes when a specific set of Î± IP addresses (SÎ± ) are distributed
into Î± different groups and hence keeping RÎ±,i = RÎ± (i.e., the adversary cannot identify collision). Note that term Ã(
d
Î±
)
i=1

Î 
Î±
i=1
|Sai
|

is all the combinations of choosing this Î± groups for the numerator
to model all the (|Sai
| âˆ’ 1)! combinations. Finally, we have
âˆ€i â‰¤ N : Pr(RÎ±,i = RÎ± ) =
Nreal view candidates
Ntot al
=
A =
Î±!
Ã(
d
Î±
)
i=1

Î 
Î±
i=1
|Sai
|

Î 
Î±âˆ’1
i=0
(D âˆ’ i)
â‰¥ e
âˆ’Ïµ
(15)
Thus, to ensure the Ïµ-indistinguishability, the data owner needs to
satisfy the expression in equation 15 which is a relationship between
the number of distinct IP addresses, the number of groups, the
cardinality of the groups in the trace and the adversaryâ€™s knowledge.
Theorem 4.4. The indistinguishability parameter Ïµ of the generated views in scheme II is lower-bounded by
ln D
Î±
d
Î±
Â· Î 
Î±âˆ’1
i=0
(d âˆ’ i)
(D âˆ’ i)

(16)
Proof. Let b1,b2, Â· Â· Â· ,bn be positive real numbers, and for k =
1, 2, Â· Â· Â· ,n define the averages Mk as follows:
Mk =
Ã
1â‰¤i1â‰¤i2â‰¤Â·Â·Â·â‰¤ik â‰¤n
bi1
bi1
Â· Â· Â· bik
n
k
 (17)
Per Maclaurinâ€™s inequality [29]: M1 â‰¥
âˆš2 M2 â‰¥ Â· Â· Â· â‰¥ âˆšn Mn,
where M1 =
Ãn
i=1
bi /n, we have
A =
Î±!
d
Î±

MÎ±
Î 
Î±âˆ’1
i=0
(D âˆ’ i)
â‰¤
Î 
Î±âˆ’1
i=0
(d âˆ’ i)(M1)
Î±
Î 
Î±âˆ’1
i=0
(D âˆ’ i)
and since M1 =
Ãn
i=1
|Si
|/n = D/d, we have A â‰¤
D
Î±
d
Î± Â· Î 
Î±âˆ’1
i=0
(dâˆ’i)
(Dâˆ’i)
.
â–¡
Figure 8(a) shows how the lower-bound in Equation 16 changes
with respect to different values of fraction d/D and also the adversaryâ€™s knowledge. As it is expected, stronger adversaries have
more power to weaken the scheme which results in increasing Ïµ
or increasing the chance of identifying the real view. Moreover,
as it is illustrated in the figure, when fraction d/D grows, Ïµ tends
to converge to very small values. Hence, to decrease Ïµ, the data
0.1 0.2 0.3 0.4 0.5
d/D
(a)
0
2
4
6
8
Adversary
0 25 50 75 100
2
 (|S1
 |,|S2 d
 |)
(b)
0.2
0.4
0.6
0.8
1
1.2
Figure 8: (a) Bound for Ïµ as adversaryâ€™s knowledge varies.
(b) The exact value of Ïµ in equation 15 for Î± = 8, d/D = 0.1
and as variance of cardinalities varies
owner may increase d/D âˆˆ [0, 1] by grouping addresses based on a
bigger number of bits in their prefixes, e.g., a certain combination
of 3 octets would be considered as a prefix instead of one or two.
Another solution could be aggregating the original trace with some
other traces for which the cardinalities of each prefix group are
small. We study this effect in our experiments in Section 5 where
we illustrate the concept especially in Figures 10, 11.
Finally, Figure 8(b) shows how variance of the cardinalities affects the indistinguishability for a set of fixed parameters d, D, Î±.
In fact, when the cardinalities of the prefix groups are close (small
Ïƒ), A grows to meet the lower-bound in Theorem 4.4. Hence, from
the data owner perspective, a trace with a lower variance of cardinalities and a bigger fraction d/D has a better chance of misleading
adversaries who wants to identify the real view.
4.2.4 Security of the communication protocol. We now analyze
the security/privacy of our protocol in semi-honest model under
secure multiparty computation (SMC) theory [43], [44].
Lemma 4.5. Scheme II only reveals the CryptoPan Key K and the
seed trace Lâˆ—
0
in semi-honest model.
Proof. Recall that our communication protocol only involves
one-round communication between two parties (data owner to
data analyst). We then only need to examine the data analystâ€™s
view (messages received from the protocol), which includes (1) N:
number of views to be generated, (2) K: the outsourced key, (3)
Lâˆ—
0
: the seed trace, and (4) V1,V2, Â· Â· Â· ,VN : the key vectors. As we
discuss in section 4.2.3, the probability of identifying the real view
by the adversary using all provided information (key and vectors)
depends on the adversary knowledge and the trace itself which
clearly implies that such â€œleakageâ€ is trivial.
Indeed, each of N and V1,V2, . . . ,VN can be simulated by generating a single random number from a uniform random distribution (which proves that they are not leakage in the protocol).
Specifically, the number of generated views N is integer which
is bounded by N0, where N0 is the maximum number of views
the data owner can afford and all the entries in V1,V2, Â· Â· Â· ,VN are
in [âˆ’d,d] where d is the number of groups. First, given integer
0 < N âˆˆ N
âˆ—
, the probability that N is simulated in the domain
would be Pr[Simulator = N] =
1
N âˆ— . Then, N can be simulated
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canad       
in polynomial time (based on the knowledge data analyst already
knew, i.e., his/her input and/or output of the protocol). Similarly, all
the random entires in V1,V2, Â· Â· Â· ,VN can also be simulated in polynomial time using a similar simulator (only changing the bound).
Thus, the protocol only reveals the outsourced key K and the seed
trace Lâˆ—
0
in semi-honest model. â–¡
Note that the outsourced key can be considered as a public key
and leakage in Lâˆ—
0
is the leakage in output of the protocol which
was studied earlier. Finally, we study the setup leakage and show
that the adversary cannot exploit outsourced parameters to increase
Ïµ (i.e., decrease the number of real view candidates) by building
his/her own key vector.
Lemma 4.6. (Proof in Appendix B.2) For an SÎ± adversary, who
wants to obtain the least number of real view candidates, if condition (2d âˆ’ 2)
D > N holds, the best approach is to follow scheme II,
(scheme II returns the least number of real view candidates).
4.3 Discussion
Application to EDB: We believe the multi-view solution would
be applicable to other related areas. For instance, processing on
encrypted databases (EDB) has a rich literature including searchable symmetric encryption (SSE) [52], [53], fully-homomorphic
encryption (FHE) [54], oblivious RAMs (ORAM) [44], functional encryption [55], and property preserving encryption (PPE) [56], [57].
All these approaches achieve different trade-offs between protection (security), utility (query expressiveness), and computational
efficiency [59]. Extending and applying the multi-view approach in
those areas could lead to interesting future directions.
Comparing the Two Schemes: As discussed earlier, scheme I
achieves a better indistinguishability but less protected partitions
in each view. Figure 14 compares the relative effectiveness of the
two schemes on a real trace under 40% adversary knowledge. In
particular, Figure 14(a,b) demonstrates the fact that despite the
lower number of real view candidates in scheme II compared with
scheme I (30 vs 160 out of 160), the end result of the leakage in
scheme II is much more appealing (3% vs 35%). Therefore, our
experimental section has mainly focused on scheme II.
Choosing the Number of Views N: The number of views N
is an important parameter that determines both the privacy and
computational overhead. The data owner could choose this value
based on the level of trust on the analysts and the affordable computational overhead. Specifically, as implied by Equation 10 and
demonstrated in our experimental results in section 5, the number
of real view candidates is approximately e
âˆ’Ïµ
Â·N. The data owner can
first estimate the adversaryâ€™s background knowledge Î± (number of
prefixes known to the adversary) and then calculate Ïµ either using
Equation 15 or (approximately) using Equation 16. As shown in Figures 8(a) and 9(b), a bigger Î± results in weaker indistinguishability
and demands a larger number of views. An alternative solution is to
increase the number of prefix groups (D) by sacrificing some prefix
relations among IPs, e.g., grouping them with the first 3 octets.
Utility: The main advantage of the multi-view approach is preserving both privacy and utility. In particular, we have shown that the
data owner can receive an analysis report based on the real view
(Î“r ) which is prefix-preserving over the entire trace. This is more accurate than the obfuscated (through bucketization and suppression)
or perturbed (through adding noise and aggregation) approaches.
Specifically, in case of a security breach, the data owner can easily
compute Lr (migration output) to find the mapped IP addresses
corresponding to each original address, and apply necessary security policies to the IP addresses that are reported to violate some
policies in Î“r .
Communicational/Computational Cost: One of our contributions in this paper is to minimize the communication overhead by
only outsourcing one (seed) view and some supplementary parameters. This is especially critical for large scale network data like
network traces from the major ISPs.
5 EXPERIMENTS
This section experimentally evaluates our technique with real data.
5.1 Setup
To validate our multi-view anonymization approach, we use a set
of network traces collected by a real ISP. We focus on attributes
Timestamp, IPaddress, and PacketSize in our experiments, and the
meta-data are summarized in Figure 9(a).
Attribute Value
Type Header
Start date
End date
Size
Format
Distinct IP addresses
Number of packets
Header
August 1st, 2016
October 21st, 2016
70 GB
pcap and TXT
883
1M
(a) (b)
Figure 9: (a) Metadata of the traces (b) Ïµ for different
number of prefix groups and adversary knowledge
In order to measure the security of the proposed approach,
we implement the frequency analysis attack [4, 59]. This attack
can compromise individual addresses protected by existing prefixpreserving anonymization in multi-linear time [4]. In the setting
of EDBs (encrypted database systems), an attack is successful if it
recovers even partial information about a single cell of the DB [59].
Accordingly, we define the information leakage metric to evaluate
the effectiveness of our solution against the adversaryâ€™s semantic
attacks. Several measures have been proposed in literature [3, 31]
to evaluate the impact of semantic attacks. Motivated by [3], we
model the information leakage (number of matches) as the number
of records/packets, their original IP addresses are known by the
adversary either fully or partially. More formally,
Information leakage metric [3]: measure Fi
is defined as the total
number of addresses that has at least i most significant bits known,
where i âˆˆ {1, 2, Â· Â· Â· , 32}.
To model the adversarial knowledge, we define a set of prefixes
known to the adversary ranging from 10% up to 100% of all the
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 468
0 20 40 60 80 100 120 140 160
# of Views
(e)
0
25
50
75
100
Real View Candidates (%)
0 20 40 60 80 100 120 140 160
# of Views
(d)
0
25
50
75
100
Real View Candidates (%)
0 20 40 60 80 100 120 140 160
0
2
4
6
8
10
12
14
16
18
Packet Leakage (%)
# of Views
 (b)
0 20 40 60 80 100 120 140 160
# of Views
 (f)
0
25
50
75
100 Real View Candidates (%)
0 20 40 60 80 100 120 140 160
# of Views
 (c)
0
2
4
6
8
10
12
14
16
Packet Leakage (%)
0 20 40 60 80 100 120 140 160
# of Views
 (a)
0
10
20
30
40
50
60
Packet Leakage (%)
Figure 10: Percentage of the compromised packets (out of 1M) and number of real view candidates when number of views
and the adversary knowledge vary and for the three different cases (1) Figures (a),(d), (2) Figures (b),(e), and (3) Figures (c),(f)
where legends marked by CP denote the CryptoPAn result whereas those marked by MV denote the multi-view results
prefixes in the trace. This knowledge is stored in a two dimensional
vector that includes Î± different addresses and their key indexes.
Next, using our multi-view scheme, we generate all the N views.
However, before we apply the frequency analysis attack, we simulate how an adversary may eliminate some fake views from further
consideration as follows. For each view, we check if two addresses
from the adversaryâ€™s knowledge set with different prefixes now
share prefixes in that view. If we find such a match in the key indexes, the corresponding view will be discarded from the set of the
real view candidates and will not be considered in our experiments
since the adversary would know it is a fake view.
We validate the effectiveness of our scheme by showing the
number of real view candidates and the percentage of the packets
in the trace that are compromised (i.e., the percentage of IP packets
whose addresses have at least 8 most significant bits known). Each
experiment is repeated more than 1, 000 times and the end results
are the average results of the frequency analysis algorithm applied
to each of the real view candidates.
Moreover, evaluating the utility preservation and studying the
scalability of using ORAM in our scheme are discussed in Appendix C.2 and C.3, respectively.
We conduct all experiments on a PC running Windows with an
Intel Core i7-6700 3.40 GHz CPU, 4 GB Memory, and 500 GB HDD.
5.2 Results
5.2.1 Information Leakage Analysis. First, the numerical results
of the indistinguishability parameter Ïµ under different adversaryâ€™s
knowledges are depicted in Figure 9(b). Those results correspond to
three different cases, i.e., when addresses are grouped based on (1)
only the first octet (136 groups), (2) the first and the second octets
(417 groups), and (3) the first three octets (506 groups). The results
show that Ïµ decreases (more privacy) as the number of prefix groups
increases, and it increases as the adversarial knowledge increases.
We next validate those numerical results through experiments in
Figure 10. Specifically, we first analyze the performance of scheme
II before comparing the two schemes in Appendix C. Figure 10
presents different facets of information leakage when our approach
is applied in various grouping cases. The results in Figure 10 are for
adversaries who have knowledge of no more than 50% of the prefix
groups (Figure 12 in Appendix C.1 presents the more extreme cases
for the same experiments, i.e., up to 100% knowledge). The analysis
of these figures is detailed in the following.
Effect of the number of prefix groups: As we discuss earlier,
three different IP grouping cases are studied. Figures 10 (a) and
(d) show the results of packet leakage and number of real view
candidates when d = 136, respectively. As the numerical results in
Figure 8 anticipates, since the fraction d/D = 0.154 is relatively low,
the indistinguishability of generated views diminishes specially
for stronger adversarial knowledges. Consequently, the adversary
discards more views and the rate of leakage increases, compared
with Figures 10 (b), (e) and Figures 10 (c), (f) for which the fraction d/D = 0.47 and 0.57, respectively. In the worst case of 50%
adversarial knowledge and the number of views is below 50, we can
verify that the number of real view candidates for case (1) remains
1 resulting in an equal packet leakage as that of CryptoPAn.
Effect of the number of views: As illustrated in the figure, increasing the number of views always improves both the number of
Session 3B: Differential Privacy 2 CCSâ€™18, October 15-19, 2018, Toronto, ON, Canada 469
real view candidates and the packet leakages. All the figures for real
view candidates evaluation, show a near linear improvement where
the slope of this improvement inversely depends on the adversarial
knowledge. For the packet leakages, we can note that the improvement converges to a small packet leakage rate under a large number
of views. This is reasonable, as each packet leakage result is an average of leakages in all the real view candidates. However, since each
of the fake views leaks a certain amount of information, increasing
the number of views beyond a certain value will no longer affect
the end result. In other words, the packet leakage converges to
the average of leakages in the (fake) real view candidates. Finally,
the results show that our proposed scheme can more efficiently
improve privacy by (1) increasing the fraction d/D (number of prefix
groups/number of distinct addresses) or (2) increasing the number of
views. The first option may affect utility (since inter-group prefix
relations will be removed), while the second option is more aligned
with our objective of trading off privacy with computation.
5.2.2 Computational Overhead Evaluation. We evaluate the computational overhead incurred by our approach. Figure 11 shows
the time required by our scheme in each grouping cases, when the
number of views varies for a trace including one million packets.
We observe that, when the number of views increases, the computational overhead increases near linearly. However, each case
shows a different slope depending on the number of groups. This
is reasonable as our second scheme generates key vectors with a
larger number of elements for more groups, which leads to applying CryptoPAn for more iterations (see the complexity analysis in
Appendix D). Finally, linking this figure to the information leakage results shown in Figure 10 demonstrates the trade-off between
privacy and computational overhead.
0 20 40 60 80 100 120 140 160
# of Views

0
50
100
150
200
Time (s)
1-octet grouped
2-octet grouped
3-octet grouped
Figure 11: Runtime for different prefix grouping cases
6 RELATED WORK
In the context of network traces anonymization, as surveyed in [18],
many solutions have been proposed [2, 4, 8, 12, 13]. These are generally classified into different categories, such as enumeration [19],
partitioning [21], and prefix-preserving [22, 25]. These methods include suppression and generalization of rows or attributes [34].
Some of them [8, 31] are designed to address specific attacks by
permuting some attributes in the network traces. Later studies either prove theoretically [5] or validate empirically [14] that those
works may be defeated by semantic attacks.
As our proposed technique falls into the category of prefixpreserving solutions, which aims to improve the utility, we review
more works in this category. First effort to find a prefix preserving
anonymization was done by Greg Minshall [48] who developed
TCPdpriv which is a table-based approach that randomly generates
a function. Fan et al. [3] then developed CryptoPAn with a completely cryptographic approach. Several works [4, 8, 31] have then
raised its vulnerability against semantic attacks which motivated
query based [17] and bucketization based [2] solutions.
In particular, the (k, j)-obfuscation method first groups together
k or more flows with similar fingerprints and then bucketizes (i.e.,
replacing original IPs with identical IPs) j < k flows inside each
group; all records whose fingerprints are not sufficiently similar
to k âˆ’ 1 others will be suppressed [2]. Clearly, both the bucketization and suppression may lead to significant utility loss. The
differentially private analysis method first adds noises to analysis
results and then publishes such aggregated results [17, 41, 42]. Although this method may provide privacy guarantee regardless of
adversarial knowledge, the perturbation and aggregation prevent
its application to analyses that demand accurate or detailed records
in the network traces. A summary of the most important network
trace anonymization schemes [18] and their main features are given
in Appendix A.2.
The last step of our solution requires data owner to privately
retrieve an audit report of the real view, which can be based on existing private information retrieval (PIR) techniques [20, 38]. Since
the sequence of accesses is not hidden by PIR while each individual access is hidden, the amortized cost is equal to the worst-case
cost [20]. Since the server computes over the entire database for
each individual query, it often results in impracticality for large
databases. On the other hand, ORAM [39] has verifiably low amortized communication complexity and does not require much computation on the server but rather periodically requires the client to
download and reshuffle the data [20]. Then, we choose ORAM since
it is relatively more efficient and secure, and also the client (data
owner in our case) has sufficient computational power and storage
needed to locally store a small number of blocks (audit reports in
our case). Appendix C.3 presents more details on the scalability of
using ORAM in our approach.
7 CONCLUSION
In this paper, we have proposed a multi-view anonymization approach mitigating the semantic attacks on CryptoPAn while preserving the utility of the trace. This novel approach shifted the
trade-off from between privacy and utility to between privacy and
computational cost; the latter has been significantly decreased, making our approach a more preferable solution for applications that
demand both privacy and utility. Our experimental results showed
that our proposed approach also drastically reduced the information
leakage compared to CryptoPAn.