Reverse engineering is a manually intensive but necessary technique for understanding the inner workings of new malware, finding vulnerabilities in existing systems, and detecting patent infringements in released software. An assembly clone search engine facilitates the work of reverse engineers by identifying those duplicated or known parts. However, it is challenging to design a robust clone search engine, since there exist various compiler optimization options and code obfuscation techniques that make logically similar assembly functions appear to be very different. A practical clone search engine relies on a robust vector representation of assembly code. However, the existing clone search approaches, which rely on a manual feature engineering process to form a feature vector for an assembly function, fail to consider the relationships between features and identify those unique patterns that can statistically distinguish assembly functions. To address this problem, we propose to jointly learn the lexical semantic relationships and the vector representation of assembly functions based on assembly code. We have developed an assembly code representation learning model \emph{Asm2Vec}. It only needs assembly code as input and does not require any prior knowledge such as the correct mapping between assembly functions. It can find and incorporate rich semantic relationships among tokens appearing in assembly code. We conduct extensive experiments and benchmark the learning model with state-of-the-art static and dynamic clone search approaches. We show that the learned representation is more robust and significantly outperforms existing methods against changes introduced by obfuscation and optimizations.
SECTION 1.Introduction
Software developments mostly do not start from scratch. Due to the prevalent and commonly uncontrolled reuse of source code in the software development process [1], [2], [3], there exist a large number of clones in the underlying assembly code as well. An effective assembly clone search engine can significantly reduce the burden of the manual analysis process involved in reverse engineering. It addresses the information needs of a reverse engineer by taking advantage of existing massive binary data.

Assembly code clone search is emerging as an Information Retrieval (IR) technique that helps address securityrelated problems. It has been used for differing binaries to locate the changed parts [4], identifying known library functions such as encryption [5], searching for known programming bugs or zero-day vulnerabilities in existing software or Internet of Things (IoT) devices firmware [6], [7], as well as detecting software plagiarism or GNU license infringements when the source code is unavailable [8], [9]. However, designing an effective search engine is difficult, due to varieties of compiler optimizations and obfuscation techniques that make logically similar assembly functions appear to be dramatically different. Figure 1 shows an example. The optimized or obfuscated assembly function breaks control flow and basic block integrity. It is challenging to identify these semantically similar, but structurally and syntactically different assembly functions as clones.

Developing a clone search solution requires a robust vector representation of assembly code, by which one can measure the similarity between a query and the indexed functions. Based on the manually engineered features, relevant studies can be categorized into static or dynamic approaches. Dynamic approaches model the semantic similarity by dynamically analyzing the I/O behavior of assembly code [10], [11], [12], [13]. Static approaches model the similarity between assembly code by looking for their static differences with respect to the syntax or descriptive statistics [6], [7], [8], [14], [15], [16], [17], [18]. Static approaches are more scalable and provide better coverage than the dynamic approaches. Dynamic approaches are more robust against changes in syntax but less scalable. We identify two problems which can be mitigated to boost the semantic richness and robustness of static features. We show that by considering these two factors, a static approach can even achieve better performance than the state-of-the-art dynamic approaches.

P1: Existing state-of-the-art static approaches fail to consider the relationships among features. LSH-S [16], n gram [8], n-perm [8], BinClone [15] and KamlnO [17] model assembly code fragments as frequency values of operations and categorized operands. Tracelet [14] models assembly code as the editing distance between instruction sequences. Discovre [7] and Genius [6] construct descriptive features, such as the ratio of arithmetic assembly instructions, the number of transfer instructions, the number of basic blocks, among others. All these approaches assume each feature or category is an independent dimension. However, a xmm0 Streaming SIMD Extensions (SSE) register is related to SSE operations such as movaps. A fclose libc function call is related to other file-related libc calls such as fopen. A strcpy libc call can be replaced with memcpy. These relationships provide more semantic information than individual tokens or descriptive statistics.


Figure 1:
Different assembly functions compiled from the same source code of gmpz tdiv r 2exp in libgmp. From left to right, the assembly functions are compiled with gcc O0 option, gcc O3 option, LLVM obfuscator Control Flow Graph Flattening option, and LLVM obfuscator Bogus Control Flow Graph option. Asm2Vec can statically identify them as clones.

Show All

To address this problem, we propose to incorporate lexical semantic relationship into the feature engineering process. Manually specifying all the potential relationships from prior knowledge of assembly language is timeconsuming and infeasible in practice. Instead, we propose to learn these relationships directly from plain assembly code. Asm2Vec explores co-occurrence relationships among tokens and discovers rich lexical semantic relationships among tokens (see Figure 2). For example, memcpy, strcpy, memncpy and mempcpy appear to be semantically similar to each other. SSE registers relate to SSE operands. Asm2Vec does not require any prior knowledge in the training process.

P2: The existing static approaches assume that features are equally important [14], [15], [16], [17] or require a mapping of equivalent assembly functions to learn the weights [6], [7]. The chosen weights may not embrace the important patterns and diversity that distinguishes one assembly function from another. An experienced reverse engineer does not identify a known function by equally looking through the whole content or logic, but rather pinpoints critical spots and important patterns that identify a specific function based on past experience in binary analysis. One also does not need mappings of equivalent assembly code. To solve this problem, we find that it is possible to simulate the way in which an experienced reverse engineer works. Inspired by recent development in representation learning [19], [20], we propose to train a neural network model to read many assembly code data and let the model identify the best representation that distinguishes one function from the rest. In this paper, we make the following contributions:

We propose a novel approach for assembly clone detection. It is the first work that employs representation learning to construct a feature vector for assembly code, as a way to mitigate problems PI and P2 in current handcrafted features. All previous research on assembly clone search requires a manual feature engineering process. The clone search engine is part of an open source platform1.

We develop a representation learning model, namely Asm2Vec, for assembly code syntax and control flow graph. The model learns latent lexical semantics between tokens and represents an assembly function as an internally weighted mixture of collective semantics. The learning process does not require any prior knowledge about assembly code, such as compiler optimization settings or the correct mapping between assembly functions. It only needs assembly code functions as inputs.

We show that Asm2Vec is more resilient to code obfuscation and compiler optimizations than state-of-the-art static features and dynamic approaches. Our experiment covers different configurations of compiler and a strong obfuscator which substitutes instructions, splits basic blocks, adds bogus logics, and completely destroys the original control flow graph. We also conduct a vulnerability search case study on a publicly available vulnerability dataset, where Asm2Vec achieves zero false positives and 100% recalls. It outperforms a dynamic state-of-the-art vulnerability search method.

Asm2Vec as a static approach cannot completely defeat code obfuscation. However, it is more resilient to code obfuscation than state-of-the-art static features. This paper is organized as follows: Section 2 formally defines the search problem. Section 3 systematically integrates representation learning into a clone search process. Section 4 describes the model. Section 5 presents our experiment. Section 6 discusses the literature. Section 7 discusses the limitations and concludes the paper.

Figure 2: - T-SNE clustering visualization of tokens appearing in assembly code. There are three categories of tokens: operation, operand, and libc function call. Each token is represented as a 200-dimensional numeric vector. They are learned by Asm2Vec on plain assembly code without any prior knowledge of the assembly language. The training assembly code does not contain the libc callee functions’ content. For visualization, T-SNE reduces the vectors to two dimensions by nearest neighbor approximation. A smaller geometric distance indicates a higher lexical semantic similarity.
Figure 2:
T-SNE clustering visualization of tokens appearing in assembly code. There are three categories of tokens: operation, operand, and libc function call. Each token is represented as a 200-dimensional numeric vector. They are learned by Asm2Vec on plain assembly code without any prior knowledge of the assembly language. The training assembly code does not contain the libc callee functions’ content. For visualization, T-SNE reduces the vectors to two dimensions by nearest neighbor approximation. A smaller geometric distance indicates a higher lexical semantic similarity.

Show All

SECTION 2.Problem Definition
In the assembly clone search literature, there are four types of clones [15], [16], [17]: Type I: literally identical; Type II: syntactically equivalent; Type III: slightly modified; and Type IV: semantically similar. We focus on Type IV clones, where assembly functions may appear syntactically different, but share similar functional logic in their source code. For example, the same source code with and without obfuscation, or a patched source code between different releases. We use the following notions: function denotes an assembly function; source function represents the original function written in source code, such as C++; repository function stands for the assembly function that is indexed inside the repository; and target function denotes the assembly function query. Given an assembly function, our goal is to search for its semantic clones from the repository RP. We formally define the search problem as follows:

Definition 1.
(Assembly function clone search) Given a target function ft, the search problem is to retrieve the top-k repository functions fs∈RP, ranked by their semantic similarity, so they can be considered as Type IV clones.

SECTION 3.Overall Workflow
Figure 3 shows the overall workflow. There are four steps: Step 1: Given a repository of assembly functions, we first build a neural network model for these functions. We only need their assembly code as training data without any prior knowledge. Step 2: After the training phase, the model produces a vector representation for each repository function. Step 3: Given a target function ft that was not trained with this model, we use the model to estimate its vector representation. Step 4: We compare the vector of ft against the other vectors in the repository by using cosine similarity to retrieve the top-k ranked candidates as results.

Figure 3: - The overall work flow of Asm2Vec.
Figure 3:
The overall work flow of Asm2Vec.

Show All

The training process is a one-time effort and is efficient to learn representation for queries. If a new assembly function is added to the repository, we follow the same procedure in Step 3 to estimate its vector representation. The model can be retrained periodically to guarantee the vectors’ quality.

SECTION 4.Assembly Code Representation Learning
In this section, we propose a representation learning model for assembly code. Specifically, our design is based on the PV-DM model [20]. PV-DM model learns document representation based on the tokens in the document. However, a document is sequentially laid out, which is different than assembly code, as the latter can be represented as a graph and has a specific syntax. First, we describe the original PV-DM neural network, which learns a vectorized representation of text paragraph. Then, we formulate our Asm2Vec model and describe how it is trained on instruction sequences for a given function. After, we elaborate how to model a control flow graph as multiple sequences.

4.1. Preliminaries
The PV-DM model is designed for text data. It is an extension of the original word2vec model. It can jointly learn vector representations for each word and each paragraph. Figure 4 shows its architecture.


Figure 4:
The PV-DM model.

Show All

Given a text paragraph which contains multiple sentences, PV-DM applies a sliding window over each sentence. The sliding window starts from the beginning of the sentence and moves forward a single word at each step. For example, in Figure 4, the sliding window has a size of 5. In the first step, the sliding window contains the five words ‘the’, ‘cat’, ‘sat’, ‘on’ and ‘a’. The word ‘sat’ in the middle is treated as the target and the surrounding words are treated as the context. In the second step, the window moves forward a single word and contains ‘cat’, ‘sat’, ‘on’, ‘a’ and ‘mat’, where the word ‘on’ is the target.

At each step, the PV-DM model performs a multi-class prediction task (see Figure 4). It maps the current paragraph into a vector based on the paragraph ID and maps each word in the context into a vector based on the word ID. The model averages these vectors and predicts the target word from the vocabulary through a softmax classification. The back-propagated classification error will be used to update these vectors. Formally, given a text corpus T that contains a list of paragraphs p∈T, each paragraph p contains a list of sentences s∈p, and each sentence is a sequence of |s| words wt∈s. PV-DM maximizes the log probability:
∑pT∑sp∑t=k|s|−klogP(wt|p, wt−k,…,wt+k)(1)
View Source

The sliding window size is 2k+1. The paragraph vector captures the information that is missing from the context to predict the target. It is interpreted as topics [20]. PVDM is designed for text data that is sequentially laid out. However, assembly code carries richer syntax than plaintext. It contains operations, operands, and control flow that are structurally different than plaintext. These differences require a different model architecture design that cannot be addressed by PV-DM. Next, we present a representation learning model that integrates the syntax of assembly code.

4.2. The Asm2Vec Model
An assembly function can be represented as a control flow graph (CFG). We propose to model the control flow graph as multiple sequences. Each sequence corresponds to a potential execution trace that contains linearly laid-out assembly instructions. Given a binary file, we use the IDA Pro2 disassembler to extract a list of assembly functions, their basic blocks, and control flow graphs.

This section corresponds to Step 1 and 2 in Figure 3. In these steps, we train a representation model and produce a numeric vector for each repository function fs∈RP. Figure 5 shows the neural network structure of the model. It is different than the original PV-DM model.

First, we map each repository function fs to a vector θfS→∈R2×d.θfS→ is the vector representation of function fs to be learned in training. d is a user chosen parameter. Similarly, we collect all the unique tokens in the repository RP. We treat operands and operations in assembly code as tokens. We map each token t into a numeric vector v⃗ t∈Rd and another numeric vector v′⃗ t∈R2×d.v⃗ t is the vector representations of token t. After training, it represents a token’s lexical semantics. v⃗ t vectors are used in Figure 2 to visualize the relationship among tokens. v′⃗ t is used for token prediction. All θfS→ and v⃗ t are initialized to small random value around zero. All v′⃗ t are initialized to zeros. We use 2×d for fs since we concatenate the vectors for operation and operands to represent an instruction.

We treat each repository function fs∈ RP as multiple sequences S(fs)=seq[1 : i], where seqi is one of them. We assume that the order of sequences is randomized. A sequence is represented as a list of instructions I(seqi)=in[1 : j], where inj is one of them. An instruction inj contains a list of operands A(inj) and one operation P(inj). Their concatenation is denoted as its list of tokens T(inj)=P(inj)||A(inj), where || denotes concatenation. Constants tokens are normalized into their hexadecimal form.


Figure 5:
The proposed Asm2Vec neural network model for assembly code.

Show All

For each sequence seqi in function fs, the neural network walks through the instructions from its beginning. We collect the current instruction inj, its previous instruction inj−1, and its next instruction inj+1. We ignore the instructions that are out-of-boundary. The proposed model tries to maximize the following log probability across the repository RP:
RPS(fS)I(seqi)T(inj)∑fS∑seqi∑inj∑tclogP(tc|fs, inj−1, inj+1)(2)
View Source

It maximizes the log probability of seeing a token tc at the current instruction, given the current assembly function fs and neighbor instructions. The intuition is to use the current function’s vector and the context provided by the neighbor instructions to predict the current instruction. The vectors provided by neighbor instructions capture the lexical semantic relationship. The function’s vector remembers what cannot be predicted given the context. It models the instructions that distinguish the current function from the others.

For a given function fs, we first look-up its vector representation θfS→ through the previously built dictionary. To model a neighbor instruction in as CT(in)∈R2×d, we average the vector representations of its operands (∈Rd) and concatenate the averaged vector (∈Rd) with the vector representation of the operation. It can be formulated as:
CT(in)=v⃗ ′p(in)||1|A(in)|∑tA(in)v⃗ tb(3)
View Source

Recall that P(∗) denotes an operation and it is a single token. By averaging fs with CT(inj−1) and CT(inj+1), δ(in, fs) models the joint memory of neighbor instructions:
δ(inj, fs)=13(θfS→+CT(inj−1)+CT(inj+1))(4)
View Source

Example 1. Consider a simple assembly code function fs and one of its sequence in Figure 5. Take the third instruction where j=3 for example. T(in3)= {’push’, rbx′}. A(in3−1)={′rbp′,rsp′}.P(in3−1)={′mov′}. We collect their respective vectors v⃗ rbp,v⃗ rsp,v⃗ mov and calculate CT(in3−1)=v⃗ mov||(v⃗ rbp+v⃗ rsp)/2. Following the same procedure, we calculate CT(in3+1). With Equation 4 and θfS we have δ(in3, fs).

Given δ(in, fs), the probability term in Equation 2 can be rewritten as follows:
P(tc|fs, inj−1, inj+1)=P(tc|δ(inj, fs))(5)
View Source

Recall that we map each token into two vectors v⃗  and v′⃗ . For each target token tc∈T(inj), which belongs to the current instruction, we look-up its output vector v′tc. The probability in Equation 5 can be modeled as a softmax multiclass regression problem:
P(tc|δ(inj, fs))=P(v′⃗ tc|δ(inj, fs))=f(v′⃗ tc,δ(inj,fs))–––––––––––––––∑dDf(v′⃗ td, δ(inj, fs))f(v′⃗ tc, δ(inj, fs))=Uh((v′⃗ tc)T×δ(inj, fs))
View Source

D denotes the whole vocabulary constructed upon the repository RP.Uh denotes a sigmoid function applied to each value of a vector. The total number of parameters to be estimated is (|D|+1)×2×d for each pass of the softmax layout. The term |D| is too large for the softmax classification. Following [20], [21], we use the k negative sampling approach to approximate the log probability as:
logP(tc|δ(inj, fs))≈logf(v′⃗ tc|δ(inj, fs))+∑i=1kEtd+Pn(tc)([td≠tcilogf(−1×v′⃗ td,δ(inj,fs(6)
View Source

[⋅] is an identity function. If the expression inside this function is evaluated to be true, then it outputs 1; otherwise 0. For example, [1+2=31=1 and [1+1=3]=0. The negative sampling algorithm distinguishes the correct guess tc with k randomly selected negative samples {td|td≠tc} using k+1 logistic regressions. Etd~Pn(tc) is a sampling function that samples a token td from the vocabulary D according to the noise distribution Pn(tc) constructed from D. By taking derivatives, respectively on v′⃗ t and θfS→, we can calculate the gradients as follows.
∂∂θfs→J(θ)=13∑ikEtbPn(tc)([tb=tcI−f(v′⃗ t,δ(inj,fs×v′⃗ t∂∂v⃗ tJ(θ)=[t=tcI−f(v′⃗ t, δ(inj, fs))×δ(inj, fs)(7)
View SourceRight-click on figure for MathML and additional features.

By taking derivatives, respectively on v⃗ ′p(inj+1) and {v⃗ tb|tb ∈ A(inj+1)}, we can calculate their gradients as follows. It will be the same equation for the previous instruction inj−1, by replacing inj+1 with inj−1.
∂∂v⃗ ′p(inj+1)J(θ)=(∂∂θfS→J(θ))[0:d−1]∂∂v⃗ tbJ(θ)=1|A(inj+1)|×(∂∂θfS→J(θ))[d:2d−1]tb∈A(inj+1)(8)
View SourceRight-click on figure for MathML and additional features.

After, we use back propagation to update the values of the involved vectors. Specifically, we update θfS→, all the involved v⃗ t and involved v′⃗ t according to their gradients, with a learning rate.

Example 2. Continue from Example 1, where the target token tc is ‘push’. Next, we calculate P(v′⃗ push|δ(inj, fs)) using negative sampling (Equation A). After, we calculate the gradients using Equation 7 and 8. We update all the involved vectors in these two examples, according to their respective gradient, with a learning rate.

4.3. Modeling Assembly Functions
In this section, we model an assembly function into multiple sequences. Formally, we treat each repository function fs∈ RP as multiple sequences S(fs)=seq[1 : i]. The original linear layout of control flow graph covers some invalid execution paths. We cannot directly use it as a training sequence. Instead, we model the control flow graph as edge coverage sequences and random walks.

4.3.1. Selective Callee Expansion.
Function inlining is a compiler optimization technique that replaces a function call instruction with the body of the called function. It extends the original assembly function and improves its performance by removing call overheads. It significantly modifies the control flow graph and is a major challenge in assembly clone search [12], [13].

BinGo [12] proposes to selectively inline callee functions into the caller function in the dynamic analysis process. We adopt this technique for static analysis. Function call instructions are selectively expanded with the body of the callee function. BinGo inlines all the standard library calls for the purpose of semantic correctness. We do not inline any library calls, since the lexical semantic among library call tokens have been well captured by the model (see the visualization in Figure 2). BinGo recursively inlines callee, but we only expand the first-order callees in the call graph. Expanding callee functions recursively will include too many callees’ body into the caller, which makes the caller function statically more similar to the callee.

The decoupling metric used by BinGo captures the ratio of in-degree and out-degree of each callee function fc:
(y(fc)=outdegree(fc)/(outdegree(fc)+indegree(fc))(9)
View Source

We adopt the same equation, as well as the same threshold value 0.01, to select a callee for expansion. Additionally, we find that if the callee function is longer than or has a comparable length to the caller, the callee will occupy a too large portion of the caller. The expanded function appears similar to the callee. Thus, we add an additional metric to filter out lengthy callees:
δ(fs, fc)=length(fc)/length(fs)(10)
View Source

We expand a callee if δ is less than 0.6 or fs is shorter than 10 lines of instructions. The second condition is to accommodate wrapper functions.

4.3.2. Edge Coverage.
To generate multiple sequences for an assembly function, we randomly sample all the edges from the callee-expanded control flow graph, until all the edges in the original graph are covered. For each sampled edge, we concatenate their assembly code to form a new sequence. This way, we ensure that the control flow graph is fully covered. The model can still produce similar sequences, even if the basic blocks in the control flow graph are split or merged.

4.3.3. Random Walk.
CACompare [13] uses a random input sequence to analyze the I/O behavior of an assembly function. A random input simulates a random walk on the valid execution flow. Inspired by this method, we extend the assembly sequences for an assembly function by adding multiple random walks on the expanded control flow graph. This way, the generated sequence is much longer than the edge sampling.

Dominator is a widely used concept in control flow analysis and compiler optimizations. A basic block dominates another if one has to pass this block in order to reach the other. Multiple random walks will put a higher probability to cover basic block that dominate others. These popular blocks can be the indicator of loop structures or cover important branching conditions. Using random walks can be considered as a natural way to prioritize basic blocks that dominate others.

4.4. Tranining, Estimating and Searching
The training procedure corresponds to Algorithm 1. For each function in the repository, it generates sequences by edging sampling and random walks. For each sequence, it goes through each instruction and applies the Asm2Vec to update the vectors (Line 10 to 19). As shown in Algorithm 1, the training procedure does not require a ground-truth mapping between equivalent assembly functions.

Algorithm 1 Training the Asm2Vec model for one epoch
1: function TRAIN(Repository RP)

2: shuffle(RP)

3: for each fs∈RP do

4: for each seqi∈S(fs) do

5: for j=1→(|seqi|−1) do

▹ Going through each instruction.

6: lookup fs's representation θfs→

7: calculate CT(inj−1) by Equ. 3

8: calculate CT(inj+1) by Equ. 3

9: calculate δ(inj, fs) by Equ. 4

10: for each tkn∈inj do

▹ Going through each token

11: targets ←EtbP~n(tkn)∪{tkn}

▹ Sample tokens from Pn(tkn)

12: calculate and cumulate gradient for θ⃗ fs (Equ. 7)

13: calculate gradient for v′t→ (Equ. 7)

14: update v′t

15: calculate and cumulate gradient for inj−1 (Equ. 8)

16: calculate and cumulate gradient for inj+1 (Equ. 8)

17: update vectors for tokens of inj−1

18: update vectors for tokens of inj+1

19: update θ⃗ fs

20:

21: function S(Function fs)

22: graph ←CFG(fs)

23: graph←ExpandSellectiveCallee(graph)

24: sequences ←{}

25: for each edg∈SampleEdge(graph) do

26: seq←source(edg)||target(edg)

▹ Concatenate the source and the target blocks

27: sequences ←sequences ∪{seq}

28: for i←numRandomWalk do

29: seq←RandomWalk(graph)

30: sequences ←sequences ∪{seq}

31: return sequences

The estimation step corresponds to Step 3 in Figure 3. For an unseen assembly function ft as query ft∉RP that does not belong to the set of training assembly functions, we first associate it with a vector θft∈R2×d, which is initialized to a sequence of small values close to zero. Then, we follow the same procedure in the training process, where the neural network goes through each sequence of ft and each instruction of the sequence. In every prediction step, we fix all v⃗ t and v′⃗ t in the trained model and only propagate errors to θft→. At the end, we have θft→ while the vectors for all fs∈RP and {v⃗ t, v′⃗ t|t∈D} remain the same. To search for a match, vectors are flattened and compared using cosine similarity.

Scalability is critical for binary clone search, as there may be millions of assembly functions inside a repository. It is practical to train Asm2Vec on a large-scale of assembly code. A similar model on text has been shown to be scalable to billions of text samples for training [21]. In this study, we only use pair-wise similarity for nearest neighbor searching. Pair-wise searching among low-dimensional fix-length vectors can be fast. In our experiment in Section 5.3, there are 139,936 functions. The average training time for each function is 49 milliseconds. The average query response time is less than 300 milliseconds.

Algorithm 2 Estimating a vector representation for a query
1: function ESTIMATE(Query Function {f}_{{t}})

2: initialize ft’s representation \theta_{f_{t}}\rightarrow

3: for each seq_{i} \in S(f_{t}) do

4: for j=1\rightarrow(|seq_{i}|-1) do

5: calculate CT(in_{j-1}) by Equ. 3

6: calculate CT(in_{j+1}) by Equ. 3

7: calculate \delta(in_{j},\ f_{t}) by Equ. 4

8: for each tkn\in in_{j} do

9: targets \leftarrow {E}_{t_{b}} \tilde P_{n}(tkn)\cup\{tkn\}

10: calculate gradient for \vec{\theta}_{f}t (Equ. 7)

11: update \vec{\theta}_{f_{t}}

SECTION 5.Experiments
We compare Asm2Vec with existing available state-of-the-art dynamic and static assembly clone search approaches. All the experiments are conducted with an Intel Xeon 6 core 3. 60GHz CPU with 32G memory. To simulate a similar environment in related studies, we limit the JVM to only 8 threads. There are four experiments. First, we benchmark the baselines against different compiler optimizations with GCC. Second, we evaluate clone search quality against different heavy code obfuscations with CLANG and O-LLVM. Third, we use all the binaries of the previous two. In the last one, we apply Asm2Vec on a publicly available vulnerability search dataset. All binary files are stripped before clone search. In all of the experiments, we choose d = 200, 25 negative samples, 10 random walks, and a decaying learning rate 0.025 for Asm2Vec. 200 corresponds to the suggested dimensionality (2d) used in [20].

5.1. Searching with Different Compiler optimization Levels
In this experiment, we benchmark the clone search performance against different optimization levels with the GCC compiler version 5.4.0. We evaluate Asm2Vec based on 10 widely used utility and numeric calculation libraries in Table 1. They are chosen according to an internal statistic of the prevalence of FOSS libraries. We first compile a selected library using the GCC compiler with four different compiler optimization settings, which results in four different binaries. Then, we test every combination of two of them, which corresponds to two different optimization levels. Given two binaries from the same library but with different optimization levels, we link their assembly functions using the compiler-output debug symbols and generate a clone mapping between functions. This mapping is used as the ground-truth data for evaluation only. We search the first against the second in RP and after, we search for the second against the first in RP. Only the binary in the repository is used for training. We take the average of the two.

A higher optimization level contains all optimization strategies from the lower level. The comparison between O2 and O3 is the easiest one (Figure 6). On average, 26% bytes of a function are modified and none of the functions are identical. 40% of a control flow graph is modified and 65% function pairs share similar graph complexity. It can be considered as the best situation where the optimization strategies used in two binaries are similar. The comparison between OO and O3 is the most difficult one. It can be considered as the worst situation where there exists a large difference in the optimization strategies (Figure 6). On average, 34% bytes of a function are modified and none of the functions are identical. 82% of a control flow graph is modified and 17% function pairs share similar graph complexity. Table 1 presents the results in these two situations. Due to the large number of cases, we only list the results for these two cases to demonstrate the best and worse situations. The results of other cases lie between these two and follow the same ranking.


Figure 6:
The difference between the O0/O2 optimized and the O3 optimized function. a) Relative string editing distance. 0.264 indicates that around 26.4% percent of bytes are different between two options for the same source code function. b) Relative absolute difference in the count of vertices and edges. 0.404% indicates that one function has 40.4% more vertices and edges than the other.

Show All

Table 1 Clone Search Between Different Compiler Optimization Options Using the Precision At Position 1 (Precision@L) Metric. It Captures the Ratio of Assembly Functions That Are Correctly Matched At Position 1. In This Case, It Equals Recall At Position 1. Asm2vec Is Our Proposed Method. Tdenotes Cited Performance. ○ and ● Respectively Indicate P>0.05 and P\leq0.01 For Wilcoxon Signed-Rank Test Between Asm2vec and Each Baseline.

Andriesse et al. [22] point out that using supervised machine learning may risk having invalid experiment results. For example, splitting coreutils binaries into training set and testing set may lead to an invalid good result since these binaries share a very similar code base. This issue is not applicable to our experiment. First, we follow the unsupervised learning paradigm, where the true clone mapping is only used for evaluation. Second, our training data is very different to the testing data, as shown in Figure 6 and Figure 7. For example, the coreutils library comes with many binaries but we statically linked them into a single binary. We train the OO-optimized binary and match the O3-optimized binary. These two binaries are very different.

We use the Precision at Position 1 (Precision@l) metric. For every query, if a baseline returns no answer, we count the precision as zero. Therefore, Precision@l captures the ratio of assembly functions that are correctly matched, which is equal to Recall at Position 1. We benchmark nine feature representations proposed in [8]: mnemonic n grams (denoted as n-gram), mnemonic n-perms (denoted as n-perm), Graphlets (denoted as Graphlet), Extended Graphlets (denoted as Graphlet-E), Colored Graphlets (denoted as Graphlet-C), Mixed Graphlets (denoted as MixGraph), Mixed n-grams/perms (denoted as MixGram), Constants, and the Composite of n-grams/perms and Graphlets (denoted as Composite). The idea of using Graphlet originated from [23]. These baseline methods cover a wide range of popular features from token to graph substructure. These baselines are configured according to the reported best settings in the paper. We also include the original PVDM model and PV-DBOW model as a baseline where each assembly function is treated as a document. We pick the best results and denote it as PV-(DM/DBOW). We only tune the configurations for PV-(DM/DBOW) as well as Asm2Vec on the zlib dataset. FuncSimSearch is an open source assembly clone static search toolkit recently released by Google3. It has a default training dataset that contains a ground-truth mapping of equivalent assembly functions. The state-of the-art dynamic approach BinGo[12] and CACompare [13] are unavailable for evaluation. However, we conduct the experiment in the same way using the same metric. Their reported results are included in Table 1. We also include the Wilcoxon signed-rank test across different binaries to see if the difference in performance is statistically significant.

As shown in Table 1, Asm2Vec significantly outperforms static features in both the best and worse situation. It also outperforms BinGo, a recent semantic clone search approach that involves dynamic features. It shows that Asm2Vec is robust against heavy syntax modifications and intensive inlining introduced by the compiler. Even in the worse case, the learned representation can still correctly match more than 75% of assembly functions at position 1. It even achieves competitive performance against the state-of-theart dynamic approach CACompare for semantic clone. The difference is not statistically different, due to the small sample size. Asm2Vec performs stably across different libraries and is able to find clones with high precision. On average, it achieves more than 93% precision in detecting clones among compiler optimization options Ol, O2, and O3. As the difference between two optimization levels increases, the performance of the Asm2Vec decreases. Nevertheless, it is much less sensitive than the other static features, which demonstrates its robustness.

Discovre and Genius are two recent static approaches that use descriptive statistics and graph matching. Both of them are not available for evaluation. CACompare has been shown to outperform Discovre [7], Genius [6] and Blanket [10]. Our approach achieves comparable performance to CACompare, which indirectly compares Asm2Vec’s performance to Discovre and Genius.

In the best situation where we compare between optimization level O2 and O3, the baseline static features’ performance is inline with the result reported in the original paper, which shows the correctness of our implementation.

In the worse case, we notice that the Constant model outperforms the other static features based on assembly instructions and graph structures. The reason is that constant tokens do not suffer from changes in assembly instructions and subgraph structures. We also notice that BinGo, in the worse case, outperforms static features. However, in the best case, its performance is not as good as static features, such as Graphlet-C and n-grams, because the noise at the symbolic logic level is higher than at the assembly code level. Logical expressions promote recall and can find clones when the syntax is very different. However, assembly instructions can provide more precise information for matching.

The largest binary, OpenSSL, has more than 5,000 functions. Asm2Vec takes on average 153 ms to train an assembly function and 20 ms to process a query. For OpenSSL, CACompare takes on average 12 seconds to fulfill a query.

5.2. Searching with Code Obfuscation
Obfuscator-LLVM (O-LLVM) [24] is built upon the LLVM framework and the CLANG compiler toolchain. It operates at the intermediate language level and modifies a program’s logics before the binary file is generated. It increases the complexity of the binary code. O-LLVM uses three different techniques and their combination: Bogus Control Flow Graph (BCF), Control Flow Flattening (FLA), and Instruction Substitution (SUB). Figure 7 shows the statistics on differences.

BCF modifies the control flow graph by adding a large number of irrelevant random basic blocks and branches. It will also split, merge, and reorder the original basic blocks. BCF breaks CFG and basic block integrity (on average 149% vertices/edges are added).

FLA reorganizes the original CFG using complex hierarchy of new conditions as switches (see an example in Figure 1). The original instructions are heavily modified to accommodate the new entering conditions and variables. The linear layout has been completely modified (on average 376% vertices and edges are added). Graphbased features are oblivious to this technique. It is also unscalable for a dynamic approach to fully cover the CFG.

SUB substitutes fragments of assembly code to its equivalent form by going one pass over the function logic using predefined rules. This technique modifies the contents of basic blocks and adds new constants. For example, additions are transformed to a= b-(-c). Subtractions are transformed to r=rand a=b-r;a=a-c;a=a+r. And operations are transformed to a= (b\wedge– c)& b. SUB does not change much of the graph structure (91% of functions keep the same number of vertex and edge).

BCF+FLA+SUB uses all the obfuscation options above.

O-LLVM heavily modifies the original assembly code. It breaks the CFG and the basic blocks integrity. By design, most of the static features are oblivious to the obfuscation. By using the CLANG compiler with O-LLVM, we successfully compile four libraries used in the last experiment and evaluate Asm2Vec using them. There were compilation errors when compiling the other binaries with the CLANG +O-LLVM toolchain. According to Figure 7, there is a significant difference between the original and the ones obfuscated with BCF and FLA. BCF doubles the number of vertices and edges. FLA almost doubles the latter. With SUB, the number of assembly instructions significantly increases. We use the same set of baselines and configurations from the previous experiment except for BinGo and CACompare, since they are unavailable for evaluation and the original papers do not include such an experiment.

Figure 7: - The difference between the original function and the obfuscated function. a) Relative string editing distance. 0.122 indicates that around 12.2% percent of bytes are modified. b) Relative absolute difference in the count of vertices and edge. 1.49% indicates the obfuscated function has 149% more vertices and edges in CFG.
Figure 7:
The difference between the original function and the obfuscated function. a) Relative string editing distance. 0.122 indicates that around 12.2% percent of bytes are modified. b) Relative absolute difference in the count of vertices and edge. 1.49% indicates the obfuscated function has 149% more vertices and edges in CFG.

Show All

Table 2 Clone Search Between the Original and Obfuscated Binary Using the Precision At Position 1 (Precision@L) Metric. It Captures the Ratio of Functions That Are Correctly Matched At Position 1, Which Is Equal To Recall At Position 1 (Recall@L) In This Case. the Difference Between Asm2vec and Each Baseline Is Significant (p\lt 0.01 In A Wilcoxon Signed-Rank Test).

We first compile a selected library without any obfuscation techniques applied. After, we compile the library again with a chosen obfuscation technique to have an original and an obfuscated binary. We link their assembly functions by using debug symbols and generate a one-to-one clone mapping between assembly functions. This mapping is used for evaluation purposes only. After stripping binaries, we search the original against the obfuscated. Then, we search for the obfuscated against the original. We report the average. We use the Precision@l as our evaluation measure. In this case, Precision@l equals Recall@l, since we treat ‘no-answer’ for a query as a zero precision.

Table 2 shows the results for O-LLVM. We find that instructions substitution can significantly reduce the performance of n-gram. SUB breaks the sequence by adding instructions in between. n-perm performs better than n-gram, since it ignores the order of tokens. Graph-based features can still recover more than 60% of clones, since the graph structure is not heavily modified. Asm2Vec can achieve more than 96% precision against assembly instruction substitution. Instructions are replaced with their equivalent form, which in fact still shares similar lexical semantic to the original. This information is well captured by Asm2Vec.


Figure 8:
Baseline comparison for the third experiment. There are 139,936 assembly functions. We search each one against the rest. The set is a mixture of different compilers, compiler optimization settings, and O-LLVM obfuscation settings. a) Recall rates are plotted for different top-K retrieved results. b) Recall-Precision Curve. c) Sensitivity test on dimensionality.

Show All

After applying BCF obfuscation, Asm2Vec can still achieve more than 88% precision, where the control flow graph already looks very different from the original. It shows that Asm2Vec is resilient to the inserted junk code and faked basic blocks. The FLA obfuscation destroys all the subgraph structures. This is also reflected from the degraded performance of graph sub-structure features. Most of them have a precision value around zero. Even in such situations, Asm2Vec can still correctly match 84% of assembly function clones. It shows that Asm2Vec is resilient to sub-structure changes and linear layout changes. After applying all the obfuscation techniques, Asm2Vec can still recover around 81% of assembly functions.

Asm2Vec can correctly pinpoint and identify critical patterns from noise. Inserted junk basic blocks or noise instructions follow the general syntax of random assembly code, which can be easily predicted by neighbor instructions. The function representation in Asm2Vec captures the missing information that cannot be provided by neighbor instructions. It also weights this information to best distinguish one function from another.

5.3. Searching against All Binaries
In this experiment, we use all the binaries in the previous two experiments. We evaluate whether Asm2Vec can distinguish different assembly functions when the candidate set is large. We also evaluate its performance with varying retrieval thresholds to inspect whether true positives are ranked at the top. Specifically, there are in total 60 binaries, which are a mixture of libraries compiled for different compiler options (OO-O3), different compilers (GCC and CLANG), and different O-LLVM obfuscation configurations. Following the experiment in Genius [6] and Discovre [7], we consider assembly functions that have at least 5 basic blocks. However, we do not use sampling. We use all of them. In total, there are 139,936 assembly functions. For each of them, we search against the rest to find clones. We sort the returned results and evaluate each of them in sequence. We use the same set of baselines and configuration from the last experiment except for FuncSimSearch, since it throws segmentation fault when indexing all the binaries. We collect recall and precision at different top-k positions. We plot recall against k in Figure 8(a). We remove Graphlet from the figure, since it does not perform any better than Graphlet-Extended. Even with a large size of assembly functions, Asm2Vec can still achieve a recall of 70% for the top 20 results. It significantly outperforms other traditional token-based and graph-based features. Moreover, we observe that token-based approaches in general perform better than subgraph-based approaches.

We plot precision against recall for each baseline in Figure 8(b). This curve evaluates a clone search engine with respect to the trade-0ff between precision and recall, when varying the number of retrieved results. As shown in the plot, Asm2Vec outperforms traditional representations of assembly code. It achieves 82% precision for the returned top clone search result where k = 1. The false positives on average have 33 basic blocks (\sigma\ =\ 231). On the other hand, all the functions in the dataset on average have 47 basic blocks (\sigma\ =\ 110) as a prior. By using a one-sided Kolmogorov-Smirnov test, we can conclude that false positives have a smaller number of basic blocks than the overall population (p\ \lt \ 2.2e^{-16}). We conduct a sensitivity test based on top-200 results to evaluate different choices of vector size. Figure 8 (c) shows that with difference vector size Asm2Vec is stable for both efficacy and efficiency. We tried to incorporate more neighbor instructions. However, this increases the possible patterns to be learned and requires more data. In our experiment, we did not find such design effective.

5.4. Searching Vulnerability Functions
In the above experiments, we evaluate Asm2Vec’s overall performance on matching general assembly functions. In this case study, we apply Asm2Vec on a publicly available vulnerability dataset4 presented in [18] to evaluate its performance in actually recovering the reuse of the vulnerabilities in functions. The dataset contains 3,015 assembly functions.

Table 3 Evaluating Asm2vec On the Vulnerability Dataset [18] Using the False Positives (FP), Receiver Operating Characteristic (ROC), and Concentrated ROC (CROC) Metrics. For All the Cases, Asm2vec Retrieves All Results without Any False Positives.

For each of the 8 given vulnerabilities, the task is to retrieve its variants from the dataset. The variants are either from different source code versions or generated by different versions of GCC, ICC and CLANG compilers. This dataset is closely related to the real-life scenario.

Figure 9 shows an example of using Asm2Vec to search for the Heartbleed vulnerability in the dataset. The query is a function containing the Heartbleed vulnerability in OpenSSL version 1. 0.1f, compiled with Clang 3.5. There are total 15 different functions containing this vulnerability. The pie chart in each ranked entry indicates the similarity. Each ranked entry contains the assembly function name and its corresponding binary file. As shown in the ranked list, Asm2Vec successfully retrieves all the 15 candidates in the top 15 results. Therefore, it has a precision and recall of 1 for this query. The first entry corresponds to the same function as the query. However, it does not have a similarity of 1 since the query’s representation is estimated but the one in repository is trained. However, it is still ranked first.

We implement Asm2Vec as an open source vulnerability search engine and follow the same experimental protocol to compare its performance with the state-of-the-art vulnerability search solution in [18]. Table 3 shows the results. We use the same performance metrics as [18]: False Positives (FP), Receiver Operating Characteristic (ROC), and Concentrated ROC (CROC). For all the vulnerabilities, Asm2Vec has zero false positives and 100% recall. Therefore, it achieves a ROC and a CROC of 1. It outperforms [18].

Tigress [25] is another advanced obfuscator. It transforms the C Intermediate Language (CIL) using virtualization and Just-In-Time (JIT) execution. Tigress failed to obfuscate a complete library binary due to compilation errors. Therefore we were unable to evaluate Asm2Vec against Tigress in the same way as against O-LLVM in Section 5.2. We increase the difficulty on the vulnerability search by using the Tigress obfuscator. In this experiment, for each of the 8 different vulnerabilities, we obfuscate the query function with literals encoded, virtualization, and Just-InTime execution. Then, we try to recover their original variants from the dataset. Encode Literals: Literal integers are replaced with opaque expressions. Literal strings are replaced with a function that generates them at runtime. Virtualization: This transformation turns a function into an interpreter with specialized byte code translation. By design, it is difficult for a static approach to detect clones protected by this technique. JIT: It transforms the function to generate its code at runtime. Almost every instruction is replaced with a function call. By design, a static approach can hardly recover any variants. Our result shows that Asm2Vec is still able to recover 97.2% with literals encoded, 35% with virualization, and 45% with JIT execution (see Table 4). We inspect the result and find that Asm2Vec tries to match any similar information neglected by the obfuscator. However, after applying three obfuscation techniques at the same time, Asm2Vec can no longer recover any clone.

Figure 9: - Searching the Heartbleed vulnerable function in the vulnerability dataset. The binary name indicates the compiler, library name, and library version. For example, clang.3.5 openssl.1.0.1f indicates that the binary is library OpenSSL version 1.0.1f compiled with clang version 3.5.
Figure 9:
Searching the Heartbleed vulnerable function in the vulnerability dataset. The binary name indicates the compiler, library name, and library version. For example, clang.3.5 openssl.1.0.1f indicates that the binary is library OpenSSL version 1.0.1f compiled with clang version 3.5.

Show All

SECTION 6.Related Work
Static approaches such as k-gram [26], LSH-S [16], n gram [8], BinClone [15], ILine [27], and KamlnO [17] rely on operations or categorized operands as static features. BinSequence [28] and Tracelet [14] model assembly code as the editing distance between instruction sequences. All these features failed to leverage the semantic relationship between operations or categories. TEDEM [29] compares basic blocks by their expression trees. However, even semantically similar instructions result in different expressions and side effects, which make them sensitive to instruction changes. ILine [27], Discovre [7], Genius [6], BinSign [30], and BinShape [31] construct descriptive statistic features, such as ratio of arithmetic assembly instructions, ratio of transfer instructions, number of basic blocks, and number of function calls, among others. Instruction-based features failed to consider the relationships between instructions and are affected by instruction substitutions. In NLP tasks one usually penalizes frequent words by filtering, subsampling or generalization. For assembly language we find that frequent words improve the robustness of the representation.

Table 4 True Positive Rate (TPR) of the Top-K Results Searching the Obfuscated Vulnerable Function Against the Dataset In [18]. K Is Chosen As the Number of Ground-Truth Clones In the Dataset. For Example, Venom CVE 2015-3456-4877 Has 6 Variants In the Dataset. By Inspecting the Top-6 Results From Asm2vec We Recovered 100% (6/6) For the Query with Literals Encoded, 100% (6/6) For the Virtualized Query, and 83.3% (5/6) For JIT-Transformed Query. After Applying All the Options At the Same Time, Asm2vec Cannot Recover Any True Positives.

Graph-based features are oblivious to CFG manipulations. BinDiff [32] and BinSlayer [33] rely on CFG matching, which is susceptible to CFG changes such as flattening. Gitz [34] is another static approach that used at the IR level. However, it operates at the boundary of a basic block and assumes basic block integrity, which is vulnerable to splitting. [35] proposes a graph convolution approach. It might be able to mitigate graph manipulation. However, it relies on supervised learning and requires a ground-truth mapping of equivalent assembly functions to be trained. Asm2Vec enriches static features by considering the lexical semantic relationships between tokens appearing in assembly code. It also avoids direct use of the graph-based features and is more robust against CFG manipulations. However, the CFG is useful in some malware analysis scenarios, especially for matching template-generated and marco-generated functions that share similar CFG structure. One direction is to combine Asm2Vec and Tracelet [14] or subgraph search [17].

Dynamic methods measure semantic similarity by dynamically analyzing the behavior of the target assembly code. BinHunt [36], iBinHunt [37], and ESH [18] use a theorem prover to verify whether two basic blocks or strands are equivalent. BinHunt and iBinHunt assume basic blocks integrity. ESH assumes strand integrity. They are vulnerable to block splitting. Jiang et al. [38], Blex [10], MultiMH [11], and BinGo [12] use randomly-sampled values to compare I/O values. Random sampling may not correctly discriminate two logics. Consider that one expression outputs 1 if v! = 100; otherwise, 0. Another expression outputs 1 if v! = 20, otherwise, 0. Given a widely-used sampling range [-1000, 1000], they have a high chance of being equivalent. CACompare follows the similar idea used in [39], [40], [41]. Besides of I/O values, it records all intermediate execution results and library function calls for matching. Using similar experiments to match assembly functions, CACompare achieves the best performance among the binary clone search literature at the time of writing this paper. However, it depends on a single input value and only covers one execution path. As stated by the authors, it is vulnerable to CFG changes. Asm2Vec leverages the lexical semantic rather than the symbolic relationship which is more scalable and less vulnerable to added noisy logics. As a static approach, Asm2Vec achieves competitive performance compared to CACompare. CryptoHunt is a recent dynamic approach for matching cryptographic functions. It can detect wrapped cryptographic API calls. Asm2Vec focuses on assembly code similarity, which is different to CryptoHunt. Source code clone is another related area. CCFINDERX [42] and CP-Miner [43] use lexical tokens as features to find code clones. Baxter et al. [44] and Deckard [45] leverage abstract syntax trees for clone detection. ReDebug [46] is another scalable source code search engine. Recently, deep learning has been applied on this problem [47].

SECTION 7.Limitations and Conclusion
Asm2Vec suffers from several limitations. First, it is designed for a single assembly code language and the clone search engine is architecture-agnostic. At this stage, it is not directly applicable for semantic clones across architectures. In the future, we will align the lexical semantic space between two different assembly languages by considering their shared tokens, such as constants and libc calls. Second, the current selective callee expansion mechanism cannot determine the dynamic jumps, such as jump table. Third, as a black box static approach, Asm2Vec cannot explain or justify the returned results by showing the cloned subgraphs or proving symbolic equivalence. It has limited interpretability.

In this paper, we propose a robust and accurate assembly clone search approach named Asm2Vec, which learns a vector representation of an assembly function by discriminating it from the others. Asm2Vec does not require any prior knowledge such as the correct mapping between assembly functions or the compiler optimization level used. It learns lexical semantic relationships of tokens appearing in assembly code, and represents an assembly function as an internally weighted mixture of latent semantics. Besides assembly functions, it can be applied on different granularities of assembly sequences, such as binaries, fragments, basic blocks, or functions. We conduct extensive experiments on assembly code clone search, using different compiler optimization options and obfuscation techniques. Our results suggest that Asm2Vec is accurate and robust against severe changes in the assembly instructions and control flow graph.