With cloud storage services, users can remotely store their data to the cloud and realize the data sharing with others. Remote data integrity auditing is proposed to guarantee the integrity of the data stored in the cloud. In some common cloud storage systems such as the electronic health records system, the cloud file might contain some sensitive information. The sensitive information should not be exposed to others when the cloud file is shared. Encrypting the whole shared file can realize the sensitive information hiding, but will make this shared file unable to be used by others. How to realize data sharing with sensitive information hiding in remote data integrity auditing still has not been explored up to now. In order to address this problem, we propose a remote data integrity auditing scheme that realizes data sharing with sensitive information hiding in this paper. In this scheme, a sanitizer is used to sanitize the data blocks corresponding to the sensitive information of the file and transforms these data blocks' signatures into valid ones for the sanitized file. These signatures are used to verify the integrity of the sanitized file in the phase of integrity auditing. As a result, our scheme makes the file stored in the cloud able to be shared and used by others on the condition that the sensitive information is hidden, while the remote data integrity auditing is still able to be efficiently executed. Meanwhile, the proposed scheme is based on identity-based cryptography, which simplifies the complicated certificate management. The security analysis and the performance evaluation show that the proposed scheme is secure and efficient.
SECTION I.Introduction
With the explosive growth of data, it is a heavy burden for users to store the sheer amount of data locally. Therefore, more and more organizations and individuals would like to store their data in the cloud. However, the data stored in the cloud might be corrupted or lost due to the inevitable software bugs, hardware faults and human errors in the cloud [1]. In order to verify whether the data is stored correctly in the cloud, many remote data integrity auditing schemes have been proposed [2]–[3][4][5][6][7][8].

In remote data integrity auditing schemes, the data owner firstly needs to generate signatures for data blocks before uploading them to the cloud. These signatures are used to prove the cloud truly possesses these data blocks in the phase of integrity auditing. And then the data owner uploads these data blocks along with their corresponding signatures to the cloud. The data stored in the cloud is often shared across multiple users in many cloud storage applications, such as Google Drive, Dropbox and iCloud. Data sharing as one of the most common features in cloud storage, allows a number of users to share their data with others. However, these shared data stored in the cloud might contain some sensitive information. For instance, the Electronic Health Records (EHRs) [9] stored and shared in the cloud usually contain patients’ sensitive information (patient’s name, telephone number and ID number, etc.) and the hospital’s sensitive information (hospital’s name, etc.). If these EHRs are directly uploaded to the cloud to be shared for research purposes, the sensitive information of patient and hospital will be inevitably exposed to the cloud and the researchers. Besides, the integrity of the EHRs needs to be guaranteed due to the existence of human errors and software/hardware failures in the cloud. Therefore, it is important to accomplish remote data integrity auditing on the condition that the sensitive information of shared data is protected.

A potential method of solving this problem is to encrypt the whole shared file before sending it to the cloud, and then generate the signatures used to verify the integrity of this encrypted file, finally upload this encrypted file and its corresponding signatures to the cloud. This method can realize the sensitive information hiding since only the data owner can decrypt this file. However, it will make the whole shared file unable to be used by others. For example, encrypting the EHRs of infectious disease patients can protect the privacy of patient and hospital, but these encrypted EHRs cannot be effectively utilized by researchers any more. Distributing the decryption key to the researchers seems to be a possible solution to the above problem. However, it is infeasible to adopt this method in real scenarios due to the following reasons. Firstly, distributing decryption key needs secure channels, which is hard to be satisfied in some instances. Furthermore, it seems very difficult for a user to know which researchers will use his/her EHRs in the near future when he/she uploads the EHRs to the cloud. As a result, it is impractical to hide sensitive information by encrypting the whole shared file. Thus, how to realize data sharing with sensitive information hiding in remote data integrity auditing is very important and valuable. Unfortunately, this problem has remained unexplored in previous researches.

Contribution

The contribution of this paper can be summarized as follows:

We investigate how to achieve data sharing with sensitive information hiding in remote data integrity auditing, and propose a new concept called identity-based shared data integrity auditing with sensitive information hiding for secure cloud storage. In such a scheme, the sensitive information can be protected and the other information can be published. It makes the file stored in the cloud able to be shared and used by others on the condition that the sensitive information is protected, while the remote data integrity auditing is still able to be efficiently executed.

We design a practical identity-based shared data integrity auditing scheme with sensitive information hiding for secure cloud storage. A sanitizer is used to sanitize the data blocks corresponding to the sensitive information of the file. In our detailed scheme, firstly, the user blinds the data blocks corresponding to the personal sensitive information of the original file and generates the corresponding signatures, and then sends them to a sanitizer. The sanitizer sanitizes these blinded data blocks into a uniform format and also sanitizes the data blocks corresponding to the organization’s sensitive information. It also transforms the corresponding signatures into valid ones for the sanitized file. This method not only realizes the remote data integrity auditing, but also supports the data sharing on the condition that sensitive information is protected in cloud storage. To the best of our knowledge, this is the first scheme with the above functions. Besides, our scheme is based on identity-based cryptography, which simplifies the complex certificate management.

We give the security analysis of the proposed scheme, and also justify the performance by concrete implementations. The result shows that the proposed scheme achieves desirable security and efficiency.

A. An Illustrative Example for EHRs
Here, we give an illustrative example for EHRs in Fig. 1. In this example, the sensitive information of EHRs contains two parts. One is the personal sensitive information (patient’s sensitive information), such as patient’s name and patient’s ID number. The other is the organization’s sensitive information (hospital’s sensitive information), such as the hospital’s name.* Generally speaking, the above sensitive information should be replaced with wildcards when the EHRs are uploaded to cloud for research purpose. The sanitizer can be viewed as the administrator of the EHR information system in a hospital. The personal sensitive information should not be exposed to the sanitizer. And all of the sensitive information should not be exposed to the cloud and the shared users. A medical doctor needs to generate and send the EHRs of patients to the sanitizer for storing them in the EHR information system. However, these EHRs usually contain the sensitive information of patient and hospital, such as patient’s name, patient’s ID number and hospital’s name. To preserve the privacy of patient from the sanitizer, the medical doctor will blind the patient’s sensitive information of each EHR before sending this EHR to the sanitizer. The medical doctor then generates signatures for this blinded EHR and sends them to the sanitizer. The sanitizer stores these messages into EHR information system. When the medical doctor needs the EHR, he sends a request to the sanitizer. And then the sanitizer downloads the blinded EHR from the EHR information system and sends it to the medical doctor. Finally, the medical doctor recovers the original EHR from this blinded EHR. When this EHR needs to be uploaded and shared in the cloud for research purpose, in order to unify the format, the sanitizer needs to sanitize the data blocks corresponding to the patient’s sensitive information of the EHR. In addition, to protect the privacy of hospital, the sanitizer needs to sanitize the data blocks corresponding to the hospital’s sensitive information. Generally, these data blocks are replaced with wildcards. Furthermore, the sanitizer can transform these data blocks’ signatures into valid ones for the sanitized EHR. It makes the remote data integrity auditing still able to be effectively performed. During the process of sanitization, the sanitizer does not need to interact with medical doctors. Finally, the sanitizer uploads these sanitized EHRs and their corresponding signatures to the cloud. In this way, the EHRs can be shared and used by researchers, while the sensitive information of EHRs can be hidden. Meanwhile, the integrity of these EHRs stored in the cloud can be ensured.


Fig. 1.
Example of EHRs.

Show All

The sanitizer is necessary because of the following reasons. Firstly, after the data blocks corresponding to the patient’s sensitive information are blinded, the contents of these data blocks might become messy code. The sanitizer can unify the format by using wildcards to replace the contents of these data blocks. In addition, the sanitizer also can sanitize the data blocks corresponding to the hospital’s sensitive information such as hospital’s name by using wildcards, which protects the privacy of the hospital. Secondly, the sanitizer can facilitate the information management. It can sanitize the EHRs in bulk, and uploads these sanitized EHRs to the cloud at a fixed time. Thirdly, when the medical doctor needs the EHR, the sanitizer as the administrator of EHR information system can download the blinded EHR from the EHR information system and sends it to the medical doctor. The medical doctor can recover the original EHR from the blinded one.

B. Related Work
In order to verify the integrity of the data stored in the cloud, many remote data integrity auditing schemes have been proposed. To reduce the computation burden on the user side, a Third Party Auditor (TPA) is introduced to periodically verify the integrity of the cloud data on behalf of user. Ateniese et al. [2] firstly proposed a notion of Provable Data Possession (PDP) to ensure the data possession on the untrusted cloud. In their proposed scheme, homomorphic authenticators and random sampling strategies are used to achieve blockless verification and reduce I/O costs. Juels and Kaliski [3] defined a model named as Proof of Retrievability (PoR) and proposed a practical scheme. In this scheme, the data stored in the cloud can be retrieved and the integrity of these data can be ensured. Based on pseudorandom function and BLS signature, Shacham and Waters [4] proposed a private remote data integrity auditing scheme and a public remote data integrity auditing scheme.

In order to protect the data privacy, Wang et al. [5] proposed a privacy-preserving remote data integrity auditing scheme with the employment of a random masking technique. Worku et al. [6] utilized a different random masking technique to further construct a remote data integrity auditing scheme supporting data privacy protection. This scheme achieves better efficiency compared with the scheme in [5]. To reduce the computation burden of signature generation on the user side, Guan et al. [7] designed a remote data integrity auditing scheme based on the indistinguishability obfuscation technique. Shen et al. [8] introduced a Third Party Medium (TPM) to design a light-weight remote data integrity auditing scheme. In this scheme, the TPM helps user generate signatures on the condition that data privacy can be protected. In order to support data dynamics, Ateniese et al. [10] firstly proposed a partially dynamic PDP scheme. Erway et al. [11] used a skip list to construct a fully data dynamic auditing scheme. Wang et al. [12] proposed another remote data integrity auditing scheme supporting full data dynamics by utilizing Merkle Hash Tree. To reduce the damage of users’ key exposure, Yu et al. [13] and [14], and Yu and Wang [15] proposed key-exposure resilient remote data integrity auditing schemes based on key update technique [16].

The data sharing is an important application in cloud storage scenarios. To protect the identity privacy of user, Wang et al. [17] designed a privacy-preserving shared data integrity auditing scheme by modifying the ring signature for secure cloud storage. Yang et al. [18] constructed an efficient shared data integrity auditing scheme, which not only supports the identity privacy but only achieves the identity traceability of users. Fu et al. [19] designed a privacy-aware shared data integrity auditing scheme by exploiting a homomorphic verifiable group signature. In order to support efficient user revocation, Wang et al. [20] proposed a shared data integrity auditing scheme with user revocation by using the proxy re-signature. With the employment of the Shamir secret sharing technique, Luo et al. [21] constructed a shared data integrity auditing scheme supporting user revocation.

The aforementioned schemes all rely on Public Key Infrastructure (PKI), which incurs the considerable overheads from the complicated certificate management. To simplify certificate management, Wang [22] proposed an identity-based remote data integrity auditing scheme in multicloud storage. This scheme used the user’s identity information such as user’s name or e-mail address to replace the public key. Wang et al. [23] designed a novel identity-based proxy-oriented remote data integrity auditing scheme by introducing a proxy to process data for users. Yu et al. [24] constructed a remote data integrity auditing scheme with perfect data privacy preserving in identity-based cryptosystems. Wang et al. [25] proposed an identity-based data integrity auditing scheme satisfying unconditional anonymity and incentive. Zhang et al. [26] proposed an identity-based remote data integrity auditing scheme for shared data supporting real efficient user revocation.

Other aspects, such as privacy-preserving authenticators [27] and data deduplication [28], [29] in remote data integrity auditing have also been explored. However, all of existing remote data integrity auditing schemes cannot support data sharing with sensitive information hiding. In this paper, we explore how to achieve data sharing with sensitive information hiding in identity-based integrity auditing for secure cloud storage.

C. Organization
The rest of this paper is organized as follows: In Section II, we present notations and preliminaries. In Section III, the system model and security model are presented. We introduce the proposed scheme in Section IV. In Section V and Section VI, the security analysis and the performance evaluation are given respectively. Finally, we conclude our paper in Section VII.

SECTION II.Notions and Preliminaries
A. Notions
We show some notations used in the description of our scheme in Table I.

TABLE I Notations
Table I- 
Notations
B. Preliminaries
In this section, we review some preliminary cryptography knowledge, including bilinear map, Computational Diffie-Hellman (CDH) problem and Discrete Logarithm (DL) problem.

Bilinear Map

Let G1 , G2 be two multiplicative cyclic groups of large prime order p , and g be a generator of G1 . Bilinear map is a map e:G1×G1→G2 with the following properties:

Bilinearity: for all u,v∈G1 and a,b∈Z∗p , e(ua,vb)=e(u,v)ab .

Computability: there exists an efficiently computable algorithm for computing map e .

Non-degeneracy: e(g,g)≠1 .

Computational Diffie-Hellman (CDH) Problem

For unknown x ,y∈Z∗p , given g , gx and gy as input, output gxy∈G1 . The CDH assumption in G1 holds if it is computationally infeasible to solve the CDH problem in G1 .

Discrete Logarithm (DL) Problem

For unknown x∈Z∗p , given g and gx as input, outputs x . The DL assumption in G1 holds if it is computationally infeasible to solve the DL problem in G1 .

SECTION III.System Model and Security Model
A. System Model
The system model involves five kinds of different entities: the cloud, the user, the sanitizer, the Private Key Generator (PKG) and the Third Party Auditor (TPA), as shown in Fig.2.

Cloud: The cloud provides enormous data storage space to the user. Through the cloud storage service, users can upload their data to the cloud and share their data with others.

User: The user is a member of an organization, which has a large number of files to be stored in the cloud.

Sanitizer: The sanitizer is in charge of sanitizing the data blocks corresponding to the sensitive information (personal sensitive information and the organization’s sensitive information) in the file, transforming these data blocks’ signatures into valid ones for the sanitized file, and uploading the sanitized file and its corresponding signatures to the cloud.

PKG: The PKG is trusted by other entities. It is responsible for generating system public parameters and the private key for the user according to his identity ID.

TPA: The TPA is a public verifier. It is in charge of verifying the integrity of the data stored in the cloud on behalf of users.


Fig. 2.
The system model.

Show All

The user firstly blinds the data blocks corresponding to the personal sensitive information of the file, and generates the corresponding signatures. These signatures are used to guarantee the authenticity of the file and verify the integrity of the file. Then the user sends this blinded file and its corresponding signatures to the sanitizer. After receiving the message from the user, the sanitizer sanitizes these blinded data blocks and the data blocks corresponding to the organization’s sensitive information, and then transforms the signatures of sanitized data blocks into valid ones for the sanitized file. Finally, the sanitizer sends this sanitized file and its corresponding signatures to the cloud. These signatures are used to verify the integrity of the sanitized file in the phase of integrity auditing.

When the TPA wants to verify the integrity of the sanitized file stored in the cloud, he sends an auditing challenge to the cloud. And then, the cloud responds to the TPA with an auditing proof of data possession. Finally, the TPA verifies the integrity of the sanitized file by checking whether this auditing proof is correct or not.

B. Design Goals
To efficiently support data sharing with sensitive information hiding in identity-based integrity auditing for secure cloud storage, our scheme is designed to achieve the following goals:

The correctness:

Private key correctness: to ensure that when the PKG sends a correct private key to the user, this private key can pass the verification of the user.

The correctness of the blinded file and its corresponding signatures: to guarantee that when the user sends a blinded file and its corresponding valid signatures to the sanitizer, the blinded file and its corresponding signatures he generates can pass the verification of the sanitizer.

Auditing correctness: to ensure that when the cloud properly stores the user’s sanitized data, the proof it generates can pass the verification of the TPA.

Sensitive information hiding: to ensure that the personal sensitive information of the file is not exposed to the sanitizer, and all of the sensitive information of the file is not exposed to the cloud and the shared users.

Auditing soundness: to assure that if the cloud does not truly store user’s intact sanitized data, it cannot pass the TPA’s verification.

C. Definition
Definition 1:
An identity-based shared data integrity auditing scheme with sensitive information hiding for secure cloud storage consists of the following six algorithms: Setup, Extract, SigGen, Sanitization, ProofGen and ProofVerif y. Specifically, these algorithms are described as follows:

Setup(1k) is a setup algorithm run by the PKG. It takes as input a security parameter k . It outputs the master secret key msk and the system public parameters pp.

Extract(pp,msk,ID) is an extraction algorithm run by the PKG. It takes as input the system public parameters pp, the master secret key msk, and a user’s identity ID. It outputs the user’s private key skID . The user can verify the correctness of skID and accept it as his private key only if it passes the verification.

SigGen(F,skID,ssk,name) is a signature generation algorithm run by the user ID. It takes as input the original file F , the user’s private key skID , the user’s signing private key ssk and the file identifier name name. It outputs a blinded file F∗ , its corresponding signature set Φ and a file tag τ .

Sanitization(F∗,Φ) is a sensitive information sanitization algorithm run by the sanitizer. It takes as input the blinded file F∗ and its signature set Φ . It outputs the sanitized file F′ and its corresponding signature set Φ′ .

ProofGen(F′,Φ′,chal) is a proof generation algorithm run by the cloud. It takes as input the sanitized file F′ , the corresponding signature set Φ′ and the auditing challenge chal. It outputs an auditing proof P that is used to demonstrate the cloud truly possesses this sanitized file F′ .

ProofVerify(chal,pp,P) is a proof verification algorithm run by the TPA. It takes as input the auditing challenge chal, the system public parameters pp and the auditing proof P . The TPA can verify the correctness of proof P .

D. Security Model
To formalize the security model, we indicate a game between a challenger C and an adversary A to show how the adversary A is against the security of an identity-based shared data integrity auditing scheme with sensitive information hiding. The data owner is viewed as a challenger C and the untrusted cloud server is viewed as an adversary A in our security model. This game includes the following phases:

Setup phase. The challenger C runs the Setup algorithm to obtain the master secret key msk and the system public parameters pp, and then sends the public parameters pp to the adversary A .

Query phase. In this phase, the adversary A makes the following two queries to the challenger C .

Extract Queries: The adversary A queries the private key for the identity ID. The challenger C runs the Extract algorithm to generate the private key skID , and sends it to the adversary A .

SigGen Queries: The adversary A queries the signatures of the file F . By running the Extract algorithm, the challenger C gets the private key. And then the challenger C runs the SigGen algorithm to calculate the signatures of the file F . Finally, the challenger C sends these signatures to the adversary A .

Challenge phase. In this phase, the adversary A acts as a prover and the challenger C plays the role of a verifier. The challenger C sends the challenge chal={i,vi}i∈I to the adversary A , where I∈{γ1,γ2,…,γc} (γj∈[1,n] , j∈[1,c] and c∈[1,n] ). Meanwhile, it requests the adversary A to provide a data possession proof P for the data blocks {mγ1,mγ2,…,mγc} under the chal.

Forgery phase. After receiving the challenge from the challenger C , the adversary A generates a data possession proof P for the data blocks indicated by chal to reply the challenger C . If this proof P can pass the verification of the challenger C with non-negligible probability, we say that the adversary A succeeds in the above game.

In the above security model, we need to prove that if an adversary A , who does not keep all the data blocks challenged by the challenger C , cannot guess all the corrupted data blocks, then it cannot generate a valid proof P to pass the verification of the challenger C . The goal of the adversary A is to pass the verification of the challenger C by generating a valid proof P for the challenged data blocks. The definition 2 presents that there exists a knowledge extractor that can capture the challenged data blocks whenever the adversary can output a valid data possession proof P . The definition 3 is to describe the detectability for the data integrity auditing scheme, which can ensure that the cloud truly keeps the data blocks that are not challenged with high probability.

Definition 2:
We say a remote data integrity auditing scheme is secure if the following condition holds: whenever an adversary A in the aforementioned game can generate a valid proof P to pass the verification of the challenger C with non-negligible probability, there exists a knowledge extractor that can capture the challenged data blocks except possibly with negligible probability.

Definition 3:
A remote data integrity auditing scheme is (ρ,δ) (0<ρ,δ<1 ) detectable if the cloud corrupted ρ fraction of the whole file, these corrupted data blocks can be detected with the probability at least δ .

We consider the sanitizer is not fully trustworthy. The sanitizer might be curious about the personal sensitive information of the file. In addition, the cloud and the shared users might be curious about all of the sensitive information of the file. Thus, the personal sensitive information of the file should not be exposed to the sanitizer, and all of the sensitive information of the file should not be exposed to the cloud and the shared users in our scheme. That is to say, even if the sanitizer is untrustworthy, the personal sensitive information of the file will not be exposed to it. Furthermore, even if the cloud and the shared users are untrustworthy, all of the sensitive information of the file will not be exposed to them. Therefore, we give the following security definition.

Definition 4:
We say a remote data integrity auditing scheme achieves sensitive information security if the sanitizer cannot derive the personal sensitive information of the file, besides the cloud and the shared users cannot derive any sensitive information of the file.

SECTION IV.The Proposed Scheme
A. An Overview
In order to achieve data sharing with sensitive information hiding, we consider making use of the idea in the sanitizable signature [30] to sanitize the sensitive information of the file by introducing an authorized sanitizer. Nonetheless, it is infeasible if this sanitizable signature is directly used in remote data integrity auditing. Firstly, this signature in [30] is constructed based on chameleon hashes [31]. However, a lot of chameleon hashes exhibit the key exposure problem. To avoid this security problem, the signature used in [30] requires strongly unforgeable chameleon hashes, which will inevitable incur huge computation overhead [31]. Secondly, the signature used in [30] does not support blockless verifiability. It means that the verifier has to download the entire data from the cloud to verify the integrity of data, which will incur huge communication overhead and excessive verification time in big data storage scenario. Thirdly, the signature used in [30] is based on the PKI, which suffers from the complicated certificate management.

In order to address above problems, we design a new efficient signature algorithm in the phase of signature generation. The designed signature scheme supports blockless verifiability, which allows the verifier to check the integrity of data without downloading the entire data from the cloud. In addition, it is based on identity-based cryptography, which simplifies the complicated certificate management.

In our proposed scheme, the PKG generates the private key for user according to his identity ID. The user can check the correctness of the received private key. When there is a desire for the user to upload data to the cloud, in order to preserve the personal sensitive information of the original file from the sanitizer, this user needs to use a blinding factor to blind the data blocks corresponding to the personal sensitive information of the original file. When necessary, the user can recover the original file from the blinded one by using this blinding factor. And then this user employs the designed signature algorithm to generate signatures for the blinded file. These signatures will be used to verify the integrity of this blinded file. In addition, the user generates a file tag, which is used to ensure the correctness of the file identifier name and some verification values. The user also computes a transformation value that is used to transform signatures for sanitizer. Finally, the user sends the blinded file, its corresponding signatures, and the file tag along with the transformation value to the sanitizer. When the above messages from user are valid, the sanitizer firstly sanitizes the blinded data blocks into a uniform format and also sanitizes the data blocks corresponding to the organization’s sensitive information to protect the privacy of organization, and then transforms their corresponding signatures into valid ones for sanitized file using transformation value. Finally, the sanitizer uploads the sanitized file and the corresponding signatures to the cloud. When the data integrity auditing task is performed, the cloud generates an auditing proof according to the challenge from the TPA. The TPA can verify the integrity of the sanitized file stored the cloud by checking whether this auditing proof is correct or not. The details will be described in the following subsection.

B. Description of the Proposed Scheme
In our scheme, an original file F is divided into n blocks (m1,m2,…,mn) , where mi∈Z∗p denotes the i -th block of file F . Assume the user’s identity ID is l -bit, which is described as ID=(ID1,ID2,…,IDl)∈{0,1}l . In previous remote data integrity auditing schemes [5], [12], a signature SSig is used to guarantee the integrity of the file identifier name. In our scheme, we also employ a similar identity-based signature SSig to guarantee the integrity of the file identifier name and the correctness of verification values. Assume ssk is the signing private key used to generate file tag in signature SSig and is held by user. Under such an assumption, our scheme is more clear and simple. Let K1 be the set of indexes of the data blocks corresponding to the personal sensitive information of the file F . Let K2 be the set of indexes of the data blocks corresponding to the organization’s sensitive information of the file F . In order to preserve the personal sensitive information of the file from the sanitizer, the data blocks whose indexes are in the set K1 should be blinded before the file is sent to the sanitizer. Assume the blinded file is F∗=(m∗1,m∗2,…,m∗n) which is different from the original file F=(m1,m2,…,mn) in index set K1 . That is to say, mi=m∗i only if i∈[1,n] and i∉K1 ; otherwise, mi≠m∗i . To unify the format, the sanitizer needs to sanitize the blinded data blocks with wildcards. Furthermore, to protect the privacy of organization, the sanitizer also needs to sanitize the data blocks corresponding to the organization’s sensitive information. The sanitized file is F′=(m′1,m′2,…,m′n) which is different from the blinded file F∗=(m∗1,m∗2,…,m∗n) in index set K1⋃K2 . That is to say, m∗i=m′i only if i∈[1,n] and i∉K1⋃K2 ; otherwise, m∗i≠m′i . In general, there is not too much sensitive information in a file, which makes the sanitizer only need to sanitize a few fields. For example, the sensitive information of the EHRs only contain the fields such as patient’s name, patient’s ID number and hospital’s name. Thus, in EHRs, only these fields containing the sensitive information need to be sanitized, and other fields do not need to be sanitized.

The details of the proposed scheme are as follows.

Algorithm Setup(1k)

The PKG chooses two multiplicative cyclic groups G1 and G2 of prime order p , a generator g of G1 , a bilinear map e:G1×G1→G2 and a pseudo-random function f:Z∗p×Z∗p→Z∗p .

The PKG randomly chooses an element x∈Z∗p , elements μ′,μ1,μ2,…,μl,u,g2∈G1 and a cryptographic hash function H:{0,1}∗→G1 .

The PKG computes the public value g1=gx and the master secret key msk=g2x .

The PKG publishes system parameters pp=(G1 , G2 , p , e , g , μ′ , μ1 , μ2,…,μl,u,g1,g2,H,f ) and holds the master secret key msk.

Algorithm Extract(pp,msk,ID)

This process is illustrated in Fig. 3.

After receiving the user’s identity ID=(ID1 , ID2,…,IDl)∈{0,1}l , the PKG randomly picks a value rID∈Z∗p and computes skID=(sk′ID,sk′′ID)=(g2x⋅(μ′∏lj=1μIDjj)rID,grID) as the private key of the user ID. The PKG sends it to the user ID.

The user ID verifies the correctness of the received private key skID by checking whether the following equation holds or not.
e(sk′ID,g)=(g1,g2)⋅e(μ′∏lj=1μIDjj,sk′′ID).(1)
View Source

If above equation does not hold, the user ID refuses the private key skID ; otherwise, accepts it.
Algorithm SigGen(F,skID,ssk,name)

The process is illustrated in Fig. 4.

The user ID randomly chooses a value r∈Z∗p , and calculates a verification value gr . Then the user ID randomly chooses a seed k1∈Z∗p as the input secret key of pseudo-random function f . The user ID employs the secret seed k1 to calculate the blinding factor αi=fk1(i,name)(i∈K1) which is used to blind the data blocks corresponding to the personal sensitive information, where name∈Z∗p is a random value chosen as the file identifier.

In order to preserve the personal sensitive information from the sanitizer, the user ID should blind the data blocks corresponding to the personal sensitive information of the original file F before sending it to the sanitizer. The indexes of these data blocks are in set K1 . The user ID computes the blinded data block m∗i=mi+αi for each block mi∈Z∗p (i∈K1 ) of the original file F . The blinded file is F∗=(m∗1,m∗2,…,m∗n) , where m∗i=mi only if i∈[1,n] and i∉K1 ; otherwise, m∗i≠mi .

For each block m∗i∈Z∗p (i∈[1,n] ) of the blinded file F∗ , the user ID calculates the signature σi on block m∗i as follows: σi=g2x(μ′∏lj=1μIDjj)rID(H(name||i)⋅um∗i)r . Let Φ={σi}1≤i≤n be the set of signatures for the blinded file F∗ .

The user ID sets τ0=name||grID||gr and calculates the file tag by computing τ=τ0||SSigssk(τ0) , where SSigssk(τ0) is the signature on τ0 under the signing private key ssk.

The user ID calculates a transformation value β=ur which is used to transform the signature in Sanitization algorithm. He sends {F∗,Φ,τ,K1} along with β to the sanitizer, and then deletes these messages from local storage. In addition, when the user ID wants to retrieve his file F , he can send a request to the sanitizer. And then the sanitizer downloads and sends the blinded file F∗ to the user. The user ID can recover the original file F using the blinding factor.

Algorithm Sanitization(F∗,Φ)

The process is illustrated in Fig. 4.

The sanitizer checks the validity of the file tag τ by verifying whether SSigssk(τ0) is a valid signature. If it is a valid signature, the sanitizer parses τ0 to obtain file identifier name name and verification values grID and gr , and then does the following steps.

The sanitizer respectively verifies the correctness of signature σi (i∈[1,n] ) as follows:
e(σi,g)=e(g1,g2)⋅e(μ′∏lj=1μIDjj,grID)⋅e(H(name||i)⋅um∗i,gr).(2)
View SourceRight-click on figure for MathML and additional features.If the equation (2) does not hold, the sanitizer thinks the signatures invalid; otherwise, goes to the step c.

The sanitizer verifies the correctness of the transformation value β by checking whether e(u,gr)=e(β,g) holds or not. If the above equation holds, the sanitizer will sanitize the blinded data blocks and the data blocks corresponding to the organization’s sensitive information. The indexes of these data blocks are in sets K1 and K2 . In SigGen algorithm, the data blocks whose indexes are in set K1 have been blinded by the user ID, which will make the contents of these data blocks become messy code. In order to unify the format, the sanitizer can use wildcards to replace the contents of these data blocks. For example, in an EHR, Bob is a user’s name. After blinded by the medical doctor, the contents of this sector will become messy code. To unify the format, the sanitizer replaces these messy code with ***, as shown in Fig. 1. In addition, to protect the privacy of organization, the sanitizer also sanitizes the data blocks whose indexes are in set K2 . For example, in an EHR, the sanitizer replaces the information such as hospital’s name with ***. And then the sanitizer transforms the signatures of data blocks in sets K1 and K2 into valid ones for sanitized file F′ as follows:
σ′i=={σi(β)m′i−m∗iσii∈K1∪K2i∈[1,n]and i∉K1∪K2}g2x(μ′∏lj=1μIDjj)rID(H(name||i)⋅um′i)r
View SourceLet Φ′={σ′i}1≤i≤n be the set of sanitized file’s signatures.

The sanitizer sends {F′,Φ′} to the cloud, and then sends the file tag τ to the TPA. Finally, he deletes these messages from local storage.

We give an example of sensitive information sanitization in Fig. 5. Assume an original file F is divided into n blocks (m1,m2,…,mn) , the index set K1 of the data blocks corresponding to the personal sensitive information is {1, 3} and the index set K2 of the data blocks corresponding to the organization’s sensitive information is {5}. That is to say, in the original file F , m1 and m3 are the data blocks corresponding to the personal sensitive information, and m5 is the data block corresponding to the organization’s sensitive information. To preserve the personal sensitive information from the sanitizer, the user ID needs to blind the data blocks {m1,m3} . The blinded file is F∗=(m∗1,m∗2,…,m∗n) , where m∗i=mi only if i∈[1,n] and i∉{1,3} ; otherwise, m∗i≠mi . To unify the format, the sanitizer sanitizes the data blocks m∗1 and m∗3 after receiving the blinded file F∗ from the user ID. In addition, to protect the privacy of organization, the sanitizer sanitizes the data block m∗5 . Then the sanitizer transforms the signatures of data blocks {m^{*}_{1}} , {m^{*}_{3}} and {m^{*}_{5}} into valid ones for sanitized file F^{\prime } . As shown in Fig. 5, we can see that data blocks {m^{*}_{i}}\ne {m^{\prime }_{i}} and their corresponding signatures {\sigma _{i}}\ne {\sigma ^{\prime }_{i}} only if i \in \{ 1,3,5\} ; otherwise, {m^{*}_{i}}={m^{\prime }_{i}} and {\sigma _{i}}{\mathrm{ = }}{\sigma ^{\prime }_{i}} .
Algorithm \mathbf {ProofGen(F^{\prime },\Phi ^{\prime },chal)}

The process is illustrated in Fig. 6.

The TPA verifies the validity of the file tag \tau . The TPA will not execute auditing task if the file tag \tau is invalid; otherwise, the TPA parses {\tau _{0}} to obtain file identifier name name and verification values {g^{{r_{ID}}}} and {g^{r}} , and then generates an auditing challenge chal as follows:

Randomly picks a set I with c elements, where I \subseteq [1, n] .

Generates a random value {v_{i}} \in Z_{p}^{*} for each i \in I .

Sends the auditing challenge chal = {\{ i,{v_{i}}\} _{i \in I}} to the cloud.

After receiving an auditing challenge from the TPA, the cloud generates a proof of data possession as follows:

Computes a linear combination of data blocks \lambda = \sum \nolimits _{i \in I} {{m^{\prime }_{i}}{v_{i}}} .

Calculates an aggregated signature \sigma = \prod \nolimits _{i \in I} {{\sigma ^{\prime }_{i}}^{v_{i}}} .

Outputs an auditing proof P = \{ \lambda,\sigma \} to the TPA.

Algorithm \mathbf {ProofVerify(chal,pp,P)}

The TPA verifies the correctness of auditing proof as follows:\begin{align*}&\hspace {-0.5pc}e(\sigma,g) \!=\! e{({g_{1}},{g_{2}})^{\!\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \!\cdot e{\left({\mu ^{\prime }\!\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\sum \nolimits _{{\mathrm{i}} \!\in \! I} {v_{i}} }} \\&\!\!\!\qquad \qquad \qquad \qquad \cdot \, e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^\lambda },{g^{r}}}\right).\tag{3}\end{align*}
View Source

If the equation (3) holds, the sanitized file stored in the cloud is intact; otherwise, it is not.


Fig. 3.
The process of private key generation.

Show All

Fig. 4. - The processes of signature generation and sensitive information sanitization.
Fig. 4.
The processes of signature generation and sensitive information sanitization.

Show All

Fig. 5. - An example of sensitive information sanitization.
Fig. 5.
An example of sensitive information sanitization.

Show All

Fig. 6. - The processes of integrity auditing.
Fig. 6.
The processes of integrity auditing.

Show All

SECTION V.Security Analysis
In this section, we prove that the proposed scheme is secure in terms of correctness, sensitive information hiding and audit soundness.

Theorem 1 (The Correctness of Private Key):
Our proposed scheme satisfies the following properties:

(Private key correctness) When the PKG sends a correct private key to the user, this private key can pass the verification of the user.

(Correctness of the blinded file and its corresponding signatures) When the user sends the blinded file and its corresponding valid signatures to the sanitizer, this file and its corresponding signatures can pass the verification of sanitizer.

(Auditing correctness) When the cloud properly stores the user’s sanitized file, the proof it generates can pass the verification of the TPA.

Proof:
Given a correct private key s{k_{ID}} = (s{k^{\prime }_{ID}},s{k^{\prime \prime }_{ID}}) generated by the PKG, the verification equation (1) in Extract algorithm will hold. Based on the properties of bilinear maps, the equation (1) can be proved correct by deducing the left-hand side from the right-hand side:\begin{align*} e(sk^{\prime }_{ID},g)=&e\left({{g_{2}}^{x}{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}}\right)^{{r_{ID}}}},g}\right) \\=&e({g_{2}}^{x},g) \cdot e\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right) \\=&e({g_{2}},{g^{x}}) \cdot e\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},sk^{\prime \prime }_{ID}}\right) \\=&e({g_{1}},{g_{2}}) \cdot e\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},sk^{\prime \prime }_{ID}}\right)\end{align*}
View SourceRight-click on figure for MathML and additional features.

Given a blinded file {F} and its corresponding valid signatures {\{ {\sigma _{i}}\} _{1 \le i \le n}} from the user ID, the verification equation (2) in SigGen algorithm will hold. According to the properties of bilinear maps, the correctness of equation (2) is presented as follows:\begin{align*} e({\sigma _{i}},g)=&e\Biggl({g_{2}}^{x} \cdot {\left(\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}\right)^{{r_{ID}}}} \\&\cdot \, {\left(H(name||i) \cdot {u^{{m^{*}_{i}}}}\right)^{r}},g\Biggr) \\=&e({g_{2}}^{x},g) \cdot e\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right) \\&\cdot \, e\left(H(name||i) \cdot {u^{{m^{*}_{i}}}},{g^{r}}\right) \\=&e({g_{2}},{g^{x}}) \cdot e\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right) \\&\cdot \, e\left(H(name||i) \cdot {u^{{m^{*}_{i}}}},{g^{r}}\right)\\=&e({g_{1}},{g_{2}}) \cdot e\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right) \\&\cdot \, e\left(H(name||i) \cdot {u^{{m^{*}_{i}}}},{g^{r}}\right)\end{align*}
View Source

Given a valid proof P = \{ \lambda,\sigma \} from the cloud, the verification equation (3) in ProofVerify algorithm will hold. Based on the properties of bilinear maps, the verification equation (3) can be proved correct by deducing the left-hand side from the right-hand side:\begin{align*} e(\sigma,g)=&e\left({\prod \nolimits _{i \in I} {{\sigma ^{\prime }_{i}}^{v_{i}}},g}\right)\\=&e\Biggl(\prod \nolimits _{i \in I} \Biggl({g_{2}}^{x}{{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}}\right)}^{{r_{ID}}}} \\&\cdot \, {{(H(name||i) \cdot {u^{{m^{\prime }_{i}}}})}^{r}}\Biggr) ^{v_{i}},g \Biggr)\\=&e\left({{\prod \nolimits _{i \in I} {({g_{2}}^{x})} ^{v_{i}}},g}\right) \\&\cdot \,e\left({\prod \nolimits _{i \in I} {{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}}\right)}^{{r_{ID}} \cdot }}^{v_{i}},g}\right)\\&\cdot \, e\left({\prod \nolimits _{i \in I} {{{(H(name||i) \cdot {u^{{m^{\prime }_{i}}}})}^{r}}^{v_{i}},g}}\right)\\=&e{({g_{1}},{g_{2}})^{\!\sum \nolimits _{i \in I} {v_{i}} }} \!\cdot e{\left({\mu ^{\prime }\!\!\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\!\sum \nolimits _{i \in I} {v_{i}} }}\\&\cdot \,e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^\lambda },{g^{r}}}\right)\end{align*}
View Source

Theorem 2 (Auditing Soundness):
Suppose the CDH problem is hard in bilinear groups and the signature scheme employed for generating file tags is existentially unforgeable. In the proposed scheme, for an adversary or an untrusted cloud, it is computationally infeasible to forge a proof that can pass the TPA’s verification if the sanitized data stored in the cloud have been corrupted.

Proof:
We will prove this theorem by using the method of knowledge proof. If the cloud can pass the TPA’s verification without keeping the intact data, then, we can extract the intact challenged data blocks by repeatedly interacting between the proposed scheme and the constructed knowledge extractor. We will accomplish our proof by a series of games. Note that in our scheme, the data stored in the cloud is the sanitized data {\{ {m^{\prime }_{i}}\} _{1 \le i \le n}} , and their corresponding signatures are {\{ {\sigma ^{\prime }_{i}}\} _{1 \le i \le n}} .

Game 0: In Game 0, both the challenger and the adversary behave in the way defined in Section III. That is, the challenger runs the Setup algorithm and Extract algorithm to obtain the master secret key msk, the system public parameters pp and the private key s{k_{ID}} , and then sends the parameters pp to the adversary. The adversary queries the signatures of a series of data blocks. The challenger runs the SigGen algorithm to compute the corresponding signatures of these data blocks, and sends these signatures to the adversary. And then the challenger sends a challenge to the adversary. Finally, the adversary returns a data possession proof P = \{ \lambda,\sigma \} to the challenger. If this proof can pass the verification of the challenger with non-negligible probability, then the adversary succeeds in this game.

Game 1: Game 1 is the same as Game 0, with one difference. The challenger holds a list of records about the queries of adversary. The challenger observes each instance of the challenge and response process with the adversary. If the adversary can generate a proof that passes the verification of the challenger, while the aggregate signature \sigma generated by the adversary is not equal to \prod \nolimits _{i \in I} {{\sigma ^{\prime }_{i}}^{v_{i}}} generated by the challenger based on maintained file, then the challenger declares failure and aborts.

Analysis: Assume that the adversary wins the Game 1 with non-negligible probability. Then, we can construct a simulator to solve the CDH problem. The simulator is given g,{g^\alpha } , h \in {G_{1}} , its goal is to generate {h^\alpha } . The simulator acts like the challenger in Game 0, but with the following differences:

It randomly chooses an element x\in Z_{p}^{*} , and sets {g_{1}}{\mathrm{=}}{g^{x}} , {g_{2}}=h and the master secret key msk={g_{2}}^{x} . And then, it selects two random values a,b \in Z_{p}^{*} , and sets u = {g_{2}}^{a}{g^{b}} .

It programs the random oracle {H} . It stores a list of queries and responses them in a consistent manner. When responding the queries of the form H(name||i) , the simulator answers them in the following way.

When processing a file {F} , it firstly extracts a private key s{k_{ID}}=(s{k^{\prime }_{ID}},s{k^{\prime \prime }_{ID}})=\left({{g_{2}}^{x} \cdot {\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}}\right)^{{r_{ID}}}},{g^{{r_{ID}}}}}\right) for ID by running Extract algorithm. And then, it chooses a random unique identifier name for file {F} and a random value \bar x\in Z_{p}^{*} , and calculates a verification value {g^{r}} = {({g^\alpha })^{\bar x}} , which implies r=\alpha \bar x . For each i(1 \le i \le n) in the challenge, the simulator chooses a random value {r_{i}} \in Z_{p}^{*} , and programs the random oracle at {i} as \begin{equation*} H(name||i)={g^{r_{i}}}/({g_{2}}^{a{m_{i}^{\prime }}} \cdot {g^{b{m_{i}^{\prime }}}})\tag{4}\end{equation*}
View SourceThe simulator can compute {\sigma ^{\prime }_{i}} for data block {m^{\prime }_{i}} , since we have \begin{align*} (H(name||i) \cdot {u^{{m^{\prime }_{i}}}})^{r}=&{({g^{r_{i}}}/({g_{2}}^{a{m^{\prime }_{i}}} \cdot {g^{b{m^{\prime }_{i}}}}) \cdot {u^{{m^{\prime }_{i}}}})^{r}}\\=&({g^{r_{i}}}/({g_{2}}^{a{m^{\prime }_{i}}} \cdot {g^{b{m^{\prime }_{i}}}}) \\&\cdot \,{({g_{2}}^{a}{g^{b}})^{{m^{\prime }_{i}}}})^{r}\\=&({g^{r_{i}}}/({g_{2}}^{a{m^{\prime }_{i}}} \cdot {g^{b{m^{\prime }_{i}}}}) \\&\cdot \, ({g_{2}}^{a{m^{\prime }_{i}}} \cdot {g^{b{m_{i}}^\prime }}))^{r}\\=&({g^{r}})^{r_{i}}\end{align*}
View SourceTherefore, the simulator calculates {\sigma ^{\prime }_{i}} as follows:\begin{align*} {\sigma ^{\prime }_{i}}=&{g_{2}}^{x}{\left(\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}\right)^{{r_{ID}}}}{(H(name||i) \cdot {u^{{m^{\prime }_{i}}}})^{r}} \\=&{g_{2}}^{x}{\left(\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}\right)^{{r_{ID}}}}{\left({{g^{r}} }\right)^{r_{i}}}.\end{align*}
View SourceRight-click on figure for MathML and additional features.

The simulator continues interacting with the adversary to perform the remote data integrity scheme. As defined in Game 1, if the adversary succeeds, but the aggregate signature \sigma ^{\prime } it generated is not equal to the expected aggregate signature \sigma , then this game aborts.

Assume that an honest prover provides a correct proof \{ \lambda,\sigma \} . From the correctness of our scheme, we can know that this proof \{ \lambda,\sigma \} can pass the verification of the following equation, i.e., that \begin{align*}&\hspace {-1.8pc}e(\sigma,g)=e{({g_{1}},{g_{2}})^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \\&\qquad \qquad \qquad \qquad \qquad \cdot \,e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^\lambda },{g^{r}}}\right)\tag{5}\end{align*}
View SourceRight-click on figure for MathML and additional features.

Assume that the adversary provides a proof \{ \lambda ^{\prime },\sigma ^{\prime }\} which is different from the honest prover provided. Because the game aborted, we can know that the forgery of adversary is successful. That is to say, the aggregate signature \sigma ^{\prime } \ne \sigma , but this aggregate signature \sigma ^{\prime } still can pass the verification of the following equation:\begin{align*}&\hspace {-1.5pc}e(\sigma ^{\prime },g)=e{\left ({{g_{1},{g_{2}}} }\right)^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \\&\qquad \qquad \qquad \qquad \cdot \,e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^{\lambda ^{\prime }}},{g^{r}}}\right)\tag{6}\end{align*}
View Source

Obviously, \lambda \ne \lambda ^{\prime } , otherwise \sigma = \sigma ^{\prime } , which contradicts our above assumption. We define \Delta \lambda = \lambda ^{\prime } - \lambda , and construct a simulator that could solve the CDH problem if the adversary makes the challenger abort with a non-negligible probability.

Now, dividing equation (6) by equation (5) and assuming {g^{r}} = {({g^\alpha })^{\bar x}} , we obtain \begin{equation*} e({{\sigma ^{\prime }} \mathord {\left /{ {\vphantom {{\sigma ^{\prime }} \sigma }} }\right. } \sigma },g) = e({u^{\Delta \lambda }},{g^{r}}) = e({({g_{2}}^{a}{g^{b}})^{\Delta \lambda }},{({g^\alpha })^{\bar x}}).\end{equation*}
View Source

Thus, we can know that \begin{equation*} e(\sigma ^{\prime } \cdot {\sigma ^{ - 1}} \cdot {({g^\alpha })^{ - \bar xb\Delta \lambda }},g) = e{(h,{g^\alpha })^{\bar xa\Delta \lambda }}.\tag{7}\end{equation*}
View Source

From the equation (7), we can know that {h^\alpha } = {(\sigma ^{\prime }{\sigma ^{ - 1}}{({g^\alpha })^{ - \bar xb\Delta \lambda }})^{{1 \mathord {\left /{ {\vphantom {1 {(\bar xa\Delta \lambda)}}} }\right. } {(\bar xa\Delta \lambda)}}}} . Note that the probability of game failure is the same as the probability of \bar x \cdot a \cdot \Delta \lambda = 0\bmod p . The probability of \bar x \cdot a \cdot \Delta \lambda = 0\bmod p is 1/p which is negligible since {p} is a large prime. Therefore, we can solve the CDH problem with a probability of 1 - 1/p , which contradicts the assumption that the CDH problem in {G_{1}} is computationally infeasible.

It means that if the difference between the adversary’s probabilities of success in Game 1 and Game 2 is non-negligible, the constructed simulator can solve the CDH problem.

Game 3: Game 3 is the same as Game 2, with one difference. The challenger still keeps and observes each instance of the proposed remote data integrity auditing scheme. For one of these instances, if the aggregate message \lambda ^{\prime } is not equal to the expected \lambda generated by the challenger, then the challenger declares failure and aborts.

Analysis: Assume that the adversary wins the game 2 with non-negligible probability. We will construct a simulator that uses the adversary to solve the DL problem. The simulator is given g,h \in {G_{1}} , its goal is to calculate a value \alpha satisfying h = {g^\alpha } . The simulator acts like the challenger in Game 2, but with the following differences:

When processing a file {F} , it firstly extracts a private key s{k_{ID}} = (s{k^{\prime }_{ID}},s{k^{\prime \prime }_{ID}}) = \left({{g_{2}}^{x} \cdot {\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}}}\right)^{{r_{ID}}}},{g^{{r_{ID}}}}}\right) for ID by running Extract algorithm. And then, it chooses two random values a,b \in Z_{p}^{*} , and sets = {g_{2}}^{a}{g^{b}} , where {g_{2}} = h .

The simulator continues interacting with the adversary to perform the remote data integrity scheme. As defined in Game 2, if the adversary succeeds, but the aggregation of data blocks \lambda ^{\prime } it generated is not equal to the expected aggregation \lambda of data blocks, then this game aborts.

Assume that an honest prover provides a correct proof \{ \lambda,\sigma \} . From the correctness of the scheme, we can know that the following verification equation e(\sigma,g) = e{({g_{1}},{g_{2}})^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^\lambda },{g^{r}}}\right) holds. Assume that the adversary provides a proof \{ \lambda ^{\prime },\sigma ^{\prime }\} which is different from what the honest prover provided. Because the game aborted, we can know that the forgery of the adversary is successful. Thus, this forged proof can pass the verification of the equation e(\sigma ^{\prime },g) = e{({g_{1}},{g_{2}})^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\vphantom {R^{'}}\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^{\lambda ^{\prime }}},{g^{r}}}\right) . According to Game 2, we know that \sigma ^{\prime } = \sigma . Define \Delta \lambda = \lambda ^{\prime } - \lambda . Based on the above two verification equations, we have \begin{align*}&\hspace {-2.5pc}e{({g_{1}},{g_{2}})^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \\&\cdot \,e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^\lambda },{g^{r}}}\right) \\=&e(\sigma,g)= e(\sigma ^{\prime },g) \\=&e{({g_{1}},{g_{2}})^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \cdot e{\left({\mu ^{\prime }\prod \nolimits _{j = 1}^{l} {\mu _{j}^{I{D_{j}}}},{g^{{r_{ID}}}}}\right)^{\sum \nolimits _{{\mathrm{i}} \in I} {v_{i}} }} \\&\cdot \,e\left({\prod \nolimits _{i \in I} {H{(name||i)^{v_{i}}}} \cdot {u^{\lambda ^{\prime }}},{g^{r}}}\right).\end{align*}
View SourceRight-click on figure for MathML and additional features.

Therefore, we have \begin{equation*} {u^\lambda } = {u^{\lambda ^{\prime }}},\end{equation*}
View SourceRight-click on figure for MathML and additional features.and can further imply that \begin{equation*} 1 = {u^{\Delta \lambda }} = {({g_{2}}^{a}{g^{b}})^{\Delta \lambda }} = {h^{a}}^{\Delta \lambda } \cdot {g^{b}}^{\Delta \lambda }.\end{equation*}
View SourceRight-click on figure for MathML and additional features.

In addition, we have \Delta \lambda \ne 0\bmod p . Otherwise, we have \lambda ^{\prime }{\mathrm{ = }}\lambda \bmod p , which contradicts the aforementioned assumption.

Therefore, we can find the solution to the DL problem as follows, \begin{equation*} h = {g^{ - \frac {b\Delta \lambda }{a\Delta \lambda }}} = {g^{ - \frac {b}{a}}}.\end{equation*}
View SourceRight-click on figure for MathML and additional features.However, a is zero only with the probability 1/p , which is negligible because {p} is a large prime. Then, we can get a solution to the DL problem with a probability of 1 - 1/p , which contradicts the assumption that the DL problem in {G_{1}} is computationally infeasible.

It means that if the difference between the adversary’s probabilities of success in Game 2 and Game 3 is non-negligible, the constructed simulator can solve the DL problem.

Note that the hardness of the CDH problem implies the hardness of the DL problem. Thus, the differences between these games defined can be ignored on the condition that the CDH problem in {G_{1}} is hard.

Finally, we construct a knowledge extractor to extract all of challenged data blocks {m_{i}^{\prime }}(i \in I,|i| = c) by selecting {c} different coefficients {v_{i}}(i \in I,|I| = c) and executing {c} times different challenges on the same data blocks {m_{i}^{\prime }}(i \in I,|i| = c) . The knowledge extractor can get independently linear equations in the variables {m_{i}^{\prime }}(i \in I,|i| = c) . By solving these equations, this knowledge extractor can extract {m_{i}^{\prime }}(i \in I,|i| = c) . It means that if the cloud can pass the TPA’s verification, it must correctly maintain the user’s sanitized data.

Theorem 3 (The Detectability):
Assume the sanitized file F^{\prime } stored in the cloud is divided into {n} blocks, {k} data blocks in this file F^{\prime } are modified or deleted by the cloud and {c} data blocks are challenged by the TPA. Our remote data integrity auditing scheme is \left ({{\frac {k}{n},1 - {{\left ({{\frac {n - k}{n}} }\right)}^{c}}} }\right) detectable.

Proof:
Let {Y} be the set of block-signature pairs corrupted by the cloud. Let {S} be the set of block-signature pairs challenged by the TPA. Let {X} be the random variable set, which is denoted as X = |Y \cap S| . Let {P_{X}} denote the probability of detecting the corrupted data blocks. In other words, if the cloud modifies or deletes {k} data blocks of the sanitized file F^{\prime } , the TPA can detect the cloud’s misbehavior with probability {P_{X}} by challenging {c} data blocks. Therefore, we have \begin{align*} {P_{X}}=&P\{ X \ge 1\} \\=&1 - P\{ X = 0\} \\=&1 - \frac {n\qquad - k}{n} \times \frac {n - 1 - k}{n - 1} \times \ldots \times \frac {n - c + 1 - k}{n - c + 1}\end{align*}
View SourceRight-click on figure for MathML and additional features.We can know that 1 - {\left({\frac {n - k}{n}}\right)^{c}} \le {P_{X}} \le 1 - {\left({\frac {n - c + 1 - k}{n - c + 1}}\right)^{c}} , since \frac {n - i - 1 - k}{n - i - 1} \le \frac {n - i - k}{n - i} . Thus, we can conclude that the proposed scheme can detect the misbehavior of the cloud with probability at least 1 - {\left ({{\frac {n - k}{n}} }\right)^{c}} .

Theorem 4:
(Sensitive information hiding) The sanitizer cannot derive the personal sensitive information of the file, besides the cloud and the shared users cannot derive any sensitive information of the file in our scheme.

Proof:
In our scheme, the user needs to blind the data blocks corresponding to the personal sensitive information of the original file {F} before sending this file to the sanitizer. Because the blinding factors \alpha _{i}=f_{k_{1}}(i,name)(i\in K_{1}) are randomly generated by the user, the blinded data blocks {m^{*}_{i}}={m_{i}}+\alpha _{i} ({\mathrm{ }}i \in K_{1} ) of F^{*} received by the sanitizer are unpredictable. Therefore, the sanitizer cannot know the real data blocks {m_{i}} ({\mathrm{ }}i \in K_{1} ) according to the blinded data blocks {m^{*}_{i}}={m_{i}}+\alpha _{i} ({\mathrm{ }}i \in K_{1} ) from the user. That is to say, the sanitizer cannot derive the personal sensitive information from F^{*} it received.

After receiving the blinded file F^{*} , the sanitizer sanitizes the data blocks corresponding to the personal sensitive information and the organization’s sensitive information, and uploads the sanitized file F^{\prime } to the cloud. In the sanitized file F^{\prime } , the data blocks corresponding to all of the sensitive information of the original file {F} have been replaced with wildcards. It means that the cloud and the shared users cannot derive the sensitive information from the sanitized file F^{\prime } . Therefore, the cloud and the shared users cannot know any sensitive information of the original file {F} . The sensitive information of the original file can be hidden.

SECTION VI.Performance Evaluation
In this section, we first give the functionality comparison among our scheme and several related schemes, and the computation overhead comparison between our scheme and Shacham and Waters scheme [4]. And then discuss the communication overhead and the computation complexity of our scheme. At last, we evaluate the performance of our scheme in experiments.

A. Functionality Comparison
We give the functionality comparison of our scheme with several related schemes [4], [20], [32]–[33][34]. As shown in Table II, our scheme is the only scheme that can satisfy all of the following properties: public verifiability, certificate management simplification, data sharing and sensitive information hiding. Note that schemes [4], [20], [32]–[33][34] all cannot support the sensitive information hiding.

TABLE II Functionality comparison With Existing Related Schemes
Table II- 
Functionality comparison With Existing Related Schemes
B. Performance Analysis and Comparison
We define the following notations to denote the operations in our scheme. Let Has{h_{G_{1}}} , Ex{p_{G_{1}}} and Mu{l_{G_{1}}} respectively denote one hashing operation, one exponentiation operation and one multiplication operation in {G_{1}} . Similarly, Su{b_{Z_{p}^{*} }} , Mu{l_{Z_{p}^{*}}} and Ad{d_{Z_{p}^{*} }} denote one subtraction operation, one multiplication operation and one addition operation in Z_{p}^{*} , respectively. Pair denotes one pairing operation. Mu{l_{G_{2}}} and Ex{p_{G_{2}}} respectively denote one multiplication operation and one exponentiation operation in {G_{2}} . {n} is the total number of data blocks. {c} is the number of challenged data blocks. d_{1} is the number of data blocks corresponding to the personal sensitive information. d_{2} is the number of data blocks corresponding to the organization’s sensitive information. {l} is the length of user identify. {\mathrm{|}}n{\mathrm{|}} is the size of an element of set [1, n] , {\mathrm{|}}p{\mathrm{|}} is the size of an element in Z_{p}^{*} , and {\mathrm{|}}q{\mathrm{|}} is the size of an element in {G_{1}} .

Computation overhead comparison. In Table III, we give the computation overhead comparison between our scheme and Shacham and Waters scheme [4] in different phases. From Section IV, we can know that, before sending the original file to the sanitizer, the user needs to blind the data blocks corresponding to the personal sensitive information of the file. The computation overhead of data blinding is d_{1}Ad{d_{Z_{\vphantom {R_{j}}p}^{*} }} . And then the user generates the signatures for the blinded file. The computation overhead of computing signatures is n(Has{h_{G_{1}}} + 2Mu{l_{G_{1}}} + 2Ex{p_{G_{1}}}) . The sanitizer sanitizes the blinded data blocks and the data blocks corresponding to the organization’s sensitive information, and transforms the signatures of these data blocks into valid ones for the sanitized file. In the phase of sanitization, the computation overhead on the sanitizer side is (d_{1}+d_{2})(Ex{p_{G_{1}}} + Mu{l_{G_{1}}} + Su{b_{Z_{p}^{*}}}) . In the phase of integrity auditing, the TPA firstly needs to generate and send an auditing challenge to the cloud, which only costs negligible computation overhead. And then, the cloud outputs an auditing proof P = \{ \lambda,\sigma \} to reply the TPA. The computation overhead of the cloud is (c - 1)Mu{l_{G_{1}}} + cEx{p_{G_{1}}} +cMu{l_{Z_{p}^{*} }} +(c - 1)Ad{d_{Z_{p}^{*} }} . When the TPA verifies this auditing proof, the computation overhead of the TPA is 4\,\,Pair + 2Mu{l_{G_{2}}} + 2(c - 1)Ad{d_{Z_{p}^{*} }} + 2Ex{p_{G_{2}}} + (l + c + 1)Ex{p_{G_{1}}} + (c + l)Mu{l_{G_{1}}} + cHas{h_{G_{1}}} .

The construction of the scheme [4] is generally regarded as one of the most efficient one among all existing remote data integrity auditing schemes. In this scheme [4], one data block is divided into multiple sectors, which can reduce storage overhead. Actually, our scheme also can support multiple sectors. But for simplification, we only consider the situation that the file {F} is divided into {n} data blocks, and do not consider the situation that each data block is divided into {s} sectors. For fairness comparison, we set {s} =1 in scheme [4]. As shown in Table III, we can see that our scheme and the scheme [4] have almost the same computation overhead in the phase of signature generation. It means that our scheme and the scheme [4] have the same efficiency when processing the same file. In the phase of proof generation, the cloud’s computation overhead in our scheme and the scheme [4] are the same. For the TPA in the phase of proof verification, our scheme costs more computation overhead than the scheme [4]. On the other hand, as Table II shows, our scheme can satisfy the following properties: data sharing, sensitive information hiding and certificate management simplification. However, the scheme [4] cannot satisfy the above properties. Therefore, the above comparison shows that our scheme has the same efficiency level with the scheme [4], but meets more properties.

Communication overhead. According to the description of Section IV, we can know that the communication overhead of the proposed scheme is mainly from the integrity auditing phase, as shown in Table IV. Thus, we only consider the communication overhead incurred in the remote data integrity auditing. In the phase of integrity auditing, the TPA sends an auditing challenge chal={\{ i,{v_{i}}\} _{i \in I}} to the cloud. The size of an auditing challenge is c \cdot \,\,(|n| + |p|) bits. After receiving the auditing challenge from the TPA, the cloud generates an auditing proof P=\{ \lambda,\sigma \} to reply the TPA. The size of an auditing proof P = \{\lambda,\sigma \} is |p| + |q| bits. Therefore, for one auditing task, the whole communication overhead is c \cdot |n| + (c + 1) \cdot |p| + |q| bits.

Computation complexity. We analyze the computation complexity of the different entities in different phases in Table V. The computation complexity of different entities in our scheme respectively depends on the number {c} of challenged blocks, the total number {n} of data blocks, the number d_{1} of data blocks corresponding to the personal sensitive information and the number d_{2} of data blocks corresponding to the organization’s sensitive information. From Table V, we see that the computation complexities of data blinding and signature generation for the user are {O} (d_{1} ) and {O} ({n} ) respectively. On the sanitizer side, the computation complexity of data sanitization is {O} (d_{1}+d_{2} ). The computation overheads of challenge generation and proof verification are both {O} ({c} ) on the TPA side. The computation complexity of proof generation for the cloud is {O} ({c} ).

TABLE III The Computation Overhead of Our Scheme and Shacham et al. Scheme [4] in Different Phases
Table III- 
The Computation Overhead of Our Scheme and Shacham et al. Scheme [4] in Different Phases
TABLE IV The Communication Overhead of the Proposed Scheme
Table IV- 
The Communication Overhead of the Proposed Scheme
TABLE V The Computation Complexity of Different Entities in Different Phases

C. Experimental Results
In this subsection, we evaluate the performance of the proposed scheme by several experiments. We run these experiments on a Linux machine with an Intel Pentium 2.30GHz processor and 8GB memory. All these experiments use C programming language with the free Pairing-Based Cryptography (PBC) Library [35] and the GNU Multiple Precision Arithmetic (GMP) [36]. In our experiments, we set the base field size to be 512 bits, the size of an element in Z_{p}^{*} to be \left |{ p }\right | =160 bits, the size of data file to be 20MB composed by 1,000,000 blocks, and the length of user identify to be 160 bits.

1) Performance of Different Processes:
To effectively evaluate the performance in different processes, we set the number of data blocks to be 100 and the number of sanitized data blocks to be 5 in our experiment. As shown in Fig. 7, private key generation and private key verification spend nearly the same time, which are nearly 0.31s. The time consumed by the signature generation is 1.476s. The time of signature verification and that of sensitive information sanitization respectively are 2.318s and 0.041s. So we can conclude that in these processes, the signature verification spends the longest time and the sensitive information sanitization spends the shortest time.


Fig. 7.
Performance of different processes.

Show All

To evaluate the performance of signature generation and signature verification, we generate the signatures for different number of blocks from 0 to 1000 increased by an interval of 100 in our experiment. As shown in Fig. 8, the time cost of the signature generation and the signature verification both linearly increases with the number of the data blocks. The time of signature generation ranges from 0.121s to 12.132s. The time of signature verification ranges from 0.128s to 12.513s.

Fig. 8. - The computation overhead in the process of signature generation and signature verification.
Fig. 8.
The computation overhead in the process of signature generation and signature verification.

Show All

2) Performance of Auditing:
With the different number of challenged data blocks, we respectively show the computation overhead of the TPA and that of the cloud in integrity auditing phase in Fig. 9 and Fig. 10. In our experiment, the number of challenged data blocks varies from 0 to 1,000. As shown in Fig. 9, we see the that the computation overheads of challenge generation and proof verification on the TPA side linearly increase with the number of challenged data blocks. The computation overhead of proof verification varies from 0.317s to 11.505s. Compared with the time of proof verification, the time of challenge generation increases slowly, just varying from 0.013s to 0461s. From Fig. 10, we have the observation that the computation overhead of proof generation on the cloud side varies from 0.021s to 3.981s. So we can conclude that, with the more challenged data blocks, both the TPA and the cloud will spend the more computation overheads.


Fig. 9.
The computation overhead of the TPA in the phase of integrity auditing.

Show All


Fig. 10.
The computation overhead of the cloud in the phase of integrity auditing.

Show All

SECTION VII.Conclusion
In this paper, we proposed an identity-based data integrity auditing scheme for secure cloud storage, which supports data sharing with sensitive information hiding. In our scheme, the file stored in the cloud can be shared and used by others on the condition that the sensitive information of the file is protected. Besides, the remote data integrity auditing is still able to be efficiently executed. The security proof and the experimental analysis demonstrate that the proposed scheme achieves desirable security and efficiency.