The new mobile edge computing (MEC) paradigm fundamentally changes the data caching technique by allowing data to be cached on edge servers attached to base stations within hundreds of meters from users. It provides a bounded latency guarantee for latency-sensitive applications, e.g., interactive AR/VR applications, online gaming, etc. However, in the highly distributed MEC environment, cache data is subject to corruption and their integrity must be ensured. Existing centralized data integrity assurance schemes are rendered obsolete by the unique characteristics of MEC, i.e., unlike cloud servers, edge servers have only limited computing and storage resources and they are deployed massively and distributed geographically. Thus, it is a new and significant challenge to ensure cache data integrity over tremendous geographically-distributed resource-constrained edge servers. This paper proposes the CooperEDI scheme to guarantee the edge data integrity in a distributed manner. CooperEDI employs a distributed consensus mechanism to form a self-management edge caching system. In the system, edge servers cooperatively ensure the integrity of cached replicas and repair corrupted ones. We experimentally evaluate its performance against three representative schemes. The results demonstrate that CooperEDI can effectively and efficiently ensure cache data integrity in the MEC environment.
SECTION I.Introduction
The fast growth of mobile and IoT devices have fueled the emergence of complicated online applications that require low latency, such as interactive virtual/augmented reality (AR/VR) and networked gaming applications. Due to the high and usually unpredictable latency between users and remote clouds, the cloud computing paradigm is not capable of ensuring low latency for the users of those applications [1], as the network latency is fundamentally determined by the round-trip time over the end-to-end physical network [2].

To tackle this challenge, mobile edge computing (MEC) was proposed and is now one of the 5G key enabler technologies. In the MEC environment, edge servers are attached to base stations so that application vendors can cache popular data on edge servers to serve nearby users with bounded latency guarantee [3]. MEC pushes cache data to users’ geographic proximity to ensure their low data access latency [4]. It enables a caching system at the network edge (referred to as edge caching system hereafter) that is fundamentally different from conventional cloud-based caching systems like content delivery networks (CDNs). Fig. 1 illustrates an example edge caching system comprised of five edge servers serving twelve users in an area supported by MEC. Offering many novel opportunities, edge caching systems also raise various new challenges [5]–[6][7].

Fig. 1. - Exemplar edge caching system.
Fig. 1.
Exemplar edge caching system.

Show All

Existing studies of edge caching systems have commonly assumed 100% data reliability and security in the system. This is unrealistic in real-world MEC environment. Different from cloud computing facilitated by mega-scale data centers, the MEC environment is much more distributed, dynamic and volatile [8]. Edge servers are geographically distributed and thus cannot always be maintained in-house like cloud servers [9]. Therefore, it is infeasible to simply assume edge servers are fully reliable [10]. In fact, researchers have found that various events can lead to the corruption of data replicas (referred to as edge data replicas hereafter) cached on edge servers, such as software exceptions or hardware faults [10]. Besides, during a cyberattack, a hacker may tamper with the data cached on edge servers. Taking Fig. 1 as an example, a hacker may tamper with a piece of data on s4 by injecting a Trojan virus. This raises a security threat to all the users accessing the corrupted data. Thus, application vendors need to verify the integrity of those edge data replicas cached in the edge caching systems.

The data integrity problem in the cloud computing environment (referred to as CDI problem hereafter) has been extensively studied. Provable data possession (PDP) [11]–[12][13][14][15] and proofs of retrievability (PoR) [16] are the most popular schemes for verifying users’ data stored in the cloud. However, the edge data integrity (EDI) problem is fundamentally different as: 1) given a piece of data, EDI demands the data integrity of massive replicas cached on various edge servers in the edge caching system instead of in application vendor’s local or cloud storage; 2) edge caching systems are comprised of highly distributed edge servers and suffer from lack of centralized control like cloud servers hosted in data centers; and 3) solutions to EDI problem must not incur heavy computation overheads on edge servers or mobile devices as they are both resource-constrained. Inspecting a large number of data replicas with PDP-based schemes incurs great pressure on those edge servers and backhaul network. Repairing corrupted data replicas with PoR-based schemes requires extra storage on storage-constrained edge servers and incurs excessive computation overheads on mobile devices.

Very recently, a PDP-based centralized scheme named EDI-V was proposed to verify the edge data integrity for application vendors [10]. Under this scheme, application vendor uses the original data to generate a variable Merkle hash tree (VMHT), then each edge server generates a small VMHT based on a few data blocks sampled from its own replica. By comparing the root nodes’ hash values of those VMHTs, application vendor can verify each individual replica’s integrity. However, there are four critical and inherent limitations to this scheme. First, it incurs extra traffic over the backhaul network, which is against one of the main design purposes of MEC [17]. Second, it is subject to low efficiency because application vendor has to collect the responses from all the edge servers for integrity verification - a slow edge servers will immediately prolong the entire process. Third, it is a probabilistic scheme and cannot detect data corruptions with a full guarantee. Finally, it cannot localize or repair corrupted edge data replicas at the data block level, which incurs extra communication overheads.

To effectively and efficiently tackle the EDI problem, we propose a novel scheme named CooperEDI to guarantee the data replica integrity on edge servers. Based on a specifically-designed distributed consensus mechanism, edge servers first reach a consensus on the ground-truth, i.e., the valid edge data replicas. Then, based on the ground-truth, they cooperatively verify the integrity of each other’s edge data replicas, localize the corruptions and repair the corrupted replicas without centralized control. CooperEDI offers a decentralized solution to the EDI problem. The following summarizes the contributions of this paper.

We propose CooperEDI, a novel decentralized scheme for helping application vendors to ensure the integrity of their edge data replicas in the volatile MEC environment.

We solve the EDI problem for application vendors by not only verifying edge data integrity but also localizing and repairing the corrupted data replicas.

We evaluate CooperEDI’s performance against two representative CDI schemes and one state-of-the-art EDI scheme. Experimental results demonstrate the effectiveness and efficiency of CooperEDI in solving the EDI problem.

Paper organization: Section II overviews CooperEDI’s general framework. Section III presents and discusses CooperEDI in detail. Section IV evaluates CooperEDI experimentally. Section V discusses the related work, and Section VI concludes this paper and points out the future work.

SECTION II.CooperEDI Overview
Edge servers deployed in a specific area can communicate with each other via high-speed links [4], [18] and constitute an edge caching system to serve the users in this area. Under the CooperEDI scheme, the edge servers in the system cooperatively verify data integrity, localize corruptions and repair the corrupted ones proactively or on-demand. They interact autonomously without application vendor’s remote control from the cloud.

A. General Framework
Given a piece of original data d kept by application vendor in its cloud storage, suppose that n replicas of d are cached on n edge servers in the edge cache system, one on each edge server. Let s1,s2,…,sn denote these edge servers and d1,d2,…,dn denote the corresponding edge data replicas. The general framework of CooperEDI consists of four main phases, as shown in Fig. 2.


Fig. 2.
CooperEDI overview.

Show All

Phase 1 (System Setup): This phase is not shown in Fig. 2. In this phase, the app vendor sets up essential parameters required by CooperEDI, including two time thresholds and a common data digest generation function for all edge servers. This phase only needs to be performed once during the life cycle of the edge data replicas.

Phase 2 (Ground-Truth Determination): Verifying the integrity of a data replica requires comparison to the ground-truth, i.e., the valid data d . Without the involvement of application vendor, the ground-truth is not straightforward - any replica of d in the edge caching system may be corrupted. Thus, edge servers interact with each other to cooperatively determine which edge data replicas are valid and can be used as the ground-truth, as shown in Fig. 2(a). This is achieved based on CooperEDI’s distributed consensus mechanism. Any edge servers that hold the ground-truth can be the managers, such as s1,s3 , and s5 in Fig. 2(a). Those manager edge servers are responsible for data integrity verification and subsequent corruption localization and data repair.

Phase 3 (Corruption Localization): In this phase, each manager sends out a set of Data Inspection Messages to notify the other edge servers in the system whether their data replicas of d are valid. As shown in Fig. 2(b), s5 notifies s1 , s2 , s3 , and s4 , individually. If replica dj cached on edge server sj is corrupted, the manager generates a set of digests based on each data block of the ground-truth and sends those digests to sj to help it localize the corrupted data blocks. For example, edge servers s2 and s4 in Fig. 2 will receive these digests as their data replicas d2 and d4 are corrupted.

Phase 4 (Data Repair): After localizing the corrupted data blocks, edge servers whose data replicas are damaged, such as s2 and s4 in Fig. 1, interact with a randomly selected manager to retrieve the corresponding valid data block(s) to repair their data replicas, as shown in Fig. 2(c).

Under the CooperEDI scheme, Phases 2–4 iterate periodically or on-demand to ensure the integrity of data d ’s replicas in the edge caching system. The integrity assurance processes for different data cached in the system can be carried out individually or as a whole without fundamentally changing the above process.

B. Data Structures
Table I summarizes the data structures used in CooperEDI as well as in this paper. Generally, edge servers employ a request-response process to communicate with each other. In Phase 2 (Ground-truth Determination), they interact with each other with Ground-truth Requests and Ground-truth Responses to determine the ground-truth. In Phase 3 (Corruption Localization), manager edge servers send Data Inspection Messages with the digests of the ground-truth attached to the other edge servers to help them localize corrupted data blocks. In Phase 4 (Data Repair), edge servers with corrupted data replicas send Data Block Requests to retrieve valid data blocks from managers who reply with Data Block Responses to supply the required valid data blocks.

TABLE I Data Structures in CooperEDI

SECTION III.CooperEDI Process and Procedures
In this section, we present and discuss CooperEDI’s four phases and corresponding procedures in detail.

A. Phase 1: System Setup
CooperEDI sets up essential parameters in this phase, including the time thresholds and the common hash function.

CooperEDI assigns each edge server with two time thresholds t1 and t2 . Parameter t1 determines when an edge server commences the data integrity assurance process by entering Phase 2 (Ground-truth Determination). Specifically, each edge server sets a timer between 0 and t1 and commences the process at timeout. The value of t1 can be empirically specified by application vendors. With a smaller t1 , data integrity inspection and repair will be performed more often at the price of higher communication and computation overheads, and vice versa. In Phase 4 (Data Repair), each edge server waits for a time period of t2 before choosing a manager to perform data repair.

CooperEDI chooses a digest generation function hash() , e.g., MD5, SHA-1, and SHA-2, for all the edge servers in the system to generate data digests in Phase 2 and data block digests in Phase 3, as shown in Fig.s 2(a) and (b), respectively. Edge servers use digests instead of the data replicas when communicating with each other in Phase 2 and Phase 3. This significantly reduces the communication overheads incurred.

B. Phase 2: Ground-Truth Determination
In this phase, edge servers interact with each other and cooperatively find out the ground-truth, i.e., which replicas are valid. Our research is inspired by the great success of distributed consensus protocols in a variety of domains, such as Paxos [19] and Raft [20], which can help achieve consensus among a group of participants in a network of unreliable or fallible processors. A fundamental assumption of those studies is that no more than half of the participants will fail simultaneously. Based on this assumption, the majority of participants in the distributed system can eventually reach an agreement when some participants fail temporarily. The same assumption is made in this research: given n replicas of d cached on n edge servers in the edge caching system, only a minority of the data replicas may be corrupted at the same time, i.e., at least ⌈(n+1)/2⌉ data replicas in total are correct at any time. We refer to those correct edge data replicas as a quorum. This is reasonable in the highly distributed MEC environment, as it is not likely for the majority of the edge data replicas to be corrupted at the same time by massive concurrent hardware faults, software exceptions or cyberattacks. All the data replicas in the quorum are valid and any of them can be employed as the ground-truth. Edge servers go through the following three steps to find out whether their edge data replicas belong to the quorum. The corresponding procedures are shown in Pseudocode 1.

At the beginning of an assurance process, each edge server waits for a random period of time between 0 and t1 and then sends Ground-truth Requests to all the other edge servers in the system. An edge server only passively responds to Ground-truth Requests before its own timer times out. Let us suppose that si requests from ground-truth determination. It executes procedure groundTruthRequest() (lines 1–8 in Pseudocode 1) to send out a Ground-truth Request to each of the other edge servers in the system (lines 5-7). The Ground-truth Request req contains the replica ID and the digest of data replica di , i.e., si.replica , (lines 3-4).

Upon the receipt of a Ground-truth Request req from si , the recipient, say sj , executes procedure groundTruthResponse() (lines 9–15 in Pseudocode 1) to respond to si . Edge server sj generates a digest of its own data replica, i.e., dj , to be compared with req.digest . If they are equal, the two corresponding data replicas are the same, i.e., di=dj . Edge server sj returns a Ground-truth Response res to notify si of the result. Taking Fig. 2(a) as an example, upon the receipt of a Ground-truth Request from s5 , edge server s1 responds to s5 with res.dataEquivalent=true as data replicas d5 and d1 are the same, i.e., both are valid. In contrast, edge server s4 responds to s5 with res.dataEquivalent=false as its d4 is not the same as s5 ’s.

Upon the receipt of a set of Ground-truth Responses RES , edge server si employs procedure groundTruthConsensus() (lines 16–29 in Pseudocode 1) to check whether its data replica di belongs to the quorum. Specifically, it inspects each of the responses in RES and records the results in si.dataEquivalent[] (lines 18-23). If its data replica di equals to the majority of data replicas cached in the system, i.e., count≥⌈(n+1)/2⌉ , di belongs to the quorum and can be the ground-truth. In this case, edge server si becomes a manager and can start Phase 3 (Corruption Localization). Otherwise, its data replica di is corrupted and si resets si.dataEquivalent[] and passively waits for other edge servers’ Ground-truth Requests or Data Inspection Messages. Let us take Fig. 1(b) as an example. The data replicas cached on s1 , s3 and s5 are the same. Edge server s5 can become a manager and its data replica d5 can be taken as the ground-truth.

Pseudocode 1 Ground-Truth Determination
procedure GroundTruthRequest() ▹ used by si

input: si.replicaId - data replica ID

si.replica - data replica

si.member - edge server information

output: req - Ground-truth Request

create a Ground-truth Request req

req.replicaId⟵si.replicaId

req.digest⟵hash(si.replica) ▹ generate data digest

for each edge server sj in si.member[] do

send out req to sj concurrently

end for

end procedure

procedure GroundTruthResponse ▹ used by sj upon the receipt of a Ground-truth Request req from si

input: sj.serverId - server’s ID

sj.replica - data replica

sj.replicaID - ID of data replica

req - Ground-truth Request

output: res - Ground-truth Response

create a Ground-truth Response res

res.serverId⟵sj.serverId

res.replicaId⟵sj.replicaId

res.dataEquivalent⟵req.digest==hash(sj.replica)?true:false

send res back to si

end procedure

procedure GroundTruthConsensus ▹ used by si to determine if data replica di can be a ground-truth

input: RES - a set of Ground-truth Responses

output: si.dataEquivalent[] - replica equivalent info.

count⟵1 ▹ # replicas that are same to si.replica

for each res∈RES do

if res.dataEquivalent==true then

count⟵count+1

si.dataEquivalent[res.serverId]⟵true

end if

end for

if count≥(⌈(n+1)/2⌉) then ▹di is valid

become a manager

else▹di is corrupted

reset si.dataEquivalent[]

end if

end procedure

Under the CooperEDI scheme, any edge server that possesses a valid data replica may become a manager. Thus, there are multiple managers in the system at the same time. A new manager will send Data Inspection Messages to all the other edge servers in Phase 3 (Corruption Localization). If an edge server si in Phase 2 receives a Data Inspection Message, which indicates the existence of a new manager, it cancels its ground-truth determination process and passively participates the data inspection in Phase 3. The reason is that, when checking if the data replica di cached on si can be the ground-truth, si needs to send messages to all the other edge servers. Then, each edge server generates a digest of its own data replica and replies to si with a Ground-truth Response. This incurs communication and computation overheads. In practice, it is not always necessary to find all the correct data replicas in the systems as ground-truth. A few ground-truth replicas usually suffice to support data inspection and repair. Therefore, when si detects the emergence of new manager, it cancels its own ground-truth determination process to prevent further communication and computation overheads.

C. Phase 3: Corruption Localization
This phase consists of two steps. First, a manager generates and sends one Data Inspection Messages to each edge server. Then, upon the receipt of such a message, an edge server verifies the integrity of its data replica and if it is corrupted, localizes the corrupted data blocks.

A manager si employs procedure genInspection() (lines 1–16 in Pseudocode 2) to send a Data Inspection Message mes to each of the other edge servers. This message helps the corresponding edge server, say sj , to find out whether its data replica dj is corrupted and localize corrupted data blocks if dj is corrupted. As introduced in Step 3 in Phase 2, manager si uses an array si.dataEquivalent[] to record whether the data replica cached on each of the other edge servers is the same as its own data replica di . If a data replica dj is not corrupted, si notifies sj by setting mes.isCorrupted=false in its message for sj . Otherwise, it sets mes.isCorrupted=true and attaches the digests of all the data blocks of its di in mes to help sj localize corrupted data blocks (lines 6-13).

Upon the receipt of mes , an edge server sj executes procedure locCorrupedDataBlocks() (lines 17–25 in Pseudocode 2) to verify the integrity of data replica dj and localize corrupted data blocks (if any) based on the data block digests in mes . Variable mes.isCorrupted=false indicates that di is valid and sj does not need to perform the subsequent data repair process in this particular assurance process (lines 18-19). Otherwise, sj generates one digest of each data block in dj and compares it with the corresponding one in mes . If any pair of digests are not equal, the corresponding data block is corrupted. In this way, all the corrupted data blocks can be localized (lines 21-23).

Pseudocode 2 Corruption Localization
procedure GenInspection ▹ used by si

input: si.member[] - info. of all edge servers

si.replica - data replica

si.replicaID - ID of data replica

si.dataEquivalent[] - replica equivalent info.

output: a set of Data Inspection Messages

for each sj in si.member[] do ▹ data inspection

create a new Data Inspection Message mes

mes.replicaId⟵si.replicaId

mes.isCorrupted⟵si.dataEquivalent[j]?false:true

if si.dataEquivalent[j]==false then

if si.digests[]=NULL then ▹ create digests

for each data block bi in si.replica do

si.digests[i]⟵hash(bi)

end for

end if

mes.digests[]⟵si.digests[]

end if

send mes to edge server sj

end for

end procedure

procedure LocCorrupedDataBlocks ▹ used by sj

input: mesj - Data Inspection Message

output: sj.validState[] - data block validity info.

if mes.isCorrupted==false then

dj is valid, finish its data inspection

else▹dj is invalid, perform corruption localization

for each data block bi in sj.replica do

sj.validState[i]⟵(mes.digests[i]==hash(bi))?true:false

end for

end if

end procedure

D. Phase 4: Data Repair
In this phase, an edge server sj interacts with a manager to repair its corrupted data. As introduced in Section III-B, there are multiple managers in the system at the same time. Thus, sj waits for a time period of t2 after it receives the first Data Inspection Message. If it receives more than one such messages within t2 , it randomly chooses and interacts with a manager to perform data repair. In this way, the overall data repair workload is shared by multiple manager edge servers. Edge server sj and manager si go through two steps to repair sj ’s corrupted data replica.

In Phase 3, edge server sj has localized all the corrupted data blocks. In this step, sj inspects sj.validState[] and creates a Data Block Request dbReq to send all the IDs of those corrupted data blocks to manager via procedure dataBlockRequest() (lines 1–11 in Pseudocode 3).

Upon the receipt of dbReq , manager si responds a set of Data Block Responses to sj by executing procedure dataBlockResponse() (lines 12–20 in Pseudocode 3). Then, sj can repair its corrupted data replica by replacing the corrupted data blocks with the valid data blocks received from si .

Pseudocode 3 Data Repair
procedure DataBlockRequest() ▹ used by sj

input: sj.replicaId - data replica ID

sj.validState - data block validity info.

output: dbReq - Data Block Request

create a new Data Block Request dbReq

dbReq.replicaId⟵sj.replicaId

i⟵0 ▹ counter

for each state of sj.validState[] do

if state==false then ▹ found a corrupted block

dbReq.dataBlockId[i++]⟵state.index

end if

end for

send dbReq to manager si

end procedure

procedure DataBlockResponse ▹ used by manager si

input: dbReq - sj ’s Data Block Request

output: a set of Data Block Responses

for each dataBlockId in dbReq.dataBlockId[] do

create a new Data Block Response dbRes

dbRes.replicaId⟵si.replicaId

dbRes.dataBlockId⟵dataBlockId

dbRes.dataBlock⟵si.replica[dataBlockId]

end for

send those responses to sj asynchronously

end procedure

SECTION IV.Experimental Evaluation
We experimentally evaluate CooperEDI’s performance against two representative PDP schemes and one state-of-the-art EDI scheme.

A. Experimental Settings
1) Competing Schemes:
Through a thorough investigation, we find that the scheme recently proposed in [10] is the state-of-the-art scheme that was specifically designed for the EDI problem. Thus, we implement this scheme as EDI-V for comparison with CooperEDI in the experiments. Besides, after a minor modification, some PDP-based schemes that support multi-replica verification in cloud computing also can solve the EDI problem. Generally, a user under PDP scheme will send an inspection request to the cloud. After receiving a batch of data integrity proofs generated by the cloud, the user verifies the data validity by inspecting those proofs. To improve the efficiency, those PDP schemes randomly sample a few data blocks from each replica. As a result, they can provide only probabilistic data integrity guarantees. The data integrity proofs are generated based on either RSA-based homomorphic functions, such as [11], [21], or BLS signature, such as [14], [15], [22]–[23][24]. Unfortunately, similar to EDI-V, other PDP-based schemes cannot localize or repair corrupted edge data replicas. Some schemes have been proposed to repair corrupted data stored in the cloud, such as PoR-based schemes [16], erasure coding-based schemes [25], [26], and network coding-based schemes [27], [28]. However, they are inapplicable to the edge caching systems due to excessive computation and communication overheads on edge servers or users [29]. Please refer to Section V for a more detailed discussion.

To facilitate a comprehensive evaluation, two schemes derived from existing PDP-based schemes are implemented for comparison against CooperEDI in our experiments:

PDP-M. Derived from MR-PDP [21], PDP-M generates data integrity proofs based on an RSA-based homomorphic function for the inspection of multiple data replicas. The data masking mechanism in MR-PDP is removed to improve its efficiency.

PDP-B. Derived from [14], [22]–[23][24], PDP-B generates BLS signatures as data integrity proofs.

Under the PDP-M and PDP-B schemes, application vendor sends data integrity verification requests and edge servers respond with data integrity proofs. Then, application vendor inspects all the received data integrity proofs in batch.

2) Performance Metrics:
The following three metrics are collected to evaluate CooperEDI’s performance.

a) Corruption Detection Rate [10]:
This is measured by the ratio of the number of detected corrupted edge data replicas over the total number of corrupted edge data replicas, the higher the better.

b) Time Consumption [14], [24], [30]:
This is measured by the computation time and communication time taken to complete the data assurance process, the lower the better.

c) Communication Overhead [10], [14], [24], [30]:
As introduced in CooperEDI scheme, application vendor is not involved in data integrity verification, corruption localization or data repair. Thus, for CooperEDI, this metric measures the overall communication overheads incurred between different edge servers. In contrast, it measures the overall communication overheads between the edge servers and application vendor incurred by the other three competing schemes. Low values indicate high performance.

3) Parameter Settings:
In the experiments, the original data to be inspected is randomly generated according to the data size (ds ). A data replica comprised of ds/bs data blocks is cached on each of the n edge servers in the edge caching system. A certain number of corrupted edge data replicas are simulated based on the corruption ratio cr by randomly modifying a certain proportion (cs ) of the data blocks in each of the corrupted data replicas, similar to the experiments in many studies of PDP-based schemes [11], [14], [21], [23]. Both PDP-M and PDP-B randomly sample a total number of ss data blocks from each data replica for inspection while CooperEDI inspects all the data blocks of each replica. Moreover, as EDI-V samples all the data blocks in a subtree, an edge server randomly selects a minimum subtree that has at least ss data blocks for inspection.

To extensively evaluate CooperEDI’s performance, the following six parameters are varied to simulate various EDI scenarios in this research. Each time the value of one parameter varies while the others fix at the default values, as shown in Table II. The experiments are repeated 100 times and the average results are reported.

Sampling Scale (ss ), the total number of data blocks sampled from each edge data replica for inspection.

Data Replica Scale (n ), the total number of edge data replicas to be inspected.

Data Size (ds ), the size of each data replica (MB as unit).

Data Block Size (bs ), the size of each data block (KB as unit).

Corruption Ratio (cr ), the percentage of corrupted edge data replicas.

Corruption Severity (cs ), the percentage of corrupted data blocks in a corrupted edge data replica.

TABLE II Parameter Settings

A total of 128 virtual machines are randomly mapped to a geographical area to simulate networked edge servers constituting the edge caching system in the area. Each of the virtual machines is equipped with 1 vCPU, 2GB RAM, running Ubuntu 16.04. It also runs DummyNet1 to specify the network latency between different edge servers [31]. Another virtual machine is deployed in Amazon’s cloud to simulate application vendor’s cloud server. It is equipped with 8 vCPUs, 32GB RAM, also running Ubuntu 16.04. The network latency between different edge servers are set to 5ms to 15ms according to the distance between them. The network latency between application vendor’s cloud server in Amazon’s cloud and the edge servers fluctuates over time and averages at 110ms in the experiments.

All the four schemes in comparison are implemented in Java with JPBC library.2 A 512-bit prime is employed by PDP-M to perform the exponential operations for generating data integrity proofs. PDP-B employs the SHA-256 hash function to map each data block to the elliptic curve during the BLS paring. SHA-256 is also used by CooperEDI to generate the digest of each data block or data replica. Time threshold t1 used in Phase 2 (Ground-truth Determination) is set to 200ms, and time threshold t2 used in Phase 4 (Data Repair) is set to 100ms.

B. Experimental Results
EDI-V, PDP-M and PDP-B can only verify data integrity, i.e., whether there are corruptions in each edge data replica. Thus, only their performance in data integrity verification are compared in this research. As they sample a fixed number of data blocks from each edge data replica for inspection, their corruption detection rates are impacted by only sampling scale ss and corruption severity cs . Moreover, their time consumption and communication overheads are impacted by only the sampling scale ss , the data replica scale n , and the data block size bs .

1) Corruption Detection Rate:
Fig. 3 compares the corruption detection rates achieved by the four competing schemes in different scenarios. The first overall observation is that PDP-M and PDP-B achieve similar corruption detection rates while EDI-V is slightly higher. As introduced in Section IV-A.1, all of them are probabilistic schemes. Given the same sampling scale ss and corruption severity cs , their theoretical performance in detecting corrupted data are the same. Compared with PDP-M and PDP-B, EDI-V obtains higher detection rates as it always samples more data blocks than PDP-M and PDP-B. For example, when PDP-M and PDP-B sample 100 data blocks, EDI-V samples at least 128 data blocks to produce a VMHT for inspection. The second overall observation is that CooperEDI always achieves a corruption detection rate of 100% in all the cases. This evidences its ability to offer a full guarantee in corruption detection as compared to PDP-M, PDP-B and EDI-V’s probabilistic guarantee.


Fig. 3.
Corruption detection rate.

Show All

Fig. 3(a) demonstrates the impact of the sampling scale ss on the four competing schemes’ corruption detection rates when ss increases from 50 to 200 with corruption severity cr fixed at 0.03. It can be seen that ss impacts PDP-M, PDP-B, and EDI-V significantly but not CooperEDI. Given a larger ss , PDP-M, PDP-B and EDI-V sample more data blocks for inspection. This increases their chances to detect corrupted data blocks. Specifically, when ss increases from 50 to 250, the average corruption detection rates achieved by PDP-M, PDP-B and EDI-V increase from 80.22% to 99.97%, from 77.80% to 99.98%, and from 92.37% to 99.99%, respectively. Similar phenomena can be observed from Fig. 3(b) where corruption severity cs increases from 0.01 to 0.05 with ss fixed at 150 (ss=256 for EDI-V). Corruption severity cs significantly impacts the corruption detection rates of PDP-M, PDP-B and EDI-V, but not CooperEDI. A larger cs means that more of the data blocks of a corrupted data are damaged. This makes it easier for them to detect corrupted data blocks with a fixed ss . However, it is impossible for PDP-M, PDP-B and EDI-V to guarantee a 100% corruption detection rate unless there is ss=ds/bs , i.e., to sample all the data blocks. This is an inherent weakness of probabilistic data integrity schemes.

Similarly, CooperEDI can always ensure a 100% success rate for corruption localization and data repair for the same reason.

2) Time Consumption:
Fig. 4(a) demonstrates that with the increase in sampling scale ss , both PDP-M and PDP-B take significantly more time to finish the verification. The first reason is that it takes PDP-M and PDP-B more time to generate data integrity proofs from the sampled data blocks. Besides, they need more time to inspect those proofs on application vendor’s side. The same applies to EDI-V as each edge server needs to generate a bigger VMHT when ss increases. As illustrated earlier in Fig. 3(a), a large ss will improve their corruption detection rates. However, Fig. 4 shows that this comes at the heavy cost of rapidly-increasing time consumption. This observation evidences the conclusion made in Section I that PDP-based schemes are impractical for the EDI problem. In contrast, CooperEDI’s time consumption is stable as it inspects all the data blocks for integrity verification.

Fig. 4. - Time consumption for integrity verification.
Fig. 4.
Time consumption for integrity verification.

Show All

Fig. 4(b) compares the time consumption of each scheme when data replica scale n increases from 20 to 100. Similar to that shown in Fig. 4(a), we can see that PDP-M, PDP-B and EDI-V take more time to finish the verification when n increases, but CooperEDI’s time consumption remains stable. For example, when n is 20, i.e., 20 data replicas in total to be inspected, PDP-M, PDP-B, EDI-V and CooperEDI take an average of 152.24s, 28.55s, 11.96s and 7.74s, respectively, to finish the inspection. When n increases to 100, their corresponding time consumption increase to 716.93s (by 370.90%), 85.80s (by 200.51%), 16.22s (by 35.61%), and 7.86s (by 1.53%). The reason is that PDP-M, PDP-B and EDI-V are centralized schemes and all the data integrity proofs are inspected on application vendor’s side. First, transmitting those proofs to application vendor’s cloud server incurs extra transmission time. Second, application vendor has to sample the same data blocks from the original data as the edge servers to perform the inspection. This is a time-consuming process. Take PDP-M and PDP-B as example, when n=60 and ss=150 , each edge server samples only 150 data blocks from its edge data replica but application vendor has to sample 9,000 corresponding data blocks to complete the inspection of all the edge data replicas. This leads to high workload for application vendor. In contrast, CooperEDI is a distributed scheme and all the edge servers cooperatively and concurrently inspect each replicas. As a result, CooperEDI is much more efficient than PDP-M and PDP-B, and scales extremely well with the data replica scales n . When n is 20, 40, 60, 80, and 100, CooperEDI’s time consumption is less than PDP-M by an average of 94.91%, 97.36%, 98.21%, 98.64%, and 98.90%, less than PDP-B by an average of 72.88%, 81.80%, 86.00%, 89.02%, and 90.84%, and less than EDI-V by an average of 58.36%, 48.69%, 40.38%, 50.56%, and 55.09%, respectively.

Similar phenomena can be observed in Fig. 4(c) where the data block size bs increases from 128KB to 2MB. With the increase in bs , the time consumption of PDP-M increases significantly. The reason is that with RSA-based homomorphic function, PDP-M needs to convert each sampled data block to a big integer and perform the exponential operation with the 512-bit prime as base to generate each corresponding proof. When bs increases, the integer becomes bigger, taking PDP-M more time to complete the conversion and the exponential operation. PDP-B’s time consumption also increases but much slower than PDP-M. PDP-B employs the SHA-256 hash function to map each data block to the elliptic curve when generating integrity proofs. The hash function is more efficient than PDP-M’s homomorphic function. In our experiments, it takes about 1.46ms to hash a 128KB data block, and 16.48ms to hash a 2MB data block. Taking this advantage, PDP-B achieves higher efficiency than PDP-M. EDI-V’s time consumption decreases when bs increases from 128 to 512, then increases when bs continues to increases. The reason is that EDI-V creates a VMHT on application vendor’s side based on the entire original data while each edge server only creates a smaller VMHT based on sampled data blocks. The increase in bs impacts the total number of nodes in the VMHT on each edge server. As a result, the time consumption taken by application vendor decreases while the time consumption taken by each edge server increases. Interestingly, as illustrated by Fig. 4(c), the data block size (bs ) rarely impacts the efficiency of CooperEDI. The reason is that CooperEDI is a deterministic scheme that employs the entire edge data replica for inspection. As a result, its time consumption is stable when data size ds is fixed. When bs is 128KB, 256KB, 512KB, 1MB, and 2MB, CooperEDI’s time consumption is less than PDP-M by an average of 75.21%, 93.39%, 98.30%, 99.57%, and 99.89%, and less than PDP-B by an average of 71.79%, 81.20%, 85.99%, 88.92%, and 90.89%, and less than EDI-V by an average of 53.37%, 40.89%, 29.57%, 36.41%, and 45.68%, respectively.

The above observations illustrate that CooperEDI is capable of verifying the integrity of a large number of edge data replicas efficiently. This is aligned with the lightweight requirement for EDI approaches, as introduced in Section I.

3) Communication Overhead:
a) Communication Overhead for Integrity Verification:
Under the CooperEDI scheme, manager edge servers need to be elected through a distributed consensus to take the responsibility to coordinate the verification process. Compared with centralized EDI approaches like EDI-V, this inevitably incurs extra communication overheads. Fig. 5 compares the communication overhead incurred by the four competing schemes when verifying the data integrity. Overall, CooperEDI incurs 2.02 times more communication overheads than EDI-V, but 73.81% and 47.21% less than PDP-M and PDP-B, respectively. However, EDI-V’s communication overheads are incurred over the backhaul network between edge servers and application vendor. This goes against the MEC’s pursuit of minimum backhaul network traffic [4], [32]–[33][34]. CooperEDI’s communication overheads are incurred only at the network edge, which ensures its practical application in real-world edge caching systems.


Fig. 5.
Communication overhead for integrity verification.

Show All

Fig. 5(a) shows that a larger ss significantly increases the PDP-M and PDP-B’s communication overheads, but not EDI-V or CooperEDI’s. Sampling more data blocks, both PDP-M and PDP-B have to transmit more data integrity proofs to application vendors for inspection. This immediately incurs extra communication overheads. EDI-V only transmits the hash tag of the root node in each edge server’s VMHT to application vendor. Therefore, its communication overhead is not impacted by ss .

Fig. 5(b) compares their communication overheads when data replica scale n increases from 20 to 100. It can be served that n impacts the communication overheads of PDP-M, PDP-B and EDI-V significantly, but not EDI-V. The reason is that when there are more edge data replicas to inspect, both PDP-M and PDP-B have to transmit more data integrity proofs from edge servers to application vendor’s cloud server. In the meantime, under the CooperEDI scheme, the increase in n involves more edge servers in determining the ground-truth for the inspection. This incurs more network traffic. Overall, CooperEDI incurs much less network traffic than PDP-M and PDP-B but more than EDI-V. The main reason is that each edge server transmits only one digest to each of the other edge servers in the system under the CooperEDI scheme. In contrast, under the PDP-M and PDP-B schemes, each edge server has to transmit more integrity proofs to application vendor - one for each of the sampled data blocks. Specifically, when n is 20, 40, 60, 80 and 100, CooperEDI incurs 91.27%, 82.54%, 73.81%, 65.08%, and 56.34% less network traffic on average compared with PDP-M, and 82.40%, 64.81%, 47.21%, 29.62%, and 12.02% less network traffic on average compared with PDP-B, but 5.14%, 100.89%, 201.34%, 301.79%, and 402.23% more network traffic on average compared with EDI-V.

In Fig. 5(c), we can find that the data block size bs does not impact the communication overheads of the four competing schemes. The network traffic incurred is stable when bs increases from 128KB to 2MB. The reason is that PDP-M, PDP-B and EDI-V sample a fixed number of data blocks for inspection and transmit only the corresponding integrity proofs of each data block over the backhaul network. Their network traffic is fixed when the sampling scale is fixed. Similarly, CooperEDI transmits digests instead of full data blocks for inspection and incurs no extra network traffic when bs increases. On average across all cases, CooperEDI incurs 73.81% and 47.21% less network traffic than PDP-M and PDP-B, and 201.30% more network traffic than EDI-V, respectively.

b) Communication Overhead for Corruption Repair:
As introduced in Section I, PDP-M, PDP-B, and EDI-V cannot localize corrected edge data replicas at the data block level. Under these schemes, when a corrupted edge data replica is detected, application vendors need to transmit the entire data from the cloud to the corresponding edge server to replace the corrupted edge data replicas. This incurs extra backhaul communication overheads. In contrast, CooperEDI is capable of localizing and repairing corrupted edge data replicas at the data block level. Manager edge servers only need to transmit the corresponding correct data blocks to the corresponding edge servers for data repair. In addition, these data blocks are only transmitted over the edge server network. These significantly reduce the overall communication overhead incurred under the CooperEDI scheme, in particular backhaul network overhead.

Fig. 6(a) compares the communication overheads incurred by repairing corrupted edge data replicas between CooperEDI and the other three schemes. Please note that PDP-M, PDP-B, and EDI-V incur the same communication overheads by transmitting the entire data for data repair. Thus, their communication overheads are represented by the same bars in Fig. 6(a) as well as Fig. 6(b), noted as PDP-M, PDP-B, EDI-V. It can be easily seen that CooperEDI’s communication overheads for data repair are multiple-order-of-magnitude lower than the other three schemes in all the cases. Fig. 6(b) illustrates the communication overheads incurred by the four schemes when corruption severity cs increases from 0.01 to 0.05. Similar to Fig. 6(a), CooperEDI outperforms the other three schemes significantly in all the cases, incurring 97.14% fewer communication overheads on average. With the increase in cs from 0.01 to 0.05, CooperEDI’s communication overhead increases from 29.30MB to 146.49MB. The reason is straightforward - more correct data blocks are needed to repair corrupted data. In contrast, the communication overheads incurred by the other three schemes remain stable as they always transmit the entire data regardless of the corruption severity.


Fig. 6.
Communication overhead for data repair.

Show All

The above observations illustrate that CooperEDI can verify and repair a large number of edge data replicas without incurring significant communication overheads, in particular no traffic pressure on the backhaul network.

4) Impact of Parameters:
Now we study the impacts of the five parameters on CooperEDI’s overall time consumption and communication overheads incurred by corruption detection, corruption localization and corruption repair to evaluate its performance in various EDI scenarios. The impact of sampling scale ss is omitted as CooperEDI inspects the entire data replica for integrity verification.

a) Impact of Data Replica Scale (n ):
Fig. 7(a) shows the impact of n on CooperEDI’s time consumption. We can find that CooperEDI’s time consumption increases as long as n increases. However, CooperEDI scales well with n . For example, when n is 20, CooperEDI takes about 17.51s to finish the overall process. When n increases to 100, it takes about 17.76s (increased by 1.42%). This is because CooperEDI allows multiple manager edge servers to concurrently help other edge servers repair corrupted data. Besides, the communication between edge servers are performed over the high-speed edge server network, which minimizes the network latency incurred. The results demonstrate CooperEDI’s advantages in solving the EDI problem in edge caching systems comprised of massive distributed edge servers. As shown in Fig. 7(b), the increase in n incurs more communication overheads for CooperEDI. That is because the total number of corrupted data replicas increases when n increases and more valid data blocks need to transmitted for data repair.


Fig. 7.
Impact of data replica scale n .

Show All

b) Impact of Data Size (ds ):
We can observe in Fig. 8 that the data size ds has a significant impact on both CooperEDI’s time consumption and communication overheads. As shown in Fig. 8(a), when ds increases from 128MB to 2GB, CooperEDI’s time consumption increases from 5.04s to 65.51s by 12.01 times. The main reasons are threefold: 1) when ds increases, edge servers take more time to generate data digests based on the entire edge data replicas in Phase 2; 2) edge servers take more time to generate data block digests in Phase 3 because the total number of data blocks in each data replica increases when ds increases; and 3) more valid data blocks are transmitted between edge servers in the system to facilitate data repair. The last two reasons are also the reasons for the increases in CooperEDI’s communication overheads, as shown in Fig. 8(b).

Fig. 8. - Impact of data size 
$ds$
.
Fig. 8.
Impact of data size ds .

Show All

c) Impact of Data Block Size (bs ):
Fig. 9 shows CooperEDI’s performance against different data block sizes bs . It can be observed that when bs increases from 128KB to 2MB, CooperEDI’s time consumption decreases slightly, as shown in Fig. 9(a). The reason behind is that, given a data replica with a fixed size, e.g., 512MB in this experiment, a larger bs will reduce the total number of data blocks in each edge data replica. As a result, CooperEDI takes less time to generate data block digests in Phase 3. Besides, the increase in bs also decreases the total number of corrupted data blocks in those corrupted replicas. This further reduces the time needed for managers to transmit valid data blocks for data repair. We can observe in Fig. 9(b) that the increase in bs decreases CooperEDI’s communication overheads. That is because the total number of corrupted data blocks decreases when bs increases, which reduces the communication overheads incurred by the transmission of the Data Inspection Messages in Phase 3.


Fig. 9.
Impact of data block size bs .

Show All

d) Impact of Corruption Ratio (cr ):
Fig. 10 illustrates the impact of cr on CooperEDI’s performance when cr increases from 0 to 0.2 in steps of 0.05. When cr =0, none of the edge data replicas is corrupted. In such cases, CooperEDI takes an average of 7.86s to finish an assurance process, as shown in Fig. 10(a). In the meantime, Fig. 10(b) shows CooperEDI incurs insignificant communication overheads when trying to determine the ground-truth and verify data integrity. For example, a total of 175.18KB data is transmitted in the system during the inspection of 60 512MB data replicas, each comprised of 1,024 512KB data blocks. This demonstrates CooperEDI’s low extra communication resource consumption when in relatively reliable edge caching systems.


Fig. 10.
Impact of corruption ratio cr .

Show All

When data corruptions are detected, CooperEDI attempts to localize the corruptions and repair corrupted replicas. This takes extra time. For example in Fig. 10(a), when the corruption ratio cr increases from 0 to 0.05, CooperEDI’s time consumption increases from 7.86s to 17.59s. When cr continues to increase, CooperEDI’s time consumption stabilizes. The reason is that under the CooperEDI scheme multiple manager edge servers can perform data assurance concurrently. They share the extra workload without significantly delaying the completion of the assurance process. This shows the advantage of CooperEDI in solving the EDI problem in a decentralized manner.

We also can observe that CooperEDI incurs higher communication overheads when cr increases, as shown in Fig. 10(b). The reasons are twofold: 1) managers need to transmit data digests to more edge servers to help them localize corrupted data blocks in Phase 3; and 2) they also need to transmit valid data blocks to more edge servers for repairing corrupted data in Phase 4. Comparing the communication overheads incurred when cr=0 and cr>0 , we can see that most of the network traffic is incurred by transmitting data blocks for data repair. For example, about 88.73% of the network traffic is incurred by sending valid data blocks when n = 60, ds = 512MB, bs = 512KB, cr = 0.1 and cs = 0.03.

e) Impact of Corruption Severity (cs ):
Fig.s 11(a) and 11(b) demonstrate the impact of corruption severity cs on CooperEDI’s time consumption and communication overheads, respectively. We can find that both of them increase along with the increase in cs . The reason is that when cs increases, more data blocks in each corrupted data replica need to be repaired. Then, a manager needs more time to transmit those valid data blocks in Phase 4 for data repair. This incurs extra time consumption and communication overheads.


Fig. 11.
Impact of corruption severity cs .

Show All

C. Discussion
1) Workload Fairness Over Manager Edge Servers:
In Phase 4 Data Repair, an edge server with corrupted data replica waits a time period of t2 before choosing one manager to perform data repair. Now we analyze how this mechanism impacts the workload fairness over multiple manager edge servers in the system. Fig. 12 compares the chosen managers’ average workload when t2 increases from 10ms to 200ms when the data replica scale is 20, 60, and 100, respectively. A chosen manager is the one that has been chosen by at least one edge server to perform data repair in Phase 4 Data Repair. The workload ratio illustrated in Fig. 12 is measured by the ratio of the number of edge servers whose edge data replicas are corrupted over the number of chosen managers. A low value indicates a low average workload on each individual manager in the system. We can find that t2 significantly impacts the workload fairness over the managers. For example, when n=100 and t2=10 ms, each chosen manager serves 2.66 other edge servers in the system on average. This poses heavy workloads on the chosen managers as they have to communicate with more edge servers and transmit valid data blocks at the same time. When t2 increases, the workload ratio decreases rapidly, downs to 1.11 when t2 is 100ms and 1.05 when t2 is 200ms. The ability of CooperEDI to distribute data assurance workloads across multiple edge servers is particularly important to edge caching systems where edge servers’ resources are often constrained [1], [34].


Fig. 12.
Impact of t2 on workload fairness.

Show All

2) Composition of CooperEDI’s Time Consumption:
Fig. 13 compares CooperEDI’s time consumption in different phases where all the parameters are fixed values as shown in Table II. It can be observed that CooperEDI takes very little time to complete Phase 1 (System Setup) and Phase 4 (Data Repair), which contributes only 0.01% and 2.55% of its overall time consumption, respectively. In contrast, CooperEDI spends 43.68%, and 53.76% of the overall time consumption in Phase 2 (Ground-truth Determination) and Phase 3 (Corruption Localization), respectively. Most of the time are consumed for generating those digests. This can be further improved by employing more efficient digest generation functions. In addition, similar to PDP-M [21] and PDP-B [14], [22]–[23][24], sampling techniques can be employed in Phase 2 and Phase 3 to sample a portion of data (or data blocks) instead of the entire data (or all the data blocks) for digest generation. However, the adoption of sampling techniques will turn CooperEDI into a probabilistic scheme, i.e., it will provide a probabilistic guarantee for data corruption discovery and repair.


Fig. 13.
Time consumption in different phases.

Show All

3) Innovation and Limitation of CooperEDI:
Compared with existing schemes, CooperEDI solves the EDI problem in a distributed manner. Under the CooperEDI scheme, edge servers communicate with each other to collaboratively detect the ground-truth (correct data replicas), find and repair corrupted data replicas. This makes CooperEDI a perfect EDI solution in the MEC environment where low latency is demanded because it does not require centralized coordination from the remote cloud. As shown in Sections IV-B.1 and IV-B.2, CooperEDI outperforms existing solutions significantly in detecting corrupted edge data replicas. In addition, the experimental results shown in Section IV-B.2 demonstrate that CooperEDI does not incur any communication overheads on the backhual network, which is another main objective of MEC. Another main innovation of CooperEDI is its ability to not only detect corrupted edge data replicas but also repair them, also in a distributed manner.

The advantages of CooperEDI comes at the price of higher communication overheads among edge servers at the network edge. The reason is that, unlike existing schemes that retrieve the ground-truth from the remote cloud, edge servers under the CooperEDI scheme communicate with each other to collaboratively find out the ground-truth. Besides, to repair corrupted data blocks, the correct data blocks need to be transmitted from a manager edge server to those edge servers with corrupted edge data replicas. This also incurs communication traffic among edge servers.

SECTION V.Related Work
Cloud-based caching systems like content delivery networks (CDNs) have been intensively studied and widely employed in the past decades to reduce the latency in users’ access to applications [35]–[36][37]. To enable modern applications with stringent latency requirements, e.g., interactive AR/VR applications and networked gaming, etc., mobile edge computing (MEC) has been included in the 5G technology stack.

MEC allows resource-limited mobile devices to offload their computation tasks to edge servers. In this way, those devices are capable of executing modern resource-intensive applications. This improves user-perceived service quality and service experience. Computation offloading has attracted massive attention from researchers in recent years. Dinh et al. studied the offloading problem in the multi-user multi-server MEC scenarios aiming to maximize the long-term CPU utilities [38]. Guo et al. extended this study to the ultra-dense IoT networks containing heterogeneous edge servers [39], and vehicle edge computing network integrating MEC and smart vehicles [40]. Guo and Liu studied the collaborative offloading problem by allowing a task to be offloaded to either edge servers or remote clouds [41]. Later, they extended the study to the Unmanned Aerial Vehicle (UAV) enhanced MEC environment where UAVs are employed to provide IoT devices reliable communication connections [42]. Apostolopoulos et al. studied the offloading problem in a similar scenarios, but those UAVs not only provide communication connections but also serve as edge servers [43]. Dbouk et al. studied the offloading problem in a different perspective [44]. Specifically, they proposed a framework to help devices offload their computation tasks to nearby devices while fulfilling the energy and CPU capacity constraints.

MEC also allows application vendors to offload their data to the network edge by caching them on edge servers [32], [33]. It further shortens the physical distance between data and users - usually within hundreds of meters. Thus, it minimizes users’ data access latency [4], [45] and provides them better service experiences.

Due to its unique characteristics, MEC is subject to many new security issues which have been attracting researchers’ attentions very recently [9], [10], [30]. To name a few, He et al. studied DDoS attach at edge servers and proposed a game theory based approach to mitigate such attack [9]. Yuan et al. proposed a blockchain-based system to build trust and offer incentives for edge servers to facilitate collaborative edge computing [46]. Li et al. studied the problem of service robustness when deploying multiple application replicas in the MEC environment [1]. Cui et al. studied system robustness in the edge server placement problem [47]. These indicate the importance and urgency of edge security studies.

As one of the most important aspects of information forensics and security, auditing cloud data integrity has been extensively studied and many state-of-the-art schemes have been proposed. Among them, PDP-based schemes are the most popular ones [11]. Given a set of files to be audited, PDP-based schemes randomly select a few data blocks in each file and generate the corresponding data integrity proofs, then verify the data integrity by inspecting those proofs in batch. A few PDP-based schemes can be employed to find out whether there are corruptions among a very small number of data replicas stored in the cloud [14], [21]–[22][23][24], [48]. However, PDP-based schemes are too heavyweight to inspect tremendous data replicas cached in an edge caching system comprised of many geographically distributed edge servers. This is confirmed by the experimental comparison demonstrated in Section IV where two representative PDP-based schemes are implemented, i.e., PDP-M and PDP-B.

Beyond data integrity auditing, many schemes have been proposed to repair corrupted data stored in the cloud, such as POR [16] and erasure coding-based schemes [25], [26]. For example, given an original file, an erasure coding-based scheme splits it into m blocks and generates k redundancy parity blocks by the (m,k ) Reed-Solomon erasure code. Next, all blocks are dispersed to m+k servers. In this way, a valid file can be rebuilt through any m of m+k data blocks and/or parity blocks, i.e., each file tolerances k blocks fault with k/m times extra storage overheads. Unfortunately, such schemes are impractical in the MEC environment as users will have to access at least m edge servers to retrieve a complete file. This is often impossible due to the coverage constraint in the MEC environment - a user cannot access an edge server if it is not covered by a base station to which the edge server is attached [49]. Besides, storing redundancy parity blocks are expensive on the edge servers where the storage resources are highly constrained compared with cloud servers [6].

Network coding-based schemes, such as those introduced in [27], [28], can also help users retrieve intact files against data failures. The general idea of such schemes is to divide an original data into m blocks with the same sizes, then generate a total number of n code files by linearly combining those data block with random combination coefficients. Next, it stores those code files at n different servers. Under the network coding-based schemes, users can retrieve the original file based on any m code files, which provides the capability to tolerate data failures. However, these schemes are not suitable for solving the EDI problem for two main reasons. First, the user may not always be able to fetch adequate code files due to the coverage constraint in the MEC environment which limits its access to edge servers. Second, even if the user can fetch adequate code files, the decoding process incurs extra (and very often profound) time consumption which contradicts MEC’s pursuit of low latency.

Existing schemes for ensuring cloud data integrity are rendered obsolete by the unique characteristics of the edge caching systems. To help users verify their data store on edge servers, Tong et al. proposed a PDP-based scheme to perform the verification [50]. However, their study mainly focuses on privacy preservation and fails to tackle the unique challenges in edge data integrity. As another variant of the PDP scheme, their scheme has the same efficiency limitation as to the other PDP schemes. Very recently, A scheme named EDI-V was proposed to verify the integrity of application vendors’ edge data replicas [10], trying to reduce the computation overheads incurred by the verification process on both application vendor and edge servers. However, EDI-V suffers from five critical limitations, i.e., high traffic over backhaul network, low efficiency, probabilistic integrity assurance and the lack of abilities to localize and repair corrupted edge data replicas at the level of data blocks. They also proposed EDI-S to solve the EDI problem based on elliptic curve cryptography [30]. Similar to CooperEDI, EDI-S can guarantee a 100% corruption detection rate. Cui et al. proposed a PDP-based scheme named ICL-EDI for edge data integrity verification and tried to improve the efficiency [51]. However, both EDI-S and ICL-EDI cannot repair corrupted edge data replicas. Besides, they are still a centralized approach which suffers the same efficiency limitation as EDI-V. To over these limitations, this paper took a giant step further to tackle the EDI problem with three main objectives: 1) to inspect a large amount of edge data replicas efficiently; 2) to localize the corruption accurately, and 3) to repair the corruption efficiently.

In the MEC environment, an edge caching system is comprised of massive geographically distributed edge servers that are close to users but far from the remote cloud. Thus, centralized control from the remote cloud is not practical because the high latency incurred can easily undermine MEC’s pursuit of low latency. Inspired by the wide success of Paxos [19] and Raft [20], we designed CooperEDI, a scheme based on distributed consensus, to tackle the EDI problem in a decentralized manner. Specifically designed for edge caching systems, CooperEDI achieves superior performance compared to those representative CDI schemes, as demonstrated in Section IV.

SECTION VI.Conclusion and Future Work
Mobile edge computing (MEC) offers application vendors a bounded latency guarantee for their latency-sensitive applications. Caching popular data on edge servers nearby users can reduce the data access latency. However, due to the distributed characteristic of MEC, those cached data replicas are subject to corruption and their integrity must be ensured. The unique characteristics of MEC render existing centralized data integrity assurance schemes obsolete. To tackle this new challenge, a novel scheme named CooperEDI is proposed to guarantee edge data integrity for application vendors. CooperEDI employs a distributed consensus mechanism to allow edge servers to cooperatively verify data integrity, localize corruptions and repair corrupted data. Extensive experiments demonstrate that CooperEDI can ensure edge data integrity in the MEC environment effectively and efficiently. In the future, we will investigate possible attacks against CooperEDI and explore corresponding defense mechanisms.