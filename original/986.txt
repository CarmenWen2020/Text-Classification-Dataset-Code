The recent success of Deep Convolutional Neural Network (DCNN) for various computer vision tasks such as image recognition has already demonstrated its robust feature representation ability. However, the limitation of training database on small scale vein recognition tasks restricts its performance because the recognition result of DCNN depends heavily on the number of trainsets. This motivates the design of a Multi-Scale Deep Representation Aggregation (MSDRA) model based on a pre-trained DCNN for vein recognition. First, the multi-scale feature maps are extracted by a pre-trained DCNN model. Second, a local mean threshold approach is designed to preliminarily remove the noisy information of multi-scale feature maps and generate the selected feature maps. Third, we propose an Unsupervised Vein Information Mining (UVIM) method to localize vein information of selected feature maps for generating a binary vein information mask, and then the vein information mask is utilized to keep useful deep representation and discard the background information. Finally, the discriminative multi-scale deep representations, which are generated by using the vein information mask to aggregate multi-scale feature maps, are concatenated into the final compact feature vectors, and then a Support Vector Machine (SVM) is introduced for final recognition. Our proposed model outperforms the state-of-the-art methods on two benchmark vein databases. Moreover, an additional experiment using the subset of PolyU Palmprint database illustrates the system's generalization ability and robustness.
SECTION I.Introduction
Due to the growing demand for security awareness, hand-dorsa vein recognition, a newly emerging identification recognition technique, has paid more considerable attention in biometric recognition fields. Compared with other biometric modes such as face recognition [1], palmprint recognition [2], [3], fingerprint recognition [4] and iris recognition [5], hand-dorsa vein recognition has three kinds of specific properties that include high security, liveness detection and convenience, which makes it become one of the most effective biometric modes. A hand-dorsa vein recognition system generally consists of the following steps such as vein image capture, vein image preprocessing, feature extraction and feature matching. Among the above mentioned steps, feature extraction is regarded as the most important part. Currently, many researchers have designed some effective feature extraction methods for hand-dorsa vein recognition tasks. These feature extraction methods can be divided into three main groups such as shape feature-based methods, texture feature-based methods and deep feature-based methods. The first vein recognition approach adopts the shape information of vein images as feature representation, and the shape information of vein images is generally obtained by mathematical methods or vein segmentation methods. Therefore, the inaccurate vein segmentation and image contrast can degrade the performance of these methods. The second vein recognition method mainly uses the scale invariant feature transform (SIFT) [6] and local binary pattern (LBP) [7] to extract texture information of vein images. However, the mismatch of key-point in the process of SIFT is affected by the image preprocessing algorithms such as contrast enhancement [8], which leads to unreliable identification results. Besides, LBP has a disadvantage in encoding sparse vessel structures [9], which degrades its performance on vein recognition tasks. The third vein recognition model obtains feature representation ability for vein images by training Deep Convolutional Neural Network (DCNN) on vein databases. However, because the performance of DCNN relies seriously on the size of vein databases, it is difficult to build a more effective vein recognition system by the DCNN model. Thus, applying the DCNN model to vein recognition tasks is still challenging because it is hard to meet the demand for a large number of training samples to train a DCNN. To address this problem, the training strategy of DCNN [10], [11] and the design of task-specific network architecture [12] are proposed in recent years. Although these methods successfully apply DCNN model to vein recognition tasks, some models among these methods need complex training process and some models among these methods need to further improve the feature representation ability of networks for vein images.

Adopting convolutional activations [13] of a pre-trained DCNN as an image representation for classification has been widely applied to image recognition tasks, and these models have obtained impressive performance in recent years. For example, Liu et al. [14] present a novel cross-convolutional-layer pooling (CL) based on convolutional activations of a pre-trained DCNN to better obtain discriminative deep representation for image recognition. Wei et al. [15] proposed a selective convolutional descriptor aggregation (SCDA) model based on the global mean threshold method, which achieves outstanding performance in fine-grained image retrieval. Inspired by this idea, a novel method that utilizes the convolutional activations from a pre-trained DCNN as image representation is proposed for vein recognition tasks in this paper. The designed model based on a pre-trained DCNN, which is shown in Fig. 1, not only deals with the problem of lack of vein databases but also reduces the time consumption of vein recognition systems. The detailed procedure of the designed model for vein recognition is as follows: First, the multi-scale feature maps are extracted by a pre-trained DCNN model. Second, a local mean threshold is utilized to firstly remove the background information of multi-scale feature maps and generate the selected feature maps. Third, a UVIM approach is designed to localize the vein information of selected feature maps for generating a binary vein information mask, and then the vein information mask is utilized to keep useful deep representation and discard the background information. Specifically, the frequency of each item corresponding to each position of the selected feature maps is calculated, and the items whose frequency are the first k are retained. Subsequently, the partial vein information in each selected feature map is mined based on frequency patterns, and then a Vein Information Mask (VIM) obtained by merging all mined feature maps in an unsupervised manner is utilized to eliminate background information of selected feature maps. Finally, the discriminative multi-scale deep representations obtained by using the VIM to aggregate multi-scale feature maps are concatenated into the final compact feature vectors, and then a Support Vector Machine (SVM) is introduced for final recognition. The advantage of the proposed MSDRA is demonstrated on three benchmark databases.

Fig. 1. - The framework of our proposed MSDRA model for vein recognition.
Fig. 1.
The framework of our proposed MSDRA model for vein recognition.

Show All

Overall, the main contributions of this paper are summarized as follows:

We propose a novel Multi-Scale Deep Representation Aggregation model based on a pre-trained DCNN for hand-dorsa vein recognition. The proposed method effectively enhances the robustness and feasibility of identity identification systems based on vein information.

A local mean threshold is designed to preliminarily eliminate the background information of the multi-scale feature maps.

We present the first model based on unsupervised pattern mining to localize vein information of feature maps from a pre-trained DCNN, which effectively explores the potential feature representation ability of the pre-trained DCNN for vein recognition tasks.

A series of rigorous experiments are conducted on three databases to evaluate the performance of our proposed MSDRA. The impressive recognition results are achieved compared with the state-of-the-art models.

The remainder of this paper is organized as follows: the related vein recognition methods in recent years are introduced in Section II. In Section III, we describe the detailed process of a novel MSDRA model for vein recognition. The experimental results and analyses on three benchmark databases are presented in Section IV. Finally, we summarize the paper and conclude the future work in Section V.

SECTION II.Related Work
According to the difference of feature extraction algorithms, vein recognition models can be divided into three categories including shape feature-based methods, texture feature-based methods and deep feature-based methods. Summary of three kinds of vein recognition models is illustrated in Table I. The basic idea of three kinds of vein recognition models is reviewed in this section.

TABLE I Summary of Three Kinds of Vein Recognition Models
Table I- 
Summary of Three Kinds of Vein Recognition Models
A. Vein Recognition Methods Based on Shape Feature
The key idea of vein recognition methods based on shape feature is to extract the shape information of vein images as image representation for final classification. Generally, the acquisition of shape information of vein images has two different ways such as mathematical methods and vein segmentation methods. The former obtains vein shape information by directly calculating maximum curvature [16] or principal curvature [17] of vein vessel structures. For example, Yang et al. [18] proposed a weighted spatial curve filter to obtain vein vessel structure information, and then utilized an accurate vector field estimation method to generate the final discriminative vein feature descriptor. This model has been proved to have a great advantage in enhancing finger vein matching accuracy. Ahmad et al. [19] proposed a wave atom transform model for better extracting structure features of vein images, and then the randomization and quantization are applied to the extracted features to generate a compact, privacy-preserving palm vein template, which improves the performance of palm vein recognition systems. The latter acquires vein shape information such as vein knuckle shapes [20], end points and cross points [21] by segmenting original vein images. For instance, Yang et al. [22] firstly designed vein segmentation algorithm to obtain vein shape structures, and then extracted the tri-branch vein structures as feature representation for finger vein recognition, which improves the matching rates of finger vein images.

B. Vein Recognition Methods Based on Texture Feature
Vein recognition methods based on texture feature mainly utilize the texture variations of vein images and can be further classified into two categories which include LBP [7] and its variants [23]–[24][25] as well as SIFT [6] and its variants [26]–[27][28]. The basic idea of the first approach is to depict the global gray distribution histogram of vein images based on local coding calculation results. The first approach has two shortcomings. On one hand, the feature representation capacity of local binary pattern is decreased when it is used to encode vein images with sparse vessel structure [29], [30]. On the other hand, the omission of contrast information of vein images during the binary coding process has a negative effect on its performance [31]. To handle these two problems, Xi et al. [29] proposed a discriminative binary codes learning method for finger vein recognition system that concentrates on capturing feature representation of discriminative information among different subjects, which effectively improve the feature descriptor ability of binary codes for finger vein images with sparse vessel structure. Kang and Wu [30] designed an improved mutual foreground LBP method to address the disadvantage of binary codes for describing the texture in palm vein images. Wang and Wang proposed an improved LBP method optimized by fisher discriminant criterion to acquire more stable and discriminative binary code, which greatly degrades the impact of omission of contrast information. The second method is invariant to rotation, translation and scale uncertainty, which makes it become the most competitive and discriminative handcrafted feature extraction method. However, to enhance the number of key-points, the contrast enhancement, which has been proved to have a negative effect on key-points matching [8], is necessarily used in the process of the second algorithm. To deal with the issue, SIFT [32] or SURF [33] is directly used to extract feature descriptors of original vein images without any contrast enhancement algorithms, followed by key-points matching. Although the idea avoids the negative effect of contrast enhancement, it results in a small number of key-points, which makes the matching threshold determination difficult. Therefore, this idea for removing the negative impact of contrast enhancement is unacceptable. Huang et al. [34] designed a novel key-point generation pattern for eliminating the negative effect of contrast enhancement, which accounts for the physiological characteristics of dorsal hand compared with the existing key-point detectors. Thus, this model improves the matching performance of feature representation.

C. Vein Recognition Methods Based on Deep Feature
Recently, DCNN model has been demonstrated to have the advantage on image recognition tasks compared with handcrafted feature, but the performance of feature representation of DCNN depends heavily on the number of training samples. Therefore, it is difficult to obtain the potential feature representation ability of DCNN for vein recognition due to the lack of training database in vein recognition fields. To solve this problem, many researchers mainly concentrate on the study of two aspects such as training strategy and task-specific network architecture. For example, Wang et al. [10] proposed a coarse-to-fine transfer strategy to obtain a more discriminative DCNN model for vein recognition, which successfully applied DCNN to vein recognition tasks and achieved acceptable performance. Fang et al. [11] designed a two-channel CNN for finger vein recognition and trained network architecture by a pair of finger vein images. Wang et al. [35] proposed a hierarchical generative adversarial network which consists of a constrained DCNN and a CycleGAN to generate vein samples for better training a DCNN model for vein recognition tasks. The training strategy of this model effectively increases the size of training samples and address the issue of over-fitting caused by the lack of training dataset. Wang and Wang [12] proposed a novel vein recognition model based on a structure growing guided DCNN model, which also improves the performance of vein recognition. Zhong et al. [36] presented a multi-biometric algorithm based on deep hashing network, and this network can obtain more discriminative feature representation and reduce the consumption of multi-biometric recognition systems. In addition, Genovese et al. [37] introduced a PalmNet for palmprint recognition, which is a novel CNN that uses a newly developed method to tune palmprint-specific filters through an unsupervised procedure based on Gabor responses and principal component analysis, and this network can extract highly discriminative palmprint-specific descriptors. However, in the above mentioned vein recognition models based on DCNN, some models need complex training processes and some models need to further improve the feature representation ability of networks for vein images. Therefore, there are still great difficulties in designing a simple and feasible vein recognition models based on deep feature. To utilize the discriminative feature descriptor capacity of DCNN for vein recognition, Wang et al [38] designed a spatial pyramid pooling of selective convolutional features model, which is different from the existing vein recognition models based on deep feature. This model adopted the convolutional features with spatial information as image representation, and proposed a weight scheme to weigh the importance of each local feature descriptor from convolutional features. However, the background information of convolutional features is not effectively removed which degrades the performance of this model. Therefore, in this paper, a multi-scale deep representation aggregation (MSDRA) is proposed to acquire more discriminative and competitive feature representation for vein recognition. In our proposed MSDRA model, a local mean threshold method is utilized to preliminarily eliminate the noisy information of multi-scale feature maps, and then an Unsupervised Vein Information Mining (UVIM) model is designed to discard noisy information of selected feature maps and keep discriminative deep representation. To our knowledge, this is the first model to remove the noisy information in the feature maps by designing a coarse-to-fine background information removal algorithm based on the specific trait of vein images.

SECTION III.Vein Information Mask Guided Multi-Scale Deep Presentation Aggregation Model
A. The Selected Feature Maps Generation
Currently, the activation of full-connected layer or convolutional layer is generally adopted as image representation for classification. Relative to the activation of full-connected layer, convolutional activation contains more spatial information and semantic information. However, it also covers more background information. Besides, some studies [39], [40] have also indicated that directly adopting the convolutional activation as image representation cannot obtain satisfactory results. Therefore, to effectively utilize the spatial information and semantic information of convolutional activation, Wei et al. [15] used a mask generated by the proposed global mean threshold to discard background information of convolutional activation and keep useful deep descriptors, which obtains the start-of-the-art result in the fine-grained image retrieval. Thus, based on such findings, the feature maps of the convolutional layer are adopted as basic vein representation in this paper. Besides, in a pre-trained DCNN, different convolutional layers can encode different-level feature information, high-level convolutional features contain more semantic information and low-level convolutional features contain more detailed information [40]. Therefore, in our model, we adopt the convolutional features of conv5_1 and pool5 layers as the feature maps due to the fact that the feature maps of multi-scale include more useful vein information. In Section IV, the selection of multi-scale feature maps is discussed.

To better analyze the specific trait of the convolutional features of vein images, we randomly select two vein images from hand-dorsa vein database and visualize the feature maps of conv5_1 and pool5 layers. The visualization results are shown in Fig. 2. It can be concluded from Fig. 2 that the activated regions in the feature maps are scattered and correspond to the vein and background regions of input vein images, that the stronger parts of strong responses in the feature maps generally correspond to vein regions (as shown in the ‘red circle 1’ of Fig. 2) and the stronger parts of weak responses in the feature maps also generally correspond to vein regions (as shown in the ‘red circle 2’ of Fig. 2), and that the small number of the stronger parts of strong responses also correspond to background regions (as shown in the ‘red circle 3’ of Fig. 2) and the small number of the stronger parts of weak responses also correspond to background regions (as shown in the ‘red circle 4’ of Fig. 2). If we want to obtain more discriminative deep representation for vein recognition, it should remove the background information of feature maps which is generated in the weaker parts of strong responses, the weaker parts of weak responses, the few stronger parts of strong responses and the few stronger parts of weak responses. Therefore, to address the problem, a novel local mean threshold is proposed to firstly eliminate the background information of the multi-scale feature maps from the weaker parts of strong responses and the weaker parts of weak responses. Then, a UVIM model based on frequency pattern is designed to finally remove the few background information of selected feature maps from the stronger parts of strong responses and the stronger parts of weak responses.


Fig. 2.
The visualization results of feature maps from Conv5_1 and Pool5 layers.

Show All

Given the feature maps of conv5_1 and pool5 layers S∈R2H×∼2W×∼C,X∈RH×∼W×∼C . Due to the fact that the size of the feature maps in the conv5_1 layer is different from the size of the feature maps in the pool5 layer, we perform a sum pooling of 2×2 on the feature maps of conv5_1 layer to acquire the same size with the feature maps of pool5 layer. The selected feature maps X′ are obtained by conducting a 3×3 of local mean threshold on the multi-scale feature maps. In the neighborhood of 3×3 , the local mean threshold operation can be represented as follows:
X′3×3(x,y)={M3×3(x,y)0if M3×3(x,y)≥Tmeanelse(1)
View Sourcewhere M3×3 is the neighborhood of 3×3 in one multi-scale feature map, X′ is the neighborhood of 3×3 in one selected feature map and Tmean is the mean value of the neighborhood of 3×3 in one multi-scale feature maps.

To verify the performance of the proposed local mean threshold in removing the background information of multi-scale feature maps from the weaker parts of strong responses and the weaker parts of weak responses, we randomly select two vein images on hand-dorsa vein database and visualize the selected feature maps. The visualization results of selected feature maps are shown in Fig. 3. It can be clearly seen that the background information of multi-scale feature maps from the weaker parts of strong responses and the weaker parts of weak responses are effectively eliminated by the proposed local mean threshold approach compared with the original multi-scale feature maps, which also demonstrates the effectiveness of the proposed method. Besides, comparison experiments conducted on two vein databases are designed to further evaluate the performance of the local mean threshold method in section IV. However, few background information of multi-scale feature maps corresponding to the stronger parts of strong responses (as shown in the ‘red circle 1’ of Fig. 3) and the stronger parts of weak responses (as shown in the ‘red circle 2’ of Fig. 3) cannot be removed and is retained in selected feature maps. Thus, to deal with the issue, we proposed a novel Unsupervised Vein Information Mining (UVIM) based on frequency patterns to discard the noisy information of selected feature maps and keep the useful vein regions of selected feature maps.

Fig. 3. - The visualization results of selected feature maps.
Fig. 3.
The visualization results of selected feature maps.

Show All

B. Unsupervised Vein Information Mining
After obtaining the selected feature maps, we need to create a set of transaction databases for later vein information mining. In our model, each selected feature map is regarded as a transaction named as T and each position index activated from the selected feature maps is served as an item f . Besides, the set of all transactions is defined as D={T1,T2,T3…,T2C} . Due to the fact that the distribution of vein information is scattered, all positions from selected feature maps are activated. Thus, {1,2,…,i,…,H×W} is the index set of all activated positions. For example, if there are three positions (1, 8 and 37) activated in the j-th selected feature maps, the corresponding transactions Tj={f1,f8,f37} . Given a set of transaction database D, the Apriori algorithm [41] is utilized to calculate the frequency of each item by the following operation:
supp(f)=|{T|T∈D,f∈T}|2C∈[0,1](2)
View Sourcewhere |.| measures the cardinality, the itemset f whose supp(f) is the first k is considered as the frequency itemset, and the 2C is the number of transactions. In each selected feature map, the activation of the position is retained when its item is included in the frequency itemset. After mining the useful vein regions of selected feature maps, we merge all mined feature maps X′′ to generate vein information mask (VIM) by the operation:
VIM(x,y)={10if ∃X′′j, fi∈X′′j, j∈[1,2C]esle(3)
View SourceRight-click on figure for MathML and additional features.where fi is frequency itemset whose frequency is the first k in frequencies of all items, and (x, y) is the position of fi . The whole procedure of the vein information mining is summarized as follows: First, the selected feature maps are converted into a set of transaction database D. Second, the frequency of each item are calculated and the items whose supp(f) is the first k are remained to generate the frequency itemset. Fourth, the useful vein regions in each selected feature map are discovered based on frequency patterns. Finally, we merge all mined feature maps to generate the Vein Information Mask (VIM). The detailed procedure of our proposed UVIM model is shown in Fig. 4.

Fig. 4. - The detailed procedure of the designed UVIM method.
Fig. 4.
The detailed procedure of the designed UVIM method.

Show All

To evaluate the performance of the proposed UVIM model in localizing vein information of feature maps, we design a visualization experiment. Meanwhile, the popular unsupervised localization approaches [15], [42] are considered as comparison results to verify the effectiveness of our proposed UVIM. The visualization results of localization maps generated by different unsupervised localization methods are shown in Fig. 5. As can be seen from Fig. 5, the localization vein information masks generated by two representative unsupervised localization models lose a lot of vein information, and the proposed UVIM extremely removes background information of vein images while localizing all vein information of input vein images. Therefore, utilizing the VIM to aggregate multi-scale feature maps can acquire more discriminative deep representation for vein recognition.


Fig. 5.
The visualization results of localization masks of vein information generated by different unsupervised localization methods.

Show All

C. Deep Representation Aggregation Based on Vein Information Mask
In this section, we utilize the obtained VIM to aggregate multi-scale feature maps because multi-scale convolutional features contain more useful vein information. Given the multi-scale feature maps M∈RH×W×2C , the multi-scale deep convolutional features F can be represented as:
F=VIM.∗M(4)
View SourceRight-click on figure for MathML and additional features.where.* demotes element-wise multiplication. It should be noted that the final compact feature vectors are obtained by concatenating the multi-scale deep convolutional features.

The whole process of the proposed MSDRA model for vein recognition is illustrated in Algorithm 1.

Algorithm 1 The Whole Process of the Proposed MSDRA
An input vein image I (224×224 )

A pre-trained DCNN model (VGG-16)

Extract multi-scale feature maps (conv5_1, pool5) of input vein image I(S∈R2H×2W×C,X∈RH×W×C) using the pre-trained DCNN model.

Convert the selected feature maps which are generated by applying the designed local mean threshold on the original feature maps into a set of transactions.

Calculate the frequencies of each item and retain the items whose frequency is the first k.

Mine useful vein regions of the selected feature maps based on frequency patterns.

Merge all mined feature maps to generate Vein Information Mas (VIM).

Aggregate the multi-scale feature maps using the VIM by the operation F=VIM.∗M .

Concatenate the multi-scale deep convolutional features F to form the final feature representation F′ which is a 7×7×1024 -d feature vector.

SECTION IV.Experiment and Discussion
A. Database
In this paper, extensive experiments are designed to evaluate the effectiveness of our proposed MSDRA for vein recognition tasks on two benchmark vein databases including hand-dorsa vein database [43] and PUT palm vein database [44]. Moreover, to verify the generalizability and robustness of our proposed MSDRA, we also carry out an additional experiment on PolyU Multispectral Palmprint database [45]. The detailed situation of three databases are illustrated as follows:

Hand-dorsa vein database, which is captured by a self-designed image capturing device referenced from our previous work [46], contains 200×10 images deriving from the hand-dorsa vein information of 200 individuals. All hand-dorsa vein images are collected in two sessions and the time interval of two sessions is more than 10 days. The ROI extraction [47] process specifically designed for this database is conducted followed by the gray and size normalization. Note that the size of vein ROI images is 181×181 and resized to 224×224 by using “imresize” operation of MATLAB in our experiment. Besides, the training dataset contains 200*5 hand-dorsa vein images, and the test database contains 200*5 hand-dorsa vein images.

PUT Palm Vein database, which consists of 1200 palm vein images, is captured by 100 palms and 12 images are acquired for each palm in three sessions. In our experiments, palm vein images from session 1 and session 2 are regarded as training samples, and the palm vein images of session 3 are adopted as test samples.

PolyU Multispectral Palmprint Database, which contains 6000 images, is acquired by 500 palms in two sessions and 6 images are captured in each session. In the experiment of generalizability evaluation, the palmprint images of the first session are used as training dataset and the palmprint images of the second session are utilized as test dataset. It should be noted that PolyU Multispectral Palmprint database (near-infrared part) is utilized to verify the generation ability of the proposed model.

Some samples of three benchmark databases including hand-dorsa vein dataset, palm vein dataset and palmprint dataset are as shown in Fig. 6.


Fig. 6.
Some samples of three databases. (a) Hand-Dorsa Vein Database (b) PUT Palm Vein Database (c) PolyU Palmprint Database.

Show All

B. Experiment Details
In our experiments, VGG-16 model [48] from ImageNet is adopted as a pre-trained DCNN model to extract multi-scale feature maps of input vein images, and the size of input vein ROI images is 224×224 . Thus, the size of X is 7×7×512 and the size of S is 14×14×512 . It should be noted that the value of k is set to 40 in our experiments, and the selection of k parameter is discussed in the next section. The final deep feature representation which is a 7×7×1024 -d feature vector is obtained by concatenating the multi-scale deep representation. To speed up the training process of SVM, PCA is employed to reduce the dimension of the final feature vector. In our experiment, the vein feature representation which is a 90-d feature vector is regarded as the input data to train SVM. Note that the radial basis function is regarded as the kernel function of SVM, the penalty parameter C of SVM is set as 128 and the gamma is set as 0.0078.

C. Baseline Parameter Setup for Our Proposed Model
In this section, four experiments are designed on two vein databases to discuss the selection of feature maps, pooling types and k parameter as well as the performance of each part of our proposed MSDR model. In the four experiments, the recognition rate is regarded as the evaluation metric.

1) The Selection of Multi-Scale Feature Maps:
In this experiment, we select six different ways of multi-scale convolutional layers. Besides, the single feature maps (Pool5 and Conv5_3) are adopted as convolutional activations for evaluating the advantage of multi-scale feature maps. Due to the fact that the size of feature maps from Conv3 layer is too large, it can increase the time consumption of our proposed MSDRA model. Therefore, we do not select the feature maps of Conv3 layer as multi-scale feature maps. The recognition rates of different ways of multi-scale feature maps are shown in Table II. It should be noted that the 2*2 of sum pooling is utilized to reduce the size of the low convolutional layers as well as the local mean threshold and UVIM are utilized to remove the background information of multi-scale feature maps. It can be seen from Table II that the model that the feature maps of Conv5_1 and Pool5 layers are adopted as multi-scale feature maps achieves the best performance compared with other different ways of multi-scale feature maps and single feature maps. Therefore, the multi-scale feature maps from Conv5_1 and Pool5 layers are adopted as convolutional activations in the later experiments.

TABLE II The Recognition Results of Different Ways of Multi-Scale Feature Maps

2) The Selection of Pooling Type:
In this section, we discuss the impact of different kinds of pooling types such as sum pooing, average pooling and max pooling for the designed vein recognition model. In this experiment, we adopt the feature maps from Conv5_1 and Pool5 layers as convolutional activations, and utilize the designed local mean threshold and UVIM approaches to eliminate the noisy background information of multi-scale feature maps and keep the useful deep representation with vein information for final classification. The performance of our proposed MSDRA model based on different kinds of pooling types is illustrated in Table III. As can be seen from Table III, the recognition rate of our proposed MSDRA with sum pooling is better than that of our proposed MSDRA with average pooling and max pooling. The sum pooling is regarded as the default choice for reducing the size of feature maps of the low convolutional layer in the multi-scale feature maps.

TABLE III The Performance of Our Proposed MSDRA Model Based on Different Kinds of Pooling Type

3) The Selection of k Parameter:
In this section, we discuss the impact of the selection of k parameter for the effectiveness of our MSDRA. The experimental results conducted on hand-dorsa vein database and palm vein database are shown in Fig. 7. It can be observed from Fig. 7 that as the number of parameter k increases, the recognition rate achieved by the proposed model first increases and then decreases. When the parameter k equals 40, our designed MADRA achieves the best result. Therefore, the parameter k is set to 40 in our experiments.


Fig. 7.
The recognition results of our MSDRA with different values of k parameter.

Show All

4) The Evaluation of Each Part of Our Proposed MSDRA:
To comprehensively evaluate the effectiveness of our proposed MSDRA, we design an experiment to verify the performance of each part including local mean threshold and Unsupervised Vein information Mining (UVIM). The experimental results are shown in Table IV. It can be concluded that local mean threshold and UVIM can improve the performance of the model, and the improvement of UVIM on the model is greater than that of the local mean threshold, which also demonstrates the effectiveness of local mean threshold and UVIM for discarding the background information of original multi-scale feature maps.

TABLE IV The Performance of Each Part of Our Proposed MSDRA Model
Table IV- 
The Performance of Each Part of Our Proposed MSDRA Model
D. Comparison With State-of-the-Art Models
In this part, extensive matching experiments are designed on two vein databases to verify the advantage of the proposed MSDRA model for vein recognition over three representative state-of-the-art feature extraction algorithms including shape feature-based methods, texture feature-based methods and deep feature-based methods. The genuine matching and imposter matching are conducted with the trained SVM for calculating false non-match rate (FNMR) and false match rate (FMR) on two vein databases, with which we can obtain the EER results of two vein databases.

1) Comparison With Vein Recognition Methods Based on Shape Feature:
Vein recognition models based on shape feature mainly obtain the shape information of vein images in two ways including mathematical methods and vein segmentation methods. Therefore, the four vein models respectively based on mathematical methods [16], [17] and vein segmentation methods [20], [21] are selected as comparison experiments for evaluating the superiority of our proposed MSDRA model. The EER results, FNMR results (FMR = 0.1%) and DET curves of different vein models on two vein databases are shown in Table V and Fig. 8. It can be clearly seen from Table V and Fig. 8 that the performance of our proposed MSDRA is better than that of four vein recognition models based on shape information, which also demonstrates its advantage for vein recognition tasks.

TABLE V The EER Results (%) and FNMR Results (FMR = 0.1%) of Four Vein Recognition Models Based on Shape Feature


Fig. 8.
The DET curves of shape feature-based vein recognition models on two vein databases.

Show All

2) Comparison With Vein Recognition Methods Based on Texture Feature:
Vein recognition methods based on texture feature consist of two representative algorithms such as LBP and its variants as well as SIFT and its variants. The former mainly contains LBP [7], LDP [23], LTP [24], and LLBP [25], and such models are widely employed to vein recognition tasks due to its efficiency, which also provides acceptable recognition rates. The latter mainly includes SIFT [6], SURF [26], RootSIFT [27], ASIFT [28], which has the advantages of being invariant to rotation, translation, scale uncertainty and even uniform illumination, which makes it become one of the best feature representation algorithms among all the hand-crafted feature extraction models. The EER results, FNMR results (FMR = 0.1%) and DET curves of vein recognition models based on texture feature on two vein databases are shown in Table VI and Fig. 9. As can be observed from Table VI and Fig. 9, the best EER results of SIFT and its variants are respectively 0.877% and 1.749% on two vein databases which are achieved by ASIFT model as well as the best EER results of LBP and its variants are respectively 0.928% and 2.037% on two vein databases which are generated by LDP model. Our proposed MSDRA model respectively achieves the EER results with 0.036% and 0.791% on two vein databases, and the performance is better than that of ASIFT and LDP, which also verifies the superiority of our proposed MSDRA.

TABLE VI The EER Results (%) and FNMR Results (FMR = 0.1%) of Vein Recognition Models Based on Texture Feature


Fig. 9.
The DET curves of texture feature-based vein recognition models on two vein databases.

Show All

3) Comparison With Vein Recognition Methods Based on Deep Feature:
In this experiment, we firstly select two vein recognition models based on deep feature which contain a structure growing guided DCNN model for hand-dorsa vein recognition [12] and CNN model for finger vein recognition [49] as comparison experiments to evaluate the advantage of our proposed MSDRA for vein recognition tasks, and then two representative image recognition models based on a pre-trained DCNN including CL [14] and SCDA [15] are also adopted as comparison algorithms to comprehensively verify the superiority of our proposed MSDRA for obtaining more discriminative deep representation. The EER results, FNMR results (FMR = 0.1%) and DET curves of four models on two vein databases are shown in Table VII and Fig. 10. It can be concluded from Table VII and Fig. 10 that our proposed MSDRA achieves the best EER result compared with the first two methods based on end-to-end CNN model, which also indicates its effectiveness for vein recognition. Besides, the EER result achieved by our proposed MSDRA is far better than the EER results obtained by the last two methods based on a pre-trained DCNN model, which evidences the superiority of our proposed UVIM model for localizing the vein information of feature maps.

TABLE VII The EER Results (%) and FNMR Results (FMR = 0.1 %) of Four Vein Recognition Models Based on Deep Feature


Fig. 10.
The DET curves of deep feature-based vein recognition models on two vein databases.

Show All

E. The Evaluation of Time Consumption
Time consumption has an essential influence on the performance of vein recognition systems in the real environment. Generally, identity verification systems based on vein information should not only have higher recognition result but also possess lower time consumption. Sometimes, the recognition rate of vein recognition systems may be appropriately reduced to optimize the time cost of the system. The cost time of each part of the proposed MSDRA model which includes the extraction of multi-scale feature maps, local mean threshold, UVIM and final classification is evaluated on hand-dorsa vein database. The evaluation experiment of time consumption is conducted by MATLAB 2017a on a PC with Core i5-8265U, CPU 3.30GHz and 8.00GB memory. The average time consumption of each image is shown in Table VIII. It can be observed from Table VIII that the time cost of the proposed MSDRA method is extremely small on hand-dorsa vein database, which demonstrates the fact that the proposed model can better meet the demand of identity recognition systems based on vein information for time consumption.

TABLE VIII The Average Time Consumption of Each Link of Our Proposed Model

F. Generalizability Evaluation of the Proposed Model
In this paper, we present a novel Multi-Scale Deep Representation Aggregation (MSDRA) for vein recognition. The model adopts a pre-trained VGG16 which is trained on ImageNet as a feature extractor, therefore, which makes it have high generalization ability and robustness. To comprehensively verify the generalization capacity of our proposed MSDRA, we design an additional experiment on PloyU Multispectral Palmprint database (near-infrared part). In our experiments, the genuine matching and imposter matching are conducted with the trained SVM for acquiring EER result. The experiments results derived from recently published methods on PolyU Multispectral Palmprint Database are shown in Table IX. It can be observed from Table IX that the proposed model could achieve state-of- the-art EER level compared with other methods, which effectively evidences its high generalization ability and robustness.

TABLE IX Summary of EER Results Derived From Recently Published Vein Recognition Models Using PolyU Palmprint Database
Table IX- 
Summary of EER Results Derived From Recently Published Vein Recognition Models Using PolyU Palmprint Database
SECTION V.Conclusion
In this paper, a novel Multi-Scale Deep Representation Aggregation (MSDRA) is proposed to enhance the feature representation ability of a pre-trained DCNN for hand-dorsa vein recognition. First, multi-scale feature maps of input vein images from a pre-trained DCNN model (VGG-16 model) are adopted as convolutional activations for obtaining richer deep representation. Second, the designed local mean threshold method is applied to firstly remove the background information of original multi-scale feature maps. Third, a novel Unsupervised Vein Information Mining (UVIM) is proposed to finally eliminate non-vein information and generate a binary Vein Information Mask (VIM), and then the VIM is used to aggregate multi-scale feature maps for obtaining the more discriminative multi-scale deep representation. Finally, the discriminative multi-scale deep representations are concatenated into the final compact feature vectors for final classification. The outstanding recognition results of extensive comparison experiments on three benchmark databases demonstrate the effectiveness and robustness of the proposed MSDRA model for vein recognition systems.

We also argue that the proposed MSDRA model is also applicable to other computer vision tasks. In the future, we will try to design a vein segmentation model based on a pre-trained DCNN.