Conventional intrusion detection systems based on supervised learning techniques require a large number of samples for training, while in some scenarios, such as zero-day attacks, security agencies can only intercept a limited number of shots of malicious samples. Therefore, there is a need for few-shot detection. In this paper, a detection method based on a meta-learning framework is proposed for this purpose. The proposed method can be used to distinguish and compare a pair of network traffic samples as a basic task of learning, including a normal unaffected sample and a malicious one. To accomplish this task, we design a deep neural network (DNN) named FC-Net, which mainly comprises two parts: feature extraction network and comparison network. FC-Net learns a pair of feature maps for classification from a pair of network traffic samples, then compares the obtained feature maps, and finally determines whether the pair of samples belongs to the same type. To evaluate the proposed detection method, we construct two datasets for few-shot network intrusion detection based on real network traffic data sources, using a specifically developed approach. The experimental results indicate that the proposed detection method is universal and is not limited to specific datasets or attack types. Training and testing on the same datasets demonstrate that the proposed method can achieve the average detection rate up to 98.88%. The outcome of training on one dataset and testing on the other one confirms that the proposed method can achieve better performance. In a few-shot scenario, malicious samples in an untrained dataset can be detected successfully, and the average detection rate is up to 99.62%.

SECTION I.Introduction
With the increasing popularity of the Internet in modern life, a larger number of devices have become interoperable through networks, and the security of cyberspace has attracted greater attention. Intrusion detection systems (IDSs) are used to detect various malicious attacks on a network effectively and are one of the most critical systems for maintaining cyberspace security [1]. From the perspective of machine learning (ML), an IDS can be defined as a system aimed to classify network traffic. A simple model is a binary classification one, which is used to distinguish between the normal and malicious network traffic, thereby enabling the detection of intrusion traffic. With recent advances in research focused on ML, many studies have shown that it is possible to design ML algorithms with the purpose of implementing IDSs. These algorithms are generally no longer based on rules and are aimed to exploit various features of network traffic. They comprise two main steps: feature extraction and classification. For example, in the research work [2], a method of encoding the payload was proposed based on recursive feature addition (RFA) and bigram, and then was utilized to detect intrusions. The experimental results on the ISCX2012 dataset demonstrated that the detection rate could reach 89.60%. In the study [3], a system called HAST-IDS was proposed using a convolutional neural network (CNN) to extract spatial features and a recurrent neural network (RNN) to extract temporal features from network traffic. This system achieved the detection rate of 96.96% on the ISCX2012 dataset. In the research work [4], a system named TR-IDS was developed to combine statistical features with the ones extracted by text CNN. It reached the detection rate of 99.26% on the ISCX2012 dataset. In general, various models have been proposed in the existing researches, including autoencoders [5], long short-term memory (LSTM) [6], genetic algorithm [7], restricted Boltzmann machine [8], Earth mover distance (EMD) [9], wavelet analysis [10], and other models that can be applied to develop IDSs. Concerning the datasets used for testing, in addition to ISCX2012, the new CICIDS2017 dataset was also used to systematically evaluate the efficiency of detecting the most recent types of network attacks [11]–[12][13].

The aforementioned works demonstrate that for a specific type of attack, as long as there is a large number of samples, many ML algorithms can perform appropriately, and detection can be completely automated, no longer requiring excessive manual intervention. It can be outlined that IDSs based on ML can detect new attacks as long as the number of samples for training is sufficient. However, at present, the cyberspace environment is constantly changing, and new types of attacks occur constantly. For example, the zero-day attack [14] is an attack launched on the day when a vulnerability is discovered. It is difficult for security agencies to obtain sufficient attack samples in a short period, and as a result, it may be too late to compose a dataset and publish it. Detection based on only a limited number of attack sample shots is considered as a few-shot intrusion detection problem. In recent years, few-shot learning has achieved considerable progress [15]–[16][17][18][19]. Several algorithms have utilized the concept of meta-learning [20], [21] to address the few-shot learning problem. However, to the best of our knowledge, there is currently no effective method introduced for few-shot detection specifically to address network intrusion detection.

Concerning human involvement in network intrusion detection, we can rely on two ideas of the human learning process. First, there is no need for a large number of labeled samples. Usually, tens to hundreds of samples are sufficient for humans to learn how to distinguish between different types of network traffic. It is worth noting that in the case when cybersecurity experts learn to identify a new type of network traffic, only a limited number or even a single sample can be sufficient. This is because humans can spontaneously identify features to distinguish between different types of network traffic. Experts can also rely on a considerable amount of prior domain knowledge to identify new types of network traffic. Second, classification knowledge corresponding to network traffic learned by humans is more “universal.” For example, traffic classification knowledge related to a certain attack learned on a local area network (LAN) can also be applied to classify the other type of attacks on the wide area network (WAN). These two peculiarities of humans are beneficial in the field of network intrusion detection. However, the variety of emerging network attacks is expanding constantly, and therefore, it is difficult to generalize the existing supervised learning algorithms aiming to identify unknown intrusion traffic. Computer networks have become widely implemented in modern daily life, and therefore, it is impractical to design a corresponding intrusion detection model for each type of network and attack that may occur. To address this issue, in this paper, we propose a detection method relying the concept of meta-learning, which can be utilized to detect intrusions requiring only a small number of samples.

The main contributions of this paper are as follows:

We proposed a few-shot network intrusion detection method based on a meta-learning framework. This method can be used to learn prior knowledge for network traffic classification directly from original traffic. After obtaining sufficient prior knowledge, new types of traffic can be detected with a few-shot of samples.

We proposed a method to construct datasets to perform training corresponding to few-shot network intrusion detection based on real network traffic. Using this method, we constructed two datasets incorporating the data public network traffic data sources and conducted two types of experiments on these datasets.

We demonstrated that the proposed network intrusion detection method is universal and is not limited to specific attack types. Using the proposed method, new types of samples on the basis of only a limited number of labels in an untrained dataset can be detected relying on learned prior knowledge.

SECTION II.Problem Formulation
In conventional ML approaches, an algorithm is usually focused on a specific task T . In the field of network intrusion detection, a basic task is to use a classifier to determine labels for network traffic samples. That is, we have K samples and labels denoted as follows: D={(x1,y1),(x2,y2),⋯(xi,yi)⋯(xK,yK)},xi∈Rd,yi∈{0,1} . The main goal is to construct a classifier model f in which sample xi is used as the input, and an estimated value of corresponding label yi is the output. In the general supervised learning scenario, the number of samples K is large, and all samples are simply divided into two parts: a training set D(train) and a test set D(test) . When the number of samples K is small, this case can be regarded as a few-shot learning problem, and the condition supervised learning method applied to this problem will encounter overfitting. To address this deficiency, we introduce a meta-learning method, and accordingly, the proposed algorithm is no longer focused on a specific task but serves to formulate a meta-task model F . It is done by learning from tasks in the task set T={TA,TB,TC⋯} to estimate the ability of accomplishing a new task TN . Fig. 1 represents a meta-learning example of binary classification, and the classification types corresponding to task N differ from the types in the previous N−1 tasks. That is, meta-learning can be used to implement transfer learning through the “learn-to-learn” approach.


Fig. 1.
Meta-learning example of binary classification.

Show All

In the field of network intrusion detection, we define a specific task Ti as a binary classification task that distinguishes between normal samples and a certain type of malicious samples, and classification types corresponding to different tasks can vary. Let us consider a simplified scenario in which there are five types of network traffic samples, denoted as O, A, B, C, and D. O represents normal samples and is usually easy to acquire. Then, A, B, C, and D are the four different types of malicious samples. Among them, A, B, and C correspond to the known types in the dataset and have a sufficient number of labeled samples. In its turn, D is a new type of malicious samples, with only K samples available. The main goal is to accomplish the ultimate task Td by learning K malicious samples of type D and K normal samples of type O to obtain classifier model fd . Then, the unknown samples can be classified accordingly, and the malicious samples of type D can be detected. In this task, 2K samples can constitute a support set denoted as Su={(x1,y1),(x2,y2),⋯,(x2K,y2K)} , where xi∈Rd , and yi∈{O,D} . The samples to be classified constitute a test set. As K is small, having only 2K samples is obviously insufficient to accomplish task Td . Nevertheless, the three other types of malicious samples can be obtained, and accordingly, tasks Ta , Tb , and Tc with the same structure of Td can be constructed. Let us consider Ta as an example: K malicious samples of type A and K normal samples of type O can constitute a sample set denoted as Sa={(x1,y1),(x2,y2),⋯,(x2K,y2K)} , where xi∈Rd , and yi∈{O,A} . The samples for classification that have the labels to be verified constitute a query set. Here, the sample and query sets are utilized to simulate the support and test sets in the ultimate task Td , respectively. The difference is that the sample and query sets are sampled from the labeled dataset, that is, we can construct a task set T(train) , which contains a large number of tasks, such as Ta , Tb , and Tc . Similarly, a task set T(test) contains the tasks such as Td and is used as a set of tasks for testing. From the perspective of meta-learning, T(train) and T(test) are the training and test sets in the meta task model F . Therefore, T(train) and T(test) can be denoted as the meta-training and meta-testing sets, respectively. Fig. 2 represents a schematic depicting the division of datasets in meta-learning.

Fig. 2. - Schematic of the division of datasets in meta-learning.
Fig. 2.
Schematic of the division of datasets in meta-learning.

Show All

SECTION III.Network Traffic Representation
A. Packet and Data Flow
In the previous section, each sample of network traffic is represented by a d− dimensional real vector; however, the real situation is more complicated. According to the Open System Interconnection (OSI) reference model [22], a network model can be divided into seven layers from bottom to top. Except the first layer (physical layer) that is not visible at the software level, the layers starting from layer two and above are reflected in the network traffic data. The minimum transmission unit of network traffic is a packet, and each packet includes one or more headers and a payload. For example, a hypertext transfer protocol (HTTP) packet contains a 14-byte media access control (MAC) layer header, a 20-byte internet protocol (IP) layer header, a 20-byte transmission control protocol (TCP) layer header, an HTTP header of a non-fixed length, and a payload. Conventional IDSs can be applied to extract a variety of features from these headers. For example, CICFlowMeter [23] can extract more than 80 network traffic features. There are two major drawbacks associated with the methods implying features extraction from packet headers based on fixed rules. The one deficiency is to use only the information stored in headers and ignore the payload. Moreover, the adaptability of such methods to different protocols is limited. For instance, the rules of extracting features from the file transfer protocol (FTP) header cannot be used for the HTTP header. The other drawback is that if a single packet is considered as a detection object, the correlation between packets is ignored. In fact, even if establishing a simplest TCP connection relies on a three-way handshake, multiple packets will be generated, which are related to each other and can be regarded as a whole. A data flow is a collection of multiple associated packets [24] that have the same quintuple: [source IP, destination IP, source port, destination port, protocol]. In this study, the data flow is considered as a detection object. To reduce the computational complexity, the following three rules are applied to sample the data flows:

The first M packets in a data flow are used to represent it as a whole, as the length of a data flow is not fixed. Generally, a data flow is defined as a collection of several packets arranged in chronological order. The packets initially transmitted in a data flow contain the most pronounced features. If M takes an appropriate value, it can usually include the process of connection establishment. The subsequently abandoned packets are considered as only the continuation of content transmission, with fewer additional features.

The first N bytes of a packet are used to represent it as a whole, as the length of a packet is not fixed. Upon taking an appropriate value N , the headers of a packet can be completely included, and even a part of the payload data can be incorporated. To facilitate the convenience of processing, N is set as a square number.

If the length of a data flow or a packet is less than the truncated value mentioned above (M or N ), the empty bytes will be filled with zeros.

A data flow is sampled according to the above rules so that its main time and spatial structures are kept unchanged. This allows reducing the amount of data and unifying the data size, thereby laying a theoretical foundation for subsequent neural network processing.

B. Visualization
In the statistical analysis method with manual intervention, network packets can be viewed using specialized software tools, such as Wireshark [25]. This kind of software tools is used to check the meaning of each byte in a packet in detail, specifically, the features contained in headers. However, this kind of feature representation is convenient for people to examine, not for computers, and can only be viewed packet by packet, which is inefficient. Therefore, there is a need to ensure that there are statistical differences between different types of network traffic so that it can be classified. Essentially, the network traffic processed in a computer can be regarded as a time series, and accordingly, this series can be overlaid in the space and time and visualized as an image. In a sample, as N is a square number, the first N bytes of each packet can be arranged into a matrix of N−−√×N−−√ , and each element in this matrix has 256 possible values, corresponding to 256 gray scales, and the gray scale image can be obtained. The data flow composed of the first M data packets is arranged in chronological order, and there are a total of M grayscale images. For the convenience of observation, three adjacent grayscale images are represented as the R, G, and B channels of a color image so that a 24-bit color image can be constructed. By setting M=9 , and N=64 , a visual representation of a network data flow can be obtained, as shown in Fig. 3.


Fig. 3.
Visual representation of a network data flow.

Show All

An advantage of visual representation is that it can be used to efficiently observe the overall situation corresponding to network traffic. In the development of end-to-end ML algorithms, the focus is emphasized on the overall trend of data rather than on a single sample. Here, four types of network data flows are selected, each of them comprising 3,000 samples. In each sample, M=9 , and N=64 . Then, the average of their visual representation is obtained, as shown in Fig. 4. Only twelve color grids are utilized to visually display the overall view over 3000×9×4=108000 packets, as shown in Fig. 4. Through visual comparison, we find that the four types of data flows are still different after sampling, which provides a foundation for classification.


Fig. 4.
Visual representation of four types of data flows (M=9;N=64 ; an average of 3,000 samples).

Show All

SECTION IV.Few-Shot Network Intrusion Detection
A. Meta-Learning Framework
It is known that network traffic can be regarded as a time series of a signal. In the field of time series analysis, recurrent neural networks (RNN) have been proved to achieve acceptable detection results [26]. In the present study, we aim to distinguish between different types of network traffic. Concerning classification problems, convolutional neural networks (CNN) have a good performance [27]. Several research works have combined the features of the time and spatial dimensions [3], that is, introducing the mixed use of RNN and CNN. It has led to the increasing complexity of algorithms with more samples for training required. In the present study, we consider the network traffic classification task from an essential point of view. By constructing a meta-learning framework, a neural network learns how to distinguish between two samples in the training process. That is, the model can learn to identify “differences.” Once a developed algorithm acquires sufficient knowledge about how to find “differences,” even in the case of the few-shot detection tasks, the proposed method can achieve an appropriate performance.

Meta-learning means that a neural network has to deal with tasks that have not been ever considered. Therefore, features should not be extracted manually, but the raw data can be directly inputted into a neural network. The feature extraction network can be used to obtain discrimination features. Knowledge of “difference” has to be acquired through comparison. To implement this step, two samples are inputted into the neural network simultaneously. Therefore, the proposed meta-learning framework is implemented as a deep neural network (DNN) named FC-Net, in which the input is two traffic samples of the target network, and the output is the delta score of the given two samples.

Fig. 5 represents the structure of the proposed detection method. for few-shot network intrusion detection, which contains two parts: the data preparation step and the few-shot detection method based on the meta-learning framework. The data preparation part is applied to compose the datasets for training and testing, including the following two steps:

Packet capture. This step implies capturing various types of raw network traffic in the target network and storing them with appropriate labels.

Datasets construction. Four datasets for meta-learning are constructed based on the captured raw traffic. This step includes data preprocessing and flow reconstruction, and all data are divided into the sample, query, support, and test sets. As shown in Fig. 2, the first two sets are used for meta-training, and the last two ones for meta-testing.

Fig. 5. - Data preparation and the proposed few-shot network intrusion detection method based on the meta-learning framework.
Fig. 5.
Data preparation and the proposed few-shot network intrusion detection method based on the meta-learning framework.

Show All

Then, we implement the few-shot detection part implementing the detection of samples in the constructed datasets through the following three steps:

Feature extraction. Two sets of features are extracted from the two data flows with the same structure.

Comparison. The two sets of features are compared, and the delta score is outputted. The delta score is a real number indicating the difference between the two input data flows.

Classification. In the meta-training phase, each sample in the query set is compared with those in the sample set one by one, and the average delta score is calculated according to different labels in the sample set. Then, in the meta-testing phase, each sample in the test set is compared with those in the support set one by one. The predicted label of a sample in the test set is the one with the minimum average delta score in the support set.

As the meta-testing phase does not necessarily requires a large number of tasks, and the number of samples in the support set can be small, the few-shot detection can be implemented. The implementation is described in detail in the following sections.
In Fig. 2, we represent an example few-shot detection task corresponding to the meta-testing set. Fig. 6 depicts the execution flow of a few-shot detection task. In this task, there are two labels, which correspond to a malicious sample of type D and a normal sample of type O, respectively. There are four samples in the support set, which are divided into two categories, each comprising two samples. There are also two samples of the unknown type that are included in the test set. Considering one of the samples to be tested, this sample is compared with the four samples in the support set using FC-Net. As a result, four delta scores are obtained, which are recorded as DS(1)~DS(4). Here, DS(2) and DS(3) are obtained by comparing with the normal samples labeled with O, and then, their average values are calculated and recorded as DS⟨O⟩ . Similarly, DS(1) and DS(4) are compared with the malicious samples labeled with D, and their average values are calculated and recorded as DS⟨D⟩ . DS⟨O⟩ and DS⟨D⟩ are used to measure the average difference between the two types of samples. Comparing the values of DS⟨O⟩ and DS⟨D⟩ , if DS⟨O⟩ is small, it indicates that the sample to be tested is closer to the normal sample with label O, and therefore the predicted label of the sample to be tested is O, and vice versa.


Fig. 6.
Execution flow of a few-shot detection task.

Show All

B. Architecture of FC-Net
An end-to-end neural network named FC-Net that consists of F-Net (feature extraction network) and C-Net (comparison network) is proposed to implement feature extraction and comparison for the purpose of few-shot detection. The two networks are cascaded, and FC-Net constitutes an end-to-end implementation of the input data flows and the output of the delta score. In the proposed framework, to perform few-shot learning detection, only the features of samples in the test and support sets need to be compared. Each sample in the test set is compared to those in the support set, and the average delta scores generated by different types of network traffic in the support set are used to determine, which type the sample to be tested belongs to. The overall architecture of FC-Net is shown in Fig. 7.


Fig. 7.
The overall architecture of FC-Net.

Show All

By visually analyzing network traffic, a data flow can be formally represented as a set of several color images, which can be used to perform feature extraction by applying a mature image feature extraction network. However, a drawback is that multiple images of data flows are time-related, and this kind of features corresponding to multiple images also constitute a part of features in data flows, which cannot be extracted by utilizing image feature extraction networks. Therefore, F-Net registers a data flow as a three-dimensional tensor rather than a two-dimensional one; that is, a sampled data flow is regarded as a set of multi-channel packets, which are inputted into a neural network in chronological order. In this way, the three-dimensional convolution operation is capable of not only extracting features in the same packet, but also deriving those of across different packets, which are exactly the features in the time dimension. Therefore, F-Net is defined as a two-way CNN that processes three-dimensional tensors, where each way is specified by the cross arrangement of Block I and Block II. As shown in Fig. 7, “Conv3D, 2×2×2 , 128” denotes a three-dimensional convolution operation, and the size of the convolution core is 2×2×2 , with 128 channels. “BN3D, 128” denotes batch normalization [28] with 128 channels. “ReLU” denotes the activation function, which is defined as a rectified linear unit [29]. “Dropout, 0.4” denotes a random drop operation to prevent overfitting [30], with a probability of 0.4. Two input samples can be converted into feature maps A and B by F-Net.

C-Net is similar to the comparator in a circuit and can be used for the comparison between feature maps A and B. If a comparison function is designed manually, it should be symmetrical to inputs A and B, that is, C(A,B)=C(B,A) . The inputs of C-Net are the feature maps obtained from the output of F-Net, and such highly nonlinear functions are difficult to design manually. However, it can be learned from the training progress [18], and therefore, C-Net needs to be constructed to learn the comparison function. As a result of training, C-Net behaves as a comparison function. The function obtained by the neural network learning does not necessarily need to strictly satisfy the symmetry. C-Net approximately satisfies the symmetry if there is no special bias, as the feature maps A and B are inputted randomly. The proposed C-Net has six layers; here, “Concatenation” denotes the concatenation layer. Two feature maps are concatenated together and fed into two convolution layers denoted as Block III with the same structure. The convolution outputs are fed into the two full-connection layers “FC, 64” and “FC, 1,” representing the cases of 64 and 1 neurons, respectively. The output layer is the Sigmoid function, which is used to obtain the normalized delta score of the feature maps A and B.

C. Few-Shot Training
FC-Net is a neural network designed for few-shot learning, and therefore, its underlying training method is different from those employed in conventional DNNs.

As described in Section II, the whole dataset is no longer simply divided into a training set and a testing one. Instead, a meta-training set containing multiple tasks needs to be generated so that each task includes a sample set and a query set for simulating the meta-testing set that comprises a support set and a test set. Algorithm 1 describes how a few-shot task is generated based on the original dataset. The generated task includes 2K samples for training and B samples for testing.


Algorithm 1
Generating a Few-Shot Task From the Dataset

Show All

Once a task is generated, it is inputted into FC-Net for training, as shown in Algorithm 2. It should be noted that the loss function used in the training process is the mean square error (MSE) function [31], defined as follows:
MSE=1n∑i=1n(yi−yiˆ)(1)
View SourceThe reason for using the MSE function instead of cross-entropy is that the output of this network is provided as a delta score, not a label. Although both predicted values and ground truths are finally binarized to {0, 1}, essentially, the network solves the regression problem, which is considered to estimate the delta score instead of marking it with a label.


Algorithm 2
Training One Task With FC-Net

Show All

The part omitted in Algorithm 2 is the backpropagation process, which is similar as in conventional DNN training. Here, we utilize the Adam optimization method based on stochastic gradient descent (SGD) [32]. According to the study [32] and the rule of thumb, the values of hyperparameters in the network are represented in Table I.

TABLE I Hyperparameter Configuration

SECTION V.Evaluation
A. Datasets
The datasets that can be used to evaluate the proposed method should satisfy the following conditions:

The datasets should contain the original raw network traffic rather than the feature vectors as a result of feature extraction.

To calculate the metrics, each sample needs to have a corresponding label.

Samples in the datasets can be packaged into few-shot tasks to evaluate whether the proposed method is still valid applied to a few-shot scenario.

In the field of network intrusion detection, the widely used datasets include various sources, such as KDD99, NSL-KDD, DEFCON, LBNL, Kyoto, ADFA, ISCX2012, CICIDS2017, etc. The datasets satisfying conditions 1) and 2) are ISCX2012 [33] and CICIDIS2017 [23]. However, for few-shot network intrusion detection, there is no suitable public dataset available at present. To satisfy condition 3, we consider the raw network traffic contained in ISCX2012 and CICIDS2017 as the data sources, and then reconstruct the few-shot datasets as ISCX2012FS and CICIDS2017FS in which samples are packaged into tasks. As the proposed construction approach is to process the raw network traffic directly, the sampling and pre-processing methods for different data sources are defined similarly.

Concerning the packet capture (PCAP) data format, the data flow reconstruction is first conducted according to the quintuple [source IP, destination IP, source port, destination port, protocol]. Then, the data flow is sampled following the principles described in Section III. According to the related research [3], if the number of samples is large, it is preferred to set the number of packets M to 6, 8, or 14, and the number of bytes N can be set between 100 and 200. However, we focus on the few-shot learning, and the proposed FC-net can be used to perform autonomous transformation and selection of features, so the parameters M and N can be even larger. In addition, the hardware accelerators, such as GPUs, will be used to run the operations, and the integer power of two can improve the overall computational efficiency. Therefore, the parameters are set to M=16 , and N=256 .

Dataset preprocessing includes two phases: normalization and anonymization:

Normalization. After sampling, the length of each data flow is M×N bytes, and the range for each byte is [0, 255]. Dividing each byte by 255 can shrink the range to [0, 1], and finally, derive the normalized data flow samples.

Anonymization. The packets captured in the target datasets include LAN IP addresses of the network, and therefore, IP addresses in the datasets should be randomized to make it closer to the real network environment [34]. The main purpose of anonymization is to prevent IP from being used for features, which are feasible in LAN, but are not feasible in real environments. As a result of randomizing IP, such a situation can be avoided. In practice, IP addresses in the packets can be overlaid by randomly generated ones, and accordingly, they will not be used as the features for classification.

Next, according to the specific conditions of different data sources, the two datasets ISCX2012FS and CICDIS2017FS were constructed. The original dataset ISCX2012 contained seven days of network traffic, including normal traffic and four types of malicious traffic. In its turn, CICIDS2017 comprised the data for five days of network traffic, including normal traffic and 14 types of malicious traffic. As there were only a limited number samples corresponding to particular types of attacks, and some labels were not matched, we selected five types of samples with the sufficient number of samples to conduct experiments. As shown in Table II, for convenience of description, a unique code was assigned for each type of attack. The prefix “i” denotes that the data is from ISCX2012, and the prefix “c” denotes that the data is from CICIDS2017. For each type of malicious traffic, we randomly selected 2,000 samples as the data source to construct tasks. Each task was defined as a few-shot binary classification task to distinguish between normal samples and a certain type of malicious samples.

TABLE II Coding for the Types of Attacks

B. Metrics
The basic unit of meta-learning is a task, and therefore evaluation of the performance of meta-learning is grounded on the estimation of the ability to accomplish tasks. Concerning binary classification tasks, the results of classification can be correct or incorrect. All results correspond to the following four outcomes:

True Positive (TP): Normal samples are classified as normal ones;

True Negative (TN): Malicious samples are classified as malicious ones;

False Positive (FP): Normal samples are classified as malicious ones (false alarms);

False Negative (FN): Malicious samples are classified as normal ones.

For simplicity, TP, TN, FP, and FN are used to represent the numbers of the four outcomes. On this basis, the accuracy and detection rate can be defined, as shown in Equation (2) [35].
⎧⎩⎨⎪⎪⎪⎪Accuracy (ACC)=TP+TNTP+TN+FN+FPDetection Rate (DR)=TPTP+FN(2)
View SourceRight-click on figure for MathML and additional features.

In few-shot learning, the number of samples in a single task is small, and the metrics for a single task may lack statistical significance. We repeated each experiment multiple times, and the average metrics were calculated to evaluate the overall performance.

C. Experimental Settings
The experiments were performed using the following hardware and software platforms: Intel Xeon E5-2660 v3 @2.6 GHz, 128 GB RAM, NVIDIA TESLA K40; Ubuntu 16.04 LTS, CUDA 10.0, cuDNN 7.5, and PyTorch 0.4.1. According to the data sources of the meta-training and meta-testing sets, the experiments can be divided into type 1 and type 2 experiments.

Type 1 experiments were conducted on two datasets separately. For ISCX2012FS, it contains four types of attacks. We utilized three of them as the data sources for the meta-training set and the remaining one as the data source for the meta-testing set. A sufficient number of training and testing tasks were constructed for experiments. As the number of combinations C(4,3)=4 , there were four combinations, providing four sets of the parallel experiments, and each set of experiments was repeated 1,000 times. Correspondingly, the CICIDS2017FS dataset contains five types of attacks. We used three of them as the data sources in the meta-training set, and the remaining two as the data sources in the meta-testing set. As the number of combinations C(5,3)=10 , we obtained ten combinations, resulting in ten sets for the parallel experiments. Each set of experiments was repeated 1,000 times. As each experiment was independent, we were able to run experiments in parallel on multiple computers. All of the conducted experiments took about a week to complete, using two computers; each of them included two physical CPUs (two Xeon E5-2660 v3 have a total of 20 cores with 40 threads) and two GPUs (two NVIDIA TESLA K40 have a total of 5,760 CUDA cores). The average metrics were considered to evaluate the performance. The fitting and generalization abilities of the proposed method were evaluated. Fitting ability refers to the ability to detect the types of attacks in the meta-training set. As the model learns these types of samples during training, it is not real few-shot detection in the strict sense, but it can reflect the ability to fit the known types of samples. Generalization ability refers to the ability to detect the types of attacks that do not appear in the meta-training set. The model has to learn from the K samples, performing the real few-shot detection of new types of attacks.

Type 2 experiments were conducted on the basis of type 1 ones but on the two datasets as data sources. For example, three types of attack traffic in ISCX2012FS were used as the data sources in the meta-training set, and five types of attack traffic in CICIDS2017FS we considered as the data sources in the meta-testing set. The two datasets were from two networks corresponding to the different hardware and software environments, and the types of attacks also differed between each other. Therefore, the detection was more challenging, and the adaptability of the proposed method can be fully evaluated. For each task, we set K=5 and 10. Accordingly, the number of samples per class was 5 or 10. This allowed simulating a scene that we could obtain only a limited number of samples in the real environment.

D. Detection Results
First, the convergence of the model had to be confirmed through checking the value of the loss function after each episode. As shown in Fig. 8, for the first 75 iterations, the value of the loss function dropped rapidly. After 75 to 100 iterations, the value of the loss function tended to be stable. Therefore, the episode value was set to 100 to conduct the following experiments.


Fig. 8.
The loss after each episode during training.

Show All

The detection results of type 1 experiments on the ISCX2012FS dataset are shown in Fig. 9. Note that in the conducted experiments, we rotated the training and testing types of samples and conducted parallel experiments. Taking Fig. 9(a) as an example, in this experiment, the samples of types iA, iB, and iC in the ISCX2012FS dataset were used for training; however, the samples of all types were tested. As the model was trained on a large number of samples of types iA, iB, and iC, only type iD was a real few-shot type used in testing. In this experiment, we denoted iA, iB, and iC as training types and iD as the few-shot type. Here, we can draw a conclusion based on the comparison within the results presented in Fig. 9. The detection results of few-shot types were not always worse than those of training types. Unexpectedly, in many cases, the detection results of few-shot types were better compared with those of training types. For example, in Fig. 9(a), the detection rate of few-shot type iD was significantly better compared with the results of training types iA, iB, and iC. Similarly, in the experiments on the CICIDS2017FS dataset, each experiment had three training types, and only two types were of few-shot types. These detailed detection results were omitted. As the main goal was to implement few-shot detection, we focused only on the detection results obtained for the few-shot types. In Table III and Table IV, we summarize the detection results of type 1 experiments on the ISCX2012FS and CICIDS2017FS datasets, respectively, and all listed detection results correspond to few-shot types.

TABLE III Detection Results of Type 1 Experiments on the ISCX2012FS Dataset (Few-Shot Types)

TABLE IV Detection Results of Type 1 Experiments on the CICIDS2017FS Dataset (Few-Shot Types)


Fig. 9.
Detection results of type 1 experiments on the ISCX2012FS dataset (K = 5; 1000 time; the range from 25% to 75%).

Show All

The comparison between the results presented in Table III and Table IV leads to the following two conclusions:

In different datasets, selection of training types has a certain impact on the detection results. In the ISCX2012FS dataset, it is not important to select which types to use as training ones, while there are differences in the CICIDS2017FS dataset. We can take arbitrary three types of samples from ISCX2012FS dataset as training types and can obtain similar results, while for the CICIDS2017FS, it is not applicable.

The proposed method is not sensitive to the number of samples K . When setting K=5 to 10, both are few-shot, but the number of samples is doubled. The detection results demonstrate that unlike in conventional supervised learning algorithms that require a large number of samples for training, the detection results of the proposed method do not differ significantly depending on the number of samples.

The above conclusions confirm that the proposed detection method based on the meta-learning framework can learn how to extract and compare network traffic features based on the training types of samples, instead of learning their features directly. Training types serve only as the materials for F-Net and C-Net to learn extracting and comparing features, respectively. In other words, learning to distinguish training types is only a process, not an ultimate goal.

Type 2 corresponds to the experiments in which two datasets are used in cross. The detection results trained on CICIDS2017FS and tested on ISCX2012FS are shown in Table V, and those trained on ISCX2012FS and tested on CICIDS2017FS are shown in Table VI. In type 2 experiments, none of types in the meta-testing set are involved in training, and therefore they are all few-shot types. Based on the results of type 2 experiments, two conclusions can be drawn:

Training and testing across different datasets are operationally feasible, although the two considered datasets have been collected from the networks composed of different hardware and software environments, and the attack types have been different. In a broad sense, they belong to the same types of computer networks, and the traffic has certain commonalities.

The phenomenon of “Stones from other hills may serve to polish the jade of this one” is observed. Table IV and Table VI both represent the detection results on the CICIDS2017FS dataset. The overall results provided in Table VI are better than the corresponding results in Table IV (K=5 ). It is worth noting that Table VI lists the results of type 2 experiments, while Table IV outlines the results of type 1 ones. On the contrary, the overall results in Table III are also better than those in Table V. That is, the results of type 1 experiments are not certainly better compared with those of type 2 experiments. The model trained on ISCX2012FS achieves better performance compared with that trained on the CICIDS2017FS dataset, regardless of which dataset is used for testing. It shows that ISCX2012FS is a more suitable dataset for meta-learning compared with CICIDS2017FS.

TABLE V Detection Results of Type 2 Experiments: Training on CICIDS2017FS, Testing on ISCX2012FS
Table V- 
Detection Results of Type 2 Experiments: Training on CICIDS2017FS, Testing on ISCX2012FS
TABLE VI Detection Results of Type 2 Experiments: Training on ISCX2012FS, Testing on CICIDS2017FS
Table VI- 
Detection Results of Type 2 Experiments: Training on ISCX2012FS, Testing on CICIDS2017FS
SECTION VI.Comparison and Discussion
Few-shot network intrusion detection is a relatively new topic. As far as we know, there is almost no related works available for comparison, and there are no suitable datasets for benchmarking. As few-shot network intrusion detection is different from the conventional intrusion detection, we construct the datasets based on real network traffic. Specifically, two public network traffic data sources are utilized to construct the few-shot detection datasets and evaluate the proposed method. The few-shot dataset ISCX2012FS composed in this study shares the same raw network traffic with the original ISCX2012 dataset (the same is for CICIDS2017FS and CICIDS2017). Therefore, we provide an overview on several most recent studies using the ISCX2012 or CICIDS2017 datasets. The comparison of detection results and the number of samples in the proposed method and related research works is represented in Table VII.

TABLE VII Comparison of Detection Results and the Number of Samples in the Proposed Method and Related Research Works

In Table VII, except for the methods proposed in this paper, none of other considered approaches are the few-shot detection ones as they all require a large number of samples for training. Among them, the RFA method [2] attempted to run few-shot detection, and the experiment results showed that 500 samples were necessary to achieve acceptable detection performance. If there were only 25 samples, the detection rate dropped significantly, and the practical value was lost. This could be explained according to the “free lunch theory” in supervised learning [38]: there is no algorithm to solve all problems. As long as the datasets are different, the algorithms will be different. Among the existing detection methods listed in Table VII, only training on a large number of samples could ensure acceptable performance, and it was achieved only on the type of samples used for training. A large number of research works on network intrusion detection indicated that it is difficult to implement few-shot detection. If only a limited number of samples are considered, the “free lunch theory” is correct. However, we consider the real world as an open environment; that is, although there are only a small number of samples for a certain new type of attack, we can obtain a large number of samples corresponding to the other types of attacks in other networks. For example, the detection results of type 2 experiments indicate that if we have only five samples with labels (that can be labeled manually) in the CICIDS2017FS dataset, we can still train the model on the ISCX2012FS dataset, which has a large number of labeled samples, and the trained model can be applied directly to detect the new type of samples in the CICIDS2017FS dataset without any modification.

To further demonstrate the necessity of few-shot detection, we considered ResNet-18 for verification. ResNet-18 is a conventional CNN model for image recognition [39]. We modified the input and output layers of ResNet-18 to complete the network intrusion detection task. Without loss of generality, we utilized iA, iB, and iC as training types, and then tested the model on all types. The detection results are shown in table VIII. As iA, iB, and iC were the types learnt by the model during training, the detection results were better. However, the remaining several types were not learnt by the model, and accordingly, the detection results were very poor, even similar to random guessing. This experiment further demonstrates the importance of few-shot network intrusion detection.

TABLE VIII Detection Results of a Conventional CNN Model
Table VIII- 
Detection Results of a Conventional CNN Model
Not all the datasets are created equal. In the study [40], it is stated that not all samples are created equal, and therefore, various samples can be weighted differently in the training process to obtain better results. According to the research work [41], not all neural network layers are created equal. In a neural network, some layers are more critical than others. Experimental results presented in this paper show that concerning few-shot detection, the model requires a dataset to construct similar tasks for training, and not all the datasets are created equal. For instance, ISCX2012FS is deemed a more suitable dataset compared with CICIDS2017FS while training the neural network for few-shot network intrusion detection. We consider this as a meaningful point as it is similar to human learning progress. For example, it is well-known that high-quality textbooks are essential in human learning.

Potential threats of the proposed detection method from adversarial samples. It should be noted that adversarial samples do pose threats to the proposed detection method as it is based on DNNs [42]. As the difference between an attack sample and a normal sample is minor (relative to the classification tasks of photos and speech), the proposed detection method is theoretically more vulnerable to adversarial samples. It can be a major direction of future research.

The codes and datasets we used are available at https://ieis.ac.cn/fsids for academic use.

SECTION VII.Conclusion
In the present paper, we proposed a novel detection method based on the meta-learning framework to implement few-shot network intrusion detection. For this purpose, a basic binary classification task was defined and a pair of network traffic samples including a normal unaffected sample and a malicious one were constructed for learning. The proposed method accomplishes this task by comparing the pair of samples using a novel deep neural network named FC-Net. The proposed FC-Net comprises the feature extraction network F-Net and the comparison network C-Net. FC-Net can be used to generate a pair of feature maps based on a pair of network traffic samples. Then, it is applied to compare the feature maps and finally to calculate the delta score, determining whether the input pair of samples corresponds to the same type. After training on a large number of basic tasks, FC-Net can acquire enough prior knowledge to detect new types of network traffic samples with only a small number of labeled samples, thereby enabling effective few-shot network intrusion detection.

To evaluate the proposed detection method, we implemented an approach to construct datasets for few-shot network intrusion detection based on real network traffic. We constructed two datasets incorporating the data from public network traffic data sources, and then, we conducted two types of experiments on these datasets. The experimental results demonstrated that the proposed detection method is universal and is not limited to specific datasets or attack types. The outcomes of training and testing on the same datasets suggested that the proposed method allows achieving the average detection rate up to 98.88%, which is close to the results obtained using the detection methods trained on a large number of samples. Furthermore, we altered the meta-training and meta-testing sets based on different datasets and performed experiments training on the one dataset and testing on the other ones. As a result, we observed that the proposed method can achieve better performance. Namely, it is capable of detecting new types of samples using a limited number of labels in an untrained dataset based on learned prior knowledge, reaching the average detection rate up to 99.62%.